Using TensorFlow backend.
[2019-03-23 12:28:22,238] A3C_AGENT_MAIN INFO:Namespace(action_repeat_n=1, action_space='part3_v1', activation='relu', agent_num=5, check_args_only=False, clip_norm=5.0, debug_log_prob=0.0005, decay_steps=1000000, dropout_prob=0.0, end_e=0.0, env='Part3-NA-Pit-Train-v1', eval_act_func='part3_pit_det_v1', eval_env_res_max_keep=50, eval_epi_num=1, eval_freq=25000, forecast_dim=0, gamma=0.99, h_decay_bounds=[], h_regu_frac=[0.0], init_e=0.0, isNoisyNet=True, isNoisyNetEval_rmNoise=True, is_greedy_policy=False, is_learning_rate_decay_staircase=False, is_warm_start=False, job_mode='Train', learning_rate=5e-05, learning_rate_decay_rate=1.0, learning_rate_decay_steps=100000, max_interactions=2500000, metric_func='part3_v1', model_dir='None', model_param=[256, 8], model_type='nn', num_threads=16, output='./Part3-NA-Pit-Train-v1-res1', p_loss_frac=1.0, raw_state_prcs_func='cslDx_1', reward_func='part3_v3', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=1.0, rwd_p_para=1.0, save_freq=500000, save_max_to_keep=5, save_scope='all', sharedNet_type='Dense', state_dim=17, test_env=['Part3-NA-Pit-Test-v1', 'Part3-NA-Pit-Test-v2', 'Part3-NA-Pit-Test-v3', 'Part3-NA-Pit-Test-v4'], test_mode='Multiple', train_act_func='part3_pit_sto_v1', train_freq=5, v_loss_frac=0.5, violation_penalty_scl=50.0, weight_initer='glorot_uniform', window_len=21)
[2019-03-23 12:28:22,239] A3C_AGENT_MAIN INFO:Start compiling...
2019-03-23 12:28:22.326234: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[2019-03-23 12:28:51,350] A3C_AGENT_MAIN INFO:Start the learning...
[2019-03-23 12:28:51,350] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['Part3-NA-Pit-Train-v1', 'Part3-NA-Pit-Test-v1', 'Part3-NA-Pit-Test-v2', 'Part3-NA-Pit-Test-v3', 'Part3-NA-Pit-Test-v4'] ...
[2019-03-23 12:28:51,361] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation worker starts!
[2019-03-23 12:28:51,364] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation worker starts!
[2019-03-23 12:28:51,367] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation worker starts!
[2019-03-23 12:28:51,372] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation worker starts!
[2019-03-23 12:28:51,376] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation worker starts!
[2019-03-23 12:28:51,376] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 12:28:51,376] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2019-03-23 12:28:51,467] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:28:51,468] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run1
[2019-03-23 12:28:52,377] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 12:28:52,381] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2019-03-23 12:28:52,539] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:28:52,539] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run1
[2019-03-23 12:28:52,924] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 12:28:52,925] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:28:52,925] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:28:52,925] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:28:52,925] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:28:52,926] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:28:52,926] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:28:52,926] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:28:52,926] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:28:52,926] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:28:52,927] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:28:52,931] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run1
[2019-03-23 12:28:52,931] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run1
[2019-03-23 12:28:52,943] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run1
[2019-03-23 12:28:52,944] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run1
[2019-03-23 12:28:52,983] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run1
[2019-03-23 12:28:53,382] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 12:28:53,383] A3C_AGENT_WORKER-Thread-9 INFO:Local worker starts!
[2019-03-23 12:28:53,491] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:28:53,492] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run1
[2019-03-23 12:28:54,384] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 12:28:54,387] A3C_AGENT_WORKER-Thread-10 INFO:Local worker starts!
[2019-03-23 12:28:54,765] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:28:54,766] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run1
[2019-03-23 12:28:55,386] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 12:28:55,387] A3C_AGENT_WORKER-Thread-11 INFO:Local worker starts!
[2019-03-23 12:28:55,439] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 12:28:55,440] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.851369125, 77.645829625, 1.0, 1.0, 0.3094280326948503, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 338066.4319928159, 338066.4319928159, 116873.5832334137]
[2019-03-23 12:28:55,440] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:28:55,520] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.21979631 0.19539502 0.1842761  0.18875884 0.21177374], sampled 0.8211302802767931
[2019-03-23 12:28:55,550] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:28:55,575] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run1
[2019-03-23 12:28:56,389] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 12:28:56,395] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2019-03-23 12:28:56,516] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:28:56,517] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run1
[2019-03-23 12:28:57,394] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 12:28:57,400] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2019-03-23 12:28:57,514] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:28:57,535] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run1
[2019-03-23 12:28:58,401] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 12:28:58,404] A3C_AGENT_WORKER-Thread-14 INFO:Local worker starts!
[2019-03-23 12:28:58,537] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:28:58,551] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run1
[2019-03-23 12:28:59,404] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 12:28:59,408] A3C_AGENT_WORKER-Thread-15 INFO:Local worker starts!
[2019-03-23 12:28:59,533] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:28:59,554] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run1
[2019-03-23 12:29:00,407] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 12:29:00,413] A3C_AGENT_WORKER-Thread-16 INFO:Local worker starts!
[2019-03-23 12:29:00,530] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:29:00,550] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run1
[2019-03-23 12:29:01,409] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 12:29:01,413] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2019-03-23 12:29:01,537] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:29:01,562] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run1
[2019-03-23 12:29:02,415] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 12:29:02,419] A3C_AGENT_WORKER-Thread-18 INFO:Local worker starts!
[2019-03-23 12:29:02,543] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:29:02,575] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run1
[2019-03-23 12:29:03,419] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 12:29:03,424] A3C_AGENT_WORKER-Thread-19 INFO:Local worker starts!
[2019-03-23 12:29:03,543] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:29:03,563] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run1
[2019-03-23 12:29:04,426] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 12:29:04,430] A3C_AGENT_WORKER-Thread-20 INFO:Local worker starts!
[2019-03-23 12:29:04,540] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:29:04,562] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run1
[2019-03-23 12:29:05,432] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 12:29:05,435] A3C_AGENT_WORKER-Thread-21 INFO:Local worker starts!
[2019-03-23 12:29:05,568] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:29:05,592] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run1
[2019-03-23 12:29:06,436] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 12:29:06,440] A3C_AGENT_WORKER-Thread-22 INFO:Local worker starts!
[2019-03-23 12:29:06,576] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:29:06,600] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run1
[2019-03-23 12:29:17,856] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 12:29:17,858] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.77086930166667, 91.33069192333333, 1.0, 2.0, 0.2403415169060597, 1.0, 1.0, 0.2403415169060597, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 548227.4761929433, 548227.4761929429, 182015.3307695845]
[2019-03-23 12:29:17,859] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:29:17,860] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.21726187 0.19890724 0.18291336 0.18350899 0.2174086 ], sampled 0.8101504887771067
[2019-03-23 12:29:23,389] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 12:29:23,391] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.88333333333333, 76.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 1.0, 0.3341654262245907, 6.9112, 6.9112, 95.55338769695034, 564971.3209172257, 564971.3209172257, 215319.6029421616]
[2019-03-23 12:29:23,394] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:29:23,398] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.21857719 0.19899863 0.1808188  0.18560386 0.21600148], sampled 0.265235403040482
[2019-03-23 12:29:29,708] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 12:29:29,709] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.95564356666667, 91.52066782, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5634876721058041, 6.911199999999999, 6.9112, 95.55338769695034, 327744.0379135608, 327744.0379135612, 88492.56529036877]
[2019-03-23 12:29:29,710] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:29:29,713] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.21609998 0.19815949 0.18264836 0.1845489  0.21854335], sampled 0.4080915140475663
[2019-03-23 12:29:37,878] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 12:29:37,880] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.94089905333333, 94.62121629333333, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 1.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 436706.4390804716, 436706.4390804716, 188191.6560156989]
[2019-03-23 12:29:37,882] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:29:37,884] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.21622144 0.19804619 0.1862259  0.18602578 0.21348076], sampled 0.4474426714217209
[2019-03-23 12:30:39,289] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 2452.3442 1996844513.0549 939.0000
[2019-03-23 12:30:39,341] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 2598.1487 2085931596.3942 754.0000
[2019-03-23 12:30:39,461] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2306.3110 2026596861.6791 1203.0000
[2019-03-23 12:30:39,548] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 2340.7096 2011625537.8754 962.0000
[2019-03-23 12:30:39,636] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 2415.2064 2003239285.0134 965.0000
[2019-03-23 12:30:40,649] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 0, evaluation results [0.0, 2598.1487320508613, 2085931596.3942, 754.0, 2452.344238253997, 1996844513.0548944, 939.0, 2415.2064095698224, 2003239285.0133998, 965.0, 2306.310968786595, 2026596861.6790738, 1203.0, 2340.7096406568394, 2011625537.8753574, 962.0]
[2019-03-23 12:30:44,295] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.21789046 0.19967873 0.18311177 0.1876493  0.21166973], sum to 1.0000
[2019-03-23 12:30:44,301] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5121
[2019-03-23 12:30:44,454] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.43333333333333, 90.0, 1.0, 2.0, 0.3620249819331597, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 397494.8465193326, 397494.8465193328, 117046.4831166837], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 9600.0000, 
sim time next is 10200.0000, 
raw observation next is [17.36666666666667, 89.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 1.0, 0.3429186800625585, 6.911199999999999, 6.9112, 77.32846344354104, 397633.1681080029, 397633.1681080032, 149584.8386733827], 
processed observation next is [1.0, 0.08695652173913043, 0.42575757575757595, 0.89, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 0.5, 0.06131240008936929, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1472715437437048, 0.14727154374370488, 0.36484106993507975], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.7349927], dtype=float32), -1.6188763]. 
=============================================
[2019-03-23 12:30:45,092] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.21609662 0.20054138 0.18838988 0.1867877  0.2081845 ], sum to 1.0000
[2019-03-23 12:30:45,098] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0290
[2019-03-23 12:30:45,257] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.16666666666667, 99.0, 1.0, 1.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 387176.9802238122, 387176.9802238125, 173164.2107200102], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 21000.0000, 
sim time next is 21600.0000, 
raw observation next is [17.0, 100.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6674080404535951, 6.9112, 6.9112, 77.32846344354104, 384791.9738610672, 384791.9738610672, 121905.4608662947], 
processed observation next is [1.0, 0.2608695652173913, 0.4090909090909091, 1.0, 0.0, 0.5, -0.25, 0.0, 0.5, -0.25, 1.0, 1.0, 0.5248686292194217, 0.0, 0.0, 0.5084288129206541, 0.14251554587446932, 0.14251554587446932, 0.29733039235681635], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.2009358], dtype=float32), -0.037061412]. 
=============================================
[2019-03-23 12:30:55,885] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.8866216e-06 9.9999154e-01 1.1809417e-06 3.4445785e-07 9.7329412e-14], sum to 1.0000
[2019-03-23 12:30:55,892] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5266
[2019-03-23 12:30:56,052] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 82.0, 1.0, 2.0, 0.2421417372973539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 262913.1773635561, 262913.1773635563, 83261.06642049483], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 223200.0000, 
sim time next is 223800.0000, 
raw observation next is [16.25, 80.83333333333334, 1.0, 2.0, 0.239576629052281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 260127.2838018535, 260127.2838018537, 83627.69493257995], 
processed observation next is [0.0, 0.6086956521739131, 0.375, 0.8083333333333335, 1.0, 1.0, 0.049470786315351234, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09634343844513094, 0.09634343844513099, 0.20396998764043892], 
reward next is 0.7960, 
noisyNet noise sample is [array([-0.51301366], dtype=float32), -0.4313348]. 
=============================================
[2019-03-23 12:30:56,360] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.460705e-07 9.999995e-01 6.583940e-08 3.473960e-13 8.572663e-22], sum to 1.0000
[2019-03-23 12:30:56,367] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2463
[2019-03-23 12:30:56,526] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.26666666666667, 67.33333333333334, 1.0, 2.0, 0.2707195150301159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 293951.7955822961, 293951.7955822958, 100122.114035504], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 231600.0000, 
sim time next is 232200.0000, 
raw observation next is [19.45, 66.5, 1.0, 2.0, 0.2730010657191126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 296429.8966326306, 296429.8966326309, 101411.4096002441], 
processed observation next is [0.0, 0.6956521739130435, 0.5204545454545454, 0.665, 1.0, 1.0, 0.09125133214889072, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10978885060467801, 0.1097888506046781, 0.24734490146400998], 
reward next is 0.7527, 
noisyNet noise sample is [array([1.6057061], dtype=float32), -0.5209351]. 
=============================================
[2019-03-23 12:30:59,820] A3C_AGENT_WORKER-Thread-18 INFO:Local step 500, global step 7879: loss 2.1565
[2019-03-23 12:30:59,899] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 500, global step 7880: learning rate 0.0000
[2019-03-23 12:30:59,950] A3C_AGENT_WORKER-Thread-10 INFO:Local step 500, global step 7912: loss 0.9799
[2019-03-23 12:30:59,952] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 500, global step 7912: learning rate 0.0000
[2019-03-23 12:31:00,002] A3C_AGENT_WORKER-Thread-16 INFO:Local step 500, global step 7940: loss 5.5145
[2019-03-23 12:31:00,004] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 500, global step 7940: learning rate 0.0000
[2019-03-23 12:31:00,021] A3C_AGENT_WORKER-Thread-9 INFO:Local step 500, global step 7950: loss 7.3821
[2019-03-23 12:31:00,022] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 500, global step 7950: learning rate 0.0000
[2019-03-23 12:31:00,069] A3C_AGENT_WORKER-Thread-22 INFO:Local step 500, global step 7973: loss 1.3830
[2019-03-23 12:31:00,071] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 500, global step 7973: learning rate 0.0000
[2019-03-23 12:31:00,077] A3C_AGENT_WORKER-Thread-17 INFO:Local step 500, global step 7975: loss 6.9929
[2019-03-23 12:31:00,080] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 500, global step 7975: learning rate 0.0000
[2019-03-23 12:31:00,086] A3C_AGENT_WORKER-Thread-2 INFO:Local step 500, global step 7980: loss 1.9295
[2019-03-23 12:31:00,088] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 500, global step 7980: learning rate 0.0000
[2019-03-23 12:31:00,123] A3C_AGENT_WORKER-Thread-15 INFO:Local step 500, global step 7999: loss 3.5568
[2019-03-23 12:31:00,124] A3C_AGENT_WORKER-Thread-20 INFO:Local step 500, global step 8000: loss 2.9290
[2019-03-23 12:31:00,126] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 500, global step 8000: learning rate 0.0000
[2019-03-23 12:31:00,127] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 500, global step 8000: learning rate 0.0000
[2019-03-23 12:31:00,150] A3C_AGENT_WORKER-Thread-12 INFO:Local step 500, global step 8014: loss 3.6083
[2019-03-23 12:31:00,151] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 500, global step 8014: learning rate 0.0000
[2019-03-23 12:31:00,156] A3C_AGENT_WORKER-Thread-19 INFO:Local step 500, global step 8015: loss 0.2405
[2019-03-23 12:31:00,159] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 500, global step 8015: learning rate 0.0000
[2019-03-23 12:31:00,161] A3C_AGENT_WORKER-Thread-11 INFO:Local step 500, global step 8017: loss 0.8178
[2019-03-23 12:31:00,166] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 500, global step 8017: learning rate 0.0000
[2019-03-23 12:31:00,179] A3C_AGENT_WORKER-Thread-3 INFO:Local step 500, global step 8027: loss 1.9963
[2019-03-23 12:31:00,181] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 500, global step 8029: learning rate 0.0000
[2019-03-23 12:31:00,198] A3C_AGENT_WORKER-Thread-14 INFO:Local step 500, global step 8034: loss 1.2404
[2019-03-23 12:31:00,200] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 500, global step 8036: learning rate 0.0000
[2019-03-23 12:31:00,209] A3C_AGENT_WORKER-Thread-13 INFO:Local step 500, global step 8040: loss 0.1551
[2019-03-23 12:31:00,211] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 500, global step 8041: learning rate 0.0000
[2019-03-23 12:31:00,234] A3C_AGENT_WORKER-Thread-21 INFO:Local step 500, global step 8053: loss 0.8137
[2019-03-23 12:31:00,237] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 500, global step 8054: learning rate 0.0000
[2019-03-23 12:31:02,970] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.9984038e-01 1.5961486e-04 3.9345407e-10 6.9059858e-12 9.8772504e-15], sum to 1.0000
[2019-03-23 12:31:02,979] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8381
[2019-03-23 12:31:03,127] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [12.16666666666667, 74.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7447934165710988, 7.236827035176712, 6.9112, 77.3274326354662, 539133.4605594424, 433377.8695264045, 94949.00897499353], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 355800.0000, 
sim time next is 356400.0000, 
raw observation next is [12.0, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.747333548436183, 7.257591649884103, 6.9112, 77.32736171169311, 547320.1439682103, 434820.823869318, 95515.80713272405], 
processed observation next is [1.0, 0.13043478260869565, 0.18181818181818182, 0.76, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6390479263374044, 0.03463916498841026, 0.0, 0.5084215691168766, 0.20271116443267048, 0.16104474958122889, 0.23296538325054644], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.15049346], dtype=float32), -1.0472543]. 
=============================================
[2019-03-23 12:31:05,575] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 5.3312188e-08 1.9691275e-09 1.7895294e-12 1.9187222e-18], sum to 1.0000
[2019-03-23 12:31:05,582] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8031
[2019-03-23 12:31:05,586] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.0, 58.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7223043549020901, 7.047239968885954, 6.9112, 77.3280288643661, 464386.1070777762, 420203.35598675, 109000.7185971087], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 402000.0000, 
sim time next is 402600.0000, 
raw observation next is [19.0, 59.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7260813155613195, 7.078937590906852, 6.9112, 77.32792442116423, 476883.4033416541, 422406.0443822746, 109974.4443095518], 
processed observation next is [1.0, 0.6521739130434783, 0.5, 0.5933333333333333, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6086875936590279, 0.016773759090685215, 0.0, 0.5084252688891944, 0.17662348271913114, 0.15644668310454615, 0.2682303519745166], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4391836], dtype=float32), 0.078700006]. 
=============================================
[2019-03-23 12:31:05,739] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9999583e-01 4.1951776e-06 2.8222868e-08 5.7136700e-09 1.1821945e-13], sum to 1.0000
[2019-03-23 12:31:05,749] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6282
[2019-03-23 12:31:05,758] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.66666666666667, 61.33333333333334, 1.0, 1.0, 0.443375734974883, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32821223726364, 481517.6456586742, 481517.645658674, 110688.6400823512], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 404400.0000, 
sim time next is 405000.0000, 
raw observation next is [18.5, 62.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7224155205338922, 7.048173835227251, 6.9112, 77.32808169353656, 464754.266406278, 420268.1859408924, 101929.9930160043], 
processed observation next is [1.0, 0.6956521739130435, 0.4772727272727273, 0.62, 0.0, 0.5, -0.25, 0.0, 1.0, -0.25, 1.0, 0.5, 0.6034507436198461, 0.013697383522725115, 0.0, 0.5084263029431767, 0.17213120978010296, 0.155654883681812, 0.24860973906342512], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.51159066], dtype=float32), -1.4296824]. 
=============================================
[2019-03-23 12:31:05,775] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[56.91844 ]
 [57.75    ]
 [57.634693]
 [57.567204]
 [57.514435]], R is [[56.20075989]
 [56.36877823]
 [55.80509186]
 [55.24703979]
 [54.69456863]].
[2019-03-23 12:31:15,696] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1000, global step 15840: loss 0.4103
[2019-03-23 12:31:15,698] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1000, global step 15840: learning rate 0.0000
[2019-03-23 12:31:15,784] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1000, global step 15889: loss 0.3913
[2019-03-23 12:31:15,787] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1000, global step 15890: learning rate 0.0000
[2019-03-23 12:31:15,842] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1000, global step 15913: loss 0.1134
[2019-03-23 12:31:15,844] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1000, global step 15915: learning rate 0.0000
[2019-03-23 12:31:15,856] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1000, global step 15918: loss 0.1740
[2019-03-23 12:31:15,858] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1000, global step 15919: learning rate 0.0000
[2019-03-23 12:31:15,878] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1000, global step 15930: loss 0.0628
[2019-03-23 12:31:15,879] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1000, global step 15931: learning rate 0.0000
[2019-03-23 12:31:15,919] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1000, global step 15952: loss 0.0014
[2019-03-23 12:31:15,920] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1000, global step 15953: learning rate 0.0000
[2019-03-23 12:31:15,945] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1000, global step 15969: loss 0.0187
[2019-03-23 12:31:15,951] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1000, global step 15970: learning rate 0.0000
[2019-03-23 12:31:15,977] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1000, global step 15984: loss 0.2626
[2019-03-23 12:31:15,978] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1000, global step 15984: loss 0.0632
[2019-03-23 12:31:15,981] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1000, global step 15984: learning rate 0.0000
[2019-03-23 12:31:15,982] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1000, global step 15984: learning rate 0.0000
[2019-03-23 12:31:16,068] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1000, global step 16024: loss 1.7939
[2019-03-23 12:31:16,073] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1000, global step 16025: learning rate 0.0000
[2019-03-23 12:31:16,111] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1000, global step 16050: loss 1.3522
[2019-03-23 12:31:16,116] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1000, global step 16053: learning rate 0.0000
[2019-03-23 12:31:16,122] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1000, global step 16056: loss 0.5298
[2019-03-23 12:31:16,126] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1000, global step 16057: learning rate 0.0000
[2019-03-23 12:31:16,132] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1000, global step 16058: loss 1.3799
[2019-03-23 12:31:16,136] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1000, global step 16059: learning rate 0.0000
[2019-03-23 12:31:16,153] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1000, global step 16067: loss 0.2848
[2019-03-23 12:31:16,153] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1000, global step 16067: learning rate 0.0000
[2019-03-23 12:31:16,168] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1000, global step 16075: loss 0.3763
[2019-03-23 12:31:16,174] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1000, global step 16075: learning rate 0.0000
[2019-03-23 12:31:16,228] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1000, global step 16104: loss 0.0023
[2019-03-23 12:31:16,232] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1000, global step 16104: learning rate 0.0000
[2019-03-23 12:31:21,824] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9999678e-01 4.4197063e-11 3.1678308e-06 7.1707614e-14 1.6563682e-16], sum to 1.0000
[2019-03-23 12:31:21,831] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9918
[2019-03-23 12:31:21,837] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.0, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5373223351653502, 6.9112, 6.9112, 77.32846344354104, 312540.5633583782, 312540.5633583782, 99155.48208328828], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 711600.0000, 
sim time next is 712200.0000, 
raw observation next is [16.0, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5394668461256177, 6.9112, 6.9112, 77.32846344354104, 313788.3486340968, 313788.3486340968, 100374.3185921043], 
processed observation next is [1.0, 0.21739130434782608, 0.36363636363636365, 0.93, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3420954944651682, 0.0, 0.0, 0.5084288129206541, 0.11621790690151733, 0.11621790690151733, 0.2448154112002544], 
reward next is 0.7552, 
noisyNet noise sample is [array([0.06848373], dtype=float32), 0.77551264]. 
=============================================
[2019-03-23 12:31:23,364] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 5.2074378e-10 4.3847724e-08 1.9534933e-10 2.8244629e-12], sum to 1.0000
[2019-03-23 12:31:23,369] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1536
[2019-03-23 12:31:23,377] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1123556.746872791 W.
[2019-03-23 12:31:23,383] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.0, 55.0, 1.0, 2.0, 0.5047877228547464, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9524611583530901, 6.94744073564504, 6.9112, 77.32837453941579, 1123556.746872791, 1111786.510718708, 257753.8655529419], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 738000.0000, 
sim time next is 738600.0000, 
raw observation next is [27.83333333333334, 55.5, 1.0, 2.0, 0.3325447830643633, 1.0, 1.0, 0.3325447830643633, 1.0, 2.0, 0.6736337135998648, 6.9112, 6.9112, 77.3421103, 1133391.589701489, 1133391.589701489, 272329.759109334], 
processed observation next is [1.0, 0.5652173913043478, 0.9015151515151518, 0.555, 1.0, 1.0, 0.1656809788304541, 1.0, 0.5, 0.1656809788304541, 1.0, 1.0, 0.5337624479998069, 0.0, 0.0, 0.5085185399722538, 0.41977466285240334, 0.41977466285240334, 0.6642189246569121], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.01785653], dtype=float32), 0.2788098]. 
=============================================
[2019-03-23 12:31:25,468] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.000000e+00 5.497788e-11 2.361929e-10 1.468506e-10 7.525558e-11], sum to 1.0000
[2019-03-23 12:31:25,475] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5758
[2019-03-23 12:31:25,481] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 579225.5687353527 W.
[2019-03-23 12:31:25,484] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.83333333333334, 73.83333333333334, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7725191787350812, 7.338516030365377, 6.9112, 77.32741203705612, 579225.5687353527, 440443.9491849214, 136619.3100604303], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 778200.0000, 
sim time next is 778800.0000, 
raw observation next is [22.66666666666667, 74.66666666666667, 1.0, 1.0, 0.2309686628247506, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4617261997961477, 6.9112, 6.9112, 77.32820665465796, 525825.8994253775, 525825.8994253775, 169751.7377093604], 
processed observation next is [0.0, 0.0, 0.6666666666666669, 0.7466666666666667, 1.0, 0.5, 0.03871082853093823, 0.0, 1.0, -0.25, 1.0, 1.0, 0.23103742828021104, 0.0, 0.0, 0.5084271245531219, 0.19475033312051018, 0.19475033312051018, 0.41402862855941563], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0700942], dtype=float32), 0.72165686]. 
=============================================
[2019-03-23 12:31:26,962] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.691452   0.10263679 0.13225591 0.05669281 0.01696254], sum to 1.0000
[2019-03-23 12:31:26,966] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2130
[2019-03-23 12:31:26,969] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 605003.5860551893 W.
[2019-03-23 12:31:27,142] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.66666666666666, 81.66666666666667, 1.0, 2.0, 0.2666688152442991, 0.0, 1.0, 0.0, 1.0, 1.0, 0.540151148242187, 6.9112, 6.9112, 77.32846344354047, 605003.5860551893, 605003.5860551893, 185399.5195052162], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 811200.0000, 
sim time next is 811800.0000, 
raw observation next is [25.0, 81.0, 1.0, 2.0, 0.2719571463207645, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5507635730857815, 6.9112, 6.9112, 77.32846344354104, 616263.7675836701, 616263.7675836701, 187138.7388370078], 
processed observation next is [0.0, 0.391304347826087, 0.7727272727272727, 0.81, 1.0, 1.0, 0.08994643290095562, 0.0, 1.0, -0.25, 1.0, 1.0, 0.35823367583683074, 0.0, 0.0, 0.5084288129206541, 0.22824583984580374, 0.22824583984580374, 0.4564359483829459], 
reward next is 0.5436, 
noisyNet noise sample is [array([-0.43018988], dtype=float32), -1.0060699]. 
=============================================
[2019-03-23 12:31:31,253] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1500, global step 23799: loss 3.9173
[2019-03-23 12:31:31,257] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1500, global step 23799: learning rate 0.0000
[2019-03-23 12:31:31,343] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0257569e-03 1.0605135e-01 8.9291245e-01 1.0439486e-05 2.0197672e-09], sum to 1.0000
[2019-03-23 12:31:31,349] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1148
[2019-03-23 12:31:31,354] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.16666666666667, 82.16666666666667, 1.0, 2.0, 0.2206331234376163, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4428751767201415, 6.911199999999999, 6.9112, 77.32846344354104, 503069.9290380511, 503069.9290380513, 168938.1290733945], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 897000.0000, 
sim time next is 897600.0000, 
raw observation next is [22.33333333333334, 81.33333333333334, 1.0, 2.0, 0.2211964323291551, 0.0, 2.0, 0.0, 1.0, 2.0, 0.444193607571637, 6.911199999999999, 6.9112, 77.32846344354104, 504420.0468266211, 504420.0468266213, 169189.0470274654], 
processed observation next is [0.0, 0.391304347826087, 0.6515151515151518, 0.8133333333333335, 1.0, 1.0, 0.02649554041144385, 0.0, 1.0, -0.25, 1.0, 1.0, 0.20599086795948146, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18682223956541522, 0.1868222395654153, 0.4126562122621107], 
reward next is 0.5873, 
noisyNet noise sample is [array([0.5560231], dtype=float32), 1.2858914]. 
=============================================
[2019-03-23 12:31:31,452] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1500, global step 23902: loss 1.2831
[2019-03-23 12:31:31,455] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1500, global step 23903: learning rate 0.0000
[2019-03-23 12:31:31,525] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1500, global step 23944: loss 4.8233
[2019-03-23 12:31:31,529] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1500, global step 23944: learning rate 0.0000
[2019-03-23 12:31:31,530] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1500, global step 23945: loss 0.7231
[2019-03-23 12:31:31,535] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1500, global step 23946: learning rate 0.0000
[2019-03-23 12:31:31,555] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1500, global step 23959: loss 3.6192
[2019-03-23 12:31:31,557] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1500, global step 23959: learning rate 0.0000
[2019-03-23 12:31:31,576] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1500, global step 23967: loss 0.7799
[2019-03-23 12:31:31,578] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1500, global step 23968: learning rate 0.0000
[2019-03-23 12:31:31,588] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1500, global step 23973: loss 1.1550
[2019-03-23 12:31:31,589] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1500, global step 23973: learning rate 0.0000
[2019-03-23 12:31:31,608] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1500, global step 23982: loss 1.1804
[2019-03-23 12:31:31,610] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1500, global step 23982: learning rate 0.0000
[2019-03-23 12:31:31,615] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1500, global step 23982: loss 0.8175
[2019-03-23 12:31:31,618] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1500, global step 23985: learning rate 0.0000
[2019-03-23 12:31:31,638] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1500, global step 23996: loss 1.6968
[2019-03-23 12:31:31,640] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1500, global step 23998: learning rate 0.0000
[2019-03-23 12:31:31,662] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1500, global step 24014: loss 0.1739
[2019-03-23 12:31:31,667] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1500, global step 24014: learning rate 0.0000
[2019-03-23 12:31:31,689] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1500, global step 24026: loss 0.6547
[2019-03-23 12:31:31,691] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1500, global step 24028: learning rate 0.0000
[2019-03-23 12:31:31,722] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1500, global step 24042: loss 0.2477
[2019-03-23 12:31:31,726] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1500, global step 24042: learning rate 0.0000
[2019-03-23 12:31:31,730] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1500, global step 24044: loss 0.3976
[2019-03-23 12:31:31,736] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1500, global step 24044: learning rate 0.0000
[2019-03-23 12:31:31,843] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1500, global step 24109: loss 0.5898
[2019-03-23 12:31:31,847] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1500, global step 24110: learning rate 0.0000
[2019-03-23 12:31:31,861] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1500, global step 24113: loss 1.4325
[2019-03-23 12:31:31,862] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1500, global step 24113: learning rate 0.0000
[2019-03-23 12:31:33,389] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.6590067e-05 3.4050788e-03 9.9654585e-01 2.5113220e-06 3.0501258e-11], sum to 1.0000
[2019-03-23 12:31:33,396] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5480
[2019-03-23 12:31:33,569] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.0, 94.0, 1.0, 2.0, 0.2127801077888758, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4245663284911103, 6.9112, 6.9112, 77.32846344354104, 483979.262929695, 483979.262929695, 165697.4067866134], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 934200.0000, 
sim time next is 934800.0000, 
raw observation next is [19.66666666666667, 96.0, 1.0, 2.0, 0.2111379339305669, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4208257072463293, 6.9112, 6.9112, 77.32846344354104, 479984.1594562021, 479984.1594562021, 165110.3750347367], 
processed observation next is [0.0, 0.8260869565217391, 0.5303030303030305, 0.96, 1.0, 1.0, 0.013922417413208613, 0.0, 1.0, -0.25, 1.0, 1.0, 0.17260815320904185, 0.0, 0.0, 0.5084288129206541, 0.17777191090970448, 0.17777191090970448, 0.40270823179204074], 
reward next is 0.5973, 
noisyNet noise sample is [array([-0.64688355], dtype=float32), -1.1897435]. 
=============================================
[2019-03-23 12:31:33,672] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 12:31:33,676] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:31:33,678] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:31:33,679] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:31:33,679] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:31:33,680] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:31:33,681] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:31:33,680] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:31:33,681] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:31:33,684] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:31:33,687] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:31:33,697] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run2
[2019-03-23 12:31:33,697] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run2
[2019-03-23 12:31:33,697] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run2
[2019-03-23 12:31:33,776] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run2
[2019-03-23 12:31:33,798] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run2
[2019-03-23 12:31:42,819] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-8.9664805e-05], dtype=float32), 0.016889991]
[2019-03-23 12:31:42,820] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.7, 40.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 347014.4791285759, 347014.4791285755, 139232.8502078445]
[2019-03-23 12:31:42,821] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:31:42,823] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.7138742e-08 1.4612704e-06 9.9999857e-01 1.3448371e-11 1.0199064e-19], sampled 0.6863147769172672
[2019-03-23 12:31:51,210] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-8.9664805e-05], dtype=float32), 0.016889991]
[2019-03-23 12:31:51,212] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.32091979, 100.0, 1.0, 2.0, 0.2694133617392626, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5456805816482854, 6.9112, 6.9112, 95.55338769695034, 610894.2138021934, 610894.2138021934, 190980.9409580772]
[2019-03-23 12:31:51,212] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:31:51,213] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.47178029e-08 7.61180786e-07 9.99999285e-01 4.06282733e-12
 1.26202324e-20], sampled 0.1871729725001572
[2019-03-23 12:31:53,851] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-8.9664805e-05], dtype=float32), 0.016889991]
[2019-03-23 12:31:53,852] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [9.080796824, 75.39196072833333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3496517766857336, 6.911199999999999, 6.9112, 95.55338769695034, 406766.0153436143, 406766.0153436146, 119631.744568432]
[2019-03-23 12:31:53,853] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:31:53,855] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.5641218e-07 3.2638777e-06 9.9999666e-01 6.0365643e-11 1.4100148e-18], sampled 0.8127229712692283
[2019-03-23 12:32:06,065] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-8.9664805e-05], dtype=float32), 0.016889991]
[2019-03-23 12:32:06,067] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [27.56380803, 52.97376048333334, 1.0, 2.0, 0.2225448689151412, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4476439850618023, 6.911200000000001, 6.9112, 95.55338769695034, 507662.1706961438, 507662.1706961435, 174711.2677444612]
[2019-03-23 12:32:06,068] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:32:06,072] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.1065374e-08 4.0229648e-07 9.9999964e-01 1.2155300e-12 1.5315692e-21], sampled 0.3947786799451307
[2019-03-23 12:32:11,784] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-8.9664805e-05], dtype=float32), 0.016889991]
[2019-03-23 12:32:11,785] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.5, 73.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3331511490499635, 6.911199999999999, 6.9112, 77.32846344354104, 384178.9211306509, 384178.9211306512, 150582.6818201465]
[2019-03-23 12:32:11,787] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:32:11,790] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.1841444e-08 6.8752462e-07 9.9999928e-01 3.2985225e-12 8.6778872e-21], sampled 0.25220635977543615
[2019-03-23 12:32:19,296] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-8.9664805e-05], dtype=float32), 0.016889991]
[2019-03-23 12:32:19,299] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.96280649, 76.73559325, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3169725232162416, 6.9112, 6.9112, 95.55338769695034, 365820.6952488237, 365820.6952488237, 152912.3142976822]
[2019-03-23 12:32:19,300] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:32:19,302] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.4790085e-08 1.4351143e-06 9.9999857e-01 1.2944080e-11 9.4472485e-20], sampled 0.832692089979442
[2019-03-23 12:33:12,051] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3519.8162 2104073997.2458 178.0000
[2019-03-23 12:33:12,248] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3119.5914 2108961267.6794 368.0000
[2019-03-23 12:33:12,324] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2760.0075 2124072790.5486 757.0000
[2019-03-23 12:33:12,359] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3362.1543 2098018266.2279 179.0000
[2019-03-23 12:33:12,416] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3614.9672 2175281892.2042 245.0000
[2019-03-23 12:33:13,434] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 25000, evaluation results [25000.0, 3614.967212759758, 2175281892.2041974, 245.0, 3362.1543063821155, 2098018266.227916, 179.0, 3519.816163416593, 2104073997.245846, 178.0, 2760.0074851005825, 2124072790.5485613, 757.0, 3119.5913605842084, 2108961267.6794324, 368.0]
[2019-03-23 12:33:19,904] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.8173231e-01 1.7993445e-02 2.7171278e-04 2.3460661e-06 9.5845131e-08], sum to 1.0000
[2019-03-23 12:33:19,912] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2023
[2019-03-23 12:33:20,084] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [13.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3551704521678019, 6.911200000000001, 6.9112, 77.32846344354104, 206567.039011478, 206567.0390114778, 65077.96309197858], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1054800.0000, 
sim time next is 1055400.0000, 
raw observation next is [13.0, 94.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6849034880460836, 6.9112, 6.9112, 77.32846344354104, 398418.2378111776, 398418.2378111776, 91917.41516666021], 
processed observation next is [1.0, 0.21739130434782608, 0.22727272727272727, 0.9400000000000002, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5498621257801195, 0.0, 0.0, 0.5084288129206541, 0.14756231030043615, 0.14756231030043615, 0.22418881747965905], 
reward next is 0.7758, 
noisyNet noise sample is [array([1.9506487], dtype=float32), -0.15339626]. 
=============================================
[2019-03-23 12:33:21,915] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9999940e-01 3.2964587e-07 2.2132433e-07 4.8651270e-09 4.2387955e-13], sum to 1.0000
[2019-03-23 12:33:21,923] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4212
[2019-03-23 12:33:21,928] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 765612.7947935734 W.
[2019-03-23 12:33:21,935] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.0, 69.0, 1.0, 2.0, 0.3375712810959696, 1.0, 2.0, 0.3375712810959696, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 765612.7947935734, 765612.7947935734, 185184.7434908181], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1090800.0000, 
sim time next is 1091400.0000, 
raw observation next is [22.16666666666667, 68.33333333333333, 1.0, 2.0, 0.268560306273703, 1.0, 2.0, 0.268560306273703, 1.0, 1.0, 0.5342623140218403, 6.911199999999999, 6.9112, 77.3421103, 915305.3946666726, 915305.3946666728, 235004.7194097075], 
processed observation next is [1.0, 0.6521739130434783, 0.6439393939393941, 0.6833333333333332, 1.0, 1.0, 0.0857003828421287, 1.0, 1.0, 0.0857003828421287, 1.0, 0.5, 0.33466044860262906, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.33900199802469355, 0.3390019980246936, 0.5731822424627012], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9013551], dtype=float32), -0.24341613]. 
=============================================
[2019-03-23 12:33:25,422] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9984574e-01 1.4856702e-05 1.3510673e-04 4.1580329e-06 6.3531020e-09], sum to 1.0000
[2019-03-23 12:33:25,427] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9162
[2019-03-23 12:33:25,434] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 933697.0510210508 W.
[2019-03-23 12:33:25,441] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.0, 76.0, 1.0, 2.0, 0.4089729011467287, 1.0, 2.0, 0.4089729011467287, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 933697.0510210508, 933697.0510210505, 206155.7361402234], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1161000.0000, 
sim time next is 1161600.0000, 
raw observation next is [23.33333333333334, 75.33333333333333, 1.0, 2.0, 0.2803588316096037, 1.0, 2.0, 0.2803588316096037, 1.0, 1.0, 0.5667097799954733, 6.9112, 6.9112, 77.3421103, 959721.6995784952, 959721.6995784952, 248593.634843497], 
processed observation next is [1.0, 0.43478260869565216, 0.6969696969696972, 0.7533333333333333, 1.0, 1.0, 0.10044853951200458, 1.0, 1.0, 0.10044853951200458, 1.0, 0.5, 0.3810139714221048, 0.0, 0.0, 0.5085185399722538, 0.3554524813253686, 0.3554524813253686, 0.6063259386426756], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.46857178], dtype=float32), 1.0456362]. 
=============================================
[2019-03-23 12:33:26,360] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.99997139e-01 3.24226960e-07 2.50575795e-06 1.21270185e-08
 1.13512956e-10], sum to 1.0000
[2019-03-23 12:33:26,367] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4435
[2019-03-23 12:33:26,373] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1346963.714952623 W.
[2019-03-23 12:33:26,535] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 62.0, 1.0, 2.0, 0.5951166432160252, 1.0, 2.0, 0.5951166432160252, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1346963.714952623, 1346963.714952623, 258466.8984795227], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1177200.0000, 
sim time next is 1177800.0000, 
raw observation next is [27.0, 62.66666666666667, 1.0, 2.0, 0.6057099048814252, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9765977840512766, 6.9112, 6.9112, 77.32846344354104, 1236949.908994925, 1236949.908994925, 277896.9477826913], 
processed observation next is [1.0, 0.6521739130434783, 0.8636363636363636, 0.6266666666666667, 1.0, 1.0, 0.5071373811017814, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9665682629303953, 0.0, 0.0, 0.5084288129206541, 0.4581295959240463, 0.4581295959240463, 0.6777974336163202], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.29582268], dtype=float32), 0.903072]. 
=============================================
[2019-03-23 12:33:27,131] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2000, global step 31806: loss 71.3584
[2019-03-23 12:33:27,132] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2000, global step 31806: learning rate 0.0000
[2019-03-23 12:33:27,251] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2000, global step 31865: loss 1.6119
[2019-03-23 12:33:27,251] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2000, global step 31865: learning rate 0.0000
[2019-03-23 12:33:27,334] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2000, global step 31913: loss 25.1366
[2019-03-23 12:33:27,335] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2000, global step 31913: learning rate 0.0000
[2019-03-23 12:33:27,354] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2000, global step 31923: loss 73.7900
[2019-03-23 12:33:27,357] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2000, global step 31923: learning rate 0.0000
[2019-03-23 12:33:27,376] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2000, global step 31931: loss -14.7851
[2019-03-23 12:33:27,377] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2000, global step 31931: learning rate 0.0000
[2019-03-23 12:33:27,397] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2000, global step 31938: loss 59.0275
[2019-03-23 12:33:27,399] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2000, global step 31938: learning rate 0.0000
[2019-03-23 12:33:27,423] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2000, global step 31949: loss -7.2531
[2019-03-23 12:33:27,428] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2000, global step 31949: learning rate 0.0000
[2019-03-23 12:33:27,508] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2000, global step 32000: loss -5.6099
[2019-03-23 12:33:27,511] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2000, global step 32000: learning rate 0.0000
[2019-03-23 12:33:27,515] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2000, global step 32000: loss -7.5431
[2019-03-23 12:33:27,519] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2000, global step 32000: learning rate 0.0000
[2019-03-23 12:33:27,534] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2000, global step 32008: loss 0.0593
[2019-03-23 12:33:27,535] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2000, global step 32008: loss 15.9681
[2019-03-23 12:33:27,537] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2000, global step 32008: learning rate 0.0000
[2019-03-23 12:33:27,538] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2000, global step 32008: learning rate 0.0000
[2019-03-23 12:33:27,556] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2000, global step 32016: loss -38.6966
[2019-03-23 12:33:27,557] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2000, global step 32016: learning rate 0.0000
[2019-03-23 12:33:27,699] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2000, global step 32089: loss 72.0650
[2019-03-23 12:33:27,702] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2000, global step 32089: learning rate 0.0000
[2019-03-23 12:33:27,739] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2000, global step 32104: loss 46.2429
[2019-03-23 12:33:27,741] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2000, global step 32105: learning rate 0.0000
[2019-03-23 12:33:27,756] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2000, global step 32112: loss -12.4890
[2019-03-23 12:33:27,758] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2000, global step 32112: learning rate 0.0000
[2019-03-23 12:33:27,848] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2000, global step 32163: loss 102.2106
[2019-03-23 12:33:27,850] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2000, global step 32163: learning rate 0.0000
[2019-03-23 12:33:42,010] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.3752088e-08 1.5095649e-11 1.0000000e+00 7.9643014e-17 3.7994736e-21], sum to 1.0000
[2019-03-23 12:33:42,022] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0825
[2019-03-23 12:33:42,184] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.2397505906298606, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4845166313557402, 6.911199999999999, 6.9112, 77.32846344354104, 546961.9143857157, 546961.914385716, 175800.5626000069], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1479600.0000, 
sim time next is 1480200.0000, 
raw observation next is [20.83333333333333, 100.0, 1.0, 2.0, 0.2382764992700906, 0.0, 2.0, 0.0, 1.0, 2.0, 0.481256372123838, 6.9112, 6.9112, 77.32846344354104, 543696.9113737689, 543696.9113737689, 175140.0455763117], 
processed observation next is [0.0, 0.13043478260869565, 0.5833333333333331, 1.0, 1.0, 1.0, 0.047845624087613225, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2589376744626257, 0.0, 0.0, 0.5084288129206541, 0.20136922643472924, 0.20136922643472924, 0.42717084286905294], 
reward next is 0.5728, 
noisyNet noise sample is [array([-1.7403533], dtype=float32), -1.7560248]. 
=============================================
[2019-03-23 12:33:42,943] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2500, global step 39769: loss 0.2471
[2019-03-23 12:33:42,945] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2500, global step 39770: learning rate 0.0000
[2019-03-23 12:33:42,995] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2500, global step 39798: loss 0.3095
[2019-03-23 12:33:42,997] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2500, global step 39799: learning rate 0.0000
[2019-03-23 12:33:43,201] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2500, global step 39903: loss 0.2352
[2019-03-23 12:33:43,203] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2500, global step 39903: learning rate 0.0000
[2019-03-23 12:33:43,210] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 39906: loss 0.3067
[2019-03-23 12:33:43,212] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2500, global step 39906: learning rate 0.0000
[2019-03-23 12:33:43,262] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2500, global step 39935: loss 0.3827
[2019-03-23 12:33:43,263] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2500, global step 39935: learning rate 0.0000
[2019-03-23 12:33:43,320] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 39965: loss 0.2668
[2019-03-23 12:33:43,322] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2500, global step 39966: learning rate 0.0000
[2019-03-23 12:33:43,353] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2500, global step 39979: loss 0.0989
[2019-03-23 12:33:43,355] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2500, global step 39980: learning rate 0.0000
[2019-03-23 12:33:43,375] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2500, global step 39987: loss 0.0304
[2019-03-23 12:33:43,377] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2500, global step 39988: learning rate 0.0000
[2019-03-23 12:33:43,410] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2500, global step 40007: loss 0.0192
[2019-03-23 12:33:43,415] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2500, global step 40008: learning rate 0.0000
[2019-03-23 12:33:43,441] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2500, global step 40021: loss 0.0044
[2019-03-23 12:33:43,445] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2500, global step 40024: learning rate 0.0000
[2019-03-23 12:33:43,453] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2500, global step 40029: loss 0.0200
[2019-03-23 12:33:43,457] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2500, global step 40030: learning rate 0.0000
[2019-03-23 12:33:43,460] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2500, global step 40030: loss 0.0045
[2019-03-23 12:33:43,462] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2500, global step 40030: learning rate 0.0000
[2019-03-23 12:33:43,511] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 40059: loss 0.0413
[2019-03-23 12:33:43,515] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2500, global step 40060: learning rate 0.0000
[2019-03-23 12:33:43,519] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 40060: loss 0.3261
[2019-03-23 12:33:43,519] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2500, global step 40060: learning rate 0.0000
[2019-03-23 12:33:43,661] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2500, global step 40137: loss 0.0274
[2019-03-23 12:33:43,668] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2500, global step 40138: learning rate 0.0000
[2019-03-23 12:33:43,811] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 40215: loss 0.2363
[2019-03-23 12:33:43,814] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2500, global step 40215: learning rate 0.0000
[2019-03-23 12:33:44,592] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.9983132e-06 1.5255016e-09 9.9999702e-01 7.9696912e-16 1.2991886e-20], sum to 1.0000
[2019-03-23 12:33:44,603] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2115
[2019-03-23 12:33:44,614] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.5, 85.83333333333334, 1.0, 2.0, 0.2555076419762871, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5174200385397841, 6.911200000000001, 6.9112, 77.32846344354104, 581662.1577227198, 581662.1577227196, 181219.8620541827], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1522200.0000, 
sim time next is 1522800.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.2580985608372217, 0.0, 2.0, 0.0, 1.0, 2.0, 0.522743791309502, 6.9112, 6.9112, 77.32846344354104, 587259.7230883589, 587259.7230883589, 182114.1257609165], 
processed observation next is [0.0, 0.6521739130434783, 0.7272727272727273, 0.83, 1.0, 1.0, 0.07262320104652713, 0.0, 1.0, -0.25, 1.0, 1.0, 0.31820541615643144, 0.0, 0.0, 0.5084288129206541, 0.21750360114383663, 0.21750360114383663, 0.44418079453882076], 
reward next is 0.5558, 
noisyNet noise sample is [array([0.80801105], dtype=float32), -0.2510438]. 
=============================================
[2019-03-23 12:33:45,534] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.2847266e-06 3.9583162e-07 9.9999738e-01 1.5609904e-13 4.5403864e-17], sum to 1.0000
[2019-03-23 12:33:45,544] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1682
[2019-03-23 12:33:45,549] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.83333333333333, 83.0, 1.0, 2.0, 0.2599422566044456, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5264168180295902, 6.9112, 6.9112, 77.32846344354104, 591708.3866010638, 591708.3866010638, 182352.6521281374], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1537800.0000, 
sim time next is 1538400.0000, 
raw observation next is [23.66666666666666, 83.0, 1.0, 2.0, 0.2560225465574951, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5183268691197083, 6.911200000000001, 6.9112, 77.32846344354104, 583187.3890402995, 583187.3890402991, 180994.5377297895], 
processed observation next is [0.0, 0.8260869565217391, 0.7121212121212118, 0.83, 1.0, 1.0, 0.07002818319686889, 0.0, 1.0, -0.25, 1.0, 1.0, 0.311895527313869, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.215995329274185, 0.21599532927418486, 0.44145009202387686], 
reward next is 0.5585, 
noisyNet noise sample is [array([0.21935868], dtype=float32), -0.5073647]. 
=============================================
[2019-03-23 12:33:51,618] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.4930634e-01 2.7379962e-02 1.1749006e-01 5.3481008e-03 4.7558622e-04], sum to 1.0000
[2019-03-23 12:33:51,627] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2068
[2019-03-23 12:33:51,775] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.83333333333334, 89.00000000000001, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7141074233875199, 6.915376824507873, 6.9112, 77.32841057831608, 412396.7201409572, 411040.1738990321, 127087.1563781024], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1656600.0000, 
sim time next is 1657200.0000, 
raw observation next is [18.66666666666667, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.681608115080789, 6.9112, 6.9112, 77.32846093303498, 392910.1248393356, 392910.1248393356, 123341.5807853016], 
processed observation next is [1.0, 0.17391304347826086, 0.4848484848484851, 0.9, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5451544501154129, 0.0, 0.0, 0.5084287964142662, 0.1455222684590132, 0.1455222684590132, 0.3008331238665893], 
reward next is 0.6992, 
noisyNet noise sample is [array([0.85426134], dtype=float32), 1.0619884]. 
=============================================
[2019-03-23 12:33:54,251] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3284744e-05 1.0623563e-06 9.9998569e-01 2.1994802e-10 1.2605130e-15], sum to 1.0000
[2019-03-23 12:33:54,260] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2941
[2019-03-23 12:33:54,265] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 55.0, 1.0, 2.0, 0.3207242225072662, 0.0, 2.0, 0.0, 1.0, 2.0, 0.598798761416474, 6.9112, 6.9112, 77.32846344354104, 696783.9810913956, 696783.9810913956, 173716.7157856427], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1696800.0000, 
sim time next is 1697400.0000, 
raw observation next is [21.0, 54.5, 1.0, 2.0, 0.3160739810588662, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5900437650603487, 6.9112, 6.9112, 77.32846344354104, 686674.0396170457, 686674.0396170457, 171583.448031974], 
processed observation next is [1.0, 0.6521739130434783, 0.5909090909090909, 0.545, 1.0, 1.0, 0.14509247632358271, 0.0, 1.0, -0.25, 1.0, 1.0, 0.41434823580049823, 0.0, 0.0, 0.5084288129206541, 0.2543237183766836, 0.2543237183766836, 0.4184962147121317], 
reward next is 0.5815, 
noisyNet noise sample is [array([1.7666788], dtype=float32), 0.36947578]. 
=============================================
[2019-03-23 12:33:56,895] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.2177377e-15 1.0106701e-09 4.2809070e-18 1.8926017e-27], sum to 1.0000
[2019-03-23 12:33:56,904] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4425
[2019-03-23 12:33:56,909] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [11.66666666666667, 68.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6337415782857839, 6.9112, 6.9112, 77.32846344107358, 368645.3657598766, 368645.3657598766, 80543.00611929518], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1755600.0000, 
sim time next is 1756200.0000, 
raw observation next is [11.83333333333333, 67.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6530550945108176, 6.9112, 6.9112, 77.32846344352576, 379884.3413264424, 379884.3413264424, 82423.76882786516], 
processed observation next is [1.0, 0.30434782608695654, 0.17424242424242412, 0.6766666666666667, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5043644207297394, 0.0, 0.0, 0.5084288129205536, 0.14069790419497866, 0.14069790419497866, 0.2010335825069882], 
reward next is 0.7990, 
noisyNet noise sample is [array([-2.4715772], dtype=float32), -0.4231461]. 
=============================================
[2019-03-23 12:33:58,422] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3000, global step 47690: loss 4.4146
[2019-03-23 12:33:58,429] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3000, global step 47690: learning rate 0.0000
[2019-03-23 12:33:58,684] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3000, global step 47829: loss 7.2244
[2019-03-23 12:33:58,687] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3000, global step 47829: learning rate 0.0000
[2019-03-23 12:33:58,729] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3000, global step 47853: loss 5.3349
[2019-03-23 12:33:58,731] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3000, global step 47853: learning rate 0.0000
[2019-03-23 12:33:58,806] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3000, global step 47890: loss 3.4416
[2019-03-23 12:33:58,811] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3000, global step 47892: learning rate 0.0000
[2019-03-23 12:33:58,914] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3000, global step 47948: loss 1.2248
[2019-03-23 12:33:58,917] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3000, global step 47948: learning rate 0.0000
[2019-03-23 12:33:58,930] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3000, global step 47953: loss 4.5276
[2019-03-23 12:33:58,932] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3000, global step 47954: learning rate 0.0000
[2019-03-23 12:33:59,012] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3000, global step 48001: loss 3.1238
[2019-03-23 12:33:59,016] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3000, global step 48003: learning rate 0.0000
[2019-03-23 12:33:59,047] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3000, global step 48020: loss 0.7436
[2019-03-23 12:33:59,048] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3000, global step 48020: loss 0.7970
[2019-03-23 12:33:59,050] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3000, global step 48020: learning rate 0.0000
[2019-03-23 12:33:59,051] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3000, global step 48020: learning rate 0.0000
[2019-03-23 12:33:59,068] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3000, global step 48031: loss 1.0911
[2019-03-23 12:33:59,069] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3000, global step 48032: loss 1.6908
[2019-03-23 12:33:59,069] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3000, global step 48031: learning rate 0.0000
[2019-03-23 12:33:59,071] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3000, global step 48032: learning rate 0.0000
[2019-03-23 12:33:59,083] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3000, global step 48037: loss 0.7488
[2019-03-23 12:33:59,084] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3000, global step 48037: learning rate 0.0000
[2019-03-23 12:33:59,123] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3000, global step 48058: loss 0.2558
[2019-03-23 12:33:59,125] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3000, global step 48059: learning rate 0.0000
[2019-03-23 12:33:59,247] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3000, global step 48126: loss 0.9003
[2019-03-23 12:33:59,250] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3000, global step 48126: learning rate 0.0000
[2019-03-23 12:33:59,327] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3000, global step 48173: loss 3.0548
[2019-03-23 12:33:59,329] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3000, global step 48174: learning rate 0.0000
[2019-03-23 12:33:59,340] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3000, global step 48180: loss 1.2929
[2019-03-23 12:33:59,342] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3000, global step 48181: learning rate 0.0000
[2019-03-23 12:34:02,751] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 12:34:02,752] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:34:02,753] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:34:02,754] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:34:02,754] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:34:02,754] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:34:02,759] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:34:02,760] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:34:02,760] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:34:02,761] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:34:02,762] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:34:02,774] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run3
[2019-03-23 12:34:02,797] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run3
[2019-03-23 12:34:02,799] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run3
[2019-03-23 12:34:02,842] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run3
[2019-03-23 12:34:02,881] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run3
[2019-03-23 12:34:14,287] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00332464], dtype=float32), 0.025924541]
[2019-03-23 12:34:14,287] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 100.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7606647718914852, 7.258403673765012, 6.9112, 77.32759024602235, 547640.3522834912, 434876.9739328703, 134355.7833028743]
[2019-03-23 12:34:14,290] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:34:14,292] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.9974126e-01 1.1298514e-04 1.4174051e-04 3.7722530e-06 1.9567419e-07], sampled 0.43541561854433486
[2019-03-23 12:34:14,293] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 547640.3522834912 W.
[2019-03-23 12:34:18,230] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00332464], dtype=float32), 0.025924541]
[2019-03-23 12:34:18,230] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.55, 91.5, 1.0, 1.0, 0.4356982461299674, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 95.55318300472291, 492250.2971259526, 492250.297125953, 133175.0655595447]
[2019-03-23 12:34:18,232] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:34:18,234] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.9947828e-01 2.3010008e-04 2.8108287e-04 9.8436503e-06 6.6838840e-07], sampled 0.41412070633011844
[2019-03-23 12:34:21,400] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00332464], dtype=float32), 0.025924541]
[2019-03-23 12:34:21,402] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.36666666666667, 75.0, 1.0, 2.0, 0.55656035150028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 627303.6872773027, 627303.6872773024, 144964.4078068579]
[2019-03-23 12:34:21,403] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:34:21,406] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.9960607e-01 1.7382040e-04 2.1305776e-04 6.6854050e-06 4.1013493e-07], sampled 0.13647644215972032
[2019-03-23 12:34:21,410] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 627303.6872773027 W.
[2019-03-23 12:34:26,244] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00332464], dtype=float32), 0.025924541]
[2019-03-23 12:34:26,245] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.88738834166667, 74.89195150500001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4652152443185787, 6.911200000000001, 6.9112, 95.55338769695034, 270572.5081424662, 270572.5081424658, 88472.25513053057]
[2019-03-23 12:34:26,246] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:34:26,249] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.99818981e-01 7.91403218e-05 9.94851071e-05 2.27990085e-06
 1.07202354e-07], sampled 0.44527541661669057
[2019-03-23 12:34:27,496] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00332464], dtype=float32), 0.025924541]
[2019-03-23 12:34:27,497] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 53.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5546207006284388, 6.911199999999999, 6.9112, 77.32846344354104, 322603.2841808617, 322603.284180862, 106989.6756344578]
[2019-03-23 12:34:27,498] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:34:27,500] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.9965143e-01 1.5402594e-04 1.8845269e-04 5.7475122e-06 3.3802689e-07], sampled 0.4711342319731304
[2019-03-23 12:34:47,743] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00332464], dtype=float32), 0.025924541]
[2019-03-23 12:34:47,745] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.66666666666666, 61.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6752698183800974, 6.911199999999999, 6.9112, 77.32846344354104, 389433.041479672, 389433.0414796722, 122588.9289567607]
[2019-03-23 12:34:47,745] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:34:47,748] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.9983239e-01 7.3198353e-05 9.2224975e-05 2.0561959e-06 9.3771106e-08], sampled 0.5124669860831773
[2019-03-23 12:34:59,413] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00332464], dtype=float32), 0.025924541]
[2019-03-23 12:34:59,414] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.26666666666667, 47.66666666666667, 1.0, 2.0, 0.4826422589517003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 544723.6868850704, 544723.68688507, 137520.5093552929]
[2019-03-23 12:34:59,416] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:34:59,418] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.9927729e-01 3.1998832e-04 3.8596729e-04 1.5581420e-05 1.1760155e-06], sampled 0.42771718629840727
[2019-03-23 12:34:59,419] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 544723.6868850704 W.
[2019-03-23 12:35:10,933] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00332464], dtype=float32), 0.025924541]
[2019-03-23 12:35:10,934] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.26666666666667, 53.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5372010299483911, 6.911199999999999, 6.9112, 95.55338769695034, 312450.8377872657, 312450.8377872661, 103811.5140545394]
[2019-03-23 12:35:10,935] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:35:10,938] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.9975973e-01 1.0580745e-04 1.3094029e-04 3.4063396e-06 1.7620049e-07], sampled 0.2744620336898521
[2019-03-23 12:35:41,205] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6325.5960 1723354501.5069 3425.0000
[2019-03-23 12:35:41,364] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6858.0118 1793136363.6515 2408.0000
[2019-03-23 12:35:41,372] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6293.5605 1685666766.7150 3228.0000
[2019-03-23 12:35:41,433] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6550.3503 1698759853.6165 2958.0000
[2019-03-23 12:35:41,471] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6476.3746 1679060662.7757 3057.0000
[2019-03-23 12:35:42,485] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 50000, evaluation results [50000.0, 6858.011773047958, 1793136363.651518, 2408.0, 6476.374622899549, 1679060662.775664, 3057.0, 6293.560490811997, 1685666766.7150059, 3228.0, 6325.59595473459, 1723354501.506876, 3425.0, 6550.350272580904, 1698759853.6164737, 2958.0]
[2019-03-23 12:35:44,898] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 2.3875549e-15 9.3480709e-12 6.3997124e-18 8.2322754e-23], sum to 1.0000
[2019-03-23 12:35:44,909] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6949
[2019-03-23 12:35:45,081] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7525069775749659, 7.234018041341365, 6.9112, 77.32743675109833, 538025.9813085054, 433182.6762779665, 131249.5213210592], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1916400.0000, 
sim time next is 1917000.0000, 
raw observation next is [18.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7512217240231605, 7.223089137970827, 6.9112, 77.32744080850739, 533717.1288455784, 432423.2556535053, 131119.6510808124], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 1.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6446024628902293, 0.031188913797082662, 0.0, 0.5084220891724629, 0.19767301068354756, 0.1601567613531501, 0.3198040270263717], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9234871], dtype=float32), -0.5349335]. 
=============================================
[2019-03-23 12:35:45,095] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[64.01056 ]
 [63.8701  ]
 [63.73222 ]
 [63.498295]
 [63.30643 ]], R is [[63.47398376]
 [62.83924484]
 [62.21085358]
 [62.28268051]
 [62.35715866]].
[2019-03-23 12:35:47,205] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.1400822e-03 4.0090214e-08 9.9785990e-01 1.7713556e-10 2.0913341e-11], sum to 1.0000
[2019-03-23 12:35:47,213] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9089
[2019-03-23 12:35:47,220] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.5, 61.0, 1.0, 2.0, 0.6283213089750159, 0.0, 2.0, 0.0, 1.0, 2.0, 0.966905798947092, 6.911199999999999, 6.9112, 77.32846344354104, 1265615.656239697, 1265615.656239697, 271312.718898797], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1956600.0000, 
sim time next is 1957200.0000, 
raw observation next is [25.66666666666666, 61.0, 1.0, 2.0, 0.6400518330072749, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9677424597626652, 6.911199999999999, 6.9112, 77.32846344354104, 1279090.578901717, 1279090.578901717, 273790.0272984174], 
processed observation next is [1.0, 0.6521739130434783, 0.8030303030303028, 0.61, 1.0, 1.0, 0.5500647912590936, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9539177996609502, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4737372514450804, 0.4737372514450804, 0.667780554386384], 
reward next is 0.3322, 
noisyNet noise sample is [array([-0.26906246], dtype=float32), -0.15945633]. 
=============================================
[2019-03-23 12:35:48,368] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9818891e-01 3.2268887e-04 1.4848771e-03 2.5979220e-06 8.3054215e-07], sum to 1.0000
[2019-03-23 12:35:48,375] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6259
[2019-03-23 12:35:48,383] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.16666666666666, 60.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5980120932958739, 6.911200000000001, 6.9112, 77.32846344354104, 347496.2402322264, 347496.2402322261, 113595.8510055381], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1979400.0000, 
sim time next is 1980000.0000, 
raw observation next is [21.0, 60.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.588590502776358, 6.911199999999999, 6.9112, 77.32846344354104, 342221.2135630362, 342221.2135630365, 111792.5838196064], 
processed observation next is [1.0, 0.9565217391304348, 0.5909090909090909, 0.6, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.41227214682336866, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12674859761593932, 0.12674859761593946, 0.2726648385844059], 
reward next is 0.7273, 
noisyNet noise sample is [array([0.9468368], dtype=float32), 0.0020531632]. 
=============================================
[2019-03-23 12:35:48,406] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[19.66636 ]
 [19.791237]
 [19.978323]
 [20.244291]
 [20.125463]], R is [[20.1576786 ]
 [20.679039  ]
 [21.19261742]
 [21.69834137]
 [22.19657135]].
[2019-03-23 12:35:49,065] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.99999881e-01 5.80679060e-10 1.01503126e-07 7.18659819e-14
 3.32958085e-15], sum to 1.0000
[2019-03-23 12:35:49,076] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0272
[2019-03-23 12:35:49,081] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.0, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4451908316994813, 6.911199999999999, 6.9112, 77.32846344354104, 258936.8034661709, 258936.8034661712, 80669.67310404603], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2002800.0000, 
sim time next is 2003400.0000, 
raw observation next is [17.0, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4444905278340225, 6.911199999999999, 6.9112, 77.32846344354104, 258529.3767500607, 258529.376750061, 80611.78331764412], 
processed observation next is [0.0, 0.17391304347826086, 0.4090909090909091, 0.72, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2064150397628893, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.095751621018541, 0.09575162101854111, 0.19661410565279053], 
reward next is 0.8034, 
noisyNet noise sample is [array([-0.0399869], dtype=float32), -0.7819421]. 
=============================================
[2019-03-23 12:35:53,262] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9999976e-01 3.0102854e-12 2.1985748e-07 5.3926010e-15 2.8625333e-17], sum to 1.0000
[2019-03-23 12:35:53,270] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9301
[2019-03-23 12:35:53,278] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.5, 78.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4471753075582133, 6.9112, 6.9112, 77.32846344354104, 260091.3448309941, 260091.3448309941, 82898.12249421875], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2076600.0000, 
sim time next is 2077200.0000, 
raw observation next is [16.0, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4463339024249112, 6.9112, 6.9112, 77.32846344354104, 259601.8263060731, 259601.8263060731, 82236.46513446314], 
processed observation next is [0.0, 0.043478260869565216, 0.36363636363636365, 0.82, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.20904843203558748, 0.0, 0.0, 0.5084288129206541, 0.09614882455780485, 0.09614882455780485, 0.2005767442303979], 
reward next is 0.7994, 
noisyNet noise sample is [array([1.0989288], dtype=float32), 1.4210899]. 
=============================================
[2019-03-23 12:35:53,902] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3500, global step 55744: loss 0.0800
[2019-03-23 12:35:53,904] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3500, global step 55744: learning rate 0.0000
[2019-03-23 12:35:54,088] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3500, global step 55839: loss 0.0330
[2019-03-23 12:35:54,090] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3500, global step 55839: learning rate 0.0000
[2019-03-23 12:35:54,106] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3500, global step 55848: loss 0.0298
[2019-03-23 12:35:54,108] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3500, global step 55850: learning rate 0.0000
[2019-03-23 12:35:54,151] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3500, global step 55869: loss 0.4038
[2019-03-23 12:35:54,153] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3500, global step 55870: learning rate 0.0000
[2019-03-23 12:35:54,201] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3500, global step 55895: loss 0.8136
[2019-03-23 12:35:54,206] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3500, global step 55896: learning rate 0.0000
[2019-03-23 12:35:54,316] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3500, global step 55954: loss 0.4893
[2019-03-23 12:35:54,320] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3500, global step 55955: learning rate 0.0000
[2019-03-23 12:35:54,341] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3500, global step 55965: loss 0.4134
[2019-03-23 12:35:54,344] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3500, global step 55966: learning rate 0.0000
[2019-03-23 12:35:54,383] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3500, global step 55984: loss 0.2291
[2019-03-23 12:35:54,387] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3500, global step 55984: learning rate 0.0000
[2019-03-23 12:35:54,429] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3500, global step 56012: loss 0.0066
[2019-03-23 12:35:54,432] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3500, global step 56013: learning rate 0.0000
[2019-03-23 12:35:54,450] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3500, global step 56025: loss 0.0102
[2019-03-23 12:35:54,453] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3500, global step 56026: learning rate 0.0000
[2019-03-23 12:35:54,466] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3500, global step 56031: loss 0.0026
[2019-03-23 12:35:54,467] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3500, global step 56032: learning rate 0.0000
[2019-03-23 12:35:54,528] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3500, global step 56057: loss 0.1510
[2019-03-23 12:35:54,531] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3500, global step 56057: learning rate 0.0000
[2019-03-23 12:35:54,704] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3500, global step 56118: loss 0.1681
[2019-03-23 12:35:54,711] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3500, global step 56120: loss 0.1244
[2019-03-23 12:35:54,713] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3500, global step 56118: learning rate 0.0000
[2019-03-23 12:35:54,714] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3500, global step 56120: learning rate 0.0000
[2019-03-23 12:35:54,736] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3500, global step 56129: loss 0.0066
[2019-03-23 12:35:54,737] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3500, global step 56129: learning rate 0.0000
[2019-03-23 12:35:54,835] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3500, global step 56183: loss 0.2372
[2019-03-23 12:35:54,839] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3500, global step 56184: learning rate 0.0000
[2019-03-23 12:35:55,861] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9999893e-01 2.9453817e-09 1.0822788e-06 1.4121674e-12 2.6054036e-14], sum to 1.0000
[2019-03-23 12:35:55,870] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2383
[2019-03-23 12:35:56,029] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.66666666666667, 47.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7469072930911028, 7.157147822685386, 6.9112, 77.3277178807524, 507718.9213560824, 427840.8692028789, 132165.5420633124], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2126400.0000, 
sim time next is 2127000.0000, 
raw observation next is [26.83333333333333, 46.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7516608496025294, 7.202948685150475, 6.9112, 77.32755244252508, 525776.5139756358, 431023.6246213891, 132377.8899027887], 
processed observation next is [0.0, 0.6086956521739131, 0.8560606060606059, 0.46, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6452297851464707, 0.029174868515047515, 0.0, 0.5084228231577067, 0.19473204221319843, 0.15963837948940338, 0.32287290220192366], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.22334166], dtype=float32), -1.8816236]. 
=============================================
[2019-03-23 12:35:56,048] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[43.29482 ]
 [43.275425]
 [43.004097]
 [44.894882]
 [44.878345]], R is [[43.15310669]
 [42.72157669]
 [42.29436111]
 [42.46403122]
 [42.03939056]].
[2019-03-23 12:35:56,359] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9999642e-01 3.2873166e-07 3.2755422e-06 1.6079749e-08 1.8503750e-09], sum to 1.0000
[2019-03-23 12:35:56,373] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9114
[2019-03-23 12:35:56,377] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.0, 45.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7542785215656215, 7.227874834125422, 6.9112, 77.3274566799025, 535603.9498767985, 432755.7799035133, 132510.0800288019], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2127600.0000, 
sim time next is 2128200.0000, 
raw observation next is [27.0, 46.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.758218673198449, 7.259534722185286, 6.9112, 77.32736674640535, 548086.224550691, 434955.8359363899, 133006.53456857], 
processed observation next is [0.0, 0.6521739130434783, 0.8636363636363636, 0.46, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.654598104569213, 0.034833472218528616, 0.0, 0.5084216022197298, 0.2029948979817374, 0.1610947540505148, 0.324406181874561], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.10817626], dtype=float32), 0.07872703]. 
=============================================
[2019-03-23 12:36:06,512] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 5.8596153e-33 1.3469235e-26 9.1223499e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 12:36:06,524] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7962
[2019-03-23 12:36:06,538] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.0, 53.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.433813089973266, 6.9112, 6.9112, 77.32846344354104, 252317.4392530376, 252317.4392530376, 68255.00020911323], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2328000.0000, 
sim time next is 2328600.0000, 
raw observation next is [17.0, 52.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4340501466525354, 6.911199999999999, 6.9112, 77.32846344354104, 252455.3536196685, 252455.3536196688, 68035.78166204567], 
processed observation next is [1.0, 0.9565217391304348, 0.4090909090909091, 0.525, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.191500209503622, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09350198282209944, 0.09350198282209955, 0.1659409308830382], 
reward next is 0.8341, 
noisyNet noise sample is [array([-0.144107], dtype=float32), 1.136822]. 
=============================================
[2019-03-23 12:36:10,030] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4000, global step 63820: loss 0.5919
[2019-03-23 12:36:10,037] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4000, global step 63821: learning rate 0.0000
[2019-03-23 12:36:10,041] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4000, global step 63822: loss 0.1577
[2019-03-23 12:36:10,043] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4000, global step 63823: learning rate 0.0000
[2019-03-23 12:36:10,139] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4000, global step 63877: loss 0.3882
[2019-03-23 12:36:10,143] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4000, global step 63880: learning rate 0.0000
[2019-03-23 12:36:10,152] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4000, global step 63880: loss 0.4715
[2019-03-23 12:36:10,155] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4000, global step 63881: learning rate 0.0000
[2019-03-23 12:36:10,205] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4000, global step 63905: loss 0.0809
[2019-03-23 12:36:10,207] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4000, global step 63906: learning rate 0.0000
[2019-03-23 12:36:10,264] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4000, global step 63937: loss 0.2065
[2019-03-23 12:36:10,265] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4000, global step 63938: learning rate 0.0000
[2019-03-23 12:36:10,286] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4000, global step 63948: loss 0.1898
[2019-03-23 12:36:10,287] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4000, global step 63949: learning rate 0.0000
[2019-03-23 12:36:10,352] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4000, global step 63981: loss 0.4393
[2019-03-23 12:36:10,354] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4000, global step 63981: learning rate 0.0000
[2019-03-23 12:36:10,411] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4000, global step 64011: loss 2.8720
[2019-03-23 12:36:10,415] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4000, global step 64011: learning rate 0.0000
[2019-03-23 12:36:10,416] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4000, global step 64012: loss 1.2521
[2019-03-23 12:36:10,425] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4000, global step 64015: learning rate 0.0000
[2019-03-23 12:36:10,433] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4000, global step 64018: loss 1.5026
[2019-03-23 12:36:10,436] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4000, global step 64018: learning rate 0.0000
[2019-03-23 12:36:10,495] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4000, global step 64052: loss 1.1019
[2019-03-23 12:36:10,498] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4000, global step 64052: learning rate 0.0000
[2019-03-23 12:36:10,563] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4000, global step 64085: loss 0.0421
[2019-03-23 12:36:10,566] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4000, global step 64085: learning rate 0.0000
[2019-03-23 12:36:10,590] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.00000000e+00 4.83210169e-18 1.01890576e-13 2.10639362e-20
 7.61689708e-22], sum to 1.0000
[2019-03-23 12:36:10,600] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6979
[2019-03-23 12:36:10,603] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.33333333333333, 55.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5264879275676376, 6.911199999999999, 6.9112, 77.32846344354104, 306236.6042942626, 306236.6042942629, 93395.58273131083], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2403600.0000, 
sim time next is 2404200.0000, 
raw observation next is [20.16666666666667, 55.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5221345057969407, 6.911199999999999, 6.9112, 77.32846344354104, 303703.6053237452, 303703.6053237455, 92446.76094599314], 
processed observation next is [1.0, 0.8260869565217391, 0.5530303030303032, 0.555, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3173350082813438, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1124828167865723, 0.11248281678657242, 0.22547990474632473], 
reward next is 0.7745, 
noisyNet noise sample is [array([-0.6989616], dtype=float32), -0.849142]. 
=============================================
[2019-03-23 12:36:10,672] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4000, global step 64143: loss 1.1242
[2019-03-23 12:36:10,675] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4000, global step 64143: learning rate 0.0000
[2019-03-23 12:36:10,691] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4000, global step 64150: loss 0.3734
[2019-03-23 12:36:10,694] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4000, global step 64151: learning rate 0.0000
[2019-03-23 12:36:10,802] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4000, global step 64207: loss 0.0613
[2019-03-23 12:36:10,809] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4000, global step 64208: learning rate 0.0000
[2019-03-23 12:36:20,619] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 7.9351462e-20 8.3041674e-13 7.2629073e-23 6.7326300e-25], sum to 1.0000
[2019-03-23 12:36:20,630] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8007
[2019-03-23 12:36:20,778] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.03333333333333, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5851728419013285, 6.9112, 6.9112, 77.32846344354104, 340128.9895166461, 340128.9895166461, 112492.7537912667], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2598000.0000, 
sim time next is 2598600.0000, 
raw observation next is [16.96666666666667, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5887864106608602, 6.911199999999999, 6.9112, 77.32846344354104, 342154.2355600811, 342154.2355600814, 112837.5462296577], 
processed observation next is [0.0, 0.043478260869565216, 0.40757575757575765, 0.93, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4125520152298004, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12672379094817818, 0.1267237909481783, 0.275213527389409], 
reward next is 0.7248, 
noisyNet noise sample is [array([0.2811556], dtype=float32), -1.0648566]. 
=============================================
[2019-03-23 12:36:20,936] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.1222423e-17 1.6093328e-13 3.0213337e-21 1.2838305e-21], sum to 1.0000
[2019-03-23 12:36:20,945] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7884
[2019-03-23 12:36:20,950] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.9, 72.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4986606592028862, 6.911199999999998, 6.9112, 77.32846344354104, 290045.787948014, 290045.7879480146, 92254.49380247867], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2590200.0000, 
sim time next is 2590800.0000, 
raw observation next is [17.83333333333333, 72.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4947776188538301, 6.9112, 6.9112, 77.32846344354104, 287786.5507206799, 287786.5507206799, 91224.38805571236], 
processed observation next is [1.0, 1.0, 0.44696969696969674, 0.7233333333333334, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2782537412197573, 0.0, 0.0, 0.5084288129206541, 0.1065876113780296, 0.1065876113780296, 0.222498507452957], 
reward next is 0.7775, 
noisyNet noise sample is [array([-0.3946876], dtype=float32), -0.27760664]. 
=============================================
[2019-03-23 12:36:25,754] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4500, global step 71813: loss 1.6256
[2019-03-23 12:36:25,755] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4500, global step 71813: learning rate 0.0000
[2019-03-23 12:36:25,791] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4500, global step 71827: loss 0.9816
[2019-03-23 12:36:25,794] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4500, global step 71827: learning rate 0.0000
[2019-03-23 12:36:25,814] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4500, global step 71840: loss 1.1466
[2019-03-23 12:36:25,817] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4500, global step 71841: learning rate 0.0000
[2019-03-23 12:36:25,915] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4500, global step 71899: loss 0.2976
[2019-03-23 12:36:25,919] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4500, global step 71899: learning rate 0.0000
[2019-03-23 12:36:25,924] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4500, global step 71903: loss 0.3190
[2019-03-23 12:36:25,925] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4500, global step 71903: learning rate 0.0000
[2019-03-23 12:36:26,022] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4500, global step 71952: loss 0.0006
[2019-03-23 12:36:26,025] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4500, global step 71953: learning rate 0.0000
[2019-03-23 12:36:26,048] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4500, global step 71967: loss 0.0244
[2019-03-23 12:36:26,052] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4500, global step 71968: learning rate 0.0000
[2019-03-23 12:36:26,085] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4500, global step 71986: loss 0.3824
[2019-03-23 12:36:26,090] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4500, global step 71986: learning rate 0.0000
[2019-03-23 12:36:26,140] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4500, global step 72013: loss 0.9429
[2019-03-23 12:36:26,141] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4500, global step 72013: loss 0.7869
[2019-03-23 12:36:26,142] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4500, global step 72013: learning rate 0.0000
[2019-03-23 12:36:26,144] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4500, global step 72014: learning rate 0.0000
[2019-03-23 12:36:26,184] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4500, global step 72038: loss 0.9835
[2019-03-23 12:36:26,186] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4500, global step 72038: learning rate 0.0000
[2019-03-23 12:36:26,193] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4500, global step 72042: loss 0.7726
[2019-03-23 12:36:26,197] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4500, global step 72043: learning rate 0.0000
[2019-03-23 12:36:26,201] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4500, global step 72047: loss 0.9346
[2019-03-23 12:36:26,206] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4500, global step 72048: learning rate 0.0000
[2019-03-23 12:36:26,223] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4500, global step 72057: loss 0.5998
[2019-03-23 12:36:26,225] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4500, global step 72057: learning rate 0.0000
[2019-03-23 12:36:26,384] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4500, global step 72142: loss 0.2188
[2019-03-23 12:36:26,389] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4500, global step 72142: learning rate 0.0000
[2019-03-23 12:36:26,582] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4500, global step 72249: loss 0.7355
[2019-03-23 12:36:26,584] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4500, global step 72250: learning rate 0.0000
[2019-03-23 12:36:27,789] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9929857e-01 2.1900150e-05 6.7657296e-04 2.4857441e-06 5.0916219e-07], sum to 1.0000
[2019-03-23 12:36:27,799] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1344
[2019-03-23 12:36:27,804] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.16666666666667, 59.33333333333334, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3100191001233255, 6.911199999999999, 6.9112, 77.3421103, 525690.4365193016, 525690.436519302, 203949.5736395554], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2736600.0000, 
sim time next is 2737200.0000, 
raw observation next is [26.33333333333334, 57.66666666666667, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.791238606855115, 7.450544023287485, 6.9112, 77.32717580298166, 623393.7126651686, 448228.7222156058, 140925.2421724228], 
processed observation next is [0.0, 0.6956521739130435, 0.8333333333333336, 0.5766666666666667, 0.0, 0.5, -0.25, 0.0, 0.5, -0.25, 1.0, 1.0, 0.7017694383644502, 0.053934402328748465, 0.0, 0.5084203467811251, 0.23088656024635873, 0.16601063785763176, 0.3437201028595678], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.69771165], dtype=float32), -1.2605821]. 
=============================================
[2019-03-23 12:36:30,267] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 6.8812507e-34 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 12:36:30,274] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1600
[2019-03-23 12:36:30,278] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.0, 88.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6250476999465052, 6.9112, 6.9112, 77.32846344354104, 362298.4303757624, 362298.4303757624, 116544.4858340564], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2779800.0000, 
sim time next is 2780400.0000, 
raw observation next is [18.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6153654807415682, 6.9112, 6.9112, 77.32846344354104, 356684.2885806828, 356684.2885806828, 115712.4587279572], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 0.88, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4505221153450974, 0.0, 0.0, 0.5084288129206541, 0.13210529206691957, 0.13210529206691957, 0.28222550909257854], 
reward next is 0.7178, 
noisyNet noise sample is [array([0.06080525], dtype=float32), 0.59332806]. 
=============================================
[2019-03-23 12:36:31,717] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 12:36:31,719] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:36:31,719] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:36:31,719] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:36:31,720] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:36:31,721] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:36:31,723] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:36:31,723] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:36:31,725] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:36:31,725] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:36:31,726] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:36:31,739] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run4
[2019-03-23 12:36:31,739] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run4
[2019-03-23 12:36:31,741] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run4
[2019-03-23 12:36:31,762] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run4
[2019-03-23 12:36:31,842] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run4
[2019-03-23 12:36:37,019] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00484514], dtype=float32), 0.03049912]
[2019-03-23 12:36:37,020] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [12.88420945, 82.82716597, 1.0, 2.0, 0.5136331207404133, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 95.55338579187325, 557801.7404685448, 557801.7404685451, 106360.435383341]
[2019-03-23 12:36:37,020] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:36:37,022] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 2.0816334e-14 2.5418350e-11 1.7178088e-16 2.4778999e-19], sampled 0.8730102291102364
[2019-03-23 12:36:37,023] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 557801.7404685448 W.
[2019-03-23 12:36:39,915] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00484514], dtype=float32), 0.03049912]
[2019-03-23 12:36:39,917] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.5, 48.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.582999347078319, 6.911199999999999, 6.9112, 95.55338769695034, 339095.9086920117, 339095.9086920121, 92901.1744780893]
[2019-03-23 12:36:39,918] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:36:39,921] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0000000e+00 1.4302710e-16 5.4840106e-13 5.5080830e-19 2.7690739e-22], sampled 0.1590674025940121
[2019-03-23 12:36:56,817] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00484514], dtype=float32), 0.03049912]
[2019-03-23 12:36:56,818] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.83333333333334, 78.0, 1.0, 2.0, 0.5967435403608566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354071, 664160.7172307868, 664160.7172307872, 141487.3776358853]
[2019-03-23 12:36:56,820] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:36:56,822] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 2.7970370e-15 5.3801278e-12 1.6832077e-17 1.5948186e-20], sampled 0.9271957708934612
[2019-03-23 12:36:56,823] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 664160.7172307868 W.
[2019-03-23 12:36:58,166] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00484514], dtype=float32), 0.03049912]
[2019-03-23 12:36:58,167] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.41034576666667, 49.18084906666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6187187445605442, 6.911199999999999, 6.9112, 95.55338769695034, 359877.9699818009, 359877.9699818013, 101218.4304500296]
[2019-03-23 12:36:58,168] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:36:58,172] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 1.1361908e-16 4.5920624e-13 4.2247247e-19 2.0225620e-22], sampled 0.7116445862703173
[2019-03-23 12:37:10,815] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00484514], dtype=float32), 0.03049912]
[2019-03-23 12:37:10,817] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.56581465, 97.73801079166668, 1.0, 2.0, 0.5716565948215807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 652029.7837918781, 652029.7837918781, 152676.3597753916]
[2019-03-23 12:37:10,818] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:37:10,819] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0000000e+00 1.5521596e-16 5.7939601e-13 5.9937424e-19 3.0431593e-22], sampled 0.9642362825499378
[2019-03-23 12:37:10,820] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 652029.7837918781 W.
[2019-03-23 12:37:16,262] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00484514], dtype=float32), 0.03049912]
[2019-03-23 12:37:16,265] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.41011997666667, 78.61702671333335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7268540472464134, 7.256499558498981, 6.9112, 95.5520360019996, 556274.7596788938, 417699.6411291832, 133251.8970898924]
[2019-03-23 12:37:16,266] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:37:16,271] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 1.3401145e-15 3.0732910e-12 7.2609865e-18 5.8791078e-21], sampled 0.10385350139532612
[2019-03-23 12:37:16,272] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 556274.7596788938 W.
[2019-03-23 12:37:21,077] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00484514], dtype=float32), 0.03049912]
[2019-03-23 12:37:21,078] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.05, 50.0, 1.0, 2.0, 0.5967669582180277, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9642717539210897, 6.9112, 6.9112, 77.32846344354039, 1228951.328142666, 1228951.328142666, 264231.8847092965]
[2019-03-23 12:37:21,078] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:37:21,081] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 1.0070668e-15 2.4659803e-12 5.1965025e-18 3.9725894e-21], sampled 0.45379381990680734
[2019-03-23 12:37:21,081] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1228951.328142666 W.
[2019-03-23 12:37:54,426] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00484514], dtype=float32), 0.03049912]
[2019-03-23 12:37:54,427] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.1, 52.0, 1.0, 2.0, 0.4985812547868818, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9382816986914063, 6.951712066779439, 6.9112, 77.32836348733763, 1115663.79429043, 1102506.320623146, 244979.3207918287]
[2019-03-23 12:37:54,429] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:37:54,432] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 4.7180646e-16 1.3543291e-12 2.1516885e-18 1.3902609e-21], sampled 0.6754677937384672
[2019-03-23 12:37:54,433] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1115663.79429043 W.
[2019-03-23 12:38:00,215] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00484514], dtype=float32), 0.03049912]
[2019-03-23 12:38:00,216] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [11.87144904, 94.832686595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3626018673254233, 6.911199999999999, 6.9112, 95.55338769695034, 210881.3661490446, 210881.3661490449, 65908.8096658126]
[2019-03-23 12:38:00,217] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:38:00,221] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0000000e+00 4.2272255e-18 3.6391442e-14 9.5113339e-21 2.2732273e-24], sampled 0.7750108662681392
[2019-03-23 12:38:09,722] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6862.2842 1793014293.7888 2409.0000
[2019-03-23 12:38:09,966] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6553.1725 1698634175.0084 2957.0000
[2019-03-23 12:38:10,101] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6294.1708 1685655849.4452 3228.0000
[2019-03-23 12:38:10,168] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6481.6076 1678885180.2952 3057.0000
[2019-03-23 12:38:10,279] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6327.0646 1723324825.4072 3425.0000
[2019-03-23 12:38:11,291] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 75000, evaluation results [75000.0, 6862.284208925443, 1793014293.78876, 2409.0, 6481.607577760913, 1678885180.2951708, 3057.0, 6294.170799910606, 1685655849.44522, 3228.0, 6327.064634615435, 1723324825.407179, 3425.0, 6553.172466661831, 1698634175.0084193, 2957.0]
[2019-03-23 12:38:13,167] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9996829e-01 3.7798316e-07 3.1154588e-05 2.6689639e-07 2.6135030e-09], sum to 1.0000
[2019-03-23 12:38:13,177] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8503
[2019-03-23 12:38:13,182] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 559910.7147087505 W.
[2019-03-23 12:38:13,187] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.33333333333333, 81.33333333333333, 1.0, 2.0, 0.2454403394994452, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4960977458924868, 6.9112, 6.9112, 77.32846344354104, 559910.7147087505, 559910.7147087505, 177186.6065866874], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2846400.0000, 
sim time next is 2847000.0000, 
raw observation next is [23.16666666666667, 82.16666666666667, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3304995710274866, 6.911199999999999, 6.9112, 77.3421103, 558508.171606873, 558508.1716068734, 209867.589941], 
processed observation next is [1.0, 0.9565217391304348, 0.6893939393939396, 0.8216666666666668, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.04357081575355233, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.20685487837291594, 0.20685487837291608, 0.5118721705878049], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.67702794], dtype=float32), -0.3119745]. 
=============================================
[2019-03-23 12:38:13,199] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[12.502774 ]
 [12.2307625]
 [12.333764 ]
 [12.42339  ]
 [12.096052 ]], R is [[12.22559357]
 [12.10333729]
 [12.54649639]
 [12.98805332]
 [12.85817337]].
[2019-03-23 12:38:13,344] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9998808e-01 8.3557376e-07 1.0827745e-05 2.8959087e-07 3.6757268e-09], sum to 1.0000
[2019-03-23 12:38:13,358] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5779
[2019-03-23 12:38:13,362] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 545228.5430028385 W.
[2019-03-23 12:38:13,367] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.0, 80.5, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.321941030190596, 6.911199999999999, 6.9112, 77.3421103, 545228.5430028385, 545228.5430028389, 207036.8052061423], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2849400.0000, 
sim time next is 2850000.0000, 
raw observation next is [23.0, 79.66666666666667, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3186378077973842, 6.911199999999999, 6.9112, 77.3421103, 539715.4655813669, 539715.4655813673, 206259.9552129041], 
processed observation next is [1.0, 1.0, 0.6818181818181818, 0.7966666666666667, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.026625439710548888, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.19989461688198776, 0.19989461688198787, 0.5030730614948881], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7608088], dtype=float32), 1.0168927]. 
=============================================
[2019-03-23 12:38:13,382] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[11.975325]
 [11.580219]
 [11.511122]
 [11.311584]
 [11.157878]], R is [[11.95332718]
 [11.83379364]
 [12.2875843 ]
 [12.73119545]
 [13.16915131]].
[2019-03-23 12:38:20,814] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5000, global step 79842: loss 1.6638
[2019-03-23 12:38:20,816] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5000, global step 79842: learning rate 0.0000
[2019-03-23 12:38:20,819] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5000, global step 79843: loss 1.7496
[2019-03-23 12:38:20,947] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5000, global step 79844: learning rate 0.0000
[2019-03-23 12:38:21,120] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5000, global step 79884: loss 1.7349
[2019-03-23 12:38:21,123] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5000, global step 79885: learning rate 0.0000
[2019-03-23 12:38:21,262] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5000, global step 79897: loss 2.2744
[2019-03-23 12:38:21,265] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5000, global step 79897: learning rate 0.0000
[2019-03-23 12:38:21,269] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5000, global step 79902: loss 1.8609
[2019-03-23 12:38:21,274] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5000, global step 79902: loss 1.8592
[2019-03-23 12:38:21,388] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5000, global step 79902: learning rate 0.0000
[2019-03-23 12:38:21,389] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5000, global step 79902: learning rate 0.0000
[2019-03-23 12:38:21,705] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5000, global step 79947: loss 1.6612
[2019-03-23 12:38:21,712] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5000, global step 79949: learning rate 0.0000
[2019-03-23 12:38:21,716] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5000, global step 79950: loss 1.9036
[2019-03-23 12:38:21,830] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5000, global step 79953: learning rate 0.0000
[2019-03-23 12:38:21,967] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5000, global step 79968: loss 2.0238
[2019-03-23 12:38:21,967] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5000, global step 79968: loss 1.4898
[2019-03-23 12:38:21,970] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5000, global step 79969: learning rate 0.0000
[2019-03-23 12:38:21,971] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5000, global step 79968: learning rate 0.0000
[2019-03-23 12:38:22,228] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5000, global step 79982: loss 2.2561
[2019-03-23 12:38:22,236] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5000, global step 79982: learning rate 0.0000
[2019-03-23 12:38:22,439] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5000, global step 80036: loss 1.4659
[2019-03-23 12:38:22,442] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5000, global step 80037: learning rate 0.0000
[2019-03-23 12:38:22,622] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5000, global step 80076: loss 1.3235
[2019-03-23 12:38:22,625] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5000, global step 80076: learning rate 0.0000
[2019-03-23 12:38:22,772] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5000, global step 80094: loss 1.2912
[2019-03-23 12:38:22,775] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5000, global step 80094: learning rate 0.0000
[2019-03-23 12:38:22,915] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5000, global step 80110: loss 1.3781
[2019-03-23 12:38:22,918] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5000, global step 80110: learning rate 0.0000
[2019-03-23 12:38:23,437] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5000, global step 80320: loss 2.6545
[2019-03-23 12:38:23,438] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5000, global step 80320: learning rate 0.0000
[2019-03-23 12:38:26,269] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9993849e-01 9.7849391e-09 6.0966828e-05 5.8331506e-07 2.1077748e-09], sum to 1.0000
[2019-03-23 12:38:26,275] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5873
[2019-03-23 12:38:26,279] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1096342.884948282 W.
[2019-03-23 12:38:26,283] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 69.0, 1.0, 2.0, 0.4804538375654245, 1.0, 2.0, 0.4804538375654245, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1096342.884948282, 1096342.884948281, 218418.5532868522], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3063600.0000, 
sim time next is 3064200.0000, 
raw observation next is [23.16666666666667, 69.0, 1.0, 2.0, 0.4392232651354644, 1.0, 2.0, 0.4392232651354644, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1002356.074444509, 1002356.074444509, 209926.3525353801], 
processed observation next is [1.0, 0.4782608695652174, 0.6893939393939396, 0.69, 1.0, 1.0, 0.29902908141933043, 1.0, 1.0, 0.29902908141933043, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3712429905350033, 0.3712429905350033, 0.5120154939887319], 
reward next is 0.4880, 
noisyNet noise sample is [array([1.098582], dtype=float32), -0.0022128148]. 
=============================================
[2019-03-23 12:38:33,047] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7666230e-06 7.9293143e-22 9.9999821e-01 1.2961916e-18 1.4050668e-25], sum to 1.0000
[2019-03-23 12:38:33,054] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7930
[2019-03-23 12:38:33,058] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 88.00000000000001, 1.0, 2.0, 0.2189952804581033, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4380472377521475, 6.9112, 6.9112, 77.32846344354104, 498679.3366191677, 498679.3366191677, 167549.4383198585], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3193800.0000, 
sim time next is 3194400.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.2194844972980502, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4390290939390011, 6.911199999999999, 6.9112, 77.32846344354104, 499795.5080413604, 499795.5080413606, 167646.2025750237], 
processed observation next is [1.0, 1.0, 0.5909090909090909, 0.88, 1.0, 1.0, 0.02435562162256273, 0.0, 1.0, -0.25, 1.0, 1.0, 0.19861299134143015, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1851094474227261, 0.18510944742272614, 0.4088931770122529], 
reward next is 0.5911, 
noisyNet noise sample is [array([0.43216252], dtype=float32), -0.26327407]. 
=============================================
[2019-03-23 12:38:37,641] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 2.3425822e-22 6.4204384e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 12:38:37,650] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8669
[2019-03-23 12:38:37,656] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.66666666666667, 52.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5964178317474153, 6.911199999999999, 6.9112, 77.32846344354104, 346597.7971566152, 346597.7971566155, 113445.0114681997], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3266400.0000, 
sim time next is 3267000.0000, 
raw observation next is [22.5, 53.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5991324151597465, 6.9112, 6.9112, 77.32846344354104, 348114.5617824472, 348114.5617824472, 113712.2224344292], 
processed observation next is [0.0, 0.8260869565217391, 0.6590909090909091, 0.535, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4273320216567807, 0.0, 0.0, 0.5084288129206541, 0.12893131917868414, 0.12893131917868414, 0.2773468839864127], 
reward next is 0.7227, 
noisyNet noise sample is [array([-0.34610015], dtype=float32), -1.463069]. 
=============================================
[2019-03-23 12:38:37,673] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[109.278175]
 [109.20385 ]
 [109.10645 ]
 [109.025246]
 [108.98249 ]], R is [[108.98271179]
 [108.61618805]
 [108.25422668]
 [107.8960495 ]
 [107.54012299]].
[2019-03-23 12:38:38,452] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5500, global step 87854: loss 0.2238
[2019-03-23 12:38:38,456] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5500, global step 87856: learning rate 0.0000
[2019-03-23 12:38:38,517] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5500, global step 87883: loss 0.5691
[2019-03-23 12:38:38,518] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5500, global step 87883: learning rate 0.0000
[2019-03-23 12:38:38,564] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5500, global step 87909: loss 0.9882
[2019-03-23 12:38:38,568] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5500, global step 87910: learning rate 0.0000
[2019-03-23 12:38:38,575] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5500, global step 87911: loss 0.8802
[2019-03-23 12:38:38,580] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5500, global step 87911: learning rate 0.0000
[2019-03-23 12:38:38,594] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5500, global step 87921: loss 0.7553
[2019-03-23 12:38:38,598] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5500, global step 87921: learning rate 0.0000
[2019-03-23 12:38:38,601] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5500, global step 87923: loss 0.6516
[2019-03-23 12:38:38,605] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5500, global step 87923: learning rate 0.0000
[2019-03-23 12:38:38,658] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5500, global step 87957: loss 0.6056
[2019-03-23 12:38:38,664] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5500, global step 87957: learning rate 0.0000
[2019-03-23 12:38:38,668] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5500, global step 87958: loss 0.2566
[2019-03-23 12:38:38,670] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5500, global step 87960: learning rate 0.0000
[2019-03-23 12:38:38,701] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5500, global step 87977: loss 0.2281
[2019-03-23 12:38:38,704] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5500, global step 87978: learning rate 0.0000
[2019-03-23 12:38:38,705] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5500, global step 87978: loss 0.1015
[2019-03-23 12:38:38,710] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5500, global step 87978: learning rate 0.0000
[2019-03-23 12:38:38,730] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5500, global step 87988: loss 0.0064
[2019-03-23 12:38:38,731] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5500, global step 87988: learning rate 0.0000
[2019-03-23 12:38:38,785] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5500, global step 88017: loss 0.0872
[2019-03-23 12:38:38,790] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5500, global step 88017: learning rate 0.0000
[2019-03-23 12:38:38,799] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 4.8950491e-34 1.3368819e-16 4.2826099e-31 2.5769105e-36], sum to 1.0000
[2019-03-23 12:38:38,803] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1020
[2019-03-23 12:38:38,808] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.0, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4601166789829113, 6.911199999999999, 6.9112, 77.32846344354104, 267620.5278875957, 267620.527887596, 83357.34137267293], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3295200.0000, 
sim time next is 3295800.0000, 
raw observation next is [16.0, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4592730475762616, 6.911199999999999, 6.9112, 77.32846344354104, 267129.7065484184, 267129.7065484187, 83300.61457960212], 
processed observation next is [0.0, 0.13043478260869565, 0.36363636363636365, 0.82, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.22753292510894516, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09893692835126607, 0.09893692835126618, 0.2031722306819564], 
reward next is 0.7968, 
noisyNet noise sample is [array([-1.2537324], dtype=float32), 0.65410364]. 
=============================================
[2019-03-23 12:38:38,849] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5500, global step 88050: loss 0.2327
[2019-03-23 12:38:38,852] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5500, global step 88050: loss 0.1415
[2019-03-23 12:38:38,855] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5500, global step 88050: learning rate 0.0000
[2019-03-23 12:38:38,856] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5500, global step 88050: learning rate 0.0000
[2019-03-23 12:38:39,022] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5500, global step 88133: loss 0.1022
[2019-03-23 12:38:39,026] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5500, global step 88134: learning rate 0.0000
[2019-03-23 12:38:39,372] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 6.4571815e-29 9.3529738e-16 6.1032965e-25 2.1395749e-33], sum to 1.0000
[2019-03-23 12:38:39,379] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1145
[2019-03-23 12:38:39,384] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.0, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5136978510755463, 6.9112, 6.9112, 77.32846344354104, 298794.8518540796, 298794.8518540796, 97702.83788010007], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3312000.0000, 
sim time next is 3312600.0000, 
raw observation next is [19.0, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5195121024145302, 6.911199999999999, 6.9112, 77.32846344354104, 302177.7900688088, 302177.7900688091, 98178.32526153019], 
processed observation next is [0.0, 0.34782608695652173, 0.5, 0.68, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.31358871773504315, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11191770002548475, 0.11191770002548486, 0.2394593299061712], 
reward next is 0.7605, 
noisyNet noise sample is [array([-0.02922105], dtype=float32), 1.7703953]. 
=============================================
[2019-03-23 12:38:39,425] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5500, global step 88332: loss 0.1233
[2019-03-23 12:38:39,425] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5500, global step 88332: learning rate 0.0000
[2019-03-23 12:38:43,531] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 4.8159506e-38 5.6969443e-21 2.6340810e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 12:38:43,543] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5808
[2019-03-23 12:38:43,547] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.33333333333334, 98.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6551137872661924, 6.911199999999999, 6.9112, 77.32846344354104, 378974.9681550415, 378974.9681550418, 119794.4542146298], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3392400.0000, 
sim time next is 3393000.0000, 
raw observation next is [17.5, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6553411909991314, 6.9112, 6.9112, 77.32846344354104, 378970.2503164877, 378970.2503164877, 119917.1878690901], 
processed observation next is [1.0, 0.2608695652173913, 0.4318181818181818, 0.97, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.507630272855902, 0.0, 0.0, 0.5084288129206541, 0.1403593519690695, 0.1403593519690695, 0.292480946022171], 
reward next is 0.7075, 
noisyNet noise sample is [array([0.61665], dtype=float32), -0.54516596]. 
=============================================
[2019-03-23 12:38:43,563] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[104.38959 ]
 [104.38619 ]
 [104.31868 ]
 [104.222015]
 [104.24155 ]], R is [[104.04445648]
 [103.71183014]
 [103.37922668]
 [103.06017303]
 [102.74710846]].
[2019-03-23 12:38:44,559] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 6.0662814e-15 4.3873072e-08 1.4562402e-12 1.4024418e-15], sum to 1.0000
[2019-03-23 12:38:44,564] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2369
[2019-03-23 12:38:44,570] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1029508.07456223 W.
[2019-03-23 12:38:44,575] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.33333333333334, 64.5, 1.0, 2.0, 0.4514096811856699, 1.0, 2.0, 0.4514096811856699, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1029508.07456223, 1029508.07456223, 217647.3203437683], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3413400.0000, 
sim time next is 3414000.0000, 
raw observation next is [25.66666666666667, 64.0, 1.0, 2.0, 0.3562054479972461, 1.0, 2.0, 0.3562054479972461, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 812190.522655976, 812190.522655976, 197951.8893335668], 
processed observation next is [1.0, 0.5217391304347826, 0.8030303030303032, 0.64, 1.0, 1.0, 0.19525680999655765, 1.0, 1.0, 0.19525680999655765, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.30081130468739853, 0.30081130468739853, 0.4828094861794312], 
reward next is 0.5172, 
noisyNet noise sample is [array([0.5349994], dtype=float32), -0.6807115]. 
=============================================
[2019-03-23 12:38:44,594] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[39.20836 ]
 [39.10642 ]
 [39.441864]
 [38.74065 ]
 [37.93492 ]], R is [[39.97075653]
 [40.04020309]
 [40.07395554]
 [40.01259995]
 [39.96061707]].
[2019-03-23 12:38:51,986] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.7778964e-01 1.2197945e-05 2.2168338e-02 2.8963004e-05 8.6207694e-07], sum to 1.0000
[2019-03-23 12:38:51,992] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0180
[2019-03-23 12:38:52,000] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 591256.3298546391 W.
[2019-03-23 12:38:52,169] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.2596343114562971, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5257094553436485, 6.911199999999999, 6.9112, 77.32846344354104, 591256.3298546391, 591256.3298546395, 182042.4698196879], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3547200.0000, 
sim time next is 3547800.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.260223377212951, 1.0, 1.0, 0.260223377212951, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 591571.8758106809, 591571.8758106809, 182506.7045860793], 
processed observation next is [1.0, 0.043478260869565216, 0.6818181818181818, 0.89, 1.0, 1.0, 0.07527922151618877, 1.0, 0.5, 0.07527922151618877, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21910069474469662, 0.21910069474469662, 0.4451383038684861], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.0089948], dtype=float32), 1.9111668]. 
=============================================
[2019-03-23 12:38:52,205] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.4993982e-01 2.2211080e-04 1.4969544e-01 1.3656277e-04 5.9526496e-06], sum to 1.0000
[2019-03-23 12:38:52,210] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3757
[2019-03-23 12:38:52,222] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 715465.073300248 W.
[2019-03-23 12:38:52,226] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.5, 91.5, 1.0, 2.0, 0.2100841039961442, 1.0, 2.0, 0.2100841039961442, 1.0, 2.0, 0.4255588300493163, 6.911199999999999, 6.9112, 77.3421103, 715465.073300248, 715465.0733002482, 231937.0668978194], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3551400.0000, 
sim time next is 3552000.0000, 
raw observation next is [22.33333333333334, 92.33333333333334, 1.0, 2.0, 0.2958361933905269, 1.0, 2.0, 0.2958361933905269, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 672577.8881691014, 672577.8881691012, 188603.995304164], 
processed observation next is [1.0, 0.08695652173913043, 0.6515151515151518, 0.9233333333333335, 1.0, 1.0, 0.11979524173815863, 1.0, 1.0, 0.11979524173815863, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24910292154411165, 0.24910292154411157, 0.46000974464430244], 
reward next is 0.5400, 
noisyNet noise sample is [array([-0.40839526], dtype=float32), -0.0763927]. 
=============================================
[2019-03-23 12:38:52,237] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[18.291382]
 [18.257195]
 [18.003063]
 [17.935238]
 [18.00278 ]], R is [[18.66523361]
 [18.91288185]
 [19.14530945]
 [19.34176254]
 [19.79392815]].
[2019-03-23 12:38:53,726] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.8088993e-02 3.1616689e-06 9.3181723e-01 8.9956535e-05 6.2022633e-07], sum to 1.0000
[2019-03-23 12:38:53,733] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3617
[2019-03-23 12:38:53,737] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.0, 89.0, 1.0, 2.0, 0.7342004019736995, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9818463422330987, 6.911199999999999, 6.9112, 77.32846344354104, 1377787.295743782, 1377787.295743782, 301636.6023003599], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3582000.0000, 
sim time next is 3582600.0000, 
raw observation next is [23.83333333333333, 89.83333333333334, 1.0, 2.0, 0.873818652436899, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9820993172635482, 6.9112, 6.9112, 77.32846344354104, 1535363.680528485, 1535363.680528485, 325603.4083909579], 
processed observation next is [1.0, 0.4782608695652174, 0.7196969696969695, 0.8983333333333334, 1.0, 1.0, 0.8422733155461237, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9744275960907831, 0.0, 0.0, 0.5084288129206541, 0.56865321501055, 0.56865321501055, 0.7941546546120924], 
reward next is 0.2058, 
noisyNet noise sample is [array([1.3040448], dtype=float32), 0.65052354]. 
=============================================
[2019-03-23 12:38:54,483] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6000, global step 95855: loss -0.7593
[2019-03-23 12:38:54,488] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6000, global step 95855: learning rate 0.0000
[2019-03-23 12:38:54,513] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6000, global step 95866: loss 100.4339
[2019-03-23 12:38:54,516] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6000, global step 95867: learning rate 0.0000
[2019-03-23 12:38:54,556] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6000, global step 95887: loss 38.7682
[2019-03-23 12:38:54,559] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6000, global step 95887: learning rate 0.0000
[2019-03-23 12:38:54,573] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6000, global step 95896: loss 21.7651
[2019-03-23 12:38:54,574] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6000, global step 95896: learning rate 0.0000
[2019-03-23 12:38:54,584] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6000, global step 95901: loss 40.5369
[2019-03-23 12:38:54,585] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6000, global step 95901: learning rate 0.0000
[2019-03-23 12:38:54,608] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6000, global step 95915: loss 70.7415
[2019-03-23 12:38:54,610] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6000, global step 95915: learning rate 0.0000
[2019-03-23 12:38:54,685] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6000, global step 95952: loss 75.9340
[2019-03-23 12:38:54,687] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6000, global step 95952: learning rate 0.0000
[2019-03-23 12:38:54,734] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6000, global step 95979: loss 16.7569
[2019-03-23 12:38:54,736] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6000, global step 95980: learning rate 0.0000
[2019-03-23 12:38:54,737] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6000, global step 95981: loss 92.8407
[2019-03-23 12:38:54,739] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6000, global step 95981: learning rate 0.0000
[2019-03-23 12:38:54,815] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6000, global step 96022: loss -1.7616
[2019-03-23 12:38:54,817] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6000, global step 96023: learning rate 0.0000
[2019-03-23 12:38:54,835] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6000, global step 96031: loss 2.0823
[2019-03-23 12:38:54,837] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6000, global step 96032: learning rate 0.0000
[2019-03-23 12:38:54,844] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6000, global step 96037: loss 12.1733
[2019-03-23 12:38:54,852] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6000, global step 96038: learning rate 0.0000
[2019-03-23 12:38:54,948] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6000, global step 96087: loss 0.4919
[2019-03-23 12:38:54,950] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6000, global step 96089: learning rate 0.0000
[2019-03-23 12:38:54,968] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6000, global step 96101: loss 44.5626
[2019-03-23 12:38:54,970] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6000, global step 96101: learning rate 0.0000
[2019-03-23 12:38:55,044] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6000, global step 96137: loss 29.7786
[2019-03-23 12:38:55,046] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6000, global step 96137: learning rate 0.0000
[2019-03-23 12:38:55,308] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6000, global step 96275: loss 9.8495
[2019-03-23 12:38:55,310] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6000, global step 96275: learning rate 0.0000
[2019-03-23 12:39:00,489] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.9143807e-04 1.7226416e-11 9.9980861e-01 1.0083537e-08 8.1987786e-13], sum to 1.0000
[2019-03-23 12:39:00,500] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2473
[2019-03-23 12:39:00,503] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.83333333333333, 84.0, 1.0, 2.0, 0.2651991186456763, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5371239425539788, 6.911199999999999, 6.9112, 77.32846344354104, 603431.1016641983, 603431.1016641987, 183874.7059637826], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3712200.0000, 
sim time next is 3712800.0000, 
raw observation next is [23.66666666666666, 85.0, 1.0, 2.0, 0.2644163545364714, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5355216460141478, 6.911199999999999, 6.9112, 77.32846344354104, 601726.8894301448, 601726.889430145, 183613.3772440234], 
processed observation next is [1.0, 1.0, 0.7121212121212118, 0.85, 1.0, 1.0, 0.08052044317058922, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3364594943059254, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22286181090005364, 0.22286181090005372, 0.4478375054732278], 
reward next is 0.5522, 
noisyNet noise sample is [array([-0.61557955], dtype=float32), -0.907613]. 
=============================================
[2019-03-23 12:39:02,296] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 12:39:02,297] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:39:02,297] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:39:02,298] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:39:02,298] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:39:02,299] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:39:02,299] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:39:02,300] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:39:02,300] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:39:02,302] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:39:02,302] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:39:02,313] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run5
[2019-03-23 12:39:02,337] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run5
[2019-03-23 12:39:02,361] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run5
[2019-03-23 12:39:02,361] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run5
[2019-03-23 12:39:02,407] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run5
[2019-03-23 12:39:08,791] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00229127], dtype=float32), 0.047120955]
[2019-03-23 12:39:08,791] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.1, 71.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 232598.4843144167, 232598.4843144167, 98473.52403233877]
[2019-03-23 12:39:08,791] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:39:08,794] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.2383523e-03 4.2802893e-07 9.9773932e-01 2.1844135e-05 8.6389669e-08], sampled 0.13871069481806686
[2019-03-23 12:39:20,759] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00229127], dtype=float32), 0.047120955]
[2019-03-23 12:39:20,761] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.6, 87.0, 1.0, 2.0, 0.2028001593865651, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4033112195162433, 6.9112, 6.9112, 95.55338769695034, 460452.1361058758, 460452.1361058758, 167719.422501503]
[2019-03-23 12:39:20,762] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:39:20,764] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.3438078e-03 3.3866274e-07 9.9763858e-01 1.7173170e-05 6.2839696e-08], sampled 0.4374114402347091
[2019-03-23 12:39:38,255] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00229127], dtype=float32), 0.047120955]
[2019-03-23 12:39:38,255] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.0, 89.0, 1.0, 2.0, 0.2625209732863616, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5315816131247872, 6.911200000000001, 6.9112, 77.32846344354104, 597761.1588436305, 597761.1588436302, 182825.7513573552]
[2019-03-23 12:39:38,256] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:39:38,258] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.4879323e-03 2.2884188e-07 9.9849725e-01 1.4686597e-05 4.5260446e-08], sampled 0.8608878355727325
[2019-03-23 12:39:38,315] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00229127], dtype=float32), 0.047120955]
[2019-03-23 12:39:38,318] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.72561078, 90.80454008, 1.0, 2.0, 0.2700388579998829, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5468785567521739, 6.911200000000001, 6.9112, 95.55338769695034, 611839.9032812382, 611839.9032812378, 191373.3044130887]
[2019-03-23 12:39:38,319] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:39:38,321] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.4472946e-03 2.0305420e-07 9.9853909e-01 1.3338902e-05 3.9245254e-08], sampled 0.5783668361328288
[2019-03-23 12:40:12,717] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00229127], dtype=float32), 0.047120955]
[2019-03-23 12:40:12,718] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.85, 84.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 296005.0006884467, 296005.0006884463, 129211.2353991035]
[2019-03-23 12:40:12,718] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:40:12,723] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.5468320e-03 3.8253441e-07 9.9743420e-01 1.8562305e-05 7.1109064e-08], sampled 0.5465148799072662
[2019-03-23 12:40:40,881] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2769.3301 2122870208.2295 759.0000
[2019-03-23 12:40:41,241] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3366.8101 2097159966.7783 186.0000
[2019-03-23 12:40:41,682] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3626.1824 2174238958.3557 248.0000
[2019-03-23 12:40:41,724] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3515.3441 2103189462.2924 188.0000
[2019-03-23 12:40:41,761] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3119.3464 2108150041.6533 377.0000
[2019-03-23 12:40:42,776] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 100000, evaluation results [100000.0, 3626.1824145273417, 2174238958.355685, 248.0, 3366.810091672486, 2097159966.77831, 186.0, 3515.3441266598206, 2103189462.2924283, 188.0, 2769.3300644180804, 2122870208.22946, 759.0, 3119.3463907888085, 2108150041.6533298, 377.0]
[2019-03-23 12:40:48,594] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 2.5392513e-23 8.6734893e-14 3.2463925e-21 8.6541024e-26], sum to 1.0000
[2019-03-23 12:40:48,600] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3901
[2019-03-23 12:40:48,605] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.16666666666667, 57.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6119244330123411, 6.911199999999999, 6.9112, 77.32846344354104, 354823.0249299374, 354823.0249299377, 115319.3282187402], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3865800.0000, 
sim time next is 3866400.0000, 
raw observation next is [22.0, 57.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6053270589197166, 6.911199999999999, 6.9112, 77.32846344354104, 351258.3460179931, 351258.3460179933, 114567.5832278449], 
processed observation next is [0.0, 0.782608695652174, 0.6363636363636364, 0.57, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4361815127424523, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1300956837103678, 0.1300956837103679, 0.2794331298240119], 
reward next is 0.7206, 
noisyNet noise sample is [array([0.06062032], dtype=float32), 1.4697857]. 
=============================================
[2019-03-23 12:40:50,164] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6500, global step 103752: loss 1.2225
[2019-03-23 12:40:50,165] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6500, global step 103752: learning rate 0.0000
[2019-03-23 12:40:50,300] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6500, global step 103822: loss 0.9813
[2019-03-23 12:40:50,302] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6500, global step 103825: learning rate 0.0000
[2019-03-23 12:40:50,326] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6500, global step 103835: loss 0.5356
[2019-03-23 12:40:50,329] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6500, global step 103835: learning rate 0.0000
[2019-03-23 12:40:50,336] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6500, global step 103839: loss 0.3223
[2019-03-23 12:40:50,339] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6500, global step 103840: learning rate 0.0000
[2019-03-23 12:40:50,339] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6500, global step 103840: loss 0.3636
[2019-03-23 12:40:50,343] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6500, global step 103840: learning rate 0.0000
[2019-03-23 12:40:50,547] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6500, global step 103945: loss 0.2722
[2019-03-23 12:40:50,550] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6500, global step 103946: learning rate 0.0000
[2019-03-23 12:40:50,562] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6500, global step 103950: loss 0.2027
[2019-03-23 12:40:50,564] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6500, global step 103952: learning rate 0.0000
[2019-03-23 12:40:50,623] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6500, global step 103986: loss 0.0988
[2019-03-23 12:40:50,626] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6500, global step 103987: learning rate 0.0000
[2019-03-23 12:40:50,704] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6500, global step 104022: loss 0.0578
[2019-03-23 12:40:50,706] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6500, global step 104023: learning rate 0.0000
[2019-03-23 12:40:50,715] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6500, global step 104027: loss 0.0599
[2019-03-23 12:40:50,718] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6500, global step 104029: learning rate 0.0000
[2019-03-23 12:40:50,746] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6500, global step 104044: loss 0.1351
[2019-03-23 12:40:50,752] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6500, global step 104047: learning rate 0.0000
[2019-03-23 12:40:50,756] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6500, global step 104049: loss 0.4659
[2019-03-23 12:40:50,757] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6500, global step 104049: learning rate 0.0000
[2019-03-23 12:40:50,808] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6500, global step 104072: loss 0.7952
[2019-03-23 12:40:50,813] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6500, global step 104072: learning rate 0.0000
[2019-03-23 12:40:50,930] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6500, global step 104138: loss 0.9069
[2019-03-23 12:40:50,931] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6500, global step 104138: learning rate 0.0000
[2019-03-23 12:40:50,997] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6500, global step 104166: loss 0.3360
[2019-03-23 12:40:51,000] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6500, global step 104166: learning rate 0.0000
[2019-03-23 12:40:51,272] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6500, global step 104309: loss 0.0195
[2019-03-23 12:40:51,278] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6500, global step 104310: learning rate 0.0000
[2019-03-23 12:40:51,799] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 2.4899015e-22 1.6844170e-15 8.5435834e-21 2.3662183e-24], sum to 1.0000
[2019-03-23 12:40:51,806] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6365
[2019-03-23 12:40:51,811] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.5, 74.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5751329818597923, 6.911199999999999, 6.9112, 77.32846344354104, 334061.8629971106, 334061.8629971109, 111883.1127935935], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3916200.0000, 
sim time next is 3916800.0000, 
raw observation next is [20.0, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5916173360369068, 6.9112, 6.9112, 77.32846344354104, 343198.380668094, 343198.380668094, 113521.9303132564], 
processed observation next is [0.0, 0.34782608695652173, 0.5454545454545454, 0.73, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4165961943384383, 0.0, 0.0, 0.5084288129206541, 0.12711051135855334, 0.12711051135855334, 0.27688275686160096], 
reward next is 0.7231, 
noisyNet noise sample is [array([0.9146395], dtype=float32), -0.77064395]. 
=============================================
[2019-03-23 12:40:56,749] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9999976e-01 2.1036005e-11 1.9705870e-07 1.1409793e-08 5.4343027e-12], sum to 1.0000
[2019-03-23 12:40:56,755] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4585
[2019-03-23 12:40:56,762] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 565631.9703793151 W.
[2019-03-23 12:40:56,767] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.0, 99.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3274555043112789, 6.9112, 6.9112, 77.3421103, 565631.9703793151, 565631.9703793151, 198072.7772949637], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4013400.0000, 
sim time next is 4014000.0000, 
raw observation next is [17.0, 100.0, 1.0, 2.0, 0.2425809936924325, 0.0, 1.0, 0.0, 1.0, 2.0, 0.4682211053136715, 6.9112, 6.9112, 77.32846344354027, 540189.257810981, 540189.257810981, 164197.3818577376], 
processed observation next is [1.0, 0.4782608695652174, 0.4090909090909091, 1.0, 1.0, 1.0, 0.053226242115540605, 0.0, 0.5, -0.25, 1.0, 1.0, 0.24031586473381647, 0.0, 0.0, 0.508428812920649, 0.20007009548554852, 0.20007009548554852, 0.4004814191652137], 
reward next is 0.5995, 
noisyNet noise sample is [array([0.5061617], dtype=float32), 0.041118763]. 
=============================================
[2019-03-23 12:40:56,794] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[28.239958]
 [27.70923 ]
 [27.499756]
 [26.86262 ]
 [27.14393 ]], R is [[29.37832642]
 [29.08454323]
 [28.79369736]
 [28.50576019]
 [28.22070312]].
[2019-03-23 12:40:57,632] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9999034e-01 7.6199208e-10 9.7009897e-06 8.7312229e-09 6.9335392e-12], sum to 1.0000
[2019-03-23 12:40:57,639] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6903
[2019-03-23 12:40:57,650] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 549531.9780870029 W.
[2019-03-23 12:40:57,661] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.0, 99.00000000000001, 1.0, 2.0, 0.2431175856161471, 1.0, 2.0, 0.2431175856161471, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 549531.9780870029, 549531.9780870029, 169064.1578042763], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4029000.0000, 
sim time next is 4029600.0000, 
raw observation next is [18.0, 98.0, 1.0, 2.0, 0.2665751767467165, 1.0, 2.0, 0.2665751767467165, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 601984.2578351917, 601984.2578351917, 172009.9082405288], 
processed observation next is [1.0, 0.6521739130434783, 0.45454545454545453, 0.98, 1.0, 1.0, 0.0832189709333956, 1.0, 1.0, 0.0832189709333956, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22295713253155247, 0.22295713253155247, 0.41953636156226537], 
reward next is 0.5805, 
noisyNet noise sample is [array([-0.86974853], dtype=float32), -2.1744695]. 
=============================================
[2019-03-23 12:41:00,414] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9999714e-01 1.6594170e-16 2.8733755e-06 1.1364000e-12 1.0084545e-17], sum to 1.0000
[2019-03-23 12:41:00,421] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1074
[2019-03-23 12:41:00,429] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 828059.5380453579 W.
[2019-03-23 12:41:00,433] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.33333333333334, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.838973654724159, 7.969666941161994, 6.9112, 77.32583991599681, 828059.5380453579, 484302.7880009559, 140575.3218573981], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4090800.0000, 
sim time next is 4091400.0000, 
raw observation next is [18.5, 94.0, 1.0, 1.0, 0.3423657901204572, 1.0, 1.0, 0.3423657901204572, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32782619481, 775168.4270508181, 775168.4270508181, 185061.4001592597], 
processed observation next is [1.0, 0.34782608695652173, 0.4772727272727273, 0.94, 1.0, 0.5, 0.17795723765057148, 1.0, 0.5, 0.17795723765057148, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084246230583263, 0.2870994174262289, 0.2870994174262289, 0.4513692686811212], 
reward next is 0.5486, 
noisyNet noise sample is [array([1.4426188], dtype=float32), -0.8889846]. 
=============================================
[2019-03-23 12:41:00,934] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.9999976e-01 7.6579322e-18 2.0475468e-07 3.2396223e-15 2.7902635e-19], sum to 1.0000
[2019-03-23 12:41:00,941] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7185
[2019-03-23 12:41:00,949] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 845653.4590589764 W.
[2019-03-23 12:41:00,954] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.5, 75.5, 1.0, 2.0, 0.2470110798781773, 1.0, 2.0, 0.2470110798781773, 1.0, 1.0, 0.4970480727409974, 6.911199999999999, 6.9112, 77.3421103, 845653.4590589764, 845653.4590589766, 234715.579840628], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4102200.0000, 
sim time next is 4102800.0000, 
raw observation next is [22.66666666666666, 74.66666666666667, 1.0, 2.0, 0.2182138071301568, 1.0, 2.0, 0.2182138071301568, 1.0, 2.0, 0.4392195744081454, 6.9112, 6.9112, 77.3421103, 747025.2396603406, 747025.2396603406, 227033.5709603482], 
processed observation next is [1.0, 0.4782608695652174, 0.6666666666666664, 0.7466666666666667, 1.0, 1.0, 0.022767258912696, 1.0, 1.0, 0.022767258912696, 1.0, 1.0, 0.19888510629735062, 0.0, 0.0, 0.5085185399722538, 0.27667601468901504, 0.27667601468901504, 0.553740416976459], 
reward next is 0.4463, 
noisyNet noise sample is [array([-1.3563629], dtype=float32), 1.495103]. 
=============================================
[2019-03-23 12:41:02,283] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9999082e-01 9.5242667e-09 9.0239291e-06 5.9094248e-08 3.1999420e-10], sum to 1.0000
[2019-03-23 12:41:02,290] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6695
[2019-03-23 12:41:02,299] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 965069.7190656137 W.
[2019-03-23 12:41:02,302] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.8475500659864228, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 965069.7190656137, 965069.7190656137, 184998.3009606194], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4119600.0000, 
sim time next is 4120200.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.869779288283002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 989368.5760312235, 989368.5760312235, 187582.6663582761], 
processed observation next is [1.0, 0.6956521739130435, 0.6363636363636364, 0.78, 1.0, 1.0, 0.8372241103537525, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.36643280593749017, 0.36643280593749017, 0.45751869843481974], 
reward next is 0.5425, 
noisyNet noise sample is [array([-0.83767104], dtype=float32), 0.9778849]. 
=============================================
[2019-03-23 12:41:06,062] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7000, global step 111757: loss -57.4945
[2019-03-23 12:41:06,067] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7000, global step 111758: learning rate 0.0000
[2019-03-23 12:41:06,244] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7000, global step 111844: loss -1.8614
[2019-03-23 12:41:06,244] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7000, global step 111844: loss -6.3307
[2019-03-23 12:41:06,245] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7000, global step 111844: learning rate 0.0000
[2019-03-23 12:41:06,247] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7000, global step 111844: learning rate 0.0000
[2019-03-23 12:41:06,262] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7000, global step 111851: loss -56.0032
[2019-03-23 12:41:06,262] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7000, global step 111851: learning rate 0.0000
[2019-03-23 12:41:06,305] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7000, global step 111871: loss 42.1656
[2019-03-23 12:41:06,306] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7000, global step 111871: learning rate 0.0000
[2019-03-23 12:41:06,390] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7000, global step 111917: loss -5.4394
[2019-03-23 12:41:06,392] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7000, global step 111918: learning rate 0.0000
[2019-03-23 12:41:06,516] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7000, global step 111980: loss -43.8690
[2019-03-23 12:41:06,518] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7000, global step 111981: learning rate 0.0000
[2019-03-23 12:41:06,535] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7000, global step 111990: loss -1.9669
[2019-03-23 12:41:06,536] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7000, global step 111990: learning rate 0.0000
[2019-03-23 12:41:06,557] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7000, global step 112001: loss 36.2618
[2019-03-23 12:41:06,558] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7000, global step 112001: learning rate 0.0000
[2019-03-23 12:41:06,590] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7000, global step 112014: loss 26.1923
[2019-03-23 12:41:06,591] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7000, global step 112014: learning rate 0.0000
[2019-03-23 12:41:06,613] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7000, global step 112023: loss -52.0731
[2019-03-23 12:41:06,614] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7000, global step 112023: learning rate 0.0000
[2019-03-23 12:41:06,647] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7000, global step 112042: loss 23.6273
[2019-03-23 12:41:06,649] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7000, global step 112044: learning rate 0.0000
[2019-03-23 12:41:06,712] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7000, global step 112080: loss 7.4275
[2019-03-23 12:41:06,717] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7000, global step 112080: learning rate 0.0000
[2019-03-23 12:41:06,764] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7000, global step 112101: loss -56.8406
[2019-03-23 12:41:06,767] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7000, global step 112102: learning rate 0.0000
[2019-03-23 12:41:06,926] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7000, global step 112184: loss -35.9221
[2019-03-23 12:41:06,928] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7000, global step 112184: learning rate 0.0000
[2019-03-23 12:41:07,310] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7000, global step 112376: loss 13.7467
[2019-03-23 12:41:07,312] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7000, global step 112377: learning rate 0.0000
[2019-03-23 12:41:08,755] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 8.6202036e-25 2.5010733e-14 2.5909749e-22 4.3373532e-26], sum to 1.0000
[2019-03-23 12:41:08,764] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4477
[2019-03-23 12:41:08,770] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.0, 80.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7171443729209607, 6.949880465079234, 6.9112, 77.3282864099239, 426000.4561285973, 413437.8609837098, 126931.5149822474], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4224600.0000, 
sim time next is 4225200.0000, 
raw observation next is [19.66666666666667, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7166932123961085, 6.946218804852915, 6.9112, 77.32830302521404, 424556.773081353, 413183.4051177154, 126879.7217277137], 
processed observation next is [1.0, 0.9130434782608695, 0.5303030303030305, 0.83, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5952760177087265, 0.0035018804852914977, 0.0, 0.5084277581822572, 0.15724324928938999, 0.15303089078433904, 0.3094627359212529], 
reward next is 0.5154, 
noisyNet noise sample is [array([-1.0077404], dtype=float32), -0.81178886]. 
=============================================
[2019-03-23 12:41:14,418] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9997008e-01 6.1631215e-07 2.8751576e-05 4.5249143e-07 1.4658254e-07], sum to 1.0000
[2019-03-23 12:41:14,425] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0696
[2019-03-23 12:41:14,433] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1052013.007208487 W.
[2019-03-23 12:41:14,444] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 78.0, 1.0, 2.0, 0.4607333442251336, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9250475205381238, 6.91809196573722, 6.9112, 77.3284468914934, 1052013.007208487, 1049774.638181235, 244280.1458132209], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4352400.0000, 
sim time next is 4353000.0000, 
raw observation next is [23.5, 75.83333333333333, 1.0, 2.0, 0.4627324897151077, 1.0, 1.0, 0.4627324897151077, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.3284593021014, 1055836.387490521, 1055836.387490521, 219539.2556358364], 
processed observation next is [1.0, 0.391304347826087, 0.7045454545454546, 0.7583333333333333, 1.0, 1.0, 0.3284156121438846, 1.0, 0.5, 0.3284156121438846, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084287856910009, 0.39105051388537815, 0.39105051388537815, 0.5354615991117961], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8632816], dtype=float32), 2.2863736]. 
=============================================
[2019-03-23 12:41:14,455] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[13.536401 ]
 [13.697718 ]
 [14.046108 ]
 [14.1029625]
 [14.33457  ]], R is [[12.983428  ]
 [12.85359383]
 [12.7250576 ]
 [13.05262756]
 [13.32536125]].
[2019-03-23 12:41:15,173] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.95929646 0.00243025 0.03434575 0.00215231 0.00177531], sum to 1.0000
[2019-03-23 12:41:15,181] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7254
[2019-03-23 12:41:15,188] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 863629.0427986035 W.
[2019-03-23 12:41:15,193] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.66666666666667, 81.33333333333334, 1.0, 1.0, 0.3791504482517275, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7582600829181387, 6.911200000000001, 6.9112, 77.32798719332558, 863629.0427986035, 863629.0427986033, 209348.9737497636], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4350000.0000, 
sim time next is 4350600.0000, 
raw observation next is [22.0, 80.5, 1.0, 2.0, 0.4133989680299177, 1.0, 1.0, 0.4133989680299177, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846049543782, 943637.8560015976, 943637.8560015976, 205349.1619304536], 
processed observation next is [1.0, 0.34782608695652173, 0.6363636363636364, 0.805, 1.0, 1.0, 0.2667487100373971, 1.0, 0.5, 0.2667487100373971, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084287935370979, 0.34949550222281395, 0.34949550222281395, 0.500851614464521], 
reward next is 0.4991, 
noisyNet noise sample is [array([0.86271167], dtype=float32), -0.18251395]. 
=============================================
[2019-03-23 12:41:21,095] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.1689051e-07 4.8632647e-12 9.9999952e-01 6.1491710e-09 3.3605911e-09], sum to 1.0000
[2019-03-23 12:41:21,100] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3851
[2019-03-23 12:41:21,104] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 80.5, 1.0, 2.0, 0.2389837742079099, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4818651088521206, 6.911199999999999, 6.9112, 77.32846344354104, 545401.8148420979, 545401.8148420982, 174458.8508043532], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4476600.0000, 
sim time next is 4477200.0000, 
raw observation next is [23.0, 79.66666666666667, 1.0, 2.0, 0.2374551305637427, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4784499042230668, 6.911199999999999, 6.9112, 77.32846344354104, 541890.5315922427, 541890.5315922429, 173821.5555628617], 
processed observation next is [0.0, 0.8260869565217391, 0.6818181818181818, 0.7966666666666667, 1.0, 1.0, 0.04681891320467837, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2549284346043812, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20070019688601579, 0.2007001968860159, 0.42395501356795534], 
reward next is 0.5760, 
noisyNet noise sample is [array([-0.25164363], dtype=float32), -0.6285774]. 
=============================================
[2019-03-23 12:41:21,876] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7500, global step 119724: loss 0.1158
[2019-03-23 12:41:21,878] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7500, global step 119724: learning rate 0.0000
[2019-03-23 12:41:22,093] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7500, global step 119838: loss 0.7945
[2019-03-23 12:41:22,094] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7500, global step 119839: learning rate 0.0000
[2019-03-23 12:41:22,098] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7500, global step 119841: loss 0.9417
[2019-03-23 12:41:22,101] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7500, global step 119841: learning rate 0.0000
[2019-03-23 12:41:22,207] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7500, global step 119899: loss 0.1231
[2019-03-23 12:41:22,208] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7500, global step 119899: learning rate 0.0000
[2019-03-23 12:41:22,212] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7500, global step 119901: loss 0.0546
[2019-03-23 12:41:22,215] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7500, global step 119902: learning rate 0.0000
[2019-03-23 12:41:22,280] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7500, global step 119934: loss 0.0235
[2019-03-23 12:41:22,281] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7500, global step 119934: learning rate 0.0000
[2019-03-23 12:41:22,377] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7500, global step 119986: loss 0.1687
[2019-03-23 12:41:22,384] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7500, global step 119989: learning rate 0.0000
[2019-03-23 12:41:22,397] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7500, global step 119994: loss 0.2980
[2019-03-23 12:41:22,399] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7500, global step 119994: learning rate 0.0000
[2019-03-23 12:41:22,411] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7500, global step 120000: loss 0.3853
[2019-03-23 12:41:22,415] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7500, global step 120000: learning rate 0.0000
[2019-03-23 12:41:22,455] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7500, global step 120029: loss 0.3606
[2019-03-23 12:41:22,459] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7500, global step 120030: learning rate 0.0000
[2019-03-23 12:41:22,485] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7500, global step 120046: loss 0.2383
[2019-03-23 12:41:22,488] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7500, global step 120046: learning rate 0.0000
[2019-03-23 12:41:22,490] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7500, global step 120047: loss 0.4178
[2019-03-23 12:41:22,496] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7500, global step 120047: learning rate 0.0000
[2019-03-23 12:41:22,509] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7500, global step 120055: loss 0.2863
[2019-03-23 12:41:22,510] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7500, global step 120055: learning rate 0.0000
[2019-03-23 12:41:22,612] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7500, global step 120112: loss 0.0218
[2019-03-23 12:41:22,616] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7500, global step 120114: loss 0.0236
[2019-03-23 12:41:22,617] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7500, global step 120114: learning rate 0.0000
[2019-03-23 12:41:22,617] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7500, global step 120114: learning rate 0.0000
[2019-03-23 12:41:22,968] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7500, global step 120297: loss 0.1340
[2019-03-23 12:41:22,970] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7500, global step 120298: learning rate 0.0000
[2019-03-23 12:41:28,993] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9999392e-01 2.4886779e-07 5.6151271e-06 1.0642081e-07 1.4880273e-07], sum to 1.0000
[2019-03-23 12:41:28,999] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1119
[2019-03-23 12:41:29,004] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 593216.1974599903 W.
[2019-03-23 12:41:29,013] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.66666666666666, 57.33333333333334, 1.0, 2.0, 0.2722466819978454, 1.0, 2.0, 0.2722466819978454, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354063, 593216.1974599903, 593216.1974599906, 162563.4266194848], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4618200.0000, 
sim time next is 4618800.0000, 
raw observation next is [21.0, 56.0, 1.0, 2.0, 0.2597407785175829, 1.0, 2.0, 0.2597407785175829, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 566489.0872661463, 566489.0872661463, 161198.0960910463], 
processed observation next is [1.0, 0.4782608695652174, 0.5909090909090909, 0.56, 1.0, 1.0, 0.07467597314697864, 1.0, 1.0, 0.07467597314697864, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20981077306153567, 0.20981077306153567, 0.3931660880269422], 
reward next is 0.6068, 
noisyNet noise sample is [array([-0.71537197], dtype=float32), 0.24147038]. 
=============================================
[2019-03-23 12:41:29,833] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.00000000e+00 1.13374194e-13 2.62489353e-11 5.74201873e-14
 5.14214973e-13], sum to 1.0000
[2019-03-23 12:41:29,840] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3571
[2019-03-23 12:41:29,843] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.33333333333334, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5756926421120515, 6.9112, 6.9112, 77.32846344354104, 334841.222732318, 334841.222732318, 110446.9953653056], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4646400.0000, 
sim time next is 4647000.0000, 
raw observation next is [22.16666666666667, 52.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5682201817476193, 6.9112, 6.9112, 77.32846344354104, 330510.3275877513, 330510.3275877513, 109086.5165666249], 
processed observation next is [1.0, 0.782608695652174, 0.6439393939393941, 0.525, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3831716882108848, 0.0, 0.0, 0.5084288129206541, 0.1224112324399079, 0.1224112324399079, 0.26606467455274363], 
reward next is 0.7339, 
noisyNet noise sample is [array([-0.30764574], dtype=float32), -1.3694575]. 
=============================================
[2019-03-23 12:41:29,862] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[28.249876]
 [26.74801 ]
 [25.58295 ]
 [24.382572]
 [22.26069 ]], R is [[29.36742783]
 [29.80437088]
 [30.23325539]
 [30.65515137]
 [31.07180595]].
[2019-03-23 12:41:31,776] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 12:41:31,777] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:41:31,777] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:41:31,778] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:41:31,779] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:41:31,779] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:41:31,780] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:41:31,781] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:41:31,781] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:41:31,782] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:41:31,782] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:41:31,794] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run6
[2019-03-23 12:41:31,817] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run6
[2019-03-23 12:41:31,817] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run6
[2019-03-23 12:41:31,856] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run6
[2019-03-23 12:41:31,889] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run6
[2019-03-23 12:41:51,600] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00627672], dtype=float32), 0.051216193]
[2019-03-23 12:41:51,601] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [9.207068956, 75.60600918166666, 1.0, 1.0, 0.2854577354006381, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5325818226806351, 6.911200000000001, 6.9112, 95.5523918291582, 620042.0531502904, 620042.05315029, 143392.8448341219]
[2019-03-23 12:41:51,604] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:41:51,607] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 4.9068110e-33 1.2041276e-25 4.6126883e-33 2.2486378e-32], sampled 0.9865197227265694
[2019-03-23 12:41:51,607] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 620042.0531502904 W.
[2019-03-23 12:41:53,099] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00627672], dtype=float32), 0.051216193]
[2019-03-23 12:41:53,100] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.996779365, 47.295190285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5595633287265114, 6.911199999999999, 6.9112, 95.55338769695034, 325460.8852040445, 325460.8852040449, 92195.90058484017]
[2019-03-23 12:41:53,100] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:41:53,105] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0000000e+00 2.7907324e-34 1.3189130e-26 2.6134826e-34 1.3425942e-33], sampled 0.712151114136206
[2019-03-23 12:41:58,585] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00627672], dtype=float32), 0.051216193]
[2019-03-23 12:41:58,586] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.95, 38.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6904788354405228, 7.016039891332424, 6.9112, 95.55301978523023, 443719.8877259724, 401645.2612407447, 110774.58108371]
[2019-03-23 12:41:58,587] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:41:58,590] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0000000e+00 3.1879434e-34 1.4650418e-26 2.9829606e-34 1.5345546e-33], sampled 0.2637304265150887
[2019-03-23 12:42:06,525] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00627672], dtype=float32), 0.051216193]
[2019-03-23 12:42:06,526] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.6, 90.0, 1.0, 1.0, 0.78261232276103, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 99.90312874189236, 890362.3314148649, 890362.3314148644, 179196.6572101088]
[2019-03-23 12:42:06,526] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:42:06,529] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0000000e+00 4.8135765e-25 1.9947662e-19 4.5163510e-25 1.6928154e-24], sampled 0.0962246708844382
[2019-03-23 12:42:06,531] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 890362.3314148649 W.
[2019-03-23 12:42:10,205] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00627672], dtype=float32), 0.051216193]
[2019-03-23 12:42:10,205] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.30694204, 84.06603766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7079548933726489, 7.126541859180669, 6.9112, 95.55241964124713, 495444.0950954791, 409023.0651774969, 129618.4413727898]
[2019-03-23 12:42:10,206] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:42:10,209] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 3.0930646e-29 1.0552281e-22 2.9034712e-29 1.2182640e-28], sampled 0.5026237369496169
[2019-03-23 12:42:13,868] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00627672], dtype=float32), 0.051216193]
[2019-03-23 12:42:13,870] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.47795356, 46.90186448, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7504358872893176, 7.429148507965612, 6.9112, 95.55175185033032, 637088.0581067706, 429226.3314283786, 137329.8098464513]
[2019-03-23 12:42:13,873] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:42:13,875] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0000000e+00 9.1278060e-25 3.6822426e-19 8.3354090e-25 3.5439395e-24], sampled 0.8591701747722845
[2019-03-23 12:42:13,878] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 637088.0581067706 W.
[2019-03-23 12:42:16,078] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00627672], dtype=float32), 0.051216193]
[2019-03-23 12:42:16,081] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.0, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4925992837655498, 6.9112, 6.9112, 77.32846344354104, 286519.152641012, 286519.152641012, 94182.56022885772]
[2019-03-23 12:42:16,081] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:42:16,085] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 1.9792776e-37 4.9434195e-29 1.8473825e-37 1.0937496e-36], sampled 0.037424300582935666
[2019-03-23 12:42:23,707] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00627672], dtype=float32), 0.051216193]
[2019-03-23 12:42:23,707] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.8, 90.0, 1.0, 2.0, 0.5285164080929371, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 602203.4020316477, 602203.4020316474, 150397.7514763059]
[2019-03-23 12:42:23,709] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:42:23,711] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0000000e+00 2.9757460e-25 1.5861252e-19 2.7015523e-25 1.2047624e-24], sampled 0.7146270502234949
[2019-03-23 12:42:23,713] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 602203.4020316477 W.
[2019-03-23 12:42:47,473] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00627672], dtype=float32), 0.051216193]
[2019-03-23 12:42:47,474] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.089731105, 92.193939825, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7202797499820672, 7.188253942728706, 6.9112, 95.55246358863111, 524330.4691278716, 413143.0846742518, 133102.0003288108]
[2019-03-23 12:42:47,475] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:42:47,479] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 1.1752097e-28 3.0134590e-22 1.1037127e-28 4.5367023e-28], sampled 0.23528137406242366
[2019-03-23 12:43:10,582] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6553.1725 1698634175.0084 2957.0000
[2019-03-23 12:43:10,796] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6480.7827 1678914073.5112 3057.0000
[2019-03-23 12:43:10,848] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6860.6620 1793042911.7432 2409.0000
[2019-03-23 12:43:11,100] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6292.5954 1685655949.7275 3227.0000
[2019-03-23 12:43:11,105] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6328.7217 1723294598.4314 3425.0000
[2019-03-23 12:43:12,120] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 125000, evaluation results [125000.0, 6860.661968857812, 1793042911.7431853, 2409.0, 6480.7826730161, 1678914073.5112047, 3057.0, 6292.595362153885, 1685655949.7275183, 3227.0, 6328.721692698646, 1723294598.4313502, 3425.0, 6553.172466661831, 1698634175.0084193, 2957.0]
[2019-03-23 12:43:12,508] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.6697454e-25 1.0629260e-19 8.3062345e-26 3.9052507e-26], sum to 1.0000
[2019-03-23 12:43:12,518] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2182
[2019-03-23 12:43:12,525] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.0, 65.33333333333334, 1.0, 1.0, 0.4873888706373866, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32825198158858, 529343.086840607, 529343.086840607, 120600.2818491085], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4699200.0000, 
sim time next is 4699800.0000, 
raw observation next is [19.5, 64.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7812169444488182, 7.541757174572078, 6.9112, 77.32698006218916, 659355.2380698936, 454567.0933918309, 119581.7027639338], 
processed observation next is [1.0, 0.391304347826087, 0.5227272727272727, 0.64, 0.0, 0.5, -0.25, 0.0, 1.0, -0.25, 1.0, 0.5, 0.687452777784026, 0.06305571745720781, 0.0, 0.5084190598001825, 0.2442056437295902, 0.16835818273771516, 0.29166268966813125], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.43910915], dtype=float32), -1.2347375]. 
=============================================
[2019-03-23 12:43:15,662] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 3.9364367e-18 3.1917220e-15 2.9682642e-17 1.3707416e-18], sum to 1.0000
[2019-03-23 12:43:15,670] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9697
[2019-03-23 12:43:15,677] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7130586363708431, 6.917563883790466, 6.9112, 77.3283905488015, 413259.0256201036, 411192.1682772469, 126420.3826761384], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4758600.0000, 
sim time next is 4759200.0000, 
raw observation next is [19.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7128106552852032, 6.915526727604627, 6.9112, 77.32839930760511, 412455.834456205, 411050.6029926005, 126393.3496823359], 
processed observation next is [1.0, 0.08695652173913043, 0.5, 0.88, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5897295075502903, 0.0004326727604627045, 0.0, 0.5084283912317142, 0.15276142016896482, 0.15224096407133353, 0.30827646263984365], 
reward next is 0.6701, 
noisyNet noise sample is [array([-0.064194], dtype=float32), -0.29955423]. 
=============================================
[2019-03-23 12:43:16,527] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9998689e-01 1.3188727e-06 1.0885962e-05 3.1338968e-07 6.2223842e-07], sum to 1.0000
[2019-03-23 12:43:16,539] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0624
[2019-03-23 12:43:16,543] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.33333333333334, 100.0, 1.0, 1.0, 0.2095582044985324, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4128500235659767, 6.911199999999999, 6.9112, 77.32824613922214, 473233.5502432557, 473233.550243256, 162198.3114113272], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4774800.0000, 
sim time next is 4775400.0000, 
raw observation next is [18.5, 100.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7449849955142293, 7.145348527139266, 6.9112, 77.32788366379458, 503066.8596128643, 427020.7773328336, 131744.8236849933], 
processed observation next is [1.0, 0.2608695652173913, 0.4772727272727273, 1.0, 0.0, 0.5, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6356928507346132, 0.02341485271392658, 0.0, 0.5084250009125639, 0.18632105911587568, 0.15815584345660505, 0.32132883825608116], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9634471], dtype=float32), -0.59377515]. 
=============================================
[2019-03-23 12:43:17,816] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8000, global step 127862: loss 0.4402
[2019-03-23 12:43:17,818] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8000, global step 127862: learning rate 0.0000
[2019-03-23 12:43:17,838] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8000, global step 127873: loss 0.0989
[2019-03-23 12:43:17,838] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8000, global step 127873: loss 0.2998
[2019-03-23 12:43:17,840] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8000, global step 127873: learning rate 0.0000
[2019-03-23 12:43:17,846] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8000, global step 127875: learning rate 0.0000
[2019-03-23 12:43:17,857] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8000, global step 127881: loss 0.3947
[2019-03-23 12:43:17,859] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8000, global step 127882: learning rate 0.0000
[2019-03-23 12:43:17,880] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8000, global step 127892: loss 0.0549
[2019-03-23 12:43:17,882] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.7775179e-06 2.4603547e-10 9.9999630e-01 4.6433937e-09 8.9929341e-07], sum to 1.0000
[2019-03-23 12:43:17,884] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8000, global step 127893: learning rate 0.0000
[2019-03-23 12:43:17,889] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7665
[2019-03-23 12:43:17,892] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 96.0, 1.0, 2.0, 0.38460629537379, 0.0, 2.0, 0.0, 1.0, 2.0, 0.776279206292161, 6.911199999999999, 6.9112, 77.32843663165485, 877997.4110743811, 877997.4110743813, 216512.2025234192], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4796400.0000, 
sim time next is 4797000.0000, 
raw observation next is [21.0, 97.0, 1.0, 2.0, 0.3353005342092548, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6768936782270681, 6.911199999999999, 6.9112, 77.32846327757301, 765331.39405102, 765331.3940510203, 200446.0311488295], 
processed observation next is [1.0, 0.5217391304347826, 0.5909090909090909, 0.97, 1.0, 1.0, 0.1691256677615685, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5384195403243831, -8.881784197001253e-17, 0.0, 0.5084288118294268, 0.28345607187074817, 0.2834560718707482, 0.4888927588995841], 
reward next is 0.5111, 
noisyNet noise sample is [array([0.81392956], dtype=float32), -0.5956638]. 
=============================================
[2019-03-23 12:43:17,910] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[62.311676]
 [61.892242]
 [61.995136]
 [61.86305 ]
 [61.813076]], R is [[62.47188568]
 [62.31908798]
 [61.86079025]
 [61.66635132]
 [61.47724533]].
[2019-03-23 12:43:18,003] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8000, global step 127953: loss 0.3124
[2019-03-23 12:43:18,004] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8000, global step 127954: learning rate 0.0000
[2019-03-23 12:43:18,060] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8000, global step 127978: loss 0.0687
[2019-03-23 12:43:18,064] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8000, global step 127980: learning rate 0.0000
[2019-03-23 12:43:18,071] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8000, global step 127984: loss 0.0419
[2019-03-23 12:43:18,074] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8000, global step 127984: learning rate 0.0000
[2019-03-23 12:43:18,089] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8000, global step 127993: loss 0.5722
[2019-03-23 12:43:18,090] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8000, global step 127993: learning rate 0.0000
[2019-03-23 12:43:18,095] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8000, global step 127997: loss 0.1144
[2019-03-23 12:43:18,096] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8000, global step 127997: learning rate 0.0000
[2019-03-23 12:43:18,121] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8000, global step 128010: loss 0.0418
[2019-03-23 12:43:18,125] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8000, global step 128012: learning rate 0.0000
[2019-03-23 12:43:18,128] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8000, global step 128013: loss 0.0197
[2019-03-23 12:43:18,129] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.9034703e-07 1.9585539e-08 9.9996543e-01 6.6912628e-07 3.3551198e-05], sum to 1.0000
[2019-03-23 12:43:18,132] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8000, global step 128013: loss 0.0322
[2019-03-23 12:43:18,134] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8000, global step 128015: learning rate 0.0000
[2019-03-23 12:43:18,137] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8000, global step 128015: learning rate 0.0000
[2019-03-23 12:43:18,138] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8648
[2019-03-23 12:43:18,146] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5138960824736641, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9561370409755156, 6.941918215794312, 6.9112, 77.32836970087274, 1133761.500030366, 1123784.863930892, 259872.5210809339], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4805400.0000, 
sim time next is 4806000.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.4367853188539323, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8842289258032039, 6.911200000000001, 6.9112, 77.32844487180391, 995482.3986018889, 995482.3986018887, 239542.5206851405], 
processed observation next is [1.0, 0.6521739130434783, 0.6363636363636364, 0.94, 1.0, 1.0, 0.2959816485674153, 0.0, 1.0, -0.25, 1.0, 1.0, 0.8346127511474342, 8.881784197001253e-17, 0.0, 0.5084286908128837, 0.3686971846673663, 0.3686971846673662, 0.5842500504515622], 
reward next is 0.4157, 
noisyNet noise sample is [array([1.2679564], dtype=float32), -0.36317173]. 
=============================================
[2019-03-23 12:43:18,169] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[46.896866]
 [46.679905]
 [46.50893 ]
 [46.328144]
 [46.098995]], R is [[47.04645157]
 [46.78856277]
 [46.53554153]
 [46.29434586]
 [46.04610443]].
[2019-03-23 12:43:18,194] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8000, global step 128044: loss 0.0845
[2019-03-23 12:43:18,197] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8000, global step 128045: learning rate 0.0000
[2019-03-23 12:43:18,230] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8000, global step 128061: loss 0.0983
[2019-03-23 12:43:18,235] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8000, global step 128062: learning rate 0.0000
[2019-03-23 12:43:18,808] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8000, global step 128354: loss 0.0588
[2019-03-23 12:43:18,811] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8000, global step 128355: learning rate 0.0000
[2019-03-23 12:43:22,253] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.8057572e-09 3.2834466e-13 9.9999833e-01 2.9416029e-08 1.7194110e-06], sum to 1.0000
[2019-03-23 12:43:22,259] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8453
[2019-03-23 12:43:22,262] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.3929864939637223, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7877261923350397, 6.9112, 6.9112, 77.32846344354104, 895988.2204126912, 895988.2204126912, 215153.8585204522], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4878000.0000, 
sim time next is 4878600.0000, 
raw observation next is [21.0, 87.16666666666667, 1.0, 2.0, 0.419244652170265, 0.0, 2.0, 0.0, 1.0, 2.0, 0.840122401242911, 6.9112, 6.9112, 77.32846344354104, 955814.6050701792, 955814.6050701792, 224352.2660423413], 
processed observation next is [1.0, 0.4782608695652174, 0.5909090909090909, 0.8716666666666667, 1.0, 1.0, 0.27405581521283123, 0.0, 1.0, -0.25, 1.0, 1.0, 0.771603430347016, 0.0, 0.0, 0.5084288129206541, 0.35400540928525154, 0.35400540928525154, 0.5472006488837593], 
reward next is 0.4528, 
noisyNet noise sample is [array([-1.2861168], dtype=float32), 0.71281683]. 
=============================================
[2019-03-23 12:43:22,998] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.1822148e-10 1.3113146e-12 1.0000000e+00 1.0270236e-11 4.5246850e-08], sum to 1.0000
[2019-03-23 12:43:23,007] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4846
[2019-03-23 12:43:23,011] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.4350110861090413, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8704061730650787, 6.911199999999999, 6.9112, 77.32846344354104, 991205.7128068806, 991205.7128068808, 229378.0409099383], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4892400.0000, 
sim time next is 4893000.0000, 
raw observation next is [22.16666666666667, 77.16666666666667, 1.0, 2.0, 0.4315276420392946, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8634777212201091, 6.911200000000001, 6.9112, 77.32846344354104, 983280.0502847629, 983280.0502847625, 228092.5575422394], 
processed observation next is [1.0, 0.6521739130434783, 0.6439393939393941, 0.7716666666666667, 1.0, 1.0, 0.2894095525491182, 0.0, 1.0, -0.25, 1.0, 1.0, 0.8049681731715846, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.364177796401764, 0.3641777964017639, 0.5563233110786326], 
reward next is 0.4437, 
noisyNet noise sample is [array([0.9230677], dtype=float32), 0.50488687]. 
=============================================
[2019-03-23 12:43:23,033] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[61.65898 ]
 [61.606827]
 [61.52693 ]
 [61.436848]
 [61.32629 ]], R is [[61.6019249 ]
 [61.42644501]
 [61.24849701]
 [61.06826782]
 [60.88375854]].
[2019-03-23 12:43:24,781] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0117375e-03 1.0040273e-05 9.9577951e-01 5.5818359e-04 2.6404408e-03], sum to 1.0000
[2019-03-23 12:43:24,787] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4810
[2019-03-23 12:43:24,790] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.365134652352389, 6.9112, 6.9112, 77.32846344354104, 419403.20342704, 419403.20342704, 155993.8372650989], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4930200.0000, 
sim time next is 4930800.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3644493040406723, 6.9112, 6.9112, 77.32846344354104, 418617.5189899665, 418617.5189899665, 155905.3799356908], 
processed observation next is [1.0, 0.043478260869565216, 0.45454545454545453, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.09207043434381755, 0.0, 0.0, 0.5084288129206541, 0.15504352555183945, 0.15504352555183945, 0.38025702423339225], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.76353246], dtype=float32), -0.9643946]. 
=============================================
[2019-03-23 12:43:28,717] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.03221819 0.00396317 0.018406   0.86613065 0.07928201], sum to 1.0000
[2019-03-23 12:43:28,724] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6503
[2019-03-23 12:43:28,731] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.0, 73.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 301054.5368126691, 301054.5368126691, 126025.6122823231], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4996800.0000, 
sim time next is 4997400.0000, 
raw observation next is [17.83333333333333, 74.5, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 302352.9385858444, 302352.9385858444, 126712.0984222817], 
processed observation next is [1.0, 0.8695652173913043, 0.44696969696969674, 0.745, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11198256984660904, 0.11198256984660904, 0.30905389859093096], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.348162], dtype=float32), 0.49057728]. 
=============================================
[2019-03-23 12:43:29,379] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.5428788  0.04923429 0.03925687 0.29238057 0.07624955], sum to 1.0000
[2019-03-23 12:43:29,388] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9955
[2019-03-23 12:43:29,395] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [17.0, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5165930600435227, 6.9112, 6.9112, 77.32846344354104, 300479.3844592215, 300479.3844592215, 95715.61491381848], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5010600.0000, 
sim time next is 5011200.0000, 
raw observation next is [17.0, 82.0, 1.0, 1.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 299303.6236827039, 299303.6236827042, 156166.0088008125], 
processed observation next is [0.0, 0.0, 0.4090909090909091, 0.82, 1.0, 0.5, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.11085319395655699, 0.1108531939565571, 0.3808927043922256], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.04271268], dtype=float32), -0.5742462]. 
=============================================
[2019-03-23 12:43:29,994] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9977392e-01 1.1970296e-05 6.8883542e-06 1.9002867e-04 1.7141345e-05], sum to 1.0000
[2019-03-23 12:43:30,000] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4851
[2019-03-23 12:43:30,005] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.452022555212128, 6.9112, 6.9112, 77.32846344354104, 262911.4198469006, 262911.4198469006, 81911.26790037124], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5020200.0000, 
sim time next is 5020800.0000, 
raw observation next is [14.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.452579229099101, 6.9112, 6.9112, 77.32846344354104, 263235.2875975666, 263235.2875975666, 81918.02662444755], 
processed observation next is [0.0, 0.08695652173913043, 0.2727272727272727, 1.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.21797032728443, 0.0, 0.0, 0.5084288129206541, 0.09749455096206171, 0.09749455096206171, 0.19980006493767696], 
reward next is 0.8002, 
noisyNet noise sample is [array([0.091451], dtype=float32), -0.80093783]. 
=============================================
[2019-03-23 12:43:33,146] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.6620442e-09 2.5883051e-09 2.5140026e-09 2.5300644e-09], sum to 1.0000
[2019-03-23 12:43:33,158] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3646
[2019-03-23 12:43:33,162] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.33333333333333, 63.83333333333334, 1.0, 1.0, 0.2267475367574221, 1.0, 1.0, 0.2267475367574221, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32821884398375, 517065.7269383004, 517065.7269383004, 171877.6111451504], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5082600.0000, 
sim time next is 5083200.0000, 
raw observation next is [24.0, 65.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7651309475070681, 7.267409306169364, 6.9112, 77.32757576026094, 551190.9335866403, 435502.7647274899, 136240.1659043185], 
processed observation next is [0.0, 0.8695652173913043, 0.7272727272727273, 0.65, 0.0, 0.5, -0.25, 0.0, 0.5, -0.25, 1.0, 0.5, 0.6644727821529545, 0.03562093061693643, 0.0, 0.5084229764700607, 0.2041447902172742, 0.1612973202694407, 0.33229308757150855], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.14290524], dtype=float32), -0.47806934]. 
=============================================
[2019-03-23 12:43:33,683] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8500, global step 135853: loss -16.1697
[2019-03-23 12:43:33,685] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8500, global step 135853: learning rate 0.0000
[2019-03-23 12:43:33,707] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8500, global step 135864: loss -13.8963
[2019-03-23 12:43:33,709] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8500, global step 135864: learning rate 0.0000
[2019-03-23 12:43:33,754] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8500, global step 135882: loss -10.5493
[2019-03-23 12:43:33,758] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8500, global step 135883: learning rate 0.0000
[2019-03-23 12:43:33,777] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8500, global step 135896: loss -11.1331
[2019-03-23 12:43:33,779] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8500, global step 135896: learning rate 0.0000
[2019-03-23 12:43:33,855] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8500, global step 135935: loss 6.8936
[2019-03-23 12:43:33,856] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8500, global step 135935: learning rate 0.0000
[2019-03-23 12:43:33,863] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8500, global step 135941: loss 8.5158
[2019-03-23 12:43:33,865] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8500, global step 135941: learning rate 0.0000
[2019-03-23 12:43:33,870] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8500, global step 135944: loss -9.2678
[2019-03-23 12:43:33,871] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8500, global step 135944: learning rate 0.0000
[2019-03-23 12:43:33,940] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8500, global step 135971: loss -11.8064
[2019-03-23 12:43:33,941] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8500, global step 135971: learning rate 0.0000
[2019-03-23 12:43:33,955] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8500, global step 135980: loss -1.0032
[2019-03-23 12:43:33,958] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8500, global step 135982: learning rate 0.0000
[2019-03-23 12:43:33,985] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8500, global step 135994: loss -3.7785
[2019-03-23 12:43:33,987] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8500, global step 135995: learning rate 0.0000
[2019-03-23 12:43:34,065] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8500, global step 136036: loss 10.0003
[2019-03-23 12:43:34,068] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8500, global step 136038: loss 4.0002
[2019-03-23 12:43:34,069] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8500, global step 136036: learning rate 0.0000
[2019-03-23 12:43:34,072] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8500, global step 136039: learning rate 0.0000
[2019-03-23 12:43:34,079] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8500, global step 136041: loss 1.4728
[2019-03-23 12:43:34,081] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8500, global step 136042: learning rate 0.0000
[2019-03-23 12:43:34,082] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8500, global step 136042: loss 0.0961
[2019-03-23 12:43:34,086] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8500, global step 136042: learning rate 0.0000
[2019-03-23 12:43:34,221] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8500, global step 136111: loss -0.0745
[2019-03-23 12:43:34,222] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8500, global step 136111: learning rate 0.0000
[2019-03-23 12:43:34,327] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9977487e-01 3.2973978e-05 5.7228179e-05 5.9125428e-05 7.5801931e-05], sum to 1.0000
[2019-03-23 12:43:34,334] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4822
[2019-03-23 12:43:34,337] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 548251.4763594853 W.
[2019-03-23 12:43:34,345] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.66666666666667, 79.66666666666667, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7635374513076337, 7.259953712254745, 6.9112, 77.32759643699725, 548251.4763594853, 434984.673827499, 135777.3230385561], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5101800.0000, 
sim time next is 5102400.0000, 
raw observation next is [21.33333333333334, 81.33333333333334, 1.0, 1.0, 0.2199454391257088, 1.0, 1.0, 0.2199454391257088, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32825386600912, 500963.3709105662, 500963.3709105659, 169807.9769539428], 
processed observation next is [0.0, 0.043478260869565216, 0.6060606060606063, 0.8133333333333335, 1.0, 0.5, 0.024931798907135982, 1.0, 0.5, 0.024931798907135982, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084274349641937, 0.18554198922613563, 0.18554198922613552, 0.41416579744864096], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6688067], dtype=float32), -1.0381459]. 
=============================================
[2019-03-23 12:43:34,619] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8500, global step 136307: loss 11.0458
[2019-03-23 12:43:34,621] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8500, global step 136309: learning rate 0.0000
[2019-03-23 12:43:34,974] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.968406   0.00864584 0.00611634 0.01268265 0.0041493 ], sum to 1.0000
[2019-03-23 12:43:34,981] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8562
[2019-03-23 12:43:34,984] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.0, 83.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.750485591503414, 7.17127906968276, 6.9112, 77.32780060677696, 513290.345291073, 428822.70703289, 133336.2905572221], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5119200.0000, 
sim time next is 5119800.0000, 
raw observation next is [21.16666666666667, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7656768788047638, 7.302468558567161, 6.9112, 77.32732710064802, 565013.3819679237, 437939.2243553318, 134805.8329170545], 
processed observation next is [0.0, 0.2608695652173913, 0.5984848484848487, 0.83, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6652526840068055, 0.03912685585671607, 0.0, 0.5084213415518665, 0.20926421554367544, 0.16219971272419695, 0.3287947144318403], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.18227674], dtype=float32), -0.9891104]. 
=============================================
[2019-03-23 12:43:36,011] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.1970411e-03 4.2101008e-05 1.4719310e-04 9.9255639e-01 5.7210644e-05], sum to 1.0000
[2019-03-23 12:43:36,021] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4912
[2019-03-23 12:43:36,025] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.2570439991368926, 1.0, 2.0, 0.2570439991368926, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 583561.2426936085, 583561.2426936082, 182483.424403147], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5140800.0000, 
sim time next is 5141400.0000, 
raw observation next is [24.5, 80.83333333333334, 1.0, 2.0, 0.2600966156816544, 1.0, 2.0, 0.2600966156816544, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 589895.922885592, 589895.922885592, 183320.9532907979], 
processed observation next is [0.0, 0.5217391304347826, 0.75, 0.8083333333333335, 1.0, 1.0, 0.07512076960206795, 1.0, 1.0, 0.07512076960206795, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21847997143910813, 0.21847997143910813, 0.44712427631901924], 
reward next is 0.5529, 
noisyNet noise sample is [array([0.75112075], dtype=float32), 1.5646609]. 
=============================================
[2019-03-23 12:43:36,552] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7274131e-08 9.4711731e-06 7.6736178e-12 9.9999058e-01 2.7624257e-12], sum to 1.0000
[2019-03-23 12:43:36,560] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2174
[2019-03-23 12:43:36,562] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 66.0, 1.0, 2.0, 0.286327700316739, 1.0, 2.0, 0.286327700316739, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 643488.9393767784, 643488.9393767784, 189862.1280486541], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5148000.0000, 
sim time next is 5148600.0000, 
raw observation next is [28.0, 66.0, 1.0, 2.0, 0.2866756862459492, 1.0, 2.0, 0.2866756862459492, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 644271.5165632213, 644271.516563221, 189924.4966202076], 
processed observation next is [0.0, 0.6086956521739131, 0.9090909090909091, 0.66, 1.0, 1.0, 0.10834460780743647, 1.0, 1.0, 0.10834460780743647, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2386190802086005, 0.23861908020860037, 0.46323047956148194], 
reward next is 0.5368, 
noisyNet noise sample is [array([-1.3663998], dtype=float32), 0.9893304]. 
=============================================
[2019-03-23 12:43:38,609] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.4373730e-05 4.8604153e-07 1.9064808e-08 9.9996507e-01 9.7430544e-09], sum to 1.0000
[2019-03-23 12:43:38,616] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5594
[2019-03-23 12:43:38,620] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.2194841965531023, 1.0, 2.0, 0.2194841965531023, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 500764.4016974586, 500764.4016974586, 171643.4953644208], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5185800.0000, 
sim time next is 5186400.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.2190663131423294, 1.0, 2.0, 0.2190663131423294, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 499809.5134760256, 499809.5134760253, 171578.9619001298], 
processed observation next is [1.0, 0.0, 0.6363636363636364, 0.83, 1.0, 1.0, 0.02383289142791175, 1.0, 1.0, 0.02383289142791175, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18511463462075023, 0.18511463462075012, 0.4184852729271458], 
reward next is 0.5815, 
noisyNet noise sample is [array([0.06930137], dtype=float32), -0.43177286]. 
=============================================
[2019-03-23 12:43:40,105] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3252592e-05 1.1172195e-09 2.3197227e-08 9.9998677e-01 1.0040722e-09], sum to 1.0000
[2019-03-23 12:43:40,110] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5271
[2019-03-23 12:43:40,114] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 83.0, 1.0, 2.0, 0.2415134936061129, 1.0, 2.0, 0.2415134936061129, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 550836.2374234125, 550836.2374234125, 177400.7817285], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5212800.0000, 
sim time next is 5213400.0000, 
raw observation next is [22.66666666666667, 84.83333333333334, 1.0, 2.0, 0.2690226227179356, 1.0, 2.0, 0.2690226227179356, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 613521.5212096309, 613521.5212096306, 181985.0577203794], 
processed observation next is [1.0, 0.34782608695652173, 0.6666666666666669, 0.8483333333333334, 1.0, 1.0, 0.08627827839741947, 1.0, 1.0, 0.08627827839741947, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22723019304060402, 0.22723019304060393, 0.4438659944399498], 
reward next is 0.5561, 
noisyNet noise sample is [array([1.7014868], dtype=float32), 0.80460125]. 
=============================================
[2019-03-23 12:43:40,370] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.44453915e-02 4.47945212e-07 1.58129376e-06 9.85552490e-01
 4.75651341e-08], sum to 1.0000
[2019-03-23 12:43:40,378] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6478
[2019-03-23 12:43:40,381] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.66666666666667, 96.0, 1.0, 2.0, 0.4488653321340489, 1.0, 2.0, 0.4488653321340489, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1020489.679715423, 1020489.679715423, 219528.1397468487], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5226000.0000, 
sim time next is 5226600.0000, 
raw observation next is [21.83333333333334, 95.0, 1.0, 2.0, 0.4493436236877475, 1.0, 2.0, 0.4493436236877475, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1021304.297092761, 1021304.297092761, 219781.3850453121], 
processed observation next is [1.0, 0.4782608695652174, 0.628787878787879, 0.95, 1.0, 1.0, 0.3116795296096843, 1.0, 1.0, 0.3116795296096843, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3782608507750967, 0.3782608507750967, 0.5360521586471028], 
reward next is 0.4639, 
noisyNet noise sample is [array([0.5057917], dtype=float32), 0.43533957]. 
=============================================
[2019-03-23 12:43:41,859] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1349452e-02 2.1791584e-05 2.3737635e-05 9.7860491e-01 1.1204601e-07], sum to 1.0000
[2019-03-23 12:43:41,865] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8546
[2019-03-23 12:43:42,037] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.2522418009151665, 1.0, 2.0, 0.2522418009151665, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 574281.7908122662, 574281.7908122662, 180479.368390492], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5250000.0000, 
sim time next is 5250600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.2518499487255406, 1.0, 2.0, 0.2518499487255406, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 573392.8742929505, 573392.8742929503, 180412.4088291187], 
processed observation next is [1.0, 0.782608695652174, 0.6363636363636364, 0.94, 1.0, 1.0, 0.06481243590692576, 1.0, 1.0, 0.06481243590692576, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2123677312196113, 0.21236773121961122, 0.4400302654368749], 
reward next is 0.5600, 
noisyNet noise sample is [array([1.0121592], dtype=float32), 0.5947447]. 
=============================================
[2019-03-23 12:43:44,423] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.31185186 0.08689088 0.02409453 0.5555782  0.02158461], sum to 1.0000
[2019-03-23 12:43:44,438] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7088
[2019-03-23 12:43:44,445] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.05, 84.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 384225.0844092862, 384225.0844092862, 151173.1393307794], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5283000.0000, 
sim time next is 5283600.0000, 
raw observation next is [18.96666666666667, 86.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385471.2029143482, 385471.2029143482, 151714.562002481], 
processed observation next is [1.0, 0.13043478260869565, 0.4984848484848486, 0.86, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14276711219049934, 0.14276711219049934, 0.37003551707922194], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9728931], dtype=float32), 0.29931533]. 
=============================================
[2019-03-23 12:43:46,081] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.6617013e-05 3.0034356e-04 2.2936829e-06 9.9966025e-01 5.0760366e-07], sum to 1.0000
[2019-03-23 12:43:46,090] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0293
[2019-03-23 12:43:46,097] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.0, 51.0, 1.0, 2.0, 0.691132888055454, 1.0, 2.0, 0.691132888055454, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1554572.884972875, 1554572.884972875, 289003.1591061301], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5328000.0000, 
sim time next is 5328600.0000, 
raw observation next is [30.0, 51.0, 1.0, 2.0, 0.6859942637448275, 1.0, 2.0, 0.6859942637448275, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1542998.768071948, 1542998.768071948, 287405.3804211307], 
processed observation next is [1.0, 0.6956521739130435, 1.0, 0.51, 1.0, 1.0, 0.6074928296810344, 1.0, 1.0, 0.6074928296810344, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5714810252118326, 0.5714810252118326, 0.700988732734465], 
reward next is 0.2990, 
noisyNet noise sample is [array([-0.09694947], dtype=float32), -0.88524675]. 
=============================================
[2019-03-23 12:43:49,633] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9000, global step 143784: loss 3.6261
[2019-03-23 12:43:49,635] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9000, global step 143785: learning rate 0.0000
[2019-03-23 12:43:49,789] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9000, global step 143865: loss 4.4042
[2019-03-23 12:43:49,789] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9000, global step 143865: learning rate 0.0000
[2019-03-23 12:43:49,825] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9000, global step 143889: loss 3.5811
[2019-03-23 12:43:49,828] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9000, global step 143889: learning rate 0.0000
[2019-03-23 12:43:49,843] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9000, global step 143896: loss 3.8884
[2019-03-23 12:43:49,846] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9000, global step 143896: learning rate 0.0000
[2019-03-23 12:43:49,883] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9000, global step 143916: loss 3.4746
[2019-03-23 12:43:49,885] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9000, global step 143917: learning rate 0.0000
[2019-03-23 12:43:49,901] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9000, global step 143926: loss 3.0296
[2019-03-23 12:43:49,902] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9000, global step 143926: learning rate 0.0000
[2019-03-23 12:43:49,969] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9000, global step 143964: loss 1.9058
[2019-03-23 12:43:49,971] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9000, global step 143966: learning rate 0.0000
[2019-03-23 12:43:49,987] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9000, global step 143976: loss 1.7509
[2019-03-23 12:43:49,991] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9000, global step 143976: learning rate 0.0000
[2019-03-23 12:43:50,005] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9000, global step 143982: loss 1.6545
[2019-03-23 12:43:50,008] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9000, global step 143982: learning rate 0.0000
[2019-03-23 12:43:50,052] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9000, global step 144002: loss 0.9420
[2019-03-23 12:43:50,056] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9000, global step 144004: learning rate 0.0000
[2019-03-23 12:43:50,066] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9000, global step 144007: loss 1.0314
[2019-03-23 12:43:50,067] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9000, global step 144008: learning rate 0.0000
[2019-03-23 12:43:50,113] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9000, global step 144041: loss 0.7207
[2019-03-23 12:43:50,115] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9000, global step 144042: learning rate 0.0000
[2019-03-23 12:43:50,158] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9000, global step 144066: loss 0.3845
[2019-03-23 12:43:50,163] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9000, global step 144066: learning rate 0.0000
[2019-03-23 12:43:50,172] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9000, global step 144070: loss 0.2860
[2019-03-23 12:43:50,174] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9000, global step 144070: learning rate 0.0000
[2019-03-23 12:43:50,282] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9000, global step 144131: loss 0.0877
[2019-03-23 12:43:50,287] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9000, global step 144133: learning rate 0.0000
[2019-03-23 12:43:50,646] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9000, global step 144321: loss 0.2273
[2019-03-23 12:43:50,650] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9000, global step 144321: learning rate 0.0000
[2019-03-23 12:43:55,905] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4030188e-06 9.9998140e-01 1.3391892e-09 1.7212595e-05 3.1098504e-09], sum to 1.0000
[2019-03-23 12:43:55,909] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0799
[2019-03-23 12:43:55,919] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.48333333333333, 75.66666666666667, 1.0, 2.0, 0.4672160934704078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 532955.2300469268, 532955.2300469268, 136378.6349358762], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5521800.0000, 
sim time next is 5522400.0000, 
raw observation next is [23.3, 76.0, 1.0, 2.0, 0.4628867125822501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 527889.0401786108, 527889.0401786106, 135630.5000952321], 
processed observation next is [1.0, 0.9565217391304348, 0.6954545454545454, 0.76, 1.0, 1.0, 0.3286083907278126, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19551445932541142, 0.19551445932541134, 0.33080609779324904], 
reward next is 0.6692, 
noisyNet noise sample is [array([0.51609516], dtype=float32), 1.8500031]. 
=============================================
[2019-03-23 12:44:01,272] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 12:44:01,274] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:44:01,275] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:44:01,275] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:44:01,277] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:44:01,277] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:44:01,278] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:44:01,278] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:44:01,279] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:44:01,280] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:44:01,280] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:44:01,292] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run7
[2019-03-23 12:44:01,292] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run7
[2019-03-23 12:44:01,293] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run7
[2019-03-23 12:44:01,340] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run7
[2019-03-23 12:44:01,400] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run7
[2019-03-23 12:44:10,788] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01862605], dtype=float32), 0.05150757]
[2019-03-23 12:44:10,789] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.78160123333333, 76.76227622333334, 1.0, 2.0, 0.3966974949824988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 448685.1661773896, 448685.1661773893, 129828.5282159957]
[2019-03-23 12:44:10,790] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:44:10,793] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.9268156e-16 1.0000000e+00 1.8795770e-29 3.6192708e-14 5.1524465e-25], sampled 0.2065595695077892
[2019-03-23 12:44:11,261] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01862605], dtype=float32), 0.05150757]
[2019-03-23 12:44:11,264] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.33912954333334, 93.21615443833333, 1.0, 2.0, 0.5883458437381734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 661515.2838136022, 661515.2838136022, 161494.0479909519]
[2019-03-23 12:44:11,264] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:44:11,267] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.3657375e-16 1.0000000e+00 5.1861113e-31 6.6633964e-15 2.4609165e-26], sampled 0.03425461232803395
[2019-03-23 12:44:12,987] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01862605], dtype=float32), 0.05150757]
[2019-03-23 12:44:12,987] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.5, 77.33333333333333, 1.0, 2.0, 0.3274825563404455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 361448.1714459403, 361448.17144594, 119499.6496653482]
[2019-03-23 12:44:12,988] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:44:12,990] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.45379881e-16 1.00000000e+00 2.67452631e-30 1.35250265e-14
 9.97187422e-26], sampled 0.29617077244672607
[2019-03-23 12:44:20,901] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01862605], dtype=float32), 0.05150757]
[2019-03-23 12:44:20,901] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.68613039, 61.91376354000001, 1.0, 2.0, 0.3250855118079901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 352980.2983100625, 352980.2983100621, 105171.0261082248]
[2019-03-23 12:44:20,901] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:44:20,905] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.3858649e-15 1.0000000e+00 3.8444794e-29 4.7943068e-14 9.5314730e-25], sampled 0.7479115321989117
[2019-03-23 12:44:34,323] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01862605], dtype=float32), 0.05150757]
[2019-03-23 12:44:34,325] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.0, 73.33333333333333, 1.0, 2.0, 0.7533340857075265, 1.0, 2.0, 0.7533340857075265, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1694692.17736792, 1694692.17736792, 309064.1165383066]
[2019-03-23 12:44:34,326] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:44:34,328] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.1417797e-18 1.0000000e+00 3.3238255e-34 2.8542811e-16 4.6470318e-29], sampled 0.8157059869729163
[2019-03-23 12:44:34,329] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 1694692.17736792 W.
[2019-03-23 12:44:50,889] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01862605], dtype=float32), 0.05150757]
[2019-03-23 12:44:50,891] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.56723232666667, 97.09632699333334, 1.0, 2.0, 0.3733095762445872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 415532.3032842154, 415532.3032842154, 124397.523976387]
[2019-03-23 12:44:50,892] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:44:50,894] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.10041915e-16 1.00000000e+00 3.36779954e-31 5.38766741e-15
 1.71007834e-26], sampled 0.34969108461936915
[2019-03-23 12:45:12,516] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01862605], dtype=float32), 0.05150757]
[2019-03-23 12:45:12,518] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.8, 56.0, 1.0, 2.0, 0.3272095403871225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 361237.9103423882, 361237.9103423885, 115198.8531771609]
[2019-03-23 12:45:12,519] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:45:12,521] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.5426310e-15 1.0000000e+00 2.5298566e-28 1.2170308e-13 4.6772596e-24], sampled 0.608167719158286
[2019-03-23 12:45:38,281] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01862605], dtype=float32), 0.05150757]
[2019-03-23 12:45:38,283] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [13.8, 90.0, 1.0, 2.0, 0.3692528221520861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 72.30625622547572, 400996.5116328195, 400996.5116328197, 87915.09646882376]
[2019-03-23 12:45:38,285] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:45:38,287] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.5198017e-16 1.0000000e+00 4.4209342e-30 1.7135563e-14 1.5286831e-25], sampled 0.5613544615659557
[2019-03-23 12:45:40,115] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 12:45:40,314] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-23 12:45:40,338] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 12:45:40,398] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 12:45:40,402] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 12:45:41,418] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 150000, evaluation results [150000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 12:45:44,814] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9500, global step 151704: loss 3.6046
[2019-03-23 12:45:44,816] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9500, global step 151704: learning rate 0.0000
[2019-03-23 12:45:44,982] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9500, global step 151789: loss 3.4704
[2019-03-23 12:45:44,984] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9500, global step 151789: learning rate 0.0000
[2019-03-23 12:45:45,081] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9500, global step 151844: loss 3.4132
[2019-03-23 12:45:45,086] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9500, global step 151844: learning rate 0.0000
[2019-03-23 12:45:45,125] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9500, global step 151861: loss 3.0716
[2019-03-23 12:45:45,126] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9500, global step 151861: learning rate 0.0000
[2019-03-23 12:45:45,230] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9500, global step 151919: loss 2.1646
[2019-03-23 12:45:45,232] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9500, global step 151919: learning rate 0.0000
[2019-03-23 12:45:45,240] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.8775056e-08 9.9998677e-01 8.0778158e-14 1.3175732e-05 3.0433117e-10], sum to 1.0000
[2019-03-23 12:45:45,250] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3166
[2019-03-23 12:45:45,258] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9500, global step 151930: loss 1.9699
[2019-03-23 12:45:45,258] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.1, 77.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 182174.8174775832, 182174.8174775835, 62696.7142151537], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5695800.0000, 
sim time next is 5696400.0000, 
raw observation next is [12.0, 78.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 180449.6676127078, 180449.6676127081, 62375.00319456595], 
processed observation next is [0.0, 0.9565217391304348, 0.18181818181818182, 0.78, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.06683321022692881, 0.06683321022692892, 0.15213415413308767], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.16587831], dtype=float32), -0.58958465]. 
=============================================
[2019-03-23 12:45:45,263] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9500, global step 151931: learning rate 0.0000
[2019-03-23 12:45:45,352] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9500, global step 151976: loss 1.2596
[2019-03-23 12:45:45,353] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9500, global step 151976: learning rate 0.0000
[2019-03-23 12:45:45,366] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9500, global step 151983: loss 1.3735
[2019-03-23 12:45:45,367] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9500, global step 151984: learning rate 0.0000
[2019-03-23 12:45:45,426] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9500, global step 152014: loss 1.0932
[2019-03-23 12:45:45,430] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9500, global step 152015: loss 0.8543
[2019-03-23 12:45:45,431] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9500, global step 152015: learning rate 0.0000
[2019-03-23 12:45:45,436] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9500, global step 152015: learning rate 0.0000
[2019-03-23 12:45:45,460] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9500, global step 152024: loss 0.8251
[2019-03-23 12:45:45,462] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9500, global step 152025: learning rate 0.0000
[2019-03-23 12:45:45,494] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9500, global step 152045: loss 0.7120
[2019-03-23 12:45:45,496] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9500, global step 152046: learning rate 0.0000
[2019-03-23 12:45:45,568] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9500, global step 152085: loss 0.5100
[2019-03-23 12:45:45,570] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9500, global step 152085: learning rate 0.0000
[2019-03-23 12:45:45,605] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9500, global step 152101: loss 0.3799
[2019-03-23 12:45:45,607] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9500, global step 152102: learning rate 0.0000
[2019-03-23 12:45:45,699] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9500, global step 152152: loss 0.2444
[2019-03-23 12:45:45,701] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9500, global step 152153: learning rate 0.0000
[2019-03-23 12:45:46,146] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9500, global step 152380: loss 2.8539
[2019-03-23 12:45:46,148] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9500, global step 152380: learning rate 0.0000
[2019-03-23 12:45:47,903] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 2.2978383e-14 2.4829093e-16 6.5884256e-16 3.8971877e-17], sum to 1.0000
[2019-03-23 12:45:47,911] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8911
[2019-03-23 12:45:47,918] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.76666666666667, 44.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4462664554365366, 6.911199999999999, 6.9112, 77.32846344354104, 259562.586550296, 259562.5865502963, 73800.92526958745], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5746800.0000, 
sim time next is 5747400.0000, 
raw observation next is [19.95, 44.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4505505627427748, 6.911199999999999, 6.9112, 77.32846344354104, 262055.0291975829, 262055.0291975832, 74779.59242232407], 
processed observation next is [0.0, 0.5217391304347826, 0.5431818181818181, 0.445, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.21507223248967827, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09705741822132699, 0.09705741822132712, 0.18238924981054652], 
reward next is 0.8176, 
noisyNet noise sample is [array([-2.1955414], dtype=float32), 2.0393085]. 
=============================================
[2019-03-23 12:45:53,880] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.320205e-09 1.000000e+00 6.469205e-24 4.338263e-11 8.554280e-21], sum to 1.0000
[2019-03-23 12:45:53,887] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2926
[2019-03-23 12:45:53,892] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 60.00000000000001, 1.0, 2.0, 0.3296481028228636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 364370.1353196029, 364370.1353196029, 115552.4081669511], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5865600.0000, 
sim time next is 5866200.0000, 
raw observation next is [21.9, 61.5, 1.0, 2.0, 0.3297373877797154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 364379.8245524464, 364379.8245524464, 115523.8874297819], 
processed observation next is [1.0, 0.9130434782608695, 0.6318181818181817, 0.615, 1.0, 1.0, 0.16217173472464422, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13495549057498013, 0.13495549057498013, 0.28176557909702904], 
reward next is 0.7182, 
noisyNet noise sample is [array([-0.23987673], dtype=float32), -0.32612866]. 
=============================================
[2019-03-23 12:45:55,903] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.6837094e-11 1.0000000e+00 1.9682861e-28 1.0338896e-17 5.9037408e-28], sum to 1.0000
[2019-03-23 12:45:55,912] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6327
[2019-03-23 12:45:55,917] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 78.0, 1.0, 2.0, 0.2751438139095884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 298757.2491657132, 298757.2491657132, 103332.1416403499], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5902200.0000, 
sim time next is 5902800.0000, 
raw observation next is [18.26666666666667, 77.33333333333334, 1.0, 2.0, 0.2832275259413657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 307537.4981042835, 307537.4981042838, 108018.1155877664], 
processed observation next is [1.0, 0.30434782608695654, 0.4666666666666668, 0.7733333333333334, 1.0, 1.0, 0.1040344074267071, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11390277707566057, 0.11390277707566067, 0.2634588185067473], 
reward next is 0.7365, 
noisyNet noise sample is [array([1.2878772], dtype=float32), 0.088602826]. 
=============================================
[2019-03-23 12:45:58,613] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7111576e-01 8.2885855e-01 4.0886187e-15 2.5668878e-05 1.0277674e-13], sum to 1.0000
[2019-03-23 12:45:58,621] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9548
[2019-03-23 12:45:58,627] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.06666666666667, 57.33333333333334, 1.0, 2.0, 0.4067203703460666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 461183.4290302964, 461183.4290302964, 127175.288127945], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5944800.0000, 
sim time next is 5945400.0000, 
raw observation next is [24.85, 58.0, 1.0, 2.0, 0.4058488564135007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 459924.7725698106, 459924.7725698106, 126907.3821559885], 
processed observation next is [1.0, 0.8260869565217391, 0.765909090909091, 0.58, 1.0, 1.0, 0.25731107051687585, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17034250835918913, 0.17034250835918913, 0.30953020038045975], 
reward next is 0.6905, 
noisyNet noise sample is [array([0.97244817], dtype=float32), 0.6638771]. 
=============================================
[2019-03-23 12:46:00,788] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10000, global step 159781: loss 1.5628
[2019-03-23 12:46:00,789] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10000, global step 159781: learning rate 0.0000
[2019-03-23 12:46:00,857] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10000, global step 159821: loss 3.1082
[2019-03-23 12:46:00,861] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10000, global step 159822: learning rate 0.0000
[2019-03-23 12:46:00,868] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10000, global step 159824: loss 3.6442
[2019-03-23 12:46:00,870] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10000, global step 159824: learning rate 0.0000
[2019-03-23 12:46:00,914] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10000, global step 159848: loss 4.2370
[2019-03-23 12:46:00,918] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10000, global step 159850: learning rate 0.0000
[2019-03-23 12:46:00,968] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10000, global step 159875: loss 3.9050
[2019-03-23 12:46:00,970] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10000, global step 159875: learning rate 0.0000
[2019-03-23 12:46:01,016] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.0849043e-07 9.9999833e-01 2.4393854e-20 1.3532400e-06 5.6991364e-19], sum to 1.0000
[2019-03-23 12:46:01,025] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1708
[2019-03-23 12:46:01,030] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.88333333333334, 70.16666666666667, 1.0, 2.0, 0.8066620956301606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 908669.5095606619, 908669.5095606619, 172111.9295485898], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5994600.0000, 
sim time next is 5995200.0000, 
raw observation next is [22.16666666666667, 69.33333333333334, 1.0, 2.0, 0.8210308949896408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 926386.3388723459, 926386.3388723456, 174983.2539286408], 
processed observation next is [1.0, 0.391304347826087, 0.6439393939393941, 0.6933333333333335, 1.0, 1.0, 0.776288618737051, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3431060514342022, 0.3431060514342021, 0.42678842421619706], 
reward next is 0.5732, 
noisyNet noise sample is [array([1.2045048], dtype=float32), -0.4188014]. 
=============================================
[2019-03-23 12:46:01,091] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10000, global step 159937: loss 1.4330
[2019-03-23 12:46:01,094] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10000, global step 159939: learning rate 0.0000
[2019-03-23 12:46:01,111] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10000, global step 159947: loss 0.6745
[2019-03-23 12:46:01,116] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10000, global step 159947: learning rate 0.0000
[2019-03-23 12:46:01,129] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10000, global step 159955: loss 0.5943
[2019-03-23 12:46:01,133] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10000, global step 159955: learning rate 0.0000
[2019-03-23 12:46:01,149] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10000, global step 159961: loss 0.3794
[2019-03-23 12:46:01,153] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10000, global step 159961: learning rate 0.0000
[2019-03-23 12:46:01,187] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10000, global step 159978: loss 0.3347
[2019-03-23 12:46:01,190] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10000, global step 159979: learning rate 0.0000
[2019-03-23 12:46:01,249] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10000, global step 160013: loss 0.1156
[2019-03-23 12:46:01,252] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10000, global step 160014: learning rate 0.0000
[2019-03-23 12:46:01,256] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10000, global step 160016: loss 0.1108
[2019-03-23 12:46:01,260] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10000, global step 160016: learning rate 0.0000
[2019-03-23 12:46:01,302] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10000, global step 160039: loss 0.1223
[2019-03-23 12:46:01,303] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10000, global step 160039: learning rate 0.0000
[2019-03-23 12:46:01,475] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10000, global step 160126: loss 0.0101
[2019-03-23 12:46:01,476] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10000, global step 160126: learning rate 0.0000
[2019-03-23 12:46:01,495] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8965674e-04 9.9979657e-01 6.1555341e-14 1.3855557e-05 5.4062982e-13], sum to 1.0000
[2019-03-23 12:46:01,504] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9849
[2019-03-23 12:46:01,505] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10000, global step 160134: loss 0.0078
[2019-03-23 12:46:01,510] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.43333333333334, 55.33333333333334, 1.0, 2.0, 0.7316154195831944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354095, 834050.4917749169, 834050.4917749169, 168781.1439875137], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6006000.0000, 
sim time next is 6006600.0000, 
raw observation next is [26.35, 56.0, 1.0, 2.0, 0.711656363805849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 811318.5832164874, 811318.5832164877, 165978.254364327], 
processed observation next is [1.0, 0.5217391304347826, 0.8340909090909091, 0.56, 1.0, 1.0, 0.6395704547573111, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3004883641542546, 0.3004883641542547, 0.4048250106447], 
reward next is 0.5952, 
noisyNet noise sample is [array([1.4620585], dtype=float32), -0.6647204]. 
=============================================
[2019-03-23 12:46:01,511] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10000, global step 160134: learning rate 0.0000
[2019-03-23 12:46:02,058] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10000, global step 160420: loss 0.5370
[2019-03-23 12:46:02,060] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10000, global step 160420: learning rate 0.0000
[2019-03-23 12:46:05,213] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.7322918e-10 1.0000000e+00 3.8157472e-33 4.8811376e-12 2.5892491e-27], sum to 1.0000
[2019-03-23 12:46:05,221] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2836
[2019-03-23 12:46:05,227] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.5, 82.5, 1.0, 2.0, 0.2032362632890489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 220660.7256857864, 220660.7256857861, 73208.24455742814], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6070200.0000, 
sim time next is 6070800.0000, 
raw observation next is [14.6, 82.0, 1.0, 2.0, 0.2020694930058368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 219393.636648974, 219393.6366489737, 73224.94529636674], 
processed observation next is [1.0, 0.2608695652173913, 0.3, 0.82, 1.0, 1.0, 0.0025868662572959764, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08125690246258296, 0.08125690246258285, 0.178597427552114], 
reward next is 0.8214, 
noisyNet noise sample is [array([-0.8086208], dtype=float32), -1.2606225]. 
=============================================
[2019-03-23 12:46:05,294] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.1181663e-06 9.9999785e-01 8.5685859e-24 4.0681570e-08 5.1162123e-21], sum to 1.0000
[2019-03-23 12:46:05,299] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2483
[2019-03-23 12:46:05,303] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.06666666666667, 74.66666666666667, 1.0, 2.0, 0.2244057218486411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 243650.9047374635, 243650.9047374635, 77441.49270844988], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6075600.0000, 
sim time next is 6076200.0000, 
raw observation next is [16.33333333333334, 73.33333333333333, 1.0, 2.0, 0.2269563209088796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 246420.9463877398, 246420.9463877395, 78096.67774736996], 
processed observation next is [1.0, 0.30434782608695654, 0.37878787878787906, 0.7333333333333333, 1.0, 1.0, 0.033695401136099486, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09126701718064437, 0.09126701718064426, 0.19047970182285356], 
reward next is 0.8095, 
noisyNet noise sample is [array([-0.23777914], dtype=float32), -0.06600335]. 
=============================================
[2019-03-23 12:46:13,992] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.2933079e-05 9.9993825e-01 3.2229064e-15 8.8667321e-06 4.3650545e-14], sum to 1.0000
[2019-03-23 12:46:14,002] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7180
[2019-03-23 12:46:14,006] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.85, 90.0, 1.0, 2.0, 0.3589764873803846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 401500.2477695443, 401500.2477695443, 119758.2231646215], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6244200.0000, 
sim time next is 6244800.0000, 
raw observation next is [19.03333333333333, 89.0, 1.0, 2.0, 0.3608171150417742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 403893.6750994094, 403893.6750994091, 120063.3582169383], 
processed observation next is [0.0, 0.2608695652173913, 0.5015151515151515, 0.89, 1.0, 1.0, 0.20102139380221776, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1495902500368183, 0.1495902500368182, 0.2928374590657032], 
reward next is 0.7072, 
noisyNet noise sample is [array([1.3993276], dtype=float32), 1.06728]. 
=============================================
[2019-03-23 12:46:16,652] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10500, global step 167788: loss 0.0275
[2019-03-23 12:46:16,655] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10500, global step 167788: learning rate 0.0000
[2019-03-23 12:46:16,786] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10500, global step 167857: loss 0.2365
[2019-03-23 12:46:16,788] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10500, global step 167857: learning rate 0.0000
[2019-03-23 12:46:16,797] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10500, global step 167862: loss 0.4067
[2019-03-23 12:46:16,799] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10500, global step 167862: learning rate 0.0000
[2019-03-23 12:46:16,844] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10500, global step 167884: loss 0.3409
[2019-03-23 12:46:16,847] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10500, global step 167884: learning rate 0.0000
[2019-03-23 12:46:16,873] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10500, global step 167897: loss 0.3475
[2019-03-23 12:46:16,875] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10500, global step 167897: learning rate 0.0000
[2019-03-23 12:46:16,916] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10500, global step 167921: loss 0.1359
[2019-03-23 12:46:16,918] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10500, global step 167922: learning rate 0.0000
[2019-03-23 12:46:16,942] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10500, global step 167933: loss 0.0085
[2019-03-23 12:46:16,943] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10500, global step 167934: learning rate 0.0000
[2019-03-23 12:46:17,002] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10500, global step 167961: loss 0.0248
[2019-03-23 12:46:17,004] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10500, global step 167961: learning rate 0.0000
[2019-03-23 12:46:17,047] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10500, global step 167984: loss 0.1570
[2019-03-23 12:46:17,049] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10500, global step 167984: learning rate 0.0000
[2019-03-23 12:46:17,066] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10500, global step 167996: loss 0.1651
[2019-03-23 12:46:17,067] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10500, global step 167996: learning rate 0.0000
[2019-03-23 12:46:17,136] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10500, global step 168031: loss 0.5311
[2019-03-23 12:46:17,141] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10500, global step 168031: learning rate 0.0000
[2019-03-23 12:46:17,158] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10500, global step 168042: loss 0.5361
[2019-03-23 12:46:17,161] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10500, global step 168042: learning rate 0.0000
[2019-03-23 12:46:17,211] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10500, global step 168067: loss 0.1249
[2019-03-23 12:46:17,216] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10500, global step 168067: learning rate 0.0000
[2019-03-23 12:46:17,231] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10500, global step 168075: loss 0.0578
[2019-03-23 12:46:17,234] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10500, global step 168076: learning rate 0.0000
[2019-03-23 12:46:17,306] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10500, global step 168120: loss 0.0349
[2019-03-23 12:46:17,314] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10500, global step 168123: learning rate 0.0000
[2019-03-23 12:46:17,917] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10500, global step 168399: loss 0.0113
[2019-03-23 12:46:17,919] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10500, global step 168400: learning rate 0.0000
[2019-03-23 12:46:19,889] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1537813e-09 1.0000000e+00 5.5624763e-19 6.3577796e-09 5.4128094e-19], sum to 1.0000
[2019-03-23 12:46:19,896] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0776
[2019-03-23 12:46:19,903] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.28333333333333, 66.66666666666667, 1.0, 2.0, 0.5522087845604828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 626359.9015990634, 626359.9015990634, 150794.4714093819], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6354600.0000, 
sim time next is 6355200.0000, 
raw observation next is [27.36666666666667, 66.33333333333334, 1.0, 2.0, 0.5539903120637266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 628285.1024123046, 628285.102412305, 151063.382587102], 
processed observation next is [0.0, 0.5652173913043478, 0.8803030303030305, 0.6633333333333334, 1.0, 1.0, 0.4424878900796582, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23269818607863132, 0.23269818607863146, 0.36844727460268784], 
reward next is 0.6316, 
noisyNet noise sample is [array([0.8194585], dtype=float32), 1.1276137]. 
=============================================
[2019-03-23 12:46:19,952] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2016051e-07 9.9999845e-01 2.8138840e-18 1.4718170e-06 3.6999132e-16], sum to 1.0000
[2019-03-23 12:46:19,958] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2530
[2019-03-23 12:46:19,966] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.65, 69.0, 1.0, 2.0, 0.5362818525853771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 609166.5270358057, 609166.5270358057, 148367.6981107929], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6348600.0000, 
sim time next is 6349200.0000, 
raw observation next is [26.83333333333334, 68.33333333333333, 1.0, 2.0, 0.5390747731570722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 612097.7350352504, 612097.7350352504, 148835.205609796], 
processed observation next is [0.0, 0.4782608695652174, 0.8560606060606063, 0.6833333333333332, 1.0, 1.0, 0.4238434664463402, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22670286482787053, 0.22670286482787053, 0.3630126966092585], 
reward next is 0.6370, 
noisyNet noise sample is [array([1.5608445], dtype=float32), -0.809557]. 
=============================================
[2019-03-23 12:46:27,042] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5104694e-06 9.9999845e-01 1.1051796e-16 3.6135646e-08 3.8943174e-15], sum to 1.0000
[2019-03-23 12:46:27,049] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9458
[2019-03-23 12:46:27,054] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.53333333333333, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 198781.0933413665, 198781.0933413662, 66930.38142599553], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6499200.0000, 
sim time next is 6499800.0000, 
raw observation next is [12.45, 87.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 196906.5847526818, 196906.5847526821, 66551.69609715507], 
processed observation next is [1.0, 0.21739130434782608, 0.20227272727272724, 0.875, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07292836472321548, 0.0729283647232156, 0.16232120999306116], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.91691], dtype=float32), -0.111686364]. 
=============================================
[2019-03-23 12:46:30,368] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 12:46:30,370] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:46:30,370] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:46:30,371] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:46:30,372] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:46:30,371] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:46:30,373] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:46:30,373] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:46:30,372] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:46:30,380] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:46:30,381] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:46:30,389] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run8
[2019-03-23 12:46:30,390] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run8
[2019-03-23 12:46:30,390] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run8
[2019-03-23 12:46:30,457] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run8
[2019-03-23 12:46:30,459] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run8
[2019-03-23 12:46:55,969] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01822182], dtype=float32), 0.06766765]
[2019-03-23 12:46:55,970] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.41627639833333, 73.31106174333334, 1.0, 2.0, 0.4230600252582913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 463385.510385523, 463385.5103855226, 125888.4604211245]
[2019-03-23 12:46:55,970] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:46:55,975] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.0586388e-09 1.0000000e+00 2.9054331e-21 1.3993619e-10 4.5172607e-19], sampled 0.7077648871768407
[2019-03-23 12:47:28,340] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01822182], dtype=float32), 0.06766765]
[2019-03-23 12:47:28,341] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.882871205, 98.29708848333334, 1.0, 2.0, 0.5012533101145018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 571914.9963013226, 571914.9963013226, 145585.9300436894]
[2019-03-23 12:47:28,342] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:47:28,346] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.3098877e-10 1.0000000e+00 4.7957297e-23 1.9642827e-11 1.1401873e-20], sampled 0.21616111225283097
[2019-03-23 12:47:41,742] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01822182], dtype=float32), 0.06766765]
[2019-03-23 12:47:41,743] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.7, 81.0, 1.0, 2.0, 0.2941101869265628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 319358.1191323, 319358.1191323003, 106759.4901434247]
[2019-03-23 12:47:41,744] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:47:41,749] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.0655652e-09 1.0000000e+00 2.8664837e-21 1.3829164e-10 4.4598673e-19], sampled 0.2863166427116659
[2019-03-23 12:48:09,214] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-23 12:48:09,273] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 12:48:09,674] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-23 12:48:09,681] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-23 12:48:09,774] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 12:48:10,790] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 175000, evaluation results [175000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 12:48:11,136] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1331311e-15 1.0000000e+00 1.4271215e-30 1.4097789e-16 4.5364900e-30], sum to 1.0000
[2019-03-23 12:48:11,137] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8519
[2019-03-23 12:48:11,145] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.91666666666667, 69.16666666666667, 1.0, 2.0, 0.2215368834958259, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 240535.2627036156, 240535.2627036159, 74692.8609780747], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6565800.0000, 
sim time next is 6566400.0000, 
raw observation next is [16.1, 67.0, 1.0, 2.0, 0.2231469456511012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 242283.8346555578, 242283.8346555578, 74625.44941716586], 
processed observation next is [1.0, 0.0, 0.3681818181818182, 0.67, 1.0, 1.0, 0.02893368206387647, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08973475357613252, 0.08973475357613252, 0.18201329126138013], 
reward next is 0.8180, 
noisyNet noise sample is [array([1.2494296], dtype=float32), 1.3836491]. 
=============================================
[2019-03-23 12:48:12,247] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11000, global step 175729: loss 4.4193
[2019-03-23 12:48:12,250] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11000, global step 175729: learning rate 0.0000
[2019-03-23 12:48:12,330] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11000, global step 175773: loss 4.6557
[2019-03-23 12:48:12,332] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11000, global step 175773: learning rate 0.0000
[2019-03-23 12:48:12,471] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11000, global step 175846: loss 4.7526
[2019-03-23 12:48:12,474] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11000, global step 175847: learning rate 0.0000
[2019-03-23 12:48:12,501] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11000, global step 175857: loss 4.7123
[2019-03-23 12:48:12,504] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11000, global step 175858: learning rate 0.0000
[2019-03-23 12:48:12,519] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11000, global step 175867: loss 4.5220
[2019-03-23 12:48:12,523] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11000, global step 175867: learning rate 0.0000
[2019-03-23 12:48:12,580] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11000, global step 175896: loss 4.4605
[2019-03-23 12:48:12,583] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11000, global step 175896: learning rate 0.0000
[2019-03-23 12:48:12,682] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11000, global step 175951: loss 4.3779
[2019-03-23 12:48:12,685] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11000, global step 175952: learning rate 0.0000
[2019-03-23 12:48:12,709] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11000, global step 175961: loss 4.1004
[2019-03-23 12:48:12,712] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11000, global step 175965: learning rate 0.0000
[2019-03-23 12:48:12,846] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11000, global step 176027: loss 3.6826
[2019-03-23 12:48:12,849] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11000, global step 176030: learning rate 0.0000
[2019-03-23 12:48:12,858] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11000, global step 176034: loss 3.3374
[2019-03-23 12:48:12,859] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11000, global step 176034: learning rate 0.0000
[2019-03-23 12:48:12,916] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11000, global step 176065: loss 3.2628
[2019-03-23 12:48:12,921] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11000, global step 176066: learning rate 0.0000
[2019-03-23 12:48:12,935] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11000, global step 176072: loss 2.9907
[2019-03-23 12:48:12,936] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11000, global step 176072: loss 2.9213
[2019-03-23 12:48:12,937] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11000, global step 176072: learning rate 0.0000
[2019-03-23 12:48:12,938] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11000, global step 176072: learning rate 0.0000
[2019-03-23 12:48:12,949] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11000, global step 176078: loss 2.7959
[2019-03-23 12:48:12,951] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11000, global step 176078: learning rate 0.0000
[2019-03-23 12:48:13,049] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11000, global step 176128: loss 2.3827
[2019-03-23 12:48:13,050] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11000, global step 176128: learning rate 0.0000
[2019-03-23 12:48:13,685] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11000, global step 176456: loss 0.2292
[2019-03-23 12:48:13,687] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11000, global step 176456: learning rate 0.0000
[2019-03-23 12:48:15,999] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.6165070e-07 9.9999988e-01 8.6228417e-23 3.5375773e-09 2.3977187e-18], sum to 1.0000
[2019-03-23 12:48:16,006] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0466
[2019-03-23 12:48:16,011] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 90.0, 1.0, 2.0, 0.3572789335560831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 399442.4561680166, 399442.4561680168, 119546.5831918114], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6658200.0000, 
sim time next is 6658800.0000, 
raw observation next is [18.8, 90.0, 1.0, 2.0, 0.3569115091411957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 399030.1448656624, 399030.1448656621, 119515.9474486197], 
processed observation next is [1.0, 0.043478260869565216, 0.49090909090909096, 0.9, 1.0, 1.0, 0.1961393864264946, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14778894254283792, 0.1477889425428378, 0.29150231085029193], 
reward next is 0.7085, 
noisyNet noise sample is [array([0.75006914], dtype=float32), 0.1711392]. 
=============================================
[2019-03-23 12:48:18,171] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.2998511e-10 1.0000000e+00 5.1605340e-24 6.4360392e-12 9.9047813e-24], sum to 1.0000
[2019-03-23 12:48:18,183] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3307
[2019-03-23 12:48:18,187] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.5998728101662401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 670795.9312112244, 670795.9312112242, 143098.7862845652], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6704400.0000, 
sim time next is 6705000.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.5894649206620893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 659056.4594391147, 659056.4594391147, 141894.7753460071], 
processed observation next is [1.0, 0.6086956521739131, 0.4681818181818182, 0.93, 1.0, 1.0, 0.48683115082761164, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24409498497744989, 0.24409498497744989, 0.3460848179170905], 
reward next is 0.6539, 
noisyNet noise sample is [array([-0.59287083], dtype=float32), -1.1756812]. 
=============================================
[2019-03-23 12:48:18,212] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[77.84135]
 [77.75077]
 [77.6003 ]
 [77.53478]
 [77.38328]], R is [[77.76386261]
 [77.6371994 ]
 [77.49865723]
 [77.37795258]
 [77.26437378]].
[2019-03-23 12:48:19,599] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7567796e-11 1.0000000e+00 2.4806787e-28 3.0929551e-16 7.1076194e-28], sum to 1.0000
[2019-03-23 12:48:19,607] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2760
[2019-03-23 12:48:19,615] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3587634829212312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 399440.0396319373, 399440.0396319376, 118939.185961492], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6726000.0000, 
sim time next is 6726600.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.3569796341583877, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 397446.7611131909, 397446.7611131906, 118793.0385180784], 
processed observation next is [1.0, 0.8695652173913043, 0.44090909090909086, 0.97, 1.0, 1.0, 0.1962245426979846, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14720250411599664, 0.14720250411599653, 0.2897391183367766], 
reward next is 0.7103, 
noisyNet noise sample is [array([-0.49409235], dtype=float32), -0.71954584]. 
=============================================
[2019-03-23 12:48:23,117] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.8619921e-06 9.9999011e-01 2.1195234e-16 4.8501372e-09 1.5171377e-16], sum to 1.0000
[2019-03-23 12:48:23,124] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1038
[2019-03-23 12:48:23,129] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.41666666666666, 60.33333333333333, 1.0, 2.0, 0.9322993131178431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344353972, 1063035.149055566, 1063035.149055566, 200626.8607424189], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6792600.0000, 
sim time next is 6793200.0000, 
raw observation next is [25.5, 60.0, 1.0, 2.0, 0.9334774290440114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1064471.649029339, 1064471.649029339, 200964.3339154349], 
processed observation next is [1.0, 0.6521739130434783, 0.7954545454545454, 0.6, 1.0, 1.0, 0.9168467863050141, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3942487588997552, 0.3942487588997552, 0.4901569119888656], 
reward next is 0.5098, 
noisyNet noise sample is [array([-1.0055089], dtype=float32), -0.3046593]. 
=============================================
[2019-03-23 12:48:24,541] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.3354684e-11 1.0000000e+00 6.6338341e-27 1.6504409e-13 1.3753938e-24], sum to 1.0000
[2019-03-23 12:48:24,548] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5215
[2019-03-23 12:48:24,553] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.51666666666667, 71.83333333333334, 1.0, 2.0, 0.4075708034054413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 461729.7404420506, 461729.7404420506, 126971.0044281856], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6819000.0000, 
sim time next is 6819600.0000, 
raw observation next is [22.33333333333334, 72.66666666666667, 1.0, 2.0, 0.4081353229611981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 462186.9833881573, 462186.9833881573, 126904.567516271], 
processed observation next is [1.0, 0.9565217391304348, 0.6515151515151518, 0.7266666666666667, 1.0, 1.0, 0.26016915370149757, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17118036421783606, 0.17118036421783606, 0.309523335405539], 
reward next is 0.6905, 
noisyNet noise sample is [array([0.0631084], dtype=float32), -0.22579761]. 
=============================================
[2019-03-23 12:48:28,067] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11500, global step 183688: loss 0.0022
[2019-03-23 12:48:28,069] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11500, global step 183688: learning rate 0.0000
[2019-03-23 12:48:28,230] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11500, global step 183772: loss 0.3737
[2019-03-23 12:48:28,234] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11500, global step 183773: learning rate 0.0000
[2019-03-23 12:48:28,262] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11500, global step 183786: loss 0.1587
[2019-03-23 12:48:28,263] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11500, global step 183786: learning rate 0.0000
[2019-03-23 12:48:28,361] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11500, global step 183841: loss 0.0373
[2019-03-23 12:48:28,363] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11500, global step 183842: learning rate 0.0000
[2019-03-23 12:48:28,396] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11500, global step 183853: loss 0.0466
[2019-03-23 12:48:28,399] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11500, global step 183853: learning rate 0.0000
[2019-03-23 12:48:28,549] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11500, global step 183932: loss 0.1900
[2019-03-23 12:48:28,551] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11500, global step 183933: learning rate 0.0000
[2019-03-23 12:48:28,572] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11500, global step 183944: loss 0.1464
[2019-03-23 12:48:28,575] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11500, global step 183944: learning rate 0.0000
[2019-03-23 12:48:28,607] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11500, global step 183961: loss 0.0796
[2019-03-23 12:48:28,609] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11500, global step 183961: learning rate 0.0000
[2019-03-23 12:48:28,632] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11500, global step 183972: loss 0.0387
[2019-03-23 12:48:28,634] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11500, global step 183972: learning rate 0.0000
[2019-03-23 12:48:28,816] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11500, global step 184068: loss 0.3475
[2019-03-23 12:48:28,822] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11500, global step 184072: learning rate 0.0000
[2019-03-23 12:48:28,829] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11500, global step 184073: loss 0.4458
[2019-03-23 12:48:28,831] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11500, global step 184074: learning rate 0.0000
[2019-03-23 12:48:28,838] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11500, global step 184079: loss 0.3145
[2019-03-23 12:48:28,840] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11500, global step 184079: loss 0.4380
[2019-03-23 12:48:28,842] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11500, global step 184079: learning rate 0.0000
[2019-03-23 12:48:28,847] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11500, global step 184079: learning rate 0.0000
[2019-03-23 12:48:28,877] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11500, global step 184095: loss 0.4133
[2019-03-23 12:48:28,878] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11500, global step 184095: learning rate 0.0000
[2019-03-23 12:48:28,931] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11500, global step 184122: loss 0.1315
[2019-03-23 12:48:28,934] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11500, global step 184123: learning rate 0.0000
[2019-03-23 12:48:29,669] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0313892e-10 1.0000000e+00 7.3576850e-25 2.3203660e-14 4.8425707e-23], sum to 1.0000
[2019-03-23 12:48:29,677] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9463
[2019-03-23 12:48:29,681] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 90.0, 1.0, 2.0, 0.3699931272565283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 413853.6026374467, 413853.602637447, 120681.7923219092], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6926400.0000, 
sim time next is 6927000.0000, 
raw observation next is [18.8, 89.5, 1.0, 2.0, 0.3682712919122944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 411556.2000045355, 411556.2000045355, 120371.1722023528], 
processed observation next is [0.0, 0.17391304347826086, 0.49090909090909096, 0.895, 1.0, 1.0, 0.210339114890368, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15242822222390204, 0.15242822222390204, 0.29358822488378733], 
reward next is 0.7064, 
noisyNet noise sample is [array([-0.10101315], dtype=float32), -1.162332]. 
=============================================
[2019-03-23 12:48:29,696] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[78.8846  ]
 [78.88463 ]
 [78.89282 ]
 [78.866875]
 [78.86414 ]], R is [[78.80301666]
 [78.72064209]
 [78.638237  ]
 [78.55564117]
 [78.4726181 ]].
[2019-03-23 12:48:29,767] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11500, global step 184555: loss 0.2709
[2019-03-23 12:48:29,771] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11500, global step 184557: learning rate 0.0000
[2019-03-23 12:48:30,126] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.1302325e-10 1.0000000e+00 8.7293889e-21 3.0589645e-11 4.1894998e-18], sum to 1.0000
[2019-03-23 12:48:30,133] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5519
[2019-03-23 12:48:30,139] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 87.5, 1.0, 2.0, 0.357530157235121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 398244.8675624959, 398244.8675624962, 118915.7953453471], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6929400.0000, 
sim time next is 6930000.0000, 
raw observation next is [18.8, 87.0, 1.0, 2.0, 0.3546248211291541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 394667.8881655901, 394667.8881655901, 118538.0359943247], 
processed observation next is [0.0, 0.21739130434782608, 0.49090909090909096, 0.87, 1.0, 1.0, 0.19328102641144262, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1461732919131815, 0.1461732919131815, 0.28911716096176754], 
reward next is 0.7109, 
noisyNet noise sample is [array([-0.49276033], dtype=float32), 0.03706742]. 
=============================================
[2019-03-23 12:48:30,152] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[64.06815]
 [64.09281]
 [64.09719]
 [64.12229]
 [64.12868]], R is [[64.11668396]
 [64.18547821]
 [64.25267029]
 [64.31829834]
 [64.38236237]].
[2019-03-23 12:48:32,646] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.2136864e-11 1.0000000e+00 2.4400056e-26 1.0129149e-12 1.0548970e-24], sum to 1.0000
[2019-03-23 12:48:32,653] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0894
[2019-03-23 12:48:32,664] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 59.0, 1.0, 2.0, 0.5079034708590616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 578828.7471920368, 578828.7471920368, 143542.5598933402], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6970800.0000, 
sim time next is 6971400.0000, 
raw observation next is [27.7, 59.5, 1.0, 2.0, 0.5109514783967793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 582133.2130296468, 582133.2130296468, 144076.5815673351], 
processed observation next is [0.0, 0.6956521739130435, 0.8954545454545454, 0.595, 1.0, 1.0, 0.38868934799597415, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.215604893714684, 0.215604893714684, 0.3514062965056953], 
reward next is 0.6486, 
noisyNet noise sample is [array([-1.730682], dtype=float32), -0.6808338]. 
=============================================
[2019-03-23 12:48:43,928] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12000, global step 191701: loss 1.8012
[2019-03-23 12:48:43,930] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12000, global step 191703: learning rate 0.0000
[2019-03-23 12:48:44,106] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12000, global step 191790: loss 2.9217
[2019-03-23 12:48:44,107] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12000, global step 191790: learning rate 0.0000
[2019-03-23 12:48:44,197] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12000, global step 191835: loss 3.6196
[2019-03-23 12:48:44,200] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12000, global step 191837: learning rate 0.0000
[2019-03-23 12:48:44,209] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12000, global step 191843: loss 3.7044
[2019-03-23 12:48:44,211] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12000, global step 191844: learning rate 0.0000
[2019-03-23 12:48:44,215] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12000, global step 191844: loss 3.7716
[2019-03-23 12:48:44,222] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12000, global step 191845: learning rate 0.0000
[2019-03-23 12:48:44,442] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12000, global step 191961: loss 4.3304
[2019-03-23 12:48:44,445] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12000, global step 191962: learning rate 0.0000
[2019-03-23 12:48:44,451] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12000, global step 191966: loss 4.2774
[2019-03-23 12:48:44,453] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12000, global step 191966: learning rate 0.0000
[2019-03-23 12:48:44,461] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12000, global step 191970: loss 4.2335
[2019-03-23 12:48:44,463] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12000, global step 191970: learning rate 0.0000
[2019-03-23 12:48:44,466] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12000, global step 191971: loss 4.4075
[2019-03-23 12:48:44,469] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12000, global step 191971: learning rate 0.0000
[2019-03-23 12:48:44,490] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12000, global step 191981: loss 4.3213
[2019-03-23 12:48:44,493] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12000, global step 191981: learning rate 0.0000
[2019-03-23 12:48:44,552] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12000, global step 192012: loss 4.1046
[2019-03-23 12:48:44,553] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12000, global step 192012: learning rate 0.0000
[2019-03-23 12:48:44,615] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12000, global step 192043: loss 3.8692
[2019-03-23 12:48:44,616] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12000, global step 192043: learning rate 0.0000
[2019-03-23 12:48:44,699] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12000, global step 192083: loss 3.3476
[2019-03-23 12:48:44,702] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12000, global step 192085: learning rate 0.0000
[2019-03-23 12:48:44,777] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12000, global step 192125: loss 3.0727
[2019-03-23 12:48:44,783] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12000, global step 192126: learning rate 0.0000
[2019-03-23 12:48:44,830] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12000, global step 192148: loss 2.7077
[2019-03-23 12:48:44,834] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12000, global step 192148: learning rate 0.0000
[2019-03-23 12:48:45,562] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12000, global step 192524: loss 0.2764
[2019-03-23 12:48:45,563] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12000, global step 192524: learning rate 0.0000
[2019-03-23 12:48:45,594] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.2876843e-10 1.0000000e+00 2.1407004e-19 3.2055303e-10 4.9218107e-17], sum to 1.0000
[2019-03-23 12:48:45,600] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1566
[2019-03-23 12:48:45,605] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.48333333333333, 45.5, 1.0, 2.0, 0.4655185608785311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 505577.8377462924, 505577.8377462924, 123839.0402786335], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7218600.0000, 
sim time next is 7219200.0000, 
raw observation next is [23.66666666666667, 45.0, 1.0, 2.0, 0.5823873805668349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 632586.1665686502, 632586.1665686502, 134661.5352056748], 
processed observation next is [1.0, 0.5652173913043478, 0.7121212121212124, 0.45, 1.0, 1.0, 0.4779842257085436, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23429117280320377, 0.23429117280320377, 0.32844276879432877], 
reward next is 0.6716, 
noisyNet noise sample is [array([0.43332568], dtype=float32), 0.13523619]. 
=============================================
[2019-03-23 12:48:46,167] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.6548386e-10 1.0000000e+00 1.3659178e-19 1.3786421e-10 9.8851402e-19], sum to 1.0000
[2019-03-23 12:48:46,174] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1721
[2019-03-23 12:48:46,181] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.01666666666667, 47.5, 1.0, 2.0, 0.3227348043717687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 350451.2208084617, 350451.2208084614, 112741.8211606803], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7236600.0000, 
sim time next is 7237200.0000, 
raw observation next is [22.73333333333333, 49.0, 1.0, 2.0, 0.3195554447608329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 346997.5864928535, 346997.5864928532, 112521.3836337097], 
processed observation next is [1.0, 0.782608695652174, 0.6696969696969696, 0.49, 1.0, 1.0, 0.14944430595104113, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12851762462698277, 0.12851762462698266, 0.274442399106609], 
reward next is 0.7256, 
noisyNet noise sample is [array([-0.9648895], dtype=float32), -1.1604729]. 
=============================================
[2019-03-23 12:48:49,922] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.8027720e-10 1.0000000e+00 1.7290504e-24 2.7959425e-12 7.3901783e-24], sum to 1.0000
[2019-03-23 12:48:49,934] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1282
[2019-03-23 12:48:49,936] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 43.0, 1.0, 2.0, 0.9480604424320707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1061584.749140004, 1061584.749140004, 190494.4337778837], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7308000.0000, 
sim time next is 7308600.0000, 
raw observation next is [26.0, 43.16666666666667, 1.0, 2.0, 0.8778639641183101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 982393.529594418, 982393.529594418, 179513.6905257438], 
processed observation next is [1.0, 0.6086956521739131, 0.8181818181818182, 0.4316666666666667, 1.0, 1.0, 0.8473299551478877, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.36384945540534, 0.36384945540534, 0.43783826957498484], 
reward next is 0.5622, 
noisyNet noise sample is [array([0.00971981], dtype=float32), 1.7161942]. 
=============================================
[2019-03-23 12:48:53,156] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3105895e-08 1.0000000e+00 6.1775347e-22 6.4591431e-13 3.0057029e-19], sum to 1.0000
[2019-03-23 12:48:53,167] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3042
[2019-03-23 12:48:53,176] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 87.0, 1.0, 2.0, 0.3244994132046122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 354439.6426102355, 354439.6426102358, 113582.8463220817], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7359000.0000, 
sim time next is 7359600.0000, 
raw observation next is [17.7, 87.0, 1.0, 2.0, 0.320322332182599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 349861.0810310873, 349861.0810310873, 113281.72271427], 
processed observation next is [1.0, 0.17391304347826086, 0.44090909090909086, 0.87, 1.0, 1.0, 0.1504029152282487, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12957817815966197, 0.12957817815966197, 0.2762968846689512], 
reward next is 0.7237, 
noisyNet noise sample is [array([-0.12493702], dtype=float32), -1.1324967]. 
=============================================
[2019-03-23 12:48:59,302] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12500, global step 199694: loss 0.0115
[2019-03-23 12:48:59,302] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12500, global step 199694: loss 0.0017
[2019-03-23 12:48:59,308] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12500, global step 199696: learning rate 0.0000
[2019-03-23 12:48:59,308] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12500, global step 199696: learning rate 0.0000
[2019-03-23 12:48:59,616] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12500, global step 199861: loss 0.0162
[2019-03-23 12:48:59,618] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12500, global step 199861: learning rate 0.0000
[2019-03-23 12:48:59,621] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12500, global step 199862: loss 0.0334
[2019-03-23 12:48:59,623] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12500, global step 199862: learning rate 0.0000
[2019-03-23 12:48:59,646] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12500, global step 199874: loss 0.1237
[2019-03-23 12:48:59,651] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12500, global step 199875: learning rate 0.0000
[2019-03-23 12:48:59,673] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12500, global step 199886: loss 0.1940
[2019-03-23 12:48:59,674] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12500, global step 199886: learning rate 0.0000
[2019-03-23 12:48:59,761] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12500, global step 199938: loss 0.1016
[2019-03-23 12:48:59,768] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12500, global step 199939: learning rate 0.0000
[2019-03-23 12:48:59,834] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12500, global step 199975: loss 0.0027
[2019-03-23 12:48:59,836] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12500, global step 199976: learning rate 0.0000
[2019-03-23 12:48:59,865] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12500, global step 199996: loss 0.0067
[2019-03-23 12:48:59,868] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12500, global step 199997: learning rate 0.0000
[2019-03-23 12:48:59,876] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 12:48:59,876] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:48:59,877] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:48:59,877] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:48:59,877] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:48:59,878] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:48:59,878] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:48:59,878] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:48:59,878] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:48:59,879] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:48:59,879] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:48:59,896] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run9
[2019-03-23 12:48:59,919] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run9
[2019-03-23 12:48:59,919] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run9
[2019-03-23 12:48:59,919] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run9
[2019-03-23 12:48:59,920] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run9
[2019-03-23 12:49:05,418] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02146075], dtype=float32), 0.08461929]
[2019-03-23 12:49:05,420] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.32687717, 45.61645352666667, 1.0, 2.0, 0.4213794287841014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 457576.7674378721, 457576.7674378717, 95387.16922138112]
[2019-03-23 12:49:05,421] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:49:05,423] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.1836708e-12 1.0000000e+00 6.9637975e-27 1.5884596e-15 5.6513916e-25], sampled 0.3286793404294277
[2019-03-23 12:49:05,480] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02146075], dtype=float32), 0.08461929]
[2019-03-23 12:49:05,482] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.51666666666667, 70.83333333333333, 1.0, 2.0, 0.4158244195516649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 460442.9539398153, 460442.9539398149, 127059.6335594646]
[2019-03-23 12:49:05,483] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:49:05,486] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.1188307e-13 1.0000000e+00 1.1499583e-28 1.5574916e-16 1.2454867e-26], sampled 0.703800085776011
[2019-03-23 12:49:17,438] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02146075], dtype=float32), 0.08461929]
[2019-03-23 12:49:17,441] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.61392463, 100.0, 1.0, 2.0, 0.4401728754842471, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 502066.5352824618, 502066.5352824615, 137872.0337602147]
[2019-03-23 12:49:17,442] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:49:17,443] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.9920964e-13 1.0000000e+00 6.5304565e-29 1.1274477e-16 7.3539455e-27], sampled 0.6896913831887369
[2019-03-23 12:49:30,540] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02146075], dtype=float32), 0.08461929]
[2019-03-23 12:49:30,543] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.7, 76.33333333333333, 1.0, 2.0, 0.4042637548934163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 457364.6302903629, 457364.6302903629, 130598.0521981447]
[2019-03-23 12:49:30,544] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:49:30,545] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.0906808e-13 1.0000000e+00 1.6859166e-28 1.9295800e-16 1.7746899e-26], sampled 0.9498097817317142
[2019-03-23 12:49:46,313] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02146075], dtype=float32), 0.08461929]
[2019-03-23 12:49:46,315] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.41791767333333, 99.68937185333334, 1.0, 2.0, 0.3249973553035481, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 356372.1601396011, 356372.1601396011, 118432.3114544071]
[2019-03-23 12:49:46,316] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:49:46,321] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.0303089e-13 1.0000000e+00 1.0949730e-28 1.5104482e-16 1.1881208e-26], sampled 0.7067021121078009
[2019-03-23 12:49:55,323] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02146075], dtype=float32), 0.08461929]
[2019-03-23 12:49:55,325] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.0, 88.0, 1.0, 2.0, 0.2010674232733537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 218305.4117290522, 218305.4117290519, 73247.96349238147]
[2019-03-23 12:49:55,327] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:49:55,330] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.9188414e-12 1.0000000e+00 2.2099676e-27 8.2637371e-16 1.9407401e-25], sampled 0.9326576572631018
[2019-03-23 12:49:58,086] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02146075], dtype=float32), 0.08461929]
[2019-03-23 12:49:58,087] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 80.5, 1.0, 2.0, 0.8919694110869517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1016365.633314188, 1016365.633314188, 192933.4521272819]
[2019-03-23 12:49:58,089] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:49:58,091] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.6931844e-13 1.0000000e+00 2.1130649e-28 2.2016581e-16 2.1925281e-26], sampled 0.052781216440018874
[2019-03-23 12:50:24,027] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02146075], dtype=float32), 0.08461929]
[2019-03-23 12:50:24,028] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.2, 96.0, 1.0, 2.0, 0.3315767435408963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 365547.2832640692, 365547.2832640692, 115325.1253524004]
[2019-03-23 12:50:24,030] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:50:24,033] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.5274355e-13 1.0000000e+00 3.5796388e-28 2.9489553e-16 3.5722219e-26], sampled 0.6846572823549678
[2019-03-23 12:50:38,662] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 12:50:38,687] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 12:50:39,055] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 12:50:39,086] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8573.5580 1683295527.7613 214.0000
[2019-03-23 12:50:39,128] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 12:50:40,143] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 200000, evaluation results [200000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8573.557968395495, 1683295527.761311, 214.0]
[2019-03-23 12:50:40,211] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12500, global step 200033: loss 0.3022
[2019-03-23 12:50:40,214] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12500, global step 200033: learning rate 0.0000
[2019-03-23 12:50:40,225] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12500, global step 200042: loss 0.2826
[2019-03-23 12:50:40,229] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12500, global step 200042: learning rate 0.0000
[2019-03-23 12:50:40,233] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12500, global step 200043: loss 0.3760
[2019-03-23 12:50:40,235] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12500, global step 200043: learning rate 0.0000
[2019-03-23 12:50:40,282] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12500, global step 200064: loss 0.4031
[2019-03-23 12:50:40,286] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12500, global step 200065: learning rate 0.0000
[2019-03-23 12:50:40,378] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12500, global step 200107: loss 0.0915
[2019-03-23 12:50:40,380] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12500, global step 200107: learning rate 0.0000
[2019-03-23 12:50:40,488] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12500, global step 200164: loss 0.0625
[2019-03-23 12:50:40,491] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12500, global step 200164: learning rate 0.0000
[2019-03-23 12:50:41,282] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12500, global step 200556: loss 0.2505
[2019-03-23 12:50:41,283] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12500, global step 200556: learning rate 0.0000
[2019-03-23 12:50:42,722] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.6930422e-16 1.0000000e+00 5.2748184e-31 2.9360533e-19 5.6205126e-27], sum to 1.0000
[2019-03-23 12:50:42,729] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7349
[2019-03-23 12:50:42,734] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.03333333333333, 77.33333333333333, 1.0, 2.0, 0.4812008355994669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 549010.1286828065, 549010.1286828065, 139374.1155821496], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7552200.0000, 
sim time next is 7552800.0000, 
raw observation next is [24.4, 76.0, 1.0, 2.0, 0.4876012719858445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 556189.370958909, 556189.3709589088, 140430.1382982024], 
processed observation next is [0.0, 0.43478260869565216, 0.7454545454545454, 0.76, 1.0, 1.0, 0.35950158998230564, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20599606331811446, 0.20599606331811438, 0.34251253243463997], 
reward next is 0.6575, 
noisyNet noise sample is [array([-0.68063885], dtype=float32), 0.6210188]. 
=============================================
[2019-03-23 12:50:48,028] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.70913404e-06 9.99998212e-01 1.21018213e-12 1.02541485e-07
 1.09386328e-12], sum to 1.0000
[2019-03-23 12:50:48,040] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4822
[2019-03-23 12:50:48,046] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1333655.688011075 W.
[2019-03-23 12:50:48,051] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.78333333333333, 63.66666666666667, 1.0, 2.0, 0.3934265844938373, 1.0, 2.0, 0.3934265844938373, 1.0, 1.0, 0.7960567354189411, 6.9112, 6.9112, 77.3421103, 1333655.688011075, 1333655.688011075, 301604.3439933514], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7647000.0000, 
sim time next is 7647600.0000, 
raw observation next is [26.96666666666667, 62.33333333333334, 1.0, 2.0, 0.4787084905345436, 1.0, 2.0, 0.4787084905345436, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1084473.663635575, 1084473.663635575, 228085.1485860034], 
processed observation next is [1.0, 0.5217391304347826, 0.8621212121212122, 0.6233333333333334, 1.0, 1.0, 0.3483856131681795, 1.0, 1.0, 0.3483856131681795, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.40165691245762036, 0.40165691245762036, 0.5563052404536668], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.741686], dtype=float32), -0.1364897]. 
=============================================
[2019-03-23 12:50:49,307] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.4338380e-11 1.0000000e+00 3.1850107e-21 2.1839258e-15 9.6802568e-22], sum to 1.0000
[2019-03-23 12:50:49,315] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3764
[2019-03-23 12:50:49,323] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.61666666666667, 80.00000000000001, 1.0, 2.0, 0.4854139185038197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 553801.2853231912, 553801.2853231912, 139910.513909901], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7672200.0000, 
sim time next is 7672800.0000, 
raw observation next is [23.43333333333334, 81.0, 1.0, 2.0, 0.4849324083747913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 553275.4391475534, 553275.4391475534, 139778.2389768701], 
processed observation next is [1.0, 0.8260869565217391, 0.7015151515151519, 0.81, 1.0, 1.0, 0.3561655104684891, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20491682931390867, 0.20491682931390867, 0.3409225340899271], 
reward next is 0.6591, 
noisyNet noise sample is [array([-0.6618966], dtype=float32), 0.58922267]. 
=============================================
[2019-03-23 12:50:53,954] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.5742628e-17 1.0000000e+00 4.6677177e-34 2.8276731e-25 4.2028634e-34], sum to 1.0000
[2019-03-23 12:50:53,955] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6932
[2019-03-23 12:50:53,963] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.1, 56.5, 1.0, 2.0, 0.266931339747504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 289837.3055710798, 289837.3055710798, 84253.12940731813], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7759800.0000, 
sim time next is 7760400.0000, 
raw observation next is [19.0, 56.66666666666667, 1.0, 2.0, 0.2652630256345247, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 288025.2933442226, 288025.2933442226, 83735.54976892777], 
processed observation next is [1.0, 0.8260869565217391, 0.5, 0.5666666666666668, 1.0, 1.0, 0.08157878204315586, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1066760345719343, 0.1066760345719343, 0.204233048216897], 
reward next is 0.7958, 
noisyNet noise sample is [array([1.5020359], dtype=float32), 1.5129946]. 
=============================================
[2019-03-23 12:50:55,378] A3C_AGENT_WORKER-Thread-10 INFO:Local step 13000, global step 207631: loss 1.0024
[2019-03-23 12:50:55,379] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 13000, global step 207631: learning rate 0.0000
[2019-03-23 12:50:55,615] A3C_AGENT_WORKER-Thread-3 INFO:Local step 13000, global step 207754: loss 0.2455
[2019-03-23 12:50:55,618] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 13000, global step 207755: learning rate 0.0000
[2019-03-23 12:50:55,744] A3C_AGENT_WORKER-Thread-20 INFO:Local step 13000, global step 207817: loss 0.0888
[2019-03-23 12:50:55,749] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 13000, global step 207818: learning rate 0.0000
[2019-03-23 12:50:55,870] A3C_AGENT_WORKER-Thread-13 INFO:Local step 13000, global step 207881: loss 0.0411
[2019-03-23 12:50:55,876] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 13000, global step 207882: learning rate 0.0000
[2019-03-23 12:50:55,886] A3C_AGENT_WORKER-Thread-18 INFO:Local step 13000, global step 207884: loss 0.0584
[2019-03-23 12:50:55,888] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 13000, global step 207886: learning rate 0.0000
[2019-03-23 12:50:55,976] A3C_AGENT_WORKER-Thread-14 INFO:Local step 13000, global step 207933: loss 0.2194
[2019-03-23 12:50:55,979] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 13000, global step 207933: learning rate 0.0000
[2019-03-23 12:50:55,988] A3C_AGENT_WORKER-Thread-9 INFO:Local step 13000, global step 207938: loss 0.1967
[2019-03-23 12:50:55,990] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 13000, global step 207938: learning rate 0.0000
[2019-03-23 12:50:56,082] A3C_AGENT_WORKER-Thread-19 INFO:Local step 13000, global step 207984: loss 0.4238
[2019-03-23 12:50:56,085] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 13000, global step 207984: learning rate 0.0000
[2019-03-23 12:50:56,100] A3C_AGENT_WORKER-Thread-2 INFO:Local step 13000, global step 207997: loss 0.5396
[2019-03-23 12:50:56,102] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 13000, global step 207997: learning rate 0.0000
[2019-03-23 12:50:56,126] A3C_AGENT_WORKER-Thread-22 INFO:Local step 13000, global step 208007: loss 0.6789
[2019-03-23 12:50:56,132] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 13000, global step 208008: learning rate 0.0000
[2019-03-23 12:50:56,169] A3C_AGENT_WORKER-Thread-11 INFO:Local step 13000, global step 208028: loss 0.6279
[2019-03-23 12:50:56,171] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 13000, global step 208028: learning rate 0.0000
[2019-03-23 12:50:56,190] A3C_AGENT_WORKER-Thread-12 INFO:Local step 13000, global step 208037: loss 0.7221
[2019-03-23 12:50:56,194] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 13000, global step 208038: learning rate 0.0000
[2019-03-23 12:50:56,227] A3C_AGENT_WORKER-Thread-16 INFO:Local step 13000, global step 208055: loss 0.5767
[2019-03-23 12:50:56,229] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 13000, global step 208055: learning rate 0.0000
[2019-03-23 12:50:56,282] A3C_AGENT_WORKER-Thread-15 INFO:Local step 13000, global step 208086: loss 0.4581
[2019-03-23 12:50:56,284] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 13000, global step 208086: learning rate 0.0000
[2019-03-23 12:50:56,466] A3C_AGENT_WORKER-Thread-21 INFO:Local step 13000, global step 208181: loss 0.1741
[2019-03-23 12:50:56,468] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 13000, global step 208181: learning rate 0.0000
[2019-03-23 12:50:57,286] A3C_AGENT_WORKER-Thread-17 INFO:Local step 13000, global step 208591: loss 0.5321
[2019-03-23 12:50:57,292] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 13000, global step 208593: learning rate 0.0000
[2019-03-23 12:50:58,618] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7250329e-15 1.0000000e+00 1.3897946e-28 7.0544588e-21 9.6519828e-28], sum to 1.0000
[2019-03-23 12:50:58,631] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3542
[2019-03-23 12:50:58,638] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.46666666666667, 49.66666666666667, 1.0, 2.0, 0.2936809542752707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 318891.8861271048, 318891.8861271051, 94862.02988711835], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7843200.0000, 
sim time next is 7843800.0000, 
raw observation next is [21.28333333333333, 49.33333333333334, 1.0, 2.0, 0.2904324212654035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 315363.3402851295, 315363.3402851292, 92536.59177533686], 
processed observation next is [1.0, 0.782608695652174, 0.6037878787878787, 0.4933333333333334, 1.0, 1.0, 0.11304052658175433, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11680123714264055, 0.11680123714264044, 0.22569900433008988], 
reward next is 0.7743, 
noisyNet noise sample is [array([0.35769287], dtype=float32), 0.8437649]. 
=============================================
[2019-03-23 12:51:01,082] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.8159283e-13 1.0000000e+00 3.6840907e-30 3.0720755e-21 1.0123171e-29], sum to 1.0000
[2019-03-23 12:51:01,091] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0636
[2019-03-23 12:51:01,099] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.18333333333333, 92.0, 1.0, 2.0, 0.7763697389249862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 882680.094276569, 882680.094276569, 172896.1302843562], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7902600.0000, 
sim time next is 7903200.0000, 
raw observation next is [20.36666666666667, 91.0, 1.0, 2.0, 0.7167669858060822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 815141.4456037289, 815141.4456037291, 164603.047092537], 
processed observation next is [1.0, 0.4782608695652174, 0.5621212121212124, 0.91, 1.0, 1.0, 0.6459587322576027, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3019042391124922, 0.30190423911249226, 0.40147084656716336], 
reward next is 0.5985, 
noisyNet noise sample is [array([0.5705913], dtype=float32), -0.8202707]. 
=============================================
[2019-03-23 12:51:04,235] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:51:04,235] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:51:04,236] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run2
[2019-03-23 12:51:04,502] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:51:04,503] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:51:04,504] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run2
[2019-03-23 12:51:04,587] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:51:04,587] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:51:04,589] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run2
[2019-03-23 12:51:04,676] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:51:04,677] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:51:04,679] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run2
[2019-03-23 12:51:04,713] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:51:04,713] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:51:04,715] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run2
[2019-03-23 12:51:04,715] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:51:04,715] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:51:04,717] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run2
[2019-03-23 12:51:04,758] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:51:04,759] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:51:04,762] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run2
[2019-03-23 12:51:04,800] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:51:04,801] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:51:04,804] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run2
[2019-03-23 12:51:04,827] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:51:04,827] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:51:04,827] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:51:04,828] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:51:04,829] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:51:04,830] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:51:04,829] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:51:04,828] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:51:04,833] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run2
[2019-03-23 12:51:04,860] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:51:04,861] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:51:04,863] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run2
[2019-03-23 12:51:04,892] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:51:04,892] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:51:04,894] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run2
[2019-03-23 12:51:04,931] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:51:04,932] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:51:04,933] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run2
[2019-03-23 12:51:04,969] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run2
[2019-03-23 12:51:05,068] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run2
[2019-03-23 12:51:05,085] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:51:05,209] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:51:05,086] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run2
[2019-03-23 12:51:05,280] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run2
[2019-03-23 12:51:11,134] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.9641149e-09 1.0000000e+00 1.5782548e-19 2.4220770e-13 1.2164120e-19], sum to 1.0000
[2019-03-23 12:51:11,141] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8224
[2019-03-23 12:51:11,151] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333334, 74.83333333333334, 1.0, 2.0, 0.2562709801893092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 278258.845760281, 278258.8457602813, 81811.19727544353], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 115800.0000, 
sim time next is 116400.0000, 
raw observation next is [16.66666666666667, 72.66666666666667, 1.0, 2.0, 0.3452893481345998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 374952.1879471433, 374952.1879471436, 91139.18800610153], 
processed observation next is [1.0, 0.34782608695652173, 0.39393939393939414, 0.7266666666666667, 1.0, 1.0, 0.18161168516824977, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13887118072116417, 0.1388711807211643, 0.22229070245390617], 
reward next is 0.7777, 
noisyNet noise sample is [array([1.0690681], dtype=float32), 0.78833467]. 
=============================================
[2019-03-23 12:51:19,916] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.9044601e-12 1.0000000e+00 2.5760587e-26 7.1542335e-16 3.5139636e-22], sum to 1.0000
[2019-03-23 12:51:19,923] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7546
[2019-03-23 12:51:19,927] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.2174539385595737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 236101.0999617164, 236101.0999617161, 79762.27544204038], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 282000.0000, 
sim time next is 282600.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.2181977327727158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 236908.8728668569, 236908.8728668572, 79842.04519190337], 
processed observation next is [0.0, 0.2608695652173913, 0.2727272727272727, 1.0, 1.0, 1.0, 0.022747165965894753, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08774402698772478, 0.08774402698772488, 0.1947366955900082], 
reward next is 0.8053, 
noisyNet noise sample is [array([1.7226567], dtype=float32), -0.17808153]. 
=============================================
[2019-03-23 12:51:22,105] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7243653e-11 1.0000000e+00 1.0143258e-24 2.2404585e-19 3.0267101e-28], sum to 1.0000
[2019-03-23 12:51:22,113] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1603
[2019-03-23 12:51:22,119] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 60.0, 1.0, 2.0, 0.2358030444268437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 256028.926264074, 256028.926264074, 86538.04332669434], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 300600.0000, 
sim time next is 301200.0000, 
raw observation next is [19.66666666666666, 58.66666666666666, 1.0, 2.0, 0.2384791834871076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 258935.3832114004, 258935.3832114002, 86528.41864877228], 
processed observation next is [0.0, 0.4782608695652174, 0.53030303030303, 0.5866666666666666, 1.0, 1.0, 0.04809897935888447, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09590199378200015, 0.09590199378200008, 0.21104492353359092], 
reward next is 0.7890, 
noisyNet noise sample is [array([0.24042736], dtype=float32), 0.13962586]. 
=============================================
[2019-03-23 12:51:24,890] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8294510e-10 1.0000000e+00 2.4409439e-20 1.4874862e-14 4.7796286e-20], sum to 1.0000
[2019-03-23 12:51:24,901] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8599
[2019-03-23 12:51:24,905] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.16666666666667, 74.5, 1.0, 2.0, 0.3989642651722201, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 433264.1353941091, 433264.1353941091, 86884.34481548284], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 355800.0000, 
sim time next is 356400.0000, 
raw observation next is [12.0, 76.0, 1.0, 2.0, 0.3987942380462075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 433079.4084106712, 433079.4084106709, 86845.40633792222], 
processed observation next is [1.0, 0.13043478260869565, 0.18181818181818182, 0.76, 1.0, 1.0, 0.24849279755775935, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16039978089284118, 0.16039978089284107, 0.21181806423883467], 
reward next is 0.7882, 
noisyNet noise sample is [array([-1.0829561], dtype=float32), -1.3456013]. 
=============================================
[2019-03-23 12:51:25,540] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.6179072e-12 1.0000000e+00 3.7996736e-30 3.4810132e-20 1.9025457e-29], sum to 1.0000
[2019-03-23 12:51:25,544] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5929
[2019-03-23 12:51:25,551] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333333, 52.66666666666667, 1.0, 2.0, 0.3134383769773016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 340352.8849060478, 340352.8849060478, 84373.13666761125], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 385800.0000, 
sim time next is 386400.0000, 
raw observation next is [18.66666666666667, 53.33333333333334, 1.0, 2.0, 0.3273420636274033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 355455.9793134736, 355455.9793134733, 87035.19037939725], 
processed observation next is [1.0, 0.4782608695652174, 0.4848484848484851, 0.5333333333333334, 1.0, 1.0, 0.15917757953425413, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13165036270869393, 0.13165036270869382, 0.21228095214487133], 
reward next is 0.7877, 
noisyNet noise sample is [array([0.09030386], dtype=float32), 0.7281248]. 
=============================================
[2019-03-23 12:51:29,367] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.9869955e-09 1.0000000e+00 2.8794224e-24 1.8131360e-16 2.7389948e-23], sum to 1.0000
[2019-03-23 12:51:29,372] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3869
[2019-03-23 12:51:29,377] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.5501713774884758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 597571.7977349275, 597571.7977349275, 111369.0579195077], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 447000.0000, 
sim time next is 447600.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.5435294941309048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 590353.296759208, 590353.296759208, 110642.0932898388], 
processed observation next is [1.0, 0.17391304347826086, 0.22727272727272727, 1.0, 1.0, 1.0, 0.42941186766363093, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21864936917007702, 0.21864936917007702, 0.26985876412155807], 
reward next is 0.7301, 
noisyNet noise sample is [array([1.0921783], dtype=float32), 0.16469182]. 
=============================================
[2019-03-23 12:51:31,502] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 12:51:31,503] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:51:31,504] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:51:31,504] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:51:31,504] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:51:31,506] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:51:31,506] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:51:31,505] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:51:31,507] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:51:31,508] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:51:31,509] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:51:31,522] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run10
[2019-03-23 12:51:31,545] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run10
[2019-03-23 12:51:31,545] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run10
[2019-03-23 12:51:31,602] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run10
[2019-03-23 12:51:31,602] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run10
[2019-03-23 12:51:58,274] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02469296], dtype=float32), 0.100825526]
[2019-03-23 12:51:58,275] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.60150933166667, 57.911668945, 1.0, 2.0, 0.2795758854783388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 303553.1236765888, 303553.1236765885, 104141.0325922377]
[2019-03-23 12:51:58,277] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:51:58,281] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.3340011e-13 1.0000000e+00 2.0761576e-29 3.3750077e-20 2.4694514e-29], sampled 0.20146227344066592
[2019-03-23 12:52:04,100] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02469296], dtype=float32), 0.100825526]
[2019-03-23 12:52:04,101] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.16666666666667, 59.83333333333334, 1.0, 2.0, 0.4575785751980683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 521955.0939161963, 521955.093916196, 135337.8021245493]
[2019-03-23 12:52:04,102] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:52:04,105] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.7495783e-14 1.0000000e+00 7.5390147e-31 3.5491941e-21 8.9618909e-31], sampled 0.29570673917016854
[2019-03-23 12:52:11,393] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02469296], dtype=float32), 0.100825526]
[2019-03-23 12:52:11,393] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.56666666666667, 86.33333333333334, 1.0, 2.0, 0.4810709330676295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 548179.2359803516, 548179.2359803512, 141276.1235582133]
[2019-03-23 12:52:11,394] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:52:11,397] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.369333e-14 1.000000e+00 5.095024e-32 5.691663e-22 6.051691e-32], sampled 0.48288758192285064
[2019-03-23 12:52:38,574] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02469296], dtype=float32), 0.100825526]
[2019-03-23 12:52:38,577] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.7108223, 81.40189916666668, 1.0, 2.0, 0.493341945121945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 562865.3591335606, 562865.3591335606, 144117.5394603011]
[2019-03-23 12:52:38,579] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:52:38,582] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.7268098e-14 1.0000000e+00 7.0110386e-32 7.0734252e-22 8.3317241e-32], sampled 0.9599046410974736
[2019-03-23 12:53:06,883] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02469296], dtype=float32), 0.100825526]
[2019-03-23 12:53:06,884] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.86666666666667, 72.0, 1.0, 2.0, 0.2100387813424805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 228037.9934889065, 228037.9934889065, 78830.00529738647]
[2019-03-23 12:53:06,884] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:53:06,887] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.4272266e-13 1.0000000e+00 6.2519291e-29 7.1148648e-20 7.4282023e-29], sampled 0.5361938904714524
[2019-03-23 12:53:08,380] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02469296], dtype=float32), 0.100825526]
[2019-03-23 12:53:08,381] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.42234875, 64.26034902, 1.0, 2.0, 0.3348138159235891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 369202.9643510695, 369202.9643510695, 119916.322750866]
[2019-03-23 12:53:08,382] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:53:08,386] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.31612662e-13 1.00000000e+00 9.06618581e-30 1.92304338e-20
 1.07824745e-29], sampled 0.8264264184065936
[2019-03-23 12:53:10,461] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02469296], dtype=float32), 0.100825526]
[2019-03-23 12:53:10,463] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.90005452, 90.47227525666666, 1.0, 2.0, 0.4745459775651482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 540681.5978660169, 540681.5978660169, 140489.0888770781]
[2019-03-23 12:53:10,465] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:53:10,467] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.1602606e-14 1.0000000e+00 1.8302308e-31 1.3566161e-21 2.1746803e-31], sampled 0.3931762568688114
[2019-03-23 12:53:10,763] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 12:53:10,807] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 12:53:10,918] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 12:53:10,973] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 12:53:11,075] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 12:53:12,090] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 225000, evaluation results [225000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 12:53:14,179] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.8405435e-14 1.0000000e+00 7.1762843e-33 8.1199952e-23 6.8488077e-33], sum to 1.0000
[2019-03-23 12:53:14,185] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3981
[2019-03-23 12:53:14,191] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2208690810202458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 239810.0126225071, 239810.0126225068, 77337.0056789239], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 528600.0000, 
sim time next is 529200.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2194162716802948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 238232.2293173193, 238232.2293173193, 77193.71409113845], 
processed observation next is [1.0, 0.13043478260869565, 0.2727272727272727, 0.94, 1.0, 1.0, 0.024270339600368472, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08823415900641456, 0.08823415900641456, 0.1882773514418011], 
reward next is 0.8117, 
noisyNet noise sample is [array([-1.8315831], dtype=float32), 1.2717758]. 
=============================================
[2019-03-23 12:53:14,606] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.6486677e-12 1.0000000e+00 5.8968339e-27 2.4745183e-19 8.7466286e-27], sum to 1.0000
[2019-03-23 12:53:14,617] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1351
[2019-03-23 12:53:14,624] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.16666666666667, 99.0, 1.0, 2.0, 0.2057826546386372, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 223426.0668872434, 223426.0668872432, 74489.98207946787], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 535800.0000, 
sim time next is 536400.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2041165091789269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221616.6571845174, 221616.6571845171, 74080.83009311638], 
processed observation next is [1.0, 0.21739130434782608, 0.22727272727272727, 1.0, 1.0, 1.0, 0.005145636473658614, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08208024340167311, 0.082080243401673, 0.18068495144662533], 
reward next is 0.8193, 
noisyNet noise sample is [array([0.76994723], dtype=float32), -0.5359851]. 
=============================================
[2019-03-23 12:53:19,193] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.0209884e-11 1.0000000e+00 1.0121583e-30 3.1711690e-19 4.0199088e-28], sum to 1.0000
[2019-03-23 12:53:19,204] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5129
[2019-03-23 12:53:19,211] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 88.0, 1.0, 2.0, 0.2569655577532808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 279013.2339095657, 279013.2339095654, 90017.54396814435], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 615000.0000, 
sim time next is 615600.0000, 
raw observation next is [16.0, 88.0, 1.0, 2.0, 0.2569832427820803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 279032.4418244897, 279032.4418244894, 90014.49611742907], 
processed observation next is [1.0, 0.13043478260869565, 0.36363636363636365, 0.88, 1.0, 1.0, 0.07122905347760035, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10334534882388506, 0.10334534882388496, 0.21954755150592456], 
reward next is 0.7805, 
noisyNet noise sample is [array([-1.6719184], dtype=float32), 0.53937674]. 
=============================================
[2019-03-23 12:53:21,018] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.7568369e-10 1.0000000e+00 6.9581859e-22 2.8682783e-13 1.7656911e-23], sum to 1.0000
[2019-03-23 12:53:21,026] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0629
[2019-03-23 12:53:21,030] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 57.0, 1.0, 2.0, 0.5759132811528127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 644483.5273992941, 644483.5273992941, 140647.6189799323], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 646200.0000, 
sim time next is 646800.0000, 
raw observation next is [23.66666666666667, 57.0, 1.0, 2.0, 0.6642506108662153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 744868.7339409532, 744868.7339409534, 151489.3091425096], 
processed observation next is [1.0, 0.4782608695652174, 0.7121212121212124, 0.57, 1.0, 1.0, 0.580313263582769, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.27587730886701967, 0.2758773088670198, 0.36948611985977947], 
reward next is 0.6305, 
noisyNet noise sample is [array([-1.2050669], dtype=float32), -0.59351146]. 
=============================================
[2019-03-23 12:53:23,604] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4686453e-11 1.0000000e+00 6.2780637e-25 1.7994114e-15 3.0551164e-22], sum to 1.0000
[2019-03-23 12:53:23,614] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0065
[2019-03-23 12:53:23,618] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 100.0, 1.0, 2.0, 0.2791171322559056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 303072.9105749211, 303072.9105749211, 95311.11836341786], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 705600.0000, 
sim time next is 706200.0000, 
raw observation next is [15.16666666666667, 98.00000000000001, 1.0, 2.0, 0.2767886090109498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 300543.7559765634, 300543.7559765631, 94669.22054756632], 
processed observation next is [1.0, 0.17391304347826086, 0.3257575757575759, 0.9800000000000001, 1.0, 1.0, 0.09598576126368726, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.111312502213542, 0.11131250221354189, 0.23090053792089346], 
reward next is 0.7691, 
noisyNet noise sample is [array([0.6480257], dtype=float32), -0.36955422]. 
=============================================
[2019-03-23 12:53:23,741] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.2021342e-11 1.0000000e+00 1.3483012e-26 7.6660006e-18 4.1121805e-27], sum to 1.0000
[2019-03-23 12:53:23,750] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8851
[2019-03-23 12:53:23,756] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 94.0, 1.0, 2.0, 0.2931818287795568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 318349.7359950736, 318349.7359950733, 102484.5161960098], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 702000.0000, 
sim time next is 702600.0000, 
raw observation next is [15.83333333333333, 95.0, 1.0, 2.0, 0.299246793971002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 324937.5423608015, 324937.5423608018, 101979.2706037509], 
processed observation next is [1.0, 0.13043478260869565, 0.3560606060606059, 0.95, 1.0, 1.0, 0.1240584924637525, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12034723791140796, 0.12034723791140807, 0.24872992830183147], 
reward next is 0.7513, 
noisyNet noise sample is [array([-0.30546373], dtype=float32), 2.319408]. 
=============================================
[2019-03-23 12:53:28,543] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.61078589e-10 1.00000000e+00 1.40899029e-21 1.01283855e-14
 1.65078674e-21], sum to 1.0000
[2019-03-23 12:53:28,549] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0967
[2019-03-23 12:53:28,554] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666667, 87.16666666666667, 1.0, 2.0, 0.4290252524480803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 488196.3866127747, 488196.3866127747, 130696.4904549169], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 803400.0000, 
sim time next is 804000.0000, 
raw observation next is [21.33333333333334, 86.33333333333334, 1.0, 2.0, 0.4341174796727586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 494136.8951468638, 494136.8951468638, 131351.2954348291], 
processed observation next is [0.0, 0.30434782608695654, 0.6060606060606063, 0.8633333333333334, 1.0, 1.0, 0.2926468495909482, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18301366486920884, 0.18301366486920884, 0.32036901325568073], 
reward next is 0.6796, 
noisyNet noise sample is [array([-0.4704843], dtype=float32), -1.4282908]. 
=============================================
[2019-03-23 12:53:28,569] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[65.58228]
 [65.59118]
 [65.59322]
 [65.61132]
 [65.61093]], R is [[65.59394836]
 [65.61923981]
 [65.6462326 ]
 [65.67578888]
 [65.707901  ]].
[2019-03-23 12:53:29,746] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.8274528e-10 1.0000000e+00 2.6030243e-20 4.6742602e-14 3.5842172e-20], sum to 1.0000
[2019-03-23 12:53:29,754] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3764
[2019-03-23 12:53:29,762] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 56.0, 1.0, 2.0, 0.5430466468020894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 616969.992596114, 616969.9925961138, 149165.0873069344], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 826800.0000, 
sim time next is 827400.0000, 
raw observation next is [29.0, 55.5, 1.0, 2.0, 0.5385107742475823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 612136.8321640952, 612136.8321640952, 148422.9067834368], 
processed observation next is [0.0, 0.5652173913043478, 0.9545454545454546, 0.555, 1.0, 1.0, 0.42313846780947784, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2267173452459612, 0.2267173452459612, 0.3620070897156995], 
reward next is 0.6380, 
noisyNet noise sample is [array([-0.2924374], dtype=float32), -1.1447238]. 
=============================================
[2019-03-23 12:53:30,089] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.7155046e-09 1.0000000e+00 1.2085710e-21 1.3226999e-14 6.3114744e-22], sum to 1.0000
[2019-03-23 12:53:30,097] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8213
[2019-03-23 12:53:30,104] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 55.0, 1.0, 2.0, 0.5303086855122982, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 603188.698899395, 603188.698899395, 147177.5945912892], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 830400.0000, 
sim time next is 831000.0000, 
raw observation next is [29.0, 55.0, 1.0, 2.0, 0.53016840109917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 603030.5458626873, 603030.5458626873, 147159.266916282], 
processed observation next is [0.0, 0.6086956521739131, 0.9545454545454546, 0.55, 1.0, 1.0, 0.4127105013739624, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2233446466158101, 0.2233446466158101, 0.3589250412592244], 
reward next is 0.6411, 
noisyNet noise sample is [array([0.85430616], dtype=float32), 1.69118]. 
=============================================
[2019-03-23 12:53:30,127] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[67.31843 ]
 [67.33707 ]
 [67.373795]
 [67.40529 ]
 [67.44039 ]], R is [[67.25550079]
 [67.22397614]
 [67.19259644]
 [67.16139984]
 [67.13023376]].
[2019-03-23 12:53:41,043] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4457128e-08 1.0000000e+00 3.2379717e-20 5.6980841e-14 8.1940337e-20], sum to 1.0000
[2019-03-23 12:53:41,054] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2854
[2019-03-23 12:53:41,064] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.83333333333333, 95.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 194091.4264379978, 194091.4264379975, 67949.95426842578], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1043400.0000, 
sim time next is 1044000.0000, 
raw observation next is [13.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 195350.3142223531, 195350.3142223528, 68325.93790657594], 
processed observation next is [1.0, 0.08695652173913043, 0.22727272727272727, 0.94, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07235196823050115, 0.07235196823050104, 0.16664862904042912], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.57157207], dtype=float32), 0.9957225]. 
=============================================
[2019-03-23 12:53:41,089] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[58.73478 ]
 [58.76408 ]
 [58.7634  ]
 [58.741978]
 [58.667557]], R is [[58.17511749]
 [57.59336853]
 [57.01743698]
 [56.44726181]
 [55.88278961]].
[2019-03-23 12:53:43,588] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.2016601e-12 1.0000000e+00 1.6818915e-25 3.3968413e-17 6.0569322e-25], sum to 1.0000
[2019-03-23 12:53:43,598] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2416
[2019-03-23 12:53:43,602] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 69.0, 1.0, 2.0, 0.707760905028003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 796769.668313924, 796769.668313924, 158367.9211512011], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1087800.0000, 
sim time next is 1088400.0000, 
raw observation next is [22.0, 69.0, 1.0, 2.0, 0.634336449147379, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 714016.6628996583, 714016.6628996581, 149149.976830098], 
processed observation next is [1.0, 0.6086956521739131, 0.6363636363636364, 0.69, 1.0, 1.0, 0.5429205614342236, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.26445061588876234, 0.26445061588876223, 0.3637804312929219], 
reward next is 0.6362, 
noisyNet noise sample is [array([-1.2252427], dtype=float32), -0.5875676]. 
=============================================
[2019-03-23 12:53:50,466] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.4425920e-10 1.0000000e+00 5.5232999e-25 1.2762220e-15 4.3286184e-22], sum to 1.0000
[2019-03-23 12:53:50,475] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8094
[2019-03-23 12:53:50,482] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.2, 88.0, 1.0, 2.0, 0.5177661103301533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 589728.3866607734, 589728.3866607734, 145051.5338955106], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1207800.0000, 
sim time next is 1208400.0000, 
raw observation next is [23.26666666666667, 87.66666666666667, 1.0, 2.0, 0.517823430977297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 589742.71216772, 589742.71216772, 145101.2583059449], 
processed observation next is [1.0, 1.0, 0.6939393939393941, 0.8766666666666667, 1.0, 1.0, 0.3972792887216212, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21842322672878517, 0.21842322672878517, 0.35390550806328025], 
reward next is 0.6461, 
noisyNet noise sample is [array([-1.8976253], dtype=float32), 0.3875537]. 
=============================================
[2019-03-23 12:53:50,512] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.8784475e-11 1.0000000e+00 3.9491185e-24 1.1014571e-15 3.6344106e-23], sum to 1.0000
[2019-03-23 12:53:50,519] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5426
[2019-03-23 12:53:50,526] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.2, 88.0, 1.0, 2.0, 0.5177661103301533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 589728.3866607734, 589728.3866607734, 145051.5338955106], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1207800.0000, 
sim time next is 1208400.0000, 
raw observation next is [23.26666666666667, 87.66666666666667, 1.0, 2.0, 0.517823430977297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 589742.71216772, 589742.71216772, 145101.2583059449], 
processed observation next is [1.0, 1.0, 0.6939393939393941, 0.8766666666666667, 1.0, 1.0, 0.3972792887216212, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21842322672878517, 0.21842322672878517, 0.35390550806328025], 
reward next is 0.6461, 
noisyNet noise sample is [array([-0.28167114], dtype=float32), 0.018326549]. 
=============================================
[2019-03-23 12:53:54,851] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.6921548e-10 1.0000000e+00 2.1491750e-21 5.6253305e-15 5.7720384e-22], sum to 1.0000
[2019-03-23 12:53:54,857] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6784
[2019-03-23 12:53:54,862] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 100.0, 1.0, 2.0, 0.3485047797178193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385853.2730918831, 385853.2730918831, 117231.7214344386], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1303200.0000, 
sim time next is 1303800.0000, 
raw observation next is [17.16666666666667, 100.0, 1.0, 2.0, 0.4214969588876555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 467658.5499376846, 467658.5499376846, 123581.4854005548], 
processed observation next is [1.0, 0.08695652173913043, 0.4166666666666669, 1.0, 1.0, 1.0, 0.2768711986095693, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1732068703472906, 0.1732068703472906, 0.3014182570745239], 
reward next is 0.6986, 
noisyNet noise sample is [array([-0.9911656], dtype=float32), 1.4395621]. 
=============================================
[2019-03-23 12:53:56,165] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.9680622e-08 1.0000000e+00 3.7155951e-21 2.7131682e-12 8.9344326e-19], sum to 1.0000
[2019-03-23 12:53:56,173] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0191
[2019-03-23 12:53:56,176] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 94.0, 1.0, 2.0, 0.4818867638886157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 549861.515477282, 549861.515477282, 139127.0786484237], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1324200.0000, 
sim time next is 1324800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5349220595426847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 610168.9490362701, 610168.9490362704, 146090.116277368], 
processed observation next is [1.0, 0.34782608695652173, 0.6363636363636364, 0.94, 1.0, 1.0, 0.4186525744283558, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22598849964306303, 0.2259884996430631, 0.35631735677406834], 
reward next is 0.6437, 
noisyNet noise sample is [array([-0.9237793], dtype=float32), 0.2834981]. 
=============================================
[2019-03-23 12:54:00,855] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 12:54:00,855] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:54:00,856] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:54:00,856] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:54:00,860] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:54:00,858] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:54:00,857] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:54:00,858] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:54:00,862] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:54:00,864] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:54:00,866] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:54:00,879] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run11
[2019-03-23 12:54:00,879] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run11
[2019-03-23 12:54:00,879] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run11
[2019-03-23 12:54:00,899] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run11
[2019-03-23 12:54:00,970] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run11
[2019-03-23 12:54:06,224] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02807727], dtype=float32), 0.113208346]
[2019-03-23 12:54:06,227] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.8, 78.0, 1.0, 2.0, 0.4944684413131846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 556044.7486146989, 556044.7486146985, 137703.3828655878]
[2019-03-23 12:54:06,227] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:54:06,230] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.7912836e-11 1.0000000e+00 3.7171027e-26 1.8864691e-18 6.4818211e-26], sampled 0.6231290950779378
[2019-03-23 12:54:28,120] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02807727], dtype=float32), 0.113208346]
[2019-03-23 12:54:28,123] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.25, 43.0, 1.0, 2.0, 0.2986190623069803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 324235.0758953321, 324235.0758953321, 91206.99128984885]
[2019-03-23 12:54:28,124] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:54:28,127] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.4507553e-10 1.0000000e+00 9.4112329e-25 1.7956380e-17 1.6059140e-24], sampled 0.1909177884000457
[2019-03-23 12:54:32,486] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02807727], dtype=float32), 0.113208346]
[2019-03-23 12:54:32,487] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.43754036666667, 90.39310546000002, 1.0, 2.0, 0.4412483069204127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 503101.9501601734, 503101.9501601734, 137555.5309475377]
[2019-03-23 12:54:32,487] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:54:32,490] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.2081712e-11 1.0000000e+00 2.4861380e-26 1.4250412e-18 4.3450040e-26], sampled 0.5198609211138638
[2019-03-23 12:54:41,748] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02807727], dtype=float32), 0.113208346]
[2019-03-23 12:54:41,749] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.67320052833334, 90.20324459666666, 1.0, 2.0, 0.379907253424569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 428422.5608356131, 428422.5608356128, 127564.9167528833]
[2019-03-23 12:54:41,754] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:54:41,758] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.2102722e-11 1.0000000e+00 1.0135242e-26 7.6195241e-19 1.7812280e-26], sampled 0.7376912055449688
[2019-03-23 12:54:45,859] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02807727], dtype=float32), 0.113208346]
[2019-03-23 12:54:45,860] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.30933901, 86.67132913500001, 1.0, 2.0, 0.3822902399313056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 431910.4806419571, 431910.4806419568, 128233.1401319056]
[2019-03-23 12:54:45,860] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:54:45,863] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.1844597e-11 1.0000000e+00 4.7110986e-26 2.2253235e-18 8.2042046e-26], sampled 0.14254702503733474
[2019-03-23 12:54:51,453] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02807727], dtype=float32), 0.113208346]
[2019-03-23 12:54:51,455] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.78333333333333, 87.0, 1.0, 2.0, 0.5054805837400594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 576508.6800346636, 576508.6800346636, 146855.3812951728]
[2019-03-23 12:54:51,455] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:54:51,460] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.8469278e-11 1.0000000e+00 6.5793218e-27 5.6385097e-19 1.1618251e-26], sampled 0.8095234339498576
[2019-03-23 12:55:28,784] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02807727], dtype=float32), 0.113208346]
[2019-03-23 12:55:28,784] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.9, 64.5, 1.0, 2.0, 0.6598066272853197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 746915.3175209493, 746915.317520949, 170408.2628243861]
[2019-03-23 12:55:28,786] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:55:28,793] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.6951400e-11 1.0000000e+00 3.4957866e-26 1.8080921e-18 6.1030834e-26], sampled 0.8304193375785839
[2019-03-23 12:55:29,298] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02807727], dtype=float32), 0.113208346]
[2019-03-23 12:55:29,298] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.256475685, 50.885102365, 1.0, 2.0, 0.4416569041887822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 485030.9643120485, 485030.9643120485, 127886.6286867801]
[2019-03-23 12:55:29,299] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:55:29,306] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.3577373e-11 1.0000000e+00 1.8355783e-25 5.7441978e-18 3.1685473e-25], sampled 0.05361495643647518
[2019-03-23 12:55:29,956] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02807727], dtype=float32), 0.113208346]
[2019-03-23 12:55:29,959] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.56725372, 57.39847388, 1.0, 2.0, 0.2268941693354067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 246341.5489681593, 246341.548968159, 76485.32525200747]
[2019-03-23 12:55:29,962] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:55:29,964] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.2305466e-11 1.0000000e+00 1.2303573e-25 4.3429340e-18 2.1293730e-25], sampled 0.04621919916714279
[2019-03-23 12:55:36,032] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02807727], dtype=float32), 0.113208346]
[2019-03-23 12:55:36,034] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.7, 55.0, 1.0, 2.0, 0.3301811491743281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 363492.6440176535, 363492.6440176528, 119340.9288602266]
[2019-03-23 12:55:36,036] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:55:36,038] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.5228314e-11 1.0000000e+00 5.6886991e-26 2.5359372e-18 9.8923102e-26], sampled 0.38473594436595615
[2019-03-23 12:55:39,291] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02807727], dtype=float32), 0.113208346]
[2019-03-23 12:55:39,293] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.1, 67.0, 1.0, 2.0, 0.5066258043748568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 573323.1897796302, 573323.1897796302, 140869.2654457741]
[2019-03-23 12:55:39,295] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:55:39,298] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.0107793e-11 1.0000000e+00 7.2803720e-26 3.0145344e-18 1.2649079e-25], sampled 0.6470964117992596
[2019-03-23 12:55:39,839] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9513 1705935940.2592 465.0000
[2019-03-23 12:55:40,067] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5896 1663766061.8834 105.0000
[2019-03-23 12:55:40,299] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 12:55:40,301] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 12:55:40,426] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 12:55:41,441] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 250000, evaluation results [250000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.58956291602, 1663766061.8834455, 105.0, 8596.951295847348, 1705935940.259201, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 12:55:47,697] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.7667886e-10 1.0000000e+00 1.0396427e-27 3.4958142e-18 2.0751847e-28], sum to 1.0000
[2019-03-23 12:55:47,704] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0437
[2019-03-23 12:55:47,709] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 87.16666666666667, 1.0, 2.0, 0.4675627662628197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 533504.07887594, 533504.0788759403, 136994.7308211309], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1543800.0000, 
sim time next is 1544400.0000, 
raw observation next is [22.0, 88.0, 1.0, 2.0, 0.4652214771917481, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 530811.0605885301, 530811.0605885301, 136615.6708893967], 
processed observation next is [0.0, 0.9130434782608695, 0.6363636363636364, 0.88, 1.0, 1.0, 0.3315268464896851, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.196596689106863, 0.196596689106863, 0.3332089533887724], 
reward next is 0.6668, 
noisyNet noise sample is [array([-0.67949957], dtype=float32), 0.31867635]. 
=============================================
[2019-03-23 12:55:48,691] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.7337804e-11 1.0000000e+00 5.4087237e-26 1.4076279e-18 9.3600338e-25], sum to 1.0000
[2019-03-23 12:55:48,699] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1767
[2019-03-23 12:55:48,704] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.83333333333333, 89.00000000000001, 1.0, 2.0, 0.4263842959443394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 485042.3021190444, 485042.3021190444, 130290.827284428], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1552200.0000, 
sim time next is 1552800.0000, 
raw observation next is [20.66666666666667, 90.0, 1.0, 2.0, 0.4240023258904605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482223.206542486, 482223.206542486, 129954.3193762244], 
processed observation next is [0.0, 1.0, 0.575757575757576, 0.9, 1.0, 1.0, 0.2800029073630756, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17860118760832813, 0.17860118760832813, 0.3169617545761571], 
reward next is 0.6830, 
noisyNet noise sample is [array([0.8137905], dtype=float32), -0.06367573]. 
=============================================
[2019-03-23 12:55:50,060] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.7438888e-09 1.0000000e+00 2.0965975e-20 7.4032475e-15 3.6305104e-19], sum to 1.0000
[2019-03-23 12:55:50,069] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9486
[2019-03-23 12:55:50,077] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.7351832207388498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 838501.248192538, 838501.248192538, 173973.5148080566], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1587000.0000, 
sim time next is 1587600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.8080596694347457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 921659.9856962793, 921659.9856962793, 185536.9379522682], 
processed observation next is [1.0, 0.391304347826087, 0.6363636363636364, 0.94, 1.0, 1.0, 0.7600745867934322, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3413555502578812, 0.3413555502578812, 0.4525291169567517], 
reward next is 0.5475, 
noisyNet noise sample is [array([0.4702179], dtype=float32), 0.06610801]. 
=============================================
[2019-03-23 12:55:57,355] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.7737152e-09 1.0000000e+00 9.0360855e-21 5.4556482e-15 1.8492326e-19], sum to 1.0000
[2019-03-23 12:55:57,363] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3987
[2019-03-23 12:55:57,371] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.5, 68.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 184454.3401867468, 184454.3401867471, 62380.84460148716], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1726200.0000, 
sim time next is 1726800.0000, 
raw observation next is [11.33333333333333, 67.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 182065.1931333552, 182065.1931333552, 62063.8280837502], 
processed observation next is [1.0, 1.0, 0.15151515151515138, 0.6766666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.06743155301235378, 0.06743155301235378, 0.15137519044817122], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.39023665], dtype=float32), -1.495171]. 
=============================================
[2019-03-23 12:56:03,374] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.7614928e-13 1.0000000e+00 1.4090843e-25 2.6113586e-20 5.5494639e-26], sum to 1.0000
[2019-03-23 12:56:03,382] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5107
[2019-03-23 12:56:03,391] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [10.0, 100.0, 1.0, 2.0, 0.3879793923443604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 421329.6991118498, 421329.6991118498, 86096.15754941243], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1828800.0000, 
sim time next is 1829400.0000, 
raw observation next is [10.0, 100.0, 1.0, 2.0, 0.3611143716774019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 392143.6243396694, 392143.6243396694, 83586.31172543675], 
processed observation next is [1.0, 0.17391304347826086, 0.09090909090909091, 1.0, 1.0, 1.0, 0.20139296459675235, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14523837938506276, 0.14523837938506276, 0.20386905298887012], 
reward next is 0.7961, 
noisyNet noise sample is [array([0.00186114], dtype=float32), 0.1967173]. 
=============================================
[2019-03-23 12:56:05,286] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.0291594e-12 1.0000000e+00 4.6255811e-28 1.7956422e-20 9.9591998e-29], sum to 1.0000
[2019-03-23 12:56:05,294] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9892
[2019-03-23 12:56:05,300] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 56.5, 1.0, 2.0, 0.2733328393126103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 296790.2528122109, 296790.2528122112, 90431.20531269805], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1891800.0000, 
sim time next is 1892400.0000, 
raw observation next is [19.66666666666667, 59.0, 1.0, 2.0, 0.2689732570939782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 292055.1100591012, 292055.1100591012, 90428.83347908365], 
processed observation next is [1.0, 0.9130434782608695, 0.5303030303030305, 0.59, 1.0, 1.0, 0.08621657136747271, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10816855928114859, 0.10816855928114859, 0.2205581304367894], 
reward next is 0.7794, 
noisyNet noise sample is [array([0.9918201], dtype=float32), 1.1495597]. 
=============================================
[2019-03-23 12:56:09,499] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.0740551e-06 9.9999595e-01 1.5613462e-12 1.7985859e-09 8.2357437e-12], sum to 1.0000
[2019-03-23 12:56:09,506] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9011
[2019-03-23 12:56:09,511] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1234448.426101218 W.
[2019-03-23 12:56:09,514] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.33333333333334, 61.0, 1.0, 2.0, 0.5407202096516908, 1.0, 2.0, 0.5407202096516908, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1234448.426101218, 1234448.426101218, 237130.7312741753], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1956000.0000, 
sim time next is 1956600.0000, 
raw observation next is [25.5, 61.0, 1.0, 2.0, 0.5545213078099143, 1.0, 2.0, 0.5545213078099143, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1265615.656239635, 1265615.656239635, 241288.9393592807], 
processed observation next is [1.0, 0.6521739130434783, 0.7954545454545454, 0.61, 1.0, 1.0, 0.4431516347623928, 1.0, 1.0, 0.4431516347623928, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.46874653934801297, 0.46874653934801297, 0.5885096081933675], 
reward next is 0.4115, 
noisyNet noise sample is [array([0.15944631], dtype=float32), -1.004213]. 
=============================================
[2019-03-23 12:56:09,562] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.0713866e-07 9.9999905e-01 7.3215245e-12 9.6564079e-10 2.7626757e-12], sum to 1.0000
[2019-03-23 12:56:09,570] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3618
[2019-03-23 12:56:09,578] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1279090.322764821 W.
[2019-03-23 12:56:09,584] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.66666666666666, 61.0, 1.0, 2.0, 0.5606519700123078, 1.0, 2.0, 0.5606519700123078, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1279090.322764821, 1279090.322764821, 243587.7266181605], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1957200.0000, 
sim time next is 1957800.0000, 
raw observation next is [25.83333333333334, 61.0, 1.0, 2.0, 0.6550442786524862, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9693772509523662, 6.911200000000001, 6.9112, 77.32846344354104, 1296173.258834816, 1296173.258834816, 277594.8911329691], 
processed observation next is [1.0, 0.6521739130434783, 0.8106060606060609, 0.61, 1.0, 1.0, 0.5688053483156077, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9562532156462373, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4800641699388208, 0.4800641699388208, 0.6770607100804125], 
reward next is 0.3229, 
noisyNet noise sample is [array([2.0862668], dtype=float32), -1.1589667]. 
=============================================
[2019-03-23 12:56:11,536] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.2477991e-08 1.0000000e+00 6.2512056e-24 8.5112579e-19 2.2830412e-22], sum to 1.0000
[2019-03-23 12:56:11,544] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9692
[2019-03-23 12:56:11,549] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 65.33333333333334, 1.0, 2.0, 0.2505491779891404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 272044.3794841779, 272044.3794841781, 83485.27817849646], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1995600.0000, 
sim time next is 1996200.0000, 
raw observation next is [18.0, 66.0, 1.0, 2.0, 0.2506293931282528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 272131.500834981, 272131.5008349807, 83988.19452268779], 
processed observation next is [0.0, 0.08695652173913043, 0.45454545454545453, 0.66, 1.0, 1.0, 0.06328674141031596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10078944475369665, 0.10078944475369656, 0.20484925493338485], 
reward next is 0.7952, 
noisyNet noise sample is [array([-2.244154], dtype=float32), -2.949341]. 
=============================================
[2019-03-23 12:56:12,135] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.2410339e-13 1.0000000e+00 4.3037944e-27 4.0525979e-20 1.3128342e-26], sum to 1.0000
[2019-03-23 12:56:12,147] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2465
[2019-03-23 12:56:12,153] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 70.0, 1.0, 2.0, 0.2453434705860926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 266390.5142771441, 266390.5142771438, 83659.14641545272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1999800.0000, 
sim time next is 2000400.0000, 
raw observation next is [17.33333333333333, 70.66666666666667, 1.0, 2.0, 0.243101222386625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 263955.2518479449, 263955.2518479446, 82961.11540864102], 
processed observation next is [0.0, 0.13043478260869565, 0.42424242424242403, 0.7066666666666667, 1.0, 1.0, 0.05387652798328122, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09776120438812774, 0.09776120438812762, 0.2023441839235147], 
reward next is 0.7977, 
noisyNet noise sample is [array([0.37156865], dtype=float32), -0.14582361]. 
=============================================
[2019-03-23 12:56:14,258] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.8027369e-13 1.0000000e+00 5.0204843e-28 4.5328956e-21 8.6415996e-26], sum to 1.0000
[2019-03-23 12:56:14,270] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2990
[2019-03-23 12:56:14,282] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 47.0, 1.0, 2.0, 0.3227681497914192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 353804.1244515233, 353804.124451523, 113912.182856772], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2048400.0000, 
sim time next is 2049000.0000, 
raw observation next is [23.86666666666667, 47.33333333333334, 1.0, 2.0, 0.3208288661562785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 351415.6619376311, 351415.6619376308, 113677.3886475386], 
processed observation next is [0.0, 0.7391304347826086, 0.7212121212121214, 0.47333333333333344, 1.0, 1.0, 0.15103608269534807, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1301539488657893, 0.13015394886578918, 0.27726192353058193], 
reward next is 0.7227, 
noisyNet noise sample is [array([1.8010238], dtype=float32), 0.9890308]. 
=============================================
[2019-03-23 12:56:14,299] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[73.18268 ]
 [73.170235]
 [73.17134 ]
 [73.16853 ]
 [73.17239 ]], R is [[73.18161774]
 [73.17196655]
 [73.162323  ]
 [73.15259552]
 [73.14279175]].
[2019-03-23 12:56:19,151] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.6866058e-13 1.0000000e+00 8.7331416e-31 5.8416759e-24 3.0218057e-29], sum to 1.0000
[2019-03-23 12:56:19,160] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1813
[2019-03-23 12:56:19,163] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 58.66666666666667, 1.0, 2.0, 0.4034230153898311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 457021.5594731956, 457021.5594731959, 126577.4475576583], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2140800.0000, 
sim time next is 2141400.0000, 
raw observation next is [24.33333333333333, 59.83333333333334, 1.0, 2.0, 0.4009151288993168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 453794.759199612, 453794.759199612, 126094.090147187], 
processed observation next is [0.0, 0.782608695652174, 0.7424242424242422, 0.5983333333333334, 1.0, 1.0, 0.25114391112414597, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16807213303689333, 0.16807213303689333, 0.30754656133460245], 
reward next is 0.6925, 
noisyNet noise sample is [array([-0.89901495], dtype=float32), -1.0372669]. 
=============================================
[2019-03-23 12:56:23,674] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.6769279e-11 1.0000000e+00 5.4832516e-30 5.1909643e-22 1.2979976e-29], sum to 1.0000
[2019-03-23 12:56:23,681] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2526
[2019-03-23 12:56:23,686] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 75.5, 1.0, 2.0, 0.3984506541093009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 449669.5693606709, 449669.5693606712, 125072.5406264556], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2226600.0000, 
sim time next is 2227200.0000, 
raw observation next is [21.33333333333334, 76.33333333333334, 1.0, 2.0, 0.3950011879531071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 445575.8105077669, 445575.8105077669, 124649.2012198164], 
processed observation next is [1.0, 0.782608695652174, 0.6060606060606063, 0.7633333333333334, 1.0, 1.0, 0.24375148494138388, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1650280779658396, 0.1650280779658396, 0.3040224419995522], 
reward next is 0.6960, 
noisyNet noise sample is [array([0.28891334], dtype=float32), -0.83963186]. 
=============================================
[2019-03-23 12:56:24,541] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3487751e-10 1.0000000e+00 6.5569479e-27 4.8020187e-19 4.8822386e-26], sum to 1.0000
[2019-03-23 12:56:24,554] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3829
[2019-03-23 12:56:24,557] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 86.33333333333334, 1.0, 2.0, 0.3731138857119658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 417789.6144477095, 417789.6144477095, 121146.2303001943], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2234400.0000, 
sim time next is 2235000.0000, 
raw observation next is [19.16666666666667, 87.16666666666667, 1.0, 2.0, 0.3703481130396409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 414353.4398925584, 414353.4398925584, 120758.2120106526], 
processed observation next is [1.0, 0.8695652173913043, 0.5075757575757578, 0.8716666666666667, 1.0, 1.0, 0.21293514129955107, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15346423699724385, 0.15346423699724385, 0.29453222441622584], 
reward next is 0.7055, 
noisyNet noise sample is [array([1.2446527], dtype=float32), -0.74100715]. 
=============================================
[2019-03-23 12:56:24,582] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[71.70095 ]
 [71.67732 ]
 [71.72444 ]
 [71.747734]
 [71.701004]], R is [[71.730896  ]
 [71.71810913]
 [71.70427704]
 [71.68959045]
 [71.67440033]].
[2019-03-23 12:56:25,782] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.6366780e-09 1.0000000e+00 1.2058303e-22 4.7327175e-17 2.4640765e-23], sum to 1.0000
[2019-03-23 12:56:25,794] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0720
[2019-03-23 12:56:25,797] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2207068479439273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 239633.8236339515, 239633.8236339518, 77314.30068432525], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2257200.0000, 
sim time next is 2257800.0000, 
raw observation next is [14.0, 92.00000000000001, 1.0, 2.0, 0.2184436015834239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 237175.8907858368, 237175.8907858365, 76334.57133923317], 
processed observation next is [1.0, 0.13043478260869565, 0.2727272727272727, 0.9200000000000002, 1.0, 1.0, 0.02305450197927987, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08784292251327289, 0.08784292251327278, 0.18618188131520286], 
reward next is 0.8138, 
noisyNet noise sample is [array([1.0856028], dtype=float32), -0.17185494]. 
=============================================
[2019-03-23 12:56:26,860] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.6866434e-12 1.0000000e+00 5.9647218e-29 2.5080819e-21 2.7766695e-29], sum to 1.0000
[2019-03-23 12:56:26,868] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4841
[2019-03-23 12:56:26,871] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 49.0, 1.0, 2.0, 0.4650070331718907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 505022.002964083, 505022.002964083, 103737.6719687098], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2294400.0000, 
sim time next is 2295000.0000, 
raw observation next is [20.0, 49.0, 1.0, 2.0, 0.4948099645601208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 537407.439777597, 537407.4397775967, 107234.946901141], 
processed observation next is [1.0, 0.5652173913043478, 0.5454545454545454, 0.49, 1.0, 1.0, 0.36851245570015095, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1990397925102211, 0.19903979251022103, 0.2615486509783927], 
reward next is 0.7385, 
noisyNet noise sample is [array([1.5532619], dtype=float32), -0.4431182]. 
=============================================
[2019-03-23 12:56:26,892] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[82.107376]
 [82.15164 ]
 [82.17956 ]
 [82.19201 ]
 [82.057495]], R is [[81.90552521]
 [81.83345032]
 [81.77523804]
 [81.71868134]
 [81.67921448]].
[2019-03-23 12:56:30,465] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 12:56:30,469] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:56:30,472] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:56:30,472] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:56:30,473] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:56:30,474] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:56:30,475] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:56:30,475] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:56:30,477] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:56:30,477] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:56:30,479] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:56:30,487] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run12
[2019-03-23 12:56:30,515] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run12
[2019-03-23 12:56:30,516] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run12
[2019-03-23 12:56:30,568] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run12
[2019-03-23 12:56:30,593] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run12
[2019-03-23 12:56:42,631] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.03016972], dtype=float32), 0.12325299]
[2019-03-23 12:56:42,635] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.001109055, 98.424555395, 1.0, 2.0, 0.3035130512216698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 329550.3357912557, 329550.3357912553, 115733.6756589987]
[2019-03-23 12:56:42,635] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:56:42,638] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.2891061e-11 1.0000000e+00 4.3227801e-28 1.9814326e-20 3.2351821e-27], sampled 0.8184021157135924
[2019-03-23 12:56:47,693] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.03016972], dtype=float32), 0.12325299]
[2019-03-23 12:56:47,696] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.1, 57.0, 1.0, 2.0, 0.4796171270365514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 547225.4196311956, 547225.4196311956, 142834.0613977538]
[2019-03-23 12:56:47,697] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:56:47,700] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.07339415e-11 1.00000000e+00 6.34563643e-29 4.96449166e-21
 5.02360722e-28], sampled 0.7321223879448653
[2019-03-23 12:56:55,860] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.03016972], dtype=float32), 0.12325299]
[2019-03-23 12:56:55,861] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.6597436, 78.96968789, 1.0, 2.0, 0.2865712900927783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 311150.4405728519, 311150.4405728519, 94518.53038594141]
[2019-03-23 12:56:55,862] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:56:55,866] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.7687676e-11 1.0000000e+00 1.5328509e-27 4.9317830e-20 1.1056944e-26], sampled 0.15101816719901184
[2019-03-23 12:57:19,363] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.03016972], dtype=float32), 0.12325299]
[2019-03-23 12:57:19,364] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.17303614, 98.74804613, 1.0, 2.0, 0.4324068733260564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 493044.8423749469, 493044.8423749469, 136689.7810336551]
[2019-03-23 12:57:19,366] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:57:19,369] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.3765171e-11 1.0000000e+00 1.1580280e-27 4.0317197e-20 8.4175857e-27], sampled 0.849708119914014
[2019-03-23 12:57:19,776] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.03016972], dtype=float32), 0.12325299]
[2019-03-23 12:57:19,778] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.9, 56.33333333333334, 1.0, 2.0, 0.5854498835469596, 0.0, 2.0, 0.0, 1.0, 2.0, 0.91318488174531, 7.003087992785849, 6.9112, 95.55305241472594, 1211831.789157954, 1174955.040755963, 271007.2242004574]
[2019-03-23 12:57:19,780] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:57:19,782] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.6536828e-11 1.0000000e+00 6.3155494e-28 2.5997495e-20 4.6779482e-27], sampled 0.2614852325368473
[2019-03-23 12:57:19,783] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1211831.789157954 W.
[2019-03-23 12:57:30,409] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.03016972], dtype=float32), 0.12325299]
[2019-03-23 12:57:30,411] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.09732591666667, 75.42458496666667, 1.0, 2.0, 0.3248504817147729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 352725.0259719823, 352725.0259719823, 108724.0536717552]
[2019-03-23 12:57:30,412] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:57:30,415] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.9686261e-11 1.0000000e+00 1.7475615e-27 5.4196867e-20 1.2559593e-26], sampled 0.9511672200509654
[2019-03-23 12:58:04,522] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.03016972], dtype=float32), 0.12325299]
[2019-03-23 12:58:04,523] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.807995775, 82.061526055, 1.0, 2.0, 0.4293889894561267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 488600.3363605128, 488600.3363605125, 135075.0586301186]
[2019-03-23 12:58:04,525] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:58:04,529] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.8459276e-11 1.0000000e+00 2.5077572e-28 1.3376290e-20 1.9077293e-27], sampled 0.05188975304875054
[2019-03-23 12:58:10,151] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 12:58:10,154] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 12:58:10,270] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 12:58:10,347] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1389 1656177241.5752 80.0000
[2019-03-23 12:58:10,491] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 12:58:11,508] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 275000, evaluation results [275000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.138916442502, 1656177241.575227, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 12:58:12,677] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0438487e-09 1.0000000e+00 3.8085005e-28 1.6910901e-19 8.3816705e-26], sum to 1.0000
[2019-03-23 12:58:12,685] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4879
[2019-03-23 12:58:12,691] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 53.0, 1.0, 2.0, 0.2924775184437781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 317584.7151102907, 317584.715110291, 95691.59435445584], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2399400.0000, 
sim time next is 2400000.0000, 
raw observation next is [21.0, 53.0, 1.0, 2.0, 0.2901942914904586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 315104.685516066, 315104.6855160663, 95456.89653693823], 
processed observation next is [1.0, 0.782608695652174, 0.5909090909090909, 0.53, 1.0, 1.0, 0.11274286436307325, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11670543908002444, 0.11670543908002456, 0.23282169887058107], 
reward next is 0.7672, 
noisyNet noise sample is [array([-0.41083372], dtype=float32), -1.1831793]. 
=============================================
[2019-03-23 12:58:12,714] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[74.712845]
 [74.72939 ]
 [74.66671 ]
 [74.59709 ]
 [74.52699 ]], R is [[74.67164612]
 [74.69153595]
 [74.71083069]
 [74.73002625]
 [74.74904633]].
[2019-03-23 12:58:12,795] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.5640081e-10 1.0000000e+00 1.2018011e-25 1.2839696e-18 2.4882741e-25], sum to 1.0000
[2019-03-23 12:58:12,802] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8401
[2019-03-23 12:58:12,806] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666667, 49.0, 1.0, 2.0, 0.5281241436045295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 573610.937584163, 573610.937584163, 111508.6633198299], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2376600.0000, 
sim time next is 2377200.0000, 
raw observation next is [20.33333333333334, 49.0, 1.0, 2.0, 0.4354473516899277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 472903.0253598017, 472903.0253598019, 102695.8815706159], 
processed observation next is [1.0, 0.5217391304347826, 0.5606060606060609, 0.49, 1.0, 1.0, 0.2943091896124096, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1751492686517784, 0.1751492686517785, 0.25047775992833143], 
reward next is 0.7495, 
noisyNet noise sample is [array([0.33416936], dtype=float32), -1.013934]. 
=============================================
[2019-03-23 12:58:14,908] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.1570391e-10 1.0000000e+00 1.2316079e-30 7.9686008e-21 3.6941020e-27], sum to 1.0000
[2019-03-23 12:58:14,918] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3177
[2019-03-23 12:58:14,922] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 88.00000000000001, 1.0, 2.0, 0.2494616238217112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 270863.1926702723, 270863.1926702723, 81933.81684688859], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2445000.0000, 
sim time next is 2445600.0000, 
raw observation next is [15.0, 88.0, 1.0, 2.0, 0.2484460541342911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 269760.1904085164, 269760.1904085162, 82003.44420593925], 
processed observation next is [1.0, 0.30434782608695654, 0.3181818181818182, 0.88, 1.0, 1.0, 0.06055756766786387, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09991118163278384, 0.09991118163278379, 0.20000840050229085], 
reward next is 0.8000, 
noisyNet noise sample is [array([-0.3596538], dtype=float32), 0.87912166]. 
=============================================
[2019-03-23 12:58:23,864] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5213544e-12 1.0000000e+00 3.9704130e-26 3.5186253e-18 8.0709779e-25], sum to 1.0000
[2019-03-23 12:58:23,872] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3482
[2019-03-23 12:58:23,877] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 80.0, 1.0, 2.0, 0.2757249109181012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 299388.4113873739, 299388.4113873739, 99116.31722033325], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2593800.0000, 
sim time next is 2594400.0000, 
raw observation next is [17.43333333333333, 82.66666666666667, 1.0, 2.0, 0.2831164596114522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 307416.8606169726, 307416.8606169729, 104390.0557016533], 
processed observation next is [0.0, 0.0, 0.42878787878787866, 0.8266666666666667, 1.0, 1.0, 0.10389557451431525, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11385809652480468, 0.11385809652480477, 0.25460989195525197], 
reward next is 0.7454, 
noisyNet noise sample is [array([0.9278902], dtype=float32), 0.21667054]. 
=============================================
[2019-03-23 12:58:25,137] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.6277997e-10 1.0000000e+00 8.3610366e-27 3.1982132e-18 1.4843645e-27], sum to 1.0000
[2019-03-23 12:58:25,146] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7129
[2019-03-23 12:58:25,150] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.26666666666667, 92.0, 1.0, 2.0, 0.2857372249759391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 310263.4788022421, 310263.4788022424, 102646.2534971646], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2604000.0000, 
sim time next is 2604600.0000, 
raw observation next is [16.2, 94.0, 1.0, 2.0, 0.2892572694090944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 314086.9005202745, 314086.9005202745, 105900.0223412015], 
processed observation next is [0.0, 0.13043478260869565, 0.3727272727272727, 0.94, 1.0, 1.0, 0.111571586761368, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11632848167417573, 0.11632848167417573, 0.25829273741756464], 
reward next is 0.7417, 
noisyNet noise sample is [array([0.3841969], dtype=float32), -1.5832032]. 
=============================================
[2019-03-23 12:58:26,894] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.0355680e-11 1.0000000e+00 3.7357871e-23 1.6794172e-17 1.2920297e-22], sum to 1.0000
[2019-03-23 12:58:26,901] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7128
[2019-03-23 12:58:26,905] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 56.0, 1.0, 2.0, 0.368705396493871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 413360.4819946928, 413360.4819946925, 121015.7456791246], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2666400.0000, 
sim time next is 2667000.0000, 
raw observation next is [24.0, 56.5, 1.0, 2.0, 0.3703278239976789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 415576.4658791418, 415576.4658791421, 121343.0747570348], 
processed observation next is [0.0, 0.8695652173913043, 0.7272727272727273, 0.565, 1.0, 1.0, 0.2129097799970986, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15391720958486735, 0.15391720958486746, 0.2959587189195971], 
reward next is 0.7040, 
noisyNet noise sample is [array([-0.17617519], dtype=float32), 1.9489408]. 
=============================================
[2019-03-23 12:58:26,928] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[59.373474]
 [59.382767]
 [59.393944]
 [59.39556 ]
 [59.390915]], R is [[59.46876907]
 [59.57891846]
 [59.68941116]
 [59.80009842]
 [59.91046143]].
[2019-03-23 12:58:35,863] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.9717743e-06 9.9999797e-01 9.3194156e-14 1.2559263e-10 1.4306801e-12], sum to 1.0000
[2019-03-23 12:58:35,871] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4681
[2019-03-23 12:58:35,881] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1143188.309911156 W.
[2019-03-23 12:58:35,885] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.83333333333334, 58.66666666666666, 1.0, 2.0, 0.9972127347241252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.932857027763682, 6.9112, 77.32839497513098, 1143188.309911156, 1136154.556484187, 220767.3582347501], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2811000.0000, 
sim time next is 2811600.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.3409058636145582, 1.0, 1.0, 0.3409058636145582, 1.0, 1.0, 0.6901916600132381, 6.911199999999999, 6.9112, 77.3421103, 1157796.460606187, 1157796.460606188, 277689.5535798047], 
processed observation next is [1.0, 0.5652173913043478, 0.9090909090909091, 0.58, 1.0, 1.0, 0.17613232951819774, 1.0, 0.5, 0.17613232951819774, 1.0, 0.5, 0.5574166571617687, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.42881350392821743, 0.4288135039282178, 0.6772915940970847], 
reward next is 0.3227, 
noisyNet noise sample is [array([-0.83823943], dtype=float32), -0.83577514]. 
=============================================
[2019-03-23 12:58:36,797] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.6808273e-11 1.0000000e+00 2.3656045e-24 6.4709460e-20 1.6718959e-22], sum to 1.0000
[2019-03-23 12:58:36,805] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3508
[2019-03-23 12:58:36,807] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 85.5, 1.0, 2.0, 0.5635644771587426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 641932.2244847708, 641932.2244847706, 145977.9308283369], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2863800.0000, 
sim time next is 2864400.0000, 
raw observation next is [21.33333333333334, 86.33333333333334, 1.0, 2.0, 0.5194618011662034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 591519.8802593278, 591519.8802593278, 140669.4037643631], 
processed observation next is [1.0, 0.13043478260869565, 0.6060606060606063, 0.8633333333333334, 1.0, 1.0, 0.3993272514577543, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21908143713308437, 0.21908143713308437, 0.34309610674234897], 
reward next is 0.6569, 
noisyNet noise sample is [array([0.17499338], dtype=float32), 1.3420507]. 
=============================================
[2019-03-23 12:58:36,951] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.8351807e-10 1.0000000e+00 1.8260181e-24 1.9459724e-19 3.9974819e-25], sum to 1.0000
[2019-03-23 12:58:36,966] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4440
[2019-03-23 12:58:36,970] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.5, 51.5, 1.0, 2.0, 0.4565262513521146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 520864.5343991533, 520864.5343991533, 136546.7794300968], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2827800.0000, 
sim time next is 2828400.0000, 
raw observation next is [28.33333333333333, 51.33333333333334, 1.0, 2.0, 0.4550417816493339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 519225.6154865143, 519225.6154865143, 136015.0885505168], 
processed observation next is [1.0, 0.7391304347826086, 0.924242424242424, 0.5133333333333334, 1.0, 1.0, 0.31880222706166733, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19230578351352381, 0.19230578351352381, 0.3317441184158947], 
reward next is 0.6683, 
noisyNet noise sample is [array([0.66180193], dtype=float32), -0.6770567]. 
=============================================
[2019-03-23 12:58:38,455] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.6547829e-11 1.0000000e+00 2.3168416e-25 3.7329562e-21 9.2602764e-24], sum to 1.0000
[2019-03-23 12:58:38,462] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8204
[2019-03-23 12:58:38,469] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 88.0, 1.0, 2.0, 0.4680740411078276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 534034.9906280726, 534034.9906280726, 136783.0306115273], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2876400.0000, 
sim time next is 2877000.0000, 
raw observation next is [22.16666666666667, 87.16666666666667, 1.0, 2.0, 0.5155068651616876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 588231.9426273059, 588231.9426273062, 142348.6075335459], 
processed observation next is [1.0, 0.30434782608695654, 0.6439393939393941, 0.8716666666666667, 1.0, 1.0, 0.3943835814521095, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21786368245455773, 0.21786368245455787, 0.34719172569157536], 
reward next is 0.6528, 
noisyNet noise sample is [array([-2.1586747], dtype=float32), -0.12730938]. 
=============================================
[2019-03-23 12:58:38,499] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[62.563953]
 [62.58424 ]
 [62.604233]
 [62.61154 ]
 [62.622772]], R is [[62.50284195]
 [62.54419708]
 [62.58713531]
 [62.63235855]
 [62.67944336]].
[2019-03-23 12:58:40,393] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7387987e-04 9.9982613e-01 4.0508397e-10 3.1683985e-08 7.4897888e-10], sum to 1.0000
[2019-03-23 12:58:40,401] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6658
[2019-03-23 12:58:40,406] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1849113.09704251 W.
[2019-03-23 12:58:40,410] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 62.66666666666667, 1.0, 2.0, 0.6082450004141547, 1.0, 2.0, 0.5479109371486847, 1.0, 2.0, 0.9865530188920543, 6.911199999999999, 6.9112, 77.3421103, 1849113.09704251, 1849113.09704251, 376172.2387432312], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2904600.0000, 
sim time next is 2905200.0000, 
raw observation next is [29.0, 62.0, 1.0, 2.0, 0.783819293647264, 1.0, 2.0, 0.783819293647264, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1763378.214928803, 1763378.214928803, 319363.5660589769], 
processed observation next is [1.0, 0.6521739130434783, 0.9545454545454546, 0.62, 1.0, 1.0, 0.7297741170590799, 1.0, 1.0, 0.7297741170590799, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.6531030425662233, 0.6531030425662233, 0.7789355269731144], 
reward next is 0.2211, 
noisyNet noise sample is [array([-1.5265995], dtype=float32), -2.179489]. 
=============================================
[2019-03-23 12:58:44,725] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.3858470e-06 9.9999356e-01 8.7164905e-13 1.2217117e-09 2.2456447e-13], sum to 1.0000
[2019-03-23 12:58:44,740] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0031
[2019-03-23 12:58:44,747] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1342514.609525732 W.
[2019-03-23 12:58:44,752] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 55.5, 1.0, 2.0, 0.5913614645661381, 1.0, 1.0, 0.5913614645661381, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1342514.609525732, 1342514.609525732, 255979.7466922077], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2991000.0000, 
sim time next is 2991600.0000, 
raw observation next is [28.0, 55.0, 1.0, 2.0, 0.5613396721738487, 1.0, 2.0, 0.5613396721738487, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1274238.562304428, 1274238.562304428, 247948.1245525803], 
processed observation next is [1.0, 0.6521739130434783, 0.9090909090909091, 0.55, 1.0, 1.0, 0.4516745902173109, 1.0, 1.0, 0.4516745902173109, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4719402082608993, 0.4719402082608993, 0.6047515232989763], 
reward next is 0.3952, 
noisyNet noise sample is [array([0.15997039], dtype=float32), 0.8198122]. 
=============================================
[2019-03-23 12:58:45,208] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7408691e-07 9.9999988e-01 5.7425135e-17 4.9522899e-14 2.9239511e-17], sum to 1.0000
[2019-03-23 12:58:45,216] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4805
[2019-03-23 12:58:45,219] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 69.0, 1.0, 2.0, 0.454348496183279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517677.7234529338, 517677.7234529338, 133990.554270101], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3009600.0000, 
sim time next is 3010200.0000, 
raw observation next is [23.83333333333333, 69.66666666666667, 1.0, 2.0, 0.4490574281481369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 511469.385222715, 511469.3852227147, 133222.1915452572], 
processed observation next is [1.0, 0.8695652173913043, 0.7196969696969695, 0.6966666666666668, 1.0, 1.0, 0.31132178518517106, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18943310563804258, 0.18943310563804247, 0.32493217450062734], 
reward next is 0.6751, 
noisyNet noise sample is [array([1.066637], dtype=float32), -0.19362624]. 
=============================================
[2019-03-23 12:58:50,584] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3769432e-08 1.0000000e+00 4.8280201e-22 3.0550559e-16 1.7043379e-22], sum to 1.0000
[2019-03-23 12:58:50,592] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4085
[2019-03-23 12:58:50,596] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 86.0, 1.0, 2.0, 0.5477144383820408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 622356.1242882697, 622356.1242882697, 149718.7760765119], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3097800.0000, 
sim time next is 3098400.0000, 
raw observation next is [24.0, 87.0, 1.0, 2.0, 0.5514945123483702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 626132.3087438502, 626132.3087438504, 150452.4978109767], 
processed observation next is [1.0, 0.8695652173913043, 0.7272727272727273, 0.87, 1.0, 1.0, 0.43936814043546274, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23190085509031488, 0.23190085509031497, 0.3669573117340895], 
reward next is 0.6330, 
noisyNet noise sample is [array([0.3882152], dtype=float32), 0.8166188]. 
=============================================
[2019-03-23 12:58:51,056] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3492493e-09 1.0000000e+00 9.2107025e-25 9.4519268e-17 4.0332323e-25], sum to 1.0000
[2019-03-23 12:58:51,063] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4747
[2019-03-23 12:58:51,070] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 72.0, 1.0, 2.0, 0.5680551596748524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 643650.9046185766, 643650.9046185766, 153122.6757367471], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3090600.0000, 
sim time next is 3091200.0000, 
raw observation next is [26.33333333333334, 72.66666666666666, 1.0, 2.0, 0.563315323645273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 638532.9432765454, 638532.9432765451, 152405.0113364428], 
processed observation next is [1.0, 0.782608695652174, 0.8333333333333336, 0.7266666666666666, 1.0, 1.0, 0.45414415455659124, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2364936826950168, 0.23649368269501672, 0.37171953984498246], 
reward next is 0.6283, 
noisyNet noise sample is [array([-0.625331], dtype=float32), -0.10108969]. 
=============================================
[2019-03-23 12:58:53,609] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.8109503e-07 9.9999976e-01 1.5882827e-16 8.1805413e-12 3.8715248e-16], sum to 1.0000
[2019-03-23 12:58:53,614] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7513
[2019-03-23 12:58:53,621] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666666, 73.66666666666667, 1.0, 2.0, 0.4603815906748029, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 525260.4093256887, 525260.4093256891, 135969.1072347617], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3172800.0000, 
sim time next is 3173400.0000, 
raw observation next is [23.5, 73.5, 1.0, 2.0, 0.438208371423839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 499554.032700329, 499554.0327003293, 132708.971048233], 
processed observation next is [1.0, 0.7391304347826086, 0.7045454545454546, 0.735, 1.0, 1.0, 0.29776046427979874, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18502001211123295, 0.1850200121112331, 0.3236804171908122], 
reward next is 0.6763, 
noisyNet noise sample is [array([-0.17919204], dtype=float32), 1.1313787]. 
=============================================
[2019-03-23 12:58:53,928] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.1255396e-07 9.9999905e-01 1.5275594e-14 1.5908938e-10 6.2595803e-15], sum to 1.0000
[2019-03-23 12:58:53,934] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2677
[2019-03-23 12:58:53,941] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1207948.237621611 W.
[2019-03-23 12:58:53,945] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.33333333333333, 78.33333333333334, 1.0, 2.0, 0.9967911922038718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.132055052648771, 6.9112, 77.32802522657404, 1207948.237621611, 1136219.440274521, 220244.5988299962], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3158400.0000, 
sim time next is 3159000.0000, 
raw observation next is [24.5, 76.0, 1.0, 2.0, 0.5808594928967988, 1.0, 1.0, 0.5808594928967988, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32833072970882, 1318721.147401854, 1318721.147401854, 253100.2009523792], 
processed observation next is [1.0, 0.5652173913043478, 0.75, 0.76, 1.0, 1.0, 0.4760743661209985, 1.0, 0.5, 0.4760743661209985, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084279403372202, 0.4884152397784644, 0.4884152397784644, 0.6173175632984859], 
reward next is 0.3827, 
noisyNet noise sample is [array([-0.8811522], dtype=float32), 1.2531989]. 
=============================================
[2019-03-23 12:58:53,957] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[34.87929 ]
 [35.11627 ]
 [34.768917]
 [34.393513]
 [34.102596]], R is [[34.07203674]
 [33.73131561]
 [33.91485596]
 [34.07562637]
 [34.25122833]].
[2019-03-23 12:59:00,764] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 12:59:00,765] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:59:00,766] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:59:00,767] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:59:00,769] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:59:00,771] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:59:00,771] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:59:00,773] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:59:00,775] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:59:00,766] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:59:00,776] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:59:00,781] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run13
[2019-03-23 12:59:00,781] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run13
[2019-03-23 12:59:00,827] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run13
[2019-03-23 12:59:00,828] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run13
[2019-03-23 12:59:00,886] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run13
[2019-03-23 12:59:11,393] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.03256736], dtype=float32), 0.12929866]
[2019-03-23 12:59:11,394] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.33996340333334, 82.97453552666667, 1.0, 2.0, 0.5054774199742976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 576450.7470401656, 576450.7470401656, 146955.801658326]
[2019-03-23 12:59:11,395] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:59:11,397] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.76363871e-11 1.00000000e+00 1.52873405e-27 3.74392479e-20
 7.52557896e-28], sampled 0.43336061205255394
[2019-03-23 12:59:18,108] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.03256736], dtype=float32), 0.12929866]
[2019-03-23 12:59:18,110] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.9, 58.0, 1.0, 2.0, 0.4857061090472665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 554175.1233596011, 554175.1233596011, 143500.2987571237]
[2019-03-23 12:59:18,110] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:59:18,112] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.2468463e-11 1.0000000e+00 2.0784101e-27 4.6779115e-20 1.0274207e-27], sampled 0.13674469370896303
[2019-03-23 12:59:36,888] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.03256736], dtype=float32), 0.12929866]
[2019-03-23 12:59:36,889] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.78382754, 89.96431211, 1.0, 2.0, 0.4948220796520965, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8852657314802945, 7.038994334673591, 6.9112, 95.55291938187825, 1110474.804624065, 1059188.093238254, 253719.34667703]
[2019-03-23 12:59:36,890] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:59:36,892] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.3012624e-10 1.0000000e+00 3.5726580e-26 3.6859527e-19 1.8428459e-26], sampled 0.6267887233104529
[2019-03-23 12:59:36,893] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1110474.804624065 W.
[2019-03-23 12:59:40,460] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.03256736], dtype=float32), 0.12929866]
[2019-03-23 12:59:40,462] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [27.85455069333334, 55.02583255666667, 1.0, 2.0, 0.7523469293502644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 858525.5294904365, 858525.5294904362, 179705.2996223123]
[2019-03-23 12:59:40,462] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:59:40,464] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.4127306e-10 1.0000000e+00 4.4090191e-26 4.2837634e-19 2.2779126e-26], sampled 0.5040966928324463
[2019-03-23 12:59:45,591] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.03256736], dtype=float32), 0.12929866]
[2019-03-23 12:59:45,593] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.83333333333334, 62.33333333333334, 1.0, 2.0, 0.6007575175052173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 684983.2317021494, 684983.231702149, 159136.3099116358]
[2019-03-23 12:59:45,595] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:59:45,600] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.0083036e-11 1.0000000e+00 5.0155291e-27 8.8600653e-20 2.5118084e-27], sampled 0.8610529204283259
[2019-03-23 12:59:48,113] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.03256736], dtype=float32), 0.12929866]
[2019-03-23 12:59:48,115] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.21666666666667, 73.33333333333333, 1.0, 2.0, 0.3971836809958206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 449547.5997850222, 449547.5997850219, 130067.6749512528]
[2019-03-23 12:59:48,116] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:59:48,119] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.7805414e-11 1.0000000e+00 6.8083488e-27 1.1056899e-19 3.4227735e-27], sampled 0.4798981854519282
[2019-03-23 12:59:57,892] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.03256736], dtype=float32), 0.12929866]
[2019-03-23 12:59:57,893] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.73693956, 57.00424166, 1.0, 2.0, 0.7444828113220203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 849251.5529404959, 849251.5529404959, 176070.6803685873]
[2019-03-23 12:59:57,897] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:59:57,898] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.3616372e-10 1.0000000e+00 4.0119623e-26 3.9993092e-19 2.0691792e-26], sampled 0.7761889485533929
[2019-03-23 13:00:41,055] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 13:00:41,155] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 13:00:41,195] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 13:00:41,330] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 13:00:41,351] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 13:00:42,368] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 300000, evaluation results [300000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 13:00:42,863] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.7959406e-10 1.0000000e+00 2.1210379e-26 4.7287988e-18 7.3083995e-24], sum to 1.0000
[2019-03-23 13:00:42,869] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6836
[2019-03-23 13:00:42,873] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.66666666666667, 84.00000000000001, 1.0, 2.0, 0.244644049157948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 265630.8848745463, 265630.884874546, 82846.49488446089], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3298200.0000, 
sim time next is 3298800.0000, 
raw observation next is [15.33333333333333, 86.0, 1.0, 2.0, 0.2417763095402696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 262516.2953458139, 262516.2953458139, 81931.23795183752], 
processed observation next is [0.0, 0.17391304347826086, 0.3333333333333332, 0.86, 1.0, 1.0, 0.05222038692533699, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09722825753548664, 0.09722825753548664, 0.1998322876874086], 
reward next is 0.8002, 
noisyNet noise sample is [array([0.31873024], dtype=float32), 0.5478624]. 
=============================================
[2019-03-23 13:00:47,848] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.1233625e-07 9.9999964e-01 7.9552466e-18 3.9839255e-13 7.1987370e-18], sum to 1.0000
[2019-03-23 13:00:47,855] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0462
[2019-03-23 13:00:47,866] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1328490.235155176 W.
[2019-03-23 13:00:47,874] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.66666666666667, 57.33333333333334, 1.0, 2.0, 0.5857027964290901, 1.0, 2.0, 0.5857027964290901, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1328490.235155176, 1328490.235155176, 254900.2856091601], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3428400.0000, 
sim time next is 3429000.0000, 
raw observation next is [27.5, 58.5, 1.0, 2.0, 0.5921147033870658, 1.0, 2.0, 0.5921147033870658, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1342473.034359453, 1342473.034359453, 256864.153791336], 
processed observation next is [1.0, 0.6956521739130435, 0.8863636363636364, 0.585, 1.0, 1.0, 0.4901433792338323, 1.0, 1.0, 0.4901433792338323, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4972122349479456, 0.4972122349479456, 0.6264979360764292], 
reward next is 0.3735, 
noisyNet noise sample is [array([0.784022], dtype=float32), -0.8939669]. 
=============================================
[2019-03-23 13:00:47,890] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[51.336678]
 [50.602383]
 [50.098576]
 [49.895164]
 [48.991478]], R is [[51.17784882]
 [51.04436111]
 [50.53391647]
 [50.30101013]
 [50.1769104 ]].
[2019-03-23 13:00:50,724] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.08314872e-07 9.99999881e-01 1.05682025e-20 9.78658797e-16
 3.64156086e-21], sum to 1.0000
[2019-03-23 13:00:50,731] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2583
[2019-03-23 13:00:50,736] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 95.0, 1.0, 2.0, 0.5061850143396202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 577336.5339282692, 577336.5339282692, 142710.1965997812], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3484200.0000, 
sim time next is 3484800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5121555535231749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 584096.161508431, 584096.1615084307, 143509.2588899656], 
processed observation next is [1.0, 0.34782608695652173, 0.6363636363636364, 0.94, 1.0, 1.0, 0.39019444190396857, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21633191166978924, 0.21633191166978916, 0.35002258265845265], 
reward next is 0.6500, 
noisyNet noise sample is [array([0.5706393], dtype=float32), -0.49753135]. 
=============================================
[2019-03-23 13:01:01,112] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.7679608e-10 1.0000000e+00 2.6750011e-26 3.6069273e-22 1.0258743e-26], sum to 1.0000
[2019-03-23 13:01:01,125] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0371
[2019-03-23 13:01:01,129] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5384792081667601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 614407.5794771836, 614407.579477184, 146080.0115454008], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3643800.0000, 
sim time next is 3644400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5203347313852147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593690.5704783297, 593690.5704783297, 143901.8144030864], 
processed observation next is [1.0, 0.17391304347826086, 0.5909090909090909, 1.0, 1.0, 1.0, 0.4004184142315183, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21988539647345542, 0.21988539647345542, 0.35098003512947906], 
reward next is 0.6490, 
noisyNet noise sample is [array([-0.9943796], dtype=float32), 0.7967979]. 
=============================================
[2019-03-23 13:01:01,921] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4148381e-08 1.0000000e+00 8.9293262e-18 3.4143684e-16 5.0142704e-18], sum to 1.0000
[2019-03-23 13:01:01,931] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3878
[2019-03-23 13:01:01,935] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.83333333333334, 78.0, 1.0, 2.0, 0.4774223198009957, 1.0, 2.0, 0.4774223198009957, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1078442.053914197, 1078442.053914197, 228757.7244089389], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3669000.0000, 
sim time next is 3669600.0000, 
raw observation next is [24.66666666666667, 78.0, 1.0, 2.0, 0.9990163961877718, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.269480539475766, 6.9112, 77.3277525518693, 1252625.329167757, 1136264.207784681, 222564.6506662121], 
processed observation next is [1.0, 0.4782608695652174, 0.7575757575757578, 0.78, 1.0, 1.0, 0.9987704952347148, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0358280539475766, 0.0, 0.5084241388615472, 0.46393530709916925, 0.4208385954758078, 0.5428406113810051], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0650994], dtype=float32), -1.7181762]. 
=============================================
[2019-03-23 13:01:08,216] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.04104307e-13 1.00000000e+00 2.17999612e-31 3.61660554e-26
 3.38588523e-31], sum to 1.0000
[2019-03-23 13:01:08,226] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3375
[2019-03-23 13:01:08,238] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3443582258916563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 379023.5013814045, 379023.5013814045, 116052.0181713404], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3789000.0000, 
sim time next is 3789600.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3421249238091587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 376559.293360077, 376559.293360077, 115882.0099887087], 
processed observation next is [1.0, 0.8695652173913043, 0.45454545454545453, 0.88, 1.0, 1.0, 0.17765615476144836, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13946640494817666, 0.13946640494817666, 0.28263904875294804], 
reward next is 0.7174, 
noisyNet noise sample is [array([-1.3729604], dtype=float32), 0.09087314]. 
=============================================
[2019-03-23 13:01:14,733] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.0327275e-15 1.0000000e+00 7.1333787e-33 1.5179364e-28 5.2114907e-33], sum to 1.0000
[2019-03-23 13:01:14,744] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2815
[2019-03-23 13:01:14,751] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333334, 78.0, 1.0, 2.0, 0.2774804900362264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 301295.2498180958, 301295.2498180961, 100572.7365648761], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3900000.0000, 
sim time next is 3900600.0000, 
raw observation next is [17.75, 78.5, 1.0, 2.0, 0.2764803620803185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 300208.9507096658, 300208.9507096655, 100131.1771334588], 
processed observation next is [0.0, 0.13043478260869565, 0.4431818181818182, 0.785, 1.0, 1.0, 0.09560045260039812, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11118850026283918, 0.11118850026283907, 0.24422238325233853], 
reward next is 0.7558, 
noisyNet noise sample is [array([0.09934345], dtype=float32), -0.5392297]. 
=============================================
[2019-03-23 13:01:15,378] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.8516383e-13 1.0000000e+00 9.2649245e-35 4.3137015e-29 3.9861193e-34], sum to 1.0000
[2019-03-23 13:01:15,388] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0617
[2019-03-23 13:01:15,391] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 51.0, 1.0, 2.0, 0.321504929173512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 354521.8972500759, 354521.8972500759, 114615.1687457561], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3928800.0000, 
sim time next is 3929400.0000, 
raw observation next is [24.0, 50.0, 1.0, 2.0, 0.3233973292133498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 357310.5158367862, 357310.5158367862, 115028.8529905605], 
processed observation next is [0.0, 0.4782608695652174, 0.7272727272727273, 0.5, 1.0, 1.0, 0.15424666151668723, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1323372280876986, 0.1323372280876986, 0.28055817802575733], 
reward next is 0.7194, 
noisyNet noise sample is [array([1.2000388], dtype=float32), -1.0136346]. 
=============================================
[2019-03-23 13:01:25,695] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.5811246e-11 1.0000000e+00 1.5754734e-22 3.8022740e-20 1.0286263e-24], sum to 1.0000
[2019-03-23 13:01:25,704] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1323
[2019-03-23 13:01:25,708] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 76.33333333333334, 1.0, 2.0, 0.8084724691447917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 919927.1127592744, 919927.1127592744, 178315.8751536927], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4117200.0000, 
sim time next is 4117800.0000, 
raw observation next is [22.16666666666667, 77.16666666666666, 1.0, 2.0, 0.8102754225332143, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 921773.5151126343, 921773.5151126343, 178404.6132510246], 
processed observation next is [1.0, 0.6521739130434783, 0.6439393939393941, 0.7716666666666666, 1.0, 1.0, 0.7628442781665179, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.34139759818986454, 0.34139759818986454, 0.4351332030512795], 
reward next is 0.5649, 
noisyNet noise sample is [array([-0.82891655], dtype=float32), -0.94468236]. 
=============================================
[2019-03-23 13:01:26,652] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.5708920e-10 1.0000000e+00 5.9934666e-27 1.8163693e-23 3.1806542e-27], sum to 1.0000
[2019-03-23 13:01:26,659] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9324
[2019-03-23 13:01:26,662] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3768039860320676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 423008.5943892029, 423008.5943892029, 121972.9079534209], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4144800.0000, 
sim time next is 4145400.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3764359247952421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 422595.8794768703, 422595.8794768703, 121941.6820442742], 
processed observation next is [1.0, 1.0, 0.45454545454545453, 1.0, 1.0, 1.0, 0.22054490599405263, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15651699239884084, 0.15651699239884084, 0.2974187366933517], 
reward next is 0.7026, 
noisyNet noise sample is [array([-2.1120572], dtype=float32), -0.39018384]. 
=============================================
[2019-03-23 13:01:31,279] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 13:01:31,281] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:01:31,281] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:01:31,282] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:01:31,283] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:01:31,284] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:01:31,283] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:01:31,289] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:01:31,285] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:01:31,291] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:01:31,293] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:01:31,304] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run14
[2019-03-23 13:01:31,329] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run14
[2019-03-23 13:01:31,330] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run14
[2019-03-23 13:01:31,364] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run14
[2019-03-23 13:01:31,389] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run14
[2019-03-23 13:01:40,978] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.03470236], dtype=float32), 0.13360754]
[2019-03-23 13:01:40,979] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.33333333333334, 90.0, 1.0, 2.0, 0.4089775961919556, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 463991.6736636991, 463991.6736636991, 127565.7866444885]
[2019-03-23 13:01:40,980] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:01:40,983] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.6605796e-13 1.0000000e+00 7.5726550e-30 3.4062348e-25 6.5893842e-30], sampled 0.410182677154016
[2019-03-23 13:01:51,340] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.03470236], dtype=float32), 0.13360754]
[2019-03-23 13:01:51,342] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [8.0, 81.0, 1.0, 2.0, 0.3290618638575187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 357324.1714810968, 357324.1714810965, 77200.29902041587]
[2019-03-23 13:01:51,343] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:01:51,348] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.4849957e-12 1.0000000e+00 3.5678757e-27 6.0174878e-23 3.1864106e-27], sampled 0.8099401497028027
[2019-03-23 13:02:02,573] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.03470236], dtype=float32), 0.13360754]
[2019-03-23 13:02:02,574] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.36081031, 60.89953387, 1.0, 2.0, 0.3775667774317695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 424269.0796426921, 424269.0796426921, 126561.7475276026]
[2019-03-23 13:02:02,575] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:02:02,578] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.4222990e-13 1.0000000e+00 1.6420054e-30 9.4236221e-26 1.4202351e-30], sampled 0.7236825227086195
[2019-03-23 13:02:06,693] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.03470236], dtype=float32), 0.13360754]
[2019-03-23 13:02:06,694] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.1, 90.0, 1.0, 2.0, 0.4528215753711531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 515886.956987187, 515886.9569871866, 138140.2734766989]
[2019-03-23 13:02:06,694] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:02:06,696] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.0563274e-13 1.0000000e+00 1.1209129e-30 6.8371635e-26 9.6794004e-31], sampled 0.4551630141236609
[2019-03-23 13:02:26,108] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.03470236], dtype=float32), 0.13360754]
[2019-03-23 13:02:26,110] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.30110903666667, 95.92978615666668, 1.0, 2.0, 0.3251820038375756, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 353085.1008612608, 353085.1008612611, 117219.9886413756]
[2019-03-23 13:02:26,111] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:02:26,116] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.1317739e-13 1.0000000e+00 9.4821641e-30 4.1143186e-25 8.2574389e-30], sampled 0.16253326230858178
[2019-03-23 13:02:29,590] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.03470236], dtype=float32), 0.13360754]
[2019-03-23 13:02:29,591] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.5, 97.0, 1.0, 2.0, 0.4120981349033215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 467736.2835558052, 467736.2835558049, 128011.6820223534]
[2019-03-23 13:02:29,593] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:02:29,595] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.1450708e-13 1.0000000e+00 5.7623350e-30 2.7066996e-25 5.0080844e-30], sampled 0.43332398979581166
[2019-03-23 13:02:33,014] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.03470236], dtype=float32), 0.13360754]
[2019-03-23 13:02:33,015] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.91561399, 70.63678283, 1.0, 2.0, 0.4181096720765373, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 474512.8405115234, 474512.840511523, 132891.5013749018]
[2019-03-23 13:02:33,016] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:02:33,019] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.1495206e-13 1.0000000e+00 3.0325781e-30 1.5778346e-25 2.6285656e-30], sampled 0.9094024459499781
[2019-03-23 13:02:51,803] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.03470236], dtype=float32), 0.13360754]
[2019-03-23 13:02:51,804] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.04899090333333, 56.51300477666666, 1.0, 2.0, 0.3326845549892573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 361233.8765063196, 361233.8765063193, 113353.8352915699]
[2019-03-23 13:02:51,804] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:02:51,807] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.3441151e-12 1.0000000e+00 9.0083086e-29 2.7315330e-24 7.9229809e-29], sampled 0.0751500578736587
[2019-03-23 13:02:58,418] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.03470236], dtype=float32), 0.13360754]
[2019-03-23 13:02:58,420] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.12782245333333, 69.60501887, 1.0, 2.0, 0.4550137750472721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 518644.1477445215, 518644.1477445211, 138732.3971291999]
[2019-03-23 13:02:58,422] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:02:58,424] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0497265e-13 1.0000000e+00 2.3284147e-31 1.8240322e-26 1.9974266e-31], sampled 0.7440355569501694
[2019-03-23 13:03:11,092] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 13:03:11,122] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 13:03:11,212] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 13:03:11,347] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 13:03:11,373] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1361 1656178005.9856 80.0000
[2019-03-23 13:03:12,389] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 325000, evaluation results [325000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.136132309683, 1656178005.9856246, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 13:03:19,283] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.3038690e-07 9.9999952e-01 2.8489152e-17 2.0448890e-14 6.5855296e-17], sum to 1.0000
[2019-03-23 13:03:19,293] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6092
[2019-03-23 13:03:19,299] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1299040.402579334 W.
[2019-03-23 13:03:19,302] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 58.0, 1.0, 2.0, 0.6579825216497833, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9716750316453852, 6.911199999999999, 6.9112, 77.32846341566933, 1299040.402579334, 1299040.402579334, 280408.9091360795], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4360800.0000, 
sim time next is 4361400.0000, 
raw observation next is [27.0, 58.0, 1.0, 2.0, 0.7177879037718229, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9717643411178497, 6.911200000000001, 6.9112, 77.32846344336852, 1367334.08844725, 1367334.08844725, 289195.5758509251], 
processed observation next is [1.0, 0.4782608695652174, 0.8636363636363636, 0.58, 1.0, 1.0, 0.6472348797147787, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9596633444540712, 8.881784197001253e-17, 0.0, 0.5084288129195198, 0.5064200327582408, 0.5064200327582408, 0.7053550630510369], 
reward next is 0.2946, 
noisyNet noise sample is [array([0.11779197], dtype=float32), -0.68060285]. 
=============================================
[2019-03-23 13:03:20,775] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.8405624e-12 1.0000000e+00 6.1994373e-31 1.2036219e-26 2.0949537e-32], sum to 1.0000
[2019-03-23 13:03:20,781] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1408
[2019-03-23 13:03:20,784] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 84.0, 1.0, 2.0, 0.444736154132969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 506656.0683562321, 506656.0683562321, 132909.0572235334], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4411200.0000, 
sim time next is 4411800.0000, 
raw observation next is [21.75, 84.5, 1.0, 2.0, 0.4437408906411728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 505490.7058245658, 505490.7058245661, 132768.2244387925], 
processed observation next is [0.0, 0.043478260869565216, 0.625, 0.845, 1.0, 1.0, 0.30467611330146593, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18721877993502437, 0.18721877993502448, 0.32382493765559145], 
reward next is 0.6762, 
noisyNet noise sample is [array([-1.1562147], dtype=float32), 0.305513]. 
=============================================
[2019-03-23 13:03:21,566] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.8632725e-12 1.0000000e+00 1.3825292e-28 1.4448741e-24 1.3494158e-29], sum to 1.0000
[2019-03-23 13:03:21,574] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7081
[2019-03-23 13:03:21,582] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.4078062964738363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 462123.3719804597, 462123.3719804597, 127077.8129050841], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4428600.0000, 
sim time next is 4429200.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.4078241235968862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 462148.5021010289, 462148.5021010286, 127082.7944508396], 
processed observation next is [0.0, 0.2608695652173913, 0.5909090909090909, 0.83, 1.0, 1.0, 0.2597801544961077, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17116611188926997, 0.17116611188926983, 0.3099580352459502], 
reward next is 0.6900, 
noisyNet noise sample is [array([0.10558127], dtype=float32), -0.5013972]. 
=============================================
[2019-03-23 13:03:23,857] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.1698754e-12 1.0000000e+00 8.1266804e-25 1.7428601e-21 1.4112374e-23], sum to 1.0000
[2019-03-23 13:03:23,867] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3809
[2019-03-23 13:03:23,873] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 74.0, 1.0, 2.0, 0.468714417457864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 534800.426693026, 534800.426693026, 137007.194379862], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4444200.0000, 
sim time next is 4444800.0000, 
raw observation next is [24.0, 74.0, 1.0, 2.0, 0.470540942097966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 536885.8649978008, 536885.8649978008, 137208.9191908331], 
processed observation next is [0.0, 0.43478260869565216, 0.7272727272727273, 0.74, 1.0, 1.0, 0.33817617762245744, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19884661666585216, 0.19884661666585216, 0.33465590046544663], 
reward next is 0.6653, 
noisyNet noise sample is [array([1.8769814], dtype=float32), 1.5498822]. 
=============================================
[2019-03-23 13:03:25,199] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.9071987e-13 1.0000000e+00 4.8664387e-24 1.7467329e-22 3.0543661e-25], sum to 1.0000
[2019-03-23 13:03:25,211] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5712
[2019-03-23 13:03:25,215] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 79.66666666666667, 1.0, 2.0, 0.4634250647715579, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 528517.3448891325, 528517.3448891328, 135717.0529536879], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4479000.0000, 
sim time next is 4479600.0000, 
raw observation next is [22.66666666666667, 81.33333333333334, 1.0, 2.0, 0.464970878559911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 530345.4137109079, 530345.4137109079, 136021.4406025698], 
processed observation next is [0.0, 0.8695652173913043, 0.6666666666666669, 0.8133333333333335, 1.0, 1.0, 0.3312135981998887, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19642422730033626, 0.19642422730033626, 0.33175961122578], 
reward next is 0.6682, 
noisyNet noise sample is [array([-1.20787], dtype=float32), -1.4331336]. 
=============================================
[2019-03-23 13:03:28,320] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.2465142e-11 1.0000000e+00 7.1020981e-26 3.0347777e-22 1.6453246e-27], sum to 1.0000
[2019-03-23 13:03:28,330] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8342
[2019-03-23 13:03:28,335] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 61.0, 1.0, 2.0, 0.3943215681016103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 445805.3601626603, 445805.36016266, 125162.6470233369], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4554000.0000, 
sim time next is 4554600.0000, 
raw observation next is [24.0, 61.0, 1.0, 2.0, 0.3932398078147097, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 444580.5100977566, 444580.5100977569, 125063.3618424385], 
processed observation next is [0.0, 0.7391304347826086, 0.7272727272727273, 0.61, 1.0, 1.0, 0.24154975976838708, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1646594481843543, 0.1646594481843544, 0.30503258985960613], 
reward next is 0.6950, 
noisyNet noise sample is [array([-1.322965], dtype=float32), 0.4541299]. 
=============================================
[2019-03-23 13:03:31,320] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.1363440e-13 1.0000000e+00 8.0138407e-28 7.9028669e-24 6.2792546e-27], sum to 1.0000
[2019-03-23 13:03:31,325] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2231
[2019-03-23 13:03:31,329] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.16666666666667, 99.0, 1.0, 2.0, 0.2405923593367007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 261230.4386375508, 261230.4386375511, 82775.24033914524], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4593000.0000, 
sim time next is 4593600.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.2388323585815924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 259318.9550870409, 259318.9550870409, 82156.60981594167], 
processed observation next is [1.0, 0.17391304347826086, 0.2727272727272727, 1.0, 1.0, 1.0, 0.048540448226990496, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09604405743964478, 0.09604405743964478, 0.20038197516083334], 
reward next is 0.7996, 
noisyNet noise sample is [array([2.7983603], dtype=float32), -0.5941351]. 
=============================================
[2019-03-23 13:03:32,744] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.6354206e-13 1.0000000e+00 2.3927075e-29 2.3436959e-25 5.7480487e-28], sum to 1.0000
[2019-03-23 13:03:32,753] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3919
[2019-03-23 13:03:32,757] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 45.0, 1.0, 2.0, 0.3828546905462714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415762.1038161949, 415762.1038161949, 111201.534304881], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4625400.0000, 
sim time next is 4626000.0000, 
raw observation next is [23.0, 44.0, 1.0, 2.0, 0.3654362921210751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 396838.8269990796, 396838.8269990796, 107128.7522134045], 
processed observation next is [1.0, 0.5652173913043478, 0.6818181818181818, 0.44, 1.0, 1.0, 0.20679536515134384, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14697734333299245, 0.14697734333299245, 0.26128963954488904], 
reward next is 0.7387, 
noisyNet noise sample is [array([-1.9734522], dtype=float32), -1.2678705]. 
=============================================
[2019-03-23 13:03:32,770] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[66.75497 ]
 [66.33103 ]
 [65.889206]
 [65.46402 ]
 [65.16033 ]], R is [[67.22418976]
 [67.28072357]
 [67.32707214]
 [67.35952759]
 [67.38014984]].
[2019-03-23 13:03:36,624] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.0779310e-15 1.0000000e+00 3.2534814e-30 8.8370177e-26 1.6792012e-30], sum to 1.0000
[2019-03-23 13:03:36,633] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0631
[2019-03-23 13:03:36,636] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 74.5, 1.0, 2.0, 0.2208646604811851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 239805.2118108541, 239805.2118108544, 76778.70110008235], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4692600.0000, 
sim time next is 4693200.0000, 
raw observation next is [16.33333333333333, 73.66666666666667, 1.0, 2.0, 0.2297260991129582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 249429.0422820077, 249429.0422820074, 78556.82959801516], 
processed observation next is [1.0, 0.30434782608695654, 0.37878787878787856, 0.7366666666666667, 1.0, 1.0, 0.03715762389119772, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09238112677111396, 0.09238112677111385, 0.19160202340979307], 
reward next is 0.8084, 
noisyNet noise sample is [array([1.2664604], dtype=float32), -2.019918]. 
=============================================
[2019-03-23 13:03:37,892] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.389100e-14 1.000000e+00 4.536886e-31 9.356780e-26 9.769724e-32], sum to 1.0000
[2019-03-23 13:03:37,902] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8344
[2019-03-23 13:03:37,905] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.83333333333334, 55.16666666666666, 1.0, 2.0, 0.4695284251064857, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9268750384444574, 6.936853637317368, 6.9112, 77.3283998955273, 1070834.279040174, 1062502.509194115, 242162.721694093], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4723800.0000, 
sim time next is 4724400.0000, 
raw observation next is [25.66666666666667, 56.33333333333334, 1.0, 2.0, 0.805103005142546, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32844802803722, 916617.9945057184, 916617.9945057184, 178305.0379137529], 
processed observation next is [1.0, 0.6956521739130435, 0.8030303030303032, 0.5633333333333335, 1.0, 1.0, 0.7563787564281823, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084287115648796, 0.33948814611322903, 0.33948814611322903, 0.43489033637500707], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9208849], dtype=float32), 0.12784763]. 
=============================================
[2019-03-23 13:03:37,946] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.7413031e-12 1.0000000e+00 6.8126763e-30 5.9620301e-24 3.8893222e-29], sum to 1.0000
[2019-03-23 13:03:37,954] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0692
[2019-03-23 13:03:37,959] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1118384.134667444 W.
[2019-03-23 13:03:37,963] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.0, 61.0, 1.0, 2.0, 0.9815727710851953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1118384.134667444, 1118384.134667444, 208182.45259082], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4726800.0000, 
sim time next is 4727400.0000, 
raw observation next is [24.83333333333334, 61.66666666666667, 1.0, 2.0, 0.2018143537221594, 1.0, 1.0, 0.2018143537221594, 1.0, 1.0, 0.4062796849803957, 6.911199999999999, 6.9112, 77.3421103, 690863.3193216565, 690863.3193216567, 223029.1846040021], 
processed observation next is [1.0, 0.7391304347826086, 0.7651515151515155, 0.6166666666666667, 1.0, 1.0, 0.0022679421526992233, 1.0, 0.5, 0.0022679421526992233, 1.0, 0.5, 0.15182812140056529, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.25587530345246534, 0.25587530345246545, 0.5439736209853709], 
reward next is 0.4560, 
noisyNet noise sample is [array([0.71212876], dtype=float32), 0.8184534]. 
=============================================
[2019-03-23 13:03:38,455] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.9621138e-18 1.0000000e+00 7.0775656e-34 3.4491265e-30 1.9363776e-32], sum to 1.0000
[2019-03-23 13:03:38,465] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3310
[2019-03-23 13:03:38,473] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666667, 59.83333333333334, 1.0, 2.0, 0.9357874126233732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1065907.498787087, 1065907.498787087, 199858.9724463703], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4726200.0000, 
sim time next is 4726800.0000, 
raw observation next is [25.0, 61.0, 1.0, 2.0, 0.9815727650661717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1118384.134667392, 1118384.134667392, 208182.4595250523], 
processed observation next is [1.0, 0.7391304347826086, 0.7727272727272727, 0.61, 1.0, 1.0, 0.9769659563327145, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4142163461731081, 0.4142163461731081, 0.5077620964025666], 
reward next is 0.4922, 
noisyNet noise sample is [array([-1.1210097], dtype=float32), -0.0147570465]. 
=============================================
[2019-03-23 13:03:47,267] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.9290370e-13 1.0000000e+00 1.5175442e-26 7.1276791e-22 5.9806542e-27], sum to 1.0000
[2019-03-23 13:03:47,275] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0732
[2019-03-23 13:03:47,281] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 74.66666666666667, 1.0, 2.0, 0.4260505502798739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 484405.2937297414, 484405.2937297414, 130024.2489444241], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4907400.0000, 
sim time next is 4908000.0000, 
raw observation next is [22.33333333333334, 76.33333333333334, 1.0, 2.0, 0.422754148930917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 480434.0143689322, 480434.0143689322, 129509.3809257295], 
processed observation next is [1.0, 0.8260869565217391, 0.6515151515151518, 0.7633333333333334, 1.0, 1.0, 0.2784426861636462, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17793852384034528, 0.17793852384034528, 0.3158765388432427], 
reward next is 0.6841, 
noisyNet noise sample is [array([-1.0091974], dtype=float32), -1.6014926]. 
=============================================
[2019-03-23 13:03:47,299] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[60.298164]
 [60.417824]
 [60.517143]
 [60.63121 ]
 [60.734505]], R is [[60.28658676]
 [60.36658859]
 [60.44506454]
 [60.52287674]
 [60.599823  ]].
[2019-03-23 13:03:47,743] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.6518664e-11 1.0000000e+00 1.1983076e-26 3.8784020e-22 1.4617147e-26], sum to 1.0000
[2019-03-23 13:03:47,748] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7548
[2019-03-23 13:03:47,754] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 73.0, 1.0, 2.0, 0.8592163324228055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 978491.1761800955, 978491.1761800955, 186993.3485989028], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4896000.0000, 
sim time next is 4896600.0000, 
raw observation next is [22.83333333333334, 73.83333333333334, 1.0, 2.0, 0.8799104457814774, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1002021.787179741, 1002021.787179741, 190287.4798164154], 
processed observation next is [1.0, 0.6956521739130435, 0.6742424242424245, 0.7383333333333334, 1.0, 1.0, 0.8498880572268466, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3711191804369411, 0.3711191804369411, 0.4641158044302815], 
reward next is 0.5359, 
noisyNet noise sample is [array([-0.22703092], dtype=float32), 0.4534484]. 
=============================================
[2019-03-23 13:03:55,478] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.9189958e-13 1.0000000e+00 5.6496153e-28 5.4125507e-23 2.0430742e-28], sum to 1.0000
[2019-03-23 13:03:55,487] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3120
[2019-03-23 13:03:55,491] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333333, 56.5, 1.0, 2.0, 0.3630738704689048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 408580.1060388203, 408580.1060388203, 121313.295373251], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5055000.0000, 
sim time next is 5055600.0000, 
raw observation next is [24.66666666666666, 56.00000000000001, 1.0, 2.0, 0.369169287482543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416321.6267677371, 416321.6267677371, 122308.0835391602], 
processed observation next is [0.0, 0.5217391304347826, 0.7575757575757573, 0.56, 1.0, 1.0, 0.21146160935317876, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15419319509916188, 0.15419319509916188, 0.2983123988760005], 
reward next is 0.7017, 
noisyNet noise sample is [array([0.96109766], dtype=float32), -0.97423565]. 
=============================================
[2019-03-23 13:03:56,054] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.2055840e-12 1.0000000e+00 1.9645271e-29 3.1597739e-24 3.3296082e-29], sum to 1.0000
[2019-03-23 13:03:56,061] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4623
[2019-03-23 13:03:56,065] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333333, 63.83333333333334, 1.0, 2.0, 0.4185759729005124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 475827.4721132774, 475827.4721132774, 129223.0133811333], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5082600.0000, 
sim time next is 5083200.0000, 
raw observation next is [24.0, 65.0, 1.0, 2.0, 0.4146797079580976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 471063.2728545679, 471063.2728545679, 128565.6206473902], 
processed observation next is [0.0, 0.8695652173913043, 0.7272727272727273, 0.65, 1.0, 1.0, 0.268349634947622, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17446787883502515, 0.17446787883502515, 0.31357468450582976], 
reward next is 0.6864, 
noisyNet noise sample is [array([-1.0063752], dtype=float32), 1.5424013]. 
=============================================
[2019-03-23 13:03:58,134] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.3605925e-13 1.0000000e+00 5.2864214e-31 4.5191579e-26 4.8640640e-31], sum to 1.0000
[2019-03-23 13:03:58,142] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8649
[2019-03-23 13:03:58,146] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 83.0, 1.0, 2.0, 0.4160346460589627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 473235.1070420854, 473235.1070420854, 129243.797050059], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5121600.0000, 
sim time next is 5122200.0000, 
raw observation next is [21.83333333333334, 83.0, 1.0, 2.0, 0.4217101730958001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 480058.424160891, 480058.424160891, 130162.7684465008], 
processed observation next is [0.0, 0.2608695652173913, 0.628787878787879, 0.83, 1.0, 1.0, 0.2771377163697501, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17779941635588556, 0.17779941635588556, 0.3174701669426849], 
reward next is 0.6825, 
noisyNet noise sample is [array([-0.46589133], dtype=float32), -0.8006463]. 
=============================================
[2019-03-23 13:04:00,370] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.2298066e-12 1.0000000e+00 1.9425029e-25 9.1864304e-23 6.5132813e-24], sum to 1.0000
[2019-03-23 13:04:00,382] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9646
[2019-03-23 13:04:00,385] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 65.83333333333333, 1.0, 2.0, 0.5295652622967036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 602423.7810249914, 602423.7810249914, 147034.7144739892], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5155800.0000, 
sim time next is 5156400.0000, 
raw observation next is [26.66666666666667, 65.66666666666667, 1.0, 2.0, 0.5218380826145657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 594123.4860657229, 594123.4860657229, 145742.1117716992], 
processed observation next is [0.0, 0.6956521739130435, 0.8484848484848487, 0.6566666666666667, 1.0, 1.0, 0.402297603268207, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22004573557989737, 0.22004573557989737, 0.3554685652968273], 
reward next is 0.6445, 
noisyNet noise sample is [array([0.19071451], dtype=float32), -1.1375496]. 
=============================================
[2019-03-23 13:04:01,601] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 13:04:01,601] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:04:01,602] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:04:01,602] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:04:01,603] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:04:01,605] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:04:01,606] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:04:01,607] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:04:01,607] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:04:01,611] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:04:01,613] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:04:01,626] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run15
[2019-03-23 13:04:01,628] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run15
[2019-03-23 13:04:01,648] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run15
[2019-03-23 13:04:01,696] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run15
[2019-03-23 13:04:01,723] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run15
[2019-03-23 13:04:10,523] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.03865276], dtype=float32), 0.14181007]
[2019-03-23 13:04:10,526] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.16666666666666, 87.16666666666667, 1.0, 2.0, 0.3356077588479955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369956.7823694117, 369956.7823694117, 115611.6456857898]
[2019-03-23 13:04:10,526] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:04:10,529] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.1225666e-10 1.0000000e+00 8.5685434e-23 2.2754281e-19 9.1314367e-23], sampled 0.08302101194072997
[2019-03-23 13:04:13,158] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.03865276], dtype=float32), 0.14181007]
[2019-03-23 13:04:13,159] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.26666666666667, 72.33333333333333, 1.0, 2.0, 0.3436187771518213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 379961.9533425693, 379961.9533425689, 120982.4304182753]
[2019-03-23 13:04:13,159] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:04:13,163] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.6221075e-10 1.0000000e+00 5.7421898e-23 1.6219500e-19 6.1134852e-23], sampled 0.7633803928469646
[2019-03-23 13:04:32,912] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.03865276], dtype=float32), 0.14181007]
[2019-03-23 13:04:32,913] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.4, 42.0, 1.0, 2.0, 0.3891644186644023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 438363.070027491, 438363.0700274906, 128112.7344791787]
[2019-03-23 13:04:32,914] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:04:32,917] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.2325301e-10 1.0000000e+00 3.9763152e-23 1.1890274e-19 4.2325881e-23], sampled 0.666689317417553
[2019-03-23 13:04:36,660] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.03865276], dtype=float32), 0.14181007]
[2019-03-23 13:04:36,660] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.66666666666667, 69.0, 1.0, 2.0, 0.8949945782352934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1019421.549671739, 1019421.549671739, 192992.1971213865]
[2019-03-23 13:04:36,661] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:04:36,665] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.7178475e-09 1.0000000e+00 4.2513469e-21 6.1838190e-18 4.5638838e-21], sampled 0.8302198838125054
[2019-03-23 13:04:54,499] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.03865276], dtype=float32), 0.14181007]
[2019-03-23 13:04:54,501] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.54317849666667, 70.19774458666667, 1.0, 2.0, 0.5185886947241894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 591167.0294879558, 591167.0294879558, 148873.3984860067]
[2019-03-23 13:04:54,502] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:04:54,504] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.03865276], dtype=float32), 0.14181007]
[2019-03-23 13:04:54,505] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.4916841e-10 1.0000000e+00 5.1112633e-23 1.4703546e-19 5.4419702e-23], sampled 0.8312829600310165
[2019-03-23 13:04:54,506] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.76666666666667, 89.33333333333334, 1.0, 2.0, 0.5163810693505079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 588581.7743556179, 588581.7743556176, 148691.398360901]
[2019-03-23 13:04:54,509] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:04:54,511] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.7027529e-10 1.0000000e+00 2.1372526e-23 7.0338515e-20 2.2720581e-23], sampled 0.09875959130903522
[2019-03-23 13:05:09,929] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.03865276], dtype=float32), 0.14181007]
[2019-03-23 13:05:09,930] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.33333333333333, 66.83333333333333, 1.0, 2.0, 0.4704366537824854, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8704062549541602, 7.024132396845447, 6.9112, 95.55294881739552, 1073618.747634625, 1028296.44878511, 244631.0731002848]
[2019-03-23 13:05:09,932] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:05:09,934] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.0339629e-10 1.0000000e+00 7.4615988e-22 1.4197780e-18 7.9865207e-22], sampled 0.5259847791653236
[2019-03-23 13:05:16,608] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.03865276], dtype=float32), 0.14181007]
[2019-03-23 13:05:16,610] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.96666666666667, 57.33333333333333, 1.0, 2.0, 0.3823148781057474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 424729.96959493, 424729.96959493, 124805.7699606487]
[2019-03-23 13:05:16,611] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:05:16,615] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.0911868e-10 1.0000000e+00 1.5910556e-22 3.8400580e-19 1.6973954e-22], sampled 0.06761668775546137
[2019-03-23 13:05:30,660] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.03865276], dtype=float32), 0.14181007]
[2019-03-23 13:05:30,662] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.93801023833333, 47.84912624333334, 1.0, 2.0, 0.4381410067150433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 480825.3332235505, 480825.3332235505, 127468.131801674]
[2019-03-23 13:05:30,664] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:05:30,666] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.2710936e-10 1.0000000e+00 2.8429926e-22 6.2755205e-19 3.0367697e-22], sampled 0.15934507343198978
[2019-03-23 13:05:30,886] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.03865276], dtype=float32), 0.14181007]
[2019-03-23 13:05:30,888] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.75, 85.16666666666667, 1.0, 2.0, 0.507119365677332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 578588.5605675714, 578588.5605675711, 146430.5629392026]
[2019-03-23 13:05:30,889] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:05:30,895] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.8180105e-10 1.0000000e+00 2.4835825e-23 7.9881743e-20 2.6416326e-23], sampled 0.795924729390543
[2019-03-23 13:05:41,384] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3791 1683296663.2329 214.0000
[2019-03-23 13:05:41,432] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 13:05:41,501] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 13:05:41,515] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 13:05:41,641] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2861 1773154298.0034 173.0000
[2019-03-23 13:05:42,656] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 350000, evaluation results [350000.0, 8512.28612121474, 1773154298.0034232, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.379088229873, 1683296663.232874, 214.0]
[2019-03-23 13:05:43,751] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.6696665e-13 1.0000000e+00 5.3742660e-29 6.7360211e-25 7.0176817e-30], sum to 1.0000
[2019-03-23 13:05:43,762] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8739
[2019-03-23 13:05:43,771] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4378027004832203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 498795.6623190084, 498795.6623190087, 132249.1853233664], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5190000.0000, 
sim time next is 5190600.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4378336890909922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 498831.1369946161, 498831.1369946161, 132252.5528133897], 
processed observation next is [1.0, 0.043478260869565216, 0.6363636363636364, 0.83, 1.0, 1.0, 0.2972921113637402, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18475227296096894, 0.18475227296096894, 0.3225672019838773], 
reward next is 0.6774, 
noisyNet noise sample is [array([1.0214115], dtype=float32), 0.34326667]. 
=============================================
[2019-03-23 13:05:47,887] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.8000294e-11 1.0000000e+00 3.4958799e-26 2.4865237e-21 6.3630048e-25], sum to 1.0000
[2019-03-23 13:05:47,896] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2427
[2019-03-23 13:05:47,899] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.1, 87.0, 1.0, 2.0, 0.3471507389384652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 387649.6530961351, 387649.6530961351, 118514.4367430459], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5290200.0000, 
sim time next is 5290800.0000, 
raw observation next is [19.2, 87.0, 1.0, 2.0, 0.3494575209111725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 390729.6396339812, 390729.6396339812, 118927.6540808951], 
processed observation next is [1.0, 0.21739130434782608, 0.509090909090909, 0.87, 1.0, 1.0, 0.1868219011389656, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14471468134591897, 0.14471468134591897, 0.2900674489777929], 
reward next is 0.7099, 
noisyNet noise sample is [array([-1.5087532], dtype=float32), 2.4834754]. 
=============================================
[2019-03-23 13:05:48,219] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.62993299e-11 1.00000000e+00 1.14077545e-26 3.36631207e-22
 4.71950137e-25], sum to 1.0000
[2019-03-23 13:05:48,226] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1895
[2019-03-23 13:05:48,231] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 87.0, 1.0, 2.0, 0.3653427537620773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 409682.1742347017, 409682.1742347014, 120777.8684153927], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5295000.0000, 
sim time next is 5295600.0000, 
raw observation next is [19.4, 87.0, 1.0, 2.0, 0.3708489315898937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415867.6929327928, 415867.6929327928, 121245.4338863126], 
processed observation next is [1.0, 0.30434782608695654, 0.5181818181818181, 0.87, 1.0, 1.0, 0.2135611644873671, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15402507145658995, 0.15402507145658995, 0.29572057045442096], 
reward next is 0.7043, 
noisyNet noise sample is [array([0.29508907], dtype=float32), -0.87493974]. 
=============================================
[2019-03-23 13:05:52,158] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.0016728e-13 1.0000000e+00 6.5130940e-28 1.0043345e-24 7.6654138e-26], sum to 1.0000
[2019-03-23 13:05:52,168] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6687
[2019-03-23 13:05:52,172] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.41666666666667, 87.0, 1.0, 2.0, 0.5135645056974256, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 585194.8504175214, 585194.8504175217, 140459.002372236], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5368200.0000, 
sim time next is 5368800.0000, 
raw observation next is [21.23333333333333, 87.0, 1.0, 2.0, 0.497357012946811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 566341.5905240111, 566341.5905240111, 138206.330167127], 
processed observation next is [1.0, 0.13043478260869565, 0.6015151515151514, 0.87, 1.0, 1.0, 0.3716962661835137, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2097561446385226, 0.2097561446385226, 0.3370886101637244], 
reward next is 0.6629, 
noisyNet noise sample is [array([0.5548203], dtype=float32), -1.1885625]. 
=============================================
[2019-03-23 13:05:52,630] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0726445e-12 1.0000000e+00 1.5130752e-27 8.8529529e-24 1.9033916e-25], sum to 1.0000
[2019-03-23 13:05:52,640] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1909
[2019-03-23 13:05:52,648] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 93.0, 1.0, 2.0, 0.5053394267366839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 571558.50888536, 571558.50888536, 136204.9846566732], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5379000.0000, 
sim time next is 5379600.0000, 
raw observation next is [19.6, 93.0, 1.0, 2.0, 0.4197326059789077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 475063.7324105696, 475063.7324105696, 127835.9226102275], 
processed observation next is [1.0, 0.2608695652173913, 0.5272727272727273, 0.93, 1.0, 1.0, 0.2746657574736346, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1759495305224332, 0.1759495305224332, 0.3117949331956768], 
reward next is 0.6882, 
noisyNet noise sample is [array([0.3568746], dtype=float32), -1.2000886]. 
=============================================
[2019-03-23 13:05:52,935] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.2105473e-14 1.0000000e+00 2.1767408e-29 2.1677131e-25 2.6111700e-27], sum to 1.0000
[2019-03-23 13:05:52,944] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0643
[2019-03-23 13:05:52,950] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.75, 80.0, 1.0, 2.0, 0.4584245981881368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522824.5514198895, 522824.5514198895, 135207.3185086852], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5362200.0000, 
sim time next is 5362800.0000, 
raw observation next is [22.56666666666667, 80.33333333333334, 1.0, 2.0, 0.4539553148775513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 517569.3307764609, 517569.3307764606, 134442.4612536181], 
processed observation next is [1.0, 0.043478260869565216, 0.6621212121212122, 0.8033333333333335, 1.0, 1.0, 0.3174441435969391, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19169234473202254, 0.19169234473202243, 0.3279084420819954], 
reward next is 0.6721, 
noisyNet noise sample is [array([-0.83678794], dtype=float32), -0.4616344]. 
=============================================
[2019-03-23 13:05:57,453] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.6809045e-13 1.0000000e+00 1.0264403e-29 1.6157580e-24 5.9001642e-27], sum to 1.0000
[2019-03-23 13:05:57,459] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6405
[2019-03-23 13:05:57,461] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 95.0, 1.0, 2.0, 0.3408636483055447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 375491.4584365489, 375491.4584365489, 115907.1935165103], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5459400.0000, 
sim time next is 5460000.0000, 
raw observation next is [17.2, 93.33333333333334, 1.0, 2.0, 0.3335775496302316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 366254.3230447882, 366254.3230447885, 114911.8387119583], 
processed observation next is [1.0, 0.17391304347826086, 0.41818181818181815, 0.9333333333333335, 1.0, 1.0, 0.1669719370377895, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1356497492758475, 0.13564974927584758, 0.2802727773462398], 
reward next is 0.7197, 
noisyNet noise sample is [array([-1.3618983], dtype=float32), -1.1728178]. 
=============================================
[2019-03-23 13:05:57,472] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[62.553318]
 [62.55224 ]
 [62.51794 ]
 [62.556385]
 [62.542492]], R is [[62.67507553]
 [62.765625  ]
 [62.85271835]
 [62.93428802]
 [63.01425934]].
[2019-03-23 13:06:07,409] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1542919e-13 1.0000000e+00 3.1077373e-32 8.0652145e-27 8.9445495e-29], sum to 1.0000
[2019-03-23 13:06:07,420] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1315
[2019-03-23 13:06:07,424] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.2, 96.33333333333333, 1.0, 2.0, 0.4035502777978255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 456784.9907222936, 456784.9907222939, 126342.5885597562], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5628000.0000, 
sim time next is 5628600.0000, 
raw observation next is [19.1, 96.5, 1.0, 2.0, 0.4004478761343627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 452963.2394714696, 452963.2394714699, 125862.0675320908], 
processed observation next is [0.0, 0.13043478260869565, 0.5045454545454546, 0.965, 1.0, 1.0, 0.2505598451679534, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16776416276721096, 0.16776416276721107, 0.30698065251729467], 
reward next is 0.6930, 
noisyNet noise sample is [array([-1.0933363], dtype=float32), -0.61744064]. 
=============================================
[2019-03-23 13:06:09,002] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.4585811e-15 1.0000000e+00 1.5821316e-33 3.2294437e-30 1.6543393e-32], sum to 1.0000
[2019-03-23 13:06:09,010] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5464
[2019-03-23 13:06:09,013] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 77.5, 1.0, 2.0, 0.2124127853596044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 230626.3589716401, 230626.3589716401, 75415.60999806697], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5674200.0000, 
sim time next is 5674800.0000, 
raw observation next is [15.5, 77.0, 1.0, 2.0, 0.213038205894841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 231305.5683559318, 231305.5683559318, 75295.13981335801], 
processed observation next is [0.0, 0.6956521739130435, 0.3409090909090909, 0.77, 1.0, 1.0, 0.01629775736855122, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08566872902071548, 0.08566872902071548, 0.1836466824716049], 
reward next is 0.8164, 
noisyNet noise sample is [array([1.0410998], dtype=float32), -1.0538547]. 
=============================================
[2019-03-23 13:06:11,516] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.3273334  0.65964115 0.00275652 0.00529082 0.00497811], sum to 1.0000
[2019-03-23 13:06:11,524] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9940
[2019-03-23 13:06:11,531] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [11.26666666666667, 77.0, 1.0, 1.0, 0.2, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 168896.8485160501, 168896.8485160501, 60327.75212558192], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5704800.0000, 
sim time next is 5705400.0000, 
raw observation next is [11.18333333333333, 77.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 167366.6115016684, 167366.6115016681, 82325.64279967821], 
processed observation next is [0.0, 0.0, 0.14469696969696955, 0.77, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.061987633889506816, 0.06198763388950671, 0.20079425073092247], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.472152], dtype=float32), 0.55476177]. 
=============================================
[2019-03-23 13:06:13,861] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 13:06:13,870] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2409
[2019-03-23 13:06:13,877] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.7, 56.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4131280701844345, 6.9112, 6.9112, 77.32846344354104, 240283.4998760915, 240283.4998760915, 70101.48851230164], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5778000.0000, 
sim time next is 5778600.0000, 
raw observation next is [17.51666666666667, 57.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4135803374386534, 6.9112, 6.9112, 77.32846344354104, 240546.6125498308, 240546.6125498308, 70131.03036524166], 
processed observation next is [0.0, 0.9130434782608695, 0.43257575757575767, 0.57, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.16225762491236204, 0.0, 0.0, 0.5084288129206541, 0.08909133798141881, 0.08909133798141881, 0.17105129357376014], 
reward next is 0.8289, 
noisyNet noise sample is [array([-0.08396576], dtype=float32), -1.4588317]. 
=============================================
[2019-03-23 13:06:14,961] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 13:06:14,970] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2646
[2019-03-23 13:06:14,974] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.86666666666667, 47.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4913990834117566, 6.911199999999998, 6.9112, 77.32846344354104, 285820.8539459503, 285820.8539459509, 85376.9939487709], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5769600.0000, 
sim time next is 5770200.0000, 
raw observation next is [20.68333333333334, 48.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4878743688047321, 6.9112, 6.9112, 77.32846344354104, 283770.11579499, 283770.11579499, 84879.82488888272], 
processed observation next is [0.0, 0.782608695652174, 0.5765151515151519, 0.4816666666666667, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2683919554353316, 0.0, 0.0, 0.5084288129206541, 0.10510004288703333, 0.10510004288703333, 0.2070239631436164], 
reward next is 0.7930, 
noisyNet noise sample is [array([-0.01980378], dtype=float32), -1.323525]. 
=============================================
[2019-03-23 13:06:16,664] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.2065106e-07 9.9999976e-01 2.3368004e-20 1.4908978e-17 1.9980568e-18], sum to 1.0000
[2019-03-23 13:06:16,671] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5685
[2019-03-23 13:06:16,678] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.86666666666667, 68.33333333333333, 1.0, 2.0, 0.2005355490297918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 217727.8093963733, 217727.8093963735, 72197.15840289826], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5816400.0000, 
sim time next is 5817000.0000, 
raw observation next is [16.23333333333333, 66.66666666666667, 1.0, 2.0, 0.2040136942913754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 221505.0019345728, 221505.0019345728, 72879.11498783804], 
processed observation next is [1.0, 0.30434782608695654, 0.3742424242424241, 0.6666666666666667, 1.0, 1.0, 0.0050171178642192255, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08203888960539733, 0.08203888960539733, 0.1777539389947269], 
reward next is 0.8222, 
noisyNet noise sample is [array([-0.68722177], dtype=float32), -1.6441056]. 
=============================================
[2019-03-23 13:06:16,699] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[45.683624]
 [45.701817]
 [45.64396 ]
 [45.342644]
 [45.846252]], R is [[45.97407532]
 [46.33824539]
 [45.87486267]
 [46.24061584]
 [46.59265137]].
[2019-03-23 13:06:16,979] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.6518910e-11 1.0000000e+00 3.4814106e-28 2.7018218e-24 1.0054446e-27], sum to 1.0000
[2019-03-23 13:06:16,986] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7943
[2019-03-23 13:06:16,995] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.6, 65.0, 1.0, 2.0, 0.2080733424014489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 225913.7314234794, 225913.7314234794, 73632.30676307909], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5817600.0000, 
sim time next is 5818200.0000, 
raw observation next is [17.06666666666667, 64.33333333333334, 1.0, 2.0, 0.2445290736174855, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 265506.0120608422, 265506.0120608425, 78174.310666232], 
processed observation next is [1.0, 0.34782608695652173, 0.4121212121212123, 0.6433333333333334, 1.0, 1.0, 0.05566134202185685, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09833556002253414, 0.09833556002253425, 0.1906690504054439], 
reward next is 0.8093, 
noisyNet noise sample is [array([0.76019603], dtype=float32), 1.5684334]. 
=============================================
[2019-03-23 13:06:19,934] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.5633634e-09 1.0000000e+00 4.8016937e-32 3.5663942e-26 1.1516731e-31], sum to 1.0000
[2019-03-23 13:06:19,938] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2274
[2019-03-23 13:06:19,943] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 77.5, 1.0, 2.0, 0.2553337593100247, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 277240.9219559106, 277240.9219559109, 89591.2610877344], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5893800.0000, 
sim time next is 5894400.0000, 
raw observation next is [17.2, 77.0, 1.0, 2.0, 0.2523915015707336, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 274045.3239021358, 274045.3239021361, 88687.73456527111], 
processed observation next is [1.0, 0.21739130434782608, 0.41818181818181815, 0.77, 1.0, 1.0, 0.06548937696341697, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10149826811190214, 0.10149826811190227, 0.21631154772017344], 
reward next is 0.7837, 
noisyNet noise sample is [array([-1.174288], dtype=float32), 1.6558172]. 
=============================================
[2019-03-23 13:06:30,125] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.2491409e-11 1.0000000e+00 1.8343005e-29 2.5728414e-23 2.6781051e-26], sum to 1.0000
[2019-03-23 13:06:30,133] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5297
[2019-03-23 13:06:30,145] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.78333333333333, 70.83333333333333, 1.0, 2.0, 0.2493784773031968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 270772.8877954859, 270772.8877954859, 80916.13507585571], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6077400.0000, 
sim time next is 6078000.0000, 
raw observation next is [16.96666666666667, 69.66666666666667, 1.0, 2.0, 0.3206557044157895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 348192.7597797352, 348192.7597797349, 88250.7683713772], 
processed observation next is [1.0, 0.34782608695652173, 0.40757575757575765, 0.6966666666666668, 1.0, 1.0, 0.15081963051973685, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12896028139990193, 0.12896028139990182, 0.21524577651555415], 
reward next is 0.7848, 
noisyNet noise sample is [array([-0.2827982], dtype=float32), 0.6730328]. 
=============================================
[2019-03-23 13:06:30,155] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[66.01532 ]
 [66.12578 ]
 [66.173904]
 [66.21431 ]
 [66.248695]], R is [[65.81122589]
 [65.95575714]
 [66.10361481]
 [66.25209808]
 [66.4006958 ]].
[2019-03-23 13:06:31,637] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 13:06:31,639] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:06:31,639] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:06:31,640] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:06:31,640] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:06:31,641] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:06:31,642] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:06:31,643] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:06:31,643] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:06:31,643] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:06:31,644] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:06:31,658] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run16
[2019-03-23 13:06:31,658] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run16
[2019-03-23 13:06:31,714] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run16
[2019-03-23 13:06:31,740] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run16
[2019-03-23 13:06:31,741] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run16
[2019-03-23 13:06:51,840] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.04143202], dtype=float32), 0.14153732]
[2019-03-23 13:06:51,840] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.96666666666667, 40.5, 1.0, 2.0, 0.4849341408113336, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 526621.2021896507, 526621.2021896507, 125889.6440441447]
[2019-03-23 13:06:51,841] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:06:51,843] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.3219334e-10 1.0000000e+00 1.7052804e-30 1.5903069e-25 2.2257792e-28], sampled 0.018714656638687988
[2019-03-23 13:06:52,036] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.04143202], dtype=float32), 0.14153732]
[2019-03-23 13:06:52,037] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.56666666666667, 45.33333333333334, 1.0, 2.0, 0.3099425211381663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 336533.3212165643, 336533.3212165643, 103531.555566249]
[2019-03-23 13:06:52,038] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:06:52,040] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.3036498e-10 1.0000000e+00 1.6238663e-30 1.5292897e-25 2.1219665e-28], sampled 0.15327922263614424
[2019-03-23 13:07:16,494] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.04143202], dtype=float32), 0.14153732]
[2019-03-23 13:07:16,495] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.7, 52.0, 1.0, 2.0, 0.3759769735264986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 421245.1020800984, 421245.1020800984, 125826.2936391234]
[2019-03-23 13:07:16,497] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:07:16,498] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.6282278e-10 1.0000000e+00 3.1177383e-30 2.6365561e-25 3.8894280e-28], sampled 0.48555205275035973
[2019-03-23 13:07:20,638] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.04143202], dtype=float32), 0.14153732]
[2019-03-23 13:07:20,640] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.6, 88.5, 1.0, 2.0, 0.7459368248030614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769687425, 851027.75423956, 851027.7542395595, 176556.3451457736]
[2019-03-23 13:07:20,642] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:07:20,645] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.9442519e-11 1.0000000e+00 4.7182424e-32 7.9725896e-27 7.9292356e-30], sampled 0.07926174489727755
[2019-03-23 13:07:35,429] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.04143202], dtype=float32), 0.14153732]
[2019-03-23 13:07:35,432] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.5, 50.33333333333334, 1.0, 2.0, 0.3614340411856619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 402767.3926867509, 402767.3926867509, 123624.6788499973]
[2019-03-23 13:07:35,433] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:07:35,436] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.6169606e-11 1.0000000e+00 4.7562481e-31 5.4942344e-26 6.7708896e-29], sampled 0.029298146883884102
[2019-03-23 13:07:49,512] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.04143202], dtype=float32), 0.14153732]
[2019-03-23 13:07:49,514] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.25, 85.33333333333334, 1.0, 2.0, 0.3555651907059216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 396909.7484344043, 396909.7484344043, 123449.9913172249]
[2019-03-23 13:07:49,516] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:07:49,519] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.5065398e-10 1.0000000e+00 2.4699119e-30 2.1721499e-25 3.1288220e-28], sampled 0.3755344040059403
[2019-03-23 13:08:11,383] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 13:08:11,462] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 13:08:11,778] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 13:08:11,819] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 13:08:11,889] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.1204 1705935497.0665 465.0000
[2019-03-23 13:08:12,904] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 375000, evaluation results [375000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.120377555595, 1705935497.0665214, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 13:08:13,187] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.2337525e-11 1.0000000e+00 4.9377551e-33 5.0119550e-26 2.4020070e-30], sum to 1.0000
[2019-03-23 13:08:13,205] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5761
[2019-03-23 13:08:13,214] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.06666666666667, 55.66666666666667, 1.0, 2.0, 0.2886281621185247, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 313403.5710086781, 313403.5710086784, 101671.8881704724], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6117600.0000, 
sim time next is 6118200.0000, 
raw observation next is [20.8, 57.0, 1.0, 2.0, 0.2862770351435021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 310849.8109035499, 310849.8109035497, 100803.7434990457], 
processed observation next is [1.0, 0.8260869565217391, 0.5818181818181819, 0.57, 1.0, 1.0, 0.10784629392937763, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11512955959390737, 0.1151295595939073, 0.24586278902206268], 
reward next is 0.7541, 
noisyNet noise sample is [array([-0.7632869], dtype=float32), -0.16846246]. 
=============================================
[2019-03-23 13:08:14,358] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.7229578e-14 1.0000000e+00 2.6903082e-35 1.9535181e-30 4.1312420e-32], sum to 1.0000
[2019-03-23 13:08:14,370] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4782
[2019-03-23 13:08:14,376] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.36666666666667, 82.0, 1.0, 2.0, 0.3598012772776941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 390717.1275802449, 390717.1275802452, 109670.8332110484], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6142800.0000, 
sim time next is 6143400.0000, 
raw observation next is [17.45, 81.0, 1.0, 2.0, 0.3116696682744627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 338431.6313856129, 338431.6313856129, 104214.1095749021], 
processed observation next is [1.0, 0.08695652173913043, 0.4295454545454545, 0.81, 1.0, 1.0, 0.13958708534307834, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1253450486613381, 0.1253450486613381, 0.25418075506073684], 
reward next is 0.7458, 
noisyNet noise sample is [array([-0.11793317], dtype=float32), -0.8976885]. 
=============================================
[2019-03-23 13:08:16,019] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.6555637e-07 9.9999976e-01 7.3324621e-26 6.4541034e-21 4.0973593e-23], sum to 1.0000
[2019-03-23 13:08:16,025] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9399
[2019-03-23 13:08:16,027] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.2, 61.0, 1.0, 2.0, 0.7934423077031075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 893205.7456502904, 893205.7456502904, 169944.7546332198], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6187800.0000, 
sim time next is 6188400.0000, 
raw observation next is [23.3, 60.0, 1.0, 2.0, 0.7907690574075777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 889596.4403636695, 889596.4403636693, 169272.0546560945], 
processed observation next is [1.0, 0.6521739130434783, 0.6954545454545454, 0.6, 1.0, 1.0, 0.7384613217594721, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3294801630976554, 0.3294801630976553, 0.4128586698929134], 
reward next is 0.5871, 
noisyNet noise sample is [array([1.3556675], dtype=float32), -0.9994781]. 
=============================================
[2019-03-23 13:08:20,847] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.1221477e-10 1.0000000e+00 3.5064221e-31 9.0553813e-27 5.0970169e-28], sum to 1.0000
[2019-03-23 13:08:20,853] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3989
[2019-03-23 13:08:20,859] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.68333333333334, 86.16666666666667, 1.0, 2.0, 0.3989964471279855, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 452346.6798077599, 452346.6798077596, 126398.3086998982], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6250200.0000, 
sim time next is 6250800.0000, 
raw observation next is [20.86666666666667, 85.33333333333334, 1.0, 2.0, 0.4014476233782631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 455377.8197177103, 455377.8197177103, 126804.9731475754], 
processed observation next is [0.0, 0.34782608695652173, 0.5848484848484851, 0.8533333333333334, 1.0, 1.0, 0.25180952922282884, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16865845174730013, 0.16865845174730013, 0.3092804223111595], 
reward next is 0.6907, 
noisyNet noise sample is [array([0.3784052], dtype=float32), -2.1432073]. 
=============================================
[2019-03-23 13:08:25,315] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.7708040e-09 1.0000000e+00 6.7501618e-27 1.5659106e-22 7.3893887e-24], sum to 1.0000
[2019-03-23 13:08:25,324] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7884
[2019-03-23 13:08:25,327] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 61.0, 1.0, 2.0, 0.550748862446027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 624818.803120832, 624818.803120832, 150558.7741364893], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6366000.0000, 
sim time next is 6366600.0000, 
raw observation next is [28.3, 61.0, 1.0, 2.0, 0.5507339376808824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 624802.3237914469, 624802.3237914469, 150556.6629894989], 
processed observation next is [0.0, 0.6956521739130435, 0.9227272727272727, 0.61, 1.0, 1.0, 0.43841742210110296, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23140826807090625, 0.23140826807090625, 0.36721137314511926], 
reward next is 0.6328, 
noisyNet noise sample is [array([-0.73851603], dtype=float32), -1.1385375]. 
=============================================
[2019-03-23 13:08:35,854] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.6192420e-14 1.0000000e+00 2.7409312e-36 3.2298624e-30 8.0573443e-34], sum to 1.0000
[2019-03-23 13:08:35,861] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1860
[2019-03-23 13:08:35,868] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666666, 56.66666666666667, 1.0, 2.0, 0.2598691600371248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 282166.8801939211, 282166.8801939211, 81804.18565133949], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6550800.0000, 
sim time next is 6551400.0000, 
raw observation next is [18.48333333333333, 57.33333333333334, 1.0, 2.0, 0.2587948090294023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 281000.0089585321, 281000.0089585324, 81376.31834281553], 
processed observation next is [1.0, 0.8260869565217391, 0.4765151515151514, 0.5733333333333335, 1.0, 1.0, 0.07349351128675283, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10407407739204894, 0.10407407739204905, 0.19847882522637936], 
reward next is 0.8015, 
noisyNet noise sample is [array([2.0656812], dtype=float32), -0.7168767]. 
=============================================
[2019-03-23 13:08:43,810] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.7941050e-11 1.0000000e+00 1.0758305e-31 1.2816497e-26 6.6834343e-29], sum to 1.0000
[2019-03-23 13:08:43,821] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8919
[2019-03-23 13:08:43,828] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.2, 93.66666666666666, 1.0, 2.0, 0.6518664969328933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 728779.9248950768, 728779.9248950768, 149041.7657164647], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6693000.0000, 
sim time next is 6693600.0000, 
raw observation next is [18.1, 94.33333333333334, 1.0, 2.0, 0.6693770697184795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 748370.1171846767, 748370.117184677, 151145.9321541288], 
processed observation next is [1.0, 0.4782608695652174, 0.45909090909090916, 0.9433333333333335, 1.0, 1.0, 0.5867213371480994, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.27717411747580617, 0.27717411747580634, 0.36864861501007024], 
reward next is 0.6314, 
noisyNet noise sample is [array([-0.05349696], dtype=float32), -1.1357168]. 
=============================================
[2019-03-23 13:08:48,354] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.0537214e-10 1.0000000e+00 8.5588802e-29 4.9157300e-25 5.3720376e-27], sum to 1.0000
[2019-03-23 13:08:48,368] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5432
[2019-03-23 13:08:48,376] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 66.0, 1.0, 2.0, 0.6667026342530882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 759701.7684583683, 759701.7684583685, 159321.6966319043], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6786000.0000, 
sim time next is 6786600.0000, 
raw observation next is [24.5, 65.33333333333333, 1.0, 2.0, 0.7110021873577137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 810200.4533527029, 810200.4533527029, 165406.3290077776], 
processed observation next is [1.0, 0.5652173913043478, 0.75, 0.6533333333333333, 1.0, 1.0, 0.6387527341971422, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.30007424198248256, 0.30007424198248256, 0.40343007075067705], 
reward next is 0.5966, 
noisyNet noise sample is [array([-0.6975996], dtype=float32), 0.36048797]. 
=============================================
[2019-03-23 13:08:56,548] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.4132672e-11 1.0000000e+00 1.1708885e-33 9.3424244e-30 3.5004884e-31], sum to 1.0000
[2019-03-23 13:08:56,557] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1319
[2019-03-23 13:08:56,562] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.43333333333333, 59.0, 1.0, 2.0, 0.4929861819020036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 562180.9461397793, 562180.9461397793, 141324.5074302757], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6954600.0000, 
sim time next is 6955200.0000, 
raw observation next is [27.7, 58.0, 1.0, 2.0, 0.495424609079681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 564876.1729463362, 564876.172946336, 141735.0948566264], 
processed observation next is [0.0, 0.5217391304347826, 0.8954545454545454, 0.58, 1.0, 1.0, 0.3692807613496012, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20921339738753192, 0.20921339738753184, 0.34569535330884493], 
reward next is 0.6543, 
noisyNet noise sample is [array([-0.7866443], dtype=float32), 0.7328728]. 
=============================================
[2019-03-23 13:08:58,120] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.5972758e-10 1.0000000e+00 6.0093029e-29 4.9310744e-25 3.9957704e-27], sum to 1.0000
[2019-03-23 13:08:58,127] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1165
[2019-03-23 13:08:58,130] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.75, 81.5, 1.0, 2.0, 0.4663440377719063, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 532024.0308561596, 532024.0308561596, 136466.7223022917], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6996600.0000, 
sim time next is 6997200.0000, 
raw observation next is [22.56666666666667, 82.33333333333334, 1.0, 2.0, 0.463721763784223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 528981.8986493002, 528981.8986493004, 136039.2315384152], 
processed observation next is [0.0, 1.0, 0.6621212121212122, 0.8233333333333335, 1.0, 1.0, 0.3296522047302787, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19591922172196305, 0.19591922172196313, 0.33180300375223215], 
reward next is 0.6682, 
noisyNet noise sample is [array([-1.129224], dtype=float32), 1.362618]. 
=============================================
[2019-03-23 13:09:01,701] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 13:09:01,702] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:09:01,702] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:09:01,703] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:09:01,704] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:09:01,705] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:09:01,705] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:09:01,705] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:09:01,706] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:09:01,706] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:09:01,707] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:09:01,726] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run17
[2019-03-23 13:09:01,752] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run17
[2019-03-23 13:09:01,752] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run17
[2019-03-23 13:09:01,753] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run17
[2019-03-23 13:09:01,831] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run17
[2019-03-23 13:09:06,214] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04632087], dtype=float32), 0.14919652]
[2019-03-23 13:09:06,215] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.176196165, 61.73485388, 1.0, 2.0, 0.2385789217651821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 259030.5495648443, 259030.5495648443, 91001.07400578921]
[2019-03-23 13:09:06,216] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:09:06,219] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.446889e-09 1.000000e+00 7.415926e-26 1.347266e-21 7.373958e-24], sampled 0.024435032098370724
[2019-03-23 13:09:34,241] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04632087], dtype=float32), 0.14919652]
[2019-03-23 13:09:34,242] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [31.3168396, 53.76065819, 1.0, 2.0, 0.612325642197402, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 688004.7821597864, 688004.7821597864, 164930.6741086257]
[2019-03-23 13:09:34,243] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:09:34,245] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.6641649e-10 1.0000000e+00 3.0612201e-28 1.4039724e-23 4.6582203e-26], sampled 0.3986846108057188
[2019-03-23 13:09:55,633] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04632087], dtype=float32), 0.14919652]
[2019-03-23 13:09:55,634] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.0, 94.0, 1.0, 2.0, 0.4238623255214058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 481521.4781384878, 481521.4781384878, 129477.1688771496]
[2019-03-23 13:09:55,636] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:09:55,639] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.3423424e-09 1.0000000e+00 1.7166143e-26 3.9944241e-22 1.9113599e-24], sampled 0.7163233908415236
[2019-03-23 13:10:11,111] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.04632087], dtype=float32), 0.14919652]
[2019-03-23 13:10:11,112] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.56666666666667, 59.00000000000001, 1.0, 2.0, 0.2618707271121041, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 284324.9725709204, 284324.9725709208, 93209.04423406099]
[2019-03-23 13:10:11,113] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:10:11,117] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.7231762e-09 1.0000000e+00 1.3923385e-25 2.2742457e-21 1.3189150e-23], sampled 0.005414637560306357
[2019-03-23 13:10:16,537] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04632087], dtype=float32), 0.14919652]
[2019-03-23 13:10:16,540] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.35, 80.5, 1.0, 2.0, 0.2512890965989289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 272848.0028022419, 272848.0028022416, 85291.85037866476]
[2019-03-23 13:10:16,542] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:10:16,546] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.6236280e-09 1.0000000e+00 2.9287957e-25 4.2190351e-21 2.6215953e-23], sampled 0.039550421895769405
[2019-03-23 13:10:41,685] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.1204 1705935497.0665 465.0000
[2019-03-23 13:10:41,909] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 13:10:41,955] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.4817 1773157126.0198 173.0000
[2019-03-23 13:10:42,114] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8573.5580 1683295527.7613 214.0000
[2019-03-23 13:10:42,139] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 13:10:43,154] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 400000, evaluation results [400000.0, 8511.481729068026, 1773157126.019825, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.120377555595, 1705935497.0665214, 465.0, 8573.557968395495, 1683295527.761311, 214.0]
[2019-03-23 13:10:46,323] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1569442e-08 1.0000000e+00 6.2051489e-28 2.2720678e-22 1.1092310e-25], sum to 1.0000
[2019-03-23 13:10:46,330] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8864
[2019-03-23 13:10:46,337] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.9, 92.0, 1.0, 2.0, 0.3730418993328339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 413150.4294223362, 413150.4294223362, 119217.8374283381], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7111200.0000, 
sim time next is 7111800.0000, 
raw observation next is [18.0, 91.5, 1.0, 2.0, 0.3615684468836178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 400648.5718287999, 400648.5718287999, 118383.5173765796], 
processed observation next is [1.0, 0.30434782608695654, 0.45454545454545453, 0.915, 1.0, 1.0, 0.2019605586045222, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14838835993659255, 0.14838835993659255, 0.2887402862843405], 
reward next is 0.7113, 
noisyNet noise sample is [array([-1.5124288], dtype=float32), -0.5090033]. 
=============================================
[2019-03-23 13:10:49,609] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.6010799e-11 1.0000000e+00 3.6329996e-29 2.0088729e-24 1.4392993e-27], sum to 1.0000
[2019-03-23 13:10:49,619] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2167
[2019-03-23 13:10:49,626] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 77.0, 1.0, 2.0, 0.2144517566349832, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 232840.6940181495, 232840.6940181492, 74049.81757067563], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7174800.0000, 
sim time next is 7175400.0000, 
raw observation next is [14.85, 77.83333333333334, 1.0, 2.0, 0.2130390704667121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 231306.5072853492, 231306.5072853495, 73786.64776627309], 
processed observation next is [1.0, 0.043478260869565216, 0.31136363636363634, 0.7783333333333334, 1.0, 1.0, 0.016298838083390124, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08566907677235155, 0.08566907677235167, 0.17996743357627584], 
reward next is 0.8200, 
noisyNet noise sample is [array([-0.06997094], dtype=float32), 1.0409515]. 
=============================================
[2019-03-23 13:10:50,280] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.1869844e-10 1.0000000e+00 1.0164684e-23 4.7209899e-20 2.3963071e-21], sum to 1.0000
[2019-03-23 13:10:50,287] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1001
[2019-03-23 13:10:50,291] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.53333333333333, 88.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 209189.046739566, 209189.0467395657, 68912.69728904047], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7186800.0000, 
sim time next is 7187400.0000, 
raw observation next is [12.45, 88.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 206748.2977326078, 206748.2977326075, 68337.62724038318], 
processed observation next is [1.0, 0.17391304347826086, 0.20227272727272724, 0.885, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07657344360466956, 0.07657344360466944, 0.1666771396106907], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.22938335], dtype=float32), -2.0845902]. 
=============================================
[2019-03-23 13:10:50,486] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.1000616e-07 9.9999964e-01 6.3595355e-24 1.9478943e-20 6.0162723e-22], sum to 1.0000
[2019-03-23 13:10:50,493] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7204
[2019-03-23 13:10:50,498] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.2, 89.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 196085.2716404065, 196085.2716404062, 66283.59816943774], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7191000.0000, 
sim time next is 7191600.0000, 
raw observation next is [12.2, 89.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 196494.2765928858, 196494.2765928855, 66326.94357421827], 
processed observation next is [1.0, 0.21739130434782608, 0.1909090909090909, 0.89, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07277565799736511, 0.072775657997365, 0.16177303310784943], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.001731], dtype=float32), 0.5292776]. 
=============================================
[2019-03-23 13:10:53,614] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.7666476e-13 1.0000000e+00 2.8680041e-36 1.6585294e-31 8.1621273e-33], sum to 1.0000
[2019-03-23 13:10:53,621] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9265
[2019-03-23 13:10:53,624] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.2, 63.66666666666666, 1.0, 2.0, 0.2774105260154257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 301219.2576093861, 301219.2576093858, 93323.63514415467], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7249200.0000, 
sim time next is 7249800.0000, 
raw observation next is [19.0, 64.33333333333334, 1.0, 2.0, 0.2742315231277504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 297766.3603674708, 297766.3603674708, 92032.17064719764], 
processed observation next is [1.0, 0.9130434782608695, 0.5, 0.6433333333333334, 1.0, 1.0, 0.09278940390968798, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11028383717313735, 0.11028383717313735, 0.224468708895604], 
reward next is 0.7755, 
noisyNet noise sample is [array([0.47782257], dtype=float32), -1.130459]. 
=============================================
[2019-03-23 13:11:10,766] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.0587375e-10 1.0000000e+00 1.7500139e-30 2.3450474e-24 5.5352324e-27], sum to 1.0000
[2019-03-23 13:11:10,769] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8727
[2019-03-23 13:11:10,779] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 94.0, 1.0, 2.0, 0.4342958257997349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 494269.1722669603, 494269.1722669603, 131297.0844213456], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7539600.0000, 
sim time next is 7540200.0000, 
raw observation next is [20.25, 94.5, 1.0, 2.0, 0.4332699838594812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 493045.9068995977, 493045.9068995977, 131138.734397459], 
processed observation next is [0.0, 0.2608695652173913, 0.5568181818181818, 0.945, 1.0, 1.0, 0.29158747982435146, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18260959514799915, 0.18260959514799915, 0.31985057170111947], 
reward next is 0.6801, 
noisyNet noise sample is [array([0.05003874], dtype=float32), 0.06951605]. 
=============================================
[2019-03-23 13:11:12,233] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2591542e-11 1.0000000e+00 2.5558225e-29 1.2773071e-24 3.8102459e-27], sum to 1.0000
[2019-03-23 13:11:12,241] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0463
[2019-03-23 13:11:12,248] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.08333333333334, 96.0, 1.0, 2.0, 0.4368728137061176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 497166.600525184, 497166.600525184, 131520.7631851669], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7600200.0000, 
sim time next is 7600800.0000, 
raw observation next is [20.06666666666667, 96.0, 1.0, 2.0, 0.43627419483389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 496447.2813604468, 496447.2813604468, 131423.0424030426], 
processed observation next is [0.0, 1.0, 0.5484848484848487, 0.96, 1.0, 1.0, 0.2953427435423625, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18386936346683216, 0.18386936346683216, 0.3205440058610795], 
reward next is 0.6795, 
noisyNet noise sample is [array([0.5449151], dtype=float32), -0.8017117]. 
=============================================
[2019-03-23 13:11:17,706] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.3747565e-10 1.0000000e+00 3.7626293e-32 4.5218241e-29 1.2983783e-30], sum to 1.0000
[2019-03-23 13:11:17,714] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5441
[2019-03-23 13:11:17,720] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 91.0, 1.0, 2.0, 0.4727570881654561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 539401.0804795505, 539401.0804795502, 137380.028301129], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7682400.0000, 
sim time next is 7683000.0000, 
raw observation next is [21.51666666666667, 91.33333333333334, 1.0, 2.0, 0.4731208553749081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 539794.7846317842, 539794.7846317845, 137330.1606169586], 
processed observation next is [1.0, 0.9565217391304348, 0.6143939393939395, 0.9133333333333334, 1.0, 1.0, 0.3414010692186351, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19992399430806823, 0.19992399430806834, 0.33495161126087464], 
reward next is 0.6650, 
noisyNet noise sample is [array([0.97759837], dtype=float32), -0.96176213]. 
=============================================
[2019-03-23 13:11:17,743] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[77.53356]
 [77.55364]
 [77.59773]
 [77.62394]
 [77.66592]], R is [[77.38710022]
 [77.27815247]
 [77.16963196]
 [77.06141663]
 [76.95336914]].
[2019-03-23 13:11:24,781] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.9827711e-09 1.0000000e+00 1.2364391e-28 9.0899701e-24 2.0771589e-26], sum to 1.0000
[2019-03-23 13:11:24,784] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2837
[2019-03-23 13:11:24,790] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.65, 50.0, 1.0, 2.0, 0.298814912305408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 324468.4266124021, 324468.4266124024, 97696.39201313372], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7842600.0000, 
sim time next is 7843200.0000, 
raw observation next is [21.46666666666667, 49.66666666666667, 1.0, 2.0, 0.2936809542752707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 318891.8861271048, 318891.8861271051, 94862.02988711835], 
processed observation next is [1.0, 0.782608695652174, 0.6121212121212122, 0.4966666666666667, 1.0, 1.0, 0.11710119284408835, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11810810597300178, 0.11810810597300189, 0.2313708046027277], 
reward next is 0.7686, 
noisyNet noise sample is [array([0.10926529], dtype=float32), 0.44064394]. 
=============================================
[2019-03-23 13:11:27,157] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.2783333e-08 1.0000000e+00 1.7799589e-25 2.3072592e-21 1.2276019e-23], sum to 1.0000
[2019-03-23 13:11:27,167] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4041
[2019-03-23 13:11:27,172] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 93.5, 1.0, 2.0, 0.6873520590352228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 778133.7176941247, 778133.7176941247, 158092.8876991878], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7895400.0000, 
sim time next is 7896000.0000, 
raw observation next is [19.4, 94.0, 1.0, 2.0, 0.6934552301900127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 785390.1518468313, 785390.1518468313, 159105.1875426223], 
processed observation next is [1.0, 0.391304347826087, 0.5181818181818181, 0.94, 1.0, 1.0, 0.6168190377375158, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.29088524142475236, 0.29088524142475236, 0.3880614330307861], 
reward next is 0.6119, 
noisyNet noise sample is [array([1.0428125], dtype=float32), -1.7868583]. 
=============================================
[2019-03-23 13:11:27,195] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[59.42579 ]
 [59.241203]
 [59.16883 ]
 [59.293877]
 [59.602654]], R is [[59.55072403]
 [59.56962204]
 [59.57940674]
 [59.58853149]
 [59.60651398]].
[2019-03-23 13:11:29,981] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:11:29,981] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:11:29,983] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run3
[2019-03-23 13:11:30,181] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:11:30,181] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:11:30,183] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run3
[2019-03-23 13:11:30,273] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:11:30,273] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:11:30,274] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run3
[2019-03-23 13:11:30,552] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:11:30,552] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:11:30,554] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run3
[2019-03-23 13:11:30,764] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:11:30,764] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:11:30,766] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run3
[2019-03-23 13:11:30,796] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:11:30,797] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:11:30,799] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run3
[2019-03-23 13:11:30,824] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:11:30,824] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:11:30,827] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run3
[2019-03-23 13:11:30,857] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:11:30,858] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:11:30,860] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run3
[2019-03-23 13:11:30,905] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:11:30,905] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:11:30,907] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run3
[2019-03-23 13:11:30,940] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:11:30,940] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:11:30,942] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run3
[2019-03-23 13:11:30,990] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:11:30,991] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:11:30,992] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run3
[2019-03-23 13:11:31,033] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:11:31,033] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:11:31,035] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run3
[2019-03-23 13:11:31,080] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:11:31,080] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:11:31,082] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run3
[2019-03-23 13:11:31,137] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:11:31,137] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:11:31,139] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run3
[2019-03-23 13:11:31,197] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:11:31,197] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:11:31,199] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run3
[2019-03-23 13:11:31,298] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:11:31,299] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:11:31,300] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run3
[2019-03-23 13:11:33,314] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.0841133e-12 1.0000000e+00 4.9725253e-37 6.8961015e-33 1.4804904e-35], sum to 1.0000
[2019-03-23 13:11:33,320] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7028
[2019-03-23 13:11:33,324] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 100.0, 1.0, 2.0, 0.3541551135089671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 391703.9777158659, 391703.9777158661, 117512.8877796386], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 14400.0000, 
sim time next is 15000.0000, 
raw observation next is [17.16666666666667, 99.00000000000001, 1.0, 2.0, 0.3982470326265929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 441226.6053496612, 441226.6053496615, 121346.4317065424], 
processed observation next is [1.0, 0.17391304347826086, 0.4166666666666669, 0.9900000000000001, 1.0, 1.0, 0.24780879078324108, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16341726124061526, 0.16341726124061537, 0.2959669066013229], 
reward next is 0.7040, 
noisyNet noise sample is [array([1.4803002], dtype=float32), 0.08158589]. 
=============================================
[2019-03-23 13:11:33,341] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[85.76955 ]
 [85.745636]
 [85.69774 ]
 [85.65495 ]
 [85.75355 ]], R is [[85.40155029]
 [85.26092529]
 [85.12317657]
 [84.9881897 ]
 [84.85710907]].
[2019-03-23 13:11:34,418] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 13:11:34,420] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:11:34,421] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:11:34,421] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:11:34,422] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:11:34,422] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:11:34,422] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:11:34,423] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:11:34,424] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:11:34,423] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:11:34,425] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:11:34,442] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run18
[2019-03-23 13:11:34,442] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run18
[2019-03-23 13:11:34,488] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run18
[2019-03-23 13:11:34,511] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run18
[2019-03-23 13:11:34,542] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run18
[2019-03-23 13:11:36,507] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04919493], dtype=float32), 0.15978819]
[2019-03-23 13:11:36,509] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.66666666666667, 84.0, 1.0, 2.0, 0.2052602216521925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 222858.7115485393, 222858.711548539, 71955.51016091136]
[2019-03-23 13:11:36,511] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:11:36,513] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.7762138e-07 9.9999964e-01 6.3637194e-21 4.6724571e-18 1.0716383e-19], sampled 0.33992765852180706
[2019-03-23 13:12:03,216] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04919493], dtype=float32), 0.15978819]
[2019-03-23 13:12:03,217] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.30684852666667, 78.54112065, 1.0, 2.0, 0.3296815135951247, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 357972.1579815142, 357972.1579815142, 104148.6983795231]
[2019-03-23 13:12:03,219] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:12:03,221] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.62642220e-07 9.99999523e-01 1.18874505e-20 7.99793572e-18
 1.93428535e-19], sampled 0.6585687280592858
[2019-03-23 13:12:07,111] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.04919493], dtype=float32), 0.15978819]
[2019-03-23 13:12:07,112] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [29.30030601, 56.513262475, 1.0, 2.0, 0.5775320154829723, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9121948226373007, 7.006830167491572, 6.9112, 95.55301833537925, 1201268.093824262, 1162889.539003765, 270953.5524621009]
[2019-03-23 13:12:07,113] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:12:07,115] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.1082808e-07 9.9999988e-01 1.4728784e-22 1.8413766e-19 3.0985917e-21], sampled 0.23824518352953883
[2019-03-23 13:12:07,116] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1201268.093824262 W.
[2019-03-23 13:12:29,528] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04919493], dtype=float32), 0.15978819]
[2019-03-23 13:12:29,531] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [13.65548855666666, 82.80662883166666, 1.0, 2.0, 0.2020090387469504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 219318.5540162996, 219318.5540162996, 75814.56435925215]
[2019-03-23 13:12:29,533] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:12:29,537] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.9255642e-07 9.9999976e-01 2.8970767e-21 2.3762926e-18 5.1088332e-20], sampled 0.2997151185258038
[2019-03-23 13:12:30,190] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.04919493], dtype=float32), 0.15978819]
[2019-03-23 13:12:30,192] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.88615205666667, 39.80690488, 1.0, 2.0, 0.3173787800192523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 344609.8716428575, 344609.8716428575, 93249.55628024443]
[2019-03-23 13:12:30,194] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:12:30,196] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.0474564e-07 9.9999964e-01 3.2975650e-21 2.6604786e-18 5.7826213e-20], sampled 0.7731349292668162
[2019-03-23 13:12:30,744] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.04919493], dtype=float32), 0.15978819]
[2019-03-23 13:12:30,747] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.2, 70.0, 1.0, 2.0, 0.2367618762605577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 257057.3201653713, 257057.3201653713, 85657.48110020773]
[2019-03-23 13:12:30,748] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:12:30,752] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.6972052e-07 9.9999976e-01 2.2601995e-21 1.9214978e-18 4.0435477e-20], sampled 0.14618000741571868
[2019-03-23 13:12:33,944] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.04919493], dtype=float32), 0.15978819]
[2019-03-23 13:12:33,945] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.66666666666667, 90.0, 1.0, 2.0, 0.4623121723746693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 525739.7336472434, 525739.733647243, 138130.3861745791]
[2019-03-23 13:12:33,946] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:12:33,948] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.4729312e-07 9.9999976e-01 1.7349261e-21 1.5328400e-18 3.1586952e-20], sampled 0.767712849717879
[2019-03-23 13:12:35,445] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04919493], dtype=float32), 0.15978819]
[2019-03-23 13:12:35,448] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.16666666666667, 81.16666666666667, 1.0, 2.0, 0.2809147974511244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 305025.4760707429, 305025.4760707432, 97049.106216607]
[2019-03-23 13:12:35,449] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:12:35,454] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.9201981e-07 9.9999964e-01 7.1395728e-21 5.1611384e-18 1.1964068e-19], sampled 0.4635484359805069
[2019-03-23 13:13:03,079] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.04919493], dtype=float32), 0.15978819]
[2019-03-23 13:13:03,082] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.26666666666667, 82.0, 1.0, 2.0, 0.4902236841180602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 559266.721179155, 559266.721179155, 144644.2654750427]
[2019-03-23 13:13:03,082] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:13:03,087] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.4147843e-07 9.9999976e-01 1.6117095e-21 1.4396020e-18 2.9500847e-20], sampled 0.4465073358404137
[2019-03-23 13:13:09,806] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04919493], dtype=float32), 0.15978819]
[2019-03-23 13:13:09,808] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.86666666666667, 66.0, 1.0, 2.0, 0.4949785275129412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 564684.9325912416, 564684.9325912413, 141104.8340623913]
[2019-03-23 13:13:09,809] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:13:09,813] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.9678344e-07 9.9999976e-01 3.0411523e-21 2.4812397e-18 5.3564627e-20], sampled 0.8444774714143987
[2019-03-23 13:13:14,129] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 13:13:14,169] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1361 1656178005.9856 80.0000
[2019-03-23 13:13:14,309] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3791 1683296663.2329 214.0000
[2019-03-23 13:13:14,368] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 13:13:14,487] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 13:13:15,501] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 425000, evaluation results [425000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.136132309683, 1656178005.9856246, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.379088229873, 1683296663.232874, 214.0]
[2019-03-23 13:13:21,145] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.8831486e-12 1.0000000e+00 6.6638913e-34 6.7857609e-28 1.5424557e-31], sum to 1.0000
[2019-03-23 13:13:21,153] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5863
[2019-03-23 13:13:21,159] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 53.83333333333334, 1.0, 2.0, 0.263419480404461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 286022.9645430361, 286022.9645430361, 80692.35674360477], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 159000.0000, 
sim time next is 159600.0000, 
raw observation next is [18.33333333333334, 55.66666666666667, 1.0, 2.0, 0.2596620582947904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 281941.943187103, 281941.9431871033, 80154.78729513787], 
processed observation next is [1.0, 0.8695652173913043, 0.46969696969696995, 0.5566666666666668, 1.0, 1.0, 0.07457757286848797, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10442294192114927, 0.10442294192114937, 0.19549948120765334], 
reward next is 0.8045, 
noisyNet noise sample is [array([0.23931444], dtype=float32), -0.04309278]. 
=============================================
[2019-03-23 13:13:22,789] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.3491979e-08 1.0000000e+00 3.9898474e-26 9.2178428e-24 3.1505904e-24], sum to 1.0000
[2019-03-23 13:13:22,794] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4229
[2019-03-23 13:13:22,798] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.66666666666667, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 216889.6491180412, 216889.6491180412, 72204.48259052282], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 175200.0000, 
sim time next is 175800.0000, 
raw observation next is [13.83333333333333, 88.0, 1.0, 2.0, 0.201381520757278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 218646.5141850015, 218646.5141850015, 72798.04880072539], 
processed observation next is [0.0, 0.0, 0.265151515151515, 0.88, 1.0, 1.0, 0.0017269009465974844, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08098019043888945, 0.08098019043888945, 0.17755621658713508], 
reward next is 0.8224, 
noisyNet noise sample is [array([-0.21132986], dtype=float32), -0.7944874]. 
=============================================
[2019-03-23 13:13:23,424] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.5988278e-06 9.9999642e-01 4.4304817e-19 3.5006895e-16 1.9216233e-18], sum to 1.0000
[2019-03-23 13:13:23,432] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4400
[2019-03-23 13:13:23,435] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.83333333333333, 89.00000000000001, 1.0, 2.0, 0.2008235813382162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 218040.6053062343, 218040.6053062343, 73038.65774945846], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 180600.0000, 
sim time next is 181200.0000, 
raw observation next is [13.66666666666667, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 216165.9151437561, 216165.9151437564, 72616.28825212488], 
processed observation next is [0.0, 0.08695652173913043, 0.25757575757575774, 0.9, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.080061450053243, 0.08006145005324311, 0.17711289817591436], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5218813], dtype=float32), -0.311342]. 
=============================================
[2019-03-23 13:13:30,340] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.3673216e-10 1.0000000e+00 3.9871794e-36 5.3139362e-32 6.8084248e-35], sum to 1.0000
[2019-03-23 13:13:30,350] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6514
[2019-03-23 13:13:30,355] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 41.33333333333334, 1.0, 2.0, 0.2750746618326431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 298682.1392508709, 298682.1392508709, 90956.2429904249], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 316200.0000, 
sim time next is 316800.0000, 
raw observation next is [23.0, 41.0, 1.0, 2.0, 0.2770991672535336, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 300881.0719294986, 300881.0719294989, 91898.11992387808], 
processed observation next is [0.0, 0.6956521739130435, 0.6818181818181818, 0.41, 1.0, 1.0, 0.09637395906691701, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11143743404796244, 0.11143743404796257, 0.22414175591189775], 
reward next is 0.7759, 
noisyNet noise sample is [array([0.33869666], dtype=float32), 0.58239585]. 
=============================================
[2019-03-23 13:13:34,544] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.3765541e-08 1.0000000e+00 1.0609027e-30 8.8489209e-27 2.6662675e-28], sum to 1.0000
[2019-03-23 13:13:34,552] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4954
[2019-03-23 13:13:34,559] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.66666666666667, 75.33333333333334, 1.0, 2.0, 0.2104909035452004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 228539.1930117886, 228539.1930117888, 75009.08986323839], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 418800.0000, 
sim time next is 419400.0000, 
raw observation next is [15.5, 77.0, 1.0, 2.0, 0.2076417582936723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 225445.0343251718, 225445.0343251718, 74795.9125804176], 
processed observation next is [1.0, 0.8695652173913043, 0.3409090909090909, 0.77, 1.0, 1.0, 0.00955219786709035, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08349816086117473, 0.08349816086117473, 0.18242905507418927], 
reward next is 0.8176, 
noisyNet noise sample is [array([1.6923451], dtype=float32), 0.62378037]. 
=============================================
[2019-03-23 13:13:36,029] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.5731837e-09 1.0000000e+00 3.0335994e-28 8.7690212e-25 1.1576444e-26], sum to 1.0000
[2019-03-23 13:13:36,036] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4883
[2019-03-23 13:13:36,045] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 99.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 206112.4075174821, 206112.4075174821, 71510.19532508623], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 436800.0000, 
sim time next is 437400.0000, 
raw observation next is [13.0, 99.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 206107.5723036369, 206107.5723036372, 71554.76725237124], 
processed observation next is [1.0, 0.043478260869565216, 0.22727272727272727, 0.995, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07633613789023588, 0.076336137890236, 0.1745238225667591], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.43223843], dtype=float32), -1.056544]. 
=============================================
[2019-03-23 13:13:38,115] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5200972e-10 1.0000000e+00 4.5837358e-30 2.4902505e-24 3.7069764e-27], sum to 1.0000
[2019-03-23 13:13:38,121] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1166
[2019-03-23 13:13:38,126] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.283355055667102, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 307676.0177598943, 307676.017759894, 82240.50029306677], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 463800.0000, 
sim time next is 464400.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2803702470257158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 304434.0022734383, 304434.002273438, 82147.41128767133], 
processed observation next is [1.0, 0.391304347826087, 0.22727272727272727, 1.0, 1.0, 1.0, 0.10046280878214471, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11275333417534752, 0.1127533341753474, 0.20035953972602763], 
reward next is 0.7996, 
noisyNet noise sample is [array([0.45045304], dtype=float32), 0.886514]. 
=============================================
[2019-03-23 13:13:39,714] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.5390507e-11 1.0000000e+00 5.4740631e-35 1.2068141e-31 2.6191829e-33], sum to 1.0000
[2019-03-23 13:13:39,722] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3345
[2019-03-23 13:13:39,730] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 91.0, 1.0, 2.0, 0.269937531616472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 293102.4489958705, 293102.4489958703, 89944.50596835648], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 498600.0000, 
sim time next is 499200.0000, 
raw observation next is [15.33333333333333, 92.0, 1.0, 2.0, 0.2651514992907338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 287904.1610614254, 287904.1610614251, 88883.56395309416], 
processed observation next is [1.0, 0.782608695652174, 0.3333333333333332, 0.92, 1.0, 1.0, 0.08143937411341721, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10663117076349089, 0.10663117076349078, 0.2167891803734004], 
reward next is 0.7832, 
noisyNet noise sample is [array([-0.07504441], dtype=float32), 0.10947242]. 
=============================================
[2019-03-23 13:13:41,069] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.3802268e-10 1.0000000e+00 4.8183031e-38 6.5341525e-34 4.9975509e-37], sum to 1.0000
[2019-03-23 13:13:41,077] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6919
[2019-03-23 13:13:41,081] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.00000000000001, 1.0, 2.0, 0.2118212866604729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 229983.9897195668, 229983.9897195671, 76369.7969033627], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 522600.0000, 
sim time next is 523200.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.211704010206047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 229856.6272607542, 229856.6272607542, 76358.68356001898], 
processed observation next is [1.0, 0.043478260869565216, 0.2727272727272727, 0.94, 1.0, 1.0, 0.01463001275755875, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.0851320841706497, 0.0851320841706497, 0.1862406916098024], 
reward next is 0.8138, 
noisyNet noise sample is [array([-1.0631007], dtype=float32), -0.2120396]. 
=============================================
[2019-03-23 13:13:47,234] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0009295e-11 1.0000000e+00 4.7757951e-30 1.2017913e-26 6.8641260e-28], sum to 1.0000
[2019-03-23 13:13:47,240] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8470
[2019-03-23 13:13:47,246] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666666, 84.83333333333333, 1.0, 2.0, 0.3047875754848544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 330956.0548651406, 330956.0548651409, 111514.887350176], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 633000.0000, 
sim time next is 633600.0000, 
raw observation next is [18.0, 83.0, 1.0, 2.0, 0.3064544531368768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 333302.4123156639, 333302.4123156636, 111813.9846441367], 
processed observation next is [1.0, 0.34782608695652173, 0.45454545454545453, 0.83, 1.0, 1.0, 0.13306806642109598, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12344533789469032, 0.12344533789469021, 0.2727170357174066], 
reward next is 0.7273, 
noisyNet noise sample is [array([-0.87524104], dtype=float32), 0.35816944]. 
=============================================
[2019-03-23 13:13:49,922] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.2496993e-11 1.0000000e+00 2.5866416e-28 3.7332174e-26 3.0611034e-28], sum to 1.0000
[2019-03-23 13:13:49,936] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8471
[2019-03-23 13:13:49,939] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 94.0, 1.0, 2.0, 0.3029825946657501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 328995.4388532988, 328995.4388532991, 103327.2544886813], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 712800.0000, 
sim time next is 713400.0000, 
raw observation next is [16.33333333333334, 93.00000000000001, 1.0, 2.0, 0.3327805207760797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 361363.7150331566, 361363.7150331566, 110362.3519148727], 
processed observation next is [1.0, 0.2608695652173913, 0.37878787878787906, 0.9300000000000002, 1.0, 1.0, 0.16597565097009964, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13383841297524318, 0.13383841297524318, 0.26917646808505535], 
reward next is 0.7308, 
noisyNet noise sample is [array([-1.6722935], dtype=float32), 0.69492286]. 
=============================================
[2019-03-23 13:13:52,247] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.6015133e-09 1.0000000e+00 2.3604022e-25 3.8044878e-23 2.5255529e-23], sum to 1.0000
[2019-03-23 13:13:52,252] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4183
[2019-03-23 13:13:52,261] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 58.0, 1.0, 2.0, 0.4739861515054887, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 540854.3870567742, 540854.387056774, 138093.0696132467], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 757800.0000, 
sim time next is 758400.0000, 
raw observation next is [27.0, 58.0, 1.0, 2.0, 0.472444829328993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 539094.7020128143, 539094.7020128143, 137920.5723282156], 
processed observation next is [1.0, 0.782608695652174, 0.8636363636363636, 0.58, 1.0, 1.0, 0.34055603666124123, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1996647044491905, 0.1996647044491905, 0.3363916398249161], 
reward next is 0.6636, 
noisyNet noise sample is [array([-0.82138693], dtype=float32), -2.0356097]. 
=============================================
[2019-03-23 13:13:55,903] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.9546498e-09 1.0000000e+00 4.4807362e-28 1.8522708e-24 1.3361677e-24], sum to 1.0000
[2019-03-23 13:13:55,911] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3200
[2019-03-23 13:13:55,914] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 83.83333333333334, 1.0, 2.0, 0.4397567715584272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 500911.0305513768, 500911.030551377, 132311.6985731785], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 805800.0000, 
sim time next is 806400.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4419870657377261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 503552.1612100686, 503552.1612100686, 132662.6053076166], 
processed observation next is [0.0, 0.34782608695652173, 0.6363636363636364, 0.83, 1.0, 1.0, 0.30248383217215763, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18650080044817358, 0.18650080044817358, 0.3235673300185771], 
reward next is 0.6764, 
noisyNet noise sample is [array([-0.40151075], dtype=float32), -1.4288383]. 
=============================================
[2019-03-23 13:13:56,991] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.5936374e-10 1.0000000e+00 6.2828934e-28 9.3379321e-23 1.8991768e-26], sum to 1.0000
[2019-03-23 13:13:56,998] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1390
[2019-03-23 13:13:57,001] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 55.0, 1.0, 2.0, 0.5304245394254601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 603323.349542184, 603323.349542184, 147190.2729774513], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 832800.0000, 
sim time next is 833400.0000, 
raw observation next is [29.0, 55.0, 1.0, 2.0, 0.5319597032333537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 605069.797326178, 605069.7973261783, 147381.4753436833], 
processed observation next is [0.0, 0.6521739130434783, 0.9545454545454546, 0.55, 1.0, 1.0, 0.41494962904169214, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2240999249356215, 0.22409992493562159, 0.3594670130333739], 
reward next is 0.6405, 
noisyNet noise sample is [array([0.5913644], dtype=float32), -0.21798177]. 
=============================================
[2019-03-23 13:14:01,813] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.0557197e-10 1.0000000e+00 1.1866041e-25 4.1511678e-22 2.4098601e-25], sum to 1.0000
[2019-03-23 13:14:01,819] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2600
[2019-03-23 13:14:01,823] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.00000000000001, 1.0, 2.0, 0.4349969447761111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 494906.5886180954, 494906.5886180954, 131210.5349362972], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 929400.0000, 
sim time next is 930000.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.4378720403501203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 498184.193366529, 498184.193366529, 131505.2734807484], 
processed observation next is [0.0, 0.782608695652174, 0.5909090909090909, 0.88, 1.0, 1.0, 0.2973400504376503, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18451266420982557, 0.18451266420982557, 0.32074456946524005], 
reward next is 0.6793, 
noisyNet noise sample is [array([1.3150734], dtype=float32), -0.9063813]. 
=============================================
[2019-03-23 13:14:01,840] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[59.02031 ]
 [59.035923]
 [59.024418]
 [59.02938 ]
 [59.039673]], R is [[59.10260391]
 [59.19155121]
 [59.28043747]
 [59.36926651]
 [59.45774841]].
[2019-03-23 13:14:04,188] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 13:14:04,189] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:14:04,190] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:14:04,191] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:14:04,191] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:14:04,190] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:14:04,194] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:14:04,195] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:14:04,196] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:14:04,197] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:14:04,200] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:14:04,207] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run19
[2019-03-23 13:14:04,230] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run19
[2019-03-23 13:14:04,252] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run19
[2019-03-23 13:14:04,276] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run19
[2019-03-23 13:14:04,276] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run19
[2019-03-23 13:14:27,537] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05112861], dtype=float32), 0.16996057]
[2019-03-23 13:14:27,538] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.45, 46.0, 1.0, 2.0, 0.3289325385451408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 361596.1518069387, 361596.1518069383, 119053.1986172527]
[2019-03-23 13:14:27,539] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:14:27,543] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.2279034e-10 1.0000000e+00 2.9762054e-29 2.2978562e-25 1.8506789e-27], sampled 0.537781786008417
[2019-03-23 13:14:35,054] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05112861], dtype=float32), 0.16996057]
[2019-03-23 13:14:35,056] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.16666666666667, 68.33333333333333, 1.0, 2.0, 0.3752814174004916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 421948.3084389602, 421948.3084389599, 122166.001295665]
[2019-03-23 13:14:35,059] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:14:35,063] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0045357e-09 1.0000000e+00 5.5194552e-29 3.9181304e-25 3.3054651e-27], sampled 0.8403682023028808
[2019-03-23 13:14:44,084] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05112861], dtype=float32), 0.16996057]
[2019-03-23 13:14:44,085] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.3, 56.0, 1.0, 2.0, 0.4541234611201771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 505814.2040754589, 505814.2040754585, 131573.1158488266]
[2019-03-23 13:14:44,089] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:14:44,094] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.0800344e-10 1.0000000e+00 2.8171483e-29 2.1909574e-25 1.7575698e-27], sampled 0.5985491880852045
[2019-03-23 13:14:45,136] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05112861], dtype=float32), 0.16996057]
[2019-03-23 13:14:45,138] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.35, 87.0, 1.0, 2.0, 0.4784938067432361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 544992.10558803, 544992.1055880296, 140683.6222780604]
[2019-03-23 13:14:45,140] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:14:45,144] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.2150852e-10 1.0000000e+00 3.7726365e-30 3.8568978e-26 2.6612276e-28], sampled 0.16438340912927318
[2019-03-23 13:14:50,673] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05112861], dtype=float32), 0.16996057]
[2019-03-23 13:14:50,676] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.16666666666666, 75.5, 1.0, 2.0, 0.2779464662118203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 301801.3753891704, 301801.3753891704, 100836.160233344]
[2019-03-23 13:14:50,678] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:14:50,682] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.5189822e-09 1.0000000e+00 1.9798378e-28 1.1812979e-24 1.0969307e-26], sampled 0.3021993444005857
[2019-03-23 13:14:52,897] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05112861], dtype=float32), 0.16996057]
[2019-03-23 13:14:52,901] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.95, 84.0, 1.0, 2.0, 0.3725625766712944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 418639.718865379, 418639.718865379, 126129.5099970758]
[2019-03-23 13:14:52,901] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:14:52,905] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.2467835e-10 1.0000000e+00 3.8560661e-30 3.9298490e-26 2.7161079e-28], sampled 0.7241204966255519
[2019-03-23 13:15:08,193] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05112861], dtype=float32), 0.16996057]
[2019-03-23 13:15:08,195] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.3757185, 84.60732394, 1.0, 2.0, 0.4708189025596831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 536869.296264476, 536869.2962644757, 143036.3226007924]
[2019-03-23 13:15:08,197] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:15:08,199] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.8059500e-10 1.0000000e+00 2.7481217e-30 2.9328080e-26 1.9760577e-28], sampled 0.49914415974784265
[2019-03-23 13:15:08,800] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05112861], dtype=float32), 0.16996057]
[2019-03-23 13:15:08,803] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.81955321, 96.708829165, 1.0, 2.0, 0.6080451129838692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 683782.1119668331, 683782.1119668328, 164206.5910815439]
[2019-03-23 13:15:08,805] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:15:08,807] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.5881721e-10 1.0000000e+00 9.0220941e-30 8.1919144e-26 6.0346901e-28], sampled 0.02313382648294915
[2019-03-23 13:15:11,398] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05112861], dtype=float32), 0.16996057]
[2019-03-23 13:15:11,399] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.91666666666667, 74.33333333333334, 1.0, 2.0, 0.3685625468701522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 412652.0417508293, 412652.0417508286, 125067.7132401675]
[2019-03-23 13:15:11,400] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:15:11,402] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.5667117e-10 1.0000000e+00 2.2998158e-29 1.8387109e-25 1.4530024e-27], sampled 0.03819369899905145
[2019-03-23 13:15:32,868] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05112861], dtype=float32), 0.16996057]
[2019-03-23 13:15:32,869] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.9, 73.33333333333334, 1.0, 2.0, 0.8144072106141343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 925151.389716091, 925151.3897160906, 193629.1485526249]
[2019-03-23 13:15:32,870] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:15:32,873] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.9162449e-10 1.0000000e+00 2.6471122e-29 2.0762568e-25 1.6578434e-27], sampled 0.7875213986742882
[2019-03-23 13:15:43,667] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05112861], dtype=float32), 0.16996057]
[2019-03-23 13:15:43,668] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.17331048, 45.99185526333333, 1.0, 2.0, 0.5214896591650131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 580241.8465714846, 580241.8465714846, 137845.7995560684]
[2019-03-23 13:15:43,670] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:15:43,673] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.2386935e-09 1.0000000e+00 1.0567758e-28 6.8655768e-25 6.0813511e-27], sampled 0.8372951989445603
[2019-03-23 13:15:44,501] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 13:15:44,655] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 13:15:44,857] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 13:15:44,895] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 13:15:44,945] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2861 1773154298.0034 173.0000
[2019-03-23 13:15:45,962] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 450000, evaluation results [450000.0, 8512.28612121474, 1773154298.0034232, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 13:15:48,063] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.0144304e-11 1.0000000e+00 2.3435408e-35 3.6242635e-30 2.2028751e-32], sum to 1.0000
[2019-03-23 13:15:48,073] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3765
[2019-03-23 13:15:48,078] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.33333333333333, 98.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 192765.274272572, 192765.2742725723, 67321.07613675598], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1039200.0000, 
sim time next is 1039800.0000, 
raw observation next is [12.16666666666667, 99.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 189535.1636603689, 189535.1636603691, 66614.60605883678], 
processed observation next is [1.0, 0.0, 0.18939393939393953, 0.99, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0701982087630996, 0.07019820876309966, 0.16247464892399216], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.38539538], dtype=float32), 0.60665315]. 
=============================================
[2019-03-23 13:15:48,800] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.5695035e-11 1.0000000e+00 6.9511201e-32 1.5699490e-28 1.0006826e-31], sum to 1.0000
[2019-03-23 13:15:48,809] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5312
[2019-03-23 13:15:48,820] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2204856896651721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 239393.6405735642, 239393.6405735645, 75769.9982177255], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1025400.0000, 
sim time next is 1026000.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2183762793758613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 237102.7776516576, 237102.7776516579, 75565.10749927536], 
processed observation next is [1.0, 0.9130434782608695, 0.22727272727272727, 1.0, 1.0, 1.0, 0.022970349219826602, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08781584357468801, 0.08781584357468811, 0.184305140242135], 
reward next is 0.8157, 
noisyNet noise sample is [array([-0.21169907], dtype=float32), -0.5302656]. 
=============================================
[2019-03-23 13:15:48,839] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[77.38071 ]
 [77.40228 ]
 [77.417656]
 [77.45955 ]
 [77.507965]], R is [[77.42503357]
 [77.46598053]
 [77.50643921]
 [77.54683685]
 [77.5867691 ]].
[2019-03-23 13:15:49,497] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.5321754e-08 1.0000000e+00 2.9962294e-23 1.0492124e-20 6.5074270e-22], sum to 1.0000
[2019-03-23 13:15:49,505] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9675
[2019-03-23 13:15:49,507] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 94.0, 1.0, 2.0, 0.4691761297639991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 509552.2333683389, 509552.2333683389, 100010.083905165], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1056600.0000, 
sim time next is 1057200.0000, 
raw observation next is [13.0, 94.0, 1.0, 2.0, 0.4392179909686459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 477000.0109187847, 477000.0109187847, 96932.64137620822], 
processed observation next is [1.0, 0.21739130434782608, 0.22727272727272727, 0.94, 1.0, 1.0, 0.29902248871080733, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.176666670710661, 0.176666670710661, 0.23642107652733713], 
reward next is 0.7636, 
noisyNet noise sample is [array([0.5765101], dtype=float32), 1.3663535]. 
=============================================
[2019-03-23 13:15:55,180] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.2878217e-09 1.0000000e+00 2.7625031e-28 1.7206734e-25 1.4129751e-26], sum to 1.0000
[2019-03-23 13:15:55,186] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5631
[2019-03-23 13:15:55,191] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.00000000000001, 1.0, 2.0, 0.3484668726925741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 387751.167507653, 387751.1675076532, 118022.9166758465], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1141800.0000, 
sim time next is 1142400.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.3435410548890108, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 382268.7527753639, 382268.7527753639, 117635.3675542094], 
processed observation next is [1.0, 0.21739130434782608, 0.45454545454545453, 0.94, 1.0, 1.0, 0.1794263186112635, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14158101954643107, 0.14158101954643107, 0.28691553062002295], 
reward next is 0.7131, 
noisyNet noise sample is [array([-0.31237638], dtype=float32), -0.28176054]. 
=============================================
[2019-03-23 13:15:57,213] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6989882e-08 1.0000000e+00 4.3587064e-23 6.4135904e-19 4.2789576e-21], sum to 1.0000
[2019-03-23 13:15:57,224] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6926
[2019-03-23 13:15:57,231] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.83333333333334, 70.66666666666667, 1.0, 2.0, 0.5185811741153342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 590461.7210730041, 590461.7210730041, 145308.4685869696], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1192200.0000, 
sim time next is 1192800.0000, 
raw observation next is [25.66666666666667, 71.33333333333334, 1.0, 2.0, 0.5170956504029625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 588893.7440306015, 588893.7440306011, 145028.9788132616], 
processed observation next is [1.0, 0.8260869565217391, 0.8030303030303032, 0.7133333333333334, 1.0, 1.0, 0.396369563003703, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21810879408540795, 0.21810879408540781, 0.35372921661771123], 
reward next is 0.6463, 
noisyNet noise sample is [array([0.05004936], dtype=float32), -0.78470945]. 
=============================================
[2019-03-23 13:16:00,198] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.5608942e-09 1.0000000e+00 8.1421337e-25 2.3491069e-21 6.7190679e-22], sum to 1.0000
[2019-03-23 13:16:00,203] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2932
[2019-03-23 13:16:00,208] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.8788403882652275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1002401.101332834, 1002401.101332834, 197584.1189473901], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1242000.0000, 
sim time next is 1242600.0000, 
raw observation next is [22.33333333333334, 91.33333333333334, 1.0, 2.0, 0.9960317095720309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.335767632339839, 6.9112, 77.32762103376, 1274175.183528612, 1136285.802626154, 219105.9657126178], 
processed observation next is [1.0, 0.391304347826087, 0.6515151515151518, 0.9133333333333334, 1.0, 1.0, 0.9950396369650385, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.04245676323398388, 0.0, 0.5084232741399013, 0.47191673464022665, 0.4208465935652422, 0.534404794421019], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7139765], dtype=float32), 0.9042145]. 
=============================================
[2019-03-23 13:16:02,274] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.1290461e-08 1.0000000e+00 1.2647770e-26 4.5873358e-24 7.4463179e-25], sum to 1.0000
[2019-03-23 13:16:02,289] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2384
[2019-03-23 13:16:02,297] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.00000000000001, 1.0, 2.0, 0.3569338614240458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 397234.4671638165, 397234.4671638168, 118721.162407649], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1296600.0000, 
sim time next is 1297200.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.3564545611689956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 396699.1692578292, 396699.1692578289, 118682.0535244918], 
processed observation next is [1.0, 0.0, 0.45454545454545453, 0.94, 1.0, 1.0, 0.19556820146124448, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14692561824364045, 0.14692561824364034, 0.2894684232304678], 
reward next is 0.7105, 
noisyNet noise sample is [array([-0.02613418], dtype=float32), -0.20814933]. 
=============================================
[2019-03-23 13:16:06,457] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0605823e-09 1.0000000e+00 2.5795482e-27 4.7406896e-23 5.0805246e-25], sum to 1.0000
[2019-03-23 13:16:06,465] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9521
[2019-03-23 13:16:06,476] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1143538.099331086 W.
[2019-03-23 13:16:06,480] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.5, 84.0, 1.0, 2.0, 0.5217683457805001, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9566832465904879, 6.936627675760589, 6.9112, 77.32840106538292, 1143538.099331086, 1135279.716991709, 259063.8046226283], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1353000.0000, 
sim time next is 1353600.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4923911849230153, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9421858123815762, 6.954627429114711, 6.9112, 77.3283414280312, 1110276.333094615, 1096172.014617734, 249750.1872062156], 
processed observation next is [1.0, 0.6956521739130435, 0.6363636363636364, 0.83, 1.0, 1.0, 0.3654889811537691, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9174083034022519, 0.00434274291147112, 0.0, 0.5084280106778826, 0.4112134567017093, 0.40598963504360513, 0.6091467980639405], 
reward next is 0.1737, 
noisyNet noise sample is [array([2.3938782], dtype=float32), -0.71147925]. 
=============================================
[2019-03-23 13:16:08,208] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.46548421e-10 1.00000000e+00 1.14448304e-29 3.59309280e-25
 1.75621774e-25], sum to 1.0000
[2019-03-23 13:16:08,216] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8479
[2019-03-23 13:16:08,219] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.4957012408507045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 565328.2472380463, 565328.2472380463, 141560.5763956346], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1411200.0000, 
sim time next is 1411800.0000, 
raw observation next is [22.16666666666667, 93.16666666666667, 1.0, 2.0, 0.4978613870064081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 567717.7593846018, 567717.7593846021, 141931.4198849726], 
processed observation next is [0.0, 0.34782608695652173, 0.6439393939393941, 0.9316666666666668, 1.0, 1.0, 0.37232673375801006, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2102658368091118, 0.21026583680911187, 0.34617419484139655], 
reward next is 0.6538, 
noisyNet noise sample is [array([-0.28062263], dtype=float32), -2.3186905]. 
=============================================
[2019-03-23 13:16:16,043] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.7276434e-12 1.0000000e+00 7.2345306e-32 6.9058330e-28 1.5728152e-27], sum to 1.0000
[2019-03-23 13:16:16,048] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7452
[2019-03-23 13:16:16,052] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 81.0, 1.0, 2.0, 0.5589412665003406, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 633492.9160699741, 633492.9160699741, 151862.691672306], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1535400.0000, 
sim time next is 1536000.0000, 
raw observation next is [24.66666666666667, 81.66666666666666, 1.0, 2.0, 0.5486318106611606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 622792.6811689954, 622792.6811689954, 150123.8438584058], 
processed observation next is [0.0, 0.782608695652174, 0.7575757575757578, 0.8166666666666665, 1.0, 1.0, 0.43578976332645075, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23066395598851683, 0.23066395598851683, 0.36615571672781905], 
reward next is 0.6338, 
noisyNet noise sample is [array([1.4781932], dtype=float32), 0.42195094]. 
=============================================
[2019-03-23 13:16:16,079] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[70.160965]
 [70.10551 ]
 [70.05946 ]
 [70.02012 ]
 [69.965836]], R is [[70.14607239]
 [70.07421112]
 [69.99925995]
 [69.92195892]
 [69.84377289]].
[2019-03-23 13:16:18,368] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.1341066e-10 1.0000000e+00 8.0827001e-29 2.7883284e-26 7.7241747e-27], sum to 1.0000
[2019-03-23 13:16:18,374] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0009
[2019-03-23 13:16:18,381] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 94.0, 1.0, 2.0, 0.4723292178321546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 538936.4318514955, 538936.4318514955, 138145.368823396], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1582800.0000, 
sim time next is 1583400.0000, 
raw observation next is [21.83333333333334, 94.0, 1.0, 2.0, 0.4872567615614969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 555883.5373226064, 555883.5373226064, 140183.3160847491], 
processed observation next is [1.0, 0.30434782608695654, 0.628787878787879, 0.94, 1.0, 1.0, 0.35907095195187105, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20588279160096534, 0.20588279160096534, 0.3419105270359734], 
reward next is 0.6581, 
noisyNet noise sample is [array([-0.02282177], dtype=float32), 2.1892388]. 
=============================================
[2019-03-23 13:16:28,304] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.1489308e-13 1.0000000e+00 2.5494464e-35 2.3835429e-29 5.1831839e-31], sum to 1.0000
[2019-03-23 13:16:28,313] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2952
[2019-03-23 13:16:28,319] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 52.0, 1.0, 2.0, 0.2257772891749842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 245140.4738658511, 245140.4738658514, 72749.52712887399], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1803600.0000, 
sim time next is 1804200.0000, 
raw observation next is [17.0, 52.5, 1.0, 2.0, 0.2264883734366213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 245912.7375428199, 245912.7375428199, 72921.81225249138], 
processed observation next is [1.0, 0.9130434782608695, 0.4090909090909091, 0.525, 1.0, 1.0, 0.033110466795776596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09107879168252589, 0.09107879168252589, 0.17785807866461312], 
reward next is 0.8221, 
noisyNet noise sample is [array([-1.6655964], dtype=float32), -0.5638152]. 
=============================================
[2019-03-23 13:16:28,395] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3224693e-12 1.0000000e+00 3.3899805e-32 1.1390611e-28 1.3280491e-29], sum to 1.0000
[2019-03-23 13:16:28,405] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3211
[2019-03-23 13:16:28,411] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 51.0, 1.0, 2.0, 0.3167137560314527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 343910.7737660002, 343910.7737660002, 80076.70285680822], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1765800.0000, 
sim time next is 1766400.0000, 
raw observation next is [16.0, 51.0, 1.0, 2.0, 0.3273216609858278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 355433.8162852126, 355433.8162852129, 80972.13658971856], 
processed observation next is [1.0, 0.43478260869565216, 0.36363636363636365, 0.51, 1.0, 1.0, 0.15915207623228475, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13164215417970837, 0.13164215417970848, 0.1974930160724843], 
reward next is 0.8025, 
noisyNet noise sample is [array([1.7946659], dtype=float32), 1.7039995]. 
=============================================
[2019-03-23 13:16:29,759] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.8842423e-13 1.0000000e+00 6.1814840e-33 2.1153139e-29 3.6350752e-31], sum to 1.0000
[2019-03-23 13:16:29,765] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3099
[2019-03-23 13:16:29,770] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [10.33333333333333, 100.0, 1.0, 2.0, 0.3432035036269434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 372686.2863741116, 372686.2863741119, 82229.50418580184], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1833600.0000, 
sim time next is 1834200.0000, 
raw observation next is [10.5, 100.0, 1.0, 2.0, 0.3406353537548021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 369896.4597298147, 369896.459729815, 82214.55982577291], 
processed observation next is [1.0, 0.21739130434782608, 0.11363636363636363, 1.0, 1.0, 1.0, 0.1757941921935026, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13699868878882027, 0.13699868878882038, 0.20052331664822662], 
reward next is 0.7995, 
noisyNet noise sample is [array([0.95886964], dtype=float32), -0.16932015]. 
=============================================
[2019-03-23 13:16:34,931] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 13:16:34,933] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:16:34,934] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:16:34,935] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:16:34,936] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:16:34,937] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:16:34,938] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:16:34,939] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:16:34,940] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:16:34,941] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:16:34,943] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:16:34,951] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run20
[2019-03-23 13:16:34,974] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run20
[2019-03-23 13:16:34,999] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run20
[2019-03-23 13:16:35,023] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run20
[2019-03-23 13:16:35,049] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run20
[2019-03-23 13:16:38,186] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05208749], dtype=float32), 0.17684019]
[2019-03-23 13:16:38,187] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.3, 43.33333333333334, 1.0, 2.0, 0.2883411835504474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 313072.6378871045, 313072.6378871042, 90512.93453451624]
[2019-03-23 13:16:38,189] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:16:38,192] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.17349163e-12 1.00000000e+00 1.02809092e-35 4.97485525e-31
 1.10191825e-32], sampled 0.5330967350508433
[2019-03-23 13:16:53,674] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05208749], dtype=float32), 0.17684019]
[2019-03-23 13:16:53,674] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.23305734833334, 76.85496862000001, 1.0, 2.0, 0.719795933246564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 818049.5565871401, 818049.5565871401, 178145.5170775577]
[2019-03-23 13:16:53,675] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:16:53,679] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.5611003e-13 1.0000000e+00 3.0190841e-38 3.1859633e-33 5.3158948e-35], sampled 0.43726998985433563
[2019-03-23 13:17:00,159] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05208749], dtype=float32), 0.17684019]
[2019-03-23 13:17:00,160] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.33333333333334, 80.33333333333334, 1.0, 2.0, 0.3314305745561528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 359897.2767207163, 359897.2767207163, 93196.49994033045]
[2019-03-23 13:17:00,161] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:17:00,163] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.9981395e-12 1.0000000e+00 2.5603704e-36 1.4920710e-31 3.0895206e-33], sampled 0.06824687946238805
[2019-03-23 13:17:04,097] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05208749], dtype=float32), 0.17684019]
[2019-03-23 13:17:04,101] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.58333333333333, 82.16666666666667, 1.0, 2.0, 0.6166781102616379, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 689471.963985772, 689471.9639857716, 149300.2585421311]
[2019-03-23 13:17:04,102] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:17:04,106] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.1633784e-13 1.0000000e+00 4.3838692e-38 4.4005178e-33 7.4753101e-35], sampled 0.9955915441659252
[2019-03-23 13:17:54,222] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05208749], dtype=float32), 0.17684019]
[2019-03-23 13:17:54,222] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.8, 77.0, 1.0, 2.0, 0.5167837339060418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588537.579543433, 588537.579543433, 144992.0176610946]
[2019-03-23 13:17:54,224] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:17:54,226] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.0838268e-13 1.0000000e+00 1.1344635e-37 1.0028411e-32 1.7846351e-34], sampled 0.7876564388123746
[2019-03-23 13:18:01,912] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05208749], dtype=float32), 0.17684019]
[2019-03-23 13:18:01,912] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.96123371, 81.55590366499999, 1.0, 2.0, 0.4043915881811031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 457802.9710758735, 457802.9710758732, 130794.332497597]
[2019-03-23 13:18:01,913] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:18:01,916] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.2472913e-13 1.0000000e+00 4.6001478e-38 4.5873498e-33 7.8119739e-35], sampled 0.23784829625890858
[2019-03-23 13:18:14,835] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 13:18:14,916] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 13:18:15,177] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 13:18:15,352] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 13:18:15,465] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 13:18:16,481] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 475000, evaluation results [475000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 13:18:17,056] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.6447780e-11 1.0000000e+00 6.5565373e-30 2.5115222e-26 1.0863365e-27], sum to 1.0000
[2019-03-23 13:18:17,068] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2353
[2019-03-23 13:18:17,074] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 97.0, 1.0, 2.0, 0.3462007792926449, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 386840.7255178929, 386840.7255178932, 118552.6763336574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1913400.0000, 
sim time next is 1914000.0000, 
raw observation next is [18.0, 98.0, 1.0, 2.0, 0.3494213221980818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 391004.2107454648, 391004.2107454651, 119070.5534865239], 
processed observation next is [1.0, 0.13043478260869565, 0.45454545454545453, 0.98, 1.0, 1.0, 0.18677665274760225, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14481637435017214, 0.14481637435017228, 0.2904159841134729], 
reward next is 0.7096, 
noisyNet noise sample is [array([2.4212146], dtype=float32), 0.0022782278]. 
=============================================
[2019-03-23 13:18:17,087] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[69.55759 ]
 [69.45416 ]
 [69.47654 ]
 [69.38981 ]
 [69.301056]], R is [[69.67517853]
 [69.68927002]
 [69.70433044]
 [69.72009277]
 [69.73737335]].
[2019-03-23 13:18:27,349] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.5127500e-10 1.0000000e+00 1.1990019e-27 3.4934173e-24 7.7877640e-25], sum to 1.0000
[2019-03-23 13:18:27,356] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8019
[2019-03-23 13:18:27,360] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333333, 58.0, 1.0, 2.0, 0.3192643396634952, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 351581.1562221225, 351581.1562221228, 114270.1853170997], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2108400.0000, 
sim time next is 2109000.0000, 
raw observation next is [22.66666666666667, 57.5, 1.0, 2.0, 0.3249471836196448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 359167.3560122128, 359167.3560122125, 115200.8644636252], 
processed observation next is [0.0, 0.391304347826087, 0.6666666666666669, 0.575, 1.0, 1.0, 0.15618397952455598, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13302494667118994, 0.13302494667118983, 0.2809777182039639], 
reward next is 0.7190, 
noisyNet noise sample is [array([1.2038192], dtype=float32), -0.83566374]. 
=============================================
[2019-03-23 13:18:27,378] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[64.23795 ]
 [64.215324]
 [64.19486 ]
 [64.17829 ]
 [64.16937 ]], R is [[64.34507751]
 [64.42292023]
 [64.50232697]
 [64.58326721]
 [64.66577148]].
[2019-03-23 13:18:43,684] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.2963836e-11 1.0000000e+00 1.1947905e-30 1.7992845e-26 1.1557106e-28], sum to 1.0000
[2019-03-23 13:18:43,694] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6299
[2019-03-23 13:18:43,697] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 89.00000000000001, 1.0, 2.0, 0.2596256327144825, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 281902.3807059495, 281902.3807059495, 79217.69881351662], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2427000.0000, 
sim time next is 2427600.0000, 
raw observation next is [14.0, 90.0, 1.0, 2.0, 0.2262556012406204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 245659.9382366446, 245659.9382366446, 76723.32398427851], 
processed observation next is [1.0, 0.08695652173913043, 0.2727272727272727, 0.9, 1.0, 1.0, 0.0328195015507755, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09098516230986838, 0.09098516230986838, 0.18713005849824027], 
reward next is 0.8129, 
noisyNet noise sample is [array([1.6423236], dtype=float32), 0.37364468]. 
=============================================
[2019-03-23 13:18:45,154] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.1058217e-11 1.0000000e+00 1.7878258e-32 4.0561098e-27 8.1947689e-31], sum to 1.0000
[2019-03-23 13:18:45,162] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7869
[2019-03-23 13:18:45,170] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.5, 85.0, 1.0, 2.0, 0.5107542704587484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 554734.2493160967, 554734.2493160967, 118852.9575844881], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2457000.0000, 
sim time next is 2457600.0000, 
raw observation next is [16.66666666666666, 86.0, 1.0, 2.0, 0.5086613968613858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 552459.87099427, 552459.8709942702, 121546.0898237038], 
processed observation next is [1.0, 0.43478260869565216, 0.39393939393939365, 0.86, 1.0, 1.0, 0.3858267460767322, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2046147670349148, 0.20461476703491488, 0.2964538776187898], 
reward next is 0.7035, 
noisyNet noise sample is [array([0.02804717], dtype=float32), 0.06587434]. 
=============================================
[2019-03-23 13:18:45,259] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.4302431e-12 1.0000000e+00 3.4263688e-33 6.5365526e-32 5.1184004e-32], sum to 1.0000
[2019-03-23 13:18:45,268] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3856
[2019-03-23 13:18:45,277] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.5, 85.0, 1.0, 2.0, 0.5107542704587484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 554734.2493160967, 554734.2493160967, 118852.9575844881], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2457000.0000, 
sim time next is 2457600.0000, 
raw observation next is [16.66666666666666, 86.0, 1.0, 2.0, 0.5086613968613858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 552459.87099427, 552459.8709942702, 121546.0898237038], 
processed observation next is [1.0, 0.43478260869565216, 0.39393939393939365, 0.86, 1.0, 1.0, 0.3858267460767322, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2046147670349148, 0.20461476703491488, 0.2964538776187898], 
reward next is 0.7035, 
noisyNet noise sample is [array([-0.16135459], dtype=float32), 1.0016363]. 
=============================================
[2019-03-23 13:18:46,775] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6784648e-11 1.0000000e+00 6.0818226e-32 1.6457336e-26 6.1517158e-29], sum to 1.0000
[2019-03-23 13:18:46,782] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8428
[2019-03-23 13:18:46,787] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.66666666666667, 96.0, 1.0, 2.0, 0.2298017837542441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 249511.239254183, 249511.239254183, 77761.96465695878], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2492400.0000, 
sim time next is 2493000.0000, 
raw observation next is [13.5, 97.0, 1.0, 2.0, 0.228056143231091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 247615.3975675354, 247615.3975675357, 77320.18341793786], 
processed observation next is [1.0, 0.8695652173913043, 0.25, 0.97, 1.0, 1.0, 0.03507017903886373, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09170940650649459, 0.0917094065064947, 0.1885858132144826], 
reward next is 0.8114, 
noisyNet noise sample is [array([-1.3459419], dtype=float32), 0.8625015]. 
=============================================
[2019-03-23 13:18:46,798] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[75.54882 ]
 [75.646996]
 [75.744   ]
 [75.84437 ]
 [75.93761 ]], R is [[75.61270142]
 [75.66690826]
 [75.71955872]
 [75.77071381]
 [75.82118225]].
[2019-03-23 13:18:51,954] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6311537e-09 1.0000000e+00 1.0739781e-29 1.2076467e-25 5.2138304e-28], sum to 1.0000
[2019-03-23 13:18:51,962] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8907
[2019-03-23 13:18:51,967] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.03333333333333, 92.0, 1.0, 2.0, 0.312113081383623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 340128.9895166467, 340128.9895166467, 112434.8797647207], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2598000.0000, 
sim time next is 2598600.0000, 
raw observation next is [16.96666666666667, 93.0, 1.0, 2.0, 0.3136948093432292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 342154.2355600817, 342154.2355600814, 112650.5794940127], 
processed observation next is [0.0, 0.043478260869565216, 0.40757575757575765, 0.93, 1.0, 1.0, 0.14211851167903647, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12672379094817843, 0.1267237909481783, 0.2747575109610066], 
reward next is 0.7252, 
noisyNet noise sample is [array([0.61257786], dtype=float32), 0.30239698]. 
=============================================
[2019-03-23 13:18:54,050] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2721642e-10 1.0000000e+00 1.2517858e-30 5.5726239e-28 4.2985234e-29], sum to 1.0000
[2019-03-23 13:18:54,055] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1721
[2019-03-23 13:18:54,068] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 38.0, 1.0, 2.0, 0.357279765614168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 400913.8607385846, 400913.8607385849, 120241.3944883136], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2647200.0000, 
sim time next is 2647800.0000, 
raw observation next is [28.0, 38.5, 1.0, 2.0, 0.3615693111518664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 406199.5687030219, 406199.5687030221, 120832.1541437957], 
processed observation next is [0.0, 0.6521739130434783, 0.9090909090909091, 0.385, 1.0, 1.0, 0.201961638939833, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15044428470482293, 0.150444284704823, 0.29471257108242854], 
reward next is 0.7053, 
noisyNet noise sample is [array([1.1280197], dtype=float32), 0.11001433]. 
=============================================
[2019-03-23 13:18:59,044] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.9729244e-12 1.0000000e+00 9.3931796e-35 5.7846231e-30 1.9486041e-32], sum to 1.0000
[2019-03-23 13:18:59,051] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8460
[2019-03-23 13:18:59,059] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 64.33333333333334, 1.0, 2.0, 0.4918740299583916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560958.8820090033, 560958.8820090033, 141119.5003766785], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2726400.0000, 
sim time next is 2727000.0000, 
raw observation next is [26.0, 65.5, 1.0, 2.0, 0.4891518255307687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 557974.8189840426, 557974.8189840426, 140573.9278032719], 
processed observation next is [0.0, 0.5652173913043478, 0.8181818181818182, 0.655, 1.0, 1.0, 0.3614397819134608, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20665734036446023, 0.20665734036446023, 0.3428632385445656], 
reward next is 0.6571, 
noisyNet noise sample is [array([-0.14100288], dtype=float32), 0.09889816]. 
=============================================
[2019-03-23 13:18:59,090] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[76.912056]
 [76.82452 ]
 [76.754715]
 [76.68335 ]
 [76.633835]], R is [[76.88790131]
 [76.77483368]
 [76.66182709]
 [76.54957581]
 [76.43956757]].
[2019-03-23 13:19:01,163] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.3130876e-12 1.0000000e+00 1.5048228e-32 7.8681641e-29 2.5985365e-30], sum to 1.0000
[2019-03-23 13:19:01,173] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0443
[2019-03-23 13:19:01,177] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.16666666666666, 87.16666666666667, 1.0, 2.0, 0.3472527954323912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 382863.2529673078, 382863.2529673081, 116514.7508992102], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2775000.0000, 
sim time next is 2775600.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3411367132002599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 375654.7686219086, 375654.7686219083, 115876.3101548518], 
processed observation next is [1.0, 0.13043478260869565, 0.45454545454545453, 0.88, 1.0, 1.0, 0.17642089150032486, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1391313957858921, 0.13913139578589198, 0.28262514671915073], 
reward next is 0.7174, 
noisyNet noise sample is [array([-0.7633794], dtype=float32), 1.1041596]. 
=============================================
[2019-03-23 13:19:02,900] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.7729916e-07 9.9999988e-01 1.1884495e-22 9.0184530e-21 1.1311885e-21], sum to 1.0000
[2019-03-23 13:19:02,910] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1568
[2019-03-23 13:19:02,923] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3221236245918009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 354497.1919219199, 354497.1919219196, 114388.2559582883], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2782200.0000, 
sim time next is 2782800.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3225865322684367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 355007.8270449263, 355007.8270449263, 114422.309716822], 
processed observation next is [1.0, 0.21739130434782608, 0.45454545454545453, 0.88, 1.0, 1.0, 0.15323316533554585, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13148438038700974, 0.13148438038700974, 0.27907880418737074], 
reward next is 0.7209, 
noisyNet noise sample is [array([-0.13400003], dtype=float32), -0.13375418]. 
=============================================
[2019-03-23 13:19:04,574] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8573259e-07 9.9999976e-01 2.7272012e-24 4.9309327e-21 9.6866768e-23], sum to 1.0000
[2019-03-23 13:19:04,580] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5614
[2019-03-23 13:19:04,585] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.66666666666667, 52.00000000000001, 1.0, 2.0, 0.45510420047955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 519113.1222756415, 519113.1222756415, 135027.6642977217], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2830800.0000, 
sim time next is 2831400.0000, 
raw observation next is [27.5, 52.5, 1.0, 2.0, 0.4550058251141221, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518952.3331494952, 518952.3331494952, 134904.7579506122], 
processed observation next is [1.0, 0.782608695652174, 0.8863636363636364, 0.525, 1.0, 1.0, 0.3187572813926526, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19220456783314638, 0.19220456783314638, 0.32903599500149316], 
reward next is 0.6710, 
noisyNet noise sample is [array([0.32035634], dtype=float32), -0.8227872]. 
=============================================
[2019-03-23 13:19:05,368] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 13:19:05,371] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:19:05,373] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:19:05,373] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:19:05,373] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:19:05,374] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:19:05,374] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:19:05,377] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run21
[2019-03-23 13:19:05,399] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:19:05,401] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:19:05,403] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run21
[2019-03-23 13:19:05,404] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run21
[2019-03-23 13:19:05,426] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:19:05,428] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:19:05,454] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run21
[2019-03-23 13:19:05,454] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run21
[2019-03-23 13:19:09,111] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05682621], dtype=float32), 0.18446757]
[2019-03-23 13:19:09,112] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.16666666666667, 34.16666666666667, 1.0, 2.0, 0.291180016634649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 316155.7726539972, 316155.7726539972, 85193.50429019074]
[2019-03-23 13:19:09,114] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:19:09,117] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.2301478e-10 1.0000000e+00 5.5620417e-30 1.2928701e-26 2.1119942e-27], sampled 0.22415029551249355
[2019-03-23 13:19:20,168] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05682621], dtype=float32), 0.18446757]
[2019-03-23 13:19:20,168] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 94.0, 1.0, 2.0, 0.3951872031516076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 445249.3766291615, 445249.3766291615, 124375.7798014731]
[2019-03-23 13:19:20,171] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:19:20,176] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.1640060e-10 1.0000000e+00 5.2166502e-30 1.2211034e-26 1.9916483e-27], sampled 0.4076456221706559
[2019-03-23 13:19:26,622] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05682621], dtype=float32), 0.18446757]
[2019-03-23 13:19:26,622] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [8.70076747, 76.91071674666668, 1.0, 2.0, 0.3590611212772823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 389883.2382187669, 389883.2382187665, 84423.215355276]
[2019-03-23 13:19:26,623] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:19:26,625] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.6565341e-09 1.0000000e+00 8.0409718e-28 1.0557384e-24 1.9870818e-25], sampled 0.16235618161319187
[2019-03-23 13:19:28,588] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05682621], dtype=float32), 0.18446757]
[2019-03-23 13:19:28,591] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.51666666666667, 78.16666666666666, 1.0, 2.0, 0.4878463278619609, 0.0, 2.0, 0.0, 1.0, 2.0, 0.868799298418076, 7.041710770196064, 6.9112, 95.55290113819359, 1102806.770198552, 1050429.902766093, 238694.2372214063]
[2019-03-23 13:19:28,591] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:19:28,593] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0662148e-09 1.0000000e+00 2.0946544e-28 3.2093480e-25 5.8120628e-26], sampled 0.2503413248555013
[2019-03-23 13:19:28,594] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1102806.770198552 W.
[2019-03-23 13:19:36,034] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05682621], dtype=float32), 0.18446757]
[2019-03-23 13:19:36,035] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [12.89760033, 100.0, 1.0, 2.0, 0.2101010570529938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 228105.6187273236, 228105.6187273236, 78929.77203689172]
[2019-03-23 13:19:36,036] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:19:36,039] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.3593355e-10 1.0000000e+00 2.1368131e-30 5.5407252e-27 8.8108878e-28], sampled 0.615741402233447
[2019-03-23 13:19:46,809] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05682621], dtype=float32), 0.18446757]
[2019-03-23 13:19:46,811] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.45766643333334, 92.7506216, 1.0, 2.0, 0.5805740471790929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 656901.0335885512, 656901.0335885509, 159381.3727066279]
[2019-03-23 13:19:46,812] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:19:46,817] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0619663e-10 1.0000000e+00 1.8815121e-31 6.4506115e-28 9.5704376e-29], sampled 0.025539446515680075
[2019-03-23 13:19:47,456] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05682621], dtype=float32), 0.18446757]
[2019-03-23 13:19:47,459] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [28.569205565, 63.65876580166666, 1.0, 2.0, 0.6872612982730533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 776205.2075746903, 776205.2075746903, 175037.0285822542]
[2019-03-23 13:19:47,461] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:19:47,464] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.9335404e-10 1.0000000e+00 1.0105577e-29 2.1927957e-26 3.6439403e-27], sampled 0.9881965808509964
[2019-03-23 13:20:20,496] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05682621], dtype=float32), 0.18446757]
[2019-03-23 13:20:20,498] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.96040443, 91.03482271, 1.0, 2.0, 0.3045114673604473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 330634.7006334027, 330634.7006334023, 115802.697049796]
[2019-03-23 13:20:20,499] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:20:20,505] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.4144425e-10 1.0000000e+00 2.2920285e-30 5.8957769e-27 9.3937146e-28], sampled 0.3367259005793317
[2019-03-23 13:20:25,323] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05682621], dtype=float32), 0.18446757]
[2019-03-23 13:20:25,325] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.3, 70.5, 1.0, 2.0, 0.2767708018005395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 300506.7064799442, 300506.7064799439, 98307.11562747606]
[2019-03-23 13:20:25,326] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:20:25,329] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.2371509e-10 1.0000000e+00 1.8180058e-30 4.8036294e-27 7.6033456e-28], sampled 0.5725833656167714
[2019-03-23 13:20:46,990] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 13:20:47,123] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 13:20:47,449] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 13:20:47,453] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 13:20:47,567] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 13:20:48,679] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 500000, evaluation results [500000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 13:20:53,578] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0002815e-09 1.0000000e+00 3.0831251e-27 3.7046088e-23 1.3419501e-24], sum to 1.0000
[2019-03-23 13:20:53,588] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2656
[2019-03-23 13:20:53,598] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 97.0, 1.0, 2.0, 0.5191422869055087, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592221.3001972331, 592221.3001972331, 144053.7172838881], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2950200.0000, 
sim time next is 2950800.0000, 
raw observation next is [21.66666666666667, 96.0, 1.0, 2.0, 0.5172721815630622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 590041.0131407635, 590041.0131407633, 143927.4692247694], 
processed observation next is [1.0, 0.13043478260869565, 0.6212121212121214, 0.96, 1.0, 1.0, 0.39659022695382773, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21853370857065316, 0.21853370857065307, 0.3510426078652912], 
reward next is 0.6490, 
noisyNet noise sample is [array([-0.2535558], dtype=float32), -0.7239283]. 
=============================================
[2019-03-23 13:20:55,080] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.5492711e-07 9.9999940e-01 3.9695785e-18 1.0644248e-15 2.6021543e-16], sum to 1.0000
[2019-03-23 13:20:55,089] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5458
[2019-03-23 13:20:55,094] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1249614.749026671 W.
[2019-03-23 13:20:55,098] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 73.33333333333334, 1.0, 2.0, 0.3704693144043259, 1.0, 1.0, 0.3704693144043259, 1.0, 2.0, 0.7486008460538599, 6.9112, 6.9112, 77.3421103, 1249614.749026671, 1249614.749026671, 293162.2845007227], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2970600.0000, 
sim time next is 2971200.0000, 
raw observation next is [26.0, 72.66666666666667, 1.0, 2.0, 0.6526357453609816, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9808083434064371, 6.911199999999999, 6.9112, 77.32846344354026, 1286649.372522962, 1286649.372522963, 288290.8513351337], 
processed observation next is [1.0, 0.391304347826087, 0.8181818181818182, 0.7266666666666667, 1.0, 1.0, 0.5657946817012269, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9725833477234817, -8.881784197001253e-17, 0.0, 0.508428812920649, 0.4765368046381341, 0.4765368046381344, 0.70314841789057], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.00678608], dtype=float32), 1.4174305]. 
=============================================
[2019-03-23 13:20:57,805] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.2397605e-10 1.0000000e+00 6.8744204e-29 8.0345409e-26 2.8482285e-27], sum to 1.0000
[2019-03-23 13:20:57,812] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8447
[2019-03-23 13:20:57,820] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3406163159904721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 374935.0348252213, 374935.034825221, 115782.5623120094], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3030000.0000, 
sim time next is 3030600.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3407265665833594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 375056.0089849171, 375056.0089849173, 115790.6685565464], 
processed observation next is [1.0, 0.043478260869565216, 0.45454545454545453, 0.88, 1.0, 1.0, 0.17590820822919925, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13890963295737668, 0.1389096329573768, 0.2824162647720644], 
reward next is 0.7176, 
noisyNet noise sample is [array([-0.60181415], dtype=float32), 0.5609007]. 
=============================================
[2019-03-23 13:21:09,356] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.20625576e-11 1.00000000e+00 1.03296552e-35 3.64562928e-31
 3.35098621e-31], sum to 1.0000
[2019-03-23 13:21:09,365] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0811
[2019-03-23 13:21:09,372] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 50.0, 1.0, 2.0, 0.3394591249521024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 375388.7571360982, 375388.7571360982, 116358.7081522852], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3253200.0000, 
sim time next is 3253800.0000, 
raw observation next is [24.0, 50.0, 1.0, 2.0, 0.34002334395809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 376015.5727304536, 376015.5727304539, 116402.7025436944], 
processed observation next is [0.0, 0.6521739130434783, 0.7272727272727273, 0.5, 1.0, 1.0, 0.17502917994761244, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13926502693720505, 0.13926502693720516, 0.28390903059437655], 
reward next is 0.7161, 
noisyNet noise sample is [array([0.77204126], dtype=float32), -1.4597164]. 
=============================================
[2019-03-23 13:21:10,637] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.606559e-10 1.000000e+00 1.612422e-30 9.341404e-27 4.083293e-27], sum to 1.0000
[2019-03-23 13:21:10,644] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1444
[2019-03-23 13:21:10,653] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 53.5, 1.0, 2.0, 0.3189548582893963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 348114.5617824472, 348114.5617824474, 113095.806697717], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3267000.0000, 
sim time next is 3267600.0000, 
raw observation next is [22.33333333333334, 54.66666666666667, 1.0, 2.0, 0.3195507305111168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 349019.0790641572, 349019.0790641569, 113227.7462840132], 
processed observation next is [0.0, 0.8260869565217391, 0.6515151515151518, 0.5466666666666667, 1.0, 1.0, 0.149438413138896, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1292663255793175, 0.1292663255793174, 0.2761652348390566], 
reward next is 0.7238, 
noisyNet noise sample is [array([0.18040259], dtype=float32), -0.9322909]. 
=============================================
[2019-03-23 13:21:14,555] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.4839248e-10 1.0000000e+00 5.9781299e-32 2.0321845e-28 1.6890636e-29], sum to 1.0000
[2019-03-23 13:21:14,561] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3654
[2019-03-23 13:21:14,564] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 50.0, 1.0, 2.0, 0.3580789109308785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 400895.1163394272, 400895.1163394272, 119869.1333852391], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3337200.0000, 
sim time next is 3337800.0000, 
raw observation next is [25.0, 50.0, 1.0, 2.0, 0.3579975380405296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 400803.833033076, 400803.8330330763, 119862.3688874233], 
processed observation next is [0.0, 0.6521739130434783, 0.7727272727272727, 0.5, 1.0, 1.0, 0.19749692255066195, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14844586408632446, 0.14844586408632457, 0.2923472411888373], 
reward next is 0.7077, 
noisyNet noise sample is [array([0.7015309], dtype=float32), -0.4192131]. 
=============================================
[2019-03-23 13:21:19,482] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.2832148e-07 9.9999928e-01 9.1279574e-21 8.6002911e-18 1.2094344e-18], sum to 1.0000
[2019-03-23 13:21:19,489] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8302
[2019-03-23 13:21:19,499] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1339571.544527453 W.
[2019-03-23 13:21:19,503] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.7, 56.66666666666666, 1.0, 2.0, 0.5898759748754099, 1.0, 1.0, 0.5898759748754099, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1339571.544527453, 1339571.544527453, 255391.0695114186], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3422400.0000, 
sim time next is 3423000.0000, 
raw observation next is [27.75, 56.33333333333334, 1.0, 2.0, 0.394915838981455, 1.0, 2.0, 0.394915838981455, 1.0, 1.0, 0.7996762105417611, 6.911199999999999, 6.9112, 77.3421103, 1342428.177003219, 1342428.177003219, 300874.4942535324], 
processed observation next is [1.0, 0.6086956521739131, 0.8977272727272727, 0.5633333333333335, 1.0, 1.0, 0.2436447987268187, 1.0, 1.0, 0.2436447987268187, 1.0, 0.5, 0.7138231579168016, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.49719562111230337, 0.49719562111230337, 0.7338402298866643], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5106905], dtype=float32), 0.2299343]. 
=============================================
[2019-03-23 13:21:19,529] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[44.814156]
 [45.056202]
 [45.162907]
 [45.208435]
 [44.55826 ]], R is [[44.7745285 ]
 [44.7038765 ]
 [44.55228424]
 [44.40377426]
 [44.33010483]].
[2019-03-23 13:21:20,399] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.2544428e-08 1.0000000e+00 8.7439980e-26 1.3778357e-24 2.3881189e-23], sum to 1.0000
[2019-03-23 13:21:20,405] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2622
[2019-03-23 13:21:20,411] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5180790456492395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 590213.3560913217, 590213.3560913217, 144976.4171016198], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3450600.0000, 
sim time next is 3451200.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5169182338544277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588890.9458383044, 588890.9458383044, 144835.2885456496], 
processed observation next is [1.0, 0.9565217391304348, 0.6818181818181818, 0.89, 1.0, 1.0, 0.3961477923180346, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2181077577178905, 0.2181077577178905, 0.35325680133085263], 
reward next is 0.6467, 
noisyNet noise sample is [array([-0.08185588], dtype=float32), 0.035364993]. 
=============================================
[2019-03-23 13:21:22,220] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5358492e-10 1.0000000e+00 2.7927340e-27 1.8310684e-24 8.8592659e-25], sum to 1.0000
[2019-03-23 13:21:22,227] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9450
[2019-03-23 13:21:22,233] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5204713872859726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593850.7366115858, 593850.7366115858, 143903.6812505987], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3478200.0000, 
sim time next is 3478800.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.498786389160498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 569092.887626923, 569092.887626923, 141362.2045243922], 
processed observation next is [1.0, 0.2608695652173913, 0.5909090909090909, 1.0, 1.0, 1.0, 0.37348298645062245, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21077514356552704, 0.21077514356552704, 0.34478586469363953], 
reward next is 0.6552, 
noisyNet noise sample is [array([1.0523013], dtype=float32), 1.2758217]. 
=============================================
[2019-03-23 13:21:23,925] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.231119e-07 9.999995e-01 2.507490e-19 1.815232e-16 5.280692e-17], sum to 1.0000
[2019-03-23 13:21:23,929] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9125
[2019-03-23 13:21:23,934] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 67.33333333333333, 1.0, 2.0, 0.5363597180139479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 609564.0886987346, 609564.0886987346, 148220.7687255396], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3525000.0000, 
sim time next is 3525600.0000, 
raw observation next is [26.66666666666667, 68.66666666666667, 1.0, 2.0, 0.5397563810762163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 613209.8646372193, 613209.8646372193, 148759.2155908476], 
processed observation next is [1.0, 0.8260869565217391, 0.8484848484848487, 0.6866666666666668, 1.0, 1.0, 0.4246954763452703, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2271147646804516, 0.2271147646804516, 0.36282735509962827], 
reward next is 0.6372, 
noisyNet noise sample is [array([0.10925455], dtype=float32), 0.80549437]. 
=============================================
[2019-03-23 13:21:37,620] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 13:21:37,621] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:21:37,622] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:21:37,622] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:21:37,622] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:21:37,625] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:21:37,627] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:21:37,627] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:21:37,628] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:21:37,629] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:21:37,629] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:21:37,646] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run22
[2019-03-23 13:21:37,646] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run22
[2019-03-23 13:21:37,647] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run22
[2019-03-23 13:21:37,723] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run22
[2019-03-23 13:21:37,749] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run22
[2019-03-23 13:22:12,441] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05887008], dtype=float32), 0.18974899]
[2019-03-23 13:22:12,442] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.66666666666667, 64.66666666666666, 1.0, 2.0, 0.7320537486384749, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9764187425254934, 6.911199999999999, 6.9112, 77.32846344354104, 1380932.996476294, 1380932.996476295, 296176.2584930128]
[2019-03-23 13:22:12,443] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:22:12,447] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.5424424e-10 1.0000000e+00 2.9363715e-31 6.1213574e-28 5.0571588e-28], sampled 0.8498696197285487
[2019-03-23 13:22:12,448] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1380932.996476294 W.
[2019-03-23 13:22:20,365] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05887008], dtype=float32), 0.18974899]
[2019-03-23 13:22:20,367] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.41666666666667, 90.0, 1.0, 2.0, 0.4708620357590691, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 534791.7662559472, 534791.7662559472, 138466.8287680368]
[2019-03-23 13:22:20,368] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:22:20,371] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.3695189e-10 1.0000000e+00 4.1953393e-32 1.0793714e-28 8.8443903e-29], sampled 0.45668050533083515
[2019-03-23 13:22:23,906] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05887008], dtype=float32), 0.18974899]
[2019-03-23 13:22:23,907] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.66666666666667, 80.66666666666666, 1.0, 2.0, 0.3201890633480935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 350937.7853066009, 350937.7853066011, 113713.458279182]
[2019-03-23 13:22:23,908] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:22:23,912] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.1541844e-10 1.0000000e+00 5.7719899e-31 1.1177335e-27 9.2584566e-28], sampled 0.00913463787765334
[2019-03-23 13:22:26,764] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05887008], dtype=float32), 0.18974899]
[2019-03-23 13:22:26,766] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [29.76666666666667, 48.33333333333333, 1.0, 2.0, 0.6529791678237299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 744475.2192706694, 744475.219270669, 166370.6194308428]
[2019-03-23 13:22:26,767] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:22:26,771] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.9706951e-11 1.0000000e+00 1.5498925e-32 4.4420166e-29 3.6236155e-29], sampled 0.07520831326100519
[2019-03-23 13:22:37,818] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05887008], dtype=float32), 0.18974899]
[2019-03-23 13:22:37,819] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.85, 88.33333333333334, 1.0, 2.0, 0.488130538216863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 555095.3461328067, 555095.3461328064, 140850.3976900871]
[2019-03-23 13:22:37,820] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:22:37,821] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.3634513e-10 1.0000000e+00 4.1365405e-32 1.0657633e-28 8.7327508e-29], sampled 0.04322834884085924
[2019-03-23 13:22:42,984] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05887008], dtype=float32), 0.18974899]
[2019-03-23 13:22:42,986] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.76666666666667, 38.5, 1.0, 2.0, 0.4713155222927493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 529273.9573709347, 529273.9573709343, 135036.8638557872]
[2019-03-23 13:22:42,987] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:22:42,990] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.4892210e-10 1.0000000e+00 5.4699590e-32 1.3677155e-28 1.1214186e-28], sampled 0.9318701862655612
[2019-03-23 13:23:06,830] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05887008], dtype=float32), 0.18974899]
[2019-03-23 13:23:06,831] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.0068282, 79.50818352833333, 1.0, 2.0, 0.4255105307246191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 480538.2861525238, 480538.2861525238, 132086.5624010851]
[2019-03-23 13:23:06,832] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:23:06,835] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.2721665e-10 1.0000000e+00 3.3302510e-32 8.7846058e-29 7.1913159e-29], sampled 0.1992224387398227
[2019-03-23 13:23:18,321] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1389 1656177241.5752 80.0000
[2019-03-23 13:23:18,863] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 13:23:18,866] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 13:23:18,918] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 13:23:18,932] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9541 1705935200.4109 465.0000
[2019-03-23 13:23:19,948] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 525000, evaluation results [525000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.138916442502, 1656177241.575227, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.954086171138, 1705935200.4108896, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 13:23:20,823] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.6847449e-10 1.0000000e+00 2.1817337e-32 5.0828601e-29 9.9293504e-28], sum to 1.0000
[2019-03-23 13:23:20,832] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6388
[2019-03-23 13:23:20,837] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.00000000000001, 1.0, 2.0, 0.3290531585613603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 360017.8669853152, 360017.8669853152, 114121.413237784], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3805800.0000, 
sim time next is 3806400.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3305697046222101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 361684.9367589866, 361684.9367589863, 114233.375117231], 
processed observation next is [0.0, 0.043478260869565216, 0.4090909090909091, 0.94, 1.0, 1.0, 0.1632121307777626, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13395738398480986, 0.13395738398480975, 0.27861798809080734], 
reward next is 0.7214, 
noisyNet noise sample is [array([0.55719936], dtype=float32), -0.29034925]. 
=============================================
[2019-03-23 13:23:25,737] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9732202e-12 1.0000000e+00 5.3768622e-32 1.3576370e-27 1.3433828e-26], sum to 1.0000
[2019-03-23 13:23:25,744] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4300
[2019-03-23 13:23:25,749] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 77.0, 1.0, 2.0, 0.2807091101047064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 304802.0647644539, 304802.0647644539, 101571.1596409499], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3898200.0000, 
sim time next is 3898800.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.279863085165468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 303883.1394239661, 303883.1394239661, 101486.710993427], 
processed observation next is [0.0, 0.13043478260869565, 0.45454545454545453, 0.77, 1.0, 1.0, 0.09982885645683497, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11254931089776522, 0.11254931089776522, 0.24752856339860244], 
reward next is 0.7525, 
noisyNet noise sample is [array([0.02670265], dtype=float32), -0.44112158]. 
=============================================
[2019-03-23 13:23:26,590] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.7360824e-11 1.0000000e+00 3.7464201e-30 2.3492967e-27 3.5787005e-26], sum to 1.0000
[2019-03-23 13:23:26,600] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2120
[2019-03-23 13:23:26,603] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 80.50000000000001, 1.0, 2.0, 0.2710923548194047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 294356.753801555, 294356.7538015553, 99476.44763157699], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3913800.0000, 
sim time next is 3914400.0000, 
raw observation next is [18.0, 79.0, 1.0, 2.0, 0.2791355266060791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 303092.8898804109, 303092.8898804109, 106293.1793455794], 
processed observation next is [0.0, 0.30434782608695654, 0.45454545454545453, 0.79, 1.0, 1.0, 0.09891940825759886, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11225662588163367, 0.11225662588163367, 0.25925165694043756], 
reward next is 0.7407, 
noisyNet noise sample is [array([-0.92073834], dtype=float32), -0.60054594]. 
=============================================
[2019-03-23 13:23:31,998] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.4929558e-10 1.0000000e+00 6.7691112e-28 1.3973082e-25 2.3562548e-25], sum to 1.0000
[2019-03-23 13:23:32,007] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7883
[2019-03-23 13:23:32,011] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 95.0, 1.0, 2.0, 0.571151620649382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 636174.4675829796, 636174.4675829796, 138912.0562819836], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4017000.0000, 
sim time next is 4017600.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.5791426731428048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 645666.1116514105, 645666.1116514105, 140003.6734729022], 
processed observation next is [1.0, 0.5217391304347826, 0.45454545454545453, 0.94, 1.0, 1.0, 0.47392834142850593, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2391355969079298, 0.2391355969079298, 0.34147237432415173], 
reward next is 0.6585, 
noisyNet noise sample is [array([1.4636834], dtype=float32), 1.5639889]. 
=============================================
[2019-03-23 13:23:32,626] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.6861996e-10 1.0000000e+00 4.7154762e-30 5.5706738e-26 1.0072340e-26], sum to 1.0000
[2019-03-23 13:23:32,632] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7671
[2019-03-23 13:23:32,635] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 83.0, 1.0, 2.0, 0.3022206829791408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 328745.7928724143, 328745.7928724143, 111544.3758659091], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4003200.0000, 
sim time next is 4003800.0000, 
raw observation next is [18.0, 83.83333333333334, 1.0, 2.0, 0.3043917566177532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 331705.0517826698, 331705.0517826698, 111902.354759036], 
processed observation next is [1.0, 0.34782608695652173, 0.45454545454545453, 0.8383333333333334, 1.0, 1.0, 0.13048969577219147, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12285372288247029, 0.12285372288247029, 0.2729325725830146], 
reward next is 0.7271, 
noisyNet noise sample is [array([2.320818], dtype=float32), 1.1654164]. 
=============================================
[2019-03-23 13:23:33,866] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.3029964e-11 1.0000000e+00 4.7012258e-33 6.0193977e-29 2.3978531e-28], sum to 1.0000
[2019-03-23 13:23:33,878] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6675
[2019-03-23 13:23:33,886] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666667, 96.0, 1.0, 2.0, 0.3151734511496563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 344130.465826027, 344130.465826027, 112882.1139729166], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4058400.0000, 
sim time next is 4059000.0000, 
raw observation next is [16.5, 97.0, 1.0, 2.0, 0.3133050832299477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 341677.9826587222, 341677.9826587222, 112605.1747615214], 
processed observation next is [1.0, 1.0, 0.38636363636363635, 0.97, 1.0, 1.0, 0.14163135403743463, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12654740098471193, 0.12654740098471193, 0.2746467677110278], 
reward next is 0.7254, 
noisyNet noise sample is [array([-0.38559267], dtype=float32), -1.1557773]. 
=============================================
[2019-03-23 13:23:33,907] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[77.210945]
 [77.18565 ]
 [77.16868 ]
 [77.139244]
 [77.125435]], R is [[77.19833374]
 [77.15103149]
 [77.1036377 ]
 [77.05628204]
 [77.00925446]].
[2019-03-23 13:23:57,306] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.7683861e-08 1.0000000e+00 2.3553268e-27 4.4379481e-23 1.0947091e-22], sum to 1.0000
[2019-03-23 13:23:57,322] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5222
[2019-03-23 13:23:57,326] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.00000000000001, 1.0, 2.0, 0.4623656036313413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 527362.0379604065, 527362.0379604065, 135717.1871890759], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4493400.0000, 
sim time next is 4494000.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.4618811080632377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 526808.9039500986, 526808.9039500986, 135664.5435188529], 
processed observation next is [0.0, 0.0, 0.5909090909090909, 0.94, 1.0, 1.0, 0.32735138507904704, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19511440887040687, 0.19511440887040687, 0.3308891305337876], 
reward next is 0.6691, 
noisyNet noise sample is [array([-0.6296498], dtype=float32), 0.02606689]. 
=============================================
[2019-03-23 13:23:57,341] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[60.519424]
 [60.628265]
 [60.83799 ]
 [60.83798 ]
 [60.8378  ]], R is [[60.60667801]
 [60.66959381]
 [60.73179626]
 [60.79335785]
 [60.85425949]].
[2019-03-23 13:24:01,331] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.1490388e-10 1.0000000e+00 4.7837448e-30 7.4560883e-27 4.5449697e-26], sum to 1.0000
[2019-03-23 13:24:01,339] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3798
[2019-03-23 13:24:01,343] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 88.0, 1.0, 2.0, 0.265496065026215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 288278.4048818094, 288278.4048818094, 91035.36442173927], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4582800.0000, 
sim time next is 4583400.0000, 
raw observation next is [16.0, 88.00000000000001, 1.0, 2.0, 0.2638065913645117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 286443.4164806057, 286443.416480606, 90832.87211452881], 
processed observation next is [1.0, 0.043478260869565216, 0.36363636363636365, 0.8800000000000001, 1.0, 1.0, 0.07975823920563958, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1060901542520762, 0.1060901542520763, 0.22154359052324102], 
reward next is 0.7785, 
noisyNet noise sample is [array([-1.5784748], dtype=float32), 0.21990864]. 
=============================================
[2019-03-23 13:24:03,026] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4471522e-09 1.0000000e+00 3.6051125e-29 3.9763982e-27 8.3699854e-24], sum to 1.0000
[2019-03-23 13:24:03,033] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9936
[2019-03-23 13:24:03,036] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 88.0, 1.0, 2.0, 0.265496065026215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 288278.4048818094, 288278.4048818094, 91035.36442173927], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4582800.0000, 
sim time next is 4583400.0000, 
raw observation next is [16.0, 88.00000000000001, 1.0, 2.0, 0.2638065913645117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 286443.4164806057, 286443.416480606, 90832.87211452881], 
processed observation next is [1.0, 0.043478260869565216, 0.36363636363636365, 0.8800000000000001, 1.0, 1.0, 0.07975823920563958, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1060901542520762, 0.1060901542520763, 0.22154359052324102], 
reward next is 0.7785, 
noisyNet noise sample is [array([-2.5889242], dtype=float32), 0.16821462]. 
=============================================
[2019-03-23 13:24:05,916] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.21436561e-10 1.00000000e+00 1.15232734e-32 4.03767505e-28
 3.05187915e-29], sum to 1.0000
[2019-03-23 13:24:05,924] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9016
[2019-03-23 13:24:05,930] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 82.0, 1.0, 2.0, 0.2431446729198389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 264002.4425163615, 264002.4425163612, 83321.43355007574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4672200.0000, 
sim time next is 4672800.0000, 
raw observation next is [16.0, 82.0, 1.0, 2.0, 0.2424278788349148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 263223.9488120923, 263223.9488120926, 83240.54836591713], 
processed observation next is [1.0, 0.08695652173913043, 0.36363636363636365, 0.82, 1.0, 1.0, 0.05303484854364347, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09749035141188604, 0.09749035141188615, 0.2030257277217491], 
reward next is 0.7970, 
noisyNet noise sample is [array([-0.4770241], dtype=float32), 1.7849925]. 
=============================================
[2019-03-23 13:24:08,732] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 13:24:08,736] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:24:08,737] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:24:08,737] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:24:08,739] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:24:08,740] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:24:08,741] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:24:08,742] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:24:08,741] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:24:08,743] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:24:08,745] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:24:08,760] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run23
[2019-03-23 13:24:08,761] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run23
[2019-03-23 13:24:08,784] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run23
[2019-03-23 13:24:08,834] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run23
[2019-03-23 13:24:08,835] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run23
[2019-03-23 13:24:17,484] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06420059], dtype=float32), 0.19736348]
[2019-03-23 13:24:17,484] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.16666666666667, 56.5, 1.0, 2.0, 0.3471248248355241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385969.9181482865, 385969.9181482865, 117795.481864375]
[2019-03-23 13:24:17,486] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:24:17,490] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.3826269e-10 1.0000000e+00 4.1562393e-29 2.7831105e-26 9.6175543e-26], sampled 0.3302866456170347
[2019-03-23 13:24:21,597] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06420059], dtype=float32), 0.19736348]
[2019-03-23 13:24:21,597] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [31.7, 46.0, 1.0, 2.0, 0.6817735784164475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 772754.9473772643, 772754.9473772639, 173322.5917089926]
[2019-03-23 13:24:21,598] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:24:21,604] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.3260198e-10 1.0000000e+00 3.7696441e-30 3.2015677e-27 1.1541962e-26], sampled 0.22161422063133462
[2019-03-23 13:24:31,160] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06420059], dtype=float32), 0.19736348]
[2019-03-23 13:24:31,161] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.98525866666667, 84.25698629666668, 1.0, 2.0, 0.4078842150155346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 462522.3905790587, 462522.3905790583, 131634.8132867388]
[2019-03-23 13:24:31,162] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:24:31,164] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.8494888e-10 1.0000000e+00 1.5652421e-29 1.1544956e-26 4.0595170e-26], sampled 0.9125456016370067
[2019-03-23 13:24:32,286] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06420059], dtype=float32), 0.19736348]
[2019-03-23 13:24:32,287] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.95, 44.66666666666667, 1.0, 2.0, 0.3601377351969661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 402453.5225713386, 402453.5225713386, 124016.9286445047]
[2019-03-23 13:24:32,288] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:24:32,291] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.5076123e-10 1.0000000e+00 2.0819154e-29 1.4926838e-26 5.2218370e-26], sampled 0.24881313701841357
[2019-03-23 13:24:36,839] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06420059], dtype=float32), 0.19736348]
[2019-03-23 13:24:36,840] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.3, 50.0, 1.0, 2.0, 0.4625165646106211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 526425.1433368154, 526425.1433368154, 138582.3407064164]
[2019-03-23 13:24:36,843] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:24:36,845] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.36492303e-10 1.00000000e+00 1.24767226e-29 9.41158207e-27
 3.32226736e-26], sampled 0.646694317938564
[2019-03-23 13:24:59,139] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06420059], dtype=float32), 0.19736348]
[2019-03-23 13:24:59,140] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.5, 97.0, 1.0, 2.0, 0.3369012181414174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 373801.9445771019, 373801.9445771019, 116665.5398699828]
[2019-03-23 13:24:59,142] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:24:59,145] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.3025494e-09 1.0000000e+00 1.1474606e-28 6.9484902e-26 2.3586921e-25], sampled 0.7464748406158029
[2019-03-23 13:25:24,748] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06420059], dtype=float32), 0.19736348]
[2019-03-23 13:25:24,750] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.9, 58.16666666666666, 1.0, 2.0, 0.5324297777200446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 578290.1935460706, 578290.1935460706, 119568.9694382348]
[2019-03-23 13:25:24,751] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:25:24,756] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.2461522e-09 1.0000000e+00 1.9465586e-27 8.9092886e-25 2.8758329e-24], sampled 0.7835215785457097
[2019-03-23 13:25:49,161] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 13:25:49,353] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 13:25:49,353] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 13:25:49,397] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 13:25:49,400] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 13:25:50,415] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 550000, evaluation results [550000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 13:25:50,643] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.128859e-09 1.000000e+00 9.602294e-28 3.033267e-26 3.396981e-26], sum to 1.0000
[2019-03-23 13:25:50,654] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0573
[2019-03-23 13:25:50,668] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1161315.077006554 W.
[2019-03-23 13:25:50,676] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 54.0, 1.0, 2.0, 0.5085706363846448, 1.0, 2.0, 0.5085706363846448, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1161315.077006554, 1161315.077006554, 226922.6138354983], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4721400.0000, 
sim time next is 4722000.0000, 
raw observation next is [26.0, 54.0, 1.0, 2.0, 0.3440460527946436, 1.0, 2.0, 0.3440460527946436, 1.0, 1.0, 0.6939645490240239, 6.9112, 6.9112, 77.3421103, 1178493.155870711, 1178493.155870711, 269227.3770316592], 
processed observation next is [1.0, 0.6521739130434783, 0.8181818181818182, 0.54, 1.0, 1.0, 0.1800575659933045, 1.0, 1.0, 0.1800575659933045, 1.0, 0.5, 0.5628064986057485, 0.0, 0.0, 0.5085185399722538, 0.43647894661878184, 0.43647894661878184, 0.6566521391016078], 
reward next is 0.3433, 
noisyNet noise sample is [array([-2.1580346], dtype=float32), 0.8995092]. 
=============================================
[2019-03-23 13:25:50,690] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[65.337006]
 [64.92954 ]
 [64.57231 ]
 [65.1287  ]
 [65.35524 ]], R is [[65.25926971]
 [65.0532074 ]
 [64.40267944]
 [64.09879303]
 [63.91447449]].
[2019-03-23 13:25:57,880] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4279734e-08 1.0000000e+00 6.8522030e-26 1.9037213e-22 9.4689682e-23], sum to 1.0000
[2019-03-23 13:25:57,893] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9666
[2019-03-23 13:25:57,904] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.3993561748064651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 452684.4236308591, 452684.4236308591, 126383.0025884632], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4858200.0000, 
sim time next is 4858800.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.3993669004198574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 452696.0835103771, 452696.0835103768, 126383.6564219044], 
processed observation next is [1.0, 0.21739130434782608, 0.5, 1.0, 1.0, 1.0, 0.24920862552482173, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16766521611495447, 0.16766521611495439, 0.3082528205412302], 
reward next is 0.6917, 
noisyNet noise sample is [array([1.4450098], dtype=float32), -0.75681037]. 
=============================================
[2019-03-23 13:26:01,079] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2462816e-07 9.9999988e-01 1.0260151e-26 3.4392040e-24 4.8202326e-23], sum to 1.0000
[2019-03-23 13:26:01,088] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6156
[2019-03-23 13:26:01,093] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3779177637786099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 424353.388339521, 424353.3883395207, 122114.2450156143], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4928400.0000, 
sim time next is 4929000.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3761778726220805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 422318.968476457, 422318.968476457, 121925.8712279834], 
processed observation next is [1.0, 0.043478260869565216, 0.45454545454545453, 1.0, 1.0, 1.0, 0.22022234077760064, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15641443276905814, 0.15641443276905814, 0.29738017372678877], 
reward next is 0.7026, 
noisyNet noise sample is [array([1.001652], dtype=float32), 1.6855627]. 
=============================================
[2019-03-23 13:26:01,111] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[59.895123]
 [59.929985]
 [59.970825]
 [60.013588]
 [60.02371 ]], R is [[59.98934937]
 [60.09161758]
 [60.19212341]
 [60.29101181]
 [60.38844681]].
[2019-03-23 13:26:03,252] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.8576520e-09 1.0000000e+00 1.3361300e-27 6.1688154e-24 7.5955338e-24], sum to 1.0000
[2019-03-23 13:26:03,254] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2684
[2019-03-23 13:26:03,260] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.6837598007283885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 744220.8854957323, 744220.8854957327, 145755.506575311], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4966200.0000, 
sim time next is 4966800.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.6760563055664499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 735897.7647482587, 735897.7647482587, 144919.9026182762], 
processed observation next is [1.0, 0.4782608695652174, 0.5, 0.73, 1.0, 1.0, 0.5950703819580624, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.27255472768454025, 0.27255472768454025, 0.3534631771177468], 
reward next is 0.6465, 
noisyNet noise sample is [array([0.46222514], dtype=float32), 0.56208754]. 
=============================================
[2019-03-23 13:26:08,032] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.1150979e-11 1.0000000e+00 1.8012234e-31 5.6088557e-29 1.2663399e-28], sum to 1.0000
[2019-03-23 13:26:08,039] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5886
[2019-03-23 13:26:08,042] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.66666666666667, 100.0, 1.0, 2.0, 0.21777275554853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 236447.3403581084, 236447.3403581084, 77984.98297248376], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5034000.0000, 
sim time next is 5034600.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.2271752520193834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 246658.714126013, 246658.7141260127, 80745.67665725912], 
processed observation next is [0.0, 0.2608695652173913, 0.2727272727272727, 1.0, 1.0, 1.0, 0.03396906502422924, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09135507930593073, 0.09135507930593063, 0.19694067477380273], 
reward next is 0.8031, 
noisyNet noise sample is [array([-0.6888867], dtype=float32), 0.34145537]. 
=============================================
[2019-03-23 13:26:19,054] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5992139e-09 1.0000000e+00 2.1908337e-31 1.1333052e-28 1.2813704e-27], sum to 1.0000
[2019-03-23 13:26:19,064] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0564
[2019-03-23 13:26:19,067] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666667, 100.0, 1.0, 2.0, 0.4967250711010698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 566592.0029374245, 566592.0029374241, 141504.3854911296], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5266200.0000, 
sim time next is 5266800.0000, 
raw observation next is [21.1, 100.0, 1.0, 2.0, 0.4929618289906171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 562360.8509805475, 562360.8509805475, 140927.4486323896], 
processed observation next is [1.0, 1.0, 0.5954545454545456, 1.0, 1.0, 1.0, 0.36620228623827134, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20828179665946203, 0.20828179665946203, 0.34372548446924295], 
reward next is 0.6563, 
noisyNet noise sample is [array([-0.75835794], dtype=float32), 0.5525886]. 
=============================================
[2019-03-23 13:26:19,627] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.6381877e-09 1.0000000e+00 3.5999608e-28 1.8399669e-25 1.3239255e-23], sum to 1.0000
[2019-03-23 13:26:19,634] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2999
[2019-03-23 13:26:19,641] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 91.5, 1.0, 2.0, 0.5109288849915887, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.3284634428716, 582363.6573017205, 582363.6573017208, 143810.379523976], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5247000.0000, 
sim time next is 5247600.0000, 
raw observation next is [22.33333333333334, 92.33333333333334, 1.0, 2.0, 0.5088487637684046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.3284634435369, 580107.7503240342, 580107.7503240342, 143423.7831576418], 
processed observation next is [1.0, 0.7391304347826086, 0.6515151515151518, 0.9233333333333335, 1.0, 1.0, 0.3860609547105057, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206269, 0.2148547223422349, 0.2148547223422349, 0.349814105262541], 
reward next is 0.6502, 
noisyNet noise sample is [array([0.623408], dtype=float32), 1.111589]. 
=============================================
[2019-03-23 13:26:20,963] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.2537923e-07 9.9999952e-01 1.8232270e-23 2.2893029e-21 1.2670843e-19], sum to 1.0000
[2019-03-23 13:26:20,969] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1674
[2019-03-23 13:26:20,974] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1085050.378669961 W.
[2019-03-23 13:26:20,982] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.85, 54.0, 1.0, 2.0, 0.3200550611495011, 1.0, 2.0, 0.3200550611495011, 1.0, 2.0, 0.6476637100911624, 6.911199999999999, 6.9112, 77.3421103, 1085050.378669961, 1085050.378669961, 270112.3867646636], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5315400.0000, 
sim time next is 5316000.0000, 
raw observation next is [29.03333333333333, 53.66666666666666, 1.0, 2.0, 0.3571138823614454, 1.0, 2.0, 0.3571138823614454, 1.0, 2.0, 0.7224457416425266, 6.911199999999999, 6.9112, 77.3421103, 1209739.697895191, 1209739.697895191, 285607.4046845578], 
processed observation next is [1.0, 0.5217391304347826, 0.9560606060606059, 0.5366666666666666, 1.0, 1.0, 0.19639235295180676, 1.0, 1.0, 0.19639235295180676, 1.0, 1.0, 0.6034939166321809, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4480517399611818, 0.4480517399611818, 0.6966034260598971], 
reward next is 0.3034, 
noisyNet noise sample is [array([0.7375079], dtype=float32), -0.204594]. 
=============================================
[2019-03-23 13:26:21,000] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[54.541813]
 [53.289852]
 [51.983795]
 [52.602776]
 [53.396828]], R is [[54.06728745]
 [53.86780548]
 [53.6322403 ]
 [53.09591675]
 [52.56495667]].
[2019-03-23 13:26:21,500] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.1677816e-09 1.0000000e+00 3.7179859e-24 5.5527578e-22 1.5254474e-21], sum to 1.0000
[2019-03-23 13:26:21,514] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0568
[2019-03-23 13:26:21,522] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.26666666666667, 69.33333333333334, 1.0, 2.0, 0.5902096761172833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 670486.555305751, 670486.555305751, 147585.7576586397], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5300400.0000, 
sim time next is 5301000.0000, 
raw observation next is [23.55, 67.5, 1.0, 2.0, 0.7220951068539286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 820715.8729440436, 820715.8729440436, 164944.4124537868], 
processed observation next is [1.0, 0.34782608695652173, 0.7068181818181819, 0.675, 1.0, 1.0, 0.6526188835674107, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.30396884183112727, 0.30396884183112727, 0.4023034450092361], 
reward next is 0.5977, 
noisyNet noise sample is [array([-0.07836204], dtype=float32), -0.4168981]. 
=============================================
[2019-03-23 13:26:21,536] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[54.430817]
 [55.24697 ]
 [55.428772]
 [55.53391 ]
 [55.640717]], R is [[53.6162529 ]
 [53.72012329]
 [53.86884308]
 [54.0216713 ]
 [54.17497635]].
[2019-03-23 13:26:39,415] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 13:26:39,417] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:26:39,417] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:26:39,417] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:26:39,418] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:26:39,419] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:26:39,419] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:26:39,420] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:26:39,422] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:26:39,421] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:26:39,422] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:26:39,434] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run24
[2019-03-23 13:26:39,460] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run24
[2019-03-23 13:26:39,461] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run24
[2019-03-23 13:26:39,512] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run24
[2019-03-23 13:26:39,540] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run24
[2019-03-23 13:26:45,882] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06736611], dtype=float32), 0.20445807]
[2019-03-23 13:26:45,883] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.112079855, 97.46251635166668, 1.0, 2.0, 0.3732465112619776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 411058.6316477465, 411058.6316477465, 122681.8113194918]
[2019-03-23 13:26:45,883] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:26:45,885] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.2924493e-10 1.0000000e+00 2.8871002e-31 6.4022401e-29 2.8107428e-27], sampled 0.05650845925964432
[2019-03-23 13:26:50,597] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06736611], dtype=float32), 0.20445807]
[2019-03-23 13:26:50,598] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 88.00000000000001, 1.0, 2.0, 0.4349969447761111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 494906.5886180954, 494906.5886180954, 131210.5349362972]
[2019-03-23 13:26:50,599] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:26:50,600] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.6928150e-10 1.0000000e+00 1.1054765e-31 2.6379592e-29 1.2181809e-27], sampled 0.37347889553315305
[2019-03-23 13:26:54,944] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06736611], dtype=float32), 0.20445807]
[2019-03-23 13:26:54,948] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.00692763333333, 95.40461121666667, 1.0, 2.0, 0.5344582529490954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 606164.4968826773, 606164.4968826773, 152826.9403042036]
[2019-03-23 13:26:54,950] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:26:54,953] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.244148e-10 1.000000e+00 2.812979e-31 6.251404e-29 2.748000e-27], sampled 0.18694571725810838
[2019-03-23 13:26:56,406] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06736611], dtype=float32), 0.20445807]
[2019-03-23 13:26:56,408] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.5, 100.0, 1.0, 2.0, 0.4593642760794168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 524066.4858245995, 524066.4858245997, 135743.0921905254]
[2019-03-23 13:26:56,409] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:26:56,414] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.0110384e-10 1.0000000e+00 6.6112823e-32 1.6408728e-29 7.7844851e-28], sampled 0.662615215794443
[2019-03-23 13:27:29,001] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06736611], dtype=float32), 0.20445807]
[2019-03-23 13:27:29,003] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.0, 100.0, 1.0, 2.0, 0.3678551276823535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 412937.3867381514, 412937.3867381514, 121200.6997883991]
[2019-03-23 13:27:29,005] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:27:29,009] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.4978254e-10 1.0000000e+00 9.6045459e-32 2.3165806e-29 1.0774097e-27], sampled 0.8769723711509587
[2019-03-23 13:28:10,094] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06736611], dtype=float32), 0.20445807]
[2019-03-23 13:28:10,095] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.21666666666667, 87.83333333333334, 1.0, 2.0, 0.3355378818667205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 370494.2851860871, 370494.2851860868, 120159.9438030387]
[2019-03-23 13:28:10,098] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:28:10,101] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.8453235e-10 1.0000000e+00 5.7475326e-32 1.4414957e-29 6.8874697e-28], sampled 0.21862826402489388
[2019-03-23 13:28:19,717] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3791 1683296663.2329 214.0000
[2019-03-23 13:28:19,789] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 13:28:19,933] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 13:28:19,973] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 13:28:19,994] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 13:28:21,008] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 575000, evaluation results [575000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.379088229873, 1683296663.232874, 214.0]
[2019-03-23 13:28:21,468] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.13109288e-11 1.00000000e+00 1.09837145e-33 1.16370285e-31
 8.89894468e-29], sum to 1.0000
[2019-03-23 13:28:21,482] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6110
[2019-03-23 13:28:21,488] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.6, 74.0, 1.0, 2.0, 0.2116034279376582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 229747.3947471854, 229747.3947471857, 74391.79374336688], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5677800.0000, 
sim time next is 5678400.0000, 
raw observation next is [15.7, 73.0, 1.0, 2.0, 0.21366325472341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 231984.3750128008, 231984.3750128005, 74537.32473470323], 
processed observation next is [0.0, 0.7391304347826086, 0.35, 0.73, 1.0, 1.0, 0.01707906840426248, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08592013889362993, 0.08592013889362982, 0.1817983530114713], 
reward next is 0.8182, 
noisyNet noise sample is [array([-1.1384087], dtype=float32), -1.7888683]. 
=============================================
[2019-03-23 13:28:29,379] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.4854601e-06 9.9999750e-01 1.7393342e-30 4.5847891e-31 1.1088553e-26], sum to 1.0000
[2019-03-23 13:28:29,386] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4310
[2019-03-23 13:28:29,391] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.86666666666667, 57.0, 1.0, 2.0, 0.3300336923274308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 358379.8567649741, 358379.8567649741, 106043.7367013972], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5823600.0000, 
sim time next is 5824200.0000, 
raw observation next is [21.23333333333333, 56.0, 1.0, 2.0, 0.3363240287000622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 365213.0270325388, 365213.0270325388, 109723.8232896708], 
processed observation next is [1.0, 0.391304347826087, 0.6015151515151514, 0.56, 1.0, 1.0, 0.17040503587507777, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13526408408612547, 0.13526408408612547, 0.26761908119431904], 
reward next is 0.7324, 
noisyNet noise sample is [array([0.4568798], dtype=float32), 1.1952295]. 
=============================================
[2019-03-23 13:28:30,551] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.5841554e-08 9.9999988e-01 3.3989703e-30 1.5087918e-28 1.9339241e-27], sum to 1.0000
[2019-03-23 13:28:30,557] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6533
[2019-03-23 13:28:30,560] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 42.0, 1.0, 2.0, 0.3262498076682779, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 359812.1231146614, 359812.1231146611, 114985.0007174087], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5853600.0000, 
sim time next is 5854200.0000, 
raw observation next is [25.31666666666667, 43.0, 1.0, 2.0, 0.3265908543892755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 360302.1857683576, 360302.1857683576, 115054.4243688081], 
processed observation next is [1.0, 0.782608695652174, 0.7871212121212122, 0.43, 1.0, 1.0, 0.15823856798659433, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13344525398828058, 0.13344525398828058, 0.2806205472409954], 
reward next is 0.7194, 
noisyNet noise sample is [array([-1.0277219], dtype=float32), -0.33955994]. 
=============================================
[2019-03-23 13:28:39,229] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.8363460e-06 9.9999619e-01 1.3611328e-26 3.0149639e-23 2.5354777e-22], sum to 1.0000
[2019-03-23 13:28:39,235] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5185
[2019-03-23 13:28:39,238] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.9, 78.0, 1.0, 2.0, 0.3558969239955178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 395933.065299292, 395933.0652992923, 118576.0735623124], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6034200.0000, 
sim time next is 6034800.0000, 
raw observation next is [19.8, 78.0, 1.0, 2.0, 0.3533230942223473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 392515.0559255779, 392515.0559255782, 118140.4132883257], 
processed observation next is [1.0, 0.8695652173913043, 0.5363636363636364, 0.78, 1.0, 1.0, 0.1916538677779341, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14537594663910292, 0.14537594663910305, 0.2881473494837212], 
reward next is 0.7119, 
noisyNet noise sample is [array([1.0854677], dtype=float32), -0.18648306]. 
=============================================
[2019-03-23 13:28:40,901] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.7227390e-06 9.9999523e-01 1.9271564e-25 5.4159715e-24 2.5121024e-20], sum to 1.0000
[2019-03-23 13:28:40,910] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7322
[2019-03-23 13:28:40,920] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1217343.457517328 W.
[2019-03-23 13:28:40,927] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.5, 69.5, 1.0, 2.0, 0.5362049610801304, 1.0, 2.0, 0.5362049610801304, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344295419, 1217343.457517328, 1217343.457517328, 241342.6663731236], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6016200.0000, 
sim time next is 6016800.0000, 
raw observation next is [25.5, 70.0, 1.0, 2.0, 0.5384027226013501, 1.0, 2.0, 0.5384027226013501, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.3284634435374, 1221421.401625545, 1221421.401625545, 242278.818321339], 
processed observation next is [1.0, 0.6521739130434783, 0.7954545454545454, 0.7, 1.0, 1.0, 0.4230034032516876, 1.0, 1.0, 0.4230034032516876, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206301, 0.45237829689835, 0.45237829689835, 0.5909239471252171], 
reward next is 0.4091, 
noisyNet noise sample is [array([1.0631813], dtype=float32), 1.4260936]. 
=============================================
[2019-03-23 13:28:40,942] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.2865213e-06 9.9999774e-01 5.2705587e-25 5.5201488e-25 2.4471266e-22], sum to 1.0000
[2019-03-23 13:28:40,950] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6271
[2019-03-23 13:28:40,959] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 58.33333333333334, 1.0, 2.0, 0.6928770309539622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 790183.8931772307, 790183.8931772307, 163777.6416327716], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6009000.0000, 
sim time next is 6009600.0000, 
raw observation next is [26.1, 58.66666666666667, 1.0, 2.0, 0.9606487944441676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1096214.073676191, 1096214.073676191, 207013.5212393143], 
processed observation next is [1.0, 0.5652173913043478, 0.8227272727272728, 0.5866666666666667, 1.0, 1.0, 0.9508109930552094, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.40600521247266336, 0.40600521247266336, 0.5049110274129617], 
reward next is 0.4951, 
noisyNet noise sample is [array([0.01356707], dtype=float32), 2.6012793]. 
=============================================
[2019-03-23 13:28:44,128] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.6440911e-06 9.9999833e-01 4.5850468e-27 2.8949879e-26 8.6441004e-24], sum to 1.0000
[2019-03-23 13:28:44,135] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2428
[2019-03-23 13:28:44,140] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.51666666666667, 66.16666666666667, 1.0, 2.0, 0.4134384202438894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 448989.924664632, 448989.9246646322, 98968.35722642888], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6079800.0000, 
sim time next is 6080400.0000, 
raw observation next is [17.7, 65.0, 1.0, 2.0, 0.4134299484815328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 448980.7201685986, 448980.7201685986, 99175.50800974775], 
processed observation next is [1.0, 0.391304347826087, 0.44090909090909086, 0.65, 1.0, 1.0, 0.266787435601916, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16628915561799948, 0.16628915561799948, 0.24189148295060425], 
reward next is 0.7581, 
noisyNet noise sample is [array([0.6699997], dtype=float32), -0.43966585]. 
=============================================
[2019-03-23 13:28:44,637] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3790859e-07 9.9999988e-01 6.7232958e-30 8.8214140e-28 9.1649978e-25], sum to 1.0000
[2019-03-23 13:28:44,647] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8303
[2019-03-23 13:28:44,651] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.6, 72.0, 1.0, 2.0, 0.2315449773833165, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 251404.4308814825, 251404.4308814825, 78960.16244624881], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6076800.0000, 
sim time next is 6077400.0000, 
raw observation next is [16.78333333333333, 70.83333333333333, 1.0, 2.0, 0.2493784773031968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 270772.8877954859, 270772.8877954859, 80916.13507585571], 
processed observation next is [1.0, 0.34782608695652173, 0.3992424242424242, 0.7083333333333333, 1.0, 1.0, 0.06172309662899597, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10028625473906885, 0.10028625473906885, 0.19735642701428222], 
reward next is 0.8026, 
noisyNet noise sample is [array([-0.91784304], dtype=float32), -1.0043765]. 
=============================================
[2019-03-23 13:28:47,886] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6445396e-06 9.9999833e-01 7.2463475e-30 3.0183014e-27 4.3298923e-25], sum to 1.0000
[2019-03-23 13:28:47,902] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9486
[2019-03-23 13:28:47,905] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.55, 73.5, 1.0, 2.0, 0.6447043601733464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 718673.1419304566, 718673.1419304563, 147339.7742706026], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6172200.0000, 
sim time next is 6172800.0000, 
raw observation next is [20.36666666666667, 76.0, 1.0, 2.0, 0.6174881692839621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 689727.9462602743, 689727.9462602743, 144779.0078720468], 
processed observation next is [1.0, 0.43478260869565216, 0.5621212121212124, 0.76, 1.0, 1.0, 0.5218602116049526, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2554547949112127, 0.2554547949112127, 0.35311953139523605], 
reward next is 0.6469, 
noisyNet noise sample is [array([-1.7855977], dtype=float32), -0.72028935]. 
=============================================
[2019-03-23 13:28:47,928] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.0022818e-08 1.0000000e+00 7.8887475e-30 2.4606442e-26 2.4046339e-26], sum to 1.0000
[2019-03-23 13:28:47,935] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7427
[2019-03-23 13:28:47,941] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 71.0, 1.0, 2.0, 0.7577996304576934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 852520.5961333811, 852520.5961333811, 164733.8354824267], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6177600.0000, 
sim time next is 6178200.0000, 
raw observation next is [21.7, 71.0, 1.0, 2.0, 0.7053934491185083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 794043.6641460327, 794043.6641460327, 158031.4423889381], 
processed observation next is [1.0, 0.5217391304347826, 0.6227272727272727, 0.71, 1.0, 1.0, 0.6317418113981355, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2940902459800121, 0.2940902459800121, 0.3854425424120441], 
reward next is 0.6146, 
noisyNet noise sample is [array([-0.58670485], dtype=float32), -0.7641995]. 
=============================================
[2019-03-23 13:28:48,991] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.9262830e-05 9.9997079e-01 2.4739075e-27 1.0480191e-25 1.9183538e-23], sum to 1.0000
[2019-03-23 13:28:49,000] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9069
[2019-03-23 13:28:49,004] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 57.00000000000001, 1.0, 2.0, 0.3493269663625418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 386609.8336658461, 386609.8336658464, 117234.6160317101], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6196800.0000, 
sim time next is 6197400.0000, 
raw observation next is [22.7, 57.0, 1.0, 2.0, 0.3369561216188806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 372635.2652126541, 372635.2652126541, 116174.6574690467], 
processed observation next is [1.0, 0.7391304347826086, 0.6681818181818181, 0.57, 1.0, 1.0, 0.17119515202360075, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1380130611898719, 0.1380130611898719, 0.28335282309523585], 
reward next is 0.7166, 
noisyNet noise sample is [array([1.4109051], dtype=float32), 0.07856147]. 
=============================================
[2019-03-23 13:28:54,158] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3586221e-07 9.9999988e-01 7.3469667e-26 1.8462672e-24 2.1833669e-23], sum to 1.0000
[2019-03-23 13:28:54,169] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3702
[2019-03-23 13:28:54,174] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.5, 55.0, 1.0, 2.0, 0.5440718470410457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 617406.3722911695, 617406.3722911695, 149633.0384649251], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6279000.0000, 
sim time next is 6279600.0000, 
raw observation next is [29.6, 55.0, 1.0, 2.0, 0.5458081290371649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 619019.5126799339, 619019.5126799339, 150003.0734545689], 
processed observation next is [0.0, 0.6956521739130435, 0.9818181818181819, 0.55, 1.0, 1.0, 0.4322601612964561, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2292664861777533, 0.2292664861777533, 0.3658611547672412], 
reward next is 0.6341, 
noisyNet noise sample is [array([0.2465354], dtype=float32), 0.75397676]. 
=============================================
[2019-03-23 13:28:56,121] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.0220816e-09 1.0000000e+00 1.3274976e-28 3.8697193e-26 6.8478199e-24], sum to 1.0000
[2019-03-23 13:28:56,128] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8560
[2019-03-23 13:28:56,137] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.08333333333334, 70.66666666666667, 1.0, 2.0, 0.4884646076387816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 557256.2370009302, 557256.2370009302, 140337.366072267], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6303000.0000, 
sim time next is 6303600.0000, 
raw observation next is [25.0, 71.0, 1.0, 2.0, 0.4872099139079955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 555844.1490525753, 555844.1490525751, 140137.3135162688], 
processed observation next is [0.0, 1.0, 0.7727272727272727, 0.71, 1.0, 1.0, 0.3590123923849943, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20586820335280567, 0.2058682033528056, 0.3417983256494361], 
reward next is 0.6582, 
noisyNet noise sample is [array([1.8923647], dtype=float32), 0.8925817]. 
=============================================
[2019-03-23 13:28:59,130] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.8681818e-07 9.9999976e-01 3.4433597e-27 1.0839452e-24 5.8842384e-23], sum to 1.0000
[2019-03-23 13:28:59,139] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2545
[2019-03-23 13:28:59,143] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 79.0, 1.0, 2.0, 0.5198590488852166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 592228.6695972449, 592228.6695972447, 145204.4975357428], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6393600.0000, 
sim time next is 6394200.0000, 
raw observation next is [24.4, 78.50000000000001, 1.0, 2.0, 0.5183973738968607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 590687.3573835366, 590687.3573835366, 144909.8014927091], 
processed observation next is [1.0, 0.0, 0.7454545454545454, 0.7850000000000001, 1.0, 1.0, 0.39799671737107584, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2187730953272358, 0.2187730953272358, 0.3534385402261198], 
reward next is 0.6466, 
noisyNet noise sample is [array([-0.766275], dtype=float32), 0.2098395]. 
=============================================
[2019-03-23 13:28:59,352] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.0188750e-07 9.9999976e-01 1.7357245e-24 7.0837349e-23 3.0743020e-21], sum to 1.0000
[2019-03-23 13:28:59,357] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3555
[2019-03-23 13:28:59,360] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.9, 63.66666666666666, 1.0, 2.0, 0.5537471184868261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 627822.228094971, 627822.228094971, 151105.2846165162], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6370800.0000, 
sim time next is 6371400.0000, 
raw observation next is [27.8, 64.33333333333334, 1.0, 2.0, 0.5550564330390555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 629207.3325573946, 629207.3325573946, 151313.1930532353], 
processed observation next is [0.0, 0.7391304347826086, 0.9, 0.6433333333333334, 1.0, 1.0, 0.4438205412988193, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23303975279903505, 0.23303975279903505, 0.3690565684225251], 
reward next is 0.6309, 
noisyNet noise sample is [array([-1.16508], dtype=float32), -0.06509015]. 
=============================================
[2019-03-23 13:29:02,179] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2537598e-07 9.9999988e-01 2.1359918e-28 7.7255632e-26 1.7630661e-23], sum to 1.0000
[2019-03-23 13:29:02,188] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5269
[2019-03-23 13:29:02,196] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.86666666666667, 83.0, 1.0, 2.0, 0.6400987552875068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 710035.8226194377, 710035.8226194374, 145462.5408712708], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6452400.0000, 
sim time next is 6453000.0000, 
raw observation next is [19.15, 81.0, 1.0, 2.0, 0.6369211946584756, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 706607.4375969777, 706607.4375969777, 145137.6686692002], 
processed observation next is [1.0, 0.6956521739130435, 0.5068181818181817, 0.81, 1.0, 1.0, 0.5461514933230945, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.261706458369251, 0.261706458369251, 0.3539943138273176], 
reward next is 0.6460, 
noisyNet noise sample is [array([1.4377959], dtype=float32), 1.0458888]. 
=============================================
[2019-03-23 13:29:02,216] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[68.707436]
 [68.51807 ]
 [68.879906]
 [68.93371 ]
 [68.93499 ]], R is [[68.74993134]
 [68.7076416 ]
 [68.6324234 ]
 [68.59319305]
 [68.55696869]].
[2019-03-23 13:29:03,094] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.6133591e-09 1.0000000e+00 2.1838915e-31 2.1468064e-29 6.4031019e-27], sum to 1.0000
[2019-03-23 13:29:03,100] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5183
[2019-03-23 13:29:03,106] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 75.0, 1.0, 2.0, 0.2192101063668565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 238008.3296091833, 238008.329609183, 75249.50223918281], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6473400.0000, 
sim time next is 6474000.0000, 
raw observation next is [15.5, 75.0, 1.0, 2.0, 0.2186431782385491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 237392.6347049871, 237392.6347049874, 75188.25774682713], 
processed observation next is [1.0, 0.9565217391304348, 0.3409090909090909, 0.75, 1.0, 1.0, 0.02330397279818635, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08792319803888411, 0.08792319803888422, 0.18338599450445642], 
reward next is 0.8166, 
noisyNet noise sample is [array([0.40314436], dtype=float32), 1.1963192]. 
=============================================
[2019-03-23 13:29:03,122] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[77.58134 ]
 [77.60215 ]
 [77.60779 ]
 [77.63479 ]
 [77.668236]], R is [[77.60798645]
 [77.64837646]
 [77.68813324]
 [77.72686005]
 [77.76455688]].
[2019-03-23 13:29:06,783] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.0435023e-06 9.9999797e-01 3.1351205e-30 3.5176070e-28 2.0452155e-27], sum to 1.0000
[2019-03-23 13:29:06,791] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6168
[2019-03-23 13:29:06,795] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 57.0, 1.0, 2.0, 0.4353145576061355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 472758.7386672294, 472758.7386672294, 101307.8654451065], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6516000.0000, 
sim time next is 6516600.0000, 
raw observation next is [18.71666666666667, 57.5, 1.0, 2.0, 0.4510384059444616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489843.6985975142, 489843.6985975142, 102847.9012556882], 
processed observation next is [1.0, 0.43478260869565216, 0.48712121212121223, 0.575, 1.0, 1.0, 0.31379800743057695, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1814235920731534, 0.1814235920731534, 0.25084853964802], 
reward next is 0.7492, 
noisyNet noise sample is [array([-1.5530691], dtype=float32), -0.88665766]. 
=============================================
[2019-03-23 13:29:09,903] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 13:29:09,904] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:29:09,905] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:29:09,905] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:29:09,906] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:29:09,906] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:29:09,908] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:29:09,909] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:29:09,912] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:29:09,907] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:29:09,916] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:29:09,924] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run25
[2019-03-23 13:29:09,950] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run25
[2019-03-23 13:29:09,950] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run25
[2019-03-23 13:29:09,950] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run25
[2019-03-23 13:29:10,025] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run25
[2019-03-23 13:29:11,755] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07615052], dtype=float32), 0.21079332]
[2019-03-23 13:29:11,756] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.859830945, 73.71608447666667, 1.0, 2.0, 0.2826074723986385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 306845.5485348399, 306845.5485348395, 98783.9627625034]
[2019-03-23 13:29:11,757] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:29:11,760] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.0696856e-09 1.0000000e+00 4.5621895e-31 1.2070600e-28 2.5080851e-26], sampled 0.6813967258495551
[2019-03-23 13:29:19,989] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07615052], dtype=float32), 0.21079332]
[2019-03-23 13:29:19,990] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.52955397, 86.02704811, 1.0, 2.0, 0.2906964633125624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 315630.6050279206, 315630.6050279202, 101563.9831974424]
[2019-03-23 13:29:19,992] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:29:19,994] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.1256678e-09 1.0000000e+00 2.1719445e-31 6.0989086e-29 1.3391464e-26], sampled 0.7011491087261662
[2019-03-23 13:29:21,330] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07615052], dtype=float32), 0.21079332]
[2019-03-23 13:29:21,331] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.89869999, 94.84617747666665, 1.0, 2.0, 0.3224981693968624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 352493.6004182126, 352493.6004182126, 117841.7203145143]
[2019-03-23 13:29:21,333] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:29:21,335] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.6712043e-09 1.0000000e+00 4.6715748e-30 1.0287542e-27 1.7936044e-25], sampled 0.9082959950174992
[2019-03-23 13:29:35,916] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07615052], dtype=float32), 0.21079332]
[2019-03-23 13:29:35,917] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.03240796333333, 84.38216718166667, 1.0, 2.0, 0.3504294533378112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 384707.1935523719, 384707.1935523715, 120461.6150403154]
[2019-03-23 13:29:35,918] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:29:35,921] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0268228e-09 1.0000000e+00 1.4629534e-33 6.1021134e-31 1.9539450e-28], sampled 0.3562119759940253
[2019-03-23 13:29:47,585] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07615052], dtype=float32), 0.21079332]
[2019-03-23 13:29:47,586] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.01666666666667, 47.16666666666667, 1.0, 2.0, 0.3197120605822146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 350640.7390989725, 350640.7390989728, 113762.5932421912]
[2019-03-23 13:29:47,587] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:29:47,591] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.849897e-09 1.000000e+00 2.202054e-30 5.146055e-28 9.488841e-26], sampled 0.9259237739433119
[2019-03-23 13:29:53,485] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07615052], dtype=float32), 0.21079332]
[2019-03-23 13:29:53,486] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.3, 87.0, 1.0, 2.0, 0.535639113142952, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 610072.9514999562, 610072.9514999562, 151506.6094868751]
[2019-03-23 13:29:53,488] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:29:53,491] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0692064e-09 1.0000000e+00 1.7023076e-33 7.0197396e-31 2.2215125e-28], sampled 0.8722873101149026
[2019-03-23 13:30:31,152] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07615052], dtype=float32), 0.21079332]
[2019-03-23 13:30:31,154] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.572520125, 59.842188005, 1.0, 2.0, 0.2788439701030108, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 302758.2369571478, 302758.2369571471, 95989.38230116555]
[2019-03-23 13:30:31,156] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:30:31,161] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.2658883e-09 1.0000000e+00 9.7794613e-31 2.4361341e-28 4.7775724e-26], sampled 0.21465660625783622
[2019-03-23 13:30:49,994] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 13:30:50,409] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 13:30:50,572] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 13:30:50,577] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 13:30:50,599] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2861 1773154298.0034 173.0000
[2019-03-23 13:30:51,613] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 600000, evaluation results [600000.0, 8512.28612121474, 1773154298.0034232, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 13:30:55,923] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0737110e-06 9.9999893e-01 1.1191476e-29 5.4284588e-26 1.4646491e-26], sum to 1.0000
[2019-03-23 13:30:55,932] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1990
[2019-03-23 13:30:55,939] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.5253283561535146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 586833.6157485014, 586833.6157485014, 134827.9701006161], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6700800.0000, 
sim time next is 6701400.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.6012417502322084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 672059.046949921, 672059.046949921, 143141.0826568769], 
processed observation next is [1.0, 0.5652173913043478, 0.4681818181818182, 0.93, 1.0, 1.0, 0.5015521877902605, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24891075812960034, 0.24891075812960034, 0.3491245918460412], 
reward next is 0.6509, 
noisyNet noise sample is [array([-0.60519856], dtype=float32), -0.68311137]. 
=============================================
[2019-03-23 13:30:59,244] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.8976841e-08 9.9999988e-01 3.2956046e-28 1.7177875e-25 2.1903889e-25], sum to 1.0000
[2019-03-23 13:30:59,251] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7337
[2019-03-23 13:30:59,260] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.46666666666667, 76.33333333333333, 1.0, 2.0, 0.6565610108369204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 741839.3698869342, 741839.3698869342, 153304.4315568978], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6774000.0000, 
sim time next is 6774600.0000, 
raw observation next is [21.83333333333333, 76.16666666666667, 1.0, 2.0, 0.6922518694497877, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 784388.7322719361, 784388.7322719361, 159173.4340207471], 
processed observation next is [1.0, 0.391304347826087, 0.6287878787878786, 0.7616666666666667, 1.0, 1.0, 0.6153148368122345, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.29051434528590225, 0.29051434528590225, 0.38822788785548074], 
reward next is 0.6118, 
noisyNet noise sample is [array([-1.515411], dtype=float32), 0.08382941]. 
=============================================
[2019-03-23 13:31:04,264] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.3261200e-12 1.0000000e+00 1.0752350e-32 4.7648355e-32 7.6969893e-29], sum to 1.0000
[2019-03-23 13:31:04,274] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7212
[2019-03-23 13:31:04,278] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.18333333333334, 58.66666666666666, 1.0, 2.0, 0.4040158892376178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354103, 458943.141082253, 458943.1410822532, 127542.2984035336], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6803400.0000, 
sim time next is 6804000.0000, 
raw observation next is [25.0, 60.0, 1.0, 2.0, 0.412681657281296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 468947.8925633206, 468947.8925633209, 128500.3556499546], 
processed observation next is [1.0, 0.782608695652174, 0.7727272727272727, 0.6, 1.0, 1.0, 0.26585207160162, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1736844046530817, 0.1736844046530818, 0.3134155015852551], 
reward next is 0.6866, 
noisyNet noise sample is [array([-0.23498382], dtype=float32), 1.1738954]. 
=============================================
[2019-03-23 13:31:04,298] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[76.30582]
 [75.64029]
 [76.08669]
 [75.63369]
 [75.64142]], R is [[76.27771759]
 [76.20385742]
 [76.13256836]
 [76.06329346]
 [75.9910202 ]].
[2019-03-23 13:31:09,746] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.9859639e-09 1.0000000e+00 9.5971670e-28 5.6624374e-26 2.7444215e-24], sum to 1.0000
[2019-03-23 13:31:09,757] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6696
[2019-03-23 13:31:09,763] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.11666666666666, 69.66666666666666, 1.0, 2.0, 0.4355580452611355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 496402.610885185, 496402.610885185, 132243.0088695563], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6947400.0000, 
sim time next is 6948000.0000, 
raw observation next is [24.4, 69.0, 1.0, 2.0, 0.4413547675680303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 503238.5092441817, 503238.5092441817, 133196.8240824229], 
processed observation next is [0.0, 0.43478260869565216, 0.7454545454545454, 0.69, 1.0, 1.0, 0.3016934594600379, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1863846330534006, 0.1863846330534006, 0.3248703026400559], 
reward next is 0.6751, 
noisyNet noise sample is [array([0.82652766], dtype=float32), -0.61589354]. 
=============================================
[2019-03-23 13:31:09,779] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[66.749535]
 [66.7064  ]
 [66.67278 ]
 [66.63701 ]
 [66.61854 ]], R is [[66.80929565]
 [66.81866455]
 [66.83016205]
 [66.84372711]
 [66.85948181]].
[2019-03-23 13:31:10,986] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.3745554e-08 9.9999988e-01 1.7886378e-24 2.2953626e-22 2.2461126e-21], sum to 1.0000
[2019-03-23 13:31:10,993] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6798
[2019-03-23 13:31:10,998] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 60.5, 1.0, 2.0, 0.5171023002028219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 588747.2699205629, 588747.2699205632, 145151.957914374], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6972600.0000, 
sim time next is 6973200.0000, 
raw observation next is [27.7, 61.0, 1.0, 2.0, 0.5205867200565468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592491.0589875246, 592491.0589875246, 145739.9440986082], 
processed observation next is [0.0, 0.7391304347826086, 0.8954545454545454, 0.61, 1.0, 1.0, 0.4007334000706835, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21944113295834244, 0.21944113295834244, 0.35546327828928825], 
reward next is 0.6445, 
noisyNet noise sample is [array([-1.5055885], dtype=float32), -1.11978]. 
=============================================
[2019-03-23 13:31:21,039] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3762782e-09 1.0000000e+00 2.1348669e-29 6.1299095e-28 8.6460555e-25], sum to 1.0000
[2019-03-23 13:31:21,046] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9720
[2019-03-23 13:31:21,053] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.63333333333333, 63.00000000000001, 1.0, 2.0, 0.2603526497857677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 282692.0076965895, 282692.0076965895, 86273.15350652678], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7158000.0000, 
sim time next is 7158600.0000, 
raw observation next is [18.55, 63.0, 1.0, 2.0, 0.2583185359688611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 280482.7214349068, 280482.7214349065, 85535.68928235778], 
processed observation next is [1.0, 0.8695652173913043, 0.47954545454545455, 0.63, 1.0, 1.0, 0.07289816996107638, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10388248942033586, 0.10388248942033573, 0.20862363239599457], 
reward next is 0.7914, 
noisyNet noise sample is [array([-1.0851799], dtype=float32), -0.24072275]. 
=============================================
[2019-03-23 13:31:21,272] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.9352004e-10 1.0000000e+00 3.3482153e-30 3.4337439e-28 1.5198218e-25], sum to 1.0000
[2019-03-23 13:31:21,282] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1187
[2019-03-23 13:31:21,287] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.36666666666667, 88.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 203189.3156030857, 203189.3156030859, 67654.60360289621], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7188000.0000, 
sim time next is 7188600.0000, 
raw observation next is [12.28333333333333, 88.83333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 199971.710939631, 199971.7109396307, 67022.60337726725], 
processed observation next is [1.0, 0.17391304347826086, 0.19469696969696954, 0.8883333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07406359664430778, 0.07406359664430766, 0.16346976433479818], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.8654039], dtype=float32), -0.17620833]. 
=============================================
[2019-03-23 13:31:33,843] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3981953e-07 9.9999988e-01 7.9757648e-24 8.2067247e-22 3.0175355e-19], sum to 1.0000
[2019-03-23 13:31:33,851] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0184
[2019-03-23 13:31:33,854] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.2, 92.0, 1.0, 2.0, 0.4034512231841743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 454710.9115245488, 454710.9115245488, 125198.122972556], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7420800.0000, 
sim time next is 7421400.0000, 
raw observation next is [19.1, 91.5, 1.0, 2.0, 0.3981917204501785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 448043.4859158302, 448043.4859158299, 124337.2473524661], 
processed observation next is [1.0, 0.9130434782608695, 0.5045454545454546, 0.915, 1.0, 1.0, 0.24773965056272307, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16594203182067785, 0.16594203182067774, 0.3032615789084539], 
reward next is 0.6967, 
noisyNet noise sample is [array([-0.33742252], dtype=float32), -0.69717586]. 
=============================================
[2019-03-23 13:31:33,951] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.11175265e-08 1.00000000e+00 1.98407377e-26 9.13495091e-24
 3.98993148e-22], sum to 1.0000
[2019-03-23 13:31:33,959] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3408
[2019-03-23 13:31:33,966] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.43333333333333, 92.33333333333334, 1.0, 2.0, 0.3687074003136087, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 411824.6662205631, 411824.6662205628, 120309.9391517507], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7428000.0000, 
sim time next is 7428600.0000, 
raw observation next is [18.25, 93.5, 1.0, 2.0, 0.3680678100797307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 410835.2274674218, 410835.2274674221, 120136.0020364119], 
processed observation next is [1.0, 1.0, 0.4659090909090909, 0.935, 1.0, 1.0, 0.21008476259966338, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15216119535830436, 0.15216119535830447, 0.29301463911319975], 
reward next is 0.7070, 
noisyNet noise sample is [array([-0.8879148], dtype=float32), -1.4589282]. 
=============================================
[2019-03-23 13:31:38,535] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.9040988e-08 9.9999988e-01 1.1607977e-25 7.1435092e-25 1.6420064e-21], sum to 1.0000
[2019-03-23 13:31:38,543] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6982
[2019-03-23 13:31:38,550] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 64.33333333333334, 1.0, 2.0, 0.4373519005605177, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 498175.8977763398, 498175.8977763395, 132072.385003871], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7503600.0000, 
sim time next is 7504200.0000, 
raw observation next is [24.7, 65.5, 1.0, 2.0, 0.4398439715794887, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 501176.2830115085, 501176.2830115085, 132528.5069175482], 
processed observation next is [0.0, 0.8695652173913043, 0.759090909090909, 0.655, 1.0, 1.0, 0.29980496447436084, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18562084555981798, 0.18562084555981798, 0.3232402607745078], 
reward next is 0.6768, 
noisyNet noise sample is [array([0.13264507], dtype=float32), -0.5474553]. 
=============================================
[2019-03-23 13:31:40,516] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 13:31:40,518] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:31:40,519] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:31:40,519] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:31:40,520] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:31:40,521] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:31:40,522] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:31:40,522] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:31:40,524] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:31:40,529] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:31:40,530] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:31:40,544] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run26
[2019-03-23 13:31:40,568] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run26
[2019-03-23 13:31:40,570] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run26
[2019-03-23 13:31:40,570] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run26
[2019-03-23 13:31:40,654] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run26
[2019-03-23 13:31:44,344] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08024463], dtype=float32), 0.21693021]
[2019-03-23 13:31:44,345] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.36666666666667, 30.66666666666666, 1.0, 2.0, 0.3278959986531049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 356032.8500609785, 356032.8500609788, 95695.57943158077]
[2019-03-23 13:31:44,346] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:31:44,348] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.9205615e-09 1.0000000e+00 7.8114876e-30 2.4298241e-27 2.7079906e-25], sampled 0.8846999579732752
[2019-03-23 13:32:23,825] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08024463], dtype=float32), 0.21693021]
[2019-03-23 13:32:23,826] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.07826294666667, 99.10680645, 1.0, 2.0, 0.4309890083006758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 490584.049665013, 490584.0496650126, 135404.6237676002]
[2019-03-23 13:32:23,828] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:32:23,831] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.2854064e-09 1.0000000e+00 2.0835271e-30 7.2487728e-28 8.8492968e-26], sampled 0.16549400074106502
[2019-03-23 13:32:30,828] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08024463], dtype=float32), 0.21693021]
[2019-03-23 13:32:30,830] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 88.00000000000001, 1.0, 2.0, 0.5920882952718747, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 662983.4864051602, 662983.4864051605, 142607.1262312475]
[2019-03-23 13:32:30,830] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:32:30,835] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.5529641e-09 1.0000000e+00 1.9927710e-29 5.7259041e-27 5.9787443e-25], sampled 0.057475858147589154
[2019-03-23 13:32:34,655] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08024463], dtype=float32), 0.21693021]
[2019-03-23 13:32:34,656] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [27.35675076166667, 75.913217075, 1.0, 2.0, 0.6070478908372283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 682071.3708224163, 682071.3708224163, 164190.649089405]
[2019-03-23 13:32:34,658] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:32:34,660] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0276261e-09 1.0000000e+00 9.9801069e-31 3.6961017e-28 4.7464186e-26], sampled 0.7897000958490742
[2019-03-23 13:32:35,519] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08024463], dtype=float32), 0.21693021]
[2019-03-23 13:32:35,521] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.83333333333333, 88.33333333333334, 1.0, 2.0, 0.4432759916943254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 504065.0654589171, 504065.0654589168, 136156.1506282285]
[2019-03-23 13:32:35,522] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:32:35,525] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0085923e-09 1.0000000e+00 9.3812386e-31 3.4922110e-28 4.5044254e-26], sampled 0.2568899561508349
[2019-03-23 13:32:46,111] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08024463], dtype=float32), 0.21693021]
[2019-03-23 13:32:46,112] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [29.9, 51.0, 1.0, 2.0, 0.90469263989972, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9789455636330022, 6.911199999999999, 6.9112, 77.32846344354104, 1574747.348331744, 1574747.348331745, 328038.4047994863]
[2019-03-23 13:32:46,114] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:32:46,118] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.0792827e-09 1.0000000e+00 9.2800916e-29 2.3408800e-26 2.2001128e-24], sampled 0.14600483781635842
[2019-03-23 13:32:46,119] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1574747.348331744 W.
[2019-03-23 13:32:57,341] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08024463], dtype=float32), 0.21693021]
[2019-03-23 13:32:57,343] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.91666666666667, 68.5, 1.0, 2.0, 0.6169183629623812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 684230.9146542558, 684230.9146542562, 142826.8690935177]
[2019-03-23 13:32:57,344] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:32:57,346] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.7033354e-09 1.0000000e+00 6.7765747e-29 1.7553662e-26 1.6841715e-24], sampled 0.29972331157385845
[2019-03-23 13:32:57,613] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08024463], dtype=float32), 0.21693021]
[2019-03-23 13:32:57,616] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.866758785, 57.66202487, 1.0, 2.0, 0.2715479872265577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 294834.5916495216, 294834.5916495213, 88982.66323795615]
[2019-03-23 13:32:57,617] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:32:57,622] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.8003093e-09 1.0000000e+00 6.3132066e-30 1.9992907e-27 2.2611095e-25], sampled 0.753489882577899
[2019-03-23 13:33:20,641] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 13:33:21,209] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 13:33:21,232] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 13:33:21,303] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 13:33:21,430] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 13:33:22,449] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 625000, evaluation results [625000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 13:33:35,288] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.4843124e-08 9.9999988e-01 3.8855609e-26 1.0678535e-23 4.1710565e-22], sum to 1.0000
[2019-03-23 13:33:35,300] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8352
[2019-03-23 13:33:35,306] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.3, 95.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 215513.4275395103, 215513.4275395103, 72818.55191323622], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7796400.0000, 
sim time next is 7797000.0000, 
raw observation next is [13.3, 95.5, 1.0, 2.0, 0.2004016930155302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 217582.4451687236, 217582.4451687236, 73279.31107844827], 
processed observation next is [1.0, 0.21739130434782608, 0.24090909090909093, 0.955, 1.0, 1.0, 0.000502116269412746, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08058609080323097, 0.08058609080323097, 0.17873002702060553], 
reward next is 0.8213, 
noisyNet noise sample is [array([-0.542414], dtype=float32), 0.9313752]. 
=============================================
[2019-03-23 13:33:35,318] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[63.414627]
 [63.424057]
 [63.416275]
 [63.391445]
 [63.398056]], R is [[63.61214066]
 [62.97602081]
 [62.34626007]
 [61.72279739]
 [61.9259491 ]].
[2019-03-23 13:33:39,182] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.7966165e-11 1.0000000e+00 2.5711114e-33 2.9731515e-30 2.5295973e-27], sum to 1.0000
[2019-03-23 13:33:39,192] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6827
[2019-03-23 13:33:39,196] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 63.0, 1.0, 2.0, 0.2900573090223287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 314955.896252626, 314955.8962526257, 103510.3628358424], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7853400.0000, 
sim time next is 7854000.0000, 
raw observation next is [20.0, 63.0, 1.0, 2.0, 0.2894517067656289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 314298.0964610373, 314298.0964610376, 103442.6677534828], 
processed observation next is [1.0, 0.9130434782608695, 0.5454545454545454, 0.63, 1.0, 1.0, 0.11181463345703614, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11640670239297678, 0.11640670239297689, 0.252299189642641], 
reward next is 0.7477, 
noisyNet noise sample is [array([-0.66096836], dtype=float32), 1.1548961]. 
=============================================
[2019-03-23 13:33:39,217] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[79.66049 ]
 [79.66487 ]
 [79.66764 ]
 [79.669205]
 [79.66138 ]], R is [[79.6108551 ]
 [79.56228638]
 [79.51376343]
 [79.4651947 ]
 [79.41690826]].
[2019-03-23 13:33:40,427] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.1527170e-09 1.0000000e+00 1.0165395e-28 7.0852664e-26 2.7708373e-23], sum to 1.0000
[2019-03-23 13:33:40,435] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5306
[2019-03-23 13:33:40,438] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 95.0, 1.0, 2.0, 0.669980958584109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 759430.4526661016, 759430.4526661016, 156442.6305132337], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7897200.0000, 
sim time next is 7897800.0000, 
raw observation next is [19.4, 95.5, 1.0, 2.0, 0.65410713327396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 741677.6823042256, 741677.682304226, 154563.5503097208], 
processed observation next is [1.0, 0.391304347826087, 0.5181818181818181, 0.955, 1.0, 1.0, 0.5676339165924499, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2746954378904539, 0.2746954378904541, 0.3769842690480995], 
reward next is 0.6230, 
noisyNet noise sample is [array([1.0183702], dtype=float32), 1.0122825]. 
=============================================
[2019-03-23 13:33:41,063] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.1233413e-08 1.0000000e+00 1.4701250e-26 1.9439939e-24 6.5127165e-22], sum to 1.0000
[2019-03-23 13:33:41,072] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6381
[2019-03-23 13:33:41,076] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.6, 92.0, 1.0, 2.0, 0.64177895154842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 730903.67253492, 730903.6725349204, 155582.1809503037], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7908600.0000, 
sim time next is 7909200.0000, 
raw observation next is [20.5, 93.0, 1.0, 2.0, 0.5922903685648304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 674530.3305855836, 674530.3305855836, 149321.0290009129], 
processed observation next is [1.0, 0.5652173913043478, 0.5681818181818182, 0.93, 1.0, 1.0, 0.49036296070603796, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24982604836503094, 0.24982604836503094, 0.36419763170954367], 
reward next is 0.6358, 
noisyNet noise sample is [array([-0.01026793], dtype=float32), -1.0206258]. 
=============================================
[2019-03-23 13:33:41,101] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.9365067e-08 1.0000000e+00 1.8236765e-27 1.1530053e-23 8.7510524e-23], sum to 1.0000
[2019-03-23 13:33:41,109] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0957
[2019-03-23 13:33:41,117] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.6, 75.66666666666667, 1.0, 2.0, 0.3247221442115309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 357547.5707837186, 357547.5707837186, 114649.8782739228], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7885200.0000, 
sim time next is 7885800.0000, 
raw observation next is [19.7, 75.5, 1.0, 2.0, 0.3249702445091896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 358263.6450910629, 358263.6450910626, 114837.9861622696], 
processed observation next is [1.0, 0.2608695652173913, 0.5318181818181817, 0.755, 1.0, 1.0, 0.15621280563648698, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1326902389226159, 0.13269023892261578, 0.2800926491762673], 
reward next is 0.7199, 
noisyNet noise sample is [array([1.0661868], dtype=float32), -1.2382375]. 
=============================================
[2019-03-23 13:33:42,748] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.5751975e-09 1.0000000e+00 4.0583105e-33 1.8034745e-28 2.2935550e-26], sum to 1.0000
[2019-03-23 13:33:42,758] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2903
[2019-03-23 13:33:42,769] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.51666666666667, 91.33333333333334, 1.0, 2.0, 0.4671092429498334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 532929.5211347294, 532929.5211347296, 136661.2884619261], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7927800.0000, 
sim time next is 7928400.0000, 
raw observation next is [21.43333333333334, 91.66666666666667, 1.0, 2.0, 0.4672763517472092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 533096.4240530259, 533096.4240530255, 136594.9872231207], 
processed observation next is [1.0, 0.782608695652174, 0.6106060606060609, 0.9166666666666667, 1.0, 1.0, 0.3340954396840115, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19744312001963923, 0.1974431200196391, 0.3331585054222456], 
reward next is 0.6668, 
noisyNet noise sample is [array([1.0735254], dtype=float32), 1.4604465]. 
=============================================
[2019-03-23 13:33:43,972] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:33:43,972] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:33:43,981] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run4
[2019-03-23 13:33:44,153] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:33:44,154] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:33:44,155] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run4
[2019-03-23 13:33:44,345] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:33:44,345] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:33:44,347] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run4
[2019-03-23 13:33:44,370] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:33:44,371] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:33:44,373] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run4
[2019-03-23 13:33:44,529] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:33:44,529] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:33:44,531] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run4
[2019-03-23 13:33:44,570] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:33:44,571] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:33:44,572] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run4
[2019-03-23 13:33:44,657] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:33:44,657] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:33:44,659] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run4
[2019-03-23 13:33:44,691] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:33:44,691] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:33:44,693] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run4
[2019-03-23 13:33:44,727] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:33:44,728] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:33:44,730] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run4
[2019-03-23 13:33:44,791] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:33:44,791] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:33:44,793] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run4
[2019-03-23 13:33:44,825] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:33:44,826] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:33:44,828] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run4
[2019-03-23 13:33:44,860] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:33:44,860] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:33:44,863] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run4
[2019-03-23 13:33:44,917] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:33:44,917] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:33:44,918] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run4
[2019-03-23 13:33:45,007] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:33:45,007] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:33:45,009] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run4
[2019-03-23 13:33:45,082] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:33:45,082] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:33:45,084] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run4
[2019-03-23 13:33:45,194] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:33:45,195] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:33:45,196] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run4
[2019-03-23 13:33:47,799] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.4800625e-08 9.9999988e-01 3.3405557e-25 8.6116701e-22 2.6702783e-20], sum to 1.0000
[2019-03-23 13:33:47,805] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8539
[2019-03-23 13:33:47,813] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 96.0, 1.0, 2.0, 0.625169407215428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 705288.0485440495, 705288.0485440495, 148855.828055557], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 30600.0000, 
sim time next is 31200.0000, 
raw observation next is [19.06666666666667, 94.66666666666666, 1.0, 2.0, 0.6888825522454957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 778331.5001018338, 778331.5001018338, 157406.8539695405], 
processed observation next is [1.0, 0.34782608695652173, 0.5030303030303032, 0.9466666666666665, 1.0, 1.0, 0.6111031903068695, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2882709259636422, 0.2882709259636422, 0.38391915602326954], 
reward next is 0.6161, 
noisyNet noise sample is [array([-1.1225636], dtype=float32), -1.2659923]. 
=============================================
[2019-03-23 13:33:49,849] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.2442583e-10 1.0000000e+00 7.6038426e-27 8.9861591e-24 3.7127155e-23], sum to 1.0000
[2019-03-23 13:33:49,853] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4523
[2019-03-23 13:33:49,861] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.9254733799113264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1051208.504710217, 1051208.504710218, 195434.933736422], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 57600.0000, 
sim time next is 58200.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.9695547659601197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1101289.474860934, 1101289.474860934, 202882.3797963662], 
processed observation next is [1.0, 0.6956521739130435, 0.5909090909090909, 0.83, 1.0, 1.0, 0.9619434574501495, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.40788499068923484, 0.40788499068923484, 0.4948350726740639], 
reward next is 0.5052, 
noisyNet noise sample is [array([-0.5484619], dtype=float32), 0.69809365]. 
=============================================
[2019-03-23 13:34:00,456] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.1902459e-09 1.0000000e+00 9.8823728e-22 1.8073602e-19 8.1387781e-18], sum to 1.0000
[2019-03-23 13:34:00,465] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2021
[2019-03-23 13:34:00,471] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666666, 78.66666666666666, 1.0, 2.0, 0.2281544702113644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 247722.1847570005, 247722.1847570003, 83368.94397450579], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 294000.0000, 
sim time next is 294600.0000, 
raw observation next is [16.83333333333334, 77.83333333333334, 1.0, 2.0, 0.2304661443550527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 250232.7657622141, 250232.7657622141, 84112.44002442757], 
processed observation next is [0.0, 0.391304347826087, 0.40151515151515177, 0.7783333333333334, 1.0, 1.0, 0.03808268044381585, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09267880213415337, 0.09267880213415337, 0.2051522927425063], 
reward next is 0.7948, 
noisyNet noise sample is [array([0.9229282], dtype=float32), 0.8147407]. 
=============================================
[2019-03-23 13:34:11,619] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.9156469e-12 1.0000000e+00 1.4866701e-28 5.0457397e-25 6.7118593e-25], sum to 1.0000
[2019-03-23 13:34:11,630] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6880
[2019-03-23 13:34:11,634] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 94.0, 1.0, 2.0, 0.2582840989128672, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 280445.3188380913, 280445.318838091, 87059.78691388416], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 501600.0000, 
sim time next is 502200.0000, 
raw observation next is [15.0, 94.0, 1.0, 2.0, 0.2575503778424892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 279648.4141945441, 279648.4141945441, 86973.74464290218], 
processed observation next is [1.0, 0.8260869565217391, 0.3181818181818182, 0.94, 1.0, 1.0, 0.07193797230311147, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10357348673872004, 0.10357348673872004, 0.21213108449488335], 
reward next is 0.7879, 
noisyNet noise sample is [array([1.5812011], dtype=float32), 1.328799]. 
=============================================
[2019-03-23 13:34:11,690] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0540844e-10 1.0000000e+00 1.4960350e-27 1.1207410e-24 2.5098690e-23], sum to 1.0000
[2019-03-23 13:34:11,698] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6090
[2019-03-23 13:34:11,703] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 94.0, 1.0, 2.0, 0.4324875608958785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469687.0908614011, 469687.0908614011, 105861.5088261764], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 489600.0000, 
sim time next is 490200.0000, 
raw observation next is [15.16666666666667, 93.00000000000001, 1.0, 2.0, 0.4352546723601938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 472693.6706915818, 472693.6706915821, 106627.3516082489], 
processed observation next is [1.0, 0.6956521739130435, 0.3257575757575759, 0.9300000000000002, 1.0, 1.0, 0.29406834045024216, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17507172988577102, 0.17507172988577113, 0.26006671123963143], 
reward next is 0.7399, 
noisyNet noise sample is [array([-1.5605143], dtype=float32), -0.5905942]. 
=============================================
[2019-03-23 13:34:13,299] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 13:34:13,300] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:34:13,300] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:34:13,300] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:34:13,301] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:34:13,301] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:34:13,302] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:34:13,303] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:34:13,304] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:34:13,303] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:34:13,305] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:34:13,321] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run27
[2019-03-23 13:34:13,345] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run27
[2019-03-23 13:34:13,346] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run27
[2019-03-23 13:34:13,398] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run27
[2019-03-23 13:34:13,427] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run27
[2019-03-23 13:34:23,099] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07953791], dtype=float32), 0.2241757]
[2019-03-23 13:34:23,099] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.76666666666667, 63.00000000000001, 1.0, 2.0, 0.2532260403378899, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 274936.8957688365, 274936.8957688361, 85751.74914282438]
[2019-03-23 13:34:23,100] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:34:23,103] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0177007e-11 1.0000000e+00 2.2117815e-34 6.3829202e-31 4.3079457e-29], sampled 0.29988101604252193
[2019-03-23 13:35:54,128] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 13:35:54,284] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 13:35:54,335] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.3054 1656177539.0774 80.0000
[2019-03-23 13:35:54,464] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 13:35:54,617] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 13:35:55,633] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 650000, evaluation results [650000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9060.305424413044, 1656177539.0773692, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 13:35:55,864] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1856494e-10 1.0000000e+00 8.5785686e-34 1.1783599e-30 9.0946986e-29], sum to 1.0000
[2019-03-23 13:35:55,870] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9983
[2019-03-23 13:35:55,877] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2107807120946072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 228853.9248712476, 228853.9248712476, 76264.21599061953], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 524400.0000, 
sim time next is 525000.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2108458308189523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 228924.6437833068, 228924.6437833065, 76265.45896963263], 
processed observation next is [1.0, 0.043478260869565216, 0.2727272727272727, 0.94, 1.0, 1.0, 0.01355728852369037, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08478690510492844, 0.08478690510492834, 0.18601331456007958], 
reward next is 0.8140, 
noisyNet noise sample is [array([-0.14971168], dtype=float32), 1.2800593]. 
=============================================
[2019-03-23 13:35:55,906] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[81.36374 ]
 [80.95508 ]
 [80.502075]
 [80.15048 ]
 [79.83768 ]], R is [[81.72176361]
 [81.71853638]
 [81.71520996]
 [81.71181488]
 [81.70843506]].
[2019-03-23 13:36:02,918] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.6070425e-08 1.0000000e+00 6.1179319e-26 9.8322064e-23 1.0168102e-22], sum to 1.0000
[2019-03-23 13:36:02,928] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8774
[2019-03-23 13:36:02,931] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333333, 49.33333333333333, 1.0, 2.0, 0.3570670266541407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 400628.2014294617, 400628.2014294617, 120200.3128425167], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 668400.0000, 
sim time next is 669000.0000, 
raw observation next is [25.16666666666667, 49.66666666666667, 1.0, 2.0, 0.3557345737944984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 398734.2405109353, 398734.240510935, 119896.6321566705], 
processed observation next is [1.0, 0.7391304347826086, 0.7803030303030305, 0.4966666666666667, 1.0, 1.0, 0.194668217243123, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14767934833738344, 0.14767934833738333, 0.29243081013822075], 
reward next is 0.7076, 
noisyNet noise sample is [array([0.5610789], dtype=float32), 0.026124377]. 
=============================================
[2019-03-23 13:36:02,950] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[59.317535]
 [59.119152]
 [59.040913]
 [58.521046]
 [57.478794]], R is [[59.48783112]
 [59.59978104]
 [59.71022034]
 [59.81488037]
 [59.87726212]].
[2019-03-23 13:36:04,629] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.0056640e-10 1.0000000e+00 6.8961015e-33 2.9440238e-29 1.7331220e-27], sum to 1.0000
[2019-03-23 13:36:04,642] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3140
[2019-03-23 13:36:04,646] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3333330801523554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 367016.7922733523, 367016.7922733523, 115277.9347688607], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 694800.0000, 
sim time next is 695400.0000, 
raw observation next is [17.83333333333333, 89.00000000000001, 1.0, 2.0, 0.3312722588496904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 364391.1046602378, 364391.1046602378, 114991.4136295862], 
processed observation next is [1.0, 0.043478260869565216, 0.44696969696969674, 0.8900000000000001, 1.0, 1.0, 0.164090323562113, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13495966839268067, 0.13495966839268067, 0.28046686251118585], 
reward next is 0.7195, 
noisyNet noise sample is [array([-0.4619432], dtype=float32), 2.2966356]. 
=============================================
[2019-03-23 13:36:10,759] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.0577520e-09 1.0000000e+00 5.6251758e-24 2.7020614e-22 1.1278756e-20], sum to 1.0000
[2019-03-23 13:36:10,767] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7087
[2019-03-23 13:36:10,772] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 66.0, 1.0, 2.0, 0.6192068542674781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 695835.938683066, 695835.938683066, 161602.1368190172], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 820800.0000, 
sim time next is 821400.0000, 
raw observation next is [29.0, 64.66666666666667, 1.0, 2.0, 0.615723996910011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 691919.2786708378, 691919.2786708378, 161104.503073487], 
processed observation next is [0.0, 0.5217391304347826, 0.9545454545454546, 0.6466666666666667, 1.0, 1.0, 0.5196549961375138, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2562663995077177, 0.2562663995077177, 0.39293781237435854], 
reward next is 0.6071, 
noisyNet noise sample is [array([0.6425873], dtype=float32), -0.76914346]. 
=============================================
[2019-03-23 13:36:13,010] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.0571671e-09 1.0000000e+00 2.6766140e-26 1.8442613e-24 3.0525522e-23], sum to 1.0000
[2019-03-23 13:36:13,018] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0293
[2019-03-23 13:36:13,024] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.3973816380588974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 447967.610409422, 447967.610409422, 124703.2344385727], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 867600.0000, 
sim time next is 868200.0000, 
raw observation next is [19.16666666666667, 93.00000000000001, 1.0, 2.0, 0.3964403217125555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 446931.3163672245, 446931.3163672248, 124632.4948233106], 
processed observation next is [0.0, 0.043478260869565216, 0.5075757575757578, 0.9300000000000002, 1.0, 1.0, 0.24555040214069435, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1655301171730461, 0.16553011717304622, 0.30398169469100145], 
reward next is 0.6960, 
noisyNet noise sample is [array([-0.6282194], dtype=float32), 1.1093026]. 
=============================================
[2019-03-23 13:36:19,831] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.9794902e-09 1.0000000e+00 4.2708214e-28 1.3736358e-26 1.0144420e-24], sum to 1.0000
[2019-03-23 13:36:19,839] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4627
[2019-03-23 13:36:19,845] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 100.0, 1.0, 2.0, 0.5599322728657555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 626050.1418875958, 626050.1418875958, 138679.8344521419], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 984600.0000, 
sim time next is 985200.0000, 
raw observation next is [17.33333333333333, 100.0, 1.0, 2.0, 0.5880247163361135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 656055.1291068787, 656055.1291068789, 141164.812588375], 
processed observation next is [1.0, 0.391304347826087, 0.42424242424242403, 1.0, 1.0, 1.0, 0.4850308954201419, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2429833811506958, 0.24298338115069587, 0.3443044209472561], 
reward next is 0.6557, 
noisyNet noise sample is [array([1.0164626], dtype=float32), 0.16144931]. 
=============================================
[2019-03-23 13:36:20,215] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.7213211e-08 1.0000000e+00 2.5526986e-26 1.7713736e-21 8.8401374e-22], sum to 1.0000
[2019-03-23 13:36:20,224] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9921
[2019-03-23 13:36:20,228] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.5036252554055104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 565907.0695655649, 565907.0695655649, 134095.4127311291], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 981600.0000, 
sim time next is 982200.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.5046118292581742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 567033.9741632368, 567033.9741632368, 134204.9451437585], 
processed observation next is [1.0, 0.34782608695652173, 0.45454545454545453, 1.0, 1.0, 1.0, 0.3807647865727177, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21001258302342105, 0.21001258302342105, 0.32732913449697193], 
reward next is 0.6727, 
noisyNet noise sample is [array([0.6719613], dtype=float32), 1.5777758]. 
=============================================
[2019-03-23 13:36:23,969] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.4970328e-09 1.0000000e+00 2.6021440e-25 2.9116087e-24 3.1376282e-22], sum to 1.0000
[2019-03-23 13:36:23,975] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5521
[2019-03-23 13:36:23,979] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 77.0, 1.0, 2.0, 0.220358227092284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 239255.2132937979, 239255.2132937982, 77886.35148916821], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1065600.0000, 
sim time next is 1066200.0000, 
raw observation next is [16.16666666666667, 77.0, 1.0, 2.0, 0.2306061945464989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 250384.8669196476, 250384.8669196473, 79628.73743202905], 
processed observation next is [1.0, 0.34782608695652173, 0.37121212121212144, 0.77, 1.0, 1.0, 0.038257743183123596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09273513589616578, 0.09273513589616567, 0.19421643276104647], 
reward next is 0.8058, 
noisyNet noise sample is [array([-1.9267782], dtype=float32), 1.9986931]. 
=============================================
[2019-03-23 13:36:25,775] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.198023e-11 1.000000e+00 9.833489e-29 5.001009e-27 8.169227e-26], sum to 1.0000
[2019-03-23 13:36:25,783] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6701
[2019-03-23 13:36:25,788] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666666, 66.33333333333333, 1.0, 2.0, 0.7613524343180025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 859288.528905357, 859288.528905357, 166633.5796993516], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1093200.0000, 
sim time next is 1093800.0000, 
raw observation next is [22.83333333333334, 65.66666666666667, 1.0, 2.0, 0.7826781492953276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 883919.1456624361, 883919.1456624361, 169920.2923560732], 
processed observation next is [1.0, 0.6521739130434783, 0.6742424242424245, 0.6566666666666667, 1.0, 1.0, 0.7283476866191596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.32737746135645784, 0.32737746135645784, 0.41443973745383705], 
reward next is 0.5856, 
noisyNet noise sample is [array([0.95270973], dtype=float32), 0.08757885]. 
=============================================
[2019-03-23 13:36:37,629] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.3463592e-09 1.0000000e+00 1.7612916e-23 1.1046516e-21 1.8992623e-20], sum to 1.0000
[2019-03-23 13:36:37,642] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7685
[2019-03-23 13:36:37,650] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.8950367762259857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1019755.038980954, 1019755.038980954, 201633.7315811075], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1328400.0000, 
sim time next is 1329000.0000, 
raw observation next is [23.16666666666667, 89.0, 1.0, 2.0, 0.9977833120494295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 8.002941514123458, 6.9112, 81.64417062235076, 1510807.082062596, 1136442.89415328, 222935.1775193469], 
processed observation next is [1.0, 0.391304347826087, 0.6893939393939396, 0.89, 1.0, 1.0, 0.9972291400617869, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.10917415141234584, 0.0, 0.5368042620130496, 0.5595581785417022, 0.4209047756123259, 0.5437443354130412], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.3717776], dtype=float32), -1.1452066]. 
=============================================
[2019-03-23 13:36:37,668] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[55.55458 ]
 [55.983643]
 [56.148582]
 [56.46522 ]
 [57.433075]], R is [[53.77394485]
 [53.74441528]
 [53.74921417]
 [53.74692917]
 [53.7254715 ]].
[2019-03-23 13:36:37,964] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.8938119e-11 1.0000000e+00 2.8969232e-28 4.5370383e-25 1.9072457e-23], sum to 1.0000
[2019-03-23 13:36:37,972] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1314
[2019-03-23 13:36:37,983] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 94.0, 1.0, 2.0, 0.4680682329977731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 534050.0855259651, 534050.0855259651, 136874.7935010906], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1323600.0000, 
sim time next is 1324200.0000, 
raw observation next is [21.66666666666667, 94.0, 1.0, 2.0, 0.4818867638886157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 549861.515477282, 549861.515477282, 139127.0786484237], 
processed observation next is [1.0, 0.30434782608695654, 0.6212121212121214, 0.94, 1.0, 1.0, 0.35235845486076955, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20365241313973406, 0.20365241313973406, 0.3393343381668871], 
reward next is 0.6607, 
noisyNet noise sample is [array([-1.3021469], dtype=float32), -1.4465595]. 
=============================================
[2019-03-23 13:36:44,369] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 13:36:44,371] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:36:44,372] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:36:44,372] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:36:44,374] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:36:44,374] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:36:44,374] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:36:44,375] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:36:44,375] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:36:44,375] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:36:44,376] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:36:44,391] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run28
[2019-03-23 13:36:44,392] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run28
[2019-03-23 13:36:44,437] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run28
[2019-03-23 13:36:44,437] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run28
[2019-03-23 13:36:44,437] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run28
[2019-03-23 13:36:55,375] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08242328], dtype=float32), 0.23110935]
[2019-03-23 13:36:55,378] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.33333333333334, 92.0, 1.0, 2.0, 0.3982856696525125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 449340.4083661537, 449340.4083661534, 124977.9712152732]
[2019-03-23 13:36:55,378] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:36:55,380] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.4776423e-11 1.0000000e+00 1.2900095e-31 1.4265895e-28 5.7163669e-27], sampled 0.3898560638058982
[2019-03-23 13:36:57,390] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08242328], dtype=float32), 0.23110935]
[2019-03-23 13:36:57,391] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.29202547, 74.23570655333334, 1.0, 2.0, 0.3655614193939046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 410099.1633466415, 410099.1633466412, 125202.6831679908]
[2019-03-23 13:36:57,391] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:36:57,394] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.3414728e-11 1.0000000e+00 9.8376388e-32 1.1171148e-28 4.5367221e-27], sampled 0.2066354621518891
[2019-03-23 13:37:08,807] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08242328], dtype=float32), 0.23110935]
[2019-03-23 13:37:08,808] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.5, 79.5, 1.0, 2.0, 0.2209845726715709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 239935.4393480825, 239935.4393480825, 77150.14854885206]
[2019-03-23 13:37:08,809] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:37:08,812] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.5750959e-11 1.0000000e+00 5.4173445e-30 4.1514264e-27 1.3793232e-25], sampled 0.334471869862051
[2019-03-23 13:37:15,553] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08242328], dtype=float32), 0.23110935]
[2019-03-23 13:37:15,556] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [28.939079, 68.4121461, 1.0, 2.0, 0.6089097937031304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 684164.5729274894, 684164.5729274891, 164456.2003055053]
[2019-03-23 13:37:15,558] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:37:15,561] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0939785e-11 1.0000000e+00 5.5345642e-32 6.6503727e-29 2.7802547e-27], sampled 0.7069578946937863
[2019-03-23 13:37:40,695] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08242328], dtype=float32), 0.23110935]
[2019-03-23 13:37:40,697] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.4, 89.5, 1.0, 2.0, 0.7120628089153184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695, 802981.1539006263, 802981.1539006263, 163990.2638313063]
[2019-03-23 13:37:40,698] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:37:40,701] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.2256414e-11 1.0000000e+00 4.0893333e-31 4.0411268e-28 1.5278487e-26], sampled 0.9860099649344004
[2019-03-23 13:37:58,282] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08242328], dtype=float32), 0.23110935]
[2019-03-23 13:37:58,284] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.16666666666667, 84.0, 1.0, 2.0, 0.3527722152593181, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 392532.8357390848, 392532.8357390844, 122678.827989935]
[2019-03-23 13:37:58,286] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:37:58,290] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.21501646e-11 1.00000000e+00 7.44319555e-32 8.68623715e-29
 3.57747034e-27], sampled 0.04585778561930265
[2019-03-23 13:37:58,584] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08242328], dtype=float32), 0.23110935]
[2019-03-23 13:37:58,588] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.56666666666667, 68.33333333333334, 1.0, 2.0, 0.7219387815990786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 815768.2296385738, 815768.2296385741, 161809.7752751512]
[2019-03-23 13:37:58,590] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:37:58,593] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.0344381e-11 1.0000000e+00 2.1832011e-30 1.8305417e-27 6.3609386e-26], sampled 0.6862045736045457
[2019-03-23 13:38:22,928] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08242328], dtype=float32), 0.23110935]
[2019-03-23 13:38:22,929] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.254913515, 52.4936289, 1.0, 2.0, 0.4402205906265536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 480182.7792851024, 480182.7792851021, 126681.6229460608]
[2019-03-23 13:38:22,931] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:38:22,934] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.7517907e-11 1.0000000e+00 2.0843290e-31 2.1995040e-28 8.6017670e-27], sampled 0.5534722445898459
[2019-03-23 13:38:25,812] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 13:38:25,838] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 13:38:25,843] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 13:38:25,933] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 13:38:26,039] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08242328], dtype=float32), 0.23110935]
[2019-03-23 13:38:26,039] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.4, 66.66666666666667, 1.0, 2.0, 0.248829352992194, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 270162.1765404897, 270162.1765404897, 85913.91166726226]
[2019-03-23 13:38:26,039] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:38:26,041] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.4980211e-11 1.0000000e+00 5.6648427e-31 5.4183006e-28 2.0150185e-26], sampled 0.28381945056375657
[2019-03-23 13:38:26,087] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 13:38:27,105] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 675000, evaluation results [675000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 13:38:29,692] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.4561989e-13 1.0000000e+00 2.3925408e-31 5.9817920e-28 1.0602610e-27], sum to 1.0000
[2019-03-23 13:38:29,698] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5537
[2019-03-23 13:38:29,702] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 83.83333333333334, 1.0, 2.0, 0.4776504385134514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 545032.6024650712, 545032.6024650712, 138577.967945097], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1541400.0000, 
sim time next is 1542000.0000, 
raw observation next is [22.66666666666667, 84.66666666666667, 1.0, 2.0, 0.4749039389591958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 541903.8384703465, 541903.8384703465, 138156.8234364557], 
processed observation next is [0.0, 0.8695652173913043, 0.6666666666666669, 0.8466666666666667, 1.0, 1.0, 0.3436299236989947, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20070512535938762, 0.20070512535938762, 0.3369678620401359], 
reward next is 0.6630, 
noisyNet noise sample is [array([1.5660381], dtype=float32), -0.18110949]. 
=============================================
[2019-03-23 13:38:29,714] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[71.99692 ]
 [72.016624]
 [72.0037  ]
 [71.99917 ]
 [71.98603 ]], R is [[71.92832947]
 [71.87104797]
 [71.81273651]
 [71.7522049 ]
 [71.68938446]].
[2019-03-23 13:38:33,420] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.9272502e-09 1.0000000e+00 8.6975569e-26 6.3939827e-24 3.8872150e-22], sum to 1.0000
[2019-03-23 13:38:33,425] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1969
[2019-03-23 13:38:33,429] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666666, 71.0, 1.0, 2.0, 0.8442142220339058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 963701.8623406739, 963701.8623406739, 189690.7163202611], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1596000.0000, 
sim time next is 1596600.0000, 
raw observation next is [25.0, 69.5, 1.0, 2.0, 0.8663203452967513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 988902.8097258199, 988902.8097258199, 193731.091132876], 
processed observation next is [1.0, 0.4782608695652174, 0.7727272727272727, 0.695, 1.0, 1.0, 0.832900431620939, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3662602998984518, 0.3662602998984518, 0.47251485642164875], 
reward next is 0.5275, 
noisyNet noise sample is [array([0.6591787], dtype=float32), -1.0484289]. 
=============================================
[2019-03-23 13:38:42,071] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1022726e-07 9.9999988e-01 1.9836234e-22 2.5059120e-20 4.9527873e-19], sum to 1.0000
[2019-03-23 13:38:42,078] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9546
[2019-03-23 13:38:42,083] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [8.0, 81.0, 1.0, 2.0, 0.3281546996286083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 356338.7322330874, 356338.7322330874, 77130.67492289764], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1741800.0000, 
sim time next is 1742400.0000, 
raw observation next is [8.0, 81.0, 1.0, 2.0, 0.327643404959841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 355783.3211844948, 355783.3211844945, 77085.15477209113], 
processed observation next is [1.0, 0.17391304347826086, 0.0, 0.81, 1.0, 1.0, 0.15955425619980124, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13177160043870179, 0.13177160043870165, 0.18801257261485643], 
reward next is 0.8120, 
noisyNet noise sample is [array([-0.64589983], dtype=float32), -2.1498685]. 
=============================================
[2019-03-23 13:38:44,974] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.0222368e-12 1.0000000e+00 1.3924848e-36 1.0916046e-33 1.5607159e-30], sum to 1.0000
[2019-03-23 13:38:44,982] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7718
[2019-03-23 13:38:44,988] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 52.0, 1.0, 2.0, 0.2290423910530957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 248686.504776765, 248686.5047767647, 73072.92126964727], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1800600.0000, 
sim time next is 1801200.0000, 
raw observation next is [17.0, 52.0, 1.0, 2.0, 0.2283013367745916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 247881.6879957156, 247881.6879957153, 72998.06089183108], 
processed observation next is [1.0, 0.8695652173913043, 0.4090909090909091, 0.52, 1.0, 1.0, 0.035376670968239494, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09180803259100577, 0.09180803259100567, 0.17804405095568554], 
reward next is 0.8220, 
noisyNet noise sample is [array([-0.2589013], dtype=float32), -0.6127552]. 
=============================================
[2019-03-23 13:38:45,620] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.25650379e-12 1.00000000e+00 1.02084546e-35 7.07619952e-31
 2.36207273e-29], sum to 1.0000
[2019-03-23 13:38:45,627] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6263
[2019-03-23 13:38:45,629] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.5, 75.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 202659.2795356423, 202659.279535642, 67288.42817367405], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1818600.0000, 
sim time next is 1819200.0000, 
raw observation next is [13.0, 79.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 196996.0891428303, 196996.0891428306, 66234.99349866474], 
processed observation next is [1.0, 0.043478260869565216, 0.22727272727272727, 0.7933333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07296151449734455, 0.07296151449734467, 0.1615487646308896], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.07646434], dtype=float32), 1.3738841]. 
=============================================
[2019-03-23 13:38:49,591] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.4489256e-13 1.0000000e+00 3.2811008e-30 1.1473743e-26 1.2956053e-26], sum to 1.0000
[2019-03-23 13:38:49,601] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0228
[2019-03-23 13:38:49,607] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 64.0, 1.0, 2.0, 0.2593609231746895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 281614.8749869078, 281614.874986908, 90054.53162816586], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1897200.0000, 
sim time next is 1897800.0000, 
raw observation next is [18.83333333333334, 64.66666666666667, 1.0, 2.0, 0.2570849669210487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 279142.9256065435, 279142.9256065438, 89191.36402453973], 
processed observation next is [1.0, 1.0, 0.4924242424242427, 0.6466666666666667, 1.0, 1.0, 0.07135620865131087, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10338626874316426, 0.10338626874316437, 0.21753991225497493], 
reward next is 0.7825, 
noisyNet noise sample is [array([-0.7160878], dtype=float32), 0.14813541]. 
=============================================
[2019-03-23 13:38:52,490] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.5337546e-08 9.9999988e-01 4.2695489e-21 1.1617183e-19 8.2776096e-18], sum to 1.0000
[2019-03-23 13:38:52,501] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7072
[2019-03-23 13:38:52,505] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 92.0, 1.0, 2.0, 0.6679082081652064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 760668.8413801303, 760668.8413801306, 159026.1215569436], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1930800.0000, 
sim time next is 1931400.0000, 
raw observation next is [21.0, 91.0, 1.0, 2.0, 0.7907212507568819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 901537.3552347525, 901537.3552347528, 177641.6208388781], 
processed observation next is [1.0, 0.34782608695652173, 0.5909090909090909, 0.91, 1.0, 1.0, 0.7384015634461024, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.33390272416101946, 0.3339027241610195, 0.4332722459484832], 
reward next is 0.5667, 
noisyNet noise sample is [array([1.6676236], dtype=float32), -0.57327795]. 
=============================================
[2019-03-23 13:38:52,512] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.8118910e-09 1.0000000e+00 1.3760578e-20 1.0678034e-18 5.8489432e-17], sum to 1.0000
[2019-03-23 13:38:52,520] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1430
[2019-03-23 13:38:52,526] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1225509.452332563 W.
[2019-03-23 13:38:52,530] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.66666666666667, 61.0, 1.0, 2.0, 0.5373457061295837, 1.0, 2.0, 0.5373457061295837, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1225509.452332563, 1225509.452332563, 238102.7888349659], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1952400.0000, 
sim time next is 1953000.0000, 
raw observation next is [25.5, 61.0, 1.0, 2.0, 0.5438811115921508, 1.0, 2.0, 0.5438811115921508, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1241104.9861726, 1241104.9861726, 238916.6333957246], 
processed observation next is [1.0, 0.6086956521739131, 0.7954545454545454, 0.61, 1.0, 1.0, 0.4298513894901885, 1.0, 1.0, 0.4298513894901885, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4596685133972592, 0.4596685133972592, 0.5827234960871331], 
reward next is 0.4173, 
noisyNet noise sample is [array([0.1796898], dtype=float32), 1.7126658]. 
=============================================
[2019-03-23 13:38:52,567] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[45.763412]
 [45.399345]
 [45.357536]
 [44.528584]
 [43.30182 ]], R is [[46.36140823]
 [45.89779282]
 [45.73797226]
 [45.71421814]
 [45.69615173]].
[2019-03-23 13:38:54,381] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.1493846e-10 1.0000000e+00 4.7035927e-26 1.1863654e-23 6.5499361e-23], sum to 1.0000
[2019-03-23 13:38:54,387] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2340
[2019-03-23 13:38:54,392] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.83333333333334, 72.83333333333333, 1.0, 2.0, 0.2351865426011889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 255359.368596598, 255359.3685965977, 80929.83126706378], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2005800.0000, 
sim time next is 2006400.0000, 
raw observation next is [16.66666666666667, 73.66666666666667, 1.0, 2.0, 0.2335806288718284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 253615.2550546222, 253615.2550546222, 80463.39699358797], 
processed observation next is [0.0, 0.21739130434782608, 0.39393939393939414, 0.7366666666666667, 1.0, 1.0, 0.041975786089785486, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09393157594615636, 0.09393157594615636, 0.19625218778923895], 
reward next is 0.8037, 
noisyNet noise sample is [array([0.71843606], dtype=float32), 0.62277824]. 
=============================================
[2019-03-23 13:39:00,703] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6427621e-09 1.0000000e+00 3.1590203e-28 4.6220780e-25 7.8052225e-25], sum to 1.0000
[2019-03-23 13:39:00,717] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1363
[2019-03-23 13:39:00,721] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 85.5, 1.0, 2.0, 0.222873740940286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 241987.1263540169, 241987.1263540171, 77988.4195812844], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2097000.0000, 
sim time next is 2097600.0000, 
raw observation next is [15.33333333333333, 82.66666666666666, 1.0, 2.0, 0.2244963918065948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 243749.3752787963, 243749.375278796, 78251.42679656901], 
processed observation next is [0.0, 0.2608695652173913, 0.3333333333333332, 0.8266666666666665, 1.0, 1.0, 0.030620489758243497, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09027754639955418, 0.09027754639955408, 0.1908571385282171], 
reward next is 0.8091, 
noisyNet noise sample is [array([0.06143289], dtype=float32), 0.10397231]. 
=============================================
[2019-03-23 13:39:01,178] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.01730527e-10 1.00000000e+00 7.66983248e-33 5.87063530e-29
 1.21600405e-26], sum to 1.0000
[2019-03-23 13:39:01,185] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2205
[2019-03-23 13:39:01,190] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 62.66666666666667, 1.0, 2.0, 0.2868568654603892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 311479.6129591942, 311479.6129591945, 108713.1944859344], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2104800.0000, 
sim time next is 2105400.0000, 
raw observation next is [20.66666666666666, 61.33333333333333, 1.0, 2.0, 0.2904082093815906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 315337.0415129002, 315337.0415128999, 110554.6060292125], 
processed observation next is [0.0, 0.34782608695652173, 0.5757575757575755, 0.6133333333333333, 1.0, 1.0, 0.11301026172698826, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1167914968566297, 0.1167914968566296, 0.2696453805590549], 
reward next is 0.7304, 
noisyNet noise sample is [array([0.25187698], dtype=float32), 1.2037742]. 
=============================================
[2019-03-23 13:39:02,550] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.8007662e-09 1.0000000e+00 4.5609309e-26 3.6385549e-25 9.6499455e-23], sum to 1.0000
[2019-03-23 13:39:02,558] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4934
[2019-03-23 13:39:02,567] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 61.0, 1.0, 2.0, 0.3988906456970279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 451082.0221729327, 451082.0221729327, 125645.8371203192], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2142000.0000, 
sim time next is 2142600.0000, 
raw observation next is [23.83333333333333, 62.33333333333334, 1.0, 2.0, 0.398721207694917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 450936.0906935387, 450936.090693539, 125658.5232557976], 
processed observation next is [0.0, 0.8260869565217391, 0.7196969696969695, 0.6233333333333334, 1.0, 1.0, 0.2484015096186462, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16701336692353286, 0.16701336692353297, 0.30648420306292096], 
reward next is 0.6935, 
noisyNet noise sample is [array([-0.13610528], dtype=float32), 1.1332902]. 
=============================================
[2019-03-23 13:39:11,958] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.0297566e-12 1.0000000e+00 1.1987206e-31 4.8159545e-29 1.0136518e-26], sum to 1.0000
[2019-03-23 13:39:11,970] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2211
[2019-03-23 13:39:11,980] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 53.0, 1.0, 2.0, 0.2444031808823973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 265369.2823202015, 265369.2823202018, 75932.75364031013], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2319600.0000, 
sim time next is 2320200.0000, 
raw observation next is [17.5, 53.5, 1.0, 2.0, 0.2425322856159216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 263337.3425577041, 263337.3425577038, 75565.2440867795], 
processed observation next is [1.0, 0.8695652173913043, 0.4318181818181818, 0.535, 1.0, 1.0, 0.05316535701990199, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09753234909544596, 0.09753234909544585, 0.184305473382389], 
reward next is 0.8157, 
noisyNet noise sample is [array([-0.14473234], dtype=float32), -0.11046368]. 
=============================================
[2019-03-23 13:39:16,084] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 13:39:16,085] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:39:16,086] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:39:16,086] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:39:16,087] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:39:16,088] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:39:16,088] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:39:16,088] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:39:16,090] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:39:16,090] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:39:16,093] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:39:16,106] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run29
[2019-03-23 13:39:16,130] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run29
[2019-03-23 13:39:16,131] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run29
[2019-03-23 13:39:16,184] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run29
[2019-03-23 13:39:16,212] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run29
[2019-03-23 13:39:18,319] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08242328], dtype=float32), 0.23841436]
[2019-03-23 13:39:18,320] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [11.489182475, 91.07831411833334, 1.0, 2.0, 0.3096381560279758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 336202.7513687795, 336202.7513687795, 83837.48481444076]
[2019-03-23 13:39:18,321] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:39:18,324] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.7449712e-11 1.0000000e+00 2.0079761e-32 1.7001824e-29 2.3838728e-27], sampled 0.1749387177577556
[2019-03-23 13:39:18,667] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08242328], dtype=float32), 0.23841436]
[2019-03-23 13:39:18,671] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.56666666666667, 36.0, 1.0, 2.0, 0.3519755670185385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 382187.0072650889, 382187.0072650886, 93116.69019602824]
[2019-03-23 13:39:18,673] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:39:18,675] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.0410071e-12 1.0000000e+00 2.1080919e-33 2.1931008e-30 3.5727089e-28], sampled 0.3075896752812689
[2019-03-23 13:39:42,456] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08242328], dtype=float32), 0.23841436]
[2019-03-23 13:39:42,456] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.0, 49.0, 1.0, 2.0, 0.4134712509379764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 449025.594929533, 449025.5949295327, 98349.02047922277]
[2019-03-23 13:39:42,458] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:39:42,460] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.1302303e-11 1.0000000e+00 5.6737468e-33 5.3917383e-30 8.2223371e-28], sampled 0.7639654588483804
[2019-03-23 13:39:45,366] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08242328], dtype=float32), 0.23841436]
[2019-03-23 13:39:45,367] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.30879603, 53.21410102, 1.0, 2.0, 0.3310835708032748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 359494.9839276885, 359494.9839276882, 107985.2811774763]
[2019-03-23 13:39:45,368] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:39:45,371] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.6508136e-12 1.0000000e+00 2.1200504e-34 2.7208843e-31 5.1651094e-29], sampled 0.35987946630828105
[2019-03-23 13:40:03,017] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08242328], dtype=float32), 0.23841436]
[2019-03-23 13:40:03,018] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.16666666666666, 81.33333333333334, 1.0, 2.0, 0.268146327420212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 291156.9489101655, 291156.9489101658, 95777.29397225968]
[2019-03-23 13:40:03,019] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:40:03,025] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.1787601e-11 1.0000000e+00 6.4175835e-33 6.0288856e-30 9.1216308e-28], sampled 0.3665049150003059
[2019-03-23 13:40:36,243] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08242328], dtype=float32), 0.23841436]
[2019-03-23 13:40:36,245] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.55, 78.5, 1.0, 2.0, 0.2537551266518845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 275511.476047144, 275511.4760471436, 89867.54878872154]
[2019-03-23 13:40:36,249] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:40:36,252] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.0754730e-12 1.0000000e+00 2.9997481e-33 3.0209857e-30 4.8082286e-28], sampled 0.4245514697834232
[2019-03-23 13:40:49,572] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08242328], dtype=float32), 0.23841436]
[2019-03-23 13:40:49,573] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.510572665, 84.52825591000001, 1.0, 2.0, 0.3514590130844674, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 388436.6489448725, 388436.6489448722, 121509.119777716]
[2019-03-23 13:40:49,574] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:40:49,578] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.0982862e-12 1.0000000e+00 4.2336118e-35 6.2959325e-32 1.3306251e-29], sampled 0.8463114495838596
[2019-03-23 13:40:51,995] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08242328], dtype=float32), 0.23841436]
[2019-03-23 13:40:51,997] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.51666666666667, 51.66666666666667, 1.0, 2.0, 0.2608128796054707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 283176.148794286, 283176.1487942856, 86662.8926906419]
[2019-03-23 13:40:51,997] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:40:52,000] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.3033081e-12 1.0000000e+00 6.2837850e-34 7.2989289e-31 1.2889145e-28], sampled 0.5418647381800593
[2019-03-23 13:40:57,373] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 13:40:57,714] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 13:40:57,857] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9513 1705935940.2592 465.0000
[2019-03-23 13:40:57,910] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 13:40:57,917] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 13:40:58,934] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 700000, evaluation results [700000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.951295847348, 1705935940.259201, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 13:41:01,004] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0080701e-11 1.0000000e+00 3.6357143e-38 9.7073357e-35 1.4181285e-31], sum to 1.0000
[2019-03-23 13:41:01,012] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9107
[2019-03-23 13:41:01,016] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 88.0, 1.0, 2.0, 0.2311675828366291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 250994.5617346748, 250994.5617346748, 80073.8855185253], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2444400.0000, 
sim time next is 2445000.0000, 
raw observation next is [15.0, 88.00000000000001, 1.0, 2.0, 0.2494616238217112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 270863.1926702723, 270863.1926702723, 81933.81684688859], 
processed observation next is [1.0, 0.30434782608695654, 0.3181818181818182, 0.8800000000000001, 1.0, 1.0, 0.06182702977713898, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10031970098898975, 0.10031970098898975, 0.19983857767533802], 
reward next is 0.8002, 
noisyNet noise sample is [array([-0.06586923], dtype=float32), -0.06712809]. 
=============================================
[2019-03-23 13:41:01,041] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[86.95938 ]
 [86.951324]
 [86.939316]
 [86.94245 ]
 [86.95146 ]], R is [[86.86891174]
 [86.80491638]
 [86.74286652]
 [86.68241119]
 [86.62361908]].
[2019-03-23 13:41:02,430] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.4031470e-10 1.0000000e+00 5.6658799e-31 7.3894904e-27 9.0476171e-26], sum to 1.0000
[2019-03-23 13:41:02,440] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8724
[2019-03-23 13:41:02,448] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.13333333333333, 62.66666666666667, 1.0, 2.0, 0.7578351155775438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 834892.196809725, 834892.196809725, 157618.6981307499], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2478000.0000, 
sim time next is 2478600.0000, 
raw observation next is [21.1, 62.0, 1.0, 2.0, 0.7750995563830971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 852048.0049246709, 852048.0049246709, 159149.7442285513], 
processed observation next is [1.0, 0.6956521739130435, 0.5954545454545456, 0.62, 1.0, 1.0, 0.7188744454788715, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.31557333515728553, 0.31557333515728553, 0.3881701078745154], 
reward next is 0.6118, 
noisyNet noise sample is [array([1.9549209], dtype=float32), 0.6118181]. 
=============================================
[2019-03-23 13:41:15,090] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.3485188e-13 1.0000000e+00 1.3654444e-33 1.7690897e-30 5.3911034e-29], sum to 1.0000
[2019-03-23 13:41:15,098] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9156
[2019-03-23 13:41:15,103] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 65.0, 1.0, 2.0, 0.4525061189077412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 515993.2660426897, 515993.2660426894, 134425.0434321327], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2732400.0000, 
sim time next is 2733000.0000, 
raw observation next is [25.16666666666667, 64.33333333333334, 1.0, 2.0, 0.4511863057931239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 514496.9480359228, 514496.9480359231, 134303.6126198515], 
processed observation next is [0.0, 0.6521739130434783, 0.7803030303030305, 0.6433333333333334, 1.0, 1.0, 0.31398288224140486, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19055442519848992, 0.19055442519849006, 0.3275697868776866], 
reward next is 0.6724, 
noisyNet noise sample is [array([1.0543447], dtype=float32), 1.3195212]. 
=============================================
[2019-03-23 13:41:15,141] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[79.67804 ]
 [79.709564]
 [79.75362 ]
 [79.78656 ]
 [79.81502 ]], R is [[79.49510193]
 [79.37228394]
 [79.24889374]
 [79.12490082]
 [79.00039673]].
[2019-03-23 13:41:26,043] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.7842831e-10 1.0000000e+00 1.8492157e-22 9.3355953e-20 3.1771401e-18], sum to 1.0000
[2019-03-23 13:41:26,050] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9868
[2019-03-23 13:41:26,053] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333333, 87.0, 1.0, 2.0, 0.5265713231073175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 599735.8448234516, 599735.8448234514, 146147.5086131898], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2922000.0000, 
sim time next is 2922600.0000, 
raw observation next is [23.16666666666667, 88.0, 1.0, 2.0, 0.5241531962662066, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 597054.4613144645, 597054.4613144647, 145788.1152929533], 
processed observation next is [1.0, 0.8260869565217391, 0.6893939393939396, 0.88, 1.0, 1.0, 0.4051914953327582, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22113128196832016, 0.22113128196832024, 0.35558076900720315], 
reward next is 0.6444, 
noisyNet noise sample is [array([0.07201066], dtype=float32), -1.1978081]. 
=============================================
[2019-03-23 13:41:26,483] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.9174954e-09 1.0000000e+00 1.7059231e-24 4.0174990e-22 2.0390183e-20], sum to 1.0000
[2019-03-23 13:41:26,491] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6003
[2019-03-23 13:41:26,496] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 96.0, 1.0, 2.0, 0.5157488834248886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 587856.485458057, 587856.485458057, 144393.1992906687], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2928000.0000, 
sim time next is 2928600.0000, 
raw observation next is [22.0, 97.0, 1.0, 2.0, 0.5201459316083114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592630.492742131, 592630.492742131, 145170.5312913271], 
processed observation next is [1.0, 0.9130434782608695, 0.6363636363636364, 0.97, 1.0, 1.0, 0.40018241451038916, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21949277508967815, 0.21949277508967815, 0.35407446656421243], 
reward next is 0.6459, 
noisyNet noise sample is [array([-1.6951935], dtype=float32), -1.1436373]. 
=============================================
[2019-03-23 13:41:29,015] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.6632027e-05 9.9993336e-01 1.8968742e-15 2.6952629e-14 2.3624798e-13], sum to 1.0000
[2019-03-23 13:41:29,021] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9997
[2019-03-23 13:41:29,025] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1330826.874583653 W.
[2019-03-23 13:41:29,029] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.83333333333333, 63.33333333333334, 1.0, 2.0, 0.6883005777174777, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9767883691889501, 6.911199999999999, 6.9112, 77.32846344354104, 1330826.874583653, 1330826.874583654, 289876.8088491818], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2976600.0000, 
sim time next is 2977200.0000, 
raw observation next is [27.0, 62.0, 1.0, 2.0, 0.4018263379636519, 1.0, 1.0, 0.4018263379636519, 1.0, 2.0, 0.8133659588571215, 6.911199999999999, 6.9112, 77.3421103, 1363906.054408779, 1363906.054408779, 304936.5321019666], 
processed observation next is [1.0, 0.4782608695652174, 0.8636363636363636, 0.62, 1.0, 1.0, 0.25228292245456485, 1.0, 0.5, 0.25228292245456485, 1.0, 1.0, 0.7333799412244594, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5051503905217699, 0.5051503905217699, 0.7437476392730893], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1932734], dtype=float32), 0.97172284]. 
=============================================
[2019-03-23 13:41:29,349] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.080210e-07 9.999993e-01 1.281652e-21 2.662172e-19 1.621011e-16], sum to 1.0000
[2019-03-23 13:41:29,353] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2769
[2019-03-23 13:41:29,358] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1296907.447728463 W.
[2019-03-23 13:41:29,361] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.5, 60.0, 1.0, 2.0, 0.6579493812799054, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9758992055320611, 6.9112, 6.9112, 77.32846344354104, 1296907.447728463, 1296907.447728463, 284586.2939236172], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2979000.0000, 
sim time next is 2979600.0000, 
raw observation next is [27.66666666666666, 59.33333333333333, 1.0, 2.0, 0.7847585754045704, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9762645249427649, 6.911199999999999, 6.9112, 77.32846344354104, 1441087.437855214, 1441087.437855215, 304421.0703865595], 
processed observation next is [1.0, 0.4782608695652174, 0.8939393939393937, 0.5933333333333333, 1.0, 1.0, 0.7309482192557128, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9660921784896643, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5337360880945238, 0.5337360880945241, 0.7424904155769745], 
reward next is 0.2575, 
noisyNet noise sample is [array([-0.448577], dtype=float32), 0.7492549]. 
=============================================
[2019-03-23 13:41:30,256] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.567136e-07 9.999993e-01 7.252898e-18 9.015301e-17 7.315907e-14], sum to 1.0000
[2019-03-23 13:41:30,263] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8327
[2019-03-23 13:41:30,273] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 55.0, 1.0, 2.0, 0.467019981964897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 532736.6740528067, 532736.6740528067, 138018.8176771706], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3000600.0000, 
sim time next is 3001200.0000, 
raw observation next is [28.0, 55.0, 1.0, 2.0, 0.4728457215517918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 539394.3627550781, 539394.3627550785, 138651.2932006884], 
processed observation next is [1.0, 0.7391304347826086, 0.9090909090909091, 0.55, 1.0, 1.0, 0.3410571519397397, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1997756899092882, 0.19977568990928832, 0.3381738858553376], 
reward next is 0.6618, 
noisyNet noise sample is [array([-0.12111318], dtype=float32), -1.6565095]. 
=============================================
[2019-03-23 13:41:35,214] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.0881723e-08 1.0000000e+00 9.4205855e-22 1.5220535e-20 7.1389591e-18], sum to 1.0000
[2019-03-23 13:41:35,221] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7550
[2019-03-23 13:41:35,224] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5251920965508002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 598327.8186483674, 598327.8186483678, 145835.5018169904], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3108600.0000, 
sim time next is 3109200.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5242350699461423, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 597237.2710054889, 597237.2710054889, 145718.3528502398], 
processed observation next is [1.0, 1.0, 0.6818181818181818, 0.89, 1.0, 1.0, 0.4052938374326779, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2211989892612922, 0.2211989892612922, 0.35541061670790197], 
reward next is 0.6446, 
noisyNet noise sample is [array([0.6213605], dtype=float32), -1.8145872]. 
=============================================
[2019-03-23 13:41:38,865] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2587917e-07 9.9999988e-01 5.0289434e-18 2.0177504e-17 1.5042194e-14], sum to 1.0000
[2019-03-23 13:41:38,874] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3492
[2019-03-23 13:41:38,882] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1456082.421343959 W.
[2019-03-23 13:41:38,887] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 65.0, 1.0, 2.0, 0.6414106621797262, 1.0, 2.0, 0.6414106621797262, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.3284634435398, 1456082.421343959, 1456082.421343959, 270130.2311558533], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3150000.0000, 
sim time next is 3150600.0000, 
raw observation next is [25.16666666666667, 68.83333333333334, 1.0, 2.0, 0.7390178844507681, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9734465989465573, 6.9112, 6.9112, 77.32846344354104, 1390840.045197968, 1390840.045197968, 294210.9566645795], 
processed observation next is [1.0, 0.4782608695652174, 0.7803030303030305, 0.6883333333333335, 1.0, 1.0, 0.67377235556346, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9620665699236532, 0.0, 0.0, 0.5084288129206541, 0.515125942665914, 0.515125942665914, 0.7175876991819012], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.81813955], dtype=float32), -0.6843627]. 
=============================================
[2019-03-23 13:41:40,818] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.7962865e-10 1.0000000e+00 2.9114280e-26 4.4530386e-24 1.9777982e-22], sum to 1.0000
[2019-03-23 13:41:40,828] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1816
[2019-03-23 13:41:40,832] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 86.33333333333334, 1.0, 2.0, 0.4450955136218914, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 506706.6955425171, 506706.6955425169, 132538.3014786443], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3184800.0000, 
sim time next is 3185400.0000, 
raw observation next is [21.16666666666666, 87.16666666666667, 1.0, 2.0, 0.4433668258906437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 504607.5860928384, 504607.5860928387, 132227.4243100816], 
processed observation next is [1.0, 0.8695652173913043, 0.5984848484848482, 0.8716666666666667, 1.0, 1.0, 0.3042085323633046, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1868916985529031, 0.18689169855290322, 0.32250591295141856], 
reward next is 0.6775, 
noisyNet noise sample is [array([-0.6710339], dtype=float32), -0.71487707]. 
=============================================
[2019-03-23 13:41:45,875] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.1705802e-09 1.0000000e+00 2.3941318e-29 1.6092537e-27 1.4720184e-23], sum to 1.0000
[2019-03-23 13:41:45,881] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6843
[2019-03-23 13:41:45,897] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 68.0, 1.0, 2.0, 0.2809368756313734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 305049.4567211351, 305049.4567211348, 98722.65492052672], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3313800.0000, 
sim time next is 3314400.0000, 
raw observation next is [19.0, 68.0, 1.0, 2.0, 0.2798804969596819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 303902.0515427217, 303902.0515427217, 98616.34232074463], 
processed observation next is [0.0, 0.34782608695652173, 0.5, 0.68, 1.0, 1.0, 0.09985062119960239, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11255631538619322, 0.11255631538619322, 0.24052766419693813], 
reward next is 0.7595, 
noisyNet noise sample is [array([0.7079998], dtype=float32), 1.7271247]. 
=============================================
[2019-03-23 13:41:47,556] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 13:41:47,557] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:41:47,558] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:41:47,558] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:41:47,559] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:41:47,559] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:41:47,559] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:41:47,560] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:41:47,561] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:41:47,563] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:41:47,564] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:41:47,580] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run30
[2019-03-23 13:41:47,605] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run30
[2019-03-23 13:41:47,632] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run30
[2019-03-23 13:41:47,633] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run30
[2019-03-23 13:41:47,633] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run30
[2019-03-23 13:41:54,607] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08242328], dtype=float32), 0.24522373]
[2019-03-23 13:41:54,609] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.977030735, 79.37975765, 1.0, 2.0, 0.2578572914207317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 61.63163626896797, 280002.2855354256, 280002.2855354256, 69936.90747132264]
[2019-03-23 13:41:54,609] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:41:54,613] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.31740571e-09 1.00000000e+00 8.73786219e-26 1.09492994e-23
 2.40855203e-20], sampled 0.962466506824131
[2019-03-23 13:41:59,932] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08242328], dtype=float32), 0.24522373]
[2019-03-23 13:41:59,934] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [29.6, 44.5, 1.0, 2.0, 0.4442965296141477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.5533876967459, 506839.9841401257, 506839.9841401254, 138523.6464202818]
[2019-03-23 13:41:59,935] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:41:59,936] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.1031129e-09 1.0000000e+00 4.5743951e-28 8.8511204e-26 3.8889949e-22], sampled 0.1211646973781505
[2019-03-23 13:42:00,547] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08242328], dtype=float32), 0.24522373]
[2019-03-23 13:42:00,549] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.63864428333333, 72.86632960333334, 1.0, 2.0, 0.2490630183165705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 270415.9317051342, 270415.9317051339, 86046.78180302352]
[2019-03-23 13:42:00,550] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:42:00,551] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.2006566e-09 1.0000000e+00 1.1291895e-26 1.6761791e-24 4.8273780e-21], sampled 0.3226397194127004
[2019-03-23 13:42:06,354] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08242328], dtype=float32), 0.24522373]
[2019-03-23 13:42:06,354] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.13333333333333, 78.0, 1.0, 2.0, 0.3199798980205572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 347434.9819009081, 347434.9819009077, 114598.7571591827]
[2019-03-23 13:42:06,355] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:42:06,358] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.1298071e-09 1.0000000e+00 1.0559306e-26 1.5762232e-24 4.5794399e-21], sampled 0.8853841911345085
[2019-03-23 13:43:29,237] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 13:43:29,558] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 13:43:29,619] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 13:43:29,657] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 13:43:29,725] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 13:43:30,741] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 725000, evaluation results [725000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 13:43:31,022] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.5767370e-10 1.0000000e+00 3.5000191e-32 1.9611128e-29 4.4546167e-25], sum to 1.0000
[2019-03-23 13:43:31,034] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1890
[2019-03-23 13:43:31,047] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 60.33333333333334, 1.0, 2.0, 0.3682270623755156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 412727.0036836132, 412727.0036836132, 120929.0861894918], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3351000.0000, 
sim time next is 3351600.0000, 
raw observation next is [23.0, 61.0, 1.0, 2.0, 0.3671877261213584, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 411324.5723782057, 411324.5723782057, 120730.0184434245], 
processed observation next is [0.0, 0.8260869565217391, 0.6818181818181818, 0.61, 1.0, 1.0, 0.208984657651698, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15234243421415025, 0.15234243421415025, 0.29446345961810855], 
reward next is 0.7055, 
noisyNet noise sample is [array([-0.5705505], dtype=float32), -1.2075685]. 
=============================================
[2019-03-23 13:43:38,545] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2233487e-06 9.9999881e-01 1.3957286e-19 2.5031412e-18 1.6948558e-16], sum to 1.0000
[2019-03-23 13:43:38,551] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6052
[2019-03-23 13:43:38,556] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5092313253943408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 581015.4342845341, 581015.4342845341, 142585.7481271915], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3466200.0000, 
sim time next is 3466800.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5130226200974819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 585344.1770142464, 585344.1770142464, 143030.2722476103], 
processed observation next is [1.0, 0.13043478260869565, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3912782751218523, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21679413963490607, 0.21679413963490607, 0.34885432255514703], 
reward next is 0.6511, 
noisyNet noise sample is [array([0.60741687], dtype=float32), 1.6175919]. 
=============================================
[2019-03-23 13:43:39,705] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.4217188e-05 9.9997580e-01 5.8088512e-15 2.9687759e-13 1.1561474e-10], sum to 1.0000
[2019-03-23 13:43:39,715] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3066
[2019-03-23 13:43:39,723] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1689539.958865927 W.
[2019-03-23 13:43:39,732] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.93333333333333, 61.66666666666667, 1.0, 2.0, 0.5138196642565576, 1.0, 2.0, 0.5006982690698861, 1.0, 2.0, 0.9865530188920543, 6.9112, 6.9112, 77.3421103, 1689539.958865927, 1689539.958865927, 358187.5863160549], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3514200.0000, 
sim time next is 3514800.0000, 
raw observation next is [28.86666666666667, 61.33333333333334, 1.0, 2.0, 0.4637858074965328, 1.0, 2.0, 0.4637858074965328, 1.0, 2.0, 0.9384146644629143, 6.911199999999999, 6.9112, 77.3421103, 1564811.606178573, 1564811.606178573, 340159.2883034407], 
processed observation next is [1.0, 0.6956521739130435, 0.9484848484848487, 0.6133333333333334, 1.0, 1.0, 0.32973225937066597, 1.0, 1.0, 0.32973225937066597, 1.0, 1.0, 0.9120209492327348, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5795598541402123, 0.5795598541402123, 0.8296568007400993], 
reward next is 0.1703, 
noisyNet noise sample is [array([-1.230485], dtype=float32), 1.1894897]. 
=============================================
[2019-03-23 13:43:46,868] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.3948030e-09 1.0000000e+00 2.4877236e-25 3.3669142e-23 9.2333157e-19], sum to 1.0000
[2019-03-23 13:43:46,877] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0953
[2019-03-23 13:43:46,883] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5123457963219865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 584302.5576395615, 584302.5576395612, 143549.1798098755], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3621600.0000, 
sim time next is 3622200.0000, 
raw observation next is [21.83333333333334, 95.0, 1.0, 2.0, 0.5102092250132598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 581905.7689154734, 581905.7689154734, 143226.3036591802], 
processed observation next is [1.0, 0.9565217391304348, 0.628787878787879, 0.95, 1.0, 1.0, 0.38776153126657475, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21552065515387903, 0.21552065515387903, 0.34933244794922], 
reward next is 0.6507, 
noisyNet noise sample is [array([0.03856553], dtype=float32), -0.5755041]. 
=============================================
[2019-03-23 13:43:47,360] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.5162236e-07 9.9999988e-01 1.0336975e-22 2.4042455e-21 2.7218793e-17], sum to 1.0000
[2019-03-23 13:43:47,365] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9658
[2019-03-23 13:43:47,373] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5853571967340944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 667905.5293936396, 667905.52939364, 152032.0826702287], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3637800.0000, 
sim time next is 3638400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5587067949922615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 637488.7957034763, 637488.7957034761, 148616.6073612014], 
processed observation next is [1.0, 0.08695652173913043, 0.5909090909090909, 1.0, 1.0, 1.0, 0.4483834937403268, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23610696137165788, 0.2361069613716578, 0.3624795301492717], 
reward next is 0.6375, 
noisyNet noise sample is [array([0.21269196], dtype=float32), -0.07187442]. 
=============================================
[2019-03-23 13:43:50,230] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.1904849e-06 9.9999678e-01 1.3833488e-19 1.0665380e-18 9.4175856e-12], sum to 1.0000
[2019-03-23 13:43:50,239] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4878
[2019-03-23 13:43:50,249] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1513715.117031717 W.
[2019-03-23 13:43:50,254] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 53.5, 1.0, 2.0, 0.8494369132225996, 0.0, 2.0, 0.0, 1.0, 2.0, 0.977359565758446, 6.911200000000001, 6.9112, 77.32846344354104, 1513715.117031717, 1513715.117031716, 316476.1855994495], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3684600.0000, 
sim time next is 3685200.0000, 
raw observation next is [29.0, 53.0, 1.0, 2.0, 0.7004901045264961, 1.0, 1.0, 0.7004901045264961, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1583402.313955424, 1583402.313955424, 290130.9419208734], 
processed observation next is [1.0, 0.6521739130434783, 0.9545454545454546, 0.53, 1.0, 1.0, 0.62561263065812, 1.0, 0.5, 0.62561263065812, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.5864453014649718, 0.5864453014649718, 0.7076364437094473], 
reward next is 0.2924, 
noisyNet noise sample is [array([1.1490122], dtype=float32), -1.370722]. 
=============================================
[2019-03-23 13:43:59,720] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1608422e-10 1.0000000e+00 9.9691159e-30 2.0916930e-27 3.2135579e-20], sum to 1.0000
[2019-03-23 13:43:59,732] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9630
[2019-03-23 13:43:59,742] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 77.0, 1.0, 2.0, 0.2812653472231958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 305406.2327507673, 305406.2327507673, 101637.6843283391], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3894000.0000, 
sim time next is 3894600.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.281362457399602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 305511.7109732488, 305511.710973249, 101643.3464513569], 
processed observation next is [0.0, 0.043478260869565216, 0.45454545454545453, 0.77, 1.0, 1.0, 0.10170307174950245, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1131524855456477, 0.11315248554564777, 0.2479106011008705], 
reward next is 0.7521, 
noisyNet noise sample is [array([0.6240421], dtype=float32), -1.921648]. 
=============================================
[2019-03-23 13:44:01,044] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2683464e-09 1.0000000e+00 3.4188049e-28 4.5267150e-26 1.6028808e-21], sum to 1.0000
[2019-03-23 13:44:01,051] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0575
[2019-03-23 13:44:01,056] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.08333333333334, 81.66666666666667, 1.0, 2.0, 0.2668279734866661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 289725.0357926652, 289725.0357926655, 95064.87674654115], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3905400.0000, 
sim time next is 3906000.0000, 
raw observation next is [17.0, 82.0, 1.0, 2.0, 0.2656358788975907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 288430.2612629862, 288430.2612629859, 94383.95777990666], 
processed observation next is [0.0, 0.21739130434782608, 0.4090909090909091, 0.82, 1.0, 1.0, 0.08204484862198838, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1068260226899949, 0.10682602268999478, 0.23020477507294307], 
reward next is 0.7698, 
noisyNet noise sample is [array([-0.50620884], dtype=float32), 0.0866662]. 
=============================================
[2019-03-23 13:44:01,072] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[74.50182]
 [74.50762]
 [74.51753]
 [74.52227]
 [74.51884]], R is [[74.52823639]
 [74.55108643]
 [74.57196808]
 [74.59082031]
 [74.60762024]].
[2019-03-23 13:44:07,481] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.7302968e-09 1.0000000e+00 2.9571634e-26 1.0230772e-24 9.9631651e-19], sum to 1.0000
[2019-03-23 13:44:07,486] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6948
[2019-03-23 13:44:07,496] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.5745875387513331, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 640759.2328179608, 640759.2328179608, 139579.7294859984], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4035000.0000, 
sim time next is 4035600.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.5533988678690038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 617032.8670627321, 617032.8670627321, 137283.2905638127], 
processed observation next is [1.0, 0.7391304347826086, 0.45454545454545453, 0.94, 1.0, 1.0, 0.44174858483625473, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2285306915047156, 0.2285306915047156, 0.33483729405807977], 
reward next is 0.6652, 
noisyNet noise sample is [array([-0.9624209], dtype=float32), 0.9080516]. 
=============================================
[2019-03-23 13:44:16,120] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.2351391e-10 1.0000000e+00 2.7375268e-27 3.1848858e-23 6.5849233e-19], sum to 1.0000
[2019-03-23 13:44:16,127] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9325
[2019-03-23 13:44:16,137] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 69.0, 1.0, 2.0, 0.4007835677211128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 454134.9739829489, 454134.9739829489, 126401.7112110999], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4212000.0000, 
sim time next is 4212600.0000, 
raw observation next is [22.83333333333334, 69.66666666666667, 1.0, 2.0, 0.408207494400151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 462411.0649646061, 462411.0649646064, 127004.2611248787], 
processed observation next is [1.0, 0.782608695652174, 0.6742424242424245, 0.6966666666666668, 1.0, 1.0, 0.26025936800018873, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17126335739429854, 0.17126335739429868, 0.30976649054848465], 
reward next is 0.6902, 
noisyNet noise sample is [array([0.26181936], dtype=float32), -0.53854305]. 
=============================================
[2019-03-23 13:44:17,109] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1438394e-10 1.0000000e+00 8.3659099e-29 1.1035290e-25 3.9532395e-21], sum to 1.0000
[2019-03-23 13:44:17,118] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4644
[2019-03-23 13:44:17,124] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 91.0, 1.0, 2.0, 0.3472620152701592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 384838.7862815846, 384838.7862815846, 117279.4024263952], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4235400.0000, 
sim time next is 4236000.0000, 
raw observation next is [17.66666666666666, 92.0, 1.0, 2.0, 0.3411751164071566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 376753.1198915946, 376753.1198915943, 116280.8213606896], 
processed observation next is [1.0, 0.0, 0.4393939393939391, 0.92, 1.0, 1.0, 0.1764688955089457, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13953819255244243, 0.13953819255244232, 0.2836117594163161], 
reward next is 0.7164, 
noisyNet noise sample is [array([0.5132699], dtype=float32), 1.3957025]. 
=============================================
[2019-03-23 13:44:17,148] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[75.57887 ]
 [75.72595 ]
 [75.929306]
 [76.214294]
 [76.57622 ]], R is [[75.40765381]
 [75.36753082]
 [75.32543945]
 [75.28157806]
 [75.23660278]].
[2019-03-23 13:44:19,656] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 13:44:19,657] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:44:19,658] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:44:19,658] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:44:19,659] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:44:19,659] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:44:19,660] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:44:19,665] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:44:19,660] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:44:19,665] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:44:19,668] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:44:19,675] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run31
[2019-03-23 13:44:19,701] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run31
[2019-03-23 13:44:19,702] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run31
[2019-03-23 13:44:19,702] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run31
[2019-03-23 13:44:19,795] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run31
[2019-03-23 13:44:33,375] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08242328], dtype=float32), 0.25106433]
[2019-03-23 13:44:33,376] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.15, 85.5, 1.0, 2.0, 0.4139974428682448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 470446.4526424289, 470446.4526424285, 132972.640868768]
[2019-03-23 13:44:33,376] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:44:33,378] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.5008503e-09 1.0000000e+00 1.8243592e-26 1.5356451e-24 6.3248608e-19], sampled 0.0722823418969919
[2019-03-23 13:44:56,999] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08242328], dtype=float32), 0.25106433]
[2019-03-23 13:44:57,001] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.88333333333333, 86.66666666666666, 1.0, 2.0, 0.3608499835407862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 401798.3085976355, 401798.3085976351, 123441.6159361201]
[2019-03-23 13:44:57,003] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:44:57,007] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.2092631e-09 1.0000000e+00 9.8237881e-27 8.6538426e-25 4.0765552e-19], sampled 0.8604036026887517
[2019-03-23 13:44:57,225] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08242328], dtype=float32), 0.25106433]
[2019-03-23 13:44:57,227] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.9, 84.0, 1.0, 2.0, 0.3509173650191625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 388884.9132192027, 388884.9132192023, 121880.2990536086]
[2019-03-23 13:44:57,230] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:44:57,232] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.7800853e-09 1.0000000e+00 2.9761531e-26 2.4164249e-24 8.9509442e-19], sampled 0.5383609495425773
[2019-03-23 13:44:59,597] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08242328], dtype=float32), 0.25106433]
[2019-03-23 13:44:59,600] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.79958004333334, 53.19548694166666, 1.0, 2.0, 0.3957107972524883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 448600.0411885597, 448600.0411885597, 130411.9587850833]
[2019-03-23 13:44:59,602] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:44:59,605] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5728296e-09 1.0000000e+00 2.0872384e-26 1.7395430e-24 6.9593641e-19], sampled 0.0983027738070168
[2019-03-23 13:45:12,531] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08242328], dtype=float32), 0.25106433]
[2019-03-23 13:45:12,532] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.1, 73.5, 1.0, 2.0, 0.9685557867638922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 1098184.433363196, 1098184.433363196, 222455.8623298413]
[2019-03-23 13:45:12,533] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:45:12,538] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.1076834e-09 1.0000000e+00 4.8288943e-26 3.7857380e-24 1.2622950e-18], sampled 0.873092073785371
[2019-03-23 13:45:12,540] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1098184.433363196 W.
[2019-03-23 13:45:12,735] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08242328], dtype=float32), 0.25106433]
[2019-03-23 13:45:12,736] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.70311881, 65.72895486666667, 1.0, 2.0, 0.456500879758665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 520837.946260969, 520837.946260969, 140265.6556611624]
[2019-03-23 13:45:12,738] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:45:12,741] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.2262440e-09 1.0000000e+00 1.0224051e-26 8.9798502e-25 4.1937349e-19], sampled 0.1546134021357498
[2019-03-23 13:45:13,562] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08242328], dtype=float32), 0.25106433]
[2019-03-23 13:45:13,563] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.7, 90.0, 1.0, 2.0, 0.524208242400887, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 597470.0081260856, 597470.0081260853, 149680.271595148]
[2019-03-23 13:45:13,565] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:45:13,569] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.2456638e-09 1.0000000e+00 1.0692175e-26 9.3601768e-25 4.3288724e-19], sampled 0.7774659129131545
[2019-03-23 13:45:14,496] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08242328], dtype=float32), 0.25106433]
[2019-03-23 13:45:14,497] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.8, 87.0, 1.0, 2.0, 0.5032713166225656, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 573998.8610378485, 573998.8610378482, 146574.2999809498]
[2019-03-23 13:45:14,498] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:45:14,503] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.3505366e-09 1.0000000e+00 1.3478949e-26 1.1600416e-24 5.1018065e-19], sampled 0.7391238036763038
[2019-03-23 13:45:18,028] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08242328], dtype=float32), 0.25106433]
[2019-03-23 13:45:18,029] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.0, 100.0, 1.0, 2.0, 0.3869987012530124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 434510.9341381144, 434510.9341381144, 122879.0777390965]
[2019-03-23 13:45:18,030] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:45:18,034] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.1330449e-09 1.0000000e+00 4.9979793e-26 3.9068340e-24 1.2931467e-18], sampled 0.3665376786397547
[2019-03-23 13:46:00,284] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 13:46:00,514] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 13:46:00,542] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 13:46:00,942] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5896 1663766061.8834 105.0000
[2019-03-23 13:46:00,995] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 13:46:02,012] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 750000, evaluation results [750000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.58956291602, 1663766061.8834455, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 13:46:13,696] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.4054035e-08 1.0000000e+00 3.7843065e-25 4.9862563e-23 2.8417842e-18], sum to 1.0000
[2019-03-23 13:46:13,701] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6414
[2019-03-23 13:46:13,705] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.4960073638037176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 565679.1683825849, 565679.1683825849, 141593.5104848112], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4525200.0000, 
sim time next is 4525800.0000, 
raw observation next is [22.0, 94.00000000000001, 1.0, 2.0, 0.4967495530125298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 566512.3537410481, 566512.3537410481, 141702.5982955012], 
processed observation next is [0.0, 0.391304347826087, 0.6363636363636364, 0.9400000000000002, 1.0, 1.0, 0.37093694126566223, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20981939027446228, 0.20981939027446228, 0.34561609340366145], 
reward next is 0.6544, 
noisyNet noise sample is [array([-1.4666793], dtype=float32), 0.52975994]. 
=============================================
[2019-03-23 13:46:14,208] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.4592090e-10 1.0000000e+00 1.0343498e-27 6.1828033e-26 3.6758670e-21], sum to 1.0000
[2019-03-23 13:46:14,215] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5212
[2019-03-23 13:46:14,221] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.83333333333333, 100.0, 1.0, 2.0, 0.4723790568942213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 539020.7334947393, 539020.7334947389, 137888.4946060037], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4521000.0000, 
sim time next is 4521600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4789837994369454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 546515.4656093493, 546515.4656093493, 138983.3522157404], 
processed observation next is [0.0, 0.34782608695652173, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3487297492961817, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2024131354108701, 0.2024131354108701, 0.33898378589204975], 
reward next is 0.6610, 
noisyNet noise sample is [array([0.4889487], dtype=float32), -0.7387585]. 
=============================================
[2019-03-23 13:46:21,345] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1639088e-13 1.0000000e+00 1.0765227e-34 2.7982949e-31 1.0069787e-22], sum to 1.0000
[2019-03-23 13:46:21,354] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9612
[2019-03-23 13:46:21,359] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 50.0, 1.0, 2.0, 0.3168250621181954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 345185.7825064994, 345185.7825064991, 112733.7831824371], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4643400.0000, 
sim time next is 4644000.0000, 
raw observation next is [23.0, 50.0, 1.0, 2.0, 0.3180395820348563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 346514.5859246352, 346514.5859246349, 112820.1994482496], 
processed observation next is [1.0, 0.782608695652174, 0.6818181818181818, 0.5, 1.0, 1.0, 0.1475494775435704, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12833873552764266, 0.12833873552764255, 0.27517121816646245], 
reward next is 0.7248, 
noisyNet noise sample is [array([-1.2104613], dtype=float32), -0.14144088]. 
=============================================
[2019-03-23 13:46:21,380] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[88.86135 ]
 [88.6527  ]
 [88.401726]
 [88.05744 ]
 [87.159035]], R is [[88.83634186]
 [88.67301941]
 [88.51156616]
 [88.35198975]
 [88.19156647]].
[2019-03-23 13:46:21,805] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.6280175e-09 1.0000000e+00 5.0633463e-24 1.7190153e-23 5.4482595e-17], sum to 1.0000
[2019-03-23 13:46:21,813] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0152
[2019-03-23 13:46:21,818] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 47.0, 1.0, 2.0, 0.6977566962580021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 759917.7962141768, 759917.7962141768, 147467.9836825842], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4632600.0000, 
sim time next is 4633200.0000, 
raw observation next is [23.0, 47.0, 1.0, 2.0, 0.6959289613914286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 756010.3821761305, 756010.3821761305, 146673.2700168135], 
processed observation next is [1.0, 0.6521739130434783, 0.6818181818181818, 0.47, 1.0, 1.0, 0.6199112017392857, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2800038452504187, 0.2800038452504187, 0.3577396829678378], 
reward next is 0.6423, 
noisyNet noise sample is [array([0.98571897], dtype=float32), -0.858189]. 
=============================================
[2019-03-23 13:46:24,959] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.4928883e-11 1.0000000e+00 7.2167123e-28 2.0120384e-26 8.9229498e-20], sum to 1.0000
[2019-03-23 13:46:24,971] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0442
[2019-03-23 13:46:24,977] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 51.5, 1.0, 2.0, 0.6324604504426518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 715078.763373928, 715078.763373928, 150586.6230087234], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4711800.0000, 
sim time next is 4712400.0000, 
raw observation next is [26.0, 51.0, 1.0, 2.0, 0.5209529116172016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 589782.2851244692, 589782.2851244692, 138209.4715714702], 
processed observation next is [1.0, 0.5652173913043478, 0.8181818181818182, 0.51, 1.0, 1.0, 0.4011911395215019, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21843788337943304, 0.21843788337943304, 0.33709627212553706], 
reward next is 0.6629, 
noisyNet noise sample is [array([1.441763], dtype=float32), -0.6615242]. 
=============================================
[2019-03-23 13:46:29,431] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1489309e-08 1.0000000e+00 9.9780640e-21 2.2672142e-19 6.4580159e-15], sum to 1.0000
[2019-03-23 13:46:29,440] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1277
[2019-03-23 13:46:29,447] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 98.0, 1.0, 2.0, 0.8845003448838906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1009353.202168492, 1009353.202168492, 197764.1528253178], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4800000.0000, 
sim time next is 4800600.0000, 
raw observation next is [21.5, 97.0, 1.0, 2.0, 0.9630557484055919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1098912.510464999, 1098912.510464999, 212217.5575427314], 
processed observation next is [1.0, 0.5652173913043478, 0.6136363636363636, 0.97, 1.0, 1.0, 0.9538196855069899, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.40700463350555516, 0.40700463350555516, 0.5176037988847108], 
reward next is 0.4824, 
noisyNet noise sample is [array([-0.4706449], dtype=float32), 0.49252]. 
=============================================
[2019-03-23 13:46:42,249] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.1440411e-11 1.0000000e+00 5.4721713e-32 2.8087021e-30 1.1984427e-22], sum to 1.0000
[2019-03-23 13:46:42,255] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0502
[2019-03-23 13:46:42,260] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 57.0, 1.0, 2.0, 0.358925786688955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 403172.2497921279, 403172.2497921276, 120581.977078482], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5054400.0000, 
sim time next is 5055000.0000, 
raw observation next is [24.33333333333333, 56.5, 1.0, 2.0, 0.3630738704689048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 408580.1060388203, 408580.1060388203, 121313.295373251], 
processed observation next is [0.0, 0.5217391304347826, 0.7424242424242422, 0.565, 1.0, 1.0, 0.203842338086131, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15132596519956307, 0.15132596519956307, 0.295886086276222], 
reward next is 0.7041, 
noisyNet noise sample is [array([0.08905954], dtype=float32), 0.43917724]. 
=============================================
[2019-03-23 13:46:42,279] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[82.82578 ]
 [82.746216]
 [82.68519 ]
 [82.63166 ]
 [82.568985]], R is [[82.74452972]
 [82.62297821]
 [82.50310516]
 [82.38490295]
 [82.26834869]].
[2019-03-23 13:46:43,086] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.2051297e-12 1.0000000e+00 7.2400437e-27 5.7824979e-25 1.5822644e-18], sum to 1.0000
[2019-03-23 13:46:43,088] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5055
[2019-03-23 13:46:43,098] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 52.5, 1.0, 2.0, 0.4141810976788013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 470909.9481936991, 470909.9481936988, 128865.7002429251], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5067000.0000, 
sim time next is 5067600.0000, 
raw observation next is [26.33333333333334, 53.0, 1.0, 2.0, 0.4135111230992308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 470006.1147478089, 470006.1147478092, 128677.4118884709], 
processed observation next is [0.0, 0.6521739130434783, 0.8333333333333336, 0.53, 1.0, 1.0, 0.2668889038740385, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1740763387954848, 0.1740763387954849, 0.3138473460694412], 
reward next is 0.6862, 
noisyNet noise sample is [array([-0.47535706], dtype=float32), -0.10011779]. 
=============================================
[2019-03-23 13:46:44,642] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.5511261e-09 1.0000000e+00 1.5033340e-28 2.9694768e-24 4.3223074e-18], sum to 1.0000
[2019-03-23 13:46:44,647] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8391
[2019-03-23 13:46:44,653] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 80.5, 1.0, 2.0, 0.4283156138530803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 487389.0147424785, 487389.0147424788, 130625.6628451537], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5095800.0000, 
sim time next is 5096400.0000, 
raw observation next is [22.0, 79.66666666666667, 1.0, 2.0, 0.4249314496288941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 483273.9570742114, 483273.9570742114, 130040.1834164642], 
processed observation next is [0.0, 1.0, 0.6363636363636364, 0.7966666666666667, 1.0, 1.0, 0.28116431203611764, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17899035447193015, 0.17899035447193015, 0.31717117906454684], 
reward next is 0.6828, 
noisyNet noise sample is [array([-0.3397787], dtype=float32), -2.4116433]. 
=============================================
[2019-03-23 13:46:47,736] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.9219805e-07 9.9999917e-01 2.9809971e-22 1.0572510e-20 1.9706490e-15], sum to 1.0000
[2019-03-23 13:46:47,740] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2153
[2019-03-23 13:46:47,751] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 66.5, 1.0, 2.0, 0.4922322819514429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 561419.5125487079, 561419.5125487079, 141071.2818553847], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5159400.0000, 
sim time next is 5160000.0000, 
raw observation next is [26.0, 68.0, 1.0, 2.0, 0.4985893363033989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 568357.2681076314, 568357.2681076316, 142271.7990951949], 
processed observation next is [0.0, 0.7391304347826086, 0.8181818181818182, 0.68, 1.0, 1.0, 0.3732366703792486, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21050269189171533, 0.21050269189171542, 0.34700438803706074], 
reward next is 0.6530, 
noisyNet noise sample is [array([1.2154022], dtype=float32), 1.4913639]. 
=============================================
[2019-03-23 13:46:47,784] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[61.075447]
 [61.08709 ]
 [61.069016]
 [61.059784]
 [61.04777 ]], R is [[61.10702133]
 [61.15187454]
 [61.19729233]
 [61.23923492]
 [61.27766418]].
[2019-03-23 13:46:49,767] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.3140247e-09 1.0000000e+00 3.3975662e-25 1.5081866e-22 2.0492933e-15], sum to 1.0000
[2019-03-23 13:46:49,776] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8391
[2019-03-23 13:46:49,784] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4535970992497777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 516808.1228682996, 516808.1228682999, 133895.8354195116], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5199000.0000, 
sim time next is 5199600.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4386581447584045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499775.048020429, 499775.048020429, 132342.3261533377], 
processed observation next is [1.0, 0.17391304347826086, 0.6363636363636364, 0.83, 1.0, 1.0, 0.29832268094800557, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1851018696371959, 0.1851018696371959, 0.32278616134960414], 
reward next is 0.6772, 
noisyNet noise sample is [array([-0.97709304], dtype=float32), 0.37698308]. 
=============================================
[2019-03-23 13:46:50,721] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 13:46:50,723] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:46:50,726] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:46:50,726] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:46:50,728] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:46:50,729] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:46:50,730] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:46:50,731] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:46:50,731] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:46:50,733] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:46:50,733] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:46:50,744] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run32
[2019-03-23 13:46:50,745] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run32
[2019-03-23 13:46:50,769] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run32
[2019-03-23 13:46:50,770] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run32
[2019-03-23 13:46:50,796] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run32
[2019-03-23 13:47:14,742] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08252316], dtype=float32), 0.2576487]
[2019-03-23 13:47:14,744] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.58101297, 73.46596937666666, 1.0, 2.0, 0.2388887474467446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 259367.0069164344, 259367.0069164344, 85069.30457318587]
[2019-03-23 13:47:14,745] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:47:14,748] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.8765749e-08 1.0000000e+00 4.2990143e-22 1.8437305e-20 1.9796168e-15], sampled 0.8392595750689116
[2019-03-23 13:47:33,471] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08252316], dtype=float32), 0.2576487]
[2019-03-23 13:47:33,472] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.36666666666667, 83.33333333333334, 1.0, 2.0, 0.5535773330676877, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 631308.0723725917, 631308.0723725917, 152832.0505709332]
[2019-03-23 13:47:33,474] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:47:33,481] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.7652725e-08 1.0000000e+00 3.8507898e-22 1.6655891e-20 1.8345586e-15], sampled 0.2124801949421008
[2019-03-23 13:47:46,913] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08252316], dtype=float32), 0.2576487]
[2019-03-23 13:47:46,913] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.0, 90.0, 1.0, 2.0, 0.4127778313916895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 467324.8728872758, 467324.8728872754, 131597.3893723748]
[2019-03-23 13:47:46,916] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:47:46,921] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.43134508e-08 1.00000000e+00 2.69302674e-22 1.19669415e-20
 1.43286560e-15], sampled 0.010655179283339256
[2019-03-23 13:48:20,067] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08252316], dtype=float32), 0.2576487]
[2019-03-23 13:48:20,069] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.8, 97.0, 1.0, 2.0, 0.3886134154227718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 438590.3068977339, 438590.3068977341, 124201.0835659917]
[2019-03-23 13:48:20,070] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:48:20,074] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.7003577e-08 1.0000000e+00 8.6542196e-22 3.5212668e-20 3.2107356e-15], sampled 0.16450116482881305
[2019-03-23 13:48:20,630] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08252316], dtype=float32), 0.2576487]
[2019-03-23 13:48:20,632] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.18333333333333, 83.0, 1.0, 2.0, 0.5901870473573558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 89.17268220069205, 672871.6579289046, 672871.6579289043, 153448.0480764954]
[2019-03-23 13:48:20,633] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:48:20,638] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.4158543e-08 1.0000000e+00 6.9275957e-22 2.8665618e-20 2.7530112e-15], sampled 0.41587650259847153
[2019-03-23 13:48:31,791] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 13:48:31,860] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 13:48:31,918] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 13:48:31,948] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 13:48:32,057] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 13:48:33,073] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 775000, evaluation results [775000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 13:48:36,834] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.5742259e-08 1.0000000e+00 1.8548526e-23 2.4663925e-21 3.3288269e-18], sum to 1.0000
[2019-03-23 13:48:36,843] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1339
[2019-03-23 13:48:36,848] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.9, 87.0, 1.0, 2.0, 0.3574230102779145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 398082.4284094052, 398082.4284094055, 118889.1704585334], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5289000.0000, 
sim time next is 5289600.0000, 
raw observation next is [19.0, 87.0, 1.0, 2.0, 0.3474498041486415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 387482.4787783488, 387482.4787783491, 118315.6109285052], 
processed observation next is [1.0, 0.21739130434782608, 0.5, 0.87, 1.0, 1.0, 0.18431225518580188, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14351202917716624, 0.14351202917716635, 0.2885746608012322], 
reward next is 0.7114, 
noisyNet noise sample is [array([-1.3777875], dtype=float32), -0.53646785]. 
=============================================
[2019-03-23 13:48:40,412] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.7468475e-10 1.0000000e+00 1.4344827e-25 3.7899592e-23 7.1213344e-18], sum to 1.0000
[2019-03-23 13:48:40,422] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4640
[2019-03-23 13:48:40,426] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.4, 52.0, 1.0, 2.0, 0.4834227062367423, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 550358.273021478, 550358.273021478, 141165.3360143545], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5333400.0000, 
sim time next is 5334000.0000, 
raw observation next is [29.2, 52.33333333333333, 1.0, 2.0, 0.4851074008444187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 552547.6122954244, 552547.6122954244, 141141.5350756336], 
processed observation next is [1.0, 0.7391304347826086, 0.9636363636363636, 0.5233333333333333, 1.0, 1.0, 0.35638425105552335, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20464726381312018, 0.20464726381312018, 0.34424764652593565], 
reward next is 0.6558, 
noisyNet noise sample is [array([-3.8577673], dtype=float32), -1.3576725]. 
=============================================
[2019-03-23 13:48:40,441] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[65.35147 ]
 [63.932022]
 [61.040665]
 [59.383102]
 [59.59381 ]], R is [[66.24757385]
 [66.24079132]
 [65.5783844 ]
 [64.92259979]
 [64.55606079]].
[2019-03-23 13:48:44,865] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.01228155e-08 1.00000000e+00 4.74913043e-28 4.57157375e-26
 3.69220106e-19], sum to 1.0000
[2019-03-23 13:48:44,875] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4875
[2019-03-23 13:48:44,880] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 96.33333333333334, 1.0, 2.0, 0.3911685220501076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 441137.0658699575, 441137.0658699572, 124242.1042926112], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5440200.0000, 
sim time next is 5440800.0000, 
raw observation next is [18.8, 95.66666666666667, 1.0, 2.0, 0.3897283972857394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 439197.6405743325, 439197.6405743325, 123942.422193243], 
processed observation next is [1.0, 1.0, 0.49090909090909096, 0.9566666666666667, 1.0, 1.0, 0.2371604966071742, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16266579280530832, 0.16266579280530832, 0.3022985907152268], 
reward next is 0.6977, 
noisyNet noise sample is [array([-0.36594337], dtype=float32), -0.051634144]. 
=============================================
[2019-03-23 13:48:46,944] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.6347871e-09 1.0000000e+00 4.2753538e-20 1.3325876e-19 3.3889884e-15], sum to 1.0000
[2019-03-23 13:48:46,950] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6303
[2019-03-23 13:48:46,959] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1485480.098130846 W.
[2019-03-23 13:48:46,964] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.2, 69.0, 1.0, 2.0, 0.832427662749838, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9840949693046215, 6.9112, 6.9112, 77.32846344354104, 1485480.098130846, 1485480.098130846, 320089.8949585829], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5497200.0000, 
sim time next is 5497800.0000, 
raw observation next is [27.1, 69.83333333333333, 1.0, 2.0, 0.632832767917617, 1.0, 1.0, 0.632832767917617, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1423272.945951217, 1423272.945951217, 271403.4780606314], 
processed observation next is [1.0, 0.6521739130434783, 0.8681818181818183, 0.6983333333333333, 1.0, 1.0, 0.5410409598970212, 1.0, 0.5, 0.5410409598970212, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5271381281300804, 0.5271381281300804, 0.6619597025869058], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.66084886], dtype=float32), -0.56470996]. 
=============================================
[2019-03-23 13:48:53,452] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.1963082e-10 1.0000000e+00 7.4686250e-24 1.0156279e-22 4.6358702e-17], sum to 1.0000
[2019-03-23 13:48:53,458] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4542
[2019-03-23 13:48:53,460] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.08333333333334, 92.0, 1.0, 2.0, 0.4192411589675605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 475773.4984225266, 475773.4984225263, 128644.4853843653], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5601000.0000, 
sim time next is 5601600.0000, 
raw observation next is [20.0, 93.0, 1.0, 2.0, 0.4212428746749342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 478161.3394232859, 478161.3394232859, 128923.7347220471], 
processed observation next is [1.0, 0.8695652173913043, 0.5454545454545454, 0.93, 1.0, 1.0, 0.27655359334366775, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17709679237899478, 0.17709679237899478, 0.31444813346840755], 
reward next is 0.6856, 
noisyNet noise sample is [array([-0.24309207], dtype=float32), -0.5050228]. 
=============================================
[2019-03-23 13:49:00,264] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 2.4457043e-22 5.6183946e-33 2.0234027e-30 4.6670304e-31], sum to 1.0000
[2019-03-23 13:49:00,270] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0427
[2019-03-23 13:49:00,281] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.63333333333333, 58.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3859365741582929, 6.911199999999998, 6.9112, 77.32846344354104, 224479.730318268, 224479.7303182686, 64746.63409169524], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5737200.0000, 
sim time next is 5737800.0000, 
raw observation next is [16.91666666666667, 57.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3925518922834385, 6.9112, 6.9112, 77.32846344354104, 228318.2936005374, 228318.2936005374, 65938.85153991918], 
processed observation next is [0.0, 0.391304347826087, 0.4053030303030305, 0.57, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.13221698897634074, 0.0, 0.0, 0.5084288129206541, 0.084562330963162, 0.084562330963162, 0.1608264671705346], 
reward next is 0.8392, 
noisyNet noise sample is [array([-0.40286615], dtype=float32), 0.32100537]. 
=============================================
[2019-03-23 13:49:04,852] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.2836694e-10 1.0000000e+00 1.5068333e-32 1.7969368e-28 6.5947419e-22], sum to 1.0000
[2019-03-23 13:49:04,861] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6254
[2019-03-23 13:49:04,864] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.53333333333333, 63.66666666666667, 1.0, 2.0, 0.2488771133298788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 270228.3601099845, 270228.3601099848, 80163.49154785585], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5818800.0000, 
sim time next is 5819400.0000, 
raw observation next is [18.0, 63.0, 1.0, 2.0, 0.2826879396050059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 306951.4131160961, 306951.4131160961, 85126.10038083138], 
processed observation next is [1.0, 0.34782608695652173, 0.45454545454545453, 0.63, 1.0, 1.0, 0.10335992450625733, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11368570856151708, 0.11368570856151708, 0.2076246350751985], 
reward next is 0.7924, 
noisyNet noise sample is [array([1.0811976], dtype=float32), -0.111569904]. 
=============================================
[2019-03-23 13:49:06,101] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.2197359e-11 1.0000000e+00 1.9882540e-28 3.1797566e-27 5.1585368e-20], sum to 1.0000
[2019-03-23 13:49:06,109] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6161
[2019-03-23 13:49:06,113] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 70.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 214761.4136587094, 214761.4136587097, 71460.52794240239], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5815800.0000, 
sim time next is 5816400.0000, 
raw observation next is [15.86666666666667, 68.33333333333333, 1.0, 2.0, 0.2005355490297918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 217727.8093963733, 217727.8093963735, 72197.15840289826], 
processed observation next is [1.0, 0.30434782608695654, 0.35757575757575777, 0.6833333333333332, 1.0, 1.0, 0.0006694362872397205, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0806399294060642, 0.08063992940606425, 0.17609063025097138], 
reward next is 0.8239, 
noisyNet noise sample is [array([0.9846977], dtype=float32), -1.1424522]. 
=============================================
[2019-03-23 13:49:08,722] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.9133960e-08 1.0000000e+00 6.0089560e-30 2.1102960e-26 7.7374774e-19], sum to 1.0000
[2019-03-23 13:49:08,731] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5229
[2019-03-23 13:49:08,735] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.83333333333333, 82.0, 1.0, 2.0, 0.2655713016563089, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 288360.1218204914, 288360.1218204914, 92505.68223752017], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5892000.0000, 
sim time next is 5892600.0000, 
raw observation next is [17.01666666666667, 80.0, 1.0, 2.0, 0.2625704014590137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 285100.7576519434, 285100.7576519434, 91588.16294138292], 
processed observation next is [1.0, 0.17391304347826086, 0.40984848484848496, 0.8, 1.0, 1.0, 0.07821300182376714, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1055928732044235, 0.1055928732044235, 0.22338576327166565], 
reward next is 0.7766, 
noisyNet noise sample is [array([0.8752477], dtype=float32), -0.6552271]. 
=============================================
[2019-03-23 13:49:12,854] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.8061029e-09 1.0000000e+00 3.3519809e-25 2.1334161e-23 4.9046291e-15], sum to 1.0000
[2019-03-23 13:49:12,859] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0661
[2019-03-23 13:49:12,863] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.41666666666667, 69.66666666666667, 1.0, 2.0, 0.3595789227156546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 401591.757164519, 401591.757164519, 119544.6706271987], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5962200.0000, 
sim time next is 5962800.0000, 
raw observation next is [21.23333333333333, 71.33333333333334, 1.0, 2.0, 0.3605735173208463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 402998.1866805669, 402998.1866805669, 119758.2070973179], 
processed observation next is [1.0, 0.0, 0.6015151515151514, 0.7133333333333334, 1.0, 1.0, 0.20071689665105785, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14925858765946923, 0.14925858765946923, 0.29209318804223877], 
reward next is 0.7079, 
noisyNet noise sample is [array([-0.37954605], dtype=float32), 0.5040405]. 
=============================================
[2019-03-23 13:49:19,702] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.2925678e-10 1.0000000e+00 2.6165207e-30 2.0862902e-27 1.4186079e-19], sum to 1.0000
[2019-03-23 13:49:19,710] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9355
[2019-03-23 13:49:19,715] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 68.0, 1.0, 2.0, 0.2881532890995476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 312887.7697249712, 312887.7697249709, 105775.5914256467], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6134400.0000, 
sim time next is 6135000.0000, 
raw observation next is [19.21666666666667, 69.16666666666667, 1.0, 2.0, 0.2889759793407742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 313781.3661821029, 313781.3661821026, 105516.353972497], 
processed observation next is [1.0, 0.0, 0.5098484848484849, 0.6916666666666668, 1.0, 1.0, 0.11121997417596771, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11621532080818625, 0.11621532080818614, 0.2573569609085293], 
reward next is 0.7426, 
noisyNet noise sample is [array([1.2391881], dtype=float32), -0.7651147]. 
=============================================
[2019-03-23 13:49:19,729] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[79.99527 ]
 [80.253456]
 [80.18419 ]
 [80.10535 ]
 [80.050255]], R is [[79.99056244]
 [79.93267059]
 [79.8789444 ]
 [79.82920074]
 [79.78327179]].
[2019-03-23 13:49:19,882] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8254662e-11 1.0000000e+00 9.4837966e-29 4.4925994e-27 8.9173399e-19], sum to 1.0000
[2019-03-23 13:49:19,891] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4921
[2019-03-23 13:49:19,895] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.2, 63.66666666666667, 1.0, 2.0, 0.2676965791841378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 290668.4601917297, 290668.4601917294, 92192.22922955663], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6128400.0000, 
sim time next is 6129000.0000, 
raw observation next is [19.4, 63.0, 1.0, 2.0, 0.2695661347267924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 292699.0590151091, 292699.0590151091, 93402.92156792663], 
processed observation next is [1.0, 0.9565217391304348, 0.5181818181818181, 0.63, 1.0, 1.0, 0.08695766840849051, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10840705889448485, 0.10840705889448485, 0.2278120038242113], 
reward next is 0.7722, 
noisyNet noise sample is [array([-0.8697994], dtype=float32), -0.32702616]. 
=============================================
[2019-03-23 13:49:19,907] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[73.89901 ]
 [73.91692 ]
 [73.933205]
 [73.92774 ]
 [73.939095]], R is [[73.91962433]
 [73.95556641]
 [73.99382019]
 [74.03391266]
 [74.07215881]].
[2019-03-23 13:49:21,912] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 13:49:21,914] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:49:21,914] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:49:21,914] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:49:21,915] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:49:21,915] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:49:21,916] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:49:21,917] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:49:21,917] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:49:21,918] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:49:21,919] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:49:21,940] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run33
[2019-03-23 13:49:21,967] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run33
[2019-03-23 13:49:21,996] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run33
[2019-03-23 13:49:21,996] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run33
[2019-03-23 13:49:21,997] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run33
[2019-03-23 13:50:08,506] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08283317], dtype=float32), 0.25374833]
[2019-03-23 13:50:08,508] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 73.0, 1.0, 2.0, 0.2982750101389878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 323881.9781609855, 323881.9781609857, 111076.2838134219]
[2019-03-23 13:50:08,510] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:50:08,513] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.9662574e-08 1.0000000e+00 3.2142871e-24 1.8048909e-22 1.8567716e-15], sampled 0.33858430747880175
[2019-03-23 13:50:18,923] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08283317], dtype=float32), 0.25374833]
[2019-03-23 13:50:18,925] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.53333333333333, 68.66666666666667, 1.0, 2.0, 0.2500280492995909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 271463.9342781388, 271463.9342781388, 87940.54307064616]
[2019-03-23 13:50:18,927] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:50:18,930] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.7703416e-08 1.0000000e+00 2.2698652e-24 1.3044004e-22 1.4910134e-15], sampled 0.2688061332053687
[2019-03-23 13:51:01,296] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08283317], dtype=float32), 0.25374833]
[2019-03-23 13:51:01,299] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.8, 70.5, 1.0, 2.0, 0.2217292827861501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 240744.2133140436, 240744.2133140434, 74850.24618056671]
[2019-03-23 13:51:01,300] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:51:01,303] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.2348593e-08 1.0000000e+00 5.0096306e-23 2.2867553e-21 1.0498962e-14], sampled 0.4329485568341397
[2019-03-23 13:51:03,029] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 13:51:03,384] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 13:51:03,441] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5896 1663766061.8834 105.0000
[2019-03-23 13:51:03,544] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 13:51:03,674] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 13:51:04,693] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 800000, evaluation results [800000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.58956291602, 1663766061.8834455, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 13:51:12,074] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1902059e-10 1.0000000e+00 1.4940640e-24 5.7155252e-24 4.8030887e-16], sum to 1.0000
[2019-03-23 13:51:12,083] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5675
[2019-03-23 13:51:12,089] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.35, 61.16666666666666, 1.0, 2.0, 0.5357957662969357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 607896.2220328451, 607896.2220328451, 148631.8788805379], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6268200.0000, 
sim time next is 6268800.0000, 
raw observation next is [27.9, 65.33333333333334, 1.0, 2.0, 0.5476158107733932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 619893.6175578646, 619893.6175578644, 150663.2939004988], 
processed observation next is [0.0, 0.5652173913043478, 0.9045454545454544, 0.6533333333333334, 1.0, 1.0, 0.4345197634667414, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22959022872513504, 0.22959022872513496, 0.36747144853780195], 
reward next is 0.6325, 
noisyNet noise sample is [array([-2.1860518], dtype=float32), 2.0492835]. 
=============================================
[2019-03-23 13:51:15,822] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4710101e-09 1.0000000e+00 4.7387910e-23 3.7214520e-22 3.1663644e-15], sum to 1.0000
[2019-03-23 13:51:15,830] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0410
[2019-03-23 13:51:15,834] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.9, 63.66666666666666, 1.0, 2.0, 0.5537471184868261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 627822.228094971, 627822.228094971, 151105.2846165162], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6370800.0000, 
sim time next is 6371400.0000, 
raw observation next is [27.8, 64.33333333333334, 1.0, 2.0, 0.5550564330390555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 629207.3325573946, 629207.3325573946, 151313.1930532353], 
processed observation next is [0.0, 0.7391304347826086, 0.9, 0.6433333333333334, 1.0, 1.0, 0.4438205412988193, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23303975279903505, 0.23303975279903505, 0.3690565684225251], 
reward next is 0.6309, 
noisyNet noise sample is [array([0.62973225], dtype=float32), -2.0426643]. 
=============================================
[2019-03-23 13:51:17,043] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.1844232e-10 1.0000000e+00 3.8332866e-24 4.3082757e-21 5.7976102e-16], sum to 1.0000
[2019-03-23 13:51:17,051] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7996
[2019-03-23 13:51:17,059] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.9, 76.5, 1.0, 2.0, 0.5208556920953176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593092.8776276096, 593092.8776276096, 145554.4468794944], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6390600.0000, 
sim time next is 6391200.0000, 
raw observation next is [24.8, 77.0, 1.0, 2.0, 0.5198469455353076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 591997.7931739304, 591997.7931739307, 145388.3628325429], 
processed observation next is [0.0, 1.0, 0.7636363636363637, 0.77, 1.0, 1.0, 0.3998086819191345, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2192584419162705, 0.21925844191627064, 0.35460576300620217], 
reward next is 0.6454, 
noisyNet noise sample is [array([-2.067723], dtype=float32), 1.3209438]. 
=============================================
[2019-03-23 13:51:23,031] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.9798769e-08 1.0000000e+00 1.3778910e-20 1.1960102e-19 2.6904117e-12], sum to 1.0000
[2019-03-23 13:51:23,039] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3972
[2019-03-23 13:51:23,044] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.56666666666667, 89.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 201693.7849662712, 201693.7849662715, 67751.43362122377], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6502800.0000, 
sim time next is 6503400.0000, 
raw observation next is [12.75, 89.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 202383.2167214659, 202383.2167214662, 68121.62665982624], 
processed observation next is [1.0, 0.2608695652173913, 0.2159090909090909, 0.89, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07495674693387626, 0.07495674693387637, 0.16615030892640548], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.32974193], dtype=float32), 1.3029453]. 
=============================================
[2019-03-23 13:51:23,539] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8134518e-11 1.0000000e+00 4.0835343e-31 7.0404266e-28 1.3248565e-21], sum to 1.0000
[2019-03-23 13:51:23,547] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7801
[2019-03-23 13:51:23,554] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.43333333333333, 60.33333333333334, 1.0, 2.0, 0.4411856588475871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 479137.9928322767, 479137.9928322767, 102431.9347355129], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6514800.0000, 
sim time next is 6515400.0000, 
raw observation next is [18.61666666666667, 58.66666666666666, 1.0, 2.0, 0.4480957039537811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 486646.2203065782, 486646.2203065782, 102926.6476983468], 
processed observation next is [1.0, 0.391304347826087, 0.48257575757575777, 0.5866666666666666, 1.0, 1.0, 0.31011962994222636, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18023934085428822, 0.18023934085428822, 0.2510406041423093], 
reward next is 0.7490, 
noisyNet noise sample is [array([2.2714171], dtype=float32), 0.873177]. 
=============================================
[2019-03-23 13:51:25,415] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.0677530e-13 1.0000000e+00 9.6503796e-32 9.0008204e-29 2.1691650e-21], sum to 1.0000
[2019-03-23 13:51:25,427] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1226
[2019-03-23 13:51:25,437] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 54.0, 1.0, 2.0, 0.2700592511002521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 293234.6537843908, 293234.6537843905, 84144.02590101304], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6548400.0000, 
sim time next is 6549000.0000, 
raw observation next is [19.21666666666667, 54.66666666666666, 1.0, 2.0, 0.2683057285627661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 291330.080690488, 291330.0806904877, 83642.44664131706], 
processed observation next is [1.0, 0.8260869565217391, 0.5098484848484849, 0.5466666666666665, 1.0, 1.0, 0.08538216070345758, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10790002988536591, 0.10790002988536582, 0.2040059674178465], 
reward next is 0.7960, 
noisyNet noise sample is [array([-1.8015373], dtype=float32), -2.4854991]. 
=============================================
[2019-03-23 13:51:25,452] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[79.96981 ]
 [79.96181 ]
 [79.99506 ]
 [80.054726]
 [80.11459 ]], R is [[79.90736389]
 [79.90306091]
 [79.89756775]
 [79.89072418]
 [79.88227081]].
[2019-03-23 13:51:28,250] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.8777917e-10 1.0000000e+00 9.7900392e-28 2.5458621e-26 7.8795842e-20], sum to 1.0000
[2019-03-23 13:51:28,263] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6796
[2019-03-23 13:51:28,269] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.68333333333333, 62.33333333333333, 1.0, 2.0, 0.4664964862048044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 506640.4699528163, 506640.4699528163, 115663.1891734445], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6603000.0000, 
sim time next is 6603600.0000, 
raw observation next is [19.96666666666667, 61.66666666666667, 1.0, 2.0, 0.4940909913579444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 536626.1401851707, 536626.1401851707, 120845.4174934113], 
processed observation next is [1.0, 0.43478260869565216, 0.5439393939393941, 0.6166666666666667, 1.0, 1.0, 0.36761373919743046, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19875042229080395, 0.19875042229080395, 0.2947449207156373], 
reward next is 0.7053, 
noisyNet noise sample is [array([-1.1889982], dtype=float32), -0.36954582]. 
=============================================
[2019-03-23 13:51:29,864] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.6739275e-08 1.0000000e+00 2.6645952e-24 2.9763280e-23 2.0126176e-15], sum to 1.0000
[2019-03-23 13:51:29,870] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7180
[2019-03-23 13:51:29,876] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 64.0, 1.0, 2.0, 0.7208717013685272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 810957.5404104303, 810957.5404104306, 159799.9708476197], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6620400.0000, 
sim time next is 6621000.0000, 
raw observation next is [22.61666666666667, 64.33333333333334, 1.0, 2.0, 0.7905606651379847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 889444.2811771238, 889444.2811771238, 169283.4276789641], 
processed observation next is [1.0, 0.6521739130434783, 0.6643939393939395, 0.6433333333333334, 1.0, 1.0, 0.7382008314224808, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.32942380784337916, 0.32942380784337916, 0.41288640897308315], 
reward next is 0.5871, 
noisyNet noise sample is [array([-0.6637872], dtype=float32), 1.151306]. 
=============================================
[2019-03-23 13:51:29,892] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[62.897995]
 [62.86182 ]
 [62.82995 ]
 [62.778122]
 [62.70451 ]], R is [[62.76044083]
 [62.74308014]
 [62.72516251]
 [62.71173477]
 [62.70426559]].
[2019-03-23 13:51:34,262] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.0281736e-10 1.0000000e+00 1.0897452e-25 2.7435632e-24 1.4663911e-16], sum to 1.0000
[2019-03-23 13:51:34,271] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9646
[2019-03-23 13:51:34,279] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.3661041197434904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 408521.7013301789, 408521.7013301786, 119921.4914555787], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6718800.0000, 
sim time next is 6719400.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.362862227404659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 404894.5177067375, 404894.5177067378, 119652.1568348116], 
processed observation next is [1.0, 0.782608695652174, 0.4681818181818182, 0.93, 1.0, 1.0, 0.20357778425582373, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14996093248397685, 0.14996093248397696, 0.2918345288653941], 
reward next is 0.7082, 
noisyNet noise sample is [array([0.7397336], dtype=float32), 1.5148661]. 
=============================================
[2019-03-23 13:51:50,374] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.6602834e-09 1.0000000e+00 3.4903687e-23 1.9550042e-20 9.9380182e-15], sum to 1.0000
[2019-03-23 13:51:50,384] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2309
[2019-03-23 13:51:50,390] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.1, 95.0, 1.0, 2.0, 0.6832456451544126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 772712.1447312009, 772712.1447312005, 157101.6554464182], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7036200.0000, 
sim time next is 7036800.0000, 
raw observation next is [19.2, 94.33333333333334, 1.0, 2.0, 0.6760761142325337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 764717.1508635818, 764717.1508635822, 156242.5356159805], 
processed observation next is [1.0, 0.43478260869565216, 0.509090909090909, 0.9433333333333335, 1.0, 1.0, 0.595095142790667, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2832285743939192, 0.2832285743939193, 0.38107935516092806], 
reward next is 0.6189, 
noisyNet noise sample is [array([1.0654012], dtype=float32), 1.3958999]. 
=============================================
[2019-03-23 13:51:51,714] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.4774952e-12 1.0000000e+00 9.0652660e-27 3.8743572e-26 2.1258522e-16], sum to 1.0000
[2019-03-23 13:51:51,725] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7401
[2019-03-23 13:51:51,729] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 84.0, 1.0, 2.0, 0.3700653421316013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 413261.1054237763, 413261.1054237766, 120386.6984407425], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7066800.0000, 
sim time next is 7067400.0000, 
raw observation next is [19.3, 85.0, 1.0, 2.0, 0.3687039892438073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 411688.2088338785, 411688.2088338782, 120251.2528987242], 
processed observation next is [1.0, 0.8260869565217391, 0.5136363636363637, 0.85, 1.0, 1.0, 0.21087998655475912, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15247711438291797, 0.15247711438291786, 0.2932957387773761], 
reward next is 0.7067, 
noisyNet noise sample is [array([-0.6789302], dtype=float32), -1.1229904]. 
=============================================
[2019-03-23 13:51:52,939] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.3883982e-10 1.0000000e+00 1.0660581e-24 1.4277092e-23 3.4576613e-16], sum to 1.0000
[2019-03-23 13:51:52,946] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6955
[2019-03-23 13:51:52,950] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.2, 90.5, 1.0, 2.0, 0.3473662740136099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 385482.9183934183, 385482.9183934185, 117501.7799569425], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7081800.0000, 
sim time next is 7082400.0000, 
raw observation next is [18.1, 91.0, 1.0, 2.0, 0.3452921885978212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 382925.0684406343, 382925.0684406343, 117236.0947227413], 
processed observation next is [1.0, 1.0, 0.45909090909090916, 0.91, 1.0, 1.0, 0.18161523574727645, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14182409942245713, 0.14182409942245713, 0.2859416944457105], 
reward next is 0.7141, 
noisyNet noise sample is [array([0.03837796], dtype=float32), -0.717539]. 
=============================================
[2019-03-23 13:51:53,416] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 13:51:53,417] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:51:53,418] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:51:53,418] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:51:53,419] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:51:53,421] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:51:53,422] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:51:53,423] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:51:53,424] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:51:53,425] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:51:53,426] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:51:53,435] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run34
[2019-03-23 13:51:53,463] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run34
[2019-03-23 13:51:53,491] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run34
[2019-03-23 13:51:53,492] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run34
[2019-03-23 13:51:53,528] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run34
[2019-03-23 13:52:01,427] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08283317], dtype=float32), 0.24618441]
[2019-03-23 13:52:01,428] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.75116173166667, 83.80800532666667, 1.0, 2.0, 0.3142828874823235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 341247.3972244958, 341247.3972244958, 116466.7721662475]
[2019-03-23 13:52:01,429] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:52:01,431] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.5549660e-10 1.0000000e+00 1.2271873e-27 1.1201506e-25 8.4598268e-18], sampled 0.410943927103932
[2019-03-23 13:52:10,261] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08283317], dtype=float32), 0.24618441]
[2019-03-23 13:52:10,261] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.56666666666667, 85.0, 1.0, 2.0, 0.3652735472848524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 408862.0143241592, 408862.0143241592, 124744.3454606259]
[2019-03-23 13:52:10,262] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:52:10,264] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.934616e-10 1.000000e+00 9.210654e-28 8.581418e-26 7.046616e-18], sampled 0.813276529440874
[2019-03-23 13:52:38,948] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08283317], dtype=float32), 0.24618441]
[2019-03-23 13:52:38,952] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.3, 56.5, 1.0, 2.0, 0.4953350218803411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 565164.5804990509, 565164.5804990504, 144842.4860271329]
[2019-03-23 13:52:38,952] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:52:38,957] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.1154031e-10 1.0000000e+00 5.9971456e-28 5.7663489e-26 5.3626847e-18], sampled 0.06697120644997023
[2019-03-23 13:52:43,769] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08283317], dtype=float32), 0.24618441]
[2019-03-23 13:52:43,771] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [29.06666666666667, 52.16666666666667, 1.0, 2.0, 0.5344774230063417, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8954544888586108, 7.022703828498742, 6.9112, 95.55288146146164, 1156458.95827531, 1111710.007425744, 259033.5804805379]
[2019-03-23 13:52:43,772] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:52:43,774] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.4631109e-09 1.0000000e+00 1.2517598e-26 9.6698343e-25 3.7144125e-17], sampled 0.8867164791172844
[2019-03-23 13:52:43,775] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1156458.95827531 W.
[2019-03-23 13:52:44,930] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08283317], dtype=float32), 0.24618441]
[2019-03-23 13:52:44,933] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.67075158, 99.6409684, 1.0, 2.0, 0.4364386422763396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 497771.845901344, 497771.8459013437, 137392.867571119]
[2019-03-23 13:52:44,934] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:52:44,938] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.2949340e-10 1.0000000e+00 1.0924995e-27 1.0058139e-25 7.8576798e-18], sampled 0.8468685477204098
[2019-03-23 13:52:55,856] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08283317], dtype=float32), 0.24618441]
[2019-03-23 13:52:55,858] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.56995997666667, 71.13083791000001, 1.0, 2.0, 0.3745757848865715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 406735.3952794043, 406735.3952794039, 112612.2635861283]
[2019-03-23 13:52:55,859] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:52:55,864] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.2022717e-09 1.0000000e+00 7.0928888e-27 5.7048488e-25 2.5863996e-17], sampled 0.03263218765421305
[2019-03-23 13:52:59,684] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08283317], dtype=float32), 0.24618441]
[2019-03-23 13:52:59,689] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.99980244333334, 49.14610695333334, 1.0, 2.0, 0.4374287329326082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 493304.4542293992, 493304.4542293992, 132842.297152792]
[2019-03-23 13:52:59,689] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:52:59,691] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.8243333e-10 1.0000000e+00 1.3798639e-27 1.2492798e-25 9.1176413e-18], sampled 0.7127481040102375
[2019-03-23 13:53:12,052] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08283317], dtype=float32), 0.24618441]
[2019-03-23 13:53:12,054] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [29.9, 54.66666666666667, 1.0, 2.0, 0.5575721078277899, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 631144.1481702137, 631144.148170214, 151963.1424713912]
[2019-03-23 13:53:12,057] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:53:12,059] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.8929340e-10 1.0000000e+00 1.4203728e-27 1.2830836e-25 9.2859866e-18], sampled 0.6980637440140426
[2019-03-23 13:53:34,361] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 13:53:34,935] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 13:53:35,001] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 13:53:35,014] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 13:53:35,282] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 13:53:36,299] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 825000, evaluation results [825000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 13:53:38,013] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3795897e-09 1.0000000e+00 8.8814635e-25 1.1906096e-22 1.7094871e-16], sum to 1.0000
[2019-03-23 13:53:38,022] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7140
[2019-03-23 13:53:38,027] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 50.0, 1.0, 2.0, 0.7561887122876212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 837882.8995001295, 837882.8995001292, 159137.0887438078], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7135200.0000, 
sim time next is 7135800.0000, 
raw observation next is [23.9, 50.0, 1.0, 2.0, 0.7655096294785052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 848876.6099856443, 848876.6099856443, 160578.4132777144], 
processed observation next is [1.0, 0.6086956521739131, 0.7227272727272727, 0.5, 1.0, 1.0, 0.7068870368481314, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3143987444391275, 0.3143987444391275, 0.3916546665310107], 
reward next is 0.6083, 
noisyNet noise sample is [array([-0.24617964], dtype=float32), -0.2651489]. 
=============================================
[2019-03-23 13:53:43,017] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.3548767e-09 1.0000000e+00 3.1169899e-22 3.9668654e-21 2.7071383e-14], sum to 1.0000
[2019-03-23 13:53:43,023] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1640
[2019-03-23 13:53:43,029] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.61666666666667, 88.16666666666667, 1.0, 2.0, 0.2037970093324619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221269.6857737168, 221269.6857737165, 70483.28859984057], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7186200.0000, 
sim time next is 7186800.0000, 
raw observation next is [12.53333333333333, 88.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 209189.046739566, 209189.0467395657, 68912.69728904047], 
processed observation next is [1.0, 0.17391304347826086, 0.2060606060606059, 0.8833333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07747742471835778, 0.07747742471835767, 0.16807974948546456], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3113191], dtype=float32), -0.6484204]. 
=============================================
[2019-03-23 13:53:43,264] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.7404136e-10 1.0000000e+00 8.6154935e-27 1.4542571e-25 1.2875360e-17], sum to 1.0000
[2019-03-23 13:53:43,271] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8593
[2019-03-23 13:53:43,275] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.8, 61.66666666666667, 1.0, 2.0, 0.2830968592876287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 307395.571235453, 307395.5712354532, 97145.24285914683], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7247400.0000, 
sim time next is 7248000.0000, 
raw observation next is [19.6, 62.33333333333334, 1.0, 2.0, 0.2807770657241773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 304875.8760690626, 304875.8760690623, 95769.0283645501], 
processed observation next is [1.0, 0.9130434782608695, 0.5272727272727273, 0.6233333333333334, 1.0, 1.0, 0.10097133215522164, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11291699113668986, 0.11291699113668974, 0.2335829960110978], 
reward next is 0.7664, 
noisyNet noise sample is [array([-0.4555605], dtype=float32), 2.2004924]. 
=============================================
[2019-03-23 13:53:43,301] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[72.50873]
 [72.5707 ]
 [72.62925]
 [72.7224 ]
 [72.8364 ]], R is [[72.45171356]
 [72.49025726]
 [72.52513123]
 [72.55849457]
 [72.59023285]].
[2019-03-23 13:53:43,686] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.7876933e-08 9.9999988e-01 2.2720457e-26 9.2221021e-23 9.7534182e-16], sum to 1.0000
[2019-03-23 13:53:43,693] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9541
[2019-03-23 13:53:43,696] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.68333333333334, 58.33333333333334, 1.0, 2.0, 0.2988249430095178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 324479.3220947147, 324479.3220947147, 103534.3998359933], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7242600.0000, 
sim time next is 7243200.0000, 
raw observation next is [20.5, 59.0, 1.0, 2.0, 0.2977164880330632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 323275.305243805, 323275.305243805, 102316.541528238], 
processed observation next is [1.0, 0.8695652173913043, 0.5681818181818182, 0.59, 1.0, 1.0, 0.12214561004132901, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1197315945347426, 0.1197315945347426, 0.2495525403127756], 
reward next is 0.7504, 
noisyNet noise sample is [array([1.379766], dtype=float32), 0.27699757]. 
=============================================
[2019-03-23 13:53:44,607] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.3726311e-10 1.0000000e+00 5.2044736e-27 1.0005029e-24 5.3524889e-17], sum to 1.0000
[2019-03-23 13:53:44,615] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6966
[2019-03-23 13:53:44,618] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.08333333333334, 60.66666666666666, 1.0, 2.0, 0.2853586830823161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 309852.3138230828, 309852.3138230831, 98969.80659904538], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7246200.0000, 
sim time next is 7246800.0000, 
raw observation next is [20.0, 61.0, 1.0, 2.0, 0.28469954360012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 309136.3699289783, 309136.369928978, 98494.12515126042], 
processed observation next is [1.0, 0.9130434782608695, 0.5454545454545454, 0.61, 1.0, 1.0, 0.10587442950015, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11449495182554753, 0.11449495182554739, 0.24022957353965957], 
reward next is 0.7598, 
noisyNet noise sample is [array([-0.47604978], dtype=float32), 0.7451344]. 
=============================================
[2019-03-23 13:53:45,001] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.8087876e-09 1.0000000e+00 1.0156633e-21 6.5462209e-21 2.6664086e-14], sum to 1.0000
[2019-03-23 13:53:45,009] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0740
[2019-03-23 13:53:45,015] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.9, 85.0, 1.0, 2.0, 0.2577390920835942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 279853.379227705, 279853.3792277047, 86506.02304641611], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7260000.0000, 
sim time next is 7260600.0000, 
raw observation next is [15.45, 87.5, 1.0, 2.0, 0.2526924119798361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 274372.142952981, 274372.142952981, 84778.48586601549], 
processed observation next is [1.0, 0.0, 0.3386363636363636, 0.875, 1.0, 1.0, 0.06586551497479512, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10161931220480777, 0.10161931220480777, 0.20677679479515973], 
reward next is 0.7932, 
noisyNet noise sample is [array([-0.9926653], dtype=float32), 0.3182493]. 
=============================================
[2019-03-23 13:53:45,375] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.6416269e-09 1.0000000e+00 6.6268815e-26 3.9961440e-23 6.4271966e-15], sum to 1.0000
[2019-03-23 13:53:45,384] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9687
[2019-03-23 13:53:45,389] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 45.16666666666666, 1.0, 2.0, 0.7350119294773526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 809253.9654518678, 809253.9654518678, 154628.7765619297], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7229400.0000, 
sim time next is 7230000.0000, 
raw observation next is [24.2, 45.33333333333334, 1.0, 2.0, 0.6861608458836511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 754372.3602680558, 754372.3602680558, 148444.0179704602], 
processed observation next is [1.0, 0.6956521739130435, 0.7363636363636363, 0.4533333333333334, 1.0, 1.0, 0.6077010573545638, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2793971704696503, 0.2793971704696503, 0.3620585804157566], 
reward next is 0.6379, 
noisyNet noise sample is [array([-0.9404558], dtype=float32), 0.3113549]. 
=============================================
[2019-03-23 13:53:45,410] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[68.82441 ]
 [68.62358 ]
 [68.60715 ]
 [68.521286]
 [68.394394]], R is [[68.94804382]
 [68.88142395]
 [68.79204559]
 [68.71581268]
 [68.64128113]].
[2019-03-23 13:53:51,166] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.4808500e-11 1.0000000e+00 1.1567135e-25 1.1231896e-23 5.0938967e-17], sum to 1.0000
[2019-03-23 13:53:51,171] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7417
[2019-03-23 13:53:51,174] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.55, 71.5, 1.0, 2.0, 0.3487961044847705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 386515.8965156064, 386515.8965156067, 117389.7122426689], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7338600.0000, 
sim time next is 7339200.0000, 
raw observation next is [20.36666666666667, 72.66666666666667, 1.0, 2.0, 0.3481321985366734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 385685.2244684424, 385685.2244684421, 117300.201846574], 
processed observation next is [1.0, 0.9565217391304348, 0.5621212121212124, 0.7266666666666667, 1.0, 1.0, 0.1851652481708417, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14284637943275644, 0.14284637943275633, 0.2860980532843268], 
reward next is 0.7139, 
noisyNet noise sample is [array([0.765002], dtype=float32), -1.2624056]. 
=============================================
[2019-03-23 13:53:52,054] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2352257e-06 9.9999881e-01 2.2672796e-20 1.7525412e-18 3.1452724e-13], sum to 1.0000
[2019-03-23 13:53:52,061] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9931
[2019-03-23 13:53:52,067] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 87.0, 1.0, 2.0, 0.3204696956654531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 350019.2557839059, 350019.2557839059, 113291.1240398766], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7362000.0000, 
sim time next is 7362600.0000, 
raw observation next is [17.7, 87.0, 1.0, 2.0, 0.3313593725374721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 361938.7861155505, 361938.7861155505, 114074.6019045904], 
processed observation next is [1.0, 0.21739130434782608, 0.44090909090909086, 0.87, 1.0, 1.0, 0.16419921567184012, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13405140226501872, 0.13405140226501872, 0.2782307363526595], 
reward next is 0.7218, 
noisyNet noise sample is [array([0.9756396], dtype=float32), 0.90916693]. 
=============================================
[2019-03-23 13:53:53,037] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.8922203e-08 1.0000000e+00 1.8956340e-22 1.7012078e-21 9.9347912e-16], sum to 1.0000
[2019-03-23 13:53:53,045] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5318
[2019-03-23 13:53:53,049] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.86666666666667, 85.66666666666667, 1.0, 2.0, 0.4256557708567498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 483202.8044534911, 483202.8044534911, 129375.4730782821], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7417200.0000, 
sim time next is 7417800.0000, 
raw observation next is [20.5, 87.5, 1.0, 2.0, 0.4214021220898271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 477953.581283025, 477953.5812830247, 128656.1907107599], 
processed observation next is [1.0, 0.8695652173913043, 0.5681818181818182, 0.875, 1.0, 1.0, 0.2767526526122838, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17701984491963887, 0.17701984491963876, 0.3137955870994144], 
reward next is 0.6862, 
noisyNet noise sample is [array([-1.0146687], dtype=float32), -0.58359593]. 
=============================================
[2019-03-23 13:53:56,032] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.8837280e-09 1.0000000e+00 3.3893089e-24 3.8483648e-23 3.6164448e-16], sum to 1.0000
[2019-03-23 13:53:56,042] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4221
[2019-03-23 13:53:56,049] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.53333333333333, 96.66666666666667, 1.0, 2.0, 0.356478451827405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 395872.0790086445, 395872.0790086445, 118329.4115254956], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7435200.0000, 
sim time next is 7435800.0000, 
raw observation next is [17.45, 96.5, 1.0, 2.0, 0.3541708469446268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 392692.8397521357, 392692.8397521357, 117896.9893693396], 
processed observation next is [0.0, 0.043478260869565216, 0.4295454545454545, 0.965, 1.0, 1.0, 0.1927135586807835, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.145441792500791, 0.145441792500791, 0.28755363260814537], 
reward next is 0.7124, 
noisyNet noise sample is [array([-1.2949464], dtype=float32), 0.54922295]. 
=============================================
[2019-03-23 13:54:01,697] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4279437e-08 1.0000000e+00 1.0064641e-22 1.5424938e-20 2.5993720e-13], sum to 1.0000
[2019-03-23 13:54:01,707] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6539
[2019-03-23 13:54:01,710] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.2, 56.16666666666667, 1.0, 2.0, 0.5061700043625438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576893.0009884045, 576893.0009884045, 143291.9260216209], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7567800.0000, 
sim time next is 7568400.0000, 
raw observation next is [28.1, 56.33333333333334, 1.0, 2.0, 0.504418069118668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 574992.9498880189, 574992.9498880189, 142972.8136656805], 
processed observation next is [0.0, 0.6086956521739131, 0.9136363636363637, 0.5633333333333335, 1.0, 1.0, 0.380522586398335, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21296035181037737, 0.21296035181037737, 0.3487141796723915], 
reward next is 0.6513, 
noisyNet noise sample is [array([0.34720302], dtype=float32), -0.11806629]. 
=============================================
[2019-03-23 13:54:02,460] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.1868669e-09 1.0000000e+00 5.6185464e-25 1.1903507e-22 1.2308277e-16], sum to 1.0000
[2019-03-23 13:54:02,467] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3144
[2019-03-23 13:54:02,472] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 95.5, 1.0, 2.0, 0.4347207577195493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 494317.936026263, 494317.9360262627, 130931.2372638307], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7595400.0000, 
sim time next is 7596000.0000, 
raw observation next is [20.0, 96.0, 1.0, 2.0, 0.4365173406285046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 496513.2129724653, 496513.2129724656, 131247.8562464824], 
processed observation next is [0.0, 0.9565217391304348, 0.5454545454545454, 0.96, 1.0, 1.0, 0.29564667578563075, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18389378258239455, 0.18389378258239467, 0.3201167225523961], 
reward next is 0.6799, 
noisyNet noise sample is [array([-0.5882582], dtype=float32), 2.1696966]. 
=============================================
[2019-03-23 13:54:02,492] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[67.57715 ]
 [67.55447 ]
 [67.53428 ]
 [67.514015]
 [67.50196 ]], R is [[67.63039398]
 [67.63475037]
 [67.63985443]
 [67.64601898]
 [67.65332031]].
[2019-03-23 13:54:04,795] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7995438e-09 1.0000000e+00 1.6807563e-25 2.3313293e-24 3.3272688e-16], sum to 1.0000
[2019-03-23 13:54:04,802] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8022
[2019-03-23 13:54:04,805] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.15, 61.0, 1.0, 2.0, 0.4254327779634485, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8616735469502547, 6.9112, 6.9112, 77.32846344354104, 968293.8463257789, 968293.8463257789, 236141.714468414], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7648200.0000, 
sim time next is 7648800.0000, 
raw observation next is [27.33333333333334, 59.66666666666667, 1.0, 2.0, 0.887721819139126, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1012119.621423438, 1012119.621423438, 199648.8369315215], 
processed observation next is [1.0, 0.5217391304347826, 0.878787878787879, 0.5966666666666667, 1.0, 1.0, 0.8596522739239073, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3748591190457178, 0.3748591190457178, 0.48694838275980856], 
reward next is 0.5131, 
noisyNet noise sample is [array([0.13217579], dtype=float32), -0.9663502]. 
=============================================
[2019-03-23 13:54:17,117] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.0212269e-13 1.0000000e+00 2.3056537e-32 7.5920676e-29 3.7881725e-20], sum to 1.0000
[2019-03-23 13:54:17,124] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5941
[2019-03-23 13:54:17,129] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.2, 66.0, 1.0, 2.0, 0.2812109115149653, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 305347.1062927122, 305347.1062927125, 97498.09123523139], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7863600.0000, 
sim time next is 7864200.0000, 
raw observation next is [19.1, 66.5, 1.0, 2.0, 0.2781426360040095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 302014.4477021217, 302014.4477021214, 96807.5708909484], 
processed observation next is [1.0, 0.0, 0.5045454545454546, 0.665, 1.0, 1.0, 0.09767829500501188, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11185720285263766, 0.11185720285263756, 0.23611602656328876], 
reward next is 0.7639, 
noisyNet noise sample is [array([-0.7804909], dtype=float32), 1.6788613]. 
=============================================
[2019-03-23 13:54:20,821] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:54:20,821] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:54:20,827] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run5
[2019-03-23 13:54:21,209] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:54:21,209] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:54:21,211] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run5
[2019-03-23 13:54:21,240] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:54:21,241] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:54:21,242] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run5
[2019-03-23 13:54:21,264] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:54:21,265] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:54:21,267] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run5
[2019-03-23 13:54:21,290] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:54:21,290] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:54:21,291] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:54:21,291] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:54:21,294] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run5
[2019-03-23 13:54:21,329] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run5
[2019-03-23 13:54:21,356] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:54:21,356] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:54:21,358] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run5
[2019-03-23 13:54:21,399] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:54:21,400] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:54:21,401] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run5
[2019-03-23 13:54:21,571] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:54:21,572] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:54:21,573] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run5
[2019-03-23 13:54:21,661] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:54:21,661] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:54:21,662] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run5
[2019-03-23 13:54:21,737] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:54:21,738] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:54:21,740] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run5
[2019-03-23 13:54:21,770] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:54:21,770] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:54:21,772] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run5
[2019-03-23 13:54:21,813] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:54:21,813] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:54:21,815] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run5
[2019-03-23 13:54:21,993] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:54:21,993] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:54:21,994] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run5
[2019-03-23 13:54:22,076] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:54:22,076] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:54:22,078] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run5
[2019-03-23 13:54:22,177] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:54:22,177] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:54:22,179] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run5
[2019-03-23 13:54:23,887] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.0126267e-11 1.0000000e+00 1.4549832e-26 4.2370607e-24 1.4860192e-19], sum to 1.0000
[2019-03-23 13:54:23,893] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6409
[2019-03-23 13:54:23,904] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 95.0, 1.0, 2.0, 0.3657822884346946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 406866.275000817, 406866.2750008167, 119343.6929902378], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 18600.0000, 
sim time next is 19200.0000, 
raw observation next is [17.66666666666667, 96.0, 1.0, 2.0, 0.3554738781628841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 395055.3200971914, 395055.3200971914, 118372.8525196534], 
processed observation next is [1.0, 0.21739130434782608, 0.4393939393939396, 0.96, 1.0, 1.0, 0.19434234770360512, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.146316785221182, 0.146316785221182, 0.28871427443817904], 
reward next is 0.7113, 
noisyNet noise sample is [array([0.46563452], dtype=float32), 0.956256]. 
=============================================
[2019-03-23 13:54:27,122] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 13:54:27,122] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:54:27,123] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:54:27,124] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:54:27,129] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:54:27,129] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:54:27,130] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:54:27,131] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:54:27,133] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:54:27,134] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:54:27,134] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:54:27,146] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run35
[2019-03-23 13:54:27,146] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run35
[2019-03-23 13:54:27,196] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run35
[2019-03-23 13:54:27,227] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run35
[2019-03-23 13:54:27,252] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run35
[2019-03-23 13:54:43,079] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08413518], dtype=float32), 0.23981263]
[2019-03-23 13:54:43,081] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.88333333333333, 84.0, 1.0, 2.0, 0.4964785234186462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 566466.0895065366, 566466.0895065363, 145022.181110804]
[2019-03-23 13:54:43,083] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:54:43,084] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.1295214e-11 1.0000000e+00 2.4754631e-26 1.4180091e-24 8.8732946e-19], sampled 0.451252287837294
[2019-03-23 13:54:44,435] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08413518], dtype=float32), 0.23981263]
[2019-03-23 13:54:44,437] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [28.88333333333333, 52.83333333333334, 1.0, 2.0, 0.51834900826573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 590748.5558752979, 590748.5558752979, 149017.4023878403]
[2019-03-23 13:54:44,438] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:54:44,441] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.6238574e-11 1.0000000e+00 8.1949421e-27 5.0556814e-25 4.0636685e-19], sampled 0.3175555448647419
[2019-03-23 13:55:03,480] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08413518], dtype=float32), 0.23981263]
[2019-03-23 13:55:03,482] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.55, 78.50000000000001, 1.0, 2.0, 0.6886040028232437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 784619.0446479509, 784619.0446479509, 166690.399666971]
[2019-03-23 13:55:03,483] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:55:03,487] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.0066988e-11 1.0000000e+00 1.2430239e-25 6.3825537e-24 2.7755942e-18], sampled 0.3053423486202834
[2019-03-23 13:55:08,987] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08413518], dtype=float32), 0.23981263]
[2019-03-23 13:55:08,989] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.9, 89.0, 1.0, 2.0, 0.3618667802978426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 404371.6779060373, 404371.6779060369, 124152.5415386947]
[2019-03-23 13:55:08,989] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:55:08,994] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.6953444e-11 1.0000000e+00 1.8865262e-26 1.1002216e-24 7.3233210e-19], sampled 0.6867861021723946
[2019-03-23 13:55:14,541] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08413518], dtype=float32), 0.23981263]
[2019-03-23 13:55:14,542] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.79935465166667, 45.38439762333334, 1.0, 2.0, 0.2936418426139217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 318829.4689910953, 318829.4689910953, 95585.8327723918]
[2019-03-23 13:55:14,547] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:55:14,550] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.9118286e-11 1.0000000e+00 3.7725865e-26 2.0959454e-24 1.1956914e-18], sampled 0.654613029071672
[2019-03-23 13:55:45,137] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08413518], dtype=float32), 0.23981263]
[2019-03-23 13:55:45,141] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.8, 93.0, 1.0, 2.0, 0.3578030676074077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 396314.7667891281, 396314.7667891281, 122340.6849902104]
[2019-03-23 13:55:45,141] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:55:45,145] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.6408855e-11 1.0000000e+00 1.8212302e-26 1.0646033e-24 7.1448677e-19], sampled 0.9721042888372635
[2019-03-23 13:56:08,706] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 13:56:08,856] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 13:56:09,028] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 13:56:09,119] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 13:56:09,143] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 13:56:10,161] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 850000, evaluation results [850000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 13:56:13,178] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.6791910e-12 1.0000000e+00 5.7170645e-27 3.2366914e-25 7.3735752e-21], sum to 1.0000
[2019-03-23 13:56:13,183] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5558
[2019-03-23 13:56:13,188] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 40.5, 1.0, 2.0, 0.7292823569229089, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 792272.808342057, 792272.8083420567, 140042.3745130112], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 145800.0000, 
sim time next is 146400.0000, 
raw observation next is [22.33333333333334, 41.33333333333333, 1.0, 2.0, 0.721375858075303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 783676.4723637482, 783676.4723637486, 139024.9072993421], 
processed observation next is [1.0, 0.6956521739130435, 0.6515151515151518, 0.4133333333333333, 1.0, 1.0, 0.6517198225941286, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.29025054531990674, 0.2902505453199069, 0.33908513975449295], 
reward next is 0.6609, 
noisyNet noise sample is [array([-0.7775322], dtype=float32), 0.5065383]. 
=============================================
[2019-03-23 13:56:13,502] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.3855517e-11 1.0000000e+00 5.6010357e-27 1.2291095e-25 2.7878051e-20], sum to 1.0000
[2019-03-23 13:56:13,509] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5568
[2019-03-23 13:56:13,518] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 43.0, 1.0, 2.0, 0.6981357731928793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 758409.5850172472, 758409.5850172472, 136062.2582258721], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 147600.0000, 
sim time next is 148200.0000, 
raw observation next is [22.0, 43.0, 1.0, 2.0, 0.4344133911386353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 471779.5822537641, 471779.5822537638, 106283.9566524734], 
processed observation next is [1.0, 0.7391304347826086, 0.6363636363636364, 0.43, 1.0, 1.0, 0.2930167389232941, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17473317861250523, 0.17473317861250512, 0.2592291625670083], 
reward next is 0.7408, 
noisyNet noise sample is [array([0.0363149], dtype=float32), 0.9422378]. 
=============================================
[2019-03-23 13:56:14,099] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.1292002e-12 1.0000000e+00 1.5656549e-28 2.4143401e-26 3.7188321e-19], sum to 1.0000
[2019-03-23 13:56:14,109] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2886
[2019-03-23 13:56:14,113] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 39.0, 1.0, 2.0, 0.6723338292170249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 730358.9541540021, 730358.9541540021, 133656.6394845964], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 142800.0000, 
sim time next is 143400.0000, 
raw observation next is [23.0, 38.5, 1.0, 2.0, 0.6701915350130709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 728030.0278762782, 728030.0278762782, 132763.0217126779], 
processed observation next is [1.0, 0.6521739130434783, 0.6818181818181818, 0.385, 1.0, 1.0, 0.5877394187663386, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.26964075106528823, 0.26964075106528823, 0.3238122480797022], 
reward next is 0.6762, 
noisyNet noise sample is [array([0.07836045], dtype=float32), -1.0914423]. 
=============================================
[2019-03-23 13:56:14,377] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.1051451e-12 1.0000000e+00 4.9173844e-31 1.3682837e-29 3.2451759e-23], sum to 1.0000
[2019-03-23 13:56:14,386] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7703
[2019-03-23 13:56:14,390] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.5, 67.5, 1.0, 2.0, 0.2404846311690566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 261113.4381194207, 261113.4381194204, 77678.42940925216], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 163800.0000, 
sim time next is 164400.0000, 
raw observation next is [16.33333333333333, 69.0, 1.0, 2.0, 0.2373309832978029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 257688.3627707408, 257688.3627707406, 77420.80611241696], 
processed observation next is [1.0, 0.9130434782608695, 0.37878787878787856, 0.69, 1.0, 1.0, 0.0466637291222536, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09544013435953362, 0.09544013435953357, 0.18883123442052918], 
reward next is 0.8112, 
noisyNet noise sample is [array([1.9740286], dtype=float32), -1.7452147]. 
=============================================
[2019-03-23 13:56:19,425] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 13:56:19,431] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7689
[2019-03-23 13:56:19,436] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [13.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3590844044261597, 6.911199999999999, 6.9112, 77.32846344354104, 208843.8812389034, 208843.8812389036, 67826.29370655608], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 269400.0000, 
sim time next is 270000.0000, 
raw observation next is [13.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3587782533896932, 6.911199999999999, 6.9112, 77.32846344354104, 208665.7852702036, 208665.7852702039, 67806.3672149199], 
processed observation next is [0.0, 0.13043478260869565, 0.22727272727272727, 1.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.08396893341384747, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07728362417414948, 0.07728362417414959, 0.16538138345102413], 
reward next is 0.8346, 
noisyNet noise sample is [array([0.10173406], dtype=float32), -1.768514]. 
=============================================
[2019-03-23 13:56:19,459] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[62.28317 ]
 [62.784782]
 [62.88348 ]
 [63.84156 ]
 [64.50636 ]], R is [[62.16227341]
 [62.37522125]
 [62.58602524]
 [62.79464722]
 [63.00087738]].
[2019-03-23 13:56:25,963] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.3176223e-15 1.0000000e+00 0.0000000e+00 0.0000000e+00 3.7412256e-28], sum to 1.0000
[2019-03-23 13:56:25,970] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9003
[2019-03-23 13:56:25,975] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 50.16666666666667, 1.0, 2.0, 0.2896070239679668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 314466.8005416808, 314466.8005416805, 86195.34662635415], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 391800.0000, 
sim time next is 392400.0000, 
raw observation next is [20.0, 49.0, 1.0, 2.0, 0.2746885104922825, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 298262.719027712, 298262.7190277117, 83924.52017252569], 
processed observation next is [1.0, 0.5652173913043478, 0.5454545454545454, 0.49, 1.0, 1.0, 0.0933606381153531, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11046767371396742, 0.1104676737139673, 0.20469395164030657], 
reward next is 0.7953, 
noisyNet noise sample is [array([-2.2606983], dtype=float32), -0.7527055]. 
=============================================
[2019-03-23 13:56:29,107] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.2768308e-04 9.9917233e-01 3.8214021e-16 1.3409581e-15 7.2250295e-13], sum to 1.0000
[2019-03-23 13:56:29,116] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0922
[2019-03-23 13:56:29,122] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 212313.4768847729, 212313.4768847729, 72810.04844572564], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 429600.0000, 
sim time next is 430200.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 210937.9063881089, 210937.9063881086, 72559.69190559353], 
processed observation next is [1.0, 1.0, 0.22727272727272727, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07812515051411441, 0.0781251505141143, 0.17697485830632567], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.09708396], dtype=float32), -1.560541]. 
=============================================
[2019-03-23 13:56:35,732] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.0187521e-09 1.0000000e+00 6.7037222e-25 8.4051804e-24 4.1152905e-18], sum to 1.0000
[2019-03-23 13:56:35,741] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8525
[2019-03-23 13:56:35,748] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333334, 79.66666666666667, 1.0, 2.0, 0.5147092019884865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 561262.4332279164, 561262.4332279164, 128889.3663853579], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 559200.0000, 
sim time next is 559800.0000, 
raw observation next is [18.5, 78.0, 1.0, 2.0, 0.5128874074495675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558800.7929176929, 558800.7929176929, 128573.0938578495], 
processed observation next is [1.0, 0.4782608695652174, 0.4772727272727273, 0.78, 1.0, 1.0, 0.39110925931195933, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20696325663618256, 0.20696325663618256, 0.3135929118484134], 
reward next is 0.6864, 
noisyNet noise sample is [array([-0.5214851], dtype=float32), 0.05040988]. 
=============================================
[2019-03-23 13:56:43,977] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.4882846e-10 1.0000000e+00 1.9127666e-25 7.5186251e-23 6.2253336e-18], sum to 1.0000
[2019-03-23 13:56:43,983] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8165
[2019-03-23 13:56:43,990] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1142593.681442482 W.
[2019-03-23 13:56:43,998] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.33333333333333, 63.66666666666667, 1.0, 2.0, 0.3338689077686084, 1.0, 1.0, 0.3338689077686084, 1.0, 1.0, 0.6753476052083351, 6.9112, 6.9112, 77.3421103, 1142593.681442482, 1142593.681442482, 268618.6370945156], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 729600.0000, 
sim time next is 730200.0000, 
raw observation next is [25.66666666666667, 62.33333333333334, 1.0, 2.0, 0.3446590025381889, 1.0, 2.0, 0.3446590025381889, 1.0, 2.0, 0.6978113104764939, 6.9112, 6.9112, 77.3421103, 1178205.44804739, 1178205.44804739, 274541.5986248933], 
processed observation next is [1.0, 0.43478260869565216, 0.8030303030303032, 0.6233333333333334, 1.0, 1.0, 0.18082375317273608, 1.0, 1.0, 0.18082375317273608, 1.0, 1.0, 0.5683018721092771, 0.0, 0.0, 0.5085185399722538, 0.4363723881657, 0.4363723881657, 0.6696136551826666], 
reward next is 0.3304, 
noisyNet noise sample is [array([0.9133801], dtype=float32), -0.090146594]. 
=============================================
[2019-03-23 13:56:46,556] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.5651369e-10 1.0000000e+00 9.5280245e-24 5.2509491e-23 1.6200347e-17], sum to 1.0000
[2019-03-23 13:56:46,562] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3963
[2019-03-23 13:56:46,571] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 79.66666666666667, 1.0, 2.0, 0.4181039425875038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 474619.3480740498, 474619.3480740501, 128636.5502537897], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 781800.0000, 
sim time next is 782400.0000, 
raw observation next is [21.33333333333334, 81.33333333333334, 1.0, 2.0, 0.4160859360502679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 472010.4947658037, 472010.4947658037, 128208.5075530325], 
processed observation next is [0.0, 0.043478260869565216, 0.6060606060606063, 0.8133333333333335, 1.0, 1.0, 0.27010742006283484, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17481870176511247, 0.17481870176511247, 0.31270367695861584], 
reward next is 0.6873, 
noisyNet noise sample is [array([2.3031142], dtype=float32), 0.8194358]. 
=============================================
[2019-03-23 13:56:55,187] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.042250e-15 1.000000e+00 9.355417e-35 7.148579e-33 3.687633e-23], sum to 1.0000
[2019-03-23 13:56:55,192] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0647
[2019-03-23 13:56:55,196] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4113056906518553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 466268.5387472646, 466268.5387472649, 127529.0012909917], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 963000.0000, 
sim time next is 963600.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4069752088150342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 461346.7336140961, 461346.7336140964, 127112.2223812859], 
processed observation next is [1.0, 0.13043478260869565, 0.5, 1.0, 1.0, 1.0, 0.2587190110187927, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17086916059781337, 0.17086916059781349, 0.31002981068606317], 
reward next is 0.6900, 
noisyNet noise sample is [array([0.5634644], dtype=float32), -1.106128]. 
=============================================
[2019-03-23 13:56:57,730] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.0757041e-10 1.0000000e+00 8.3966713e-28 8.0103382e-25 4.9618297e-18], sum to 1.0000
[2019-03-23 13:56:57,736] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4806
[2019-03-23 13:56:57,742] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 100.0, 1.0, 2.0, 0.5974121650764935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 663447.7261132408, 663447.7261132408, 141004.9448589727], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 986400.0000, 
sim time next is 987000.0000, 
raw observation next is [16.83333333333334, 100.0, 1.0, 2.0, 0.6743811287930669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 747361.1448951832, 747361.1448951832, 149171.9985957403], 
processed observation next is [1.0, 0.43478260869565216, 0.40151515151515177, 1.0, 1.0, 1.0, 0.5929764109913336, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.276800424035253, 0.276800424035253, 0.36383414291643973], 
reward next is 0.6362, 
noisyNet noise sample is [array([2.376448], dtype=float32), -0.037427887]. 
=============================================
[2019-03-23 13:56:57,762] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[67.61811 ]
 [67.65768 ]
 [67.705086]
 [67.81221 ]
 [67.79809 ]], R is [[67.32335663]
 [67.30620575]
 [67.28862   ]
 [67.27143097]
 [67.26047516]].
[2019-03-23 13:56:58,061] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.9495347e-12 1.0000000e+00 9.5823049e-30 1.2874600e-28 3.0556193e-21], sum to 1.0000
[2019-03-23 13:56:58,067] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1598
[2019-03-23 13:56:58,069] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 100.0, 1.0, 2.0, 0.5334777920560477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 581984.6916891524, 581984.6916891524, 130726.2442204382], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 990000.0000, 
sim time next is 990600.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.5077320523078238, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 553143.9644882332, 553143.9644882332, 128087.5359890725], 
processed observation next is [1.0, 0.4782608695652174, 0.36363636363636365, 1.0, 1.0, 1.0, 0.38466506538477974, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20486813499564194, 0.20486813499564194, 0.31240862436359146], 
reward next is 0.6876, 
noisyNet noise sample is [array([0.55488867], dtype=float32), -1.2658341]. 
=============================================
[2019-03-23 13:56:58,627] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 13:56:58,629] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:56:58,630] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:56:58,633] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:56:58,634] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:56:58,635] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:56:58,635] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:56:58,635] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:56:58,637] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:56:58,638] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:56:58,637] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:56:58,653] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run36
[2019-03-23 13:56:58,678] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run36
[2019-03-23 13:56:58,703] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run36
[2019-03-23 13:56:58,703] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run36
[2019-03-23 13:56:58,753] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run36
[2019-03-23 13:57:03,785] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08605795], dtype=float32), 0.23155902]
[2019-03-23 13:57:03,787] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.3, 80.0, 1.0, 2.0, 0.6316630038412988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 689500.2147299928, 689500.2147299924, 145058.6056497122]
[2019-03-23 13:57:03,787] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:57:03,790] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.7431746e-12 1.0000000e+00 3.9044084e-30 2.6082518e-28 1.7056200e-21], sampled 0.0402636604195602
[2019-03-23 13:57:10,517] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08605795], dtype=float32), 0.23155902]
[2019-03-23 13:57:10,521] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.89869999, 94.84617747666665, 1.0, 2.0, 0.3224981693968624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 352493.6004182126, 352493.6004182126, 117841.7203145143]
[2019-03-23 13:57:10,522] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:57:10,524] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.93212135e-12 1.00000000e+00 1.50459962e-31 1.22867575e-29
 1.69944267e-22], sampled 0.6919213157372873
[2019-03-23 13:57:12,337] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08605795], dtype=float32), 0.23155902]
[2019-03-23 13:57:12,338] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.39011409, 88.73018602333335, 1.0, 2.0, 0.3095145389709785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 337167.4782339408, 337167.4782339408, 116524.4111807709]
[2019-03-23 13:57:12,340] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:57:12,342] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.2739219e-12 1.0000000e+00 2.2983926e-31 1.8279859e-29 2.2940585e-22], sampled 0.6250707103986833
[2019-03-23 13:57:43,754] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08605795], dtype=float32), 0.23155902]
[2019-03-23 13:57:43,755] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.84889739, 92.87998682, 1.0, 2.0, 0.4249419265741081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 482045.357224292, 482045.3572242917, 133390.6645462552]
[2019-03-23 13:57:43,757] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:57:43,759] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.7383264e-12 1.0000000e+00 1.1443509e-31 9.5051970e-30 1.3997484e-22], sampled 0.7429057217845729
[2019-03-23 13:57:47,925] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08605795], dtype=float32), 0.23155902]
[2019-03-23 13:57:47,926] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.072440805, 80.22171926499999, 1.0, 2.0, 0.2900465613247297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 314924.7735942358, 314924.7735942354, 99956.60587151875]
[2019-03-23 13:57:47,929] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:57:47,933] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.5964547e-12 1.0000000e+00 3.2589826e-31 2.5370940e-29 2.9374941e-22], sampled 0.1823122335796522
[2019-03-23 13:57:57,786] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08605795], dtype=float32), 0.23155902]
[2019-03-23 13:57:57,788] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.6, 90.0, 1.0, 2.0, 0.3026814572112543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 328647.1554622275, 328647.1554622279, 97731.53178607963]
[2019-03-23 13:57:57,790] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:57:57,794] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.0280457e-12 1.0000000e+00 4.8470235e-31 3.6812406e-29 3.8914286e-22], sampled 0.7016557797491839
[2019-03-23 13:58:00,463] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08605795], dtype=float32), 0.23155902]
[2019-03-23 13:58:00,464] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.141895955, 68.75191102, 1.0, 2.0, 0.4304112891227879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 488014.1715205982, 488014.1715205982, 133757.7849792704]
[2019-03-23 13:58:00,465] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:58:00,469] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.4498112e-12 1.0000000e+00 2.8016060e-31 2.2030550e-29 2.6399214e-22], sampled 0.6046780105280385
[2019-03-23 13:58:03,153] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08605795], dtype=float32), 0.23155902]
[2019-03-23 13:58:03,158] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.45, 49.33333333333334, 1.0, 2.0, 0.3984502529506651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 451215.1821128855, 451215.1821128855, 130334.9070172366]
[2019-03-23 13:58:03,160] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:58:03,162] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.4385387e-12 1.0000000e+00 2.7689240e-31 2.1783523e-29 2.6176293e-22], sampled 0.01817169471330138
[2019-03-23 13:58:39,943] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 13:58:40,179] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 13:58:40,331] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 13:58:40,391] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 13:58:40,618] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 13:58:41,637] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 875000, evaluation results [875000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 13:58:49,577] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1461221e-09 1.0000000e+00 6.8437271e-22 5.7972608e-22 1.7019643e-17], sum to 1.0000
[2019-03-23 13:58:49,586] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7714
[2019-03-23 13:58:49,592] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.624218064884321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 707928.7721485365, 707928.7721485368, 150909.0020377623], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1155600.0000, 
sim time next is 1156200.0000, 
raw observation next is [21.16666666666667, 82.16666666666667, 1.0, 2.0, 0.7213358074391799, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 818680.3407805809, 818680.3407805811, 163962.5713377817], 
processed observation next is [1.0, 0.391304347826087, 0.5984848484848487, 0.8216666666666668, 1.0, 1.0, 0.6516697592989747, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.30321494102984475, 0.30321494102984486, 0.39990871057995536], 
reward next is 0.6001, 
noisyNet noise sample is [array([0.07063042], dtype=float32), -1.5375018]. 
=============================================
[2019-03-23 13:58:50,349] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.8468965e-08 9.9999988e-01 4.6143753e-19 2.1905221e-18 9.0854440e-13], sum to 1.0000
[2019-03-23 13:58:50,356] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8068
[2019-03-23 13:58:50,360] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666666, 70.66666666666667, 1.0, 2.0, 0.711101243783071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 811649.7561770075, 811649.7561770077, 168537.3776626913], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1165200.0000, 
sim time next is 1165800.0000, 
raw observation next is [24.83333333333334, 69.83333333333333, 1.0, 2.0, 0.7348103687561904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 838729.3471525018, 838729.3471525015, 172159.640395507], 
processed observation next is [1.0, 0.4782608695652174, 0.7651515151515155, 0.6983333333333333, 1.0, 1.0, 0.668512960945238, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.31064049894537105, 0.31064049894537094, 0.419901561940261], 
reward next is 0.5801, 
noisyNet noise sample is [array([1.4061394], dtype=float32), -1.3683933]. 
=============================================
[2019-03-23 13:58:51,646] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0032741e-10 1.0000000e+00 3.7767998e-29 3.5849448e-26 2.1961091e-20], sum to 1.0000
[2019-03-23 13:58:51,650] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7103
[2019-03-23 13:58:51,654] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.524425208064203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 597025.8363248658, 597025.8363248655, 146092.7566254341], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1202400.0000, 
sim time next is 1203000.0000, 
raw observation next is [23.83333333333333, 84.0, 1.0, 2.0, 0.5249379835318629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 597658.9955382376, 597658.9955382376, 146118.8507153082], 
processed observation next is [1.0, 0.9565217391304348, 0.7196969696969695, 0.84, 1.0, 1.0, 0.40617247941482865, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2213551835326806, 0.2213551835326806, 0.3563874407690444], 
reward next is 0.6436, 
noisyNet noise sample is [array([1.9619286], dtype=float32), -0.6789085]. 
=============================================
[2019-03-23 13:58:51,672] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[70.83305 ]
 [70.79654 ]
 [70.79036 ]
 [70.773346]
 [70.75192 ]], R is [[70.77947998]
 [70.71536255]
 [70.65208435]
 [70.5897522 ]
 [70.5283432 ]].
[2019-03-23 13:58:56,395] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1311475e-11 1.0000000e+00 4.6795928e-26 8.3026317e-24 9.2715457e-18], sum to 1.0000
[2019-03-23 13:58:56,401] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9184
[2019-03-23 13:58:56,408] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 96.0, 1.0, 2.0, 0.3562506697715428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 395919.5867535276, 395919.5867535279, 118434.9442397721], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1300800.0000, 
sim time next is 1301400.0000, 
raw observation next is [17.5, 97.0, 1.0, 2.0, 0.3534197516592281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 392423.1792989468, 392423.1792989465, 118066.3259230504], 
processed observation next is [1.0, 0.043478260869565216, 0.4318181818181818, 0.97, 1.0, 1.0, 0.19177468957403512, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1453419182588692, 0.14534191825886908, 0.28796664859280585], 
reward next is 0.7120, 
noisyNet noise sample is [array([0.2641801], dtype=float32), -0.12688665]. 
=============================================
[2019-03-23 13:58:58,541] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.01885504e-11 1.00000000e+00 8.78069919e-26 2.87622788e-24
 1.02314326e-17], sum to 1.0000
[2019-03-23 13:58:58,547] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3072
[2019-03-23 13:58:58,551] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 93.16666666666667, 1.0, 2.0, 0.5699668308386217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 649970.6180745355, 649970.6180745352, 150781.3677545834], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1325400.0000, 
sim time next is 1326000.0000, 
raw observation next is [22.33333333333334, 92.33333333333334, 1.0, 2.0, 0.769311646553492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 877252.9453802031, 877252.9453802033, 179539.1819004332], 
processed observation next is [1.0, 0.34782608695652173, 0.6515151515151518, 0.9233333333333335, 1.0, 1.0, 0.711639558191865, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3249084982889641, 0.3249084982889642, 0.4379004436595932], 
reward next is 0.5621, 
noisyNet noise sample is [array([-0.8298419], dtype=float32), 0.42701954]. 
=============================================
[2019-03-23 13:58:58,569] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[62.798737]
 [63.063293]
 [63.312695]
 [63.383514]
 [63.466343]], R is [[61.69322205]
 [61.70853043]
 [61.73513031]
 [61.7784462 ]
 [61.82682419]].
[2019-03-23 13:59:02,755] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6414413e-08 1.0000000e+00 6.2381988e-24 5.6034701e-20 1.0792751e-16], sum to 1.0000
[2019-03-23 13:59:02,762] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5293
[2019-03-23 13:59:02,768] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 80.5, 1.0, 2.0, 0.5063503778681593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 577114.8536393715, 577114.8536393715, 143295.4240502509], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1423800.0000, 
sim time next is 1424400.0000, 
raw observation next is [24.0, 79.66666666666667, 1.0, 2.0, 0.5016480665104888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 571943.0704805969, 571943.0704805965, 142508.1779709401], 
processed observation next is [0.0, 0.4782608695652174, 0.7272727272727273, 0.7966666666666667, 1.0, 1.0, 0.3770600831381109, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2118307668446655, 0.21183076684466537, 0.34758092188034173], 
reward next is 0.6524, 
noisyNet noise sample is [array([0.94805163], dtype=float32), 0.5617746]. 
=============================================
[2019-03-23 13:59:05,579] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2482115e-12 1.0000000e+00 1.9705530e-30 2.2168079e-26 6.1602039e-18], sum to 1.0000
[2019-03-23 13:59:05,588] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7194
[2019-03-23 13:59:05,597] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 100.0, 1.0, 2.0, 0.4539092548523319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517702.0864592558, 517702.0864592558, 134791.1544931686], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1459200.0000, 
sim time next is 1459800.0000, 
raw observation next is [20.5, 100.0, 1.0, 2.0, 0.4593642760794168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 524066.4858245995, 524066.4858245997, 135743.0921905254], 
processed observation next is [0.0, 0.9130434782608695, 0.5681818181818182, 1.0, 1.0, 1.0, 0.324205345099271, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19409869845355537, 0.19409869845355543, 0.3310807126598181], 
reward next is 0.6689, 
noisyNet noise sample is [array([-1.1035727], dtype=float32), 0.42069337]. 
=============================================
[2019-03-23 13:59:06,691] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.3438484e-09 1.0000000e+00 2.0544969e-24 2.9089347e-23 8.9412219e-18], sum to 1.0000
[2019-03-23 13:59:06,699] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2175
[2019-03-23 13:59:06,711] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 98.0, 1.0, 2.0, 0.4888425109474595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 557361.9166576172, 557361.9166576172, 140978.1940865699], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1495200.0000, 
sim time next is 1495800.0000, 
raw observation next is [22.0, 97.0, 1.0, 2.0, 0.4968571669372808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 566134.3073804653, 566134.3073804653, 142336.779502821], 
processed observation next is [0.0, 0.30434782608695654, 0.6363636363636364, 0.97, 1.0, 1.0, 0.371071458671601, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20967937310387605, 0.20967937310387605, 0.3471628768361488], 
reward next is 0.6528, 
noisyNet noise sample is [array([1.2535393], dtype=float32), -1.0632836]. 
=============================================
[2019-03-23 13:59:22,465] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.0424916e-11 1.0000000e+00 1.1578717e-30 1.4383003e-27 4.9407248e-21], sum to 1.0000
[2019-03-23 13:59:22,473] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9181
[2019-03-23 13:59:22,479] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.16666666666667, 45.0, 1.0, 2.0, 0.4682673526405095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 508564.7329191666, 508564.7329191663, 99260.54145829595], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1779000.0000, 
sim time next is 1779600.0000, 
raw observation next is [19.33333333333334, 44.0, 1.0, 2.0, 0.4761166557537839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517094.0524603709, 517094.0524603709, 100425.7868358169], 
processed observation next is [1.0, 0.6086956521739131, 0.5151515151515155, 0.44, 1.0, 1.0, 0.34514581969222985, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19151631572606329, 0.19151631572606329, 0.24494094350199247], 
reward next is 0.7551, 
noisyNet noise sample is [array([0.36706173], dtype=float32), 1.4355497]. 
=============================================
[2019-03-23 13:59:24,283] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.4387379e-09 1.0000000e+00 2.5017593e-26 1.6423933e-23 4.5850927e-18], sum to 1.0000
[2019-03-23 13:59:24,291] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2448
[2019-03-23 13:59:24,293] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.66666666666667, 77.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 216920.116625292, 216920.116625292, 72142.7916756642], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1840800.0000, 
sim time next is 1841400.0000, 
raw observation next is [15.0, 75.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 217007.4697613968, 217007.4697613971, 72060.41501395663], 
processed observation next is [1.0, 0.30434782608695654, 0.3181818181818182, 0.75, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08037313694866548, 0.0803731369486656, 0.17575710979013814], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.76219696], dtype=float32), 0.44174746]. 
=============================================
[2019-03-23 13:59:30,275] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 13:59:30,279] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:59:30,279] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:59:30,280] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:59:30,281] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:59:30,281] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:59:30,282] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:59:30,281] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:59:30,283] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:59:30,284] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:59:30,283] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:59:30,301] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run37
[2019-03-23 13:59:30,327] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run37
[2019-03-23 13:59:30,328] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run37
[2019-03-23 13:59:30,329] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run37
[2019-03-23 13:59:30,387] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run37
[2019-03-23 14:00:03,733] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08605795], dtype=float32), 0.22852498]
[2019-03-23 14:00:03,734] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.8, 86.0, 1.0, 2.0, 0.4225763872306594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 479474.6333987897, 479474.6333987897, 133244.1165049381]
[2019-03-23 14:00:03,735] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:00:03,739] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.8485434e-09 1.0000000e+00 8.7769283e-23 2.5388277e-21 5.8249212e-16], sampled 0.06300520510375451
[2019-03-23 14:00:24,763] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08605795], dtype=float32), 0.22852498]
[2019-03-23 14:00:24,764] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.41093785333333, 83.01361795499999, 1.0, 2.0, 0.5807200997238909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 655012.0333716924, 655012.0333716924, 159983.8861472167]
[2019-03-23 14:00:24,765] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:00:24,773] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.6132434e-09 1.0000000e+00 1.7605199e-22 4.8621596e-21 9.4455153e-16], sampled 0.050799039469097584
[2019-03-23 14:00:44,823] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08605795], dtype=float32), 0.22852498]
[2019-03-23 14:00:44,824] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.98333333333333, 55.16666666666666, 1.0, 2.0, 0.292677316620009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 317781.932273409, 317781.932273409, 95192.04778057945]
[2019-03-23 14:00:44,825] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:00:44,829] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.1137888e-09 1.0000000e+00 2.8310125e-22 7.5811006e-21 1.3131571e-15], sampled 0.23530652586010836
[2019-03-23 14:00:50,106] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08605795], dtype=float32), 0.22852498]
[2019-03-23 14:00:50,110] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.85, 67.0, 1.0, 2.0, 0.2708327788422464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 294057.8605858401, 294057.8605858397, 98338.61181461586]
[2019-03-23 14:00:50,114] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:00:50,118] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.5110006e-08 1.0000000e+00 1.9187860e-20 3.8910041e-19 2.4501499e-14], sampled 0.20256702689625405
[2019-03-23 14:01:12,125] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 14:01:12,171] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:01:12,219] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 14:01:12,361] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 14:01:12,397] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 14:01:13,412] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 900000, evaluation results [900000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 14:01:14,554] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.3056125e-11 1.0000000e+00 8.1466530e-29 7.8086090e-27 1.0429592e-20], sum to 1.0000
[2019-03-23 14:01:14,556] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5787
[2019-03-23 14:01:14,562] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 64.66666666666667, 1.0, 2.0, 0.2511294644623122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 272674.6267190891, 272674.6267190894, 83078.8441110169], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1995000.0000, 
sim time next is 1995600.0000, 
raw observation next is [18.0, 65.33333333333334, 1.0, 2.0, 0.2505491779891404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 272044.3794841779, 272044.3794841781, 83485.27817849646], 
processed observation next is [0.0, 0.08695652173913043, 0.45454545454545453, 0.6533333333333334, 1.0, 1.0, 0.06318647248642548, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10075717758673255, 0.10075717758673262, 0.20362262970364992], 
reward next is 0.7964, 
noisyNet noise sample is [array([-1.234769], dtype=float32), 0.43143916]. 
=============================================
[2019-03-23 14:01:19,749] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.1084492e-11 1.0000000e+00 1.3863348e-31 3.8761232e-30 5.1674563e-21], sum to 1.0000
[2019-03-23 14:01:19,754] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2202
[2019-03-23 14:01:19,757] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 60.00000000000001, 1.0, 2.0, 0.2633521714196965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 285949.8584271665, 285949.8584271662, 86135.54585811684], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2071200.0000, 
sim time next is 2071800.0000, 
raw observation next is [19.0, 60.0, 1.0, 2.0, 0.2633868447400624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 285987.5180604642, 285987.5180604642, 86137.10863042015], 
processed observation next is [0.0, 1.0, 0.5, 0.6, 1.0, 1.0, 0.079233555925078, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10592130298535711, 0.10592130298535711, 0.21009050885468328], 
reward next is 0.7899, 
noisyNet noise sample is [array([-0.59885305], dtype=float32), -1.4335597]. 
=============================================
[2019-03-23 14:01:21,967] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5366786e-10 1.0000000e+00 2.8649503e-23 4.1002841e-23 3.2789596e-16], sum to 1.0000
[2019-03-23 14:01:21,976] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4466
[2019-03-23 14:01:21,980] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.23333333333333, 56.33333333333334, 1.0, 2.0, 0.3359119902307323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 373427.7569107942, 373427.7569107942, 116892.0331230313], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2110800.0000, 
sim time next is 2111400.0000, 
raw observation next is [23.35, 56.0, 1.0, 2.0, 0.3380947532414459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 376135.883429849, 376135.883429849, 117180.0699975291], 
processed observation next is [0.0, 0.43478260869565216, 0.6977272727272728, 0.56, 1.0, 1.0, 0.17261844155180733, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13930958645549962, 0.13930958645549962, 0.2858050487744612], 
reward next is 0.7142, 
noisyNet noise sample is [array([0.06818002], dtype=float32), 1.1069416]. 
=============================================
[2019-03-23 14:01:24,933] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4262938e-12 1.0000000e+00 9.8665120e-30 1.3215211e-27 3.1085000e-22], sum to 1.0000
[2019-03-23 14:01:24,946] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5319
[2019-03-23 14:01:24,952] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 61.0, 1.0, 2.0, 0.3693062975049223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 412073.5938750424, 412073.5938750424, 120174.1069010847], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2151000.0000, 
sim time next is 2151600.0000, 
raw observation next is [22.33333333333334, 58.33333333333333, 1.0, 2.0, 0.3544582400222306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 392324.1735296901, 392324.1735296898, 117646.0246315732], 
processed observation next is [0.0, 0.9130434782608695, 0.6515151515151518, 0.5833333333333333, 1.0, 1.0, 0.1930728000277882, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14530524945544077, 0.14530524945544065, 0.2869415234916419], 
reward next is 0.7131, 
noisyNet noise sample is [array([-0.04116949], dtype=float32), 0.30509856]. 
=============================================
[2019-03-23 14:01:36,771] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.3285006e-09 1.0000000e+00 6.1933046e-27 1.9839394e-24 8.6500034e-20], sum to 1.0000
[2019-03-23 14:01:36,778] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9588
[2019-03-23 14:01:36,782] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 48.33333333333334, 1.0, 2.0, 0.3086029938471158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 335100.4852159505, 335100.4852159508, 96542.87796863068], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2395200.0000, 
sim time next is 2395800.0000, 
raw observation next is [21.5, 49.5, 1.0, 2.0, 0.2970670769777586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 322569.9086915394, 322569.9086915394, 95148.90058355757], 
processed observation next is [1.0, 0.7391304347826086, 0.6136363636363636, 0.495, 1.0, 1.0, 0.12133384622219821, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.119470336552422, 0.119470336552422, 0.23207048922818918], 
reward next is 0.7679, 
noisyNet noise sample is [array([-0.01660866], dtype=float32), 0.08174966]. 
=============================================
[2019-03-23 14:01:49,547] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.8429206e-10 1.0000000e+00 7.7891012e-25 5.2267451e-24 1.1333202e-17], sum to 1.0000
[2019-03-23 14:01:49,557] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3767
[2019-03-23 14:01:49,561] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 45.33333333333334, 1.0, 2.0, 0.3382224910392259, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 375943.5498696246, 375943.5498696246, 117047.9062609873], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2632800.0000, 
sim time next is 2633400.0000, 
raw observation next is [25.5, 44.5, 1.0, 2.0, 0.3365027540866403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 373957.9669475067, 373957.966947507, 116883.9812712907], 
processed observation next is [0.0, 0.4782608695652174, 0.7954545454545454, 0.445, 1.0, 1.0, 0.17062844260830037, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13850295072129878, 0.1385029507212989, 0.2850828811494895], 
reward next is 0.7149, 
noisyNet noise sample is [array([0.38588274], dtype=float32), 0.50257707]. 
=============================================
[2019-03-23 14:01:49,658] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4918742e-09 1.0000000e+00 1.6233369e-26 9.1465976e-24 3.3175191e-18], sum to 1.0000
[2019-03-23 14:01:49,665] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3956
[2019-03-23 14:01:49,671] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 39.0, 1.0, 2.0, 0.3656260653901498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 411219.5685071338, 411219.5685071338, 121408.4974283063], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2648400.0000, 
sim time next is 2649000.0000, 
raw observation next is [28.0, 39.5, 1.0, 2.0, 0.3687702926333499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 415201.942525901, 415201.9425259013, 121908.8533715636], 
processed observation next is [0.0, 0.6521739130434783, 0.9090909090909091, 0.395, 1.0, 1.0, 0.21096286579168738, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1537784972318152, 0.1537784972318153, 0.2973386667599112], 
reward next is 0.7027, 
noisyNet noise sample is [array([0.7280339], dtype=float32), -0.7374806]. 
=============================================
[2019-03-23 14:01:49,696] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[69.044136]
 [69.00577 ]
 [68.973   ]
 [68.93856 ]
 [68.92244 ]], R is [[69.09693909]
 [69.10984802]
 [69.12403107]
 [69.13951874]
 [69.15578461]].
[2019-03-23 14:01:52,038] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7968368e-10 1.0000000e+00 2.2309849e-25 7.2169433e-25 8.3706815e-18], sum to 1.0000
[2019-03-23 14:01:52,045] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3786
[2019-03-23 14:01:52,052] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.96666666666667, 100.0, 1.0, 2.0, 0.3369965084514139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 372686.3429636353, 372686.342963635, 116180.3969635463], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2703000.0000, 
sim time next is 2703600.0000, 
raw observation next is [17.0, 100.0, 1.0, 2.0, 0.338122666654246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 374140.7818413713, 374140.7818413716, 116348.409893502], 
processed observation next is [0.0, 0.30434782608695654, 0.4090909090909091, 1.0, 1.0, 1.0, 0.1726533333178075, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13857065994124865, 0.13857065994124876, 0.28377660949634637], 
reward next is 0.7162, 
noisyNet noise sample is [array([0.27567926], dtype=float32), 1.4330022]. 
=============================================
[2019-03-23 14:01:52,526] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.4306218e-09 1.0000000e+00 7.3667637e-23 1.1441385e-21 1.5076325e-17], sum to 1.0000
[2019-03-23 14:01:52,539] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1455
[2019-03-23 14:01:52,543] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.08333333333333, 93.5, 1.0, 2.0, 0.41090534374979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 466752.4943498238, 466752.4943498241, 128185.2223373235], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2707800.0000, 
sim time next is 2708400.0000, 
raw observation next is [20.36666666666667, 92.0, 1.0, 2.0, 0.4164031128496326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 473307.4788793892, 473307.4788793892, 128969.5577554427], 
processed observation next is [0.0, 0.34782608695652173, 0.5621212121212124, 0.92, 1.0, 1.0, 0.2705038910620407, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1752990662516256, 0.1752990662516256, 0.3145598969644944], 
reward next is 0.6854, 
noisyNet noise sample is [array([0.23663872], dtype=float32), 0.016778009]. 
=============================================
[2019-03-23 14:01:59,352] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.5848860e-06 9.9999142e-01 9.6052643e-18 2.2813471e-17 1.7769676e-11], sum to 1.0000
[2019-03-23 14:01:59,360] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1889
[2019-03-23 14:01:59,365] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 66.66666666666667, 1.0, 2.0, 0.4670432020286377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 532922.5857140784, 532922.5857140784, 137043.9148341972], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2841600.0000, 
sim time next is 2842200.0000, 
raw observation next is [25.0, 69.5, 1.0, 2.0, 0.4732500090667939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 540014.1194904122, 540014.1194904122, 138007.7225044856], 
processed observation next is [1.0, 0.9130434782608695, 0.7727272727272727, 0.695, 1.0, 1.0, 0.3415625113334923, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2000052294408934, 0.2000052294408934, 0.3366042012304527], 
reward next is 0.6634, 
noisyNet noise sample is [array([-0.37676966], dtype=float32), -1.0064105]. 
=============================================
[2019-03-23 14:02:01,156] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3054576e-08 1.0000000e+00 1.5252612e-21 1.2987019e-20 8.5892651e-14], sum to 1.0000
[2019-03-23 14:02:01,164] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5703
[2019-03-23 14:02:01,169] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.5055914020099112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576129.0566119277, 576129.0566119277, 139592.1268365822], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2861400.0000, 
sim time next is 2862000.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4830300214273789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 550394.0224676426, 550394.0224676428, 137081.4149143145], 
processed observation next is [1.0, 0.13043478260869565, 0.6363636363636364, 0.83, 1.0, 1.0, 0.3537875267842236, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2038496379509787, 0.20384963795097882, 0.3343449144251573], 
reward next is 0.6657, 
noisyNet noise sample is [array([2.2139935], dtype=float32), -0.2257085]. 
=============================================
[2019-03-23 14:02:01,198] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[58.74825 ]
 [58.783596]
 [58.826756]
 [58.765038]
 [58.652775]], R is [[58.67829895]
 [58.75104904]
 [58.82271194]
 [58.88776779]
 [58.92293549]].
[2019-03-23 14:02:02,207] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 14:02:02,208] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:02:02,208] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:02:02,209] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:02:02,212] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:02:02,213] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:02:02,214] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:02:02,218] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:02:02,219] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:02:02,212] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:02:02,221] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:02:02,235] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run38
[2019-03-23 14:02:02,258] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run38
[2019-03-23 14:02:02,284] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run38
[2019-03-23 14:02:02,284] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run38
[2019-03-23 14:02:02,335] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run38
[2019-03-23 14:02:06,618] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08605795], dtype=float32), 0.22117932]
[2019-03-23 14:02:06,619] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.4, 77.0, 1.0, 2.0, 0.3389165050251622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 373301.0225861823, 373301.0225861823, 120061.113064143]
[2019-03-23 14:02:06,620] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:02:06,621] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.9373505e-08 1.0000000e+00 4.0891312e-23 5.4156722e-22 3.1955961e-15], sampled 0.40759513561982474
[2019-03-23 14:02:19,496] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08605795], dtype=float32), 0.22117932]
[2019-03-23 14:02:19,497] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.997602565, 95.57588894833333, 1.0, 2.0, 0.4350967599233744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 494681.1487204963, 494681.1487204963, 135260.8046062274]
[2019-03-23 14:02:19,497] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:02:19,500] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.2962723e-08 1.0000000e+00 6.6452197e-23 8.5929010e-22 4.3827666e-15], sampled 0.40848678848153697
[2019-03-23 14:03:03,513] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08605795], dtype=float32), 0.22117932]
[2019-03-23 14:03:03,515] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.918252505, 77.056450065, 1.0, 2.0, 0.5675405764177746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 647512.4345087805, 647512.4345087805, 153963.1325844493]
[2019-03-23 14:03:03,515] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:03:03,518] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.0153594e-08 1.0000000e+00 3.2771488e-22 3.9183029e-21 1.2376323e-14], sampled 0.5035960311959509
[2019-03-23 14:03:44,012] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:03:44,150] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 14:03:44,231] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 14:03:44,430] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 14:03:44,431] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 14:03:45,446] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 925000, evaluation results [925000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 14:03:54,388] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.7239210e-07 9.9999976e-01 8.0470786e-20 4.4561755e-19 2.6898236e-10], sum to 1.0000
[2019-03-23 14:03:54,396] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8541
[2019-03-23 14:03:54,401] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 100.0, 1.0, 2.0, 0.3204245071344767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 348029.7681757664, 348029.7681757667, 112613.9308585838], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3042600.0000, 
sim time next is 3043200.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.3140034459599708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 341013.4996507291, 341013.4996507288, 112157.637030585], 
processed observation next is [1.0, 0.21739130434782608, 0.36363636363636365, 1.0, 1.0, 1.0, 0.1425043074499635, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12630129616693672, 0.12630129616693658, 0.2735552122697195], 
reward next is 0.7264, 
noisyNet noise sample is [array([1.5564041], dtype=float32), 2.3020554]. 
=============================================
[2019-03-23 14:04:02,143] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0857871e-06 9.9999654e-01 1.9179075e-21 3.5796138e-20 2.3246068e-06], sum to 1.0000
[2019-03-23 14:04:02,154] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3935
[2019-03-23 14:04:02,162] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.00000000000001, 1.0, 2.0, 0.3932352588736159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 443133.9690793836, 443133.9690793836, 124246.1581462039], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3201000.0000, 
sim time next is 3201600.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.3926725303613477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 442476.807457871, 442476.8074578713, 124183.7120546314], 
processed observation next is [0.0, 0.043478260869565216, 0.5, 0.94, 1.0, 1.0, 0.2408406629516846, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16388029905847074, 0.16388029905847087, 0.3028871025722717], 
reward next is 0.6971, 
noisyNet noise sample is [array([-0.14246227], dtype=float32), -0.9712638]. 
=============================================
[2019-03-23 14:04:07,784] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.4593016e-07 9.9999392e-01 1.9354683e-21 1.1677878e-22 5.5420401e-06], sum to 1.0000
[2019-03-23 14:04:07,788] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9737
[2019-03-23 14:04:07,793] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 82.00000000000001, 1.0, 2.0, 0.2465514276973876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 267702.4582011909, 267702.4582011912, 83653.85165899356], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3294600.0000, 
sim time next is 3295200.0000, 
raw observation next is [16.0, 82.0, 1.0, 2.0, 0.2464759914093134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 267620.5278875957, 267620.5278875957, 83649.55243183271], 
processed observation next is [0.0, 0.13043478260869565, 0.36363636363636365, 0.82, 1.0, 1.0, 0.05809498926164173, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09911871403244285, 0.09911871403244285, 0.2040232986142261], 
reward next is 0.7960, 
noisyNet noise sample is [array([-1.1494305], dtype=float32), -1.191623]. 
=============================================
[2019-03-23 14:04:08,259] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9952267e-06 9.9995041e-01 5.7005063e-22 1.5425459e-21 3.9527666e-05], sum to 1.0000
[2019-03-23 14:04:08,265] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5483
[2019-03-23 14:04:08,268] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 59.0, 1.0, 2.0, 0.3317998552847385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 366576.7519417403, 366576.7519417406, 115645.9638042463], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3323400.0000, 
sim time next is 3324000.0000, 
raw observation next is [22.66666666666667, 58.00000000000001, 1.0, 2.0, 0.3343539872109814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 370254.4407490553, 370254.4407490556, 116177.0404470497], 
processed observation next is [0.0, 0.4782608695652174, 0.6666666666666669, 0.5800000000000001, 1.0, 1.0, 0.16794248401372674, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13713127435150196, 0.13713127435150207, 0.28335863523670657], 
reward next is 0.7166, 
noisyNet noise sample is [array([0.03876166], dtype=float32), 0.061263602]. 
=============================================
[2019-03-23 14:04:08,283] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[78.46156 ]
 [78.437645]
 [78.3792  ]
 [78.32914 ]
 [78.28197 ]], R is [[78.4193573 ]
 [78.35309601]
 [78.28883362]
 [78.22629547]
 [78.16524506]].
[2019-03-23 14:04:27,760] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4330449e-07 9.9999988e-01 1.5054929e-19 6.0387473e-19 2.9034240e-12], sum to 1.0000
[2019-03-23 14:04:27,815] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7614
[2019-03-23 14:04:27,818] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.83333333333334, 58.66666666666667, 1.0, 2.0, 0.5107122852314957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 581860.9234998829, 581860.9234998829, 144047.2052969309], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3694200.0000, 
sim time next is 3694800.0000, 
raw observation next is [27.66666666666667, 59.33333333333334, 1.0, 2.0, 0.5117604160003532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 583116.6992714668, 583116.699271467, 144114.5402809719], 
processed observation next is [1.0, 0.782608695652174, 0.8939393939393941, 0.5933333333333334, 1.0, 1.0, 0.3897005200004414, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21596914787832105, 0.21596914787832114, 0.3514988787340778], 
reward next is 0.6485, 
noisyNet noise sample is [array([0.97099787], dtype=float32), 0.13218349]. 
=============================================
[2019-03-23 14:04:32,734] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.8055456e-08 1.0000000e+00 5.1627496e-20 6.8204602e-20 8.7899021e-14], sum to 1.0000
[2019-03-23 14:04:32,739] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5896
[2019-03-23 14:04:32,743] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 60.0, 1.0, 2.0, 0.7108049256655935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 787430.4775476579, 787430.4775476579, 153422.0100865731], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3776400.0000, 
sim time next is 3777000.0000, 
raw observation next is [21.83333333333334, 60.66666666666666, 1.0, 2.0, 0.4586160643082496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 506625.5243620845, 506625.5243620842, 126075.8192670314], 
processed observation next is [1.0, 0.7391304347826086, 0.628787878787879, 0.6066666666666666, 1.0, 1.0, 0.32327008038531196, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18763908309706834, 0.18763908309706823, 0.3075019982122717], 
reward next is 0.6925, 
noisyNet noise sample is [array([1.320599], dtype=float32), 0.15267476]. 
=============================================
[2019-03-23 14:04:32,763] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[61.305927]
 [60.971493]
 [60.812977]
 [60.484463]
 [59.53745 ]], R is [[62.39680099]
 [62.39863586]
 [62.39926529]
 [62.4081459 ]
 [62.43712234]].
[2019-03-23 14:04:33,259] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9622648e-09 1.0000000e+00 1.6508804e-22 1.7420150e-22 1.9726167e-12], sum to 1.0000
[2019-03-23 14:04:33,267] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2849
[2019-03-23 14:04:33,274] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3293051225576521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 360305.7360320345, 360305.7360320345, 114143.8791659174], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3799200.0000, 
sim time next is 3799800.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3277192893070773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 358560.5118278777, 358560.511827878, 114026.331293692], 
processed observation next is [1.0, 1.0, 0.4090909090909091, 0.94, 1.0, 1.0, 0.15964911163384657, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13280018956588063, 0.13280018956588074, 0.2781130031553463], 
reward next is 0.7219, 
noisyNet noise sample is [array([-1.0594414], dtype=float32), -0.1404101]. 
=============================================
[2019-03-23 14:04:34,745] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 14:04:34,747] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:04:34,747] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:04:34,749] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:04:34,753] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:04:34,752] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:04:34,754] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:04:34,754] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:04:34,748] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:04:34,755] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:04:34,756] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:04:34,763] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run39
[2019-03-23 14:04:34,789] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run39
[2019-03-23 14:04:34,790] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run39
[2019-03-23 14:04:34,840] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run39
[2019-03-23 14:04:34,864] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run39
[2019-03-23 14:04:59,913] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07855099], dtype=float32), 0.2163246]
[2019-03-23 14:04:59,914] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [13.6, 61.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 208860.8650603548, 208860.8650603544, 71173.36327479515]
[2019-03-23 14:04:59,914] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:04:59,919] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.6996408e-11 1.0000000e+00 7.0046442e-26 1.2599429e-25 9.2537767e-17], sampled 0.02047998118662886
[2019-03-23 14:05:09,149] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07855099], dtype=float32), 0.2163246]
[2019-03-23 14:05:09,151] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.650052795, 100.0, 1.0, 2.0, 0.5858323947673124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 662669.8967827089, 662669.8967827089, 160148.3986875529]
[2019-03-23 14:05:09,151] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:05:09,154] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.6363434e-11 1.0000000e+00 7.2420597e-27 1.3315716e-26 2.1601276e-17], sampled 0.9867781932010969
[2019-03-23 14:05:25,260] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07855099], dtype=float32), 0.2163246]
[2019-03-23 14:05:25,261] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [30.3, 49.0, 1.0, 2.0, 0.6545456284843985, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 744608.5957599485, 744608.5957599485, 168011.1985789466]
[2019-03-23 14:05:25,261] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:05:25,264] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.7098498e-11 1.0000000e+00 1.6671096e-26 3.0410526e-26 3.6899941e-17], sampled 0.23413884175918276
[2019-03-23 14:05:25,973] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07855099], dtype=float32), 0.2163246]
[2019-03-23 14:05:25,975] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.0, 83.0, 1.0, 2.0, 0.6455621180323182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 736653.3438130042, 736653.3438130037, 163905.0226738832]
[2019-03-23 14:05:25,975] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:05:25,978] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.9504027e-11 1.0000000e+00 5.2740874e-26 9.5062312e-26 7.7142024e-17], sampled 0.5097665742217258
[2019-03-23 14:05:29,597] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07855099], dtype=float32), 0.2163246]
[2019-03-23 14:05:29,599] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.09970686333333, 74.813441275, 1.0, 2.0, 0.6289775350298812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 706725.7394036982, 706725.7394036979, 167301.7944246333]
[2019-03-23 14:05:29,599] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:05:29,601] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.8527806e-11 1.0000000e+00 1.8231209e-26 3.3212536e-26 3.9072654e-17], sampled 0.8615877963620019
[2019-03-23 14:05:31,047] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07855099], dtype=float32), 0.2163246]
[2019-03-23 14:05:31,048] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.44710337666667, 62.16863928666667, 1.0, 2.0, 0.3328810838393041, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 361447.3346509679, 361447.3346509676, 117760.0753002958]
[2019-03-23 14:05:31,048] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:05:31,052] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.2654122e-11 1.0000000e+00 1.2164727e-26 2.2259174e-26 3.0142716e-17], sampled 0.10519359172023524
[2019-03-23 14:05:33,429] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07855099], dtype=float32), 0.2163246]
[2019-03-23 14:05:33,432] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.85444808, 74.58643917, 1.0, 2.0, 0.5673041514165227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 639595.9779736785, 639595.9779736781, 158252.284470724]
[2019-03-23 14:05:33,433] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:05:33,436] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.8148914e-11 1.0000000e+00 8.4970789e-27 1.5608739e-26 2.3971074e-17], sampled 0.9082745896428494
[2019-03-23 14:05:42,006] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07855099], dtype=float32), 0.2163246]
[2019-03-23 14:05:42,008] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.83670668, 76.0795399, 1.0, 2.0, 0.339928664103498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 375721.1860168549, 375721.1860168545, 120638.8495809911]
[2019-03-23 14:05:42,009] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:05:42,011] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.3492951e-11 1.0000000e+00 1.2953780e-26 2.3664957e-26 3.1401629e-17], sampled 0.05483682880383223
[2019-03-23 14:06:11,620] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07855099], dtype=float32), 0.2163246]
[2019-03-23 14:06:11,622] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.62967537666667, 90.65735341333334, 1.0, 2.0, 0.4787155467727061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 546162.8856872645, 546162.8856872645, 142434.6069609498]
[2019-03-23 14:06:11,623] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:06:11,625] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.9842123e-11 1.0000000e+00 1.9766552e-26 3.5986189e-26 4.1145707e-17], sampled 0.9587774801744329
[2019-03-23 14:06:16,360] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 14:06:16,468] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 14:06:16,555] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 14:06:16,668] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:06:16,678] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 14:06:17,695] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 950000, evaluation results [950000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 14:06:27,118] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.7026500e-10 1.0000000e+00 7.0202199e-24 3.2793498e-22 1.0859227e-11], sum to 1.0000
[2019-03-23 14:06:27,128] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1727
[2019-03-23 14:06:27,133] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.4435104074039491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 488587.7082887352, 488587.7082887352, 124249.476828817], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4006800.0000, 
sim time next is 4007400.0000, 
raw observation next is [17.83333333333333, 89.00000000000001, 1.0, 2.0, 0.4790077265218124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 527689.1816201988, 527689.1816201988, 127423.905726889], 
processed observation next is [1.0, 0.391304347826087, 0.44696969696969674, 0.8900000000000001, 1.0, 1.0, 0.34875965815226545, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19544043763711066, 0.19544043763711066, 0.31079001396802197], 
reward next is 0.6892, 
noisyNet noise sample is [array([-0.83829296], dtype=float32), 1.2863644]. 
=============================================
[2019-03-23 14:06:29,148] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2234656e-10 1.0000000e+00 1.3472845e-24 1.2029255e-24 1.0404158e-13], sum to 1.0000
[2019-03-23 14:06:29,158] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8845
[2019-03-23 14:06:29,161] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 100.0, 1.0, 2.0, 0.30588027435917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 332143.2399115372, 332143.2399115369, 111588.839162521], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4061400.0000, 
sim time next is 4062000.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.3059268126916925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 332193.5273246546, 332193.5273246549, 111591.8855501155], 
processed observation next is [1.0, 0.0, 0.36363636363636365, 1.0, 1.0, 1.0, 0.13240851586461558, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12303463974987208, 0.1230346397498722, 0.2721753306100378], 
reward next is 0.7278, 
noisyNet noise sample is [array([0.6193388], dtype=float32), -0.7050745]. 
=============================================
[2019-03-23 14:06:29,175] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[74.98908 ]
 [74.98689 ]
 [75.33766 ]
 [75.30182 ]
 [75.258575]], R is [[75.07177734]
 [75.04888916]
 [75.02600098]
 [75.00260162]
 [74.97868347]].
[2019-03-23 14:06:32,294] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.9738109e-11 1.0000000e+00 6.1232149e-24 2.5278180e-23 1.4553891e-14], sum to 1.0000
[2019-03-23 14:06:32,302] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1680
[2019-03-23 14:06:32,307] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 78.0, 1.0, 2.0, 0.7294138580984019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 826613.7826807536, 826613.7826807536, 164246.3170655193], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4109400.0000, 
sim time next is 4110000.0000, 
raw observation next is [21.33333333333334, 79.66666666666666, 1.0, 2.0, 0.7510167203026683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 851583.9189755277, 851583.9189755277, 167559.2018999989], 
processed observation next is [1.0, 0.5652173913043478, 0.6060606060606063, 0.7966666666666665, 1.0, 1.0, 0.6887709003783354, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.31540145147241766, 0.31540145147241766, 0.40868098024389976], 
reward next is 0.5913, 
noisyNet noise sample is [array([-0.17250736], dtype=float32), -0.6143857]. 
=============================================
[2019-03-23 14:06:32,335] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[70.71158 ]
 [70.88092 ]
 [71.079544]
 [71.27191 ]
 [71.22736 ]], R is [[70.45731354]
 [70.3521347 ]
 [70.26179504]
 [70.19441986]
 [70.15405273]].
[2019-03-23 14:06:36,650] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.1241910e-08 1.0000000e+00 1.1062093e-18 1.8440559e-18 5.7541043e-09], sum to 1.0000
[2019-03-23 14:06:36,664] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9289
[2019-03-23 14:06:36,672] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 59.0, 1.0, 2.0, 0.8205327032690592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 930424.545706033, 930424.545706033, 177660.1512135432], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4199400.0000, 
sim time next is 4200000.0000, 
raw observation next is [24.66666666666666, 58.33333333333334, 1.0, 2.0, 0.873679165057013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 991106.2640665829, 991106.2640665829, 186101.1679013683], 
processed observation next is [1.0, 0.6086956521739131, 0.7575757575757573, 0.5833333333333335, 1.0, 1.0, 0.8420989563212663, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3670763940987344, 0.3670763940987344, 0.4539052875643129], 
reward next is 0.5461, 
noisyNet noise sample is [array([-2.0939806], dtype=float32), -1.4448606]. 
=============================================
[2019-03-23 14:06:36,687] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[61.36894 ]
 [61.2799  ]
 [61.18768 ]
 [61.343365]
 [61.541023]], R is [[61.21578979]
 [61.17031479]
 [61.12209702]
 [61.0576973 ]
 [61.00369644]].
[2019-03-23 14:06:37,133] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2068994e-06 9.9999881e-01 6.8566457e-17 9.8946782e-18 1.4184179e-10], sum to 1.0000
[2019-03-23 14:06:37,141] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5413
[2019-03-23 14:06:37,147] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 61.66666666666666, 1.0, 2.0, 0.5771260655978017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 652716.6729312759, 652716.6729312759, 144125.0166729515], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4193400.0000, 
sim time next is 4194000.0000, 
raw observation next is [24.0, 61.0, 1.0, 2.0, 0.5567067951301787, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 629842.8550282681, 629842.8550282683, 141925.0812899932], 
processed observation next is [1.0, 0.5652173913043478, 0.7272727272727273, 0.61, 1.0, 1.0, 0.44588349391272336, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23327513149195114, 0.23327513149195123, 0.34615873485364196], 
reward next is 0.6538, 
noisyNet noise sample is [array([0.3357939], dtype=float32), 2.0847151]. 
=============================================
[2019-03-23 14:06:37,172] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[56.60419 ]
 [56.485176]
 [56.315395]
 [55.95608 ]
 [55.47313 ]], R is [[56.88568878]
 [56.96530914]
 [57.05016708]
 [57.14050293]
 [57.21295166]].
[2019-03-23 14:06:39,972] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.1287693e-09 1.0000000e+00 5.1663326e-21 8.7685759e-20 4.9871357e-10], sum to 1.0000
[2019-03-23 14:06:39,977] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4571
[2019-03-23 14:06:39,980] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 98.0, 1.0, 2.0, 0.2945707737253355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 319858.4095461228, 319858.4095461228, 110829.3907135193], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4254000.0000, 
sim time next is 4254600.0000, 
raw observation next is [16.0, 99.0, 1.0, 2.0, 0.2985165763076291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 324144.3702518584, 324144.3702518581, 111092.9203172651], 
processed observation next is [1.0, 0.21739130434782608, 0.36363636363636365, 0.99, 1.0, 1.0, 0.12314572038453639, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12005347046365125, 0.12005347046365114, 0.270958342237232], 
reward next is 0.7290, 
noisyNet noise sample is [array([-0.00984319], dtype=float32), -0.094251074]. 
=============================================
[2019-03-23 14:06:45,654] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.6515489e-06 9.9999237e-01 1.5028681e-15 3.3553993e-16 2.6952039e-08], sum to 1.0000
[2019-03-23 14:06:45,664] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2719
[2019-03-23 14:06:45,668] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 75.83333333333333, 1.0, 2.0, 0.924343639060375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1055148.483067978, 1055148.483067978, 201713.6692514569], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4353000.0000, 
sim time next is 4353600.0000, 
raw observation next is [24.0, 73.66666666666667, 1.0, 2.0, 0.9019623624141818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1029701.412623869, 1029701.412623869, 198507.9210103193], 
processed observation next is [1.0, 0.391304347826087, 0.7272727272727273, 0.7366666666666667, 1.0, 1.0, 0.8774529530177272, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3813708935643959, 0.3813708935643959, 0.48416566100077874], 
reward next is 0.5158, 
noisyNet noise sample is [array([0.1170354], dtype=float32), -2.2801838]. 
=============================================
[2019-03-23 14:06:57,515] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.0998349e-14 1.0000000e+00 2.8941978e-26 1.0800362e-25 2.4608983e-18], sum to 1.0000
[2019-03-23 14:06:57,524] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1463
[2019-03-23 14:06:57,535] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.33333333333333, 98.0, 1.0, 2.0, 0.2423835307534611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 263175.7834134179, 263175.7834134176, 83407.7597804811], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4592400.0000, 
sim time next is 4593000.0000, 
raw observation next is [14.16666666666667, 99.0, 1.0, 2.0, 0.2405923593367007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 261230.4386375508, 261230.4386375511, 82775.24033914524], 
processed observation next is [1.0, 0.13043478260869565, 0.28030303030303044, 0.99, 1.0, 1.0, 0.05074044917087586, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.096752014310204, 0.09675201431020411, 0.2018908300954762], 
reward next is 0.7981, 
noisyNet noise sample is [array([-1.7536703], dtype=float32), -0.37982675]. 
=============================================
[2019-03-23 14:06:57,550] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[79.64857]
 [79.62072]
 [79.59951]
 [79.74741]
 [79.79303]], R is [[79.66992188]
 [79.66979218]
 [79.66812897]
 [79.66481018]
 [79.65939331]].
[2019-03-23 14:07:01,822] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4103204e-11 1.0000000e+00 1.9269873e-27 7.0021027e-27 5.9931117e-16], sum to 1.0000
[2019-03-23 14:07:01,832] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9682
[2019-03-23 14:07:01,835] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.33333333333333, 82.0, 1.0, 2.0, 0.227278084272239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 246770.3940097448, 246770.3940097448, 78350.76937467974], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4675200.0000, 
sim time next is 4675800.0000, 
raw observation next is [15.16666666666667, 82.0, 1.0, 2.0, 0.2225859754265449, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 241674.6047906237, 241674.6047906234, 77198.79126156302], 
processed observation next is [1.0, 0.08695652173913043, 0.3257575757575759, 0.82, 1.0, 1.0, 0.028232469283181114, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08950911288541619, 0.08950911288541608, 0.18828973478430006], 
reward next is 0.8117, 
noisyNet noise sample is [array([0.5096228], dtype=float32), -0.63593537]. 
=============================================
[2019-03-23 14:07:05,561] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.76886300e-10 1.00000000e+00 1.08986846e-20 2.19252655e-20
 5.11590510e-12], sum to 1.0000
[2019-03-23 14:07:05,564] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9322
[2019-03-23 14:07:05,569] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 88.0, 1.0, 2.0, 0.3626766045012074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 405324.367637117, 405324.3676371168, 119919.4738540799], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4758600.0000, 
sim time next is 4759200.0000, 
raw observation next is [19.0, 88.0, 1.0, 2.0, 0.3628679951201932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 405537.9505492924, 405537.9505492921, 119935.0429426868], 
processed observation next is [1.0, 0.08695652173913043, 0.5, 0.88, 1.0, 1.0, 0.20358499390024146, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15019924094418236, 0.15019924094418224, 0.29252449498216293], 
reward next is 0.7075, 
noisyNet noise sample is [array([-0.28011525], dtype=float32), 1.1515343]. 
=============================================
[2019-03-23 14:07:05,877] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.0662825e-08 1.0000000e+00 3.2704176e-22 7.4385216e-22 5.2784296e-13], sum to 1.0000
[2019-03-23 14:07:05,884] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0055
[2019-03-23 14:07:05,889] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.372105236968091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 417657.7477335338, 417657.7477335338, 121535.6141258447], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4766400.0000, 
sim time next is 4767000.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.4209566532031394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 472668.9206066694, 472668.9206066694, 125917.7830021543], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 1.0, 1.0, 1.0, 0.2761958165039242, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17506256318765534, 0.17506256318765534, 0.30711654390769344], 
reward next is 0.6929, 
noisyNet noise sample is [array([1.1723113], dtype=float32), -0.5556834]. 
=============================================
[2019-03-23 14:07:05,903] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[68.108025]
 [68.05846 ]
 [67.99698 ]
 [67.94901 ]
 [67.896385]], R is [[67.97186279]
 [67.99571991]
 [68.01991272]
 [68.04412079]
 [68.06819153]].
[2019-03-23 14:07:06,393] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 14:07:06,394] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:07:06,395] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:07:06,398] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:07:06,399] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:07:06,399] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:07:06,400] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:07:06,400] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:07:06,401] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:07:06,401] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:07:06,402] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:07:06,422] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run40
[2019-03-23 14:07:06,447] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run40
[2019-03-23 14:07:06,469] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run40
[2019-03-23 14:07:06,470] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run40
[2019-03-23 14:07:06,471] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run40
[2019-03-23 14:07:23,341] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0713134], dtype=float32), 0.21023123]
[2019-03-23 14:07:23,343] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.83329315333334, 61.65300035333334, 1.0, 2.0, 0.507053716527985, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 578113.3409396773, 578113.3409396769, 147356.7613284724]
[2019-03-23 14:07:23,344] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:07:23,346] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.5064747e-10 1.0000000e+00 2.6770481e-22 8.5560374e-22 2.8541601e-13], sampled 0.04262004506063766
[2019-03-23 14:07:41,109] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0713134], dtype=float32), 0.21023123]
[2019-03-23 14:07:41,111] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.06326363, 98.41300732, 1.0, 2.0, 0.4782165442044274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 545609.8843682964, 545609.8843682964, 143041.9580317564]
[2019-03-23 14:07:41,111] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:07:41,113] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.0546016e-10 1.0000000e+00 1.7237901e-22 5.5650782e-22 2.2064203e-13], sampled 0.3470686145211893
[2019-03-23 14:07:44,783] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0713134], dtype=float32), 0.21023123]
[2019-03-23 14:07:44,784] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.93774674666667, 85.23450894333334, 1.0, 2.0, 0.3709486999645614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 416345.0006175064, 416345.0006175067, 125755.1636866776]
[2019-03-23 14:07:44,785] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:07:44,794] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.4642291e-10 1.0000000e+00 2.5776269e-22 8.2470215e-22 2.7914598e-13], sampled 0.9020829376205981
[2019-03-23 14:07:48,761] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0713134], dtype=float32), 0.21023123]
[2019-03-23 14:07:48,762] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.33333333333334, 65.66666666666667, 1.0, 2.0, 0.652743541255119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 744001.3921740488, 744001.3921740488, 166581.9324926426]
[2019-03-23 14:07:48,764] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:07:48,766] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.9839559e-10 1.0000000e+00 7.4691739e-22 2.3313151e-21 5.1983895e-13], sampled 0.948548196435811
[2019-03-23 14:08:14,831] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0713134], dtype=float32), 0.21023123]
[2019-03-23 14:08:14,836] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.2, 75.33333333333334, 1.0, 2.0, 0.3832238267257276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 430873.6818812168, 430873.6818812171, 127175.1471474797]
[2019-03-23 14:08:14,838] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:08:14,840] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.1368593e-10 1.0000000e+00 1.8804085e-22 6.0601310e-22 2.3221293e-13], sampled 0.3026536864731738
[2019-03-23 14:08:17,393] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0713134], dtype=float32), 0.21023123]
[2019-03-23 14:08:17,394] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 96.66666666666666, 1.0, 2.0, 0.3973909972397753, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 449185.0256047716, 449185.0256047716, 125387.6135667995]
[2019-03-23 14:08:17,396] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:08:17,401] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.0503489e-10 1.0000000e+00 4.1329180e-22 1.3076644e-21 3.6763661e-13], sampled 0.14359332316822937
[2019-03-23 14:08:29,704] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0713134], dtype=float32), 0.21023123]
[2019-03-23 14:08:29,704] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.98478512, 49.17386558, 1.0, 2.0, 0.2708656308412681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 294093.5385126831, 294093.5385126831, 82537.11820909013]
[2019-03-23 14:08:29,705] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:08:29,707] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.2955097e-10 1.0000000e+00 4.9050604e-22 1.5461750e-21 4.0645569e-13], sampled 0.7213922936601211
[2019-03-23 14:08:37,581] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0713134], dtype=float32), 0.21023123]
[2019-03-23 14:08:37,583] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.03333333333333, 80.0, 1.0, 2.0, 0.4583320931720765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 522835.453677665, 522835.4536776646, 139940.8063424162]
[2019-03-23 14:08:37,583] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:08:37,588] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.4907812e-10 1.0000000e+00 2.6398106e-22 8.4398888e-22 2.8304098e-13], sampled 0.006258723698709168
[2019-03-23 14:08:40,775] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0713134], dtype=float32), 0.21023123]
[2019-03-23 14:08:40,776] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.161205045, 92.76838136, 1.0, 2.0, 0.3289371577060899, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 360986.872284842, 360986.872284842, 118824.4916600654]
[2019-03-23 14:08:40,777] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:08:40,780] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.2900112e-10 1.0000000e+00 2.1908689e-22 7.0340594e-22 2.5371629e-13], sampled 0.44156728987526794
[2019-03-23 14:08:48,372] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:08:48,507] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 14:08:48,534] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 14:08:48,558] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 14:08:48,593] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 14:08:49,608] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 975000, evaluation results [975000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 14:09:01,563] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.6424262e-10 1.0000000e+00 1.2672288e-21 1.0276400e-20 6.9672480e-13], sum to 1.0000
[2019-03-23 14:09:01,575] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1509
[2019-03-23 14:09:01,579] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 66.0, 1.0, 2.0, 0.5197439508448356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 565191.3620400566, 565191.3620400566, 128874.9365946779], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4980600.0000, 
sim time next is 4981200.0000, 
raw observation next is [20.0, 65.33333333333333, 1.0, 2.0, 0.582910721221126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 633154.9867752973, 633154.9867752973, 134712.8767478144], 
processed observation next is [1.0, 0.6521739130434783, 0.5454545454545454, 0.6533333333333333, 1.0, 1.0, 0.4786384015264074, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23450184695381382, 0.23450184695381382, 0.32856799206784], 
reward next is 0.6714, 
noisyNet noise sample is [array([-1.0552526], dtype=float32), 0.839608]. 
=============================================
[2019-03-23 14:09:05,986] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.7839242e-10 1.0000000e+00 6.6465313e-25 8.9520870e-23 4.3474226e-12], sum to 1.0000
[2019-03-23 14:09:05,994] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3615
[2019-03-23 14:09:06,001] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333333, 71.66666666666667, 1.0, 2.0, 0.4291316628426298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 488394.9788751634, 488394.9788751637, 130783.9494620991], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5089200.0000, 
sim time next is 5089800.0000, 
raw observation next is [23.16666666666667, 72.33333333333333, 1.0, 2.0, 0.4271253106486599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 485974.5363510355, 485974.5363510355, 130449.1107196122], 
processed observation next is [0.0, 0.9130434782608695, 0.6893939393939396, 0.7233333333333333, 1.0, 1.0, 0.2839066383108248, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17999056901890204, 0.17999056901890204, 0.3181685627307615], 
reward next is 0.6818, 
noisyNet noise sample is [array([-1.4751706], dtype=float32), 1.0960692]. 
=============================================
[2019-03-23 14:09:06,457] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.8639121e-10 1.0000000e+00 1.9049707e-22 3.4514605e-20 9.6022443e-12], sum to 1.0000
[2019-03-23 14:09:06,466] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6920
[2019-03-23 14:09:06,470] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 51.5, 1.0, 2.0, 0.4161175248792196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 473304.5104742421, 473304.5104742421, 129228.3884650239], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5071800.0000, 
sim time next is 5072400.0000, 
raw observation next is [27.0, 51.0, 1.0, 2.0, 0.4177714993195757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 475310.8212366672, 475310.8212366674, 129507.9764528291], 
processed observation next is [0.0, 0.7391304347826086, 0.8636363636363636, 0.51, 1.0, 1.0, 0.2722143741494696, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17604104490246933, 0.1760410449024694, 0.3158731132995832], 
reward next is 0.6841, 
noisyNet noise sample is [array([-1.3286964], dtype=float32), 1.465083]. 
=============================================
[2019-03-23 14:09:06,909] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.5942985e-10 1.0000000e+00 1.3532358e-21 8.1378336e-21 8.3867080e-11], sum to 1.0000
[2019-03-23 14:09:06,917] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3732
[2019-03-23 14:09:06,925] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.401303556315889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 454755.1831054394, 454755.1831054394, 126470.9205580385], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5109000.0000, 
sim time next is 5109600.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.401599997068757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 455095.7677011748, 455095.7677011751, 126501.6253037097], 
processed observation next is [0.0, 0.13043478260869565, 0.5909090909090909, 0.83, 1.0, 1.0, 0.2519999963359462, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16855398803747212, 0.16855398803747226, 0.30854054952124316], 
reward next is 0.6915, 
noisyNet noise sample is [array([0.5594759], dtype=float32), 1.4407129]. 
=============================================
[2019-03-23 14:09:12,805] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.2219905e-09 1.0000000e+00 1.1651790e-21 4.5121588e-21 1.1950369e-11], sum to 1.0000
[2019-03-23 14:09:12,817] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7163
[2019-03-23 14:09:12,823] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 84.66666666666667, 1.0, 2.0, 0.5113176646236545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 582506.7669803014, 582506.7669803011, 140050.2541670307], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5192400.0000, 
sim time next is 5193000.0000, 
raw observation next is [21.5, 85.5, 1.0, 2.0, 0.4549093991982819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 518049.1965510637, 518049.196551064, 133730.0767880293], 
processed observation next is [1.0, 0.08695652173913043, 0.6136363636363636, 0.855, 1.0, 1.0, 0.3186367489978523, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19187007279669024, 0.19187007279669036, 0.32617091899519346], 
reward next is 0.6738, 
noisyNet noise sample is [array([-0.40504315], dtype=float32), -0.18940814]. 
=============================================
[2019-03-23 14:09:12,847] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[67.5366  ]
 [67.44514 ]
 [67.718765]
 [67.8099  ]
 [67.95759 ]], R is [[67.37511444]
 [67.35977936]
 [67.30849457]
 [67.3129425 ]
 [67.31724548]].
[2019-03-23 14:09:16,378] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.4626898e-10 1.0000000e+00 2.1246643e-20 4.1126543e-18 7.1108341e-09], sum to 1.0000
[2019-03-23 14:09:16,386] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9081
[2019-03-23 14:09:16,388] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5027834570954457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 573392.8742929505, 573392.8742929503, 142416.1570483416], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5250600.0000, 
sim time next is 5251200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5024427068572177, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 573004.2842035897, 573004.2842035897, 142375.7612971348], 
processed observation next is [1.0, 0.782608695652174, 0.6363636363636364, 0.94, 1.0, 1.0, 0.3780533835715221, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21222380896429247, 0.21222380896429247, 0.34725795438325563], 
reward next is 0.6527, 
noisyNet noise sample is [array([-0.89854586], dtype=float32), -1.5836693]. 
=============================================
[2019-03-23 14:09:25,656] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6311039e-09 1.0000000e+00 1.5416166e-21 8.8920287e-20 1.1342189e-11], sum to 1.0000
[2019-03-23 14:09:25,662] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2603
[2019-03-23 14:09:25,666] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.46666666666667, 96.33333333333333, 1.0, 2.0, 0.3802504271915222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 427073.7043781012, 427073.7043781015, 122364.5224760864], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5437200.0000, 
sim time next is 5437800.0000, 
raw observation next is [18.55, 96.5, 1.0, 2.0, 0.3824064399718912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 429988.6786287776, 429988.6786287776, 122796.5303249117], 
processed observation next is [1.0, 0.9565217391304348, 0.47954545454545455, 0.965, 1.0, 1.0, 0.228008049964864, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15925506615880652, 0.15925506615880652, 0.2995037324997846], 
reward next is 0.7005, 
noisyNet noise sample is [array([-1.0095073], dtype=float32), -0.5750182]. 
=============================================
[2019-03-23 14:09:29,371] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.8683527e-07 9.9999845e-01 4.3738659e-19 8.5473036e-17 6.5878993e-07], sum to 1.0000
[2019-03-23 14:09:29,380] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6522
[2019-03-23 14:09:29,386] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.15, 58.5, 1.0, 2.0, 0.4866346816569536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 555213.6905209704, 555213.6905209702, 139989.2334631178], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5509800.0000, 
sim time next is 5510400.0000, 
raw observation next is [26.96666666666667, 59.0, 1.0, 2.0, 0.4818459902884021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 549787.4395893663, 549787.4395893663, 139285.194606147], 
processed observation next is [1.0, 0.782608695652174, 0.8621212121212122, 0.59, 1.0, 1.0, 0.3523074878605026, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20362497762569123, 0.20362497762569123, 0.33971998684426097], 
reward next is 0.6603, 
noisyNet noise sample is [array([-0.23063613], dtype=float32), -1.2555443]. 
=============================================
[2019-03-23 14:09:31,596] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.8466157e-05 9.9963903e-01 1.0614228e-14 4.4095085e-13 2.9243040e-04], sum to 1.0000
[2019-03-23 14:09:31,605] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1630
[2019-03-23 14:09:31,614] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1550930.704664359 W.
[2019-03-23 14:09:31,618] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.46666666666667, 55.0, 1.0, 2.0, 0.881297711545008, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9764078130021057, 6.911199999999999, 6.9112, 77.32846344354104, 1550930.704664359, 1550930.704664359, 321062.5675656066], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5582400.0000, 
sim time next is 5583000.0000, 
raw observation next is [28.38333333333333, 55.0, 1.0, 2.0, 0.6823119577992117, 1.0, 1.0, 0.6823119577992117, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1544477.473584986, 1544477.473584986, 283863.6828673473], 
processed observation next is [1.0, 0.6086956521739131, 0.9265151515151513, 0.55, 1.0, 1.0, 0.6028899472490146, 1.0, 0.5, 0.6028899472490146, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5720286939203653, 0.5720286939203653, 0.6923504460179203], 
reward next is 0.3076, 
noisyNet noise sample is [array([0.29199776], dtype=float32), 0.46863264]. 
=============================================
[2019-03-23 14:09:31,630] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[46.92308 ]
 [47.125423]
 [47.974056]
 [48.048565]
 [48.24449 ]], R is [[47.59616089]
 [47.33712006]
 [46.86375046]
 [46.69325638]
 [46.22632599]].
[2019-03-23 14:09:38,294] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 14:09:38,294] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:09:38,295] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:09:38,295] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:09:38,296] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:09:38,297] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:09:38,298] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:09:38,305] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:09:38,305] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:09:38,306] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:09:38,307] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:09:38,318] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run41
[2019-03-23 14:09:38,344] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run41
[2019-03-23 14:09:38,369] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run41
[2019-03-23 14:09:38,397] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run41
[2019-03-23 14:09:38,433] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run41
[2019-03-23 14:10:05,997] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06428879], dtype=float32), 0.20831639]
[2019-03-23 14:10:05,999] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.132452175, 77.66479925, 1.0, 2.0, 0.4302255442900469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 467186.5165397492, 467186.5165397492, 124611.8521339835]
[2019-03-23 14:10:06,002] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:10:06,005] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.3552680e-04 9.9984884e-01 3.1878529e-14 4.5594279e-13 1.5664849e-05], sampled 0.10650517594491793
[2019-03-23 14:10:21,477] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06428879], dtype=float32), 0.20831639]
[2019-03-23 14:10:21,478] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.22314151166667, 51.53273146333333, 1.0, 2.0, 0.3599408752055806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 401685.793781072, 401685.7937810716, 123755.8163895111]
[2019-03-23 14:10:21,479] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:10:21,482] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.1715350e-04 9.9975580e-01 1.6116057e-13 1.9499955e-12 2.7030484e-05], sampled 0.18633963117450636
[2019-03-23 14:10:30,504] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06428879], dtype=float32), 0.20831639]
[2019-03-23 14:10:30,507] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.46666666666667, 58.66666666666667, 1.0, 2.0, 0.8532258958768622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 972878.2476616629, 972878.2476616629, 197597.7413416393]
[2019-03-23 14:10:30,509] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:10:30,513] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.5217325e-04 9.9982953e-01 4.7102167e-14 6.6017271e-13 1.8280280e-05], sampled 0.9249660774236891
[2019-03-23 14:10:31,711] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06428879], dtype=float32), 0.20831639]
[2019-03-23 14:10:31,712] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.15565279666667, 78.9782447, 1.0, 2.0, 0.4636605957067212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 523612.4293483674, 523612.429348367, 135784.9244297762]
[2019-03-23 14:10:31,715] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:10:31,717] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.2367839e-04 9.9986219e-01 2.3394604e-14 3.4479903e-13 1.4069306e-05], sampled 0.3092505635220687
[2019-03-23 14:10:39,713] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06428879], dtype=float32), 0.20831639]
[2019-03-23 14:10:39,715] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.78333333333333, 72.0, 1.0, 2.0, 0.236719289534624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 257011.0729809968, 257011.0729809968, 84921.3395817986]
[2019-03-23 14:10:39,718] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:10:39,721] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.5747684e-04 9.9970919e-01 2.8586413e-13 3.2952642e-12 3.3207794e-05], sampled 0.004554922539628303
[2019-03-23 14:11:13,953] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06428879], dtype=float32), 0.20831639]
[2019-03-23 14:11:13,955] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.7, 56.33333333333334, 1.0, 2.0, 0.2760695038766625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 299745.0752659101, 299745.0752659097, 92716.69215671517]
[2019-03-23 14:11:13,955] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:11:13,959] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.4497028e-04 9.9926072e-01 6.8021864e-12 5.8000167e-11 9.4286173e-05], sampled 0.7421431199247273
[2019-03-23 14:11:23,417] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8595.5823 1705946828.1490 466.0000
[2019-03-23 14:11:23,538] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1617 1683344680.2732 214.0000
[2019-03-23 14:11:23,620] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8854.5739 1663774829.3655 106.0000
[2019-03-23 14:11:23,657] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9054.8897 1656218988.6071 82.0000
[2019-03-23 14:11:23,664] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.9705 1773113967.4122 174.0000
[2019-03-23 14:11:24,680] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1000000, evaluation results [1000000.0, 8512.97047052295, 1773113967.412211, 174.0, 9054.889689276413, 1656218988.6070619, 82.0, 8854.573870021733, 1663774829.3654833, 106.0, 8595.582324998595, 1705946828.1490126, 466.0, 8575.161677999195, 1683344680.2731519, 214.0]
[2019-03-23 14:11:27,272] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 14:11:27,278] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2291
[2019-03-23 14:11:27,284] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.53333333333333, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.39933298410438, 6.911199999999999, 6.9112, 77.32846344354104, 232258.1093321505, 232258.1093321508, 66383.01759476376], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5740800.0000, 
sim time next is 5741400.0000, 
raw observation next is [17.61666666666667, 51.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4015313933268552, 6.911199999999999, 6.9112, 77.32846344354104, 233537.0300308069, 233537.0300308071, 66325.73850239953], 
processed observation next is [0.0, 0.43478260869565216, 0.4371212121212123, 0.51, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1450448476097932, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08649519630770626, 0.08649519630770633, 0.16177009390829153], 
reward next is 0.8382, 
noisyNet noise sample is [array([1.3150618], dtype=float32), -0.011570876]. 
=============================================
[2019-03-23 14:11:28,862] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.7186458e-33 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 14:11:28,867] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2769
[2019-03-23 14:11:28,875] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.26666666666667, 63.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3852486261679124, 6.9112, 6.9112, 77.32846344354104, 224064.5260193651, 224064.5260193651, 66539.38327986104], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5784000.0000, 
sim time next is 5784600.0000, 
raw observation next is [16.18333333333333, 63.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.383140529758536, 6.911199999999999, 6.9112, 77.32846344354104, 222838.1548126463, 222838.1548126466, 66221.46714838961], 
processed observation next is [0.0, 0.9565217391304348, 0.37196969696969684, 0.6366666666666666, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.11877218536933719, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08253264993060974, 0.08253264993060985, 0.16151577353265759], 
reward next is 0.8385, 
noisyNet noise sample is [array([0.37235922], dtype=float32), -1.4785062]. 
=============================================
[2019-03-23 14:11:31,639] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.2005008e-05 9.9997795e-01 1.1432271e-22 4.2796444e-22 2.3459595e-11], sum to 1.0000
[2019-03-23 14:11:31,646] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1046
[2019-03-23 14:11:31,649] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 50.66666666666666, 1.0, 2.0, 0.397616373747309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 443031.8429439754, 443031.8429439754, 122292.1612617641], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5834400.0000, 
sim time next is 5835000.0000, 
raw observation next is [24.4, 50.33333333333334, 1.0, 2.0, 0.393207877060344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 437742.9023046792, 437742.9023046794, 121760.6737569876], 
processed observation next is [1.0, 0.5217391304347826, 0.7454545454545454, 0.5033333333333334, 1.0, 1.0, 0.24150984632542996, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1621270008535849, 0.16212700085358495, 0.2969772530658234], 
reward next is 0.7030, 
noisyNet noise sample is [array([0.44625247], dtype=float32), 0.04015117]. 
=============================================
[2019-03-23 14:11:31,671] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[71.76335]
 [71.66751]
 [71.45589]
 [71.22662]
 [71.1857 ]], R is [[71.86463928]
 [71.84772491]
 [71.828125  ]
 [71.80191803]
 [71.75911713]].
[2019-03-23 14:11:38,147] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.2883536e-10 1.0000000e+00 2.8237035e-27 1.5518208e-25 8.6198198e-15], sum to 1.0000
[2019-03-23 14:11:38,156] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9954
[2019-03-23 14:11:38,160] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.76666666666667, 80.0, 1.0, 2.0, 0.3572922183232616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 398221.6522246539, 398221.6522246539, 119000.3302969522], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5967600.0000, 
sim time next is 5968200.0000, 
raw observation next is [19.58333333333334, 80.5, 1.0, 2.0, 0.3547950071885356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 394796.4605603834, 394796.4605603834, 118525.8086998529], 
processed observation next is [1.0, 0.043478260869565216, 0.5265151515151518, 0.805, 1.0, 1.0, 0.1934937589856695, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14622091131866052, 0.14622091131866052, 0.28908733829232414], 
reward next is 0.7109, 
noisyNet noise sample is [array([-1.1340934], dtype=float32), -0.15545385]. 
=============================================
[2019-03-23 14:11:48,917] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.28719574e-07 9.99999404e-01 1.17564426e-20 1.15460041e-19
 6.22736849e-08], sum to 1.0000
[2019-03-23 14:11:48,923] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8480
[2019-03-23 14:11:48,931] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.53333333333333, 80.0, 1.0, 2.0, 0.2963509934153077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 321792.0930050683, 321792.0930050685, 101864.5587610781], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6144000.0000, 
sim time next is 6144600.0000, 
raw observation next is [17.61666666666667, 79.0, 1.0, 2.0, 0.2911164983773168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 316106.3804600625, 316106.3804600622, 100654.4384353624], 
processed observation next is [1.0, 0.08695652173913043, 0.4371212121212123, 0.79, 1.0, 1.0, 0.11389562297164597, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11707643720743055, 0.11707643720743044, 0.2454986303301522], 
reward next is 0.7545, 
noisyNet noise sample is [array([-1.275843], dtype=float32), -0.3205847]. 
=============================================
[2019-03-23 14:11:50,289] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.4972355e-09 9.9999988e-01 7.1981748e-22 1.4244915e-19 1.5829704e-07], sum to 1.0000
[2019-03-23 14:11:50,298] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1044
[2019-03-23 14:11:50,307] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.96666666666667, 64.33333333333333, 1.0, 2.0, 0.3460446049976357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 385024.981814187, 385024.9818141867, 117819.3677828247], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6201600.0000, 
sim time next is 6202200.0000, 
raw observation next is [21.78333333333333, 66.16666666666667, 1.0, 2.0, 0.3485641030070381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 388368.2509071157, 388368.2509071159, 118248.6888461788], 
processed observation next is [1.0, 0.782608695652174, 0.6265151515151515, 0.6616666666666667, 1.0, 1.0, 0.1857051287587976, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14384009292856137, 0.14384009292856142, 0.2884114362101922], 
reward next is 0.7116, 
noisyNet noise sample is [array([-0.7684968], dtype=float32), 0.60031605]. 
=============================================
[2019-03-23 14:11:55,684] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.8583819e-07 9.9999976e-01 4.1537076e-19 2.0938657e-18 3.4879722e-08], sum to 1.0000
[2019-03-23 14:11:55,691] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9107
[2019-03-23 14:11:55,695] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 84.5, 1.0, 2.0, 0.4821460749801338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 550156.7517094942, 550156.7517094942, 139161.6176450846], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6317400.0000, 
sim time next is 6318000.0000, 
raw observation next is [22.7, 85.0, 1.0, 2.0, 0.480688355695413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 548499.9041544797, 548499.9041544797, 138931.1401921162], 
processed observation next is [0.0, 0.13043478260869565, 0.6681818181818181, 0.85, 1.0, 1.0, 0.35086044461926624, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2031481126498073, 0.2031481126498073, 0.33885643949296634], 
reward next is 0.6611, 
noisyNet noise sample is [array([-0.40017936], dtype=float32), -0.3904484]. 
=============================================
[2019-03-23 14:11:55,707] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[62.292923]
 [62.21537 ]
 [62.269047]
 [62.357445]
 [62.355644]], R is [[62.30838776]
 [62.34588242]
 [62.38266373]
 [62.41890335]
 [62.45438766]].
[2019-03-23 14:11:59,557] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.6275966e-08 9.9999964e-01 8.9602334e-19 6.2468426e-16 3.9275213e-07], sum to 1.0000
[2019-03-23 14:11:59,564] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5443
[2019-03-23 14:11:59,569] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 61.0, 1.0, 2.0, 0.5507339376808824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 624802.3237914469, 624802.3237914469, 150556.6629894989], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6366600.0000, 
sim time next is 6367200.0000, 
raw observation next is [28.3, 61.0, 1.0, 2.0, 0.5508808658879646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 624969.0770937268, 624969.0770937272, 150575.5808630608], 
processed observation next is [0.0, 0.6956521739130435, 0.9227272727272727, 0.61, 1.0, 1.0, 0.4386010823599557, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23147002855323215, 0.2314700285532323, 0.3672575143001483], 
reward next is 0.6327, 
noisyNet noise sample is [array([-1.4203383], dtype=float32), 1.2349836]. 
=============================================
[2019-03-23 14:12:12,277] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1280799e-09 1.0000000e+00 3.0399237e-21 7.7047836e-19 7.7788460e-09], sum to 1.0000
[2019-03-23 14:12:12,283] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9315
[2019-03-23 14:12:12,286] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 87.0, 1.0, 2.0, 0.3539400499467937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 393802.0607554178, 393802.0607554181, 118439.8755832229], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6647400.0000, 
sim time next is 6648000.0000, 
raw observation next is [18.8, 87.0, 1.0, 2.0, 0.3522656330513716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 391934.4890670407, 391934.4890670404, 118304.9712200769], 
processed observation next is [1.0, 0.9565217391304348, 0.49090909090909096, 0.87, 1.0, 1.0, 0.19033204131421447, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14516092187668173, 0.14516092187668161, 0.2885487102928705], 
reward next is 0.7115, 
noisyNet noise sample is [array([0.60159856], dtype=float32), 0.061882094]. 
=============================================
[2019-03-23 14:12:12,299] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[62.332886]
 [62.32674 ]
 [62.351215]
 [62.35418 ]
 [62.34438 ]], R is [[62.4289856 ]
 [62.51581573]
 [62.60163879]
 [62.68674469]
 [62.77112961]].
[2019-03-23 14:12:12,862] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 14:12:12,865] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:12:12,866] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:12:12,866] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:12:12,867] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:12:12,869] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:12:12,869] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:12:12,866] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:12:12,870] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:12:12,871] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:12:12,870] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:12:12,892] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run42
[2019-03-23 14:12:12,917] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run42
[2019-03-23 14:12:12,945] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run42
[2019-03-23 14:12:12,971] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run42
[2019-03-23 14:12:13,004] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run42
[2019-03-23 14:13:22,173] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06498577], dtype=float32), 0.2057862]
[2019-03-23 14:13:22,175] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.16666666666667, 82.33333333333334, 1.0, 2.0, 0.3433003818719494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 380915.3729893867, 380915.3729893871, 121481.1943997987]
[2019-03-23 14:13:22,177] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:13:22,179] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.0764229e-08 9.9999976e-01 4.4883536e-18 1.1137259e-16 6.1015434e-08], sampled 0.6149831660625728
[2019-03-23 14:13:51,156] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06498577], dtype=float32), 0.2057862]
[2019-03-23 14:13:51,159] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.83099175666667, 95.16745681666667, 1.0, 2.0, 0.4375020222548807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 498780.1203934155, 498780.1203934155, 137078.7248819669]
[2019-03-23 14:13:51,161] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:13:51,164] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.2249247e-08 1.0000000e+00 1.0046633e-18 2.8062039e-17 3.2553306e-08], sampled 0.6436754050306233
[2019-03-23 14:13:55,112] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:13:55,486] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 14:13:55,506] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 14:13:55,508] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 14:13:55,705] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 14:13:56,720] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1025000, evaluation results [1025000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 14:14:12,583] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.3427766e-12 1.0000000e+00 9.3695148e-22 3.1946479e-21 5.7816238e-11], sum to 1.0000
[2019-03-23 14:14:12,591] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5432
[2019-03-23 14:14:12,597] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 88.0, 1.0, 2.0, 0.3603749863647621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 401752.8538482962, 401752.8538482962, 119290.2267775082], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6928800.0000, 
sim time next is 6929400.0000, 
raw observation next is [18.8, 87.5, 1.0, 2.0, 0.357530157235121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 398244.8675624959, 398244.8675624962, 118915.7953453471], 
processed observation next is [0.0, 0.17391304347826086, 0.49090909090909096, 0.875, 1.0, 1.0, 0.19691269654390123, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14749809909722073, 0.1474980990972208, 0.2900385252325539], 
reward next is 0.7100, 
noisyNet noise sample is [array([0.89621156], dtype=float32), -0.020610897]. 
=============================================
[2019-03-23 14:14:15,849] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.7538855e-09 1.0000000e+00 1.2226545e-20 9.0781722e-20 4.0561506e-11], sum to 1.0000
[2019-03-23 14:14:15,856] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0908
[2019-03-23 14:14:15,861] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 76.0, 1.0, 2.0, 0.4751774455789325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 542210.8502042642, 542210.8502042642, 137958.9759202792], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6991200.0000, 
sim time next is 6991800.0000, 
raw observation next is [23.71666666666667, 76.5, 1.0, 2.0, 0.473860961165452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 540704.3938939177, 540704.3938939173, 137773.6914796401], 
processed observation next is [0.0, 0.9565217391304348, 0.7143939393939395, 0.765, 1.0, 1.0, 0.34232620145681497, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20026088662737693, 0.2002608866273768, 0.33603339385278075], 
reward next is 0.6640, 
noisyNet noise sample is [array([-0.5649107], dtype=float32), -0.7600135]. 
=============================================
[2019-03-23 14:14:17,752] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.8925673e-08 9.9999988e-01 1.2668433e-19 4.3091527e-18 7.0606082e-10], sum to 1.0000
[2019-03-23 14:14:17,762] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0268
[2019-03-23 14:14:17,769] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 80.66666666666667, 1.0, 2.0, 0.7621920917927395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 867414.4758805983, 867414.4758805986, 171581.8139667572], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7047600.0000, 
sim time next is 7048200.0000, 
raw observation next is [22.01666666666667, 79.83333333333334, 1.0, 2.0, 0.790126305478003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 899575.1803290991, 899575.1803290987, 176055.7549305499], 
processed observation next is [1.0, 0.5652173913043478, 0.6371212121212122, 0.7983333333333335, 1.0, 1.0, 0.7376578818475038, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3331759927144811, 0.333175992714481, 0.42940428031841443], 
reward next is 0.5706, 
noisyNet noise sample is [array([-1.1095934], dtype=float32), 1.9489074]. 
=============================================
[2019-03-23 14:14:18,494] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0349079e-09 1.0000000e+00 5.7318411e-22 1.6893676e-20 2.5326788e-11], sum to 1.0000
[2019-03-23 14:14:18,503] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7866
[2019-03-23 14:14:18,509] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.9, 89.0, 1.0, 2.0, 0.364956978397764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 407929.1291870957, 407929.1291870957, 120132.2619205124], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7069800.0000, 
sim time next is 7070400.0000, 
raw observation next is [18.8, 90.0, 1.0, 2.0, 0.3655309196119287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 408668.0784307547, 408668.0784307547, 120223.4895621449], 
processed observation next is [1.0, 0.8695652173913043, 0.49090909090909096, 0.9, 1.0, 1.0, 0.20691364951491084, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1513585475669462, 0.1513585475669462, 0.29322802332230463], 
reward next is 0.7068, 
noisyNet noise sample is [array([-1.87026], dtype=float32), -1.0914711]. 
=============================================
[2019-03-23 14:14:22,752] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.8345433e-11 1.0000000e+00 8.0597906e-22 7.1764885e-22 4.7197510e-11], sum to 1.0000
[2019-03-23 14:14:22,762] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1026
[2019-03-23 14:14:22,769] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 54.0, 1.0, 2.0, 0.3203476791393048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 349571.7293260719, 349571.7293260721, 113170.9100942428], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7150200.0000, 
sim time next is 7150800.0000, 
raw observation next is [21.96666666666667, 55.0, 1.0, 2.0, 0.3176576905154065, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 345519.6629993082, 345519.6629993079, 112592.334260119], 
processed observation next is [1.0, 0.782608695652174, 0.6348484848484849, 0.55, 1.0, 1.0, 0.14707211314425808, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12797024555529934, 0.12797024555529923, 0.2746154494149244], 
reward next is 0.7254, 
noisyNet noise sample is [array([0.02435945], dtype=float32), 1.2550564]. 
=============================================
[2019-03-23 14:14:23,246] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3453439e-08 1.0000000e+00 3.2698562e-22 8.5060881e-21 2.3198763e-09], sum to 1.0000
[2019-03-23 14:14:23,251] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7518
[2019-03-23 14:14:23,254] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 63.0, 1.0, 2.0, 0.2547388989450258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 276594.8400094663, 276594.840009466, 83755.6886854631], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7160400.0000, 
sim time next is 7161000.0000, 
raw observation next is [18.11666666666667, 64.16666666666667, 1.0, 2.0, 0.2530809362137678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 274794.1197782113, 274794.119778211, 83493.28668188541], 
processed observation next is [1.0, 0.9130434782608695, 0.459848484848485, 0.6416666666666667, 1.0, 1.0, 0.06635117026720976, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10177559991785604, 0.10177559991785592, 0.2036421626387449], 
reward next is 0.7964, 
noisyNet noise sample is [array([-1.5702908], dtype=float32), 0.3937069]. 
=============================================
[2019-03-23 14:14:23,273] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[68.53048]
 [68.59837]
 [68.6928 ]
 [68.76748]
 [68.83896]], R is [[68.57131958]
 [68.68132019]
 [68.78884888]
 [68.89388275]
 [68.996315  ]].
[2019-03-23 14:14:29,596] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.1248166e-07 9.9999964e-01 5.4528292e-18 8.3274946e-17 5.5832725e-09], sum to 1.0000
[2019-03-23 14:14:29,601] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7897
[2019-03-23 14:14:29,610] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.2, 80.0, 1.0, 2.0, 0.2000916645616575, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 217245.7623183948, 217245.7623183951, 71568.70815778337], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7281600.0000, 
sim time next is 7282200.0000, 
raw observation next is [14.3, 80.5, 1.0, 2.0, 0.2030408445510181, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 220448.5046405575, 220448.5046405575, 72168.65456286567], 
processed observation next is [1.0, 0.2608695652173913, 0.2863636363636364, 0.805, 1.0, 1.0, 0.003801055688772599, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.0816475943113176, 0.0816475943113176, 0.17602110868991627], 
reward next is 0.8240, 
noisyNet noise sample is [array([0.95793676], dtype=float32), 1.5949779]. 
=============================================
[2019-03-23 14:14:29,767] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.1711623e-07 9.9999928e-01 2.9787984e-18 2.5012549e-16 5.6226622e-07], sum to 1.0000
[2019-03-23 14:14:29,775] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2665
[2019-03-23 14:14:29,778] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.9, 87.16666666666666, 1.0, 2.0, 0.21340017600327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 231698.6698798368, 231698.6698798371, 74040.53089377288], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7267800.0000, 
sim time next is 7268400.0000, 
raw observation next is [13.8, 87.0, 1.0, 2.0, 0.2106262290411179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 228686.1563698546, 228686.1563698546, 73426.83876367976], 
processed observation next is [1.0, 0.13043478260869565, 0.26363636363636367, 0.87, 1.0, 1.0, 0.013282786301397377, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08469857643327948, 0.08469857643327948, 0.17908985064312136], 
reward next is 0.8209, 
noisyNet noise sample is [array([0.64545524], dtype=float32), -0.3064726]. 
=============================================
[2019-03-23 14:14:32,884] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.7256816e-10 9.9999988e-01 1.4982790e-20 7.9045670e-21 6.6088035e-08], sum to 1.0000
[2019-03-23 14:14:32,885] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4056
[2019-03-23 14:14:32,893] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.08333333333334, 46.16666666666666, 1.0, 2.0, 0.3404725264292291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 378107.7282218347, 378107.7282218344, 117081.1192500866], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7321800.0000, 
sim time next is 7322400.0000, 
raw observation next is [25.0, 46.0, 1.0, 2.0, 0.3408225332353125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 377939.7814750216, 377939.7814750216, 116879.3745416186], 
processed observation next is [1.0, 0.782608695652174, 0.7727272727272727, 0.46, 1.0, 1.0, 0.17602816654414058, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1399776968426006, 0.1399776968426006, 0.28507164522346], 
reward next is 0.7149, 
noisyNet noise sample is [array([-1.1143525], dtype=float32), 0.48116803]. 
=============================================
[2019-03-23 14:14:37,183] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.0087887e-09 1.0000000e+00 6.7962542e-20 1.0211653e-19 2.8830245e-11], sum to 1.0000
[2019-03-23 14:14:37,194] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1500
[2019-03-23 14:14:37,200] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.53333333333333, 96.66666666666667, 1.0, 2.0, 0.356478451827405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 395872.0790086445, 395872.0790086445, 118329.4115254956], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7435200.0000, 
sim time next is 7435800.0000, 
raw observation next is [17.45, 96.5, 1.0, 2.0, 0.3541708469446268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 392692.8397521357, 392692.8397521357, 117896.9893693396], 
processed observation next is [0.0, 0.043478260869565216, 0.4295454545454545, 0.965, 1.0, 1.0, 0.1927135586807835, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.145441792500791, 0.145441792500791, 0.28755363260814537], 
reward next is 0.7124, 
noisyNet noise sample is [array([-0.0911743], dtype=float32), 0.7940613]. 
=============================================
[2019-03-23 14:14:37,692] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.7555001e-11 1.0000000e+00 5.3057163e-23 1.4735208e-20 1.2937508e-11], sum to 1.0000
[2019-03-23 14:14:37,697] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6376
[2019-03-23 14:14:37,701] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 90.0, 1.0, 2.0, 0.3784833557028973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 423226.7126907096, 423226.7126907099, 121338.1590476795], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7424400.0000, 
sim time next is 7425000.0000, 
raw observation next is [18.8, 90.0, 1.0, 2.0, 0.3777429747719234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 422395.5133996037, 422395.5133996034, 121274.3316233929], 
processed observation next is [1.0, 0.9565217391304348, 0.49090909090909096, 0.9, 1.0, 1.0, 0.22217871846490425, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15644278274059398, 0.15644278274059387, 0.2957910527399827], 
reward next is 0.7042, 
noisyNet noise sample is [array([-0.03451354], dtype=float32), -0.7618978]. 
=============================================
[2019-03-23 14:14:37,725] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[65.37074 ]
 [65.41012 ]
 [65.44548 ]
 [65.44504 ]
 [65.448425]], R is [[65.39590454]
 [65.44599915]
 [65.49573517]
 [65.54450989]
 [65.59073639]].
[2019-03-23 14:14:39,551] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4245158e-08 1.0000000e+00 1.2949521e-20 1.9176986e-17 3.2700929e-11], sum to 1.0000
[2019-03-23 14:14:39,558] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8707
[2019-03-23 14:14:39,573] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.68333333333333, 86.5, 1.0, 2.0, 0.3668735738326588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 412139.5827249974, 412139.5827249977, 121269.2615325897], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7459800.0000, 
sim time next is 7460400.0000, 
raw observation next is [19.96666666666667, 86.0, 1.0, 2.0, 0.3732557413888919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 420305.9020279915, 420305.9020279918, 122322.9167880176], 
processed observation next is [0.0, 0.34782608695652173, 0.5439393939393941, 0.86, 1.0, 1.0, 0.21656967673611485, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15566885260295982, 0.15566885260295993, 0.29834857753175026], 
reward next is 0.7017, 
noisyNet noise sample is [array([-0.968737], dtype=float32), 0.83953667]. 
=============================================
[2019-03-23 14:14:42,084] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8980426e-08 1.0000000e+00 2.5045979e-24 3.9689220e-22 1.0999226e-11], sum to 1.0000
[2019-03-23 14:14:42,093] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2227
[2019-03-23 14:14:42,099] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.43333333333334, 54.33333333333334, 1.0, 2.0, 0.500599284149318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 570756.7129705144, 570756.7129705148, 142371.6539389306], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7489200.0000, 
sim time next is 7489800.0000, 
raw observation next is [28.25, 55.0, 1.0, 2.0, 0.4989302357746543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 568907.1413428747, 568907.1413428744, 142100.1950591807], 
processed observation next is [0.0, 0.6956521739130435, 0.9204545454545454, 0.55, 1.0, 1.0, 0.3736627947183178, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21070634864550916, 0.21070634864550902, 0.3465858416077578], 
reward next is 0.6534, 
noisyNet noise sample is [array([0.04139157], dtype=float32), 1.0353886]. 
=============================================
[2019-03-23 14:14:43,352] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.4066881e-11 1.0000000e+00 3.5672961e-24 1.8675705e-21 2.3516237e-12], sum to 1.0000
[2019-03-23 14:14:43,357] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6531
[2019-03-23 14:14:43,359] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.98333333333333, 65.0, 1.0, 2.0, 0.4930948570046049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 562572.8054262019, 562572.8054262019, 140779.6859844341], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7559400.0000, 
sim time next is 7560000.0000, 
raw observation next is [26.1, 64.0, 1.0, 2.0, 0.4891846457281034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558142.2564397618, 558142.2564397618, 140217.6245380648], 
processed observation next is [0.0, 0.5217391304347826, 0.8227272727272728, 0.64, 1.0, 1.0, 0.3614808071601292, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20671935423694884, 0.20671935423694884, 0.34199420619040194], 
reward next is 0.6580, 
noisyNet noise sample is [array([0.9740557], dtype=float32), -0.84141576]. 
=============================================
[2019-03-23 14:14:43,371] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[66.836334]
 [66.84352 ]
 [66.85377 ]
 [66.853455]
 [66.85265 ]], R is [[66.84037781]
 [66.82860565]
 [66.81616211]
 [66.80374908]
 [66.79124451]].
[2019-03-23 14:14:45,192] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 14:14:45,193] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:14:45,194] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:14:45,194] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:14:45,194] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:14:45,195] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:14:45,196] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:14:45,195] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:14:45,196] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:14:45,197] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:14:45,197] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:14:45,217] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run43
[2019-03-23 14:14:45,245] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run43
[2019-03-23 14:14:45,246] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run43
[2019-03-23 14:14:45,271] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run43
[2019-03-23 14:14:45,331] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run43
[2019-03-23 14:15:04,889] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06498577], dtype=float32), 0.19909602]
[2019-03-23 14:15:04,891] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.52583457666667, 80.61569273333333, 1.0, 2.0, 0.472666411586911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 527768.6934090507, 527768.6934090503, 133837.1453720104]
[2019-03-23 14:15:04,892] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:15:04,895] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.4275335e-10 1.0000000e+00 1.1581680e-22 3.8385017e-21 3.7023835e-12], sampled 0.42639404868339237
[2019-03-23 14:15:15,484] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06498577], dtype=float32), 0.19909602]
[2019-03-23 14:15:15,486] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.73333333333333, 92.0, 1.0, 2.0, 0.3088586403924025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 335378.1779925019, 335378.1779925022, 111789.6299509721]
[2019-03-23 14:15:15,487] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:15:15,491] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.6107232e-10 1.0000000e+00 1.5103513e-22 4.9152340e-21 4.2534266e-12], sampled 0.16600862120058213
[2019-03-23 14:15:17,242] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06498577], dtype=float32), 0.19909602]
[2019-03-23 14:15:17,245] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.83333333333333, 77.0, 1.0, 2.0, 0.3891277542125294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 437129.7587015657, 437129.7587015653, 127500.5091476597]
[2019-03-23 14:15:17,246] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:15:17,248] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.8934943e-11 1.0000000e+00 4.0979387e-23 1.4571087e-21 2.1480701e-12], sampled 0.9054230858074691
[2019-03-23 14:15:32,605] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06498577], dtype=float32), 0.19909602]
[2019-03-23 14:15:32,606] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.66666666666667, 77.33333333333333, 1.0, 2.0, 0.3813775732710532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 427812.2980949028, 427812.2980949028, 126529.3681756496]
[2019-03-23 14:15:32,608] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:15:32,611] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.2418391e-10 1.0000000e+00 8.5293118e-23 2.8857496e-21 3.1538504e-12], sampled 0.2722317861716905
[2019-03-23 14:15:35,357] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06498577], dtype=float32), 0.19909602]
[2019-03-23 14:15:35,359] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.9, 100.0, 1.0, 2.0, 0.3028478409433902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 328849.0662544512, 328849.0662544515, 111383.2118593207]
[2019-03-23 14:15:35,360] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:15:35,364] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.5171485e-10 1.0000000e+00 1.3239615e-22 4.3482647e-21 3.9710019e-12], sampled 0.1054759549034533
[2019-03-23 14:15:35,656] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06498577], dtype=float32), 0.19909602]
[2019-03-23 14:15:35,658] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.97390268666667, 100.0, 1.0, 2.0, 0.4830091591118824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 551013.136465932, 551013.136465932, 143890.1657529879]
[2019-03-23 14:15:35,661] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:15:35,664] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.6676152e-11 1.0000000e+00 3.8723093e-23 1.3824129e-21 2.0856177e-12], sampled 0.27104948644727556
[2019-03-23 14:15:42,676] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06498577], dtype=float32), 0.19909602]
[2019-03-23 14:15:42,678] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.53333333333333, 87.33333333333334, 1.0, 2.0, 0.5042353630493148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 575209.2440504493, 575209.2440504493, 146424.7354184427]
[2019-03-23 14:15:42,679] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:15:42,681] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.2501520e-11 1.0000000e+00 4.4687134e-23 1.5792348e-21 2.2476188e-12], sampled 0.5567808533790485
[2019-03-23 14:15:46,359] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06498577], dtype=float32), 0.19909602]
[2019-03-23 14:15:46,360] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.65491653, 100.0, 1.0, 2.0, 0.4269850363279915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 485939.298001172, 485939.298001172, 134911.0938886577]
[2019-03-23 14:15:46,361] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:15:46,363] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.03205305e-10 1.00000000e+00 5.68070602e-23 1.97597414e-21
 2.54925725e-12], sampled 0.10669916725560669
[2019-03-23 14:15:51,406] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06498577], dtype=float32), 0.19909602]
[2019-03-23 14:15:51,407] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.4, 48.0, 1.0, 2.0, 0.4627924694972271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 518547.0048659008, 518547.0048659005, 133678.2020380241]
[2019-03-23 14:15:51,408] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:15:51,414] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.6086509e-10 1.0000000e+00 1.5055654e-22 4.9012099e-21 4.2475489e-12], sampled 0.6142850058682727
[2019-03-23 14:16:21,057] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06498577], dtype=float32), 0.19909602]
[2019-03-23 14:16:21,059] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.53237537, 96.75818491, 1.0, 2.0, 0.3129613543344331, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 340721.1662273108, 340721.1662273104, 116691.6672972952]
[2019-03-23 14:16:21,060] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:16:21,064] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0283020e-10 1.0000000e+00 5.6370789e-23 1.9614050e-21 2.5384712e-12], sampled 0.5190021528460832
[2019-03-23 14:16:27,513] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 14:16:27,718] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3791 1683296663.2329 214.0000
[2019-03-23 14:16:27,789] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:16:27,888] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 14:16:28,041] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 14:16:29,058] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1050000, evaluation results [1050000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.379088229873, 1683296663.232874, 214.0]
[2019-03-23 14:16:29,620] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.0796267e-09 1.0000000e+00 7.2209232e-21 4.1704906e-19 8.2950098e-11], sum to 1.0000
[2019-03-23 14:16:29,628] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0953
[2019-03-23 14:16:29,636] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 96.0, 1.0, 2.0, 0.4365173406285046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 496513.2129724653, 496513.2129724656, 131247.8562464824], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7596000.0000, 
sim time next is 7596600.0000, 
raw observation next is [20.01666666666667, 96.0, 1.0, 2.0, 0.4369698830219297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 497096.705571554, 497096.7055715543, 131356.9094439003], 
processed observation next is [0.0, 0.9565217391304348, 0.5462121212121214, 0.96, 1.0, 1.0, 0.29621235377741206, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1841098909524274, 0.18410989095242752, 0.3203827059607325], 
reward next is 0.6796, 
noisyNet noise sample is [array([-0.30944958], dtype=float32), 1.1269903]. 
=============================================
[2019-03-23 14:16:32,436] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.1067693e-09 1.0000000e+00 1.4126212e-16 6.3097845e-16 2.1195184e-10], sum to 1.0000
[2019-03-23 14:16:32,442] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2699
[2019-03-23 14:16:32,448] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1216026.458658882 W.
[2019-03-23 14:16:32,453] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.46666666666667, 54.33333333333334, 1.0, 2.0, 0.5870192549836204, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9760374240119225, 6.911200000000001, 6.9112, 77.32846344354104, 1216026.458658882, 1216026.458658881, 274672.0862493482], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7658400.0000, 
sim time next is 7659000.0000, 
raw observation next is [28.55, 54.0, 1.0, 2.0, 0.5612571091349602, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9738768964724341, 6.912938227503329, 6.9112, 77.3284591793963, 1187313.712308008, 1186749.171598958, 269830.6084546229], 
processed observation next is [1.0, 0.6521739130434783, 0.9340909090909091, 0.54, 1.0, 1.0, 0.4515713864187002, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9626812806749061, 0.00017382275033286376, 0.0, 0.5084287848842242, 0.4397458193733363, 0.4395367302218363, 0.6581234352551778], 
reward next is 0.3332, 
noisyNet noise sample is [array([-0.5470023], dtype=float32), 1.9340148]. 
=============================================
[2019-03-23 14:16:32,482] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[45.421204]
 [44.402336]
 [45.216286]
 [45.54117 ]
 [45.643528]], R is [[45.66628647]
 [45.53969193]
 [45.3452034 ]
 [45.29432297]
 [44.84138107]].
[2019-03-23 14:16:48,744] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:16:48,744] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:16:48,749] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run6
[2019-03-23 14:16:48,853] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:16:48,853] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:16:48,858] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run6
[2019-03-23 14:16:48,937] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:16:48,937] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:16:48,941] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run6
[2019-03-23 14:16:49,078] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:16:49,079] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:16:49,083] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run6
[2019-03-23 14:16:49,198] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:16:49,198] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:16:49,202] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run6
[2019-03-23 14:16:49,226] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:16:49,227] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:16:49,232] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run6
[2019-03-23 14:16:49,254] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:16:49,255] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:16:49,258] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run6
[2019-03-23 14:16:49,283] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:16:49,283] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:16:49,287] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run6
[2019-03-23 14:16:49,314] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:16:49,315] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:16:49,319] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run6
[2019-03-23 14:16:49,436] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:16:49,437] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:16:49,440] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run6
[2019-03-23 14:16:49,479] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:16:49,480] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:16:49,490] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run6
[2019-03-23 14:16:49,573] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:16:49,574] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:16:49,593] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run6
[2019-03-23 14:16:49,701] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:16:49,702] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:16:49,702] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:16:49,702] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:16:49,715] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run6
[2019-03-23 14:16:49,706] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run6
[2019-03-23 14:16:49,705] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:16:49,806] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:16:49,703] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:16:49,829] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:16:49,832] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run6
[2019-03-23 14:16:49,987] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run6
[2019-03-23 14:16:58,088] A3C_AGENT_WORKER-Thread-3 INFO:Local step 66500, global step 1063583: loss 0.0702
[2019-03-23 14:16:58,090] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 66500, global step 1063584: learning rate 0.0000
[2019-03-23 14:16:58,164] A3C_AGENT_WORKER-Thread-9 INFO:Local step 66500, global step 1063625: loss 0.0005
[2019-03-23 14:16:58,166] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 66500, global step 1063625: learning rate 0.0000
[2019-03-23 14:16:58,265] A3C_AGENT_WORKER-Thread-20 INFO:Local step 66500, global step 1063677: loss 0.0594
[2019-03-23 14:16:58,268] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 66500, global step 1063678: learning rate 0.0000
[2019-03-23 14:16:58,420] A3C_AGENT_WORKER-Thread-14 INFO:Local step 66500, global step 1063759: loss 0.0029
[2019-03-23 14:16:58,422] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 66500, global step 1063759: learning rate 0.0000
[2019-03-23 14:16:58,537] A3C_AGENT_WORKER-Thread-13 INFO:Local step 66500, global step 1063819: loss 0.0271
[2019-03-23 14:16:58,540] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 66500, global step 1063820: learning rate 0.0000
[2019-03-23 14:16:58,674] A3C_AGENT_WORKER-Thread-22 INFO:Local step 66500, global step 1063888: loss 0.0020
[2019-03-23 14:16:58,676] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 66500, global step 1063888: learning rate 0.0000
[2019-03-23 14:16:58,747] A3C_AGENT_WORKER-Thread-21 INFO:Local step 66500, global step 1063927: loss 0.0138
[2019-03-23 14:16:58,750] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 66500, global step 1063928: learning rate 0.0000
[2019-03-23 14:16:58,770] A3C_AGENT_WORKER-Thread-2 INFO:Local step 66500, global step 1063935: loss 0.0188
[2019-03-23 14:16:58,774] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 66500, global step 1063938: learning rate 0.0000
[2019-03-23 14:16:58,784] A3C_AGENT_WORKER-Thread-12 INFO:Local step 66500, global step 1063945: loss 0.0289
[2019-03-23 14:16:58,785] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 66500, global step 1063945: learning rate 0.0000
[2019-03-23 14:16:58,880] A3C_AGENT_WORKER-Thread-11 INFO:Local step 66500, global step 1063994: loss 0.0558
[2019-03-23 14:16:58,882] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 66500, global step 1063994: learning rate 0.0000
[2019-03-23 14:16:58,974] A3C_AGENT_WORKER-Thread-16 INFO:Local step 66500, global step 1064045: loss 0.0072
[2019-03-23 14:16:58,978] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 66500, global step 1064046: learning rate 0.0000
[2019-03-23 14:16:59,259] A3C_AGENT_WORKER-Thread-10 INFO:Local step 66500, global step 1064197: loss 0.0006
[2019-03-23 14:16:59,260] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 66500, global step 1064197: learning rate 0.0000
[2019-03-23 14:16:59,374] A3C_AGENT_WORKER-Thread-17 INFO:Local step 66500, global step 1064256: loss 0.0105
[2019-03-23 14:16:59,375] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 66500, global step 1064256: learning rate 0.0000
[2019-03-23 14:16:59,545] A3C_AGENT_WORKER-Thread-19 INFO:Local step 66500, global step 1064346: loss 0.0157
[2019-03-23 14:16:59,548] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 66500, global step 1064347: learning rate 0.0000
[2019-03-23 14:16:59,604] A3C_AGENT_WORKER-Thread-15 INFO:Local step 66500, global step 1064378: loss 0.0121
[2019-03-23 14:16:59,608] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 66500, global step 1064378: learning rate 0.0000
[2019-03-23 14:16:59,649] A3C_AGENT_WORKER-Thread-18 INFO:Local step 66500, global step 1064402: loss 0.0302
[2019-03-23 14:16:59,651] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 66500, global step 1064403: learning rate 0.0000
[2019-03-23 14:17:06,523] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 9.4827618e-11 3.0540257e-34 3.2761165e-34 5.6617808e-29], sum to 1.0000
[2019-03-23 14:17:06,530] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8936
[2019-03-23 14:17:06,540] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.0, 45.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4752493319281098, 6.9112, 6.9112, 77.32846344354104, 276424.7282769462, 276424.7282769462, 82423.21457840248], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 308400.0000, 
sim time next is 309000.0000, 
raw observation next is [21.0, 44.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4786277410437258, 6.9112, 6.9112, 77.32846344354104, 278390.3135770482, 278390.3135770482, 81715.06482697059], 
processed observation next is [0.0, 0.5652173913043478, 0.5909090909090909, 0.44, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2551824872053226, 0.0, 0.0, 0.5084288129206541, 0.10310752354705488, 0.10310752354705488, 0.19930503616334289], 
reward next is 0.8007, 
noisyNet noise sample is [array([1.5444223], dtype=float32), -0.39455515]. 
=============================================
[2019-03-23 14:17:06,555] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[76.09413 ]
 [76.06982 ]
 [76.00337 ]
 [75.94531 ]
 [75.870865]], R is [[76.16409302]
 [76.20141602]
 [76.23593903]
 [76.26768494]
 [76.29667664]].
[2019-03-23 14:17:13,048] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67000, global step 1071536: loss 0.0835
[2019-03-23 14:17:13,053] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67000, global step 1071536: learning rate 0.0000
[2019-03-23 14:17:13,334] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67000, global step 1071691: loss 0.2461
[2019-03-23 14:17:13,336] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67000, global step 1071691: learning rate 0.0000
[2019-03-23 14:17:13,381] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67000, global step 1071710: loss 0.3945
[2019-03-23 14:17:13,382] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67000, global step 1071710: learning rate 0.0000
[2019-03-23 14:17:13,397] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67000, global step 1071717: loss 0.3306
[2019-03-23 14:17:13,398] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67000, global step 1071717: learning rate 0.0000
[2019-03-23 14:17:13,596] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67000, global step 1071828: loss 1.1838
[2019-03-23 14:17:13,599] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67000, global step 1071829: learning rate 0.0000
[2019-03-23 14:17:13,675] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67000, global step 1071866: loss 113.7830
[2019-03-23 14:17:13,680] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67000, global step 1071867: learning rate 0.0000
[2019-03-23 14:17:13,740] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 7.7109330e-18 0.0000000e+00 3.2937285e-38 2.2291503e-30], sum to 1.0000
[2019-03-23 14:17:13,747] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5753
[2019-03-23 14:17:13,758] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 602536.4805450242 W.
[2019-03-23 14:17:13,765] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.5547394215962042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 602536.4805450242, 602536.4805450242, 111867.6658572172], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 453000.0000, 
sim time next is 453600.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2800866760842228, 1.0, 1.0, 0.2800866760842228, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 608442.2999204869, 608442.2999204866, 146879.5861874987], 
processed observation next is [1.0, 0.2608695652173913, 0.22727272727272727, 1.0, 1.0, 1.0, 0.10010834510527845, 1.0, 0.5, 0.10010834510527845, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2253489999705507, 0.2253489999705506, 0.3582428931402407], 
reward next is 0.6418, 
noisyNet noise sample is [array([1.1306316], dtype=float32), -0.17525592]. 
=============================================
[2019-03-23 14:17:13,877] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67000, global step 1071972: loss 107.4915
[2019-03-23 14:17:13,881] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67000, global step 1071973: learning rate 0.0000
[2019-03-23 14:17:13,897] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67000, global step 1071982: loss 99.1920
[2019-03-23 14:17:13,899] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67000, global step 1071982: learning rate 0.0000
[2019-03-23 14:17:13,957] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67000, global step 1072014: loss 112.1097
[2019-03-23 14:17:13,959] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67000, global step 1072014: learning rate 0.0000
[2019-03-23 14:17:13,959] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67000, global step 1072014: loss 240.5403
[2019-03-23 14:17:13,964] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67000, global step 1072015: learning rate 0.0000
[2019-03-23 14:17:13,996] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67000, global step 1072033: loss 30.2759
[2019-03-23 14:17:13,998] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67000, global step 1072033: learning rate 0.0000
[2019-03-23 14:17:14,344] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67000, global step 1072210: loss -211.1192
[2019-03-23 14:17:14,346] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67000, global step 1072212: learning rate 0.0000
[2019-03-23 14:17:14,507] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67000, global step 1072296: loss -1.3951
[2019-03-23 14:17:14,510] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67000, global step 1072297: learning rate 0.0000
[2019-03-23 14:17:14,594] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67000, global step 1072348: loss -99.8141
[2019-03-23 14:17:14,597] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67000, global step 1072348: learning rate 0.0000
[2019-03-23 14:17:14,675] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67000, global step 1072386: loss -209.6378
[2019-03-23 14:17:14,676] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67000, global step 1072386: learning rate 0.0000
[2019-03-23 14:17:14,776] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67000, global step 1072441: loss -233.9041
[2019-03-23 14:17:14,781] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67000, global step 1072441: learning rate 0.0000
[2019-03-23 14:17:19,213] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9583286e-01 4.1671386e-03 1.3054351e-18 3.1613700e-16 5.5407137e-11], sum to 1.0000
[2019-03-23 14:17:19,219] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7927
[2019-03-23 14:17:19,225] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.0, 94.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.6076514772767946, 6.9112, 6.9112, 77.32846344354104, 353463.295596047, 353463.295596047, 85193.13135626803], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 541800.0000, 
sim time next is 542400.0000, 
raw observation next is [14.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4162421473935798, 6.911199999999998, 6.9112, 77.32846344354104, 242095.159856794, 242095.1598567945, 75934.73178648407], 
processed observation next is [1.0, 0.2608695652173913, 0.2727272727272727, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.16606021056225687, -1.7763568394002506e-16, 0.0, 0.5084288129206541, 0.08966487402103482, 0.089664874021035, 0.1852066628938636], 
reward next is 0.8148, 
noisyNet noise sample is [array([0.76449865], dtype=float32), 0.53823054]. 
=============================================
[2019-03-23 14:17:19,246] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 7.4465757e-17 2.1553475e-30 2.6738251e-28 7.1406496e-25], sum to 1.0000
[2019-03-23 14:17:19,251] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7316
[2019-03-23 14:17:19,256] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.66666666666667, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4756802124797102, 6.911199999999999, 6.9112, 77.32846344354104, 276675.4175677272, 276675.4175677274, 87789.94364967597], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 546600.0000, 
sim time next is 547200.0000, 
raw observation next is [16.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4811156679434008, 6.9112, 6.9112, 77.32846344354104, 279837.8143188721, 279837.8143188721, 90292.72319427745], 
processed observation next is [1.0, 0.34782608695652173, 0.36363636363636365, 0.88, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.25873666849057264, 0.0, 0.0, 0.5084288129206541, 0.1036436349329156, 0.1036436349329156, 0.22022615413238403], 
reward next is 0.7798, 
noisyNet noise sample is [array([1.6156745], dtype=float32), 0.64039123]. 
=============================================
[2019-03-23 14:17:19,619] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 14:17:19,620] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:17:19,621] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:17:19,621] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:17:19,622] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:17:19,623] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:17:19,624] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:17:19,624] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:17:19,625] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:17:19,625] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:17:19,627] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:17:19,641] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run44
[2019-03-23 14:17:19,668] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run44
[2019-03-23 14:17:19,668] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run44
[2019-03-23 14:17:19,723] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run44
[2019-03-23 14:17:19,752] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run44
[2019-03-23 14:17:29,182] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06421962], dtype=float32), 0.1993187]
[2019-03-23 14:17:29,183] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.66666666666666, 84.66666666666667, 1.0, 1.0, 0.4396588368737931, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32825950199367, 498168.7179640622, 498168.7179640622, 130102.4903343736]
[2019-03-23 14:17:29,185] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:17:29,187] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 2.2043781e-26 1.2448541e-35 1.7386849e-34 2.1769286e-32], sampled 0.30820904641971214
[2019-03-23 14:17:30,972] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06421962], dtype=float32), 0.1993187]
[2019-03-23 14:17:30,974] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.8, 41.66666666666667, 1.0, 1.0, 0.4295863012702613, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 95.55318751746184, 485407.948428616, 485407.948428616, 132626.2057489879]
[2019-03-23 14:17:30,976] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:17:30,980] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0000000e+00 8.4478707e-31 0.0000000e+00 0.0000000e+00 3.1931599e-37], sampled 0.2774735608640536
[2019-03-23 14:18:23,255] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06421962], dtype=float32), 0.1993187]
[2019-03-23 14:18:23,256] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [12.8, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3429719743658108, 6.9112, 6.9112, 95.55338769695034, 199475.3522859719, 199475.3522859719, 64405.82368122839]
[2019-03-23 14:18:23,259] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:18:23,262] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 1.2802933e-38 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.004404146341814741
[2019-03-23 14:18:31,752] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06421962], dtype=float32), 0.1993187]
[2019-03-23 14:18:31,752] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.0, 60.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.492148136224295, 6.9112, 6.9112, 95.55338769695034, 286240.6004282705, 286240.6004282705, 91658.16801293837]
[2019-03-23 14:18:31,756] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:18:31,758] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.6317726827996815
[2019-03-23 14:18:41,850] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06421962], dtype=float32), 0.1993187]
[2019-03-23 14:18:41,853] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.17579502833333, 62.61840251, 1.0, 2.0, 0.4428723919152167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338702745104, 504679.7614908613, 504679.7614908617, 137283.472563927]
[2019-03-23 14:18:41,854] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:18:41,857] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0000000e+00 1.2274593e-19 5.1301902e-31 7.4399674e-30 3.7329610e-26], sampled 0.8416801257285094
[2019-03-23 14:18:49,842] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06421962], dtype=float32), 0.1993187]
[2019-03-23 14:18:49,843] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.31666666666667, 96.83333333333334, 1.0, 2.0, 0.5444808275486305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354103, 620676.0480931813, 620676.0480931813, 144339.0673512719]
[2019-03-23 14:18:49,844] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:18:49,847] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 8.4135146e-18 1.5096951e-29 2.1606512e-28 2.1915185e-24], sampled 0.6093920060920686
[2019-03-23 14:18:49,848] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 620676.0480931813 W.
[2019-03-23 14:18:50,020] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06421962], dtype=float32), 0.1993187]
[2019-03-23 14:18:50,022] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.9, 96.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7621720192241603, 7.291224620834284, 6.9112, 77.32728559196433, 560580.3118161546, 437157.9677897859, 133511.1011816154]
[2019-03-23 14:18:50,024] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:18:50,027] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.000000e+00 1.305560e-30 0.000000e+00 0.000000e+00 4.007687e-37], sampled 0.1565926320314811
[2019-03-23 14:18:50,028] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 560580.3118161546 W.
[2019-03-23 14:18:53,673] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06421962], dtype=float32), 0.1993187]
[2019-03-23 14:18:53,674] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.3, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.480090627865507, 6.911200000000001, 6.9112, 95.55338769695034, 279226.147083301, 279226.1470833007, 90077.57876141713]
[2019-03-23 14:18:53,676] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:18:53,681] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 1.0141837e-37 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.09408415151572913
[2019-03-23 14:19:01,537] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06421962], dtype=float32), 0.1993187]
[2019-03-23 14:19:01,539] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.7, 75.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6182668234184246, 6.911199999999999, 6.9112, 77.32846344354104, 358263.6450910629, 358263.6450910632, 116037.7052135576]
[2019-03-23 14:19:01,540] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:19:01,546] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 1.1882079e-32 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.9320904673399613
[2019-03-23 14:19:01,915] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6328.7217 1723294598.4314 3425.0000
[2019-03-23 14:19:02,267] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6294.2336 1685637051.0100 3227.0000
[2019-03-23 14:19:02,271] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6862.2842 1793014293.7888 2409.0000
[2019-03-23 14:19:02,384] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6553.1725 1698634175.0084 2957.0000
[2019-03-23 14:19:02,404] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6481.5837 1678897646.1340 3057.0000
[2019-03-23 14:19:03,419] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1075000, evaluation results [1075000.0, 6862.284208925443, 1793014293.78876, 2409.0, 6481.5837183961685, 1678897646.1340423, 3057.0, 6294.233601728252, 1685637051.0100183, 3227.0, 6328.721692698646, 1723294598.4313502, 3425.0, 6553.172466661831, 1698634175.0084193, 2957.0]
[2019-03-23 14:19:04,269] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 3.5494957e-34 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 14:19:04,276] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6676
[2019-03-23 14:19:04,280] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.16666666666667, 76.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6730245406534281, 6.911199999999999, 6.9112, 77.32846344354104, 388767.1178285255, 388767.1178285258, 121905.9223729586], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 586200.0000, 
sim time next is 586800.0000, 
raw observation next is [20.0, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6731825994471178, 6.911199999999999, 6.9112, 77.32846344354104, 388784.7405928556, 388784.7405928559, 121975.8163441266], 
processed observation next is [1.0, 0.8260869565217391, 0.5454545454545454, 0.78, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5331179992101683, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1439943483677243, 0.1439943483677244, 0.2975019910832356], 
reward next is 0.7025, 
noisyNet noise sample is [array([0.51558924], dtype=float32), -0.84704673]. 
=============================================
[2019-03-23 14:19:04,916] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.00000000e+00 2.59310217e-21 1.76191660e-38 1.01485814e-35
 4.47466104e-33], sum to 1.0000
[2019-03-23 14:19:04,926] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9271
[2019-03-23 14:19:04,932] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.16666666666667, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4660780533162099, 6.911200000000001, 6.9112, 77.32846344354104, 271088.8454725049, 271088.8454725046, 86726.32066652336], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 618600.0000, 
sim time next is 619200.0000, 
raw observation next is [15.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4623532920770269, 6.911200000000001, 6.9112, 77.32846344354104, 268921.782734085, 268921.7827340847, 85902.36387856999], 
processed observation next is [1.0, 0.17391304347826086, 0.3181818181818182, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.23193327439575276, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09960066027188333, 0.09960066027188322, 0.209517960679439], 
reward next is 0.7905, 
noisyNet noise sample is [array([2.2825472], dtype=float32), 0.07159172]. 
=============================================
[2019-03-23 14:19:06,896] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 4.2599846e-13 2.0699487e-30 1.7811099e-29 3.4661273e-23], sum to 1.0000
[2019-03-23 14:19:06,907] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8086
[2019-03-23 14:19:06,917] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.16666666666667, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4660780533162099, 6.911200000000001, 6.9112, 77.32846344354104, 271088.8454725049, 271088.8454725046, 86726.32066652336], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 618600.0000, 
sim time next is 619200.0000, 
raw observation next is [15.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4623532920770269, 6.911200000000001, 6.9112, 77.32846344354104, 268921.782734085, 268921.7827340847, 85902.36387856999], 
processed observation next is [1.0, 0.17391304347826086, 0.3181818181818182, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.23193327439575276, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09960066027188333, 0.09960066027188322, 0.209517960679439], 
reward next is 0.7905, 
noisyNet noise sample is [array([-0.50038004], dtype=float32), 0.5200814]. 
=============================================
[2019-03-23 14:19:07,627] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 6.2491630e-29 0.0000000e+00 5.1301133e-38 2.5500384e-36], sum to 1.0000
[2019-03-23 14:19:07,634] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7751
[2019-03-23 14:19:07,646] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.5, 49.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6980466513832285, 6.9112, 6.9112, 77.32846344354104, 400347.2724933724, 400347.2724933724, 126467.9615670201], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 667800.0000, 
sim time next is 668400.0000, 
raw observation next is [25.33333333333333, 49.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6968247162405785, 6.911199999999999, 6.9112, 77.32846344354104, 400628.4453121457, 400628.4453121459, 125634.4228782752], 
processed observation next is [1.0, 0.7391304347826086, 0.7878787878787876, 0.4933333333333333, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5668924517722551, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14838090567116508, 0.14838090567116516, 0.3064254216543298], 
reward next is 0.6936, 
noisyNet noise sample is [array([0.48121658], dtype=float32), -2.2047753]. 
=============================================
[2019-03-23 14:19:10,680] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 3.0399213e-30 0.0000000e+00 0.0000000e+00 6.8911211e-36], sum to 1.0000
[2019-03-23 14:19:10,686] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9455
[2019-03-23 14:19:10,692] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.5, 80.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6700653368502996, 6.911199999999999, 6.9112, 77.32846344354104, 387596.0526237994, 387596.0526237997, 121220.4273625504], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 718200.0000, 
sim time next is 718800.0000, 
raw observation next is [20.0, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7118222861851273, 6.920284897258322, 6.9112, 77.32841672425758, 414331.7998430918, 411381.2128145198, 125619.3062083496], 
processed observation next is [1.0, 0.30434782608695654, 0.5454545454545454, 0.78, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5883175516930391, 0.00090848972583224, 0.0, 0.5084285057448902, 0.15345622216410806, 0.15236341215352586, 0.306388551727682], 
reward next is 0.6482, 
noisyNet noise sample is [array([0.880883], dtype=float32), -2.2126713]. 
=============================================
[2019-03-23 14:19:12,198] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67500, global step 1079415: loss -242.0250
[2019-03-23 14:19:12,200] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67500, global step 1079417: learning rate 0.0000
[2019-03-23 14:19:12,772] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67500, global step 1079703: loss -92.2795
[2019-03-23 14:19:12,778] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67500, global step 1079705: learning rate 0.0000
[2019-03-23 14:19:12,797] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67500, global step 1079712: loss -107.5009
[2019-03-23 14:19:12,799] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67500, global step 1079712: learning rate 0.0000
[2019-03-23 14:19:12,950] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67500, global step 1079789: loss -43.4845
[2019-03-23 14:19:12,952] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67500, global step 1079790: learning rate 0.0000
[2019-03-23 14:19:13,145] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67500, global step 1079885: loss -58.7848
[2019-03-23 14:19:13,146] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67500, global step 1079885: learning rate 0.0000
[2019-03-23 14:19:13,239] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67500, global step 1079934: loss -32.9378
[2019-03-23 14:19:13,242] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67500, global step 1079934: learning rate 0.0000
[2019-03-23 14:19:13,269] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67500, global step 1079949: loss 25.8626
[2019-03-23 14:19:13,279] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67500, global step 1079951: learning rate 0.0000
[2019-03-23 14:19:13,319] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67500, global step 1079972: loss -42.4773
[2019-03-23 14:19:13,321] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67500, global step 1079972: learning rate 0.0000
[2019-03-23 14:19:13,351] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67500, global step 1079986: loss -65.8240
[2019-03-23 14:19:13,352] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67500, global step 1079986: learning rate 0.0000
[2019-03-23 14:19:13,462] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67500, global step 1080040: loss -65.7286
[2019-03-23 14:19:13,466] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67500, global step 1080041: learning rate 0.0000
[2019-03-23 14:19:13,545] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67500, global step 1080082: loss -44.0628
[2019-03-23 14:19:13,546] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67500, global step 1080082: learning rate 0.0000
[2019-03-23 14:19:13,669] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67500, global step 1080143: loss -13.3660
[2019-03-23 14:19:13,673] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67500, global step 1080143: learning rate 0.0000
[2019-03-23 14:19:13,810] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67500, global step 1080213: loss -87.6195
[2019-03-23 14:19:13,812] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67500, global step 1080213: learning rate 0.0000
[2019-03-23 14:19:13,930] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67500, global step 1080270: loss -43.3476
[2019-03-23 14:19:13,931] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67500, global step 1080270: learning rate 0.0000
[2019-03-23 14:19:14,075] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67500, global step 1080345: loss 26.6582
[2019-03-23 14:19:14,077] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67500, global step 1080346: learning rate 0.0000
[2019-03-23 14:19:14,377] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67500, global step 1080496: loss -16.0205
[2019-03-23 14:19:14,379] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67500, global step 1080496: learning rate 0.0000
[2019-03-23 14:19:21,844] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 2.1906426e-15 8.4428088e-17 2.7906091e-16 4.9628004e-16], sum to 1.0000
[2019-03-23 14:19:21,852] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5728
[2019-03-23 14:19:21,858] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.66666666666667, 75.33333333333333, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 1.0, 0.3156930566523418, 6.911199999999999, 6.9112, 77.3421103, 535130.9209065577, 535130.9209065579, 205301.698914754], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 913200.0000, 
sim time next is 913800.0000, 
raw observation next is [23.83333333333333, 74.66666666666667, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8038601927336926, 7.544975906055745, 6.9112, 77.32692580577826, 660624.1800198826, 454790.8216666202, 142952.7598504176], 
processed observation next is [0.0, 0.5652173913043478, 0.7196969696969695, 0.7466666666666667, 0.0, 0.5, -0.25, 0.0, 0.5, -0.25, 1.0, 1.0, 0.7198002753338465, 0.0633775906055745, 0.0, 0.5084187030683743, 0.24467562222958616, 0.16844104506171118, 0.34866526792784786], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.3583775], dtype=float32), 0.7327924]. 
=============================================
[2019-03-23 14:19:25,385] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.8753554e-07 9.9999952e-01 2.2886767e-19 4.4219013e-19 7.0725614e-10], sum to 1.0000
[2019-03-23 14:19:25,391] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6503
[2019-03-23 14:19:25,394] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3897073541600273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 437645.5902666529, 437645.5902666529, 123160.1220769558], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 979200.0000, 
sim time next is 979800.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3924630471788959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 440658.8130639003, 440658.8130639, 123361.7720155168], 
processed observation next is [1.0, 0.34782608695652173, 0.45454545454545453, 1.0, 1.0, 1.0, 0.24057880897361986, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16320696780144456, 0.16320696780144445, 0.3008823707695532], 
reward next is 0.6991, 
noisyNet noise sample is [array([-2.6931171], dtype=float32), 0.06903566]. 
=============================================
[2019-03-23 14:19:27,856] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68000, global step 1087301: loss 2.9370
[2019-03-23 14:19:27,859] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68000, global step 1087301: learning rate 0.0000
[2019-03-23 14:19:28,592] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68000, global step 1087695: loss 0.7739
[2019-03-23 14:19:28,595] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68000, global step 1087697: learning rate 0.0000
[2019-03-23 14:19:28,658] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68000, global step 1087732: loss 0.8081
[2019-03-23 14:19:28,660] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68000, global step 1087734: learning rate 0.0000
[2019-03-23 14:19:28,762] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68000, global step 1087784: loss 0.6801
[2019-03-23 14:19:28,764] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68000, global step 1087784: learning rate 0.0000
[2019-03-23 14:19:28,837] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68000, global step 1087826: loss 0.8272
[2019-03-23 14:19:28,843] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68000, global step 1087826: learning rate 0.0000
[2019-03-23 14:19:29,022] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68000, global step 1087922: loss 0.6984
[2019-03-23 14:19:29,023] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68000, global step 1087923: learning rate 0.0000
[2019-03-23 14:19:29,087] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68000, global step 1087957: loss 0.6676
[2019-03-23 14:19:29,090] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68000, global step 1087957: learning rate 0.0000
[2019-03-23 14:19:29,096] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68000, global step 1087961: loss 0.7826
[2019-03-23 14:19:29,102] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68000, global step 1087961: learning rate 0.0000
[2019-03-23 14:19:29,259] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68000, global step 1088046: loss 0.9171
[2019-03-23 14:19:29,260] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68000, global step 1088046: learning rate 0.0000
[2019-03-23 14:19:29,285] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68000, global step 1088059: loss 1.0828
[2019-03-23 14:19:29,287] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68000, global step 1088059: learning rate 0.0000
[2019-03-23 14:19:29,290] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68000, global step 1088060: loss 1.0197
[2019-03-23 14:19:29,291] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68000, global step 1088060: learning rate 0.0000
[2019-03-23 14:19:29,329] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68000, global step 1088080: loss 1.2276
[2019-03-23 14:19:29,332] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68000, global step 1088080: learning rate 0.0000
[2019-03-23 14:19:29,638] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68000, global step 1088239: loss 1.8169
[2019-03-23 14:19:29,639] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68000, global step 1088239: learning rate 0.0000
[2019-03-23 14:19:29,717] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68000, global step 1088286: loss 2.1171
[2019-03-23 14:19:29,722] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68000, global step 1088287: learning rate 0.0000
[2019-03-23 14:19:29,789] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68000, global step 1088318: loss 2.1690
[2019-03-23 14:19:29,791] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68000, global step 1088319: learning rate 0.0000
[2019-03-23 14:19:29,865] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.0886601e-07 9.9999964e-01 1.0394313e-21 2.4824323e-18 1.2282051e-09], sum to 1.0000
[2019-03-23 14:19:29,873] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9715
[2019-03-23 14:19:29,878] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2258507517259405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 245220.256842913, 245220.2568429127, 76689.73850449799], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1048800.0000, 
sim time next is 1049400.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2103041611653223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 228336.3910402417, 228336.3910402417, 74853.6741052901], 
processed observation next is [1.0, 0.13043478260869565, 0.22727272727272727, 1.0, 1.0, 1.0, 0.012880201456652862, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08456903371860804, 0.08456903371860804, 0.182569936842171], 
reward next is 0.8174, 
noisyNet noise sample is [array([-0.31478152], dtype=float32), -0.087812714]. 
=============================================
[2019-03-23 14:19:30,211] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68000, global step 1088547: loss 2.1288
[2019-03-23 14:19:30,215] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68000, global step 1088547: learning rate 0.0000
[2019-03-23 14:19:33,669] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.7447691e-07 9.9999952e-01 9.5883147e-19 2.8595065e-19 9.0629982e-08], sum to 1.0000
[2019-03-23 14:19:33,678] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6085
[2019-03-23 14:19:33,685] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.3430358853876961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 381699.1013899249, 381699.1013899252, 117592.6440204725], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1143600.0000, 
sim time next is 1144200.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.3426527449931661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 381271.7499714233, 381271.749971423, 117562.258273542], 
processed observation next is [1.0, 0.21739130434782608, 0.45454545454545453, 0.94, 1.0, 1.0, 0.17831593124145761, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1412117592486753, 0.14121175924867518, 0.28673721530132196], 
reward next is 0.7133, 
noisyNet noise sample is [array([0.6843164], dtype=float32), 0.26980615]. 
=============================================
[2019-03-23 14:19:40,319] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.5401092e-07 9.9999917e-01 1.6703425e-18 6.7778511e-17 1.4724763e-10], sum to 1.0000
[2019-03-23 14:19:40,325] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2565
[2019-03-23 14:19:40,328] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 64.66666666666667, 1.0, 2.0, 0.5092806193326702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 580316.7849342152, 580316.7849342152, 143791.0672747928], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1275600.0000, 
sim time next is 1276200.0000, 
raw observation next is [26.5, 66.0, 1.0, 2.0, 0.5117632508027569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 583014.1205802982, 583014.1205802982, 144215.0930117472], 
processed observation next is [1.0, 0.782608695652174, 0.8409090909090909, 0.66, 1.0, 1.0, 0.38970406350344605, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21593115577048083, 0.21593115577048083, 0.3517441292969444], 
reward next is 0.6483, 
noisyNet noise sample is [array([1.0096545], dtype=float32), 0.5149754]. 
=============================================
[2019-03-23 14:19:40,376] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.7343363e-06 9.9999821e-01 2.7149774e-18 2.4528525e-18 1.3833157e-09], sum to 1.0000
[2019-03-23 14:19:40,387] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9720
[2019-03-23 14:19:40,390] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.4152339e-06 9.9999559e-01 5.8451643e-19 7.2539464e-19 8.7230417e-10], sum to 1.0000
[2019-03-23 14:19:40,397] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1462647.952356672 W.
[2019-03-23 14:19:40,402] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.6484482639358347, 1.0, 2.0, 0.6484482639358347, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1462647.952356672, 1462647.952356672, 275082.0519964871], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1267200.0000, 
sim time next is 1267800.0000, 
raw observation next is [27.83333333333334, 58.66666666666667, 1.0, 2.0, 0.5607646115067575, 1.0, 2.0, 0.5607646115067575, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1267649.054407289, 1267649.054407289, 249603.3948151653], 
processed observation next is [1.0, 0.6956521739130435, 0.9015151515151518, 0.5866666666666667, 1.0, 1.0, 0.4509557643834468, 1.0, 1.0, 0.4509557643834468, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4694996497804774, 0.4694996497804774, 0.6087887678418665], 
reward next is 0.3912, 
noisyNet noise sample is [array([1.0514386], dtype=float32), -1.2272317]. 
=============================================
[2019-03-23 14:19:40,404] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5339
[2019-03-23 14:19:40,408] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 70.0, 1.0, 2.0, 0.5227592930973619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 595135.3567246563, 595135.3567246567, 145883.5676481674], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1278000.0000, 
sim time next is 1278600.0000, 
raw observation next is [24.66666666666667, 74.0, 1.0, 2.0, 0.5110697679400863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 582754.2421343029, 582754.2421343025, 143535.532790821], 
processed observation next is [1.0, 0.8260869565217391, 0.7575757575757578, 0.74, 1.0, 1.0, 0.38883720992510784, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21583490449418624, 0.2158349044941861, 0.35008666534346583], 
reward next is 0.6499, 
noisyNet noise sample is [array([-2.2906494], dtype=float32), 1.5382549]. 
=============================================
[2019-03-23 14:19:41,369] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.2720581e-04 9.9967229e-01 2.4219529e-17 5.8124207e-18 4.8339922e-07], sum to 1.0000
[2019-03-23 14:19:41,380] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7723
[2019-03-23 14:19:41,392] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3749271288937751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 420916.3839985394, 420916.3839985397, 121819.8999297152], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1308000.0000, 
sim time next is 1308600.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3751892114712815, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 421202.104405626, 421202.104405626, 121838.0944100263], 
processed observation next is [1.0, 0.13043478260869565, 0.45454545454545453, 1.0, 1.0, 1.0, 0.21898651433910182, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1560007794094911, 0.1560007794094911, 0.2971660839268934], 
reward next is 0.7028, 
noisyNet noise sample is [array([0.40064305], dtype=float32), -1.3545636]. 
=============================================
[2019-03-23 14:19:42,944] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68500, global step 1095298: loss -136.8597
[2019-03-23 14:19:42,948] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68500, global step 1095299: learning rate 0.0000
[2019-03-23 14:19:43,773] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68500, global step 1095734: loss -49.1358
[2019-03-23 14:19:43,775] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68500, global step 1095735: learning rate 0.0000
[2019-03-23 14:19:43,835] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68500, global step 1095770: loss -83.7109
[2019-03-23 14:19:43,836] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68500, global step 1095771: learning rate 0.0000
[2019-03-23 14:19:43,846] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68500, global step 1095775: loss -149.9545
[2019-03-23 14:19:43,850] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68500, global step 1095775: learning rate 0.0000
[2019-03-23 14:19:43,988] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68500, global step 1095849: loss -92.4531
[2019-03-23 14:19:43,990] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68500, global step 1095849: learning rate 0.0000
[2019-03-23 14:19:44,055] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68500, global step 1095880: loss -233.3555
[2019-03-23 14:19:44,058] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68500, global step 1095881: learning rate 0.0000
[2019-03-23 14:19:44,279] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68500, global step 1096000: loss -43.6294
[2019-03-23 14:19:44,280] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68500, global step 1096000: learning rate 0.0000
[2019-03-23 14:19:44,291] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68500, global step 1096007: loss 13.7410
[2019-03-23 14:19:44,294] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68500, global step 1096007: learning rate 0.0000
[2019-03-23 14:19:44,319] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68500, global step 1096021: loss -79.9092
[2019-03-23 14:19:44,322] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68500, global step 1096021: learning rate 0.0000
[2019-03-23 14:19:44,345] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68500, global step 1096033: loss 8.9996
[2019-03-23 14:19:44,346] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68500, global step 1096034: learning rate 0.0000
[2019-03-23 14:19:44,444] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68500, global step 1096087: loss -64.8299
[2019-03-23 14:19:44,446] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68500, global step 1096087: learning rate 0.0000
[2019-03-23 14:19:44,542] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68500, global step 1096129: loss -117.7133
[2019-03-23 14:19:44,545] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68500, global step 1096130: learning rate 0.0000
[2019-03-23 14:19:44,823] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68500, global step 1096283: loss -181.0365
[2019-03-23 14:19:44,824] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68500, global step 1096283: learning rate 0.0000
[2019-03-23 14:19:44,846] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68500, global step 1096294: loss -149.7648
[2019-03-23 14:19:44,849] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68500, global step 1096294: learning rate 0.0000
[2019-03-23 14:19:45,156] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68500, global step 1096461: loss 48.0066
[2019-03-23 14:19:45,158] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68500, global step 1096461: learning rate 0.0000
[2019-03-23 14:19:45,385] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68500, global step 1096582: loss 61.1724
[2019-03-23 14:19:45,388] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68500, global step 1096584: learning rate 0.0000
[2019-03-23 14:19:51,441] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6541058e-07 9.9999976e-01 1.1453490e-19 1.4637633e-17 1.2000321e-07], sum to 1.0000
[2019-03-23 14:19:51,451] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4532
[2019-03-23 14:19:51,456] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 92.33333333333334, 1.0, 2.0, 0.5430586454984954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 614996.5673150487, 614996.567315049, 149987.2433683303], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1498800.0000, 
sim time next is 1499400.0000, 
raw observation next is [24.0, 91.5, 1.0, 2.0, 0.55374907883398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 625929.2756125516, 625929.2756125516, 151740.4715912617], 
processed observation next is [0.0, 0.34782608695652173, 0.7272727272727273, 0.915, 1.0, 1.0, 0.4421863485424749, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23182565763427837, 0.23182565763427837, 0.3700987111981993], 
reward next is 0.6299, 
noisyNet noise sample is [array([0.6503372], dtype=float32), -0.4192388]. 
=============================================
[2019-03-23 14:19:51,860] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 14:19:51,860] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:19:51,861] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:19:51,861] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:19:51,862] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:19:51,862] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:19:51,863] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:19:51,865] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:19:51,866] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:19:51,865] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:19:51,867] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:19:51,882] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run45
[2019-03-23 14:19:51,911] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run45
[2019-03-23 14:19:51,912] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run45
[2019-03-23 14:19:51,912] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run45
[2019-03-23 14:19:51,912] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run45
[2019-03-23 14:20:09,984] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05625537], dtype=float32), 0.19611292]
[2019-03-23 14:20:09,986] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.6, 91.5, 1.0, 2.0, 0.4015823407971886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 449035.8133704404, 449035.81337044, 127632.9629237791]
[2019-03-23 14:20:09,988] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:20:09,992] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.3769691e-07 9.9999762e-01 3.1867565e-19 3.4402433e-18 1.7521770e-06], sampled 0.8933339169546408
[2019-03-23 14:20:11,721] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05625537], dtype=float32), 0.19611292]
[2019-03-23 14:20:11,721] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.72216641, 81.46107708, 1.0, 2.0, 0.4063734741227589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 459339.429937723, 459339.429937723, 130542.1934177426]
[2019-03-23 14:20:11,721] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:20:11,724] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.0595082e-07 9.9999785e-01 2.6722817e-19 2.9121446e-18 1.6579003e-06], sampled 0.3028425237601826
[2019-03-23 14:20:39,624] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05625537], dtype=float32), 0.19611292]
[2019-03-23 14:20:39,625] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.76679574, 90.785262795, 1.0, 2.0, 0.3376897584387466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 372678.9252645944, 372678.9252645937, 120247.1227985498]
[2019-03-23 14:20:39,628] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:20:39,633] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.8979359e-07 9.9999785e-01 2.4360658e-19 2.6666719e-18 1.6104190e-06], sampled 0.24891891056948756
[2019-03-23 14:20:47,561] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05625537], dtype=float32), 0.19611292]
[2019-03-23 14:20:47,564] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.0, 78.0, 1.0, 2.0, 0.4507269448755032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 513946.6334416406, 513946.6334416409, 134206.9373651471]
[2019-03-23 14:20:47,566] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:20:47,570] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.166434e-07 9.999970e-01 7.305693e-19 7.542724e-18 2.274265e-06], sampled 0.024786328155064652
[2019-03-23 14:20:51,786] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05625537], dtype=float32), 0.19611292]
[2019-03-23 14:20:51,788] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.9, 63.0, 1.0, 2.0, 0.4183469265412845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 457238.4940639197, 457238.4940639194, 125170.656961968]
[2019-03-23 14:20:51,790] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:20:51,792] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.3827019e-07 9.9999738e-01 5.2293971e-19 5.4956048e-18 2.0471991e-06], sampled 0.45844736713743095
[2019-03-23 14:20:58,648] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05625537], dtype=float32), 0.19611292]
[2019-03-23 14:20:58,649] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 94.0, 1.0, 2.0, 0.499038169451421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 569119.9796836253, 569119.9796836256, 141976.0305143243]
[2019-03-23 14:20:58,651] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:20:58,654] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.2773373e-07 9.9999785e-01 3.0223104e-19 3.2702677e-18 1.7230608e-06], sampled 0.0002634517961623839
[2019-03-23 14:21:05,548] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05625537], dtype=float32), 0.19611292]
[2019-03-23 14:21:05,550] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [11.370693795, 97.15391206333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 156311.4417988588, 156311.4417988584, 63077.02520796072]
[2019-03-23 14:21:05,550] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:21:05,553] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.6098393e-06 9.9999356e-01 7.5485699e-18 6.8784052e-17 4.7391541e-06], sampled 0.3670454402268436
[2019-03-23 14:21:33,649] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:21:34,468] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 14:21:34,687] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 14:21:34,836] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 14:21:34,912] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 14:21:35,928] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1100000, evaluation results [1100000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 14:21:39,857] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.2712171e-06 9.9998522e-01 1.2988130e-14 5.7082546e-15 5.4936063e-06], sum to 1.0000
[2019-03-23 14:21:39,867] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6514
[2019-03-23 14:21:39,870] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4267887999402837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 483873.1089522718, 483873.1089522715, 129044.5905182465], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1570800.0000, 
sim time next is 1571400.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4225471590481668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 479039.168803352, 479039.168803352, 128618.5966168546], 
processed observation next is [1.0, 0.17391304347826086, 0.5, 1.0, 1.0, 1.0, 0.27818394881020847, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17742191437161184, 0.17742191437161184, 0.31370389418745026], 
reward next is 0.6863, 
noisyNet noise sample is [array([-1.1394814], dtype=float32), -0.9160182]. 
=============================================
[2019-03-23 14:21:42,452] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69000, global step 1103265: loss 0.0436
[2019-03-23 14:21:42,456] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69000, global step 1103266: learning rate 0.0000
[2019-03-23 14:21:43,131] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69000, global step 1103606: loss 0.0328
[2019-03-23 14:21:43,133] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69000, global step 1103607: learning rate 0.0000
[2019-03-23 14:21:43,310] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69000, global step 1103693: loss 0.0475
[2019-03-23 14:21:43,311] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69000, global step 1103693: learning rate 0.0000
[2019-03-23 14:21:43,382] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69000, global step 1103730: loss 0.0875
[2019-03-23 14:21:43,384] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69000, global step 1103731: learning rate 0.0000
[2019-03-23 14:21:43,553] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69000, global step 1103817: loss 0.0420
[2019-03-23 14:21:43,556] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69000, global step 1103818: learning rate 0.0000
[2019-03-23 14:21:43,819] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69000, global step 1103887: loss 0.0208
[2019-03-23 14:21:43,823] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69000, global step 1103888: learning rate 0.0000
[2019-03-23 14:21:44,049] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69000, global step 1104000: loss 0.0366
[2019-03-23 14:21:44,050] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69000, global step 1104000: learning rate 0.0000
[2019-03-23 14:21:44,068] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69000, global step 1104008: loss 0.0731
[2019-03-23 14:21:44,069] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69000, global step 1104008: learning rate 0.0000
[2019-03-23 14:21:44,163] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69000, global step 1104060: loss 0.0761
[2019-03-23 14:21:44,166] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69000, global step 1104061: learning rate 0.0000
[2019-03-23 14:21:44,194] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69000, global step 1104076: loss 0.0815
[2019-03-23 14:21:44,197] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69000, global step 1104076: learning rate 0.0000
[2019-03-23 14:21:44,218] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69000, global step 1104082: loss 0.0667
[2019-03-23 14:21:44,221] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69000, global step 1104082: learning rate 0.0000
[2019-03-23 14:21:44,272] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69000, global step 1104111: loss 0.0437
[2019-03-23 14:21:44,273] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69000, global step 1104111: learning rate 0.0000
[2019-03-23 14:21:44,468] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.1707540e-07 9.9999869e-01 2.7165235e-17 9.6284148e-17 3.8107450e-07], sum to 1.0000
[2019-03-23 14:21:44,478] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8718
[2019-03-23 14:21:44,488] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 90.0, 1.0, 2.0, 0.365053865292118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 407422.2900025758, 407422.2900025758, 119867.2944202927], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1654800.0000, 
sim time next is 1655400.0000, 
raw observation next is [18.83333333333333, 89.0, 1.0, 2.0, 0.3620446862603866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 404316.3050732794, 404316.3050732797, 119732.8527728953], 
processed observation next is [1.0, 0.13043478260869565, 0.4924242424242422, 0.89, 1.0, 1.0, 0.20255585782548324, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14974677965677016, 0.14974677965677027, 0.2920313482265739], 
reward next is 0.7080, 
noisyNet noise sample is [array([-0.2886591], dtype=float32), 0.4936708]. 
=============================================
[2019-03-23 14:21:44,522] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69000, global step 1104240: loss 0.0127
[2019-03-23 14:21:44,524] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69000, global step 1104240: learning rate 0.0000
[2019-03-23 14:21:44,569] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69000, global step 1104257: loss 0.0126
[2019-03-23 14:21:44,569] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69000, global step 1104257: learning rate 0.0000
[2019-03-23 14:21:44,913] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69000, global step 1104426: loss 0.0336
[2019-03-23 14:21:44,916] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69000, global step 1104427: learning rate 0.0000
[2019-03-23 14:21:45,101] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69000, global step 1104524: loss 0.0117
[2019-03-23 14:21:45,103] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69000, global step 1104524: learning rate 0.0000
[2019-03-23 14:21:46,604] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.8837944e-05 9.9916494e-01 4.0303399e-18 4.1106175e-17 7.7618216e-04], sum to 1.0000
[2019-03-23 14:21:46,611] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1637
[2019-03-23 14:21:46,614] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333333, 55.5, 1.0, 2.0, 0.514829283100873, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 559162.6984728166, 559162.6984728166, 111709.9975179553], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1702200.0000, 
sim time next is 1702800.0000, 
raw observation next is [19.0, 56.0, 1.0, 2.0, 0.499000025311241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 541960.75374106, 541960.7537410603, 108814.4768935334], 
processed observation next is [1.0, 0.7391304347826086, 0.5, 0.56, 1.0, 1.0, 0.3737500316390512, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2007262050892815, 0.20072620508928157, 0.2654011631549595], 
reward next is 0.7346, 
noisyNet noise sample is [array([-0.5596089], dtype=float32), 0.4614705]. 
=============================================
[2019-03-23 14:21:50,464] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.1072158e-06 9.9999166e-01 4.4995457e-18 2.5374877e-15 2.1263936e-07], sum to 1.0000
[2019-03-23 14:21:50,474] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0729
[2019-03-23 14:21:50,479] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 40.0, 1.0, 2.0, 0.4386813281911915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476416.8982334274, 476416.8982334274, 95508.77389238345], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1783200.0000, 
sim time next is 1783800.0000, 
raw observation next is [19.5, 40.0, 1.0, 2.0, 0.4412349259192966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 479191.5243996654, 479191.5243996654, 95349.57332669398], 
processed observation next is [1.0, 0.6521739130434783, 0.5227272727272727, 0.4, 1.0, 1.0, 0.3015436573991207, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17747834237024646, 0.17747834237024646, 0.23255993494315605], 
reward next is 0.7674, 
noisyNet noise sample is [array([0.9629555], dtype=float32), -1.0832244]. 
=============================================
[2019-03-23 14:21:50,660] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7444452e-04 9.9981326e-01 6.8316494e-15 4.2030913e-14 1.2275606e-05], sum to 1.0000
[2019-03-23 14:21:50,665] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9380
[2019-03-23 14:21:50,668] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 45.5, 1.0, 2.0, 0.3202835550187206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 347788.506676555, 347788.5066765553, 81700.05929428608], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1774200.0000, 
sim time next is 1774800.0000, 
raw observation next is [18.0, 45.0, 1.0, 2.0, 0.3254672856580749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 353419.4454214352, 353419.4454214349, 82328.3792094001], 
processed observation next is [1.0, 0.5652173913043478, 0.45454545454545453, 0.45, 1.0, 1.0, 0.15683410707259363, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13089609089682785, 0.13089609089682774, 0.20080092490097584], 
reward next is 0.7992, 
noisyNet noise sample is [array([-0.85103685], dtype=float32), -2.3847253]. 
=============================================
[2019-03-23 14:21:58,684] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69500, global step 1111321: loss 59.4309
[2019-03-23 14:21:58,685] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69500, global step 1111321: learning rate 0.0000
[2019-03-23 14:21:59,326] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69500, global step 1111665: loss 24.4050
[2019-03-23 14:21:59,327] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69500, global step 1111665: learning rate 0.0000
[2019-03-23 14:21:59,329] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69500, global step 1111665: loss -23.9544
[2019-03-23 14:21:59,329] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69500, global step 1111665: learning rate 0.0000
[2019-03-23 14:21:59,344] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69500, global step 1111670: loss -9.2380
[2019-03-23 14:21:59,344] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69500, global step 1111670: learning rate 0.0000
[2019-03-23 14:21:59,634] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69500, global step 1111826: loss -23.8581
[2019-03-23 14:21:59,639] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69500, global step 1111828: learning rate 0.0000
[2019-03-23 14:21:59,868] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69500, global step 1111947: loss 66.6945
[2019-03-23 14:21:59,870] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69500, global step 1111947: learning rate 0.0000
[2019-03-23 14:22:00,002] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69500, global step 1112019: loss 191.3967
[2019-03-23 14:22:00,004] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69500, global step 1112019: learning rate 0.0000
[2019-03-23 14:22:00,087] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69500, global step 1112063: loss 48.6680
[2019-03-23 14:22:00,090] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69500, global step 1112065: learning rate 0.0000
[2019-03-23 14:22:00,102] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69500, global step 1112070: loss -16.4071
[2019-03-23 14:22:00,102] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69500, global step 1112070: learning rate 0.0000
[2019-03-23 14:22:00,117] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69500, global step 1112079: loss 120.9633
[2019-03-23 14:22:00,120] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69500, global step 1112079: learning rate 0.0000
[2019-03-23 14:22:00,131] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69500, global step 1112086: loss 75.1718
[2019-03-23 14:22:00,134] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69500, global step 1112087: learning rate 0.0000
[2019-03-23 14:22:00,323] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69500, global step 1112192: loss -37.2896
[2019-03-23 14:22:00,324] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69500, global step 1112192: learning rate 0.0000
[2019-03-23 14:22:00,485] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69500, global step 1112277: loss 118.2062
[2019-03-23 14:22:00,485] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69500, global step 1112277: loss -49.5194
[2019-03-23 14:22:00,486] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69500, global step 1112277: learning rate 0.0000
[2019-03-23 14:22:00,487] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69500, global step 1112277: learning rate 0.0000
[2019-03-23 14:22:00,631] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.8034983e-04 9.9923587e-01 7.6871145e-15 5.0631327e-14 8.3738058e-05], sum to 1.0000
[2019-03-23 14:22:00,638] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6114
[2019-03-23 14:22:00,646] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1170111.143594208 W.
[2019-03-23 14:22:00,652] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.16666666666667, 57.66666666666666, 1.0, 2.0, 0.5124150018634627, 1.0, 2.0, 0.5124150018634627, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354094, 1170111.143594208, 1170111.143594208, 227888.4205321781], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1961400.0000, 
sim time next is 1962000.0000, 
raw observation next is [25.0, 57.0, 1.0, 2.0, 0.5170491279585683, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9457973640987545, 6.940079797857919, 6.9112, 77.328392596783, 1137158.951930583, 1127779.392873717, 249151.3128815743], 
processed observation next is [1.0, 0.7391304347826086, 0.7727272727272727, 0.57, 1.0, 1.0, 0.3963114099482103, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9225676629982207, 0.0028879797857919165, 0.0, 0.5084283471085652, 0.4211699821965122, 0.41769607143471, 0.6076861289794495], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.81985784], dtype=float32), -0.5925003]. 
=============================================
[2019-03-23 14:22:00,671] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[57.281303]
 [57.080753]
 [55.705597]
 [56.268875]
 [55.159046]], R is [[55.95335007]
 [55.3938179 ]
 [54.8398819 ]
 [54.71912766]
 [54.5056839 ]].
[2019-03-23 14:22:00,705] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69500, global step 1112383: loss 49.4415
[2019-03-23 14:22:00,706] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69500, global step 1112383: learning rate 0.0000
[2019-03-23 14:22:00,848] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69500, global step 1112459: loss 18.0775
[2019-03-23 14:22:00,850] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69500, global step 1112460: learning rate 0.0000
[2019-03-23 14:22:09,215] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.8524323e-07 9.9999976e-01 8.6012940e-22 2.0565864e-20 1.2516946e-08], sum to 1.0000
[2019-03-23 14:22:09,229] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3470
[2019-03-23 14:22:09,234] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 54.0, 1.0, 2.0, 0.4121625356111729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468088.7411587946, 468088.7411587946, 128232.3861064064], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2136600.0000, 
sim time next is 2137200.0000, 
raw observation next is [26.0, 54.0, 1.0, 2.0, 0.4122124472360064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468144.2228325692, 468144.2228325692, 128236.2183784048], 
processed observation next is [0.0, 0.7391304347826086, 0.8181818181818182, 0.54, 1.0, 1.0, 0.265265559045008, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17338674919724786, 0.17338674919724786, 0.3127712643375727], 
reward next is 0.6872, 
noisyNet noise sample is [array([0.42765838], dtype=float32), 0.28728744]. 
=============================================
[2019-03-23 14:22:13,722] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70000, global step 1119242: loss 0.0374
[2019-03-23 14:22:13,725] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70000, global step 1119242: learning rate 0.0000
[2019-03-23 14:22:13,855] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.0482050e-09 9.9999976e-01 1.3824244e-19 2.6375393e-19 2.0793290e-07], sum to 1.0000
[2019-03-23 14:22:13,860] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2780
[2019-03-23 14:22:13,863] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 70.33333333333334, 1.0, 2.0, 0.8139317790585784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 918499.1550624, 918499.1550624, 174016.547732781], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2215200.0000, 
sim time next is 2215800.0000, 
raw observation next is [22.0, 71.0, 1.0, 2.0, 0.8231504190516441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 929675.1085295215, 929675.1085295213, 175785.3195975355], 
processed observation next is [1.0, 0.6521739130434783, 0.6363636363636364, 0.71, 1.0, 1.0, 0.7789380238145551, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.34432411427019316, 0.34432411427019305, 0.42874468194520854], 
reward next is 0.5713, 
noisyNet noise sample is [array([-0.6211834], dtype=float32), 0.8090666]. 
=============================================
[2019-03-23 14:22:14,494] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70000, global step 1119649: loss 0.0161
[2019-03-23 14:22:14,498] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70000, global step 1119650: learning rate 0.0000
[2019-03-23 14:22:14,597] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70000, global step 1119703: loss 0.0065
[2019-03-23 14:22:14,599] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70000, global step 1119703: learning rate 0.0000
[2019-03-23 14:22:14,701] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70000, global step 1119761: loss 0.1653
[2019-03-23 14:22:14,704] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70000, global step 1119761: learning rate 0.0000
[2019-03-23 14:22:14,805] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70000, global step 1119812: loss 0.0601
[2019-03-23 14:22:14,808] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70000, global step 1119813: learning rate 0.0000
[2019-03-23 14:22:15,070] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70000, global step 1119957: loss 0.0108
[2019-03-23 14:22:15,071] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70000, global step 1119957: learning rate 0.0000
[2019-03-23 14:22:15,156] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70000, global step 1120003: loss 0.0077
[2019-03-23 14:22:15,158] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70000, global step 1120005: learning rate 0.0000
[2019-03-23 14:22:15,170] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70000, global step 1120011: loss 0.0287
[2019-03-23 14:22:15,172] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70000, global step 1120011: learning rate 0.0000
[2019-03-23 14:22:15,274] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70000, global step 1120066: loss 0.0587
[2019-03-23 14:22:15,277] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70000, global step 1120067: learning rate 0.0000
[2019-03-23 14:22:15,279] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70000, global step 1120068: loss 0.1314
[2019-03-23 14:22:15,281] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70000, global step 1120069: learning rate 0.0000
[2019-03-23 14:22:15,325] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70000, global step 1120092: loss 0.1161
[2019-03-23 14:22:15,328] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70000, global step 1120093: learning rate 0.0000
[2019-03-23 14:22:15,348] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70000, global step 1120101: loss 0.1502
[2019-03-23 14:22:15,353] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70000, global step 1120101: learning rate 0.0000
[2019-03-23 14:22:15,680] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70000, global step 1120276: loss 0.0012
[2019-03-23 14:22:15,680] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70000, global step 1120276: learning rate 0.0000
[2019-03-23 14:22:15,781] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70000, global step 1120329: loss 0.0315
[2019-03-23 14:22:15,782] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70000, global step 1120329: learning rate 0.0000
[2019-03-23 14:22:15,835] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70000, global step 1120358: loss 0.0134
[2019-03-23 14:22:15,836] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70000, global step 1120358: learning rate 0.0000
[2019-03-23 14:22:15,866] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70000, global step 1120369: loss 0.0079
[2019-03-23 14:22:15,869] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70000, global step 1120370: learning rate 0.0000
[2019-03-23 14:22:16,763] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.5465740e-06 9.9999285e-01 2.5035248e-20 1.1187666e-19 2.6386831e-06], sum to 1.0000
[2019-03-23 14:22:16,773] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4585
[2019-03-23 14:22:16,777] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 56.0, 1.0, 2.0, 0.4487807166029232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 487390.5388122255, 487390.5388122255, 99217.21162536815], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2284200.0000, 
sim time next is 2284800.0000, 
raw observation next is [18.0, 56.0, 1.0, 2.0, 0.4288957900087293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 465784.5125564045, 465784.5125564045, 97119.44651303478], 
processed observation next is [1.0, 0.43478260869565216, 0.45454545454545453, 0.56, 1.0, 1.0, 0.2861197375109116, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17251278242829796, 0.17251278242829796, 0.23687669881227996], 
reward next is 0.7631, 
noisyNet noise sample is [array([-0.44820744], dtype=float32), -0.81293654]. 
=============================================
[2019-03-23 14:22:24,587] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 14:22:24,590] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:22:24,590] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:22:24,591] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:22:24,593] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:22:24,595] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:22:24,601] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:22:24,600] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:22:24,602] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:22:24,601] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:22:24,603] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:22:24,615] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run46
[2019-03-23 14:22:24,641] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run46
[2019-03-23 14:22:24,669] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run46
[2019-03-23 14:22:24,698] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run46
[2019-03-23 14:22:24,698] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run46
[2019-03-23 14:22:29,074] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05978165], dtype=float32), 0.20422125]
[2019-03-23 14:22:29,075] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.90547422, 29.76673815, 1.0, 2.0, 0.2737763046903476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 297254.5968323155, 297254.5968323151, 84940.88013183976]
[2019-03-23 14:22:29,078] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:22:29,080] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.7005010e-06 9.9999416e-01 8.8872678e-19 4.7697521e-18 1.2402413e-06], sampled 0.6163404469011903
[2019-03-23 14:22:33,429] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05978165], dtype=float32), 0.20422125]
[2019-03-23 14:22:33,430] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.436464885, 90.65320499166668, 1.0, 2.0, 0.4250555733755346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 467557.5571618381, 467557.5571618377, 126732.2992092439]
[2019-03-23 14:22:33,431] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:22:33,433] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.1999987e-06 9.9999595e-01 2.5001839e-19 1.4070585e-18 8.1427964e-07], sampled 0.5014878120010462
[2019-03-23 14:23:38,458] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05978165], dtype=float32), 0.20422125]
[2019-03-23 14:23:38,458] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.26322353, 60.16826962, 1.0, 2.0, 0.2315817381268884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 251431.9595333831, 251431.9595333828, 83643.42998228212]
[2019-03-23 14:23:38,459] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:23:38,462] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.5232204e-06 9.9999309e-01 1.5132737e-18 7.9621461e-18 1.4797596e-06], sampled 0.8332400031309372
[2019-03-23 14:24:05,637] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05978165], dtype=float32), 0.20422125]
[2019-03-23 14:24:05,638] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.52686904, 81.33417085333335, 1.0, 2.0, 0.2363020843174004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 256558.0078963783, 256558.0078963779, 80864.17448003992]
[2019-03-23 14:24:05,639] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:24:05,641] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.7185781e-06 9.9999404e-01 8.9968299e-19 4.8279637e-18 1.2449410e-06], sampled 0.9984968047565385
[2019-03-23 14:24:05,701] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05978165], dtype=float32), 0.20422125]
[2019-03-23 14:24:05,701] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.33333333333333, 84.33333333333333, 1.0, 2.0, 0.2398412240282618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 260401.3566575281, 260401.3566575281, 85327.20961017539]
[2019-03-23 14:24:05,703] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:24:05,705] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.1916896e-06 9.9999475e-01 6.0889577e-19 3.3157303e-18 1.0936104e-06], sampled 0.4541372968332801
[2019-03-23 14:24:07,392] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 14:24:07,525] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 14:24:07,572] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 14:24:07,662] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:24:07,815] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 14:24:08,835] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1125000, evaluation results [1125000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 14:24:12,513] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.6303571e-08 9.9999988e-01 1.5179705e-21 1.3496784e-21 4.1935078e-09], sum to 1.0000
[2019-03-23 14:24:12,522] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3496
[2019-03-23 14:24:12,527] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2136661935365249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 231987.5665831442, 231987.5665831439, 75060.324892402], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2505000.0000, 
sim time next is 2505600.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2129305200287874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 231188.620975836, 231188.6209758357, 74984.5745007623], 
processed observation next is [1.0, 0.0, 0.22727272727272727, 1.0, 1.0, 1.0, 0.016163150035984238, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08562541517623556, 0.08562541517623545, 0.18288920609942025], 
reward next is 0.8171, 
noisyNet noise sample is [array([0.4757921], dtype=float32), 0.25452065]. 
=============================================
[2019-03-23 14:24:13,193] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70500, global step 1127191: loss 0.8164
[2019-03-23 14:24:13,194] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70500, global step 1127192: learning rate 0.0000
[2019-03-23 14:24:14,053] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70500, global step 1127624: loss 0.0737
[2019-03-23 14:24:14,055] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70500, global step 1127625: learning rate 0.0000
[2019-03-23 14:24:14,223] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70500, global step 1127712: loss 0.1477
[2019-03-23 14:24:14,227] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70500, global step 1127713: learning rate 0.0000
[2019-03-23 14:24:14,263] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70500, global step 1127730: loss 0.1799
[2019-03-23 14:24:14,265] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70500, global step 1127730: learning rate 0.0000
[2019-03-23 14:24:14,506] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70500, global step 1127856: loss 0.0820
[2019-03-23 14:24:14,509] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70500, global step 1127856: learning rate 0.0000
[2019-03-23 14:24:14,764] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70500, global step 1127978: loss 0.0164
[2019-03-23 14:24:14,766] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70500, global step 1127978: learning rate 0.0000
[2019-03-23 14:24:14,807] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70500, global step 1128004: loss 0.0345
[2019-03-23 14:24:14,807] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70500, global step 1128004: learning rate 0.0000
[2019-03-23 14:24:14,890] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70500, global step 1128047: loss 0.1115
[2019-03-23 14:24:14,892] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70500, global step 1128049: learning rate 0.0000
[2019-03-23 14:24:14,915] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70500, global step 1128062: loss 0.1850
[2019-03-23 14:24:14,922] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70500, global step 1128067: learning rate 0.0000
[2019-03-23 14:24:14,933] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70500, global step 1128070: loss 0.2241
[2019-03-23 14:24:14,936] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70500, global step 1128070: learning rate 0.0000
[2019-03-23 14:24:15,002] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70500, global step 1128104: loss 0.2632
[2019-03-23 14:24:15,006] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70500, global step 1128105: learning rate 0.0000
[2019-03-23 14:24:15,073] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70500, global step 1128139: loss 0.1646
[2019-03-23 14:24:15,077] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70500, global step 1128141: learning rate 0.0000
[2019-03-23 14:24:15,147] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70500, global step 1128180: loss 0.0671
[2019-03-23 14:24:15,152] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70500, global step 1128181: learning rate 0.0000
[2019-03-23 14:24:15,258] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70500, global step 1128237: loss 0.0159
[2019-03-23 14:24:15,260] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70500, global step 1128237: learning rate 0.0000
[2019-03-23 14:24:15,509] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70500, global step 1128366: loss 0.1457
[2019-03-23 14:24:15,511] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70500, global step 1128366: learning rate 0.0000
[2019-03-23 14:24:15,815] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70500, global step 1128519: loss 0.1193
[2019-03-23 14:24:15,819] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70500, global step 1128519: learning rate 0.0000
[2019-03-23 14:24:17,416] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4131707e-06 9.9999845e-01 2.8040900e-18 3.4438007e-20 1.4910343e-07], sum to 1.0000
[2019-03-23 14:24:17,426] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7600
[2019-03-23 14:24:17,433] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 86.66666666666666, 1.0, 2.0, 0.3428297752092589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 381828.784877916, 381828.784877916, 117731.3007562408], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2619600.0000, 
sim time next is 2620200.0000, 
raw observation next is [19.5, 84.83333333333333, 1.0, 2.0, 0.3515942909343036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 393062.8268622554, 393062.8268622554, 119074.8714901742], 
processed observation next is [0.0, 0.30434782608695654, 0.5227272727272727, 0.8483333333333333, 1.0, 1.0, 0.18949286366787949, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1455788247637983, 0.1455788247637983, 0.2904265158296932], 
reward next is 0.7096, 
noisyNet noise sample is [array([-1.1038848], dtype=float32), -0.9519473]. 
=============================================
[2019-03-23 14:24:17,651] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.47815887e-07 9.99999404e-01 1.02536824e-20 4.44771913e-18
 8.26292634e-09], sum to 1.0000
[2019-03-23 14:24:17,658] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2240
[2019-03-23 14:24:17,663] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.2, 94.0, 1.0, 2.0, 0.2892572694090944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 314086.9005202745, 314086.9005202745, 105900.0223412015], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2604600.0000, 
sim time next is 2605200.0000, 
raw observation next is [16.13333333333333, 96.0, 1.0, 2.0, 0.2927701363924898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 317902.5561637745, 317902.5561637745, 109571.290003023], 
processed observation next is [0.0, 0.13043478260869565, 0.3696969696969695, 0.96, 1.0, 1.0, 0.11596267049061221, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11774168746806464, 0.11774168746806464, 0.267247048787861], 
reward next is 0.7328, 
noisyNet noise sample is [array([-0.27945465], dtype=float32), -0.33246]. 
=============================================
[2019-03-23 14:24:29,076] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.1949656e-04 9.9910706e-01 9.3558921e-09 4.5096556e-08 3.7336233e-04], sum to 1.0000
[2019-03-23 14:24:29,085] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8324
[2019-03-23 14:24:29,096] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1354456.720851353 W.
[2019-03-23 14:24:29,103] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.66666666666666, 54.0, 1.0, 2.0, 0.7091582258284832, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9769286365367397, 6.911200000000001, 6.9112, 77.32846344354104, 1354456.720851353, 1354456.720851353, 293152.9981092307], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2817600.0000, 
sim time next is 2818200.0000, 
raw observation next is [28.83333333333334, 53.0, 1.0, 2.0, 0.3838602555152787, 1.0, 1.0, 0.3838602555152787, 1.0, 2.0, 0.7769970455769843, 6.911199999999999, 6.9112, 77.3421103, 1302839.494657642, 1302839.494657642, 296602.9079730252], 
processed observation next is [1.0, 0.6086956521739131, 0.9469696969696972, 0.53, 1.0, 1.0, 0.22982531939409834, 1.0, 0.5, 0.22982531939409834, 1.0, 1.0, 0.6814243508242634, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.48253314616949705, 0.48253314616949705, 0.7234217267634762], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.68679917], dtype=float32), 1.2268128]. 
=============================================
[2019-03-23 14:24:29,239] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71000, global step 1135222: loss 1.2189
[2019-03-23 14:24:29,240] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71000, global step 1135222: learning rate 0.0000
[2019-03-23 14:24:29,998] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71000, global step 1135581: loss 0.2023
[2019-03-23 14:24:29,999] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71000, global step 1135581: learning rate 0.0000
[2019-03-23 14:24:30,202] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71000, global step 1135681: loss 0.2990
[2019-03-23 14:24:30,206] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71000, global step 1135681: learning rate 0.0000
[2019-03-23 14:24:30,336] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71000, global step 1135755: loss 0.0437
[2019-03-23 14:24:30,339] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71000, global step 1135755: learning rate 0.0000
[2019-03-23 14:24:30,623] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71000, global step 1135908: loss 0.1137
[2019-03-23 14:24:30,625] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71000, global step 1135909: learning rate 0.0000
[2019-03-23 14:24:30,772] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71000, global step 1135981: loss 0.3080
[2019-03-23 14:24:30,774] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71000, global step 1135983: learning rate 0.0000
[2019-03-23 14:24:30,874] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71000, global step 1136040: loss 0.1159
[2019-03-23 14:24:30,875] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71000, global step 1136040: learning rate 0.0000
[2019-03-23 14:24:30,887] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71000, global step 1136041: loss 0.1919
[2019-03-23 14:24:30,890] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71000, global step 1136041: learning rate 0.0000
[2019-03-23 14:24:30,911] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71000, global step 1136051: loss 0.1063
[2019-03-23 14:24:30,912] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71000, global step 1136052: learning rate 0.0000
[2019-03-23 14:24:30,942] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71000, global step 1136070: loss 0.0359
[2019-03-23 14:24:30,943] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71000, global step 1136070: learning rate 0.0000
[2019-03-23 14:24:31,062] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71000, global step 1136135: loss 0.0087
[2019-03-23 14:24:31,063] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71000, global step 1136135: learning rate 0.0000
[2019-03-23 14:24:31,099] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71000, global step 1136156: loss 0.0134
[2019-03-23 14:24:31,100] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71000, global step 1136156: learning rate 0.0000
[2019-03-23 14:24:31,113] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71000, global step 1136162: loss 0.0297
[2019-03-23 14:24:31,115] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71000, global step 1136162: learning rate 0.0000
[2019-03-23 14:24:31,154] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71000, global step 1136188: loss 0.0228
[2019-03-23 14:24:31,155] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71000, global step 1136189: learning rate 0.0000
[2019-03-23 14:24:31,280] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.7619510e-07 9.9999928e-01 1.2066706e-16 2.3196728e-15 4.3203502e-07], sum to 1.0000
[2019-03-23 14:24:31,288] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7934
[2019-03-23 14:24:31,297] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.00000000000001, 1.0, 2.0, 0.4900773483942352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 557658.0005121512, 557658.0005121512, 137016.0770267598], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2866200.0000, 
sim time next is 2866800.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.4508753187143489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 513007.0155125057, 513007.0155125054, 132851.5677507168], 
processed observation next is [1.0, 0.17391304347826086, 0.5909090909090909, 0.88, 1.0, 1.0, 0.3135941483929361, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1900025983379651, 0.19000259833796496, 0.3240282140261385], 
reward next is 0.6760, 
noisyNet noise sample is [array([0.08349364], dtype=float32), 0.8405804]. 
=============================================
[2019-03-23 14:24:31,478] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71000, global step 1136359: loss 0.0170
[2019-03-23 14:24:31,480] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71000, global step 1136359: learning rate 0.0000
[2019-03-23 14:24:31,776] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71000, global step 1136513: loss 0.0350
[2019-03-23 14:24:31,780] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71000, global step 1136516: learning rate 0.0000
[2019-03-23 14:24:34,588] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.2283677e-07 9.9999964e-01 1.5458710e-17 1.1741327e-15 8.7602679e-08], sum to 1.0000
[2019-03-23 14:24:34,599] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1504
[2019-03-23 14:24:34,604] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 99.0, 1.0, 2.0, 0.5295078092985315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 602706.2678558031, 602706.2678558028, 146797.2988304999], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2929800.0000, 
sim time next is 2930400.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.5347879761405113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 608365.5635725994, 608365.5635725994, 147686.8222854604], 
processed observation next is [1.0, 0.9565217391304348, 0.6363636363636364, 1.0, 1.0, 1.0, 0.4184849701756391, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22532057910096276, 0.22532057910096276, 0.36021176167185465], 
reward next is 0.6398, 
noisyNet noise sample is [array([-1.1383103], dtype=float32), 0.6073252]. 
=============================================
[2019-03-23 14:24:39,298] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0365212e-06 9.9986243e-01 8.2474410e-19 2.2903847e-15 1.3641964e-04], sum to 1.0000
[2019-03-23 14:24:39,306] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6253
[2019-03-23 14:24:39,310] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 83.0, 1.0, 2.0, 0.3846391377603145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 432053.4160753345, 432053.4160753342, 122768.0491574353], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3022200.0000, 
sim time next is 3022800.0000, 
raw observation next is [19.66666666666667, 84.66666666666667, 1.0, 2.0, 0.3806071205500096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 426934.1949744721, 426934.1949744718, 122132.9241656498], 
processed observation next is [1.0, 1.0, 0.5303030303030305, 0.8466666666666667, 1.0, 1.0, 0.225758900687512, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15812377591647114, 0.15812377591647103, 0.2978851808918288], 
reward next is 0.7021, 
noisyNet noise sample is [array([-1.4931568], dtype=float32), -0.9788834]. 
=============================================
[2019-03-23 14:24:44,647] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71500, global step 1143294: loss 18.7016
[2019-03-23 14:24:44,649] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71500, global step 1143296: learning rate 0.0000
[2019-03-23 14:24:45,123] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71500, global step 1143546: loss 9.5154
[2019-03-23 14:24:45,126] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71500, global step 1143548: learning rate 0.0000
[2019-03-23 14:24:45,351] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71500, global step 1143665: loss 26.1867
[2019-03-23 14:24:45,353] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71500, global step 1143666: learning rate 0.0000
[2019-03-23 14:24:45,673] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71500, global step 1143838: loss -4.4508
[2019-03-23 14:24:45,677] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71500, global step 1143839: learning rate 0.0000
[2019-03-23 14:24:45,873] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71500, global step 1143942: loss -53.9203
[2019-03-23 14:24:45,875] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71500, global step 1143942: learning rate 0.0000
[2019-03-23 14:24:45,962] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71500, global step 1143991: loss -7.7989
[2019-03-23 14:24:45,967] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71500, global step 1143995: learning rate 0.0000
[2019-03-23 14:24:46,001] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71500, global step 1144009: loss -25.1943
[2019-03-23 14:24:46,002] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71500, global step 1144009: learning rate 0.0000
[2019-03-23 14:24:46,049] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71500, global step 1144033: loss -19.7123
[2019-03-23 14:24:46,050] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71500, global step 1144033: learning rate 0.0000
[2019-03-23 14:24:46,089] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71500, global step 1144057: loss -20.6311
[2019-03-23 14:24:46,092] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71500, global step 1144058: learning rate 0.0000
[2019-03-23 14:24:46,103] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71500, global step 1144064: loss -86.4891
[2019-03-23 14:24:46,105] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71500, global step 1144064: learning rate 0.0000
[2019-03-23 14:24:46,144] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71500, global step 1144083: loss -38.1019
[2019-03-23 14:24:46,147] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71500, global step 1144084: learning rate 0.0000
[2019-03-23 14:24:46,157] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71500, global step 1144088: loss -27.6988
[2019-03-23 14:24:46,158] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71500, global step 1144089: learning rate 0.0000
[2019-03-23 14:24:46,249] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71500, global step 1144140: loss 29.7018
[2019-03-23 14:24:46,251] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71500, global step 1144140: learning rate 0.0000
[2019-03-23 14:24:46,383] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71500, global step 1144210: loss -26.9502
[2019-03-23 14:24:46,384] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71500, global step 1144210: learning rate 0.0000
[2019-03-23 14:24:46,632] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71500, global step 1144333: loss 30.1370
[2019-03-23 14:24:46,633] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71500, global step 1144334: learning rate 0.0000
[2019-03-23 14:24:46,790] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.5360951e-03 9.6668476e-01 5.7674421e-12 1.6554109e-10 2.9779123e-02], sum to 1.0000
[2019-03-23 14:24:46,796] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2259
[2019-03-23 14:24:46,804] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1295297.746161448 W.
[2019-03-23 14:24:46,809] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 74.0, 1.0, 2.0, 0.6543861973469904, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9702123773436498, 6.9112, 6.9112, 77.32846344354104, 1295297.746161448, 1295297.746161448, 278387.3360944511], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3168000.0000, 
sim time next is 3168600.0000, 
raw observation next is [24.0, 74.0, 1.0, 2.0, 0.5648527499003814, 1.0, 1.0, 0.5648527499003814, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1287204.841391187, 1287204.841391187, 246098.0219148407], 
processed observation next is [1.0, 0.6956521739130435, 0.7272727272727273, 0.74, 1.0, 1.0, 0.4560659373754767, 1.0, 0.5, 0.4560659373754767, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4767425338485877, 0.4767425338485877, 0.6002390778410749], 
reward next is 0.3998, 
noisyNet noise sample is [array([0.46305683], dtype=float32), 0.40403214]. 
=============================================
[2019-03-23 14:24:47,105] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71500, global step 1144586: loss -82.5129
[2019-03-23 14:24:47,108] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71500, global step 1144586: learning rate 0.0000
[2019-03-23 14:24:47,350] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.9131521e-05 9.9980408e-01 4.4894877e-14 4.9881987e-12 1.6683045e-04], sum to 1.0000
[2019-03-23 14:24:47,356] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7190
[2019-03-23 14:24:47,363] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1309255.251948384 W.
[2019-03-23 14:24:47,370] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.66666666666666, 73.66666666666667, 1.0, 2.0, 0.6680424465316297, 0.0, 1.0, 0.0, 1.0, 1.0, 0.974540339585428, 6.911200000000001, 6.9112, 77.32846262203068, 1309255.251948384, 1309255.251948384, 284722.4277771926], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3159600.0000, 
sim time next is 3160200.0000, 
raw observation next is [24.83333333333334, 71.33333333333333, 1.0, 2.0, 0.568446689834943, 1.0, 1.0, 0.568446689834943, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846343845583, 1292600.150455166, 1292600.150455166, 248805.9524817013], 
processed observation next is [1.0, 0.5652173913043478, 0.7651515151515155, 0.7133333333333333, 1.0, 1.0, 0.46055836229367864, 1.0, 0.5, 0.46055836229367864, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288128872192, 0.4787407964648763, 0.4787407964648763, 0.6068437865407349], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.10691052], dtype=float32), -0.10487799]. 
=============================================
[2019-03-23 14:24:51,957] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.8202369e-08 9.9971217e-01 7.2083409e-19 1.2846925e-18 2.8764439e-04], sum to 1.0000
[2019-03-23 14:24:51,966] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8824
[2019-03-23 14:24:51,976] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 55.83333333333333, 1.0, 2.0, 0.3210806450883226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 350925.5197553088, 350925.5197553091, 113419.3825378409], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3268200.0000, 
sim time next is 3268800.0000, 
raw observation next is [22.0, 57.0, 1.0, 2.0, 0.3231489305473952, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 353405.012645313, 353405.012645313, 113644.0924907997], 
processed observation next is [0.0, 0.8695652173913043, 0.6363636363636364, 0.57, 1.0, 1.0, 0.15393616318424397, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13089074542419, 0.13089074542419, 0.27718071339219436], 
reward next is 0.7228, 
noisyNet noise sample is [array([0.5495894], dtype=float32), 2.1965492]. 
=============================================
[2019-03-23 14:24:54,052] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.2690968e-07 9.9999034e-01 1.7373935e-21 4.0731296e-18 9.3759090e-06], sum to 1.0000
[2019-03-23 14:24:54,058] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9211
[2019-03-23 14:24:54,061] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 68.0, 1.0, 2.0, 0.2782930207503172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 302177.7900688094, 302177.7900688091, 98404.87468196466], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3312600.0000, 
sim time next is 3313200.0000, 
raw observation next is [19.0, 68.0, 1.0, 2.0, 0.2808050735767668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 304906.2973407179, 304906.2973407182, 98687.78694228042], 
processed observation next is [0.0, 0.34782608695652173, 0.5, 0.68, 1.0, 1.0, 0.10100634197095851, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11292825827433997, 0.11292825827434008, 0.24070191937141566], 
reward next is 0.7593, 
noisyNet noise sample is [array([0.02755716], dtype=float32), 0.8493437]. 
=============================================
[2019-03-23 14:24:56,669] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0112180e-07 9.9997246e-01 9.3521363e-18 4.1248474e-16 2.7375136e-05], sum to 1.0000
[2019-03-23 14:24:56,675] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6535
[2019-03-23 14:24:56,680] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 50.0, 1.0, 2.0, 0.3613296061412748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 404545.6002680939, 404545.6002680939, 120141.8485076815], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3344400.0000, 
sim time next is 3345000.0000, 
raw observation next is [24.83333333333334, 51.16666666666667, 1.0, 2.0, 0.3623054975770358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 405847.7160408788, 405847.7160408791, 120320.6525217437], 
processed observation next is [0.0, 0.7391304347826086, 0.7651515151515155, 0.5116666666666667, 1.0, 1.0, 0.2028818719712947, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15031396890402918, 0.1503139689040293, 0.2934650061505944], 
reward next is 0.7065, 
noisyNet noise sample is [array([-0.25071228], dtype=float32), 0.27746424]. 
=============================================
[2019-03-23 14:24:56,698] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[68.6106  ]
 [68.5876  ]
 [68.57738 ]
 [68.558426]
 [68.539185]], R is [[68.63342285]
 [68.65406036]
 [68.67446136]
 [68.69474792]
 [68.71504211]].
[2019-03-23 14:24:56,851] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.1547529e-07 9.9977249e-01 1.0510821e-17 8.4801053e-16 2.2718729e-04], sum to 1.0000
[2019-03-23 14:24:56,860] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3629
[2019-03-23 14:24:56,867] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3340228342795715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 367659.3139318851, 367659.3139318848, 115285.1314058683], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3372000.0000, 
sim time next is 3372600.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3333412929145349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 366907.0275929371, 366907.0275929371, 115233.9195509946], 
processed observation next is [1.0, 0.0, 0.45454545454545453, 0.88, 1.0, 1.0, 0.16667661614316862, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13589149170108783, 0.13589149170108783, 0.28105834036827954], 
reward next is 0.7189, 
noisyNet noise sample is [array([1.4547257], dtype=float32), 1.7400559]. 
=============================================
[2019-03-23 14:24:57,182] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 14:24:57,183] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:24:57,184] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:24:57,185] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:24:57,185] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:24:57,186] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:24:57,189] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:24:57,190] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:24:57,195] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:24:57,197] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:24:57,192] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:24:57,217] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run47
[2019-03-23 14:24:57,218] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run47
[2019-03-23 14:24:57,281] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run47
[2019-03-23 14:24:57,306] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run47
[2019-03-23 14:24:57,338] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run47
[2019-03-23 14:25:04,712] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05978165], dtype=float32), 0.21188495]
[2019-03-23 14:25:04,713] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 64.0, 1.0, 2.0, 0.5417743230980001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595820.1037126207, 595820.1037126207, 133064.7583131954]
[2019-03-23 14:25:04,714] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:25:04,718] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.6570490e-07 9.9995148e-01 4.9751238e-17 1.8796426e-15 4.8321850e-05], sampled 0.8931737027895801
[2019-03-23 14:25:05,230] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05978165], dtype=float32), 0.21188495]
[2019-03-23 14:25:05,231] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.75329875666667, 90.76963713666666, 1.0, 2.0, 0.3256524328797096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 358321.3673179895, 358321.3673179895, 118939.0525712243]
[2019-03-23 14:25:05,232] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:25:05,233] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.7005793e-08 9.9998021e-01 1.7412932e-18 8.9988774e-17 1.9653029e-05], sampled 0.5248554117935891
[2019-03-23 14:25:23,573] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05978165], dtype=float32), 0.21188495]
[2019-03-23 14:25:23,574] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.13333333333333, 52.33333333333334, 1.0, 2.0, 0.2735322175790329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 296989.5120124999, 296989.5120124992, 82001.94565043233]
[2019-03-23 14:25:23,575] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:25:23,578] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.2656949e-07 9.9997008e-01 8.1834881e-18 3.6594952e-16 2.9770468e-05], sampled 0.003104232200273338
[2019-03-23 14:25:55,126] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05978165], dtype=float32), 0.21188495]
[2019-03-23 14:25:55,131] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.42070916, 81.41120361, 1.0, 2.0, 0.4083826889180074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 463224.3335319182, 463224.3335319179, 131779.4405235333]
[2019-03-23 14:25:55,132] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:25:55,136] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.2996189e-08 9.9998307e-01 9.8484641e-19 5.3680816e-17 1.6867923e-05], sampled 0.24756832234098503
[2019-03-23 14:25:57,665] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05978165], dtype=float32), 0.21188495]
[2019-03-23 14:25:57,667] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.70780799666667, 95.89122599999999, 1.0, 2.0, 0.4465860255111098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 503124.5812123393, 503124.5812123389, 133454.9475831597]
[2019-03-23 14:25:57,669] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:25:57,672] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0916789e-07 9.9997282e-01 5.7095906e-18 2.6408349e-16 2.7031867e-05], sampled 0.9011553298299483
[2019-03-23 14:26:06,650] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05978165], dtype=float32), 0.21188495]
[2019-03-23 14:26:06,652] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [28.16666666666667, 49.0, 1.0, 2.0, 0.757777520340239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 864477.9986314416, 864477.9986314413, 178163.1483340901]
[2019-03-23 14:26:06,654] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:26:06,656] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.9412086e-07 9.9996042e-01 2.3181649e-17 9.4066312e-16 3.9368813e-05], sampled 0.2366341011384019
[2019-03-23 14:26:35,253] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05978165], dtype=float32), 0.21188495]
[2019-03-23 14:26:35,254] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.63333333333334, 57.33333333333333, 1.0, 2.0, 0.3589652523031743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 402117.0731196664, 402117.073119666, 124370.8917038112]
[2019-03-23 14:26:35,255] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:26:35,258] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.6194558e-08 9.9998462e-01 7.0511553e-19 3.9651485e-17 1.5421187e-05], sampled 0.5325603411739754
[2019-03-23 14:26:39,382] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.7292 1656203264.9586 79.0000
[2019-03-23 14:26:39,447] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05978165], dtype=float32), 0.21188495]
[2019-03-23 14:26:39,449] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.6, 71.0, 1.0, 2.0, 0.3116577853951367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 339356.2747003317, 339356.274700332, 112306.2570923225]
[2019-03-23 14:26:39,450] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:26:39,451] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.4778393e-08 9.9997520e-01 4.0487468e-18 1.9336216e-16 2.4648982e-05], sampled 0.3878075595803161
[2019-03-23 14:26:40,135] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 14:26:40,167] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 14:26:40,245] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 14:26:40,388] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 14:26:41,406] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1150000, evaluation results [1150000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.729235023584, 1656203264.9585803, 79.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 14:26:43,248] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.1155553e-06 9.9952042e-01 2.5614153e-12 4.8362363e-11 4.7449328e-04], sum to 1.0000
[2019-03-23 14:26:43,257] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3004
[2019-03-23 14:26:43,266] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1125591.49504841 W.
[2019-03-23 14:26:43,270] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 65.0, 1.0, 2.0, 0.9859183059760028, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344353861, 1125591.49504841, 1125591.49504841, 213193.4441102018], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3411600.0000, 
sim time next is 3412200.0000, 
raw observation next is [25.0, 65.0, 1.0, 2.0, 0.5053366552999198, 1.0, 1.0, 0.5053366552999198, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354103, 1153358.164196634, 1153358.164196634, 229035.2389141222], 
processed observation next is [1.0, 0.4782608695652174, 0.7727272727272727, 0.65, 1.0, 1.0, 0.3816708191248997, 1.0, 0.5, 0.3816708191248997, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.508428812920654, 0.42716969044319775, 0.42716969044319775, 0.5586225339368834], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1850191], dtype=float32), 0.44262552]. 
=============================================
[2019-03-23 14:26:43,961] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72000, global step 1151265: loss 0.5857
[2019-03-23 14:26:43,964] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72000, global step 1151266: learning rate 0.0000
[2019-03-23 14:26:44,470] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72000, global step 1151528: loss -4.9210
[2019-03-23 14:26:44,471] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72000, global step 1151528: learning rate 0.0000
[2019-03-23 14:26:44,906] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72000, global step 1151746: loss 2.5093
[2019-03-23 14:26:44,908] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72000, global step 1151746: learning rate 0.0000
[2019-03-23 14:26:44,917] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72000, global step 1151749: loss 4.3547
[2019-03-23 14:26:44,919] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72000, global step 1151749: learning rate 0.0000
[2019-03-23 14:26:45,015] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72000, global step 1151798: loss 1.9247
[2019-03-23 14:26:45,016] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72000, global step 1151798: learning rate 0.0000
[2019-03-23 14:26:45,287] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72000, global step 1151934: loss -2.5644
[2019-03-23 14:26:45,290] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72000, global step 1151934: learning rate 0.0000
[2019-03-23 14:26:45,475] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72000, global step 1152029: loss -1.1228
[2019-03-23 14:26:45,478] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72000, global step 1152031: learning rate 0.0000
[2019-03-23 14:26:45,515] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72000, global step 1152047: loss 0.6755
[2019-03-23 14:26:45,518] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72000, global step 1152048: learning rate 0.0000
[2019-03-23 14:26:45,563] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72000, global step 1152074: loss -1.6278
[2019-03-23 14:26:45,566] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72000, global step 1152075: learning rate 0.0000
[2019-03-23 14:26:45,574] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72000, global step 1152078: loss -0.2666
[2019-03-23 14:26:45,576] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72000, global step 1152079: learning rate 0.0000
[2019-03-23 14:26:45,602] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72000, global step 1152090: loss -1.3548
[2019-03-23 14:26:45,604] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72000, global step 1152091: learning rate 0.0000
[2019-03-23 14:26:45,624] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72000, global step 1152101: loss -1.2383
[2019-03-23 14:26:45,625] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72000, global step 1152101: loss 0.1565
[2019-03-23 14:26:45,628] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72000, global step 1152101: learning rate 0.0000
[2019-03-23 14:26:45,629] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72000, global step 1152102: learning rate 0.0000
[2019-03-23 14:26:45,937] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72000, global step 1152263: loss -1.5735
[2019-03-23 14:26:45,938] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72000, global step 1152263: learning rate 0.0000
[2019-03-23 14:26:45,988] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72000, global step 1152287: loss 0.1016
[2019-03-23 14:26:45,994] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72000, global step 1152288: learning rate 0.0000
[2019-03-23 14:26:46,888] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72000, global step 1152712: loss 0.0832
[2019-03-23 14:26:46,890] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72000, global step 1152713: learning rate 0.0000
[2019-03-23 14:27:00,009] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0049916e-06 9.9626130e-01 5.1563876e-15 2.6436080e-09 3.7377456e-03], sum to 1.0000
[2019-03-23 14:27:00,016] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8071
[2019-03-23 14:27:00,020] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 68.66666666666667, 1.0, 2.0, 0.522079172206488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 594533.9234486866, 594533.9234486866, 145666.5067482021], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3700200.0000, 
sim time next is 3700800.0000, 
raw observation next is [26.0, 70.0, 1.0, 2.0, 0.5258029303340938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 598638.7378771971, 598638.7378771971, 146229.4423130417], 
processed observation next is [1.0, 0.8695652173913043, 0.8181818181818182, 0.7, 1.0, 1.0, 0.40725366291761717, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22171805106562856, 0.22171805106562856, 0.3566571763732725], 
reward next is 0.6433, 
noisyNet noise sample is [array([1.6136502], dtype=float32), -0.9414392]. 
=============================================
[2019-03-23 14:27:00,106] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72500, global step 1159326: loss 9.8784
[2019-03-23 14:27:00,107] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72500, global step 1159326: learning rate 0.0000
[2019-03-23 14:27:00,823] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72500, global step 1159692: loss -26.7708
[2019-03-23 14:27:00,825] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72500, global step 1159692: learning rate 0.0000
[2019-03-23 14:27:00,909] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72500, global step 1159730: loss -100.9327
[2019-03-23 14:27:00,911] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72500, global step 1159731: learning rate 0.0000
[2019-03-23 14:27:00,977] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72500, global step 1159767: loss -19.0665
[2019-03-23 14:27:00,981] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72500, global step 1159768: learning rate 0.0000
[2019-03-23 14:27:01,024] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72500, global step 1159788: loss 4.1604
[2019-03-23 14:27:01,026] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72500, global step 1159788: learning rate 0.0000
[2019-03-23 14:27:01,256] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72500, global step 1159902: loss -94.1282
[2019-03-23 14:27:01,259] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72500, global step 1159903: learning rate 0.0000
[2019-03-23 14:27:01,376] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72500, global step 1159960: loss -1.4392
[2019-03-23 14:27:01,377] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72500, global step 1159960: learning rate 0.0000
[2019-03-23 14:27:01,491] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72500, global step 1160015: loss 9.4845
[2019-03-23 14:27:01,494] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72500, global step 1160015: learning rate 0.0000
[2019-03-23 14:27:01,517] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72500, global step 1160029: loss -82.9495
[2019-03-23 14:27:01,518] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72500, global step 1160029: learning rate 0.0000
[2019-03-23 14:27:01,601] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72500, global step 1160073: loss 1.7243
[2019-03-23 14:27:01,604] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72500, global step 1160073: learning rate 0.0000
[2019-03-23 14:27:01,609] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72500, global step 1160076: loss -6.3117
[2019-03-23 14:27:01,611] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72500, global step 1160076: learning rate 0.0000
[2019-03-23 14:27:01,749] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72500, global step 1160145: loss 3.7386
[2019-03-23 14:27:01,750] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72500, global step 1160145: learning rate 0.0000
[2019-03-23 14:27:01,790] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72500, global step 1160167: loss -36.1471
[2019-03-23 14:27:01,792] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72500, global step 1160169: learning rate 0.0000
[2019-03-23 14:27:01,875] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72500, global step 1160209: loss -74.3403
[2019-03-23 14:27:01,876] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72500, global step 1160209: learning rate 0.0000
[2019-03-23 14:27:02,015] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72500, global step 1160269: loss -149.6536
[2019-03-23 14:27:02,017] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72500, global step 1160269: learning rate 0.0000
[2019-03-23 14:27:03,097] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72500, global step 1160760: loss -126.2371
[2019-03-23 14:27:03,103] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72500, global step 1160760: learning rate 0.0000
[2019-03-23 14:27:03,673] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.5232015e-10 9.9999928e-01 1.2058524e-22 3.5702096e-15 7.4450605e-07], sum to 1.0000
[2019-03-23 14:27:03,684] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5391
[2019-03-23 14:27:03,687] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.00000000000001, 1.0, 2.0, 0.323499180491624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 353919.7351028778, 353919.7351028781, 113716.145436956], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3809400.0000, 
sim time next is 3810000.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3230181168876665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 353391.2034483018, 353391.2034483021, 113681.0877164559], 
processed observation next is [0.0, 0.08695652173913043, 0.4090909090909091, 0.94, 1.0, 1.0, 0.15377264610958313, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13088563090677846, 0.13088563090677857, 0.27727094564989246], 
reward next is 0.7227, 
noisyNet noise sample is [array([0.24355946], dtype=float32), -0.7427799]. 
=============================================
[2019-03-23 14:27:03,705] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[73.07233 ]
 [72.88764 ]
 [72.792885]
 [72.55964 ]
 [72.51736 ]], R is [[73.06465149]
 [73.05664825]
 [73.04866028]
 [73.04063416]
 [73.03237152]].
[2019-03-23 14:27:04,135] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.0180473e-08 9.9999988e-01 1.6619023e-19 4.0096494e-12 1.3943657e-07], sum to 1.0000
[2019-03-23 14:27:04,145] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8885
[2019-03-23 14:27:04,149] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 91.0, 1.0, 2.0, 0.334727113946463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 367491.3285960814, 367491.3285960814, 114987.2903776571], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3796200.0000, 
sim time next is 3796800.0000, 
raw observation next is [17.33333333333333, 92.0, 1.0, 2.0, 0.3335091822995002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 365792.3634065549, 365792.3634065552, 114765.8611823734], 
processed observation next is [1.0, 0.9565217391304348, 0.42424242424242403, 0.92, 1.0, 1.0, 0.16688647787437524, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13547865311353885, 0.13547865311353896, 0.2799167345911546], 
reward next is 0.7201, 
noisyNet noise sample is [array([-1.3152306], dtype=float32), 1.3933693]. 
=============================================
[2019-03-23 14:27:12,745] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.8711905e-08 9.9998856e-01 3.4744249e-17 7.8520149e-11 1.1352386e-05], sum to 1.0000
[2019-03-23 14:27:12,755] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7134
[2019-03-23 14:27:12,758] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.5, 88.0, 1.0, 2.0, 0.2734096376227215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 296873.6674021565, 296873.6674021562, 97860.88957480535], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3987000.0000, 
sim time next is 3987600.0000, 
raw observation next is [16.33333333333333, 90.0, 1.0, 2.0, 0.2746021842260901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 298168.9553683809, 298168.9553683809, 98840.37117845147], 
processed observation next is [1.0, 0.13043478260869565, 0.37878787878787856, 0.9, 1.0, 1.0, 0.09325273028261263, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11043294643273366, 0.11043294643273366, 0.24107407604500358], 
reward next is 0.7589, 
noisyNet noise sample is [array([0.34494534], dtype=float32), 0.16150184]. 
=============================================
[2019-03-23 14:27:15,450] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73000, global step 1167285: loss 0.0274
[2019-03-23 14:27:15,453] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73000, global step 1167285: learning rate 0.0000
[2019-03-23 14:27:16,139] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73000, global step 1167642: loss 0.0097
[2019-03-23 14:27:16,141] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73000, global step 1167644: learning rate 0.0000
[2019-03-23 14:27:16,189] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73000, global step 1167670: loss 0.0225
[2019-03-23 14:27:16,192] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73000, global step 1167672: learning rate 0.0000
[2019-03-23 14:27:16,228] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73000, global step 1167692: loss 0.0314
[2019-03-23 14:27:16,232] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73000, global step 1167692: learning rate 0.0000
[2019-03-23 14:27:16,279] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73000, global step 1167715: loss 0.0256
[2019-03-23 14:27:16,282] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73000, global step 1167717: learning rate 0.0000
[2019-03-23 14:27:16,398] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73000, global step 1167777: loss 0.0067
[2019-03-23 14:27:16,405] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73000, global step 1167777: learning rate 0.0000
[2019-03-23 14:27:16,863] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73000, global step 1168025: loss 0.0029
[2019-03-23 14:27:16,866] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73000, global step 1168025: learning rate 0.0000
[2019-03-23 14:27:16,881] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73000, global step 1168035: loss 0.0173
[2019-03-23 14:27:16,885] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73000, global step 1168035: learning rate 0.0000
[2019-03-23 14:27:16,939] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73000, global step 1168066: loss 0.0502
[2019-03-23 14:27:16,943] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73000, global step 1168066: learning rate 0.0000
[2019-03-23 14:27:16,955] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73000, global step 1168072: loss 0.0709
[2019-03-23 14:27:16,957] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73000, global step 1168074: learning rate 0.0000
[2019-03-23 14:27:17,092] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73000, global step 1168146: loss 0.0823
[2019-03-23 14:27:17,093] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73000, global step 1168147: learning rate 0.0000
[2019-03-23 14:27:17,124] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73000, global step 1168160: loss 0.0309
[2019-03-23 14:27:17,125] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73000, global step 1168160: learning rate 0.0000
[2019-03-23 14:27:17,187] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73000, global step 1168190: loss 0.0098
[2019-03-23 14:27:17,188] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73000, global step 1168190: learning rate 0.0000
[2019-03-23 14:27:17,248] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73000, global step 1168226: loss 0.0010
[2019-03-23 14:27:17,256] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73000, global step 1168226: learning rate 0.0000
[2019-03-23 14:27:17,487] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73000, global step 1168351: loss 0.0103
[2019-03-23 14:27:17,490] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73000, global step 1168353: learning rate 0.0000
[2019-03-23 14:27:18,214] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73000, global step 1168737: loss 0.0694
[2019-03-23 14:27:18,219] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73000, global step 1168737: learning rate 0.0000
[2019-03-23 14:27:24,366] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.5222948e-11 9.9999976e-01 9.3539018e-23 3.0907345e-14 2.7397087e-07], sum to 1.0000
[2019-03-23 14:27:24,373] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5544
[2019-03-23 14:27:24,379] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 73.0, 1.0, 2.0, 0.3660961150829387, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 409322.867486709, 409322.8674867087, 120280.4680762273], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4221600.0000, 
sim time next is 4222200.0000, 
raw observation next is [21.0, 73.0, 1.0, 2.0, 0.3653083579086901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 408439.0412104639, 408439.0412104641, 120214.0198250457], 
processed observation next is [1.0, 0.8695652173913043, 0.5909090909090909, 0.73, 1.0, 1.0, 0.2066354473858626, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15127371896683847, 0.15127371896683856, 0.29320492640255047], 
reward next is 0.7068, 
noisyNet noise sample is [array([2.3538182], dtype=float32), -0.95385426]. 
=============================================
[2019-03-23 14:27:30,089] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 14:27:30,091] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:27:30,093] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:27:30,093] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:27:30,095] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:27:30,096] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:27:30,097] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:27:30,098] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:27:30,095] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:27:30,098] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:27:30,099] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:27:30,107] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run48
[2019-03-23 14:27:30,136] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run48
[2019-03-23 14:27:30,164] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run48
[2019-03-23 14:27:30,164] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run48
[2019-03-23 14:27:30,220] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run48
[2019-03-23 14:27:32,276] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05978165], dtype=float32), 0.2177979]
[2019-03-23 14:27:32,277] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.97795945333333, 71.55685822666666, 1.0, 2.0, 0.2501014024923023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 271543.5943182483, 271543.5943182487, 87161.82497653988]
[2019-03-23 14:27:32,277] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:27:32,280] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.1395305e-10 1.0000000e+00 7.0751827e-21 6.4448738e-15 3.2338114e-09], sampled 0.6562798453678294
[2019-03-23 14:27:53,904] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05978165], dtype=float32), 0.2177979]
[2019-03-23 14:27:53,906] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.2, 45.5, 1.0, 2.0, 0.3177873069142262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 347763.4726942303, 347763.47269423, 117659.5970671322]
[2019-03-23 14:27:53,907] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:27:53,911] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.1726140e-10 1.0000000e+00 7.2992719e-21 6.5871724e-15 3.2766643e-09], sampled 0.780368816540355
[2019-03-23 14:27:59,299] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05978165], dtype=float32), 0.2177979]
[2019-03-23 14:27:59,300] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.38333333333333, 49.66666666666667, 1.0, 2.0, 0.4686273350029286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 533428.9181921481, 533428.9181921477, 139273.1687976014]
[2019-03-23 14:27:59,301] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:27:59,305] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.8966581e-10 1.0000000e+00 5.5243015e-21 5.4105907e-15 2.9112976e-09], sampled 0.5054193512883454
[2019-03-23 14:28:23,111] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05978165], dtype=float32), 0.2177979]
[2019-03-23 14:28:23,112] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [31.45, 48.0, 1.0, 2.0, 0.9234258621840367, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9832912491552335, 6.911199999999997, 6.9112, 95.5533876394972, 1589064.230634834, 1589064.230634835, 340252.4984999077]
[2019-03-23 14:28:23,114] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:28:23,118] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.2721945e-10 1.0000000e+00 8.0161621e-21 7.0352380e-15 3.4082643e-09], sampled 0.5417478386112113
[2019-03-23 14:28:23,119] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1589064.230634834 W.
[2019-03-23 14:28:26,900] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05978165], dtype=float32), 0.2177979]
[2019-03-23 14:28:26,902] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 94.0, 1.0, 2.0, 0.4616544531435548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 526550.0462893476, 526550.0462893473, 135639.720165106]
[2019-03-23 14:28:26,903] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:28:26,907] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.1092025e-10 1.0000000e+00 6.8696510e-21 6.3116414e-15 3.1933882e-09], sampled 0.762960085700722
[2019-03-23 14:29:03,502] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05978165], dtype=float32), 0.2177979]
[2019-03-23 14:29:03,503] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [12.05092162, 86.66383414333333, 1.0, 2.0, 0.2229091605265458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 242014.1091105466, 242014.1091105459, 75959.18360544165]
[2019-03-23 14:29:03,504] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:29:03,505] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.6404499e-10 1.0000000e+00 2.1052047e-20 1.3919454e-14 5.1340558e-09], sampled 0.8273030089035097
[2019-03-23 14:29:09,866] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05978165], dtype=float32), 0.2177979]
[2019-03-23 14:29:09,868] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.5, 91.5, 1.0, 2.0, 0.4311201808068552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 490361.4663856686, 490361.4663856686, 130697.1836539792]
[2019-03-23 14:29:09,868] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:29:09,870] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.0971480e-10 1.0000000e+00 6.7894880e-21 6.2595625e-15 3.1774516e-09], sampled 0.6648482107573334
[2019-03-23 14:29:13,190] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:29:13,213] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 14:29:13,272] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 14:29:13,313] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 14:29:13,392] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 14:29:14,408] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1175000, evaluation results [1175000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 14:29:15,151] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73500, global step 1175367: loss -45.0333
[2019-03-23 14:29:15,152] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73500, global step 1175367: learning rate 0.0000
[2019-03-23 14:29:15,532] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73500, global step 1175554: loss -56.4903
[2019-03-23 14:29:15,534] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73500, global step 1175554: learning rate 0.0000
[2019-03-23 14:29:15,704] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73500, global step 1175641: loss -20.1027
[2019-03-23 14:29:15,705] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73500, global step 1175641: learning rate 0.0000
[2019-03-23 14:29:15,961] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73500, global step 1175768: loss -37.3317
[2019-03-23 14:29:15,963] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73500, global step 1175769: learning rate 0.0000
[2019-03-23 14:29:15,993] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73500, global step 1175784: loss -38.3866
[2019-03-23 14:29:15,996] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73500, global step 1175784: learning rate 0.0000
[2019-03-23 14:29:16,062] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73500, global step 1175817: loss -36.5868
[2019-03-23 14:29:16,065] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73500, global step 1175819: learning rate 0.0000
[2019-03-23 14:29:16,090] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1044598e-10 1.0000000e+00 1.7160001e-17 1.0810321e-13 1.0093511e-08], sum to 1.0000
[2019-03-23 14:29:16,097] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8049
[2019-03-23 14:29:16,100] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333333, 79.66666666666667, 1.0, 2.0, 0.8242211777360824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 939416.6074471476, 939416.6074471476, 182381.2937001936], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4351200.0000, 
sim time next is 4351800.0000, 
raw observation next is [22.66666666666667, 78.83333333333333, 1.0, 2.0, 0.8368682169015174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 954467.804609175, 954467.804609175, 185263.0550741871], 
processed observation next is [1.0, 0.34782608695652173, 0.6666666666666669, 0.7883333333333333, 1.0, 1.0, 0.7960852711268968, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.35350659429969444, 0.35350659429969444, 0.45186110993704176], 
reward next is 0.5481, 
noisyNet noise sample is [array([-0.76490176], dtype=float32), -1.1910084]. 
=============================================
[2019-03-23 14:29:16,184] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73500, global step 1175875: loss -48.4003
[2019-03-23 14:29:16,188] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73500, global step 1175877: learning rate 0.0000
[2019-03-23 14:29:16,316] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73500, global step 1175939: loss -26.3486
[2019-03-23 14:29:16,320] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73500, global step 1175939: learning rate 0.0000
[2019-03-23 14:29:16,355] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73500, global step 1175961: loss -29.8922
[2019-03-23 14:29:16,357] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73500, global step 1175961: learning rate 0.0000
[2019-03-23 14:29:16,454] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73500, global step 1176003: loss -31.2697
[2019-03-23 14:29:16,456] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73500, global step 1176003: learning rate 0.0000
[2019-03-23 14:29:16,741] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73500, global step 1176149: loss -14.9890
[2019-03-23 14:29:16,742] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73500, global step 1176149: learning rate 0.0000
[2019-03-23 14:29:16,860] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73500, global step 1176211: loss -53.7977
[2019-03-23 14:29:16,861] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73500, global step 1176211: loss -40.8538
[2019-03-23 14:29:16,866] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73500, global step 1176211: learning rate 0.0000
[2019-03-23 14:29:16,868] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73500, global step 1176213: learning rate 0.0000
[2019-03-23 14:29:17,007] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73500, global step 1176282: loss -55.5951
[2019-03-23 14:29:17,008] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73500, global step 1176282: learning rate 0.0000
[2019-03-23 14:29:17,023] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73500, global step 1176288: loss -41.6837
[2019-03-23 14:29:17,025] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73500, global step 1176289: learning rate 0.0000
[2019-03-23 14:29:17,720] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73500, global step 1176635: loss -24.4738
[2019-03-23 14:29:17,723] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73500, global step 1176635: learning rate 0.0000
[2019-03-23 14:29:17,830] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5055472e-08 9.9999988e-01 8.6289190e-18 1.5952751e-12 6.9801011e-08], sum to 1.0000
[2019-03-23 14:29:17,838] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2900
[2019-03-23 14:29:17,843] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 57.0, 1.0, 2.0, 0.4778755108595197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 545262.127360979, 545262.1273609793, 138799.9192052417], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4387200.0000, 
sim time next is 4387800.0000, 
raw observation next is [27.16666666666666, 57.5, 1.0, 2.0, 0.4769958480661194, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 544277.285079412, 544277.2850794124, 138578.4471764476], 
processed observation next is [1.0, 0.782608695652174, 0.871212121212121, 0.575, 1.0, 1.0, 0.3462448100826492, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2015841796590415, 0.20158417965904163, 0.33799621262548196], 
reward next is 0.6620, 
noisyNet noise sample is [array([0.6128656], dtype=float32), -0.20881633]. 
=============================================
[2019-03-23 14:29:24,360] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.0106611e-11 1.0000000e+00 3.7356381e-19 8.3382865e-14 1.6674476e-10], sum to 1.0000
[2019-03-23 14:29:24,365] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4723
[2019-03-23 14:29:24,371] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 100.0, 1.0, 2.0, 0.4184580159991009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 475296.8420955094, 475296.8420955091, 128884.2928737413], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4515600.0000, 
sim time next is 4516200.0000, 
raw observation next is [19.5, 100.0, 1.0, 2.0, 0.4227879584412305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 480685.5397863167, 480685.5397863167, 129695.4282004744], 
processed observation next is [0.0, 0.2608695652173913, 0.5227272727272727, 1.0, 1.0, 1.0, 0.2784849480515381, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17803168140233952, 0.17803168140233952, 0.3163303126840839], 
reward next is 0.6837, 
noisyNet noise sample is [array([2.2310743], dtype=float32), 0.5238086]. 
=============================================
[2019-03-23 14:29:26,136] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.1007309e-13 1.0000000e+00 4.7929159e-22 7.0108785e-17 6.5364977e-11], sum to 1.0000
[2019-03-23 14:29:26,143] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9015
[2019-03-23 14:29:26,154] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666666, 89.0, 1.0, 2.0, 0.4530210675113022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516204.9339574765, 516204.9339574765, 133903.6831965887], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4531800.0000, 
sim time next is 4532400.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.4412092239127522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 502165.6470338663, 502165.6470338663, 132021.7929360781], 
processed observation next is [0.0, 0.4782608695652174, 0.5909090909090909, 0.88, 1.0, 1.0, 0.3015115298909402, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18598727667920975, 0.18598727667920975, 0.32200437301482465], 
reward next is 0.6780, 
noisyNet noise sample is [array([0.36147177], dtype=float32), 1.8079928]. 
=============================================
[2019-03-23 14:29:27,573] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.8806182e-11 1.0000000e+00 7.0356994e-21 7.5908179e-15 1.5031034e-11], sum to 1.0000
[2019-03-23 14:29:27,584] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8814
[2019-03-23 14:29:27,592] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 61.0, 1.0, 2.0, 0.3924700066656023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 443708.1064311732, 443708.1064311735, 124992.3347552092], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4555200.0000, 
sim time next is 4555800.0000, 
raw observation next is [24.0, 61.0, 1.0, 2.0, 0.3920858247548311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 443272.4404316834, 443272.4404316834, 124956.748800857], 
processed observation next is [0.0, 0.7391304347826086, 0.7272727272727273, 0.61, 1.0, 1.0, 0.24010728094353886, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1641749779376605, 0.1641749779376605, 0.3047725580508707], 
reward next is 0.6952, 
noisyNet noise sample is [array([-0.04490352], dtype=float32), -0.7963457]. 
=============================================
[2019-03-23 14:29:28,946] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7815083e-13 1.0000000e+00 1.3801555e-24 1.6783460e-19 4.9400474e-13], sum to 1.0000
[2019-03-23 14:29:28,958] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5024
[2019-03-23 14:29:28,963] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.83333333333334, 83.00000000000001, 1.0, 2.0, 0.2744181352719697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 297969.0498357413, 297969.049835741, 94894.31921057339], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4579800.0000, 
sim time next is 4580400.0000, 
raw observation next is [16.66666666666667, 84.0, 1.0, 2.0, 0.2738230916740566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 297322.7413333947, 297322.7413333944, 94244.38286062122], 
processed observation next is [1.0, 0.0, 0.39393939393939414, 0.84, 1.0, 1.0, 0.09227886459257074, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11011953382718323, 0.11011953382718312, 0.22986434844053955], 
reward next is 0.7701, 
noisyNet noise sample is [array([-0.8561377], dtype=float32), 0.29883215]. 
=============================================
[2019-03-23 14:29:30,566] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.167470e-11 1.000000e+00 5.860213e-20 1.575509e-15 6.943469e-11], sum to 1.0000
[2019-03-23 14:29:30,572] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8527
[2019-03-23 14:29:30,579] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 77.5, 1.0, 2.0, 0.4228393426560543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 459204.0523988286, 459204.0523988289, 110184.1792708267], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4609800.0000, 
sim time next is 4610400.0000, 
raw observation next is [17.66666666666667, 76.0, 1.0, 2.0, 0.4282396008140365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 465071.544597264, 465071.5445972643, 110897.3757818225], 
processed observation next is [1.0, 0.34782608695652173, 0.4393939393939396, 0.76, 1.0, 1.0, 0.2852995010175456, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17224872022120888, 0.17224872022120902, 0.27048140434590856], 
reward next is 0.7295, 
noisyNet noise sample is [array([1.3559514], dtype=float32), 1.9874995]. 
=============================================
[2019-03-23 14:29:31,019] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74000, global step 1183285: loss 0.0543
[2019-03-23 14:29:31,020] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74000, global step 1183285: learning rate 0.0000
[2019-03-23 14:29:31,256] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.4467912e-11 1.0000000e+00 1.8063718e-22 7.4252443e-17 1.3423686e-11], sum to 1.0000
[2019-03-23 14:29:31,270] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6976
[2019-03-23 14:29:31,274] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 47.0, 1.0, 2.0, 0.6977566962580021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 759917.7962141768, 759917.7962141768, 147467.9836825842], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4632600.0000, 
sim time next is 4633200.0000, 
raw observation next is [23.0, 47.0, 1.0, 2.0, 0.6959289613914286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 756010.3821761305, 756010.3821761305, 146673.2700168135], 
processed observation next is [1.0, 0.6521739130434783, 0.6818181818181818, 0.47, 1.0, 1.0, 0.6199112017392857, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2800038452504187, 0.2800038452504187, 0.3577396829678378], 
reward next is 0.6423, 
noisyNet noise sample is [array([0.40002468], dtype=float32), 0.4529449]. 
=============================================
[2019-03-23 14:29:31,662] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74000, global step 1183601: loss 0.0169
[2019-03-23 14:29:31,666] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74000, global step 1183601: learning rate 0.0000
[2019-03-23 14:29:31,769] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74000, global step 1183654: loss 0.0002
[2019-03-23 14:29:31,770] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74000, global step 1183654: learning rate 0.0000
[2019-03-23 14:29:31,971] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74000, global step 1183757: loss 0.0067
[2019-03-23 14:29:31,980] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74000, global step 1183759: learning rate 0.0000
[2019-03-23 14:29:31,989] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74000, global step 1183760: loss 0.0070
[2019-03-23 14:29:31,992] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74000, global step 1183760: learning rate 0.0000
[2019-03-23 14:29:32,120] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74000, global step 1183824: loss 0.0008
[2019-03-23 14:29:32,121] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74000, global step 1183824: learning rate 0.0000
[2019-03-23 14:29:32,243] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74000, global step 1183889: loss 0.0214
[2019-03-23 14:29:32,247] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74000, global step 1183889: learning rate 0.0000
[2019-03-23 14:29:32,428] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74000, global step 1183981: loss 0.0014
[2019-03-23 14:29:32,430] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74000, global step 1183981: learning rate 0.0000
[2019-03-23 14:29:32,495] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74000, global step 1184014: loss 0.0149
[2019-03-23 14:29:32,501] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74000, global step 1184016: learning rate 0.0000
[2019-03-23 14:29:32,641] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74000, global step 1184085: loss 0.0089
[2019-03-23 14:29:32,642] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74000, global step 1184086: learning rate 0.0000
[2019-03-23 14:29:32,737] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74000, global step 1184128: loss 0.0002
[2019-03-23 14:29:32,740] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74000, global step 1184130: learning rate 0.0000
[2019-03-23 14:29:32,968] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74000, global step 1184248: loss 0.0010
[2019-03-23 14:29:32,970] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74000, global step 1184249: learning rate 0.0000
[2019-03-23 14:29:32,999] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74000, global step 1184263: loss 0.0008
[2019-03-23 14:29:33,002] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74000, global step 1184266: learning rate 0.0000
[2019-03-23 14:29:33,039] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74000, global step 1184279: loss 0.0168
[2019-03-23 14:29:33,040] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74000, global step 1184279: learning rate 0.0000
[2019-03-23 14:29:33,205] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74000, global step 1184360: loss 0.0034
[2019-03-23 14:29:33,207] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74000, global step 1184360: learning rate 0.0000
[2019-03-23 14:29:33,844] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74000, global step 1184681: loss 0.0492
[2019-03-23 14:29:33,849] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74000, global step 1184681: learning rate 0.0000
[2019-03-23 14:29:34,064] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4511848e-13 1.0000000e+00 1.5432904e-25 4.8499225e-18 3.7589300e-16], sum to 1.0000
[2019-03-23 14:29:34,070] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2143
[2019-03-23 14:29:34,075] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 65.33333333333334, 1.0, 2.0, 0.4523476943871485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 491266.3507310716, 491266.3507310716, 112312.6589139471], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4699200.0000, 
sim time next is 4699800.0000, 
raw observation next is [19.5, 64.0, 1.0, 2.0, 0.4875912169884661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 529562.9699941453, 529562.9699941453, 119167.8300171048], 
processed observation next is [1.0, 0.391304347826087, 0.5227272727272727, 0.64, 1.0, 1.0, 0.3594890212355826, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19613443333116493, 0.19613443333116493, 0.29065324394415804], 
reward next is 0.7093, 
noisyNet noise sample is [array([1.8023851], dtype=float32), -0.7748939]. 
=============================================
[2019-03-23 14:29:41,001] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4433707e-12 1.0000000e+00 9.5567446e-24 5.6955190e-18 4.1850160e-12], sum to 1.0000
[2019-03-23 14:29:41,009] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5655
[2019-03-23 14:29:41,013] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666666, 99.0, 1.0, 2.0, 0.5014788269402078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 572125.4865761545, 572125.4865761545, 141803.4291729788], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4816200.0000, 
sim time next is 4816800.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.503470366748855, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 574433.3817306015, 574433.3817306015, 141929.5947814181], 
processed observation next is [1.0, 0.782608695652174, 0.5909090909090909, 1.0, 1.0, 1.0, 0.37933795843606877, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21275310434466724, 0.21275310434466724, 0.34616974336931244], 
reward next is 0.6538, 
noisyNet noise sample is [array([-0.29789516], dtype=float32), -0.027550602]. 
=============================================
[2019-03-23 14:29:42,632] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.8002548e-12 1.0000000e+00 1.3048433e-22 2.4318128e-16 6.0043368e-12], sum to 1.0000
[2019-03-23 14:29:42,647] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9669
[2019-03-23 14:29:42,655] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 94.0, 1.0, 2.0, 0.4199084648685328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 477039.4878292025, 477039.4878292025, 129100.3908253982], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4850400.0000, 
sim time next is 4851000.0000, 
raw observation next is [20.0, 94.0, 1.0, 2.0, 0.4150020672130239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 471447.0900417712, 471447.0900417712, 128611.135307073], 
processed observation next is [1.0, 0.13043478260869565, 0.5454545454545454, 0.94, 1.0, 1.0, 0.2687525840162798, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17461003334880415, 0.17461003334880415, 0.3136856958709097], 
reward next is 0.6863, 
noisyNet noise sample is [array([0.34139004], dtype=float32), -0.9953098]. 
=============================================
[2019-03-23 14:29:42,670] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[67.84189 ]
 [67.808556]
 [67.659454]
 [67.74629 ]
 [67.61371 ]], R is [[67.90348053]
 [67.90956879]
 [67.91020966]
 [67.90650177]
 [67.90227509]].
[2019-03-23 14:29:45,220] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.6248400e-13 1.0000000e+00 4.5242015e-23 4.6185518e-18 2.2824431e-12], sum to 1.0000
[2019-03-23 14:29:45,228] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2460
[2019-03-23 14:29:45,233] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 76.33333333333334, 1.0, 2.0, 0.422754148930917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 480434.0143689322, 480434.0143689322, 129509.3809257295], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4908000.0000, 
sim time next is 4908600.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.4191911349874821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476129.1111338629, 476129.1111338629, 128954.2614235547], 
processed observation next is [1.0, 0.8260869565217391, 0.6363636363636364, 0.78, 1.0, 1.0, 0.2739889187343526, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17634411523476404, 0.17634411523476404, 0.31452258883793827], 
reward next is 0.6855, 
noisyNet noise sample is [array([1.8837442], dtype=float32), -1.297121]. 
=============================================
[2019-03-23 14:29:46,567] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74500, global step 1191306: loss 0.3200
[2019-03-23 14:29:46,571] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74500, global step 1191308: learning rate 0.0000
[2019-03-23 14:29:47,092] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74500, global step 1191582: loss 0.3863
[2019-03-23 14:29:47,096] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74500, global step 1191582: learning rate 0.0000
[2019-03-23 14:29:47,396] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74500, global step 1191746: loss 0.7401
[2019-03-23 14:29:47,398] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74500, global step 1191746: learning rate 0.0000
[2019-03-23 14:29:47,424] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74500, global step 1191759: loss 0.8310
[2019-03-23 14:29:47,426] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74500, global step 1191759: learning rate 0.0000
[2019-03-23 14:29:47,437] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74500, global step 1191762: loss 0.9015
[2019-03-23 14:29:47,439] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74500, global step 1191762: learning rate 0.0000
[2019-03-23 14:29:47,517] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.1885872e-12 1.0000000e+00 1.7581902e-23 1.8952050e-17 2.1770502e-12], sum to 1.0000
[2019-03-23 14:29:47,524] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9826
[2019-03-23 14:29:47,531] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.5136556265279839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 563418.3496465817, 563418.3496465817, 129850.1772988182], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4957200.0000, 
sim time next is 4957800.0000, 
raw observation next is [17.16666666666667, 92.16666666666667, 1.0, 2.0, 0.5884783218115732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 645545.8145123834, 645545.8145123834, 137253.249863814], 
processed observation next is [1.0, 0.391304347826087, 0.4166666666666669, 0.9216666666666667, 1.0, 1.0, 0.4855979022644665, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23909104241199386, 0.23909104241199386, 0.334764024058083], 
reward next is 0.6652, 
noisyNet noise sample is [array([-1.6253642], dtype=float32), -1.8680408]. 
=============================================
[2019-03-23 14:29:47,554] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74500, global step 1191826: loss 0.7510
[2019-03-23 14:29:47,555] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74500, global step 1191826: learning rate 0.0000
[2019-03-23 14:29:47,829] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74500, global step 1191974: loss 0.2179
[2019-03-23 14:29:47,833] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74500, global step 1191975: learning rate 0.0000
[2019-03-23 14:29:47,845] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74500, global step 1191980: loss 0.2401
[2019-03-23 14:29:47,848] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74500, global step 1191983: learning rate 0.0000
[2019-03-23 14:29:47,915] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74500, global step 1192016: loss 0.3096
[2019-03-23 14:29:47,921] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74500, global step 1192016: learning rate 0.0000
[2019-03-23 14:29:47,941] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74500, global step 1192032: loss 0.3592
[2019-03-23 14:29:47,944] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74500, global step 1192033: learning rate 0.0000
[2019-03-23 14:29:48,059] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74500, global step 1192094: loss 0.5351
[2019-03-23 14:29:48,060] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74500, global step 1192094: learning rate 0.0000
[2019-03-23 14:29:48,191] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74500, global step 1192163: loss 0.4670
[2019-03-23 14:29:48,193] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74500, global step 1192164: learning rate 0.0000
[2019-03-23 14:29:48,273] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74500, global step 1192211: loss 0.3094
[2019-03-23 14:29:48,276] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74500, global step 1192211: learning rate 0.0000
[2019-03-23 14:29:48,423] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74500, global step 1192293: loss 0.3456
[2019-03-23 14:29:48,426] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74500, global step 1192294: learning rate 0.0000
[2019-03-23 14:29:48,696] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74500, global step 1192436: loss 0.2913
[2019-03-23 14:29:48,698] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74500, global step 1192437: learning rate 0.0000
[2019-03-23 14:29:49,130] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74500, global step 1192659: loss 0.2124
[2019-03-23 14:29:49,132] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74500, global step 1192659: learning rate 0.0000
[2019-03-23 14:29:49,907] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.6655913e-15 1.0000000e+00 2.6122348e-28 1.0720634e-20 2.2417261e-17], sum to 1.0000
[2019-03-23 14:29:49,909] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1131
[2019-03-23 14:29:49,919] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333334, 71.33333333333333, 1.0, 2.0, 0.2779444985766245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 301799.2382176683, 301799.2382176683, 95754.07799354676], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4995600.0000, 
sim time next is 4996200.0000, 
raw observation next is [18.16666666666666, 72.16666666666667, 1.0, 2.0, 0.2772184534759199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 301010.6359196728, 301010.6359196726, 95019.67470619973], 
processed observation next is [1.0, 0.8260869565217391, 0.4621212121212119, 0.7216666666666667, 1.0, 1.0, 0.09652306684489985, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11148542071098992, 0.11148542071098985, 0.23175530416146276], 
reward next is 0.7682, 
noisyNet noise sample is [array([-0.7138752], dtype=float32), 0.3221507]. 
=============================================
[2019-03-23 14:29:50,414] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.5918468e-13 1.0000000e+00 4.0847482e-24 9.8303462e-20 3.3228308e-15], sum to 1.0000
[2019-03-23 14:29:50,423] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8401
[2019-03-23 14:29:50,426] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 77.83333333333334, 1.0, 2.0, 0.2923808457665064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 317479.7094796926, 317479.7094796929, 101948.673556375], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5004600.0000, 
sim time next is 5005200.0000, 
raw observation next is [17.66666666666667, 78.66666666666667, 1.0, 2.0, 0.2931112814467748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 318273.1075283297, 318273.1075283297, 101054.8470717239], 
processed observation next is [1.0, 0.9565217391304348, 0.4393939393939396, 0.7866666666666667, 1.0, 1.0, 0.11638910180846847, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11787892871419618, 0.11787892871419618, 0.2464752367603022], 
reward next is 0.7535, 
noisyNet noise sample is [array([0.5029115], dtype=float32), 1.5557799]. 
=============================================
[2019-03-23 14:29:52,585] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.9629185e-12 1.0000000e+00 1.6479215e-24 3.3271494e-19 6.5132646e-14], sum to 1.0000
[2019-03-23 14:29:52,592] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0057
[2019-03-23 14:29:52,599] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 71.33333333333333, 1.0, 2.0, 0.3551886139860279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 398105.1195237255, 398105.1195237257, 119844.0902696905], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5046600.0000, 
sim time next is 5047200.0000, 
raw observation next is [22.0, 69.0, 1.0, 2.0, 0.3597076405977501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 403865.8730537352, 403865.8730537355, 120555.253094567], 
processed observation next is [0.0, 0.43478260869565216, 0.6363636363636364, 0.69, 1.0, 1.0, 0.19963455074718764, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1495799529828649, 0.149579952982865, 0.2940372026696756], 
reward next is 0.7060, 
noisyNet noise sample is [array([1.1257231], dtype=float32), 0.25048143]. 
=============================================
[2019-03-23 14:30:01,296] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75000, global step 1199092: loss 0.3219
[2019-03-23 14:30:01,298] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75000, global step 1199092: learning rate 0.0000
[2019-03-23 14:30:02,174] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75000, global step 1199559: loss 0.4491
[2019-03-23 14:30:02,178] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75000, global step 1199559: learning rate 0.0000
[2019-03-23 14:30:02,342] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75000, global step 1199643: loss 0.2990
[2019-03-23 14:30:02,346] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75000, global step 1199644: learning rate 0.0000
[2019-03-23 14:30:02,449] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75000, global step 1199698: loss 0.2376
[2019-03-23 14:30:02,456] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75000, global step 1199699: learning rate 0.0000
[2019-03-23 14:30:02,559] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75000, global step 1199753: loss 0.1407
[2019-03-23 14:30:02,561] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75000, global step 1199753: learning rate 0.0000
[2019-03-23 14:30:02,740] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75000, global step 1199852: loss 0.1357
[2019-03-23 14:30:02,742] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75000, global step 1199853: learning rate 0.0000
[2019-03-23 14:30:02,898] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75000, global step 1199934: loss 0.1142
[2019-03-23 14:30:02,903] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75000, global step 1199936: learning rate 0.0000
[2019-03-23 14:30:03,026] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 14:30:03,027] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:30:03,028] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:30:03,031] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:30:03,033] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:30:03,033] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:30:03,033] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:30:03,034] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:30:03,034] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:30:03,036] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:30:03,038] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:30:03,056] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run49
[2019-03-23 14:30:03,083] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run49
[2019-03-23 14:30:03,084] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run49
[2019-03-23 14:30:03,149] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run49
[2019-03-23 14:30:03,177] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run49
[2019-03-23 14:30:18,018] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05978165], dtype=float32), 0.22482216]
[2019-03-23 14:30:18,018] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.3, 61.0, 1.0, 2.0, 0.8212046428802982, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 95.55332016070422, 935403.406496264, 935403.406496264, 193166.7823217817]
[2019-03-23 14:30:18,019] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:30:18,022] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.8713490e-12 1.0000000e+00 5.6996122e-23 1.6983916e-16 1.3731584e-12], sampled 0.3962314027530677
[2019-03-23 14:30:28,114] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05978165], dtype=float32), 0.22482216]
[2019-03-23 14:30:28,116] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.83308883, 60.21459331333334, 1.0, 2.0, 0.3505134262030607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 391092.9115154312, 391092.9115154312, 122964.2615254583]
[2019-03-23 14:30:28,116] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:30:28,119] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.3384843e-12 1.0000000e+00 7.3966927e-24 3.9822172e-17 4.5915279e-13], sampled 0.6508522467084639
[2019-03-23 14:30:33,702] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05978165], dtype=float32), 0.22482216]
[2019-03-23 14:30:33,704] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [28.2, 59.0, 1.0, 2.0, 0.55453649519965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 630674.1426088482, 630674.1426088482, 154542.6603669338]
[2019-03-23 14:30:33,706] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:30:33,710] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.0434326e-13 1.0000000e+00 1.1314760e-24 1.0492700e-17 1.6768153e-13], sampled 0.6878694339671148
[2019-03-23 14:30:55,624] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05978165], dtype=float32), 0.22482216]
[2019-03-23 14:30:55,625] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [29.83333333333334, 52.5, 1.0, 2.0, 0.6185645307752318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 702470.0165562769, 702470.0165562769, 163607.4402052388]
[2019-03-23 14:30:55,626] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:30:55,633] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0366686e-12 1.0000000e+00 4.5224047e-24 2.8076280e-17 3.5262128e-13], sampled 0.49851611690160935
[2019-03-23 14:30:57,368] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05978165], dtype=float32), 0.22482216]
[2019-03-23 14:30:57,368] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.2, 88.0, 1.0, 2.0, 0.49405155857051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 563704.1886324727, 563704.1886324722, 144571.4370440149]
[2019-03-23 14:30:57,369] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:30:57,375] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.9211147e-13 1.0000000e+00 6.9737735e-25 7.4400694e-18 1.2933276e-13], sampled 0.1091037601888254
[2019-03-23 14:31:29,994] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05978165], dtype=float32), 0.22482216]
[2019-03-23 14:31:29,995] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.549211875, 96.70830842000001, 1.0, 2.0, 0.5085160750173183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 579904.0930764745, 579904.0930764745, 145014.3206493876]
[2019-03-23 14:31:29,996] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:31:29,999] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.3471258e-12 1.0000000e+00 7.4858814e-24 4.0161455e-17 4.6209336e-13], sampled 0.8670292244773882
[2019-03-23 14:31:45,698] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 14:31:46,113] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:31:46,151] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 14:31:46,314] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 14:31:46,323] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 14:31:47,341] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1200000, evaluation results [1200000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 14:31:47,448] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75000, global step 1200059: loss 0.0343
[2019-03-23 14:31:47,453] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75000, global step 1200060: learning rate 0.0000
[2019-03-23 14:31:47,570] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75000, global step 1200114: loss 0.2022
[2019-03-23 14:31:47,571] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75000, global step 1200114: learning rate 0.0000
[2019-03-23 14:31:47,601] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75000, global step 1200130: loss 0.0362
[2019-03-23 14:31:47,603] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75000, global step 1200132: learning rate 0.0000
[2019-03-23 14:31:47,632] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75000, global step 1200146: loss 0.0029
[2019-03-23 14:31:47,633] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75000, global step 1200147: loss 0.0073
[2019-03-23 14:31:47,634] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75000, global step 1200147: learning rate 0.0000
[2019-03-23 14:31:47,637] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75000, global step 1200147: learning rate 0.0000
[2019-03-23 14:31:47,784] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75000, global step 1200223: loss 0.0105
[2019-03-23 14:31:47,787] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75000, global step 1200223: learning rate 0.0000
[2019-03-23 14:31:47,977] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75000, global step 1200315: loss 0.0317
[2019-03-23 14:31:47,982] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75000, global step 1200317: learning rate 0.0000
[2019-03-23 14:31:48,143] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75000, global step 1200403: loss 0.0225
[2019-03-23 14:31:48,146] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75000, global step 1200403: learning rate 0.0000
[2019-03-23 14:31:48,590] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.7688393e-12 1.0000000e+00 3.2426512e-23 3.6931907e-17 1.6872354e-13], sum to 1.0000
[2019-03-23 14:31:48,608] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3690
[2019-03-23 14:31:48,613] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 87.0, 1.0, 2.0, 0.3639213606297486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 408079.7580427905, 408079.7580427905, 120655.0791790432], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5293800.0000, 
sim time next is 5294400.0000, 
raw observation next is [19.4, 87.0, 1.0, 2.0, 0.3654375169752801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 409786.4869952445, 409786.4869952445, 120784.8563878006], 
processed observation next is [1.0, 0.2608695652173913, 0.5181818181818181, 0.87, 1.0, 1.0, 0.2067968962191001, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15177277296120167, 0.15177277296120167, 0.29459721070195266], 
reward next is 0.7054, 
noisyNet noise sample is [array([0.73725355], dtype=float32), -0.62564623]. 
=============================================
[2019-03-23 14:31:48,924] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75000, global step 1200798: loss 0.1822
[2019-03-23 14:31:48,926] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75000, global step 1200799: learning rate 0.0000
[2019-03-23 14:31:58,645] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.2920233e-12 1.0000000e+00 2.3325415e-22 5.6855175e-16 7.1527159e-13], sum to 1.0000
[2019-03-23 14:31:58,654] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8186
[2019-03-23 14:31:58,660] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 90.0, 1.0, 2.0, 0.3229236141814408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 351644.2493624321, 351644.2493624324, 113095.2400403471], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5463600.0000, 
sim time next is 5464200.0000, 
raw observation next is [17.2, 90.0, 1.0, 2.0, 0.3232221185051365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 351970.6876271881, 351970.6876271878, 113116.6384186741], 
processed observation next is [1.0, 0.21739130434782608, 0.41818181818181815, 0.9, 1.0, 1.0, 0.15402764813142059, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1303595139359956, 0.13035951393599549, 0.2758942400455466], 
reward next is 0.7241, 
noisyNet noise sample is [array([0.27949226], dtype=float32), -0.4329996]. 
=============================================
[2019-03-23 14:31:59,765] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.1265936e-08 9.9999988e-01 6.4591730e-15 3.4694572e-10 4.4680633e-09], sum to 1.0000
[2019-03-23 14:31:59,773] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0433
[2019-03-23 14:31:59,778] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.9, 85.33333333333334, 1.0, 2.0, 0.753009645266359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 855222.3163131514, 855222.3163131516, 168810.1112818748], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5476800.0000, 
sim time next is 5477400.0000, 
raw observation next is [21.35, 84.5, 1.0, 2.0, 0.7954124395747453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 905147.4749658565, 905147.4749658565, 176422.4478382318], 
processed observation next is [1.0, 0.391304347826087, 0.6068181818181819, 0.845, 1.0, 1.0, 0.7442655494684316, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.33523980554290983, 0.33523980554290983, 0.43029865326398004], 
reward next is 0.5697, 
noisyNet noise sample is [array([0.30898264], dtype=float32), -1.3455951]. 
=============================================
[2019-03-23 14:32:01,620] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75500, global step 1207124: loss 0.0811
[2019-03-23 14:32:01,627] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75500, global step 1207129: learning rate 0.0000
[2019-03-23 14:32:02,571] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75500, global step 1207612: loss 0.0282
[2019-03-23 14:32:02,573] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75500, global step 1207612: learning rate 0.0000
[2019-03-23 14:32:02,597] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75500, global step 1207622: loss 0.0422
[2019-03-23 14:32:02,600] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75500, global step 1207622: learning rate 0.0000
[2019-03-23 14:32:02,656] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75500, global step 1207650: loss 0.0398
[2019-03-23 14:32:02,658] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75500, global step 1207651: learning rate 0.0000
[2019-03-23 14:32:02,726] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75500, global step 1207690: loss 0.0267
[2019-03-23 14:32:02,733] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75500, global step 1207690: learning rate 0.0000
[2019-03-23 14:32:02,962] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75500, global step 1207804: loss 0.0217
[2019-03-23 14:32:02,964] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75500, global step 1207804: learning rate 0.0000
[2019-03-23 14:32:03,157] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75500, global step 1207905: loss 0.0396
[2019-03-23 14:32:03,159] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75500, global step 1207906: learning rate 0.0000
[2019-03-23 14:32:03,495] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75500, global step 1208071: loss 0.2385
[2019-03-23 14:32:03,495] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75500, global step 1208071: learning rate 0.0000
[2019-03-23 14:32:03,543] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75500, global step 1208097: loss 0.2196
[2019-03-23 14:32:03,544] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75500, global step 1208097: learning rate 0.0000
[2019-03-23 14:32:03,576] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75500, global step 1208117: loss 0.2079
[2019-03-23 14:32:03,579] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75500, global step 1208117: learning rate 0.0000
[2019-03-23 14:32:03,610] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75500, global step 1208132: loss 0.1644
[2019-03-23 14:32:03,612] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75500, global step 1208132: loss 0.1582
[2019-03-23 14:32:03,612] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75500, global step 1208132: learning rate 0.0000
[2019-03-23 14:32:03,614] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75500, global step 1208132: learning rate 0.0000
[2019-03-23 14:32:03,825] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75500, global step 1208235: loss 0.0241
[2019-03-23 14:32:03,827] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75500, global step 1208237: learning rate 0.0000
[2019-03-23 14:32:03,870] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75500, global step 1208257: loss 0.0404
[2019-03-23 14:32:03,873] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75500, global step 1208258: learning rate 0.0000
[2019-03-23 14:32:03,927] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75500, global step 1208289: loss 0.0494
[2019-03-23 14:32:03,928] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75500, global step 1208289: learning rate 0.0000
[2019-03-23 14:32:04,780] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75500, global step 1208714: loss 0.0408
[2019-03-23 14:32:04,781] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75500, global step 1208714: learning rate 0.0000
[2019-03-23 14:32:07,799] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.4515568e-10 9.9999988e-01 4.2658392e-20 1.0421555e-13 1.0440726e-07], sum to 1.0000
[2019-03-23 14:32:07,806] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3270
[2019-03-23 14:32:07,810] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.7, 97.5, 1.0, 2.0, 0.3279431783570608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 359649.8988505, 359649.8988504997, 114347.1475445627], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5644200.0000, 
sim time next is 5644800.0000, 
raw observation next is [16.6, 97.0, 1.0, 2.0, 0.3229415006497224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 353121.7489254708, 353121.7489254708, 113608.7048024116], 
processed observation next is [0.0, 0.34782608695652173, 0.390909090909091, 0.97, 1.0, 1.0, 0.15367687581215295, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13078583293535956, 0.13078583293535956, 0.27709440195710144], 
reward next is 0.7229, 
noisyNet noise sample is [array([-1.8248202], dtype=float32), -1.0765662]. 
=============================================
[2019-03-23 14:32:09,763] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.1467223e-13 1.0000000e+00 1.0952008e-24 5.5735933e-16 2.0867109e-13], sum to 1.0000
[2019-03-23 14:32:09,772] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5370
[2019-03-23 14:32:09,781] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.1, 67.33333333333334, 1.0, 2.0, 0.2162510434541037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 234794.7386791859, 234794.7386791856, 74044.73906437184], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5682000.0000, 
sim time next is 5682600.0000, 
raw observation next is [16.1, 66.5, 1.0, 2.0, 0.2154935001095687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 233972.0375768875, 233972.0375768872, 73723.28705125193], 
processed observation next is [0.0, 0.782608695652174, 0.3681818181818182, 0.665, 1.0, 1.0, 0.01936687513696085, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08665631021366203, 0.08665631021366192, 0.17981289524695593], 
reward next is 0.8202, 
noisyNet noise sample is [array([0.72075975], dtype=float32), -0.30963317]. 
=============================================
[2019-03-23 14:32:11,474] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.6607559e-11 1.4618860e-13 1.0716016e-12 9.4132644e-13], sum to 1.0000
[2019-03-23 14:32:11,480] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1794
[2019-03-23 14:32:11,486] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [11.35, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 171266.5400878269, 171266.5400878272, 57496.85219055242], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5704200.0000, 
sim time next is 5704800.0000, 
raw observation next is [11.26666666666667, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 168896.8485160496, 168896.8485160496, 57075.01633280031], 
processed observation next is [0.0, 0.0, 0.1484848484848486, 0.77, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.06255438833927762, 0.06255438833927762, 0.13920735690926905], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0658017], dtype=float32), 1.2614654]. 
=============================================
[2019-03-23 14:32:13,675] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.8293086e-02 9.7159922e-01 9.5886836e-09 1.2685221e-06 1.0649782e-04], sum to 1.0000
[2019-03-23 14:32:13,687] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0433
[2019-03-23 14:32:13,693] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.05, 45.0, 1.0, 2.0, 0.2549630502631106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 276838.2922017153, 276838.2922017156, 82740.87824057709], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5751000.0000, 
sim time next is 5751600.0000, 
raw observation next is [21.23333333333333, 45.33333333333333, 1.0, 2.0, 0.2570818369793472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 279139.5261397271, 279139.5261397274, 84061.550945801], 
processed observation next is [0.0, 0.5652173913043478, 0.6015151515151514, 0.4533333333333333, 1.0, 1.0, 0.07135229622418401, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10338500968138041, 0.10338500968138051, 0.20502817303853904], 
reward next is 0.7950, 
noisyNet noise sample is [array([-0.38103226], dtype=float32), -0.9786081]. 
=============================================
[2019-03-23 14:32:13,854] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.7185923e-04 9.9972528e-01 6.1721045e-11 1.3870340e-07 2.6865455e-06], sum to 1.0000
[2019-03-23 14:32:13,861] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8942
[2019-03-23 14:32:13,871] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 70.0, 1.0, 2.0, 0.208152044335668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 225999.2011813978, 225999.2011813975, 72737.82448186837], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5774400.0000, 
sim time next is 5775000.0000, 
raw observation next is [15.86666666666667, 67.66666666666667, 1.0, 2.0, 0.2052730537898988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 222872.6470730592, 222872.6470730595, 72538.28840508316], 
processed observation next is [0.0, 0.8695652173913043, 0.35757575757575777, 0.6766666666666667, 1.0, 1.0, 0.006591317237373481, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08254542484187377, 0.08254542484187388, 0.1769226546465443], 
reward next is 0.8231, 
noisyNet noise sample is [array([1.6088272], dtype=float32), -1.8675643]. 
=============================================
[2019-03-23 14:32:13,896] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[35.8836  ]
 [35.19311 ]
 [35.00184 ]
 [33.274025]
 [33.388023]], R is [[36.01538849]
 [36.47782516]
 [36.93084335]
 [37.37426758]
 [37.79415131]].
[2019-03-23 14:32:15,385] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.8925251e-08 1.0000000e+00 2.0660889e-17 1.1763272e-12 2.0428601e-09], sum to 1.0000
[2019-03-23 14:32:15,393] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2306
[2019-03-23 14:32:15,398] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 56.0, 1.0, 2.0, 0.2213050631044537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 240283.499876091, 240283.4998760913, 74570.09858279159], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5778000.0000, 
sim time next is 5778600.0000, 
raw observation next is [17.51666666666667, 57.0, 1.0, 2.0, 0.2215473343042552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 240546.6125498313, 240546.6125498313, 74545.06141748077], 
processed observation next is [0.0, 0.9130434782608695, 0.43257575757575767, 0.57, 1.0, 1.0, 0.026934167880318972, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08909133798141901, 0.08909133798141901, 0.1818172229694653], 
reward next is 0.8182, 
noisyNet noise sample is [array([1.2747824], dtype=float32), 1.0692209]. 
=============================================
[2019-03-23 14:32:16,218] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.2531572e-11 1.0000000e+00 4.7413046e-23 6.5097807e-16 3.9723558e-13], sum to 1.0000
[2019-03-23 14:32:16,224] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4974
[2019-03-23 14:32:16,228] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.6, 86.0, 1.0, 2.0, 0.3843669964197777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 417405.1014805901, 417405.1014805898, 86249.13341938303], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5808000.0000, 
sim time next is 5808600.0000, 
raw observation next is [11.6, 86.0, 1.0, 2.0, 0.3835354935600098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416501.7403817616, 416501.7403817616, 86152.28665494948], 
processed observation next is [1.0, 0.21739130434782608, 0.1636363636363636, 0.86, 1.0, 1.0, 0.22941936695001225, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1542599038450969, 0.1542599038450969, 0.21012752842670604], 
reward next is 0.7899, 
noisyNet noise sample is [array([1.5261202], dtype=float32), 0.3324111]. 
=============================================
[2019-03-23 14:32:17,361] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76000, global step 1215182: loss 0.6446
[2019-03-23 14:32:17,362] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76000, global step 1215182: learning rate 0.0000
[2019-03-23 14:32:18,022] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.5971593e-09 1.0000000e+00 1.4684137e-21 4.6150387e-14 2.3304922e-10], sum to 1.0000
[2019-03-23 14:32:18,034] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2700
[2019-03-23 14:32:18,037] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 50.33333333333334, 1.0, 2.0, 0.393207877060344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 437742.9023046792, 437742.9023046794, 121760.6737569876], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5835000.0000, 
sim time next is 5835600.0000, 
raw observation next is [24.4, 50.0, 1.0, 2.0, 0.387988213169624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 431566.1417091941, 431566.1417091941, 121170.7185631389], 
processed observation next is [1.0, 0.5652173913043478, 0.7454545454545454, 0.5, 1.0, 1.0, 0.23498526646203, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15983931174414598, 0.15983931174414598, 0.29553833795887535], 
reward next is 0.7045, 
noisyNet noise sample is [array([1.1577717], dtype=float32), -1.3681445]. 
=============================================
[2019-03-23 14:32:18,096] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76000, global step 1215573: loss 0.0170
[2019-03-23 14:32:18,097] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76000, global step 1215573: learning rate 0.0000
[2019-03-23 14:32:18,189] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76000, global step 1215616: loss 0.0677
[2019-03-23 14:32:18,190] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76000, global step 1215616: learning rate 0.0000
[2019-03-23 14:32:18,261] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76000, global step 1215659: loss 0.0855
[2019-03-23 14:32:18,266] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76000, global step 1215662: learning rate 0.0000
[2019-03-23 14:32:18,384] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76000, global step 1215723: loss 0.0128
[2019-03-23 14:32:18,389] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76000, global step 1215723: learning rate 0.0000
[2019-03-23 14:32:18,576] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76000, global step 1215828: loss 0.1414
[2019-03-23 14:32:18,578] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76000, global step 1215828: learning rate 0.0000
[2019-03-23 14:32:18,602] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76000, global step 1215841: loss 0.2022
[2019-03-23 14:32:18,604] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76000, global step 1215842: learning rate 0.0000
[2019-03-23 14:32:19,045] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76000, global step 1216078: loss 0.0014
[2019-03-23 14:32:19,045] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76000, global step 1216078: loss 0.0021
[2019-03-23 14:32:19,047] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76000, global step 1216078: learning rate 0.0000
[2019-03-23 14:32:19,047] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76000, global step 1216078: learning rate 0.0000
[2019-03-23 14:32:19,052] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76000, global step 1216080: loss 0.0018
[2019-03-23 14:32:19,056] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76000, global step 1216080: loss 0.0021
[2019-03-23 14:32:19,058] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76000, global step 1216080: learning rate 0.0000
[2019-03-23 14:32:19,059] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76000, global step 1216080: learning rate 0.0000
[2019-03-23 14:32:19,195] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76000, global step 1216157: loss 0.0047
[2019-03-23 14:32:19,199] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76000, global step 1216157: learning rate 0.0000
[2019-03-23 14:32:19,231] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76000, global step 1216173: loss 0.0095
[2019-03-23 14:32:19,235] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76000, global step 1216173: learning rate 0.0000
[2019-03-23 14:32:19,547] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76000, global step 1216341: loss 0.0017
[2019-03-23 14:32:19,548] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76000, global step 1216341: learning rate 0.0000
[2019-03-23 14:32:19,758] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76000, global step 1216452: loss 0.0331
[2019-03-23 14:32:19,760] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76000, global step 1216452: learning rate 0.0000
[2019-03-23 14:32:20,544] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.5420589e-10 1.0000000e+00 1.1294380e-21 1.7294004e-16 2.6579620e-12], sum to 1.0000
[2019-03-23 14:32:20,554] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7558
[2019-03-23 14:32:20,558] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.36666666666667, 83.0, 1.0, 2.0, 0.2859104537405453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 310451.6366956673, 310451.6366956671, 104089.6812381449], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5884800.0000, 
sim time next is 5885400.0000, 
raw observation next is [17.28333333333333, 83.5, 1.0, 2.0, 0.284989204434354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 309450.9935036004, 309450.9935036007, 103542.9294524099], 
processed observation next is [1.0, 0.08695652173913043, 0.4219696969696969, 0.835, 1.0, 1.0, 0.10623650554294248, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11461147907540756, 0.11461147907540767, 0.25254373037173145], 
reward next is 0.7475, 
noisyNet noise sample is [array([0.9994929], dtype=float32), 0.0009605043]. 
=============================================
[2019-03-23 14:32:20,646] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76000, global step 1216925: loss 0.0269
[2019-03-23 14:32:20,649] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76000, global step 1216926: learning rate 0.0000
[2019-03-23 14:32:21,549] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.6023763e-10 1.0000000e+00 1.6335062e-18 1.4990040e-14 6.9039602e-10], sum to 1.0000
[2019-03-23 14:32:21,555] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1542
[2019-03-23 14:32:21,560] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 60.0, 1.0, 2.0, 0.7532517813207026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 856938.5945414561, 856938.5945414561, 170012.5845312773], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5914800.0000, 
sim time next is 5915400.0000, 
raw observation next is [25.26666666666667, 58.83333333333333, 1.0, 2.0, 0.9082307701043172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1033923.92094801, 1033923.92094801, 194592.5029776561], 
processed observation next is [1.0, 0.4782608695652174, 0.784848484848485, 0.5883333333333333, 1.0, 1.0, 0.8852884626303964, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3829347855363, 0.3829347855363, 0.47461586092111246], 
reward next is 0.5254, 
noisyNet noise sample is [array([0.07925826], dtype=float32), -0.8555003]. 
=============================================
[2019-03-23 14:32:26,257] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2005354e-08 1.0000000e+00 4.2853858e-17 1.9134360e-12 1.4428754e-08], sum to 1.0000
[2019-03-23 14:32:26,269] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6529
[2019-03-23 14:32:26,277] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.23333333333333, 62.66666666666667, 1.0, 2.0, 0.8018914808409484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 911003.1716171622, 911003.1716171622, 176122.0959533345], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5998800.0000, 
sim time next is 5999400.0000, 
raw observation next is [24.7, 61.0, 1.0, 2.0, 0.840471720331793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 955803.2024265308, 955803.2024265308, 182764.583365479], 
processed observation next is [1.0, 0.43478260869565216, 0.759090909090909, 0.61, 1.0, 1.0, 0.8005896504147411, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3540011860839003, 0.3540011860839003, 0.44576727650116826], 
reward next is 0.5542, 
noisyNet noise sample is [array([-1.0212518], dtype=float32), -0.23543935]. 
=============================================
[2019-03-23 14:32:27,430] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.8618264e-08 9.9999988e-01 3.9710993e-16 9.8771833e-12 4.3374587e-08], sum to 1.0000
[2019-03-23 14:32:27,436] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9613
[2019-03-23 14:32:27,447] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1138162.720214273 W.
[2019-03-23 14:32:27,449] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.7, 66.0, 1.0, 2.0, 0.3335590793864077, 1.0, 1.0, 0.3335590793864077, 1.0, 2.0, 0.6756644745657917, 6.9112, 6.9112, 77.3421103, 1138162.720214273, 1138162.720214273, 271888.2149166115], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6014400.0000, 
sim time next is 6015000.0000, 
raw observation next is [25.6, 67.5, 1.0, 2.0, 0.5100367697538879, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9544131017934933, 6.944218107054358, 6.9112, 77.32838214020371, 1129511.804891845, 1118788.210332493, 258803.9135147023], 
processed observation next is [1.0, 0.6086956521739131, 0.8, 0.675, 1.0, 1.0, 0.3875459621923598, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9348758597049905, 0.0033018107054357594, 0.0, 0.5084282783573453, 0.41833770551549815, 0.4143660038268493, 0.6312290573529324], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.23238565], dtype=float32), 0.053750988]. 
=============================================
[2019-03-23 14:32:27,464] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[52.936905]
 [53.409447]
 [53.262398]
 [53.177467]
 [52.441277]], R is [[52.78159714]
 [52.59063721]
 [52.41327667]
 [51.8891449 ]
 [51.79661942]].
[2019-03-23 14:32:28,619] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1709495e-13 1.0000000e+00 1.1756734e-25 6.6178616e-19 4.2870074e-12], sum to 1.0000
[2019-03-23 14:32:28,625] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1668
[2019-03-23 14:32:28,629] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.61666666666667, 75.83333333333333, 1.0, 2.0, 0.2737113376264473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 297201.3594138383, 297201.3594138381, 93717.57579263662], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6045000.0000, 
sim time next is 6045600.0000, 
raw observation next is [17.53333333333333, 76.66666666666667, 1.0, 2.0, 0.2736446098231166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 297128.8828690052, 297128.8828690055, 93936.22680341495], 
processed observation next is [1.0, 1.0, 0.43333333333333324, 0.7666666666666667, 1.0, 1.0, 0.09205576227889575, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11004773439592785, 0.11004773439592797, 0.22911274830101205], 
reward next is 0.7709, 
noisyNet noise sample is [array([0.66527516], dtype=float32), 0.27030155]. 
=============================================
[2019-03-23 14:32:29,550] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.8785270e-09 1.0000000e+00 3.9327723e-19 2.7406392e-13 5.0045283e-09], sum to 1.0000
[2019-03-23 14:32:29,555] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4987
[2019-03-23 14:32:29,560] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.8, 81.0, 1.0, 2.0, 0.2064821975343058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 224185.7622897608, 224185.7622897608, 73868.72112555786], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6072000.0000, 
sim time next is 6072600.0000, 
raw observation next is [14.9, 80.5, 1.0, 2.0, 0.2157553415539415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 234256.4003493353, 234256.400349335, 74905.62671866638], 
processed observation next is [1.0, 0.2608695652173913, 0.31363636363636366, 0.805, 1.0, 1.0, 0.019694176942426853, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08676162975901308, 0.08676162975901296, 0.18269665053333262], 
reward next is 0.8173, 
noisyNet noise sample is [array([-1.2184678], dtype=float32), -0.9853205]. 
=============================================
[2019-03-23 14:32:32,777] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76500, global step 1223344: loss 0.0615
[2019-03-23 14:32:32,782] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76500, global step 1223347: learning rate 0.0000
[2019-03-23 14:32:33,000] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76500, global step 1223468: loss 0.0059
[2019-03-23 14:32:33,001] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76500, global step 1223468: learning rate 0.0000
[2019-03-23 14:32:33,274] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76500, global step 1223614: loss 0.1003
[2019-03-23 14:32:33,276] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76500, global step 1223614: learning rate 0.0000
[2019-03-23 14:32:33,314] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76500, global step 1223634: loss 0.0672
[2019-03-23 14:32:33,317] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76500, global step 1223636: learning rate 0.0000
[2019-03-23 14:32:33,461] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76500, global step 1223717: loss 0.0554
[2019-03-23 14:32:33,463] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76500, global step 1223717: learning rate 0.0000
[2019-03-23 14:32:33,674] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76500, global step 1223827: loss 0.0041
[2019-03-23 14:32:33,676] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76500, global step 1223827: learning rate 0.0000
[2019-03-23 14:32:33,847] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76500, global step 1223914: loss 0.0837
[2019-03-23 14:32:33,851] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76500, global step 1223916: learning rate 0.0000
[2019-03-23 14:32:34,106] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76500, global step 1224056: loss 0.0008
[2019-03-23 14:32:34,109] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76500, global step 1224058: learning rate 0.0000
[2019-03-23 14:32:34,130] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76500, global step 1224065: loss 0.0011
[2019-03-23 14:32:34,131] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76500, global step 1224065: learning rate 0.0000
[2019-03-23 14:32:34,236] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76500, global step 1224130: loss 0.0051
[2019-03-23 14:32:34,237] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76500, global step 1224130: learning rate 0.0000
[2019-03-23 14:32:34,243] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76500, global step 1224131: loss 0.0085
[2019-03-23 14:32:34,245] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76500, global step 1224131: learning rate 0.0000
[2019-03-23 14:32:34,276] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76500, global step 1224145: loss 0.0112
[2019-03-23 14:32:34,277] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76500, global step 1224145: learning rate 0.0000
[2019-03-23 14:32:34,348] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76500, global step 1224185: loss 0.0093
[2019-03-23 14:32:34,350] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76500, global step 1224185: learning rate 0.0000
[2019-03-23 14:32:34,547] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76500, global step 1224292: loss 0.0097
[2019-03-23 14:32:34,552] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76500, global step 1224293: learning rate 0.0000
[2019-03-23 14:32:34,696] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76500, global step 1224372: loss 0.0481
[2019-03-23 14:32:34,698] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76500, global step 1224372: learning rate 0.0000
[2019-03-23 14:32:34,891] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.07482165e-08 1.00000000e+00 1.75672069e-17 3.68580427e-12
 4.83374869e-08], sum to 1.0000
[2019-03-23 14:32:34,900] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3416
[2019-03-23 14:32:34,906] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 66.0, 1.0, 2.0, 0.587630879465166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 650224.9175589904, 650224.9175589908, 139081.1695278409], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6170400.0000, 
sim time next is 6171000.0000, 
raw observation next is [20.91666666666667, 68.5, 1.0, 2.0, 0.6169183629623812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 684230.9146542558, 684230.9146542562, 142826.8690935177], 
processed observation next is [1.0, 0.43478260869565216, 0.5871212121212124, 0.685, 1.0, 1.0, 0.5211479537029765, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.25341885727935404, 0.25341885727935415, 0.34835821730126265], 
reward next is 0.6516, 
noisyNet noise sample is [array([0.9095914], dtype=float32), -0.7229286]. 
=============================================
[2019-03-23 14:32:34,924] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[60.2774  ]
 [60.22492 ]
 [60.114746]
 [59.940876]
 [59.84472 ]], R is [[60.28054047]
 [60.33851242]
 [60.39873505]
 [60.45760345]
 [60.5118866 ]].
[2019-03-23 14:32:35,767] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76500, global step 1224937: loss 0.0041
[2019-03-23 14:32:35,769] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76500, global step 1224937: learning rate 0.0000
[2019-03-23 14:32:35,895] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 14:32:35,896] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:32:35,897] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:32:35,898] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:32:35,899] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:32:35,900] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:32:35,900] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:32:35,901] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:32:35,905] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:32:35,907] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:32:35,901] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:32:35,919] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run50
[2019-03-23 14:32:35,947] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run50
[2019-03-23 14:32:35,977] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run50
[2019-03-23 14:32:35,978] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run50
[2019-03-23 14:32:36,004] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run50
[2019-03-23 14:33:20,207] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06152939], dtype=float32), 0.22763368]
[2019-03-23 14:33:20,209] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.73333333333333, 89.33333333333333, 1.0, 2.0, 0.4382572595554526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 498387.1398027299, 498387.1398027299, 135676.9455227544]
[2019-03-23 14:33:20,210] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:33:20,211] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.3619750e-10 1.0000000e+00 8.6255783e-22 5.8025912e-15 1.9845933e-10], sampled 0.8408462489955367
[2019-03-23 14:33:40,281] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06152939], dtype=float32), 0.22763368]
[2019-03-23 14:33:40,283] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.85, 43.0, 1.0, 2.0, 0.3116947587165272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 338436.4236635925, 338436.4236635922, 114616.4198253379]
[2019-03-23 14:33:40,285] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:33:40,289] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.1396530e-10 1.0000000e+00 4.9793236e-21 1.8621528e-14 4.4098791e-10], sampled 0.08001784293776637
[2019-03-23 14:33:58,834] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06152939], dtype=float32), 0.22763368]
[2019-03-23 14:33:58,837] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.38333333333333, 69.0, 1.0, 2.0, 0.6584416029605322, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 751030.8603477146, 751030.8603477143, 163827.5729800242]
[2019-03-23 14:33:58,838] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:33:58,841] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.5893871e-10 1.0000000e+00 6.6102353e-21 2.3123691e-14 5.0997767e-10], sampled 0.03962221581305814
[2019-03-23 14:34:00,443] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06152939], dtype=float32), 0.22763368]
[2019-03-23 14:34:00,445] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.779246645, 53.364344855, 1.0, 2.0, 0.3089842345969606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 335492.5302774149, 335492.5302774145, 100475.977680546]
[2019-03-23 14:34:00,446] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:34:00,449] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.4686634e-10 1.0000000e+00 6.1541818e-21 2.1807344e-14 4.9047538e-10], sampled 0.7738731996970599
[2019-03-23 14:34:17,159] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06152939], dtype=float32), 0.22763368]
[2019-03-23 14:34:17,162] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.51969976, 73.64260074, 1.0, 2.0, 0.2171236002645593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 235731.4522066091, 235731.4522066091, 76985.8224334816]
[2019-03-23 14:34:17,162] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:34:17,167] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.7869425e-10 1.0000000e+00 1.2103756e-20 3.4332837e-14 6.6813832e-10], sampled 0.5280245587365942
[2019-03-23 14:34:18,792] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 14:34:18,907] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2494 1773207034.4548 173.0000
[2019-03-23 14:34:19,159] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 14:34:19,266] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 14:34:19,272] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:34:20,286] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1225000, evaluation results [1225000.0, 8512.249429056992, 1773207034.4547563, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 14:34:21,494] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.7721987e-09 1.0000000e+00 2.7515910e-17 2.8640800e-13 8.2053359e-10], sum to 1.0000
[2019-03-23 14:34:21,499] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0859
[2019-03-23 14:34:21,502] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 93.0, 1.0, 2.0, 0.3759028775952223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 422101.6093847186, 422101.6093847186, 121947.1724742738], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6229800.0000, 
sim time next is 6230400.0000, 
raw observation next is [18.8, 93.0, 1.0, 2.0, 0.375844437029173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 422036.1373270213, 422036.137327021, 121942.2514246581], 
processed observation next is [0.0, 0.08695652173913043, 0.49090909090909096, 0.93, 1.0, 1.0, 0.2198055462864662, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15630968049148936, 0.15630968049148924, 0.2974201254259954], 
reward next is 0.7026, 
noisyNet noise sample is [array([0.26566315], dtype=float32), -0.5078084]. 
=============================================
[2019-03-23 14:34:22,890] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.9688635e-10 1.0000000e+00 1.8545290e-21 1.3512521e-14 4.8483279e-12], sum to 1.0000
[2019-03-23 14:34:22,900] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1572
[2019-03-23 14:34:22,909] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 77.66666666666667, 1.0, 2.0, 0.4904776346311364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 559200.750838258, 559200.750838258, 141203.4317425451], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6261600.0000, 
sim time next is 6262200.0000, 
raw observation next is [24.95, 75.5, 1.0, 2.0, 0.5001059701652204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 569810.649629426, 569810.649629426, 142746.6312446623], 
processed observation next is [0.0, 0.4782608695652174, 0.7704545454545454, 0.755, 1.0, 1.0, 0.37513246270652545, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21104098134423183, 0.21104098134423183, 0.34816251523088365], 
reward next is 0.6518, 
noisyNet noise sample is [array([-2.0480182], dtype=float32), 0.04144738]. 
=============================================
[2019-03-23 14:34:23,998] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.8630580e-11 1.0000000e+00 1.0051485e-21 3.7023900e-16 1.5664258e-09], sum to 1.0000
[2019-03-23 14:34:24,004] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2729
[2019-03-23 14:34:24,008] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.45, 84.5, 1.0, 2.0, 0.4543481884157023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 518355.7276977163, 518355.7276977166, 135256.2794077026], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6258600.0000, 
sim time next is 6259200.0000, 
raw observation next is [22.73333333333333, 83.66666666666667, 1.0, 2.0, 0.4603383683132869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 525262.3152954999, 525262.3152954999, 136255.164981471], 
processed observation next is [0.0, 0.43478260869565216, 0.6696969696969696, 0.8366666666666667, 1.0, 1.0, 0.32542296039160856, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19454159825759254, 0.19454159825759254, 0.33232967068651464], 
reward next is 0.6677, 
noisyNet noise sample is [array([-1.687942], dtype=float32), -0.3211941]. 
=============================================
[2019-03-23 14:34:25,844] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.1118133e-07 9.9999952e-01 1.2364872e-18 5.8951411e-13 1.9900916e-07], sum to 1.0000
[2019-03-23 14:34:25,858] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0708
[2019-03-23 14:34:25,864] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.93333333333334, 60.0, 1.0, 2.0, 0.524742771256471, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 597000.015174264, 597000.015174264, 146397.7966700128], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6290400.0000, 
sim time next is 6291000.0000, 
raw observation next is [27.75, 60.5, 1.0, 2.0, 0.5225254247378239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 594693.2334189588, 594693.2334189588, 145980.5615362865], 
processed observation next is [0.0, 0.8260869565217391, 0.8977272727272727, 0.605, 1.0, 1.0, 0.40315678092227986, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2202567531181329, 0.2202567531181329, 0.35605015008850366], 
reward next is 0.6439, 
noisyNet noise sample is [array([-0.5974004], dtype=float32), 0.2539792]. 
=============================================
[2019-03-23 14:34:25,879] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[72.65636 ]
 [72.641464]
 [72.634094]
 [72.59182 ]
 [72.584625]], R is [[72.58599091]
 [72.50305939]
 [72.42015839]
 [72.33760071]
 [72.25606537]].
[2019-03-23 14:34:26,809] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3326044e-07 9.9999988e-01 1.5543804e-17 2.2731760e-12 2.9922941e-08], sum to 1.0000
[2019-03-23 14:34:26,818] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0136
[2019-03-23 14:34:26,823] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 76.0, 1.0, 2.0, 0.4941707069433646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 563648.1612180007, 563648.1612180007, 141264.3354765124], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6310800.0000, 
sim time next is 6311400.0000, 
raw observation next is [24.21666666666667, 77.0, 1.0, 2.0, 0.4942403274583709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 563745.7384933794, 563745.7384933794, 141237.1387376797], 
processed observation next is [0.0, 0.043478260869565216, 0.7371212121212122, 0.77, 1.0, 1.0, 0.36780040932296354, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2087947179605109, 0.2087947179605109, 0.3444808261894627], 
reward next is 0.6555, 
noisyNet noise sample is [array([-0.5250842], dtype=float32), 0.5325994]. 
=============================================
[2019-03-23 14:34:29,650] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.1932332e-09 1.0000000e+00 1.1429482e-20 4.3907655e-15 1.0740628e-09], sum to 1.0000
[2019-03-23 14:34:29,656] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5754
[2019-03-23 14:34:29,661] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.53333333333333, 87.0, 1.0, 2.0, 0.4778411014963833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 545231.0239863064, 545231.0239863064, 138750.6113231829], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6331200.0000, 
sim time next is 6331800.0000, 
raw observation next is [22.61666666666667, 87.0, 1.0, 2.0, 0.4811809142075557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 549007.9117737338, 549007.9117737336, 139297.340425392], 
processed observation next is [0.0, 0.2608695652173913, 0.6643939393939395, 0.87, 1.0, 1.0, 0.3514761427594446, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2033362636199014, 0.20333626361990131, 0.339749610793639], 
reward next is 0.6603, 
noisyNet noise sample is [array([-0.4127925], dtype=float32), -0.6436805]. 
=============================================
[2019-03-23 14:34:29,904] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.83086684e-08 1.00000000e+00 2.87808197e-17 1.12962036e-11
 1.37253542e-08], sum to 1.0000
[2019-03-23 14:34:29,914] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3612
[2019-03-23 14:34:29,921] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.9, 63.66666666666667, 1.0, 2.0, 0.5576156484359851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 632155.0294285876, 632155.029428588, 151628.2963255544], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6362400.0000, 
sim time next is 6363000.0000, 
raw observation next is [28.0, 63.0, 1.0, 2.0, 0.5566576726741328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 631169.8408765283, 631169.8408765281, 151464.6630192412], 
processed observation next is [0.0, 0.6521739130434783, 0.9090909090909091, 0.63, 1.0, 1.0, 0.44582209084266594, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23376660773204752, 0.23376660773204744, 0.36942600736400294], 
reward next is 0.6306, 
noisyNet noise sample is [array([-0.07208658], dtype=float32), 1.5242251]. 
=============================================
[2019-03-23 14:34:29,938] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[57.157627]
 [57.159744]
 [57.159206]
 [57.138412]
 [57.12907 ]], R is [[57.21681595]
 [57.27482605]
 [57.33208084]
 [57.38862991]
 [57.44462967]].
[2019-03-23 14:34:30,747] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.7328346e-10 1.0000000e+00 1.5826069e-20 1.4065366e-13 2.2952785e-08], sum to 1.0000
[2019-03-23 14:34:30,755] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2097
[2019-03-23 14:34:30,762] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 74.33333333333334, 1.0, 2.0, 0.5791555697904275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 660835.6190273796, 660835.6190273796, 151201.9765666981], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6403800.0000, 
sim time next is 6404400.0000, 
raw observation next is [24.4, 74.0, 1.0, 2.0, 0.5639433554686417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 643502.7400136221, 643502.7400136221, 149147.544752039], 
processed observation next is [1.0, 0.13043478260869565, 0.7454545454545454, 0.74, 1.0, 1.0, 0.4549291943358021, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23833434815319338, 0.23833434815319338, 0.36377449939521705], 
reward next is 0.6362, 
noisyNet noise sample is [array([-0.5220443], dtype=float32), -0.096882746]. 
=============================================
[2019-03-23 14:34:30,852] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.9286431e-10 1.0000000e+00 7.7977903e-23 6.4474345e-14 1.8004570e-09], sum to 1.0000
[2019-03-23 14:34:30,859] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8975
[2019-03-23 14:34:30,864] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 79.66666666666667, 1.0, 2.0, 0.5648490620174811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 639867.6081783714, 639867.6081783717, 152753.8134690016], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6380400.0000, 
sim time next is 6381000.0000, 
raw observation next is [25.25, 80.0, 1.0, 2.0, 0.5634859468535822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 638479.5795716877, 638479.5795716877, 152518.5975798556], 
processed observation next is [0.0, 0.8695652173913043, 0.7840909090909091, 0.8, 1.0, 1.0, 0.4543574335669777, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23647391835988435, 0.23647391835988435, 0.3719965794630624], 
reward next is 0.6280, 
noisyNet noise sample is [array([0.5197738], dtype=float32), -2.429882]. 
=============================================
[2019-03-23 14:34:30,887] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[69.75271 ]
 [69.74354 ]
 [69.72625 ]
 [69.681984]
 [69.662575]], R is [[69.68255615]
 [69.61315918]
 [69.54383087]
 [69.47454834]
 [69.40542603]].
[2019-03-23 14:34:30,930] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.9549873e-11 1.0000000e+00 7.0192434e-20 1.8220935e-13 5.6676486e-10], sum to 1.0000
[2019-03-23 14:34:30,941] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0164
[2019-03-23 14:34:30,947] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 76.0, 1.0, 2.0, 0.521651774787865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593958.2517192913, 593958.2517192913, 145684.0242553583], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6390000.0000, 
sim time next is 6390600.0000, 
raw observation next is [24.9, 76.5, 1.0, 2.0, 0.5208556920953176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593092.8776276096, 593092.8776276096, 145554.4468794944], 
processed observation next is [0.0, 1.0, 0.7681818181818181, 0.765, 1.0, 1.0, 0.4010696151191469, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21966402875096652, 0.21966402875096652, 0.35501084604754735], 
reward next is 0.6450, 
noisyNet noise sample is [array([-2.3421152], dtype=float32), 0.7162286]. 
=============================================
[2019-03-23 14:34:32,921] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77000, global step 1231302: loss 2.6194
[2019-03-23 14:34:32,928] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77000, global step 1231306: learning rate 0.0000
[2019-03-23 14:34:33,327] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77000, global step 1231500: loss 2.2686
[2019-03-23 14:34:33,331] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77000, global step 1231500: learning rate 0.0000
[2019-03-23 14:34:33,446] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77000, global step 1231561: loss 2.2459
[2019-03-23 14:34:33,449] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77000, global step 1231561: learning rate 0.0000
[2019-03-23 14:34:33,537] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77000, global step 1231607: loss 1.7153
[2019-03-23 14:34:33,541] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77000, global step 1231607: learning rate 0.0000
[2019-03-23 14:34:33,836] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77000, global step 1231755: loss 1.5910
[2019-03-23 14:34:33,844] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77000, global step 1231756: learning rate 0.0000
[2019-03-23 14:34:33,981] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77000, global step 1231828: loss 1.5358
[2019-03-23 14:34:33,984] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77000, global step 1231829: learning rate 0.0000
[2019-03-23 14:34:34,104] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77000, global step 1231891: loss 1.3264
[2019-03-23 14:34:34,106] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77000, global step 1231891: learning rate 0.0000
[2019-03-23 14:34:34,382] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77000, global step 1232034: loss 1.7973
[2019-03-23 14:34:34,384] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77000, global step 1232034: learning rate 0.0000
[2019-03-23 14:34:34,504] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77000, global step 1232091: loss 1.9498
[2019-03-23 14:34:34,506] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77000, global step 1232094: learning rate 0.0000
[2019-03-23 14:34:34,539] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77000, global step 1232113: loss 1.6800
[2019-03-23 14:34:34,542] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77000, global step 1232113: learning rate 0.0000
[2019-03-23 14:34:34,567] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77000, global step 1232125: loss 1.5771
[2019-03-23 14:34:34,569] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77000, global step 1232126: learning rate 0.0000
[2019-03-23 14:34:34,625] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77000, global step 1232154: loss 1.3961
[2019-03-23 14:34:34,627] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77000, global step 1232154: learning rate 0.0000
[2019-03-23 14:34:34,731] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77000, global step 1232209: loss 1.2156
[2019-03-23 14:34:34,735] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77000, global step 1232209: learning rate 0.0000
[2019-03-23 14:34:34,841] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77000, global step 1232266: loss 1.1935
[2019-03-23 14:34:34,844] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77000, global step 1232266: learning rate 0.0000
[2019-03-23 14:34:35,163] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77000, global step 1232431: loss 1.2470
[2019-03-23 14:34:35,166] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77000, global step 1232433: learning rate 0.0000
[2019-03-23 14:34:36,204] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77000, global step 1232959: loss 2.2252
[2019-03-23 14:34:36,206] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77000, global step 1232959: learning rate 0.0000
[2019-03-23 14:34:40,050] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.54905366e-09 1.00000000e+00 1.04042855e-19 2.73442429e-14
 7.46611439e-10], sum to 1.0000
[2019-03-23 14:34:40,060] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2385
[2019-03-23 14:34:40,066] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.68333333333333, 80.33333333333334, 1.0, 2.0, 0.2093325592126231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 227281.2340004096, 227281.2340004093, 73715.63655692604], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6569400.0000, 
sim time next is 6570000.0000, 
raw observation next is [14.4, 83.0, 1.0, 2.0, 0.2064366741724614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 224136.324415165, 224136.3244151653, 73446.78689758519], 
processed observation next is [1.0, 0.043478260869565216, 0.29090909090909095, 0.83, 1.0, 1.0, 0.008045842715576727, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08301345348709815, 0.08301345348709825, 0.17913850462825656], 
reward next is 0.8209, 
noisyNet noise sample is [array([-0.09580506], dtype=float32), -0.2976616]. 
=============================================
[2019-03-23 14:34:40,083] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[66.896255]
 [67.36873 ]
 [67.629135]
 [68.11127 ]
 [68.46319 ]], R is [[66.65699005]
 [66.81062317]
 [66.96207428]
 [67.11134338]
 [67.2585144 ]].
[2019-03-23 14:34:44,010] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.3476712e-10 1.0000000e+00 1.5969310e-20 1.1905491e-13 7.2773487e-10], sum to 1.0000
[2019-03-23 14:34:44,016] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2759
[2019-03-23 14:34:44,019] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 66.0, 1.0, 2.0, 0.7894240661689729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 886903.5721799568, 886903.5721799568, 168515.6236227381], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6626400.0000, 
sim time next is 6627000.0000, 
raw observation next is [22.2, 66.0, 1.0, 2.0, 0.7911640616890385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 888896.4737163142, 888896.4737163142, 168775.6684374223], 
processed observation next is [1.0, 0.6956521739130435, 0.6454545454545454, 0.66, 1.0, 1.0, 0.7389550771112982, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.32922091619122745, 0.32922091619122745, 0.41164797179859103], 
reward next is 0.5884, 
noisyNet noise sample is [array([-0.7381389], dtype=float32), -1.1549814]. 
=============================================
[2019-03-23 14:34:44,037] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[65.10359 ]
 [65.09539 ]
 [65.031006]
 [64.866776]
 [64.948524]], R is [[65.08152008]
 [65.01969147]
 [64.96393585]
 [64.9115448 ]
 [64.84199524]].
[2019-03-23 14:34:45,147] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3744988e-10 1.0000000e+00 1.5329943e-23 8.8471863e-15 2.0302000e-10], sum to 1.0000
[2019-03-23 14:34:45,159] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0385
[2019-03-23 14:34:45,162] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.28333333333333, 65.66666666666666, 1.0, 2.0, 0.7139547427094691, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 802064.6027122927, 802064.6027122929, 158369.6037470848], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6623400.0000, 
sim time next is 6624000.0000, 
raw observation next is [22.2, 66.0, 1.0, 2.0, 0.7516956391851674, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 844326.2764864819, 844326.2764864822, 163274.5872113481], 
processed observation next is [1.0, 0.6956521739130435, 0.6454545454545454, 0.66, 1.0, 1.0, 0.689619548981459, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.312713435735734, 0.3127134357357342, 0.39823070051548315], 
reward next is 0.6018, 
noisyNet noise sample is [array([0.4189276], dtype=float32), 0.9200991]. 
=============================================
[2019-03-23 14:34:45,190] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[71.6506  ]
 [71.562294]
 [71.5194  ]
 [71.442406]
 [71.289505]], R is [[71.54862213]
 [71.4468689 ]
 [71.34380341]
 [71.2406311 ]
 [71.13794708]].
[2019-03-23 14:34:48,481] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77500, global step 1239207: loss 0.0839
[2019-03-23 14:34:48,484] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77500, global step 1239209: learning rate 0.0000
[2019-03-23 14:34:49,067] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77500, global step 1239523: loss 0.0879
[2019-03-23 14:34:49,068] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77500, global step 1239523: learning rate 0.0000
[2019-03-23 14:34:49,105] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77500, global step 1239541: loss 0.0659
[2019-03-23 14:34:49,110] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77500, global step 1239542: learning rate 0.0000
[2019-03-23 14:34:49,209] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77500, global step 1239598: loss 0.0333
[2019-03-23 14:34:49,214] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77500, global step 1239599: learning rate 0.0000
[2019-03-23 14:34:49,641] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77500, global step 1239824: loss 0.1258
[2019-03-23 14:34:49,646] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77500, global step 1239824: learning rate 0.0000
[2019-03-23 14:34:49,688] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77500, global step 1239847: loss 0.0727
[2019-03-23 14:34:49,691] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77500, global step 1239847: learning rate 0.0000
[2019-03-23 14:34:49,764] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77500, global step 1239890: loss 0.0183
[2019-03-23 14:34:49,767] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77500, global step 1239891: learning rate 0.0000
[2019-03-23 14:34:49,769] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77500, global step 1239892: loss 0.0235
[2019-03-23 14:34:49,770] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77500, global step 1239892: learning rate 0.0000
[2019-03-23 14:34:50,144] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77500, global step 1240087: loss 0.0503
[2019-03-23 14:34:50,146] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77500, global step 1240088: learning rate 0.0000
[2019-03-23 14:34:50,182] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77500, global step 1240105: loss 0.0448
[2019-03-23 14:34:50,186] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77500, global step 1240105: learning rate 0.0000
[2019-03-23 14:34:50,238] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77500, global step 1240137: loss 0.0162
[2019-03-23 14:34:50,240] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77500, global step 1240137: learning rate 0.0000
[2019-03-23 14:34:50,279] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77500, global step 1240159: loss 0.0108
[2019-03-23 14:34:50,281] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77500, global step 1240161: learning rate 0.0000
[2019-03-23 14:34:50,426] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77500, global step 1240240: loss 0.0090
[2019-03-23 14:34:50,434] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77500, global step 1240241: learning rate 0.0000
[2019-03-23 14:34:50,572] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77500, global step 1240317: loss 0.0228
[2019-03-23 14:34:50,575] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77500, global step 1240318: learning rate 0.0000
[2019-03-23 14:34:50,800] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77500, global step 1240436: loss 0.0680
[2019-03-23 14:34:50,804] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77500, global step 1240436: learning rate 0.0000
[2019-03-23 14:34:51,956] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77500, global step 1241045: loss 0.1067
[2019-03-23 14:34:51,957] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77500, global step 1241046: learning rate 0.0000
[2019-03-23 14:34:55,901] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.2771169e-12 1.0000000e+00 1.0553484e-23 9.1143425e-17 1.2714023e-14], sum to 1.0000
[2019-03-23 14:34:55,908] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3589
[2019-03-23 14:34:55,913] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 54.0, 1.0, 2.0, 0.4497993159976334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 512976.8877901407, 512976.887790141, 134279.9053980983], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6890400.0000, 
sim time next is 6891000.0000, 
raw observation next is [26.91666666666667, 55.33333333333333, 1.0, 2.0, 0.453162778938679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516826.6017550799, 516826.6017550799, 134660.3215789458], 
processed observation next is [0.0, 0.782608695652174, 0.8598484848484851, 0.5533333333333332, 1.0, 1.0, 0.31645347367334875, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19141725990928884, 0.19141725990928884, 0.3284398087291361], 
reward next is 0.6716, 
noisyNet noise sample is [array([-0.9713251], dtype=float32), 0.042577405]. 
=============================================
[2019-03-23 14:34:55,938] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[72.606415]
 [72.60689 ]
 [72.61905 ]
 [72.629745]
 [72.64929 ]], R is [[72.51998138]
 [72.4672699 ]
 [72.41624451]
 [72.36685944]
 [72.31903839]].
[2019-03-23 14:35:00,696] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.7574239e-10 1.0000000e+00 1.4367864e-20 8.0159074e-16 1.6576600e-12], sum to 1.0000
[2019-03-23 14:35:00,703] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7845
[2019-03-23 14:35:00,707] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 58.0, 1.0, 2.0, 0.4983928780534986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 568236.8903054247, 568236.8903054249, 142116.6073123562], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6958800.0000, 
sim time next is 6959400.0000, 
raw observation next is [27.8, 57.66666666666667, 1.0, 2.0, 0.4989875855143396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 568881.3639257028, 568881.3639257028, 142231.0131472865], 
processed observation next is [0.0, 0.5652173913043478, 0.9, 0.5766666666666667, 1.0, 1.0, 0.37373448189292446, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.210696801453964, 0.210696801453964, 0.3469049101153329], 
reward next is 0.6531, 
noisyNet noise sample is [array([-1.8177533], dtype=float32), 1.9939029]. 
=============================================
[2019-03-23 14:35:03,479] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78000, global step 1247164: loss -5.4521
[2019-03-23 14:35:03,483] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78000, global step 1247164: learning rate 0.0000
[2019-03-23 14:35:04,058] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78000, global step 1247468: loss -78.1991
[2019-03-23 14:35:04,060] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78000, global step 1247469: learning rate 0.0000
[2019-03-23 14:35:04,101] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78000, global step 1247491: loss -57.3418
[2019-03-23 14:35:04,103] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78000, global step 1247491: learning rate 0.0000
[2019-03-23 14:35:04,191] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78000, global step 1247536: loss -13.9083
[2019-03-23 14:35:04,196] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78000, global step 1247538: learning rate 0.0000
[2019-03-23 14:35:04,472] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78000, global step 1247684: loss -56.4749
[2019-03-23 14:35:04,473] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78000, global step 1247684: learning rate 0.0000
[2019-03-23 14:35:04,623] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78000, global step 1247761: loss -68.7473
[2019-03-23 14:35:04,625] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78000, global step 1247763: learning rate 0.0000
[2019-03-23 14:35:04,658] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78000, global step 1247780: loss -21.3017
[2019-03-23 14:35:04,660] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78000, global step 1247780: learning rate 0.0000
[2019-03-23 14:35:04,893] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78000, global step 1247908: loss -60.1279
[2019-03-23 14:35:04,894] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78000, global step 1247908: learning rate 0.0000
[2019-03-23 14:35:05,211] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.6749607e-11 1.0000000e+00 1.5128769e-22 3.4385346e-17 5.3638188e-11], sum to 1.0000
[2019-03-23 14:35:05,220] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8992
[2019-03-23 14:35:05,229] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.38333333333333, 93.0, 1.0, 2.0, 0.3673691406593022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 410522.8315937088, 410522.8315937088, 120285.2487049308], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7077000.0000, 
sim time next is 7077600.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.3651220861565875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 407554.5946939969, 407554.5946939969, 119897.2005422009], 
processed observation next is [1.0, 0.9565217391304348, 0.4681818181818182, 0.93, 1.0, 1.0, 0.20640260769573432, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15094614618296182, 0.15094614618296182, 0.29243219644439244], 
reward next is 0.7076, 
noisyNet noise sample is [array([0.20819034], dtype=float32), -0.97350305]. 
=============================================
[2019-03-23 14:35:05,254] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78000, global step 1248093: loss -5.6493
[2019-03-23 14:35:05,258] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78000, global step 1248095: learning rate 0.0000
[2019-03-23 14:35:05,372] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78000, global step 1248157: loss -19.8713
[2019-03-23 14:35:05,374] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78000, global step 1248157: learning rate 0.0000
[2019-03-23 14:35:05,468] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78000, global step 1248210: loss 7.4481
[2019-03-23 14:35:05,471] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78000, global step 1248211: learning rate 0.0000
[2019-03-23 14:35:05,595] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78000, global step 1248277: loss 41.1824
[2019-03-23 14:35:05,597] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78000, global step 1248277: learning rate 0.0000
[2019-03-23 14:35:05,627] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78000, global step 1248295: loss 6.8669
[2019-03-23 14:35:05,628] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78000, global step 1248296: learning rate 0.0000
[2019-03-23 14:35:05,761] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78000, global step 1248365: loss -78.1493
[2019-03-23 14:35:05,764] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78000, global step 1248368: learning rate 0.0000
[2019-03-23 14:35:06,002] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78000, global step 1248493: loss -2.5889
[2019-03-23 14:35:06,004] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78000, global step 1248494: learning rate 0.0000
[2019-03-23 14:35:06,792] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.9387393e-10 1.0000000e+00 1.3939896e-20 2.7111053e-15 4.6578957e-13], sum to 1.0000
[2019-03-23 14:35:06,803] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4273
[2019-03-23 14:35:06,807] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 90.5, 1.0, 2.0, 0.352137945299304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 391401.0757138183, 391401.0757138183, 118130.8909963871], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7080600.0000, 
sim time next is 7081200.0000, 
raw observation next is [18.3, 90.0, 1.0, 2.0, 0.3495772888626847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 388214.0501200749, 388214.0501200752, 117787.9330521604], 
processed observation next is [1.0, 1.0, 0.4681818181818182, 0.9, 1.0, 1.0, 0.18697161107835583, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14378298152595367, 0.14378298152595376, 0.28728764159063513], 
reward next is 0.7127, 
noisyNet noise sample is [array([0.7386537], dtype=float32), -0.7399005]. 
=============================================
[2019-03-23 14:35:07,294] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78000, global step 1249180: loss 7.1583
[2019-03-23 14:35:07,296] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78000, global step 1249181: learning rate 0.0000
[2019-03-23 14:35:08,830] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 14:35:08,835] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:35:08,836] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:35:08,838] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:35:08,839] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:35:08,839] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:35:08,840] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:35:08,840] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:35:08,843] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:35:08,842] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:35:08,844] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:35:08,862] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run51
[2019-03-23 14:35:08,892] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run51
[2019-03-23 14:35:08,918] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run51
[2019-03-23 14:35:08,918] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run51
[2019-03-23 14:35:08,974] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run51
[2019-03-23 14:35:11,645] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06152939], dtype=float32), 0.23268029]
[2019-03-23 14:35:11,646] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.33333333333333, 75.33333333333333, 1.0, 2.0, 0.2238209589298302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 243015.833551317, 243015.833551317, 75388.60300259451]
[2019-03-23 14:35:11,648] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:35:11,651] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0967687e-09 1.0000000e+00 1.9582072e-19 2.4076087e-14 1.0074363e-10], sampled 0.7898831625893431
[2019-03-23 14:35:13,970] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06152939], dtype=float32), 0.23268029]
[2019-03-23 14:35:13,971] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.5, 60.0, 1.0, 2.0, 0.3023002732548105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 328254.2860647654, 328254.2860647654, 84037.21170550282]
[2019-03-23 14:35:13,972] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:35:13,975] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.3946748e-10 1.0000000e+00 6.4671455e-20 1.0719112e-14 5.5481519e-11], sampled 0.31293793312191365
[2019-03-23 14:35:21,370] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06152939], dtype=float32), 0.23268029]
[2019-03-23 14:35:21,371] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.05727519333333, 94.81854027666668, 1.0, 2.0, 0.2279274910931607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 247463.6689547508, 247463.6689547508, 83159.51915722668]
[2019-03-23 14:35:21,372] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:35:21,375] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.51849796e-10 1.00000000e+00 6.73031046e-20 1.10387206e-14
 5.66909401e-11], sampled 0.7461594210491447
[2019-03-23 14:35:21,904] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06152939], dtype=float32), 0.23268029]
[2019-03-23 14:35:21,906] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.2, 84.33333333333333, 1.0, 2.0, 0.7163977995895461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 814557.0552243997, 814557.0552243993, 168829.2403397617]
[2019-03-23 14:35:21,907] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:35:21,909] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.9500531e-10 1.0000000e+00 3.8257856e-20 7.3071787e-15 4.1819621e-11], sampled 0.3995370249002774
[2019-03-23 14:35:40,973] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06152939], dtype=float32), 0.23268029]
[2019-03-23 14:35:40,974] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.79495976833334, 31.724356915, 1.0, 2.0, 0.3513324100209753, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 381488.4239167716, 381488.4239167716, 119084.8370004681]
[2019-03-23 14:35:40,974] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:35:40,976] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.1035015e-10 1.0000000e+00 6.6070082e-21 2.0266625e-15 1.6246999e-11], sampled 0.12734735338403635
[2019-03-23 14:35:59,315] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06152939], dtype=float32), 0.23268029]
[2019-03-23 14:35:59,316] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.41791767333333, 99.68937185333334, 1.0, 2.0, 0.5038134080663768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 553284.068914501, 553284.0689145006, 133472.6337140756]
[2019-03-23 14:35:59,316] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:35:59,319] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.5903979e-10 1.0000000e+00 1.0122600e-20 2.7672043e-15 2.0442847e-11], sampled 0.7441478118547796
[2019-03-23 14:36:09,673] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06152939], dtype=float32), 0.23268029]
[2019-03-23 14:36:09,674] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.667277745, 94.40109276999999, 1.0, 2.0, 0.4460634048735873, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 502465.3939365635, 502465.3939365631, 133366.8493644907]
[2019-03-23 14:36:09,676] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:36:09,679] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.1770986e-10 1.0000000e+00 1.5394195e-20 3.7582149e-15 2.5616535e-11], sampled 0.9440553712732924
[2019-03-23 14:36:15,112] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06152939], dtype=float32), 0.23268029]
[2019-03-23 14:36:15,115] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.88333333333334, 57.0, 1.0, 2.0, 0.350201608316827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 388264.2147757263, 388264.214775726, 121893.8609038714]
[2019-03-23 14:36:15,116] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:36:15,118] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.3043738e-10 1.0000000e+00 7.9632524e-21 2.3226584e-15 1.7965412e-11], sampled 0.9959602810950154
[2019-03-23 14:36:34,746] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06152939], dtype=float32), 0.23268029]
[2019-03-23 14:36:34,747] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.03333333333333, 45.66666666666667, 1.0, 2.0, 0.4146120845440423, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 468816.937132931, 468816.937132931, 131407.8715163632]
[2019-03-23 14:36:34,748] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:36:34,752] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.3085883e-10 1.0000000e+00 8.0019861e-21 2.3310198e-15 1.8010666e-11], sampled 0.400977371069721
[2019-03-23 14:36:51,924] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 14:36:51,995] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 14:36:52,199] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 14:36:52,234] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 14:36:52,261] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:36:53,277] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1250000, evaluation results [1250000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 14:36:58,620] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.4420359e-11 1.0000000e+00 8.7759911e-23 1.9215798e-17 1.0017483e-12], sum to 1.0000
[2019-03-23 14:36:58,631] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9996
[2019-03-23 14:36:58,636] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 45.0, 1.0, 2.0, 0.8100081966237735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 892182.0018925531, 892182.0018925531, 164231.8794847278], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7228800.0000, 
sim time next is 7229400.0000, 
raw observation next is [24.3, 45.16666666666666, 1.0, 2.0, 0.7350119294773526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 809253.9654518678, 809253.9654518678, 154628.7765619297], 
processed observation next is [1.0, 0.6956521739130435, 0.740909090909091, 0.45166666666666655, 1.0, 1.0, 0.6687649118466906, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2997236909080992, 0.2997236909080992, 0.3771433574681212], 
reward next is 0.6229, 
noisyNet noise sample is [array([2.3881752], dtype=float32), -1.0477353]. 
=============================================
[2019-03-23 14:37:03,439] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78500, global step 1255114: loss 0.0299
[2019-03-23 14:37:03,442] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78500, global step 1255115: learning rate 0.0000
[2019-03-23 14:37:03,989] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78500, global step 1255384: loss 0.0192
[2019-03-23 14:37:03,994] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78500, global step 1255386: learning rate 0.0000
[2019-03-23 14:37:04,212] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78500, global step 1255497: loss 0.2059
[2019-03-23 14:37:04,216] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78500, global step 1255497: learning rate 0.0000
[2019-03-23 14:37:04,333] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78500, global step 1255562: loss 0.3338
[2019-03-23 14:37:04,335] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78500, global step 1255562: learning rate 0.0000
[2019-03-23 14:37:04,409] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78500, global step 1255601: loss 0.0753
[2019-03-23 14:37:04,413] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78500, global step 1255601: learning rate 0.0000
[2019-03-23 14:37:04,638] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78500, global step 1255715: loss 0.0302
[2019-03-23 14:37:04,641] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78500, global step 1255715: learning rate 0.0000
[2019-03-23 14:37:04,790] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78500, global step 1255792: loss 0.0749
[2019-03-23 14:37:04,793] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78500, global step 1255793: learning rate 0.0000
[2019-03-23 14:37:05,067] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78500, global step 1255934: loss 0.0919
[2019-03-23 14:37:05,069] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78500, global step 1255934: learning rate 0.0000
[2019-03-23 14:37:05,358] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78500, global step 1256079: loss 0.0027
[2019-03-23 14:37:05,369] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78500, global step 1256082: learning rate 0.0000
[2019-03-23 14:37:05,680] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78500, global step 1256241: loss 0.0104
[2019-03-23 14:37:05,681] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78500, global step 1256241: learning rate 0.0000
[2019-03-23 14:37:05,724] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78500, global step 1256263: loss 0.0021
[2019-03-23 14:37:05,726] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78500, global step 1256263: learning rate 0.0000
[2019-03-23 14:37:05,746] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78500, global step 1256275: loss 0.0015
[2019-03-23 14:37:05,747] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78500, global step 1256275: learning rate 0.0000
[2019-03-23 14:37:05,764] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78500, global step 1256284: loss 0.0121
[2019-03-23 14:37:05,765] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78500, global step 1256284: learning rate 0.0000
[2019-03-23 14:37:05,826] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78500, global step 1256314: loss 0.0091
[2019-03-23 14:37:05,827] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78500, global step 1256314: learning rate 0.0000
[2019-03-23 14:37:06,123] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78500, global step 1256466: loss 0.0794
[2019-03-23 14:37:06,129] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78500, global step 1256466: learning rate 0.0000
[2019-03-23 14:37:07,475] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78500, global step 1257120: loss 0.6435
[2019-03-23 14:37:07,479] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78500, global step 1257121: learning rate 0.0000
[2019-03-23 14:37:07,487] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.0321577e-09 1.0000000e+00 7.4148285e-17 1.4076537e-12 2.7399705e-09], sum to 1.0000
[2019-03-23 14:37:07,493] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3521
[2019-03-23 14:37:07,497] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.88333333333333, 95.83333333333334, 1.0, 2.0, 0.3662329248576071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 408193.756061652, 408193.7560616517, 119728.1607560946], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7429800.0000, 
sim time next is 7430400.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.3646109298407925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 406065.1102387932, 406065.1102387932, 119459.3363367975], 
processed observation next is [0.0, 0.0, 0.44090909090909086, 0.97, 1.0, 1.0, 0.20576366230099064, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15039448527362712, 0.15039448527362712, 0.2913642349677988], 
reward next is 0.7086, 
noisyNet noise sample is [array([0.34410203], dtype=float32), -0.94387555]. 
=============================================
[2019-03-23 14:37:08,250] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.2789345e-09 1.0000000e+00 2.8106807e-18 4.4290027e-15 3.8741377e-10], sum to 1.0000
[2019-03-23 14:37:08,258] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1738
[2019-03-23 14:37:08,265] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 90.0, 1.0, 2.0, 0.3714894370775202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415383.3110193208, 415383.3110193208, 120741.705924234], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7426800.0000, 
sim time next is 7427400.0000, 
raw observation next is [18.61666666666667, 91.16666666666666, 1.0, 2.0, 0.3697969050487659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 413300.8027555678, 413300.8027555681, 120515.3480078931], 
processed observation next is [1.0, 1.0, 0.48257575757575777, 0.9116666666666666, 1.0, 1.0, 0.21224613131095735, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15307437139095104, 0.15307437139095115, 0.29393987318998316], 
reward next is 0.7061, 
noisyNet noise sample is [array([-0.2487028], dtype=float32), -0.8970345]. 
=============================================
[2019-03-23 14:37:09,162] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.9888677e-10 1.0000000e+00 6.3107045e-22 9.9874145e-17 8.3342291e-11], sum to 1.0000
[2019-03-23 14:37:09,172] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3193
[2019-03-23 14:37:09,178] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 84.0, 1.0, 2.0, 0.4012274178863636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 455189.7414357798, 455189.7414357798, 126829.4440743815], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7462800.0000, 
sim time next is 7463400.0000, 
raw observation next is [21.55, 82.33333333333333, 1.0, 2.0, 0.4088064096946097, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 464446.0612430241, 464446.0612430238, 128047.9036562129], 
processed observation next is [0.0, 0.391304347826087, 0.615909090909091, 0.8233333333333333, 1.0, 1.0, 0.2610080121182621, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17201705971963854, 0.17201705971963843, 0.31231196013710466], 
reward next is 0.6877, 
noisyNet noise sample is [array([1.2506926], dtype=float32), -1.1022806]. 
=============================================
[2019-03-23 14:37:11,973] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.6170949e-11 1.0000000e+00 1.7746063e-21 2.8810573e-18 5.3470612e-13], sum to 1.0000
[2019-03-23 14:37:11,979] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1591
[2019-03-23 14:37:11,984] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 55.0, 1.0, 2.0, 0.5066615378217184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 577639.3252311315, 577639.3252311315, 143130.2429428764], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7484400.0000, 
sim time next is 7485000.0000, 
raw observation next is [28.38333333333334, 54.66666666666667, 1.0, 2.0, 0.5048221253907265, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 575562.6685907962, 575562.6685907962, 142884.5579963353], 
processed observation next is [0.0, 0.6521739130434783, 0.9265151515151518, 0.5466666666666667, 1.0, 1.0, 0.38102765673840805, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21317135873733192, 0.21317135873733192, 0.3484989219422812], 
reward next is 0.6515, 
noisyNet noise sample is [array([1.6680065], dtype=float32), -1.9578203]. 
=============================================
[2019-03-23 14:37:12,003] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[67.540955]
 [67.50727 ]
 [67.48188 ]
 [67.45245 ]
 [67.43216 ]], R is [[67.5293808 ]
 [67.50498962]
 [67.47966766]
 [67.45323181]
 [67.42540741]].
[2019-03-23 14:37:14,704] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.8833778e-11 1.0000000e+00 3.6040546e-21 3.5945760e-16 2.6250523e-12], sum to 1.0000
[2019-03-23 14:37:14,714] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1543
[2019-03-23 14:37:14,718] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 82.0, 1.0, 2.0, 0.4620696854628064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 527138.5004883284, 527138.5004883284, 135982.7562774552], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7520400.0000, 
sim time next is 7521000.0000, 
raw observation next is [22.6, 82.66666666666667, 1.0, 2.0, 0.4628192953208357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 527996.1888024249, 527996.1888024249, 136070.1472873194], 
processed observation next is [0.0, 0.043478260869565216, 0.6636363636363637, 0.8266666666666667, 1.0, 1.0, 0.3285241191510446, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19555414400089813, 0.19555414400089813, 0.33187840801785223], 
reward next is 0.6681, 
noisyNet noise sample is [array([2.8099258], dtype=float32), -0.09389553]. 
=============================================
[2019-03-23 14:37:14,738] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[61.400265]
 [61.407963]
 [61.310604]
 [61.30899 ]
 [61.205605]], R is [[61.44311523]
 [61.49702072]
 [61.55068588]
 [61.60425568]
 [61.65795517]].
[2019-03-23 14:37:14,898] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.5376095e-10 1.0000000e+00 6.5295360e-21 5.4120122e-16 4.1086723e-10], sum to 1.0000
[2019-03-23 14:37:14,906] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9905
[2019-03-23 14:37:14,909] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.96666666666667, 78.5, 1.0, 2.0, 0.4540075123781619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517746.3870885313, 517746.3870885313, 134660.5947600924], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7516200.0000, 
sim time next is 7516800.0000, 
raw observation next is [22.9, 79.0, 1.0, 2.0, 0.4539338768894024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517667.5570437185, 517667.5570437185, 134662.9661212126], 
processed observation next is [0.0, 0.0, 0.6772727272727272, 0.79, 1.0, 1.0, 0.317417346111753, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19172872483100686, 0.19172872483100686, 0.3284462588322259], 
reward next is 0.6716, 
noisyNet noise sample is [array([1.4646844], dtype=float32), 2.3582544]. 
=============================================
[2019-03-23 14:37:15,218] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3306347e-11 1.0000000e+00 2.1949677e-22 4.1444224e-17 1.6167844e-13], sum to 1.0000
[2019-03-23 14:37:15,225] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6426
[2019-03-23 14:37:15,232] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.28333333333333, 89.0, 1.0, 2.0, 0.4445732648540986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 506596.9856327844, 506596.9856327844, 133055.2688972402], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7546200.0000, 
sim time next is 7546800.0000, 
raw observation next is [21.46666666666667, 88.0, 1.0, 2.0, 0.4477848858819659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 510350.5192417791, 510350.5192417791, 133515.67277436], 
processed observation next is [0.0, 0.34782608695652173, 0.6121212121212122, 0.88, 1.0, 1.0, 0.30973110735245735, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18901871083028857, 0.18901871083028857, 0.3256479823764878], 
reward next is 0.6744, 
noisyNet noise sample is [array([-0.13429585], dtype=float32), -0.30054417]. 
=============================================
[2019-03-23 14:37:15,652] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.8488945e-11 1.0000000e+00 2.5978830e-22 6.1089144e-16 4.0231807e-11], sum to 1.0000
[2019-03-23 14:37:15,662] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3083
[2019-03-23 14:37:15,673] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.41666666666667, 93.5, 1.0, 2.0, 0.4348207613553599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 494921.3629572942, 494921.3629572945, 131405.2690699933], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7539000.0000, 
sim time next is 7539600.0000, 
raw observation next is [20.33333333333334, 94.0, 1.0, 2.0, 0.4342958257997349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 494269.1722669603, 494269.1722669603, 131297.0844213456], 
processed observation next is [0.0, 0.2608695652173913, 0.5606060606060609, 0.94, 1.0, 1.0, 0.2928697822496686, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1830626563951705, 0.1830626563951705, 0.3202367912715746], 
reward next is 0.6798, 
noisyNet noise sample is [array([2.1481135], dtype=float32), -0.9414848]. 
=============================================
[2019-03-23 14:37:16,936] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2821481e-08 1.0000000e+00 1.5329858e-19 1.1402957e-13 2.0130989e-10], sum to 1.0000
[2019-03-23 14:37:16,949] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4922
[2019-03-23 14:37:16,952] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 90.0, 1.0, 2.0, 0.4041627074086424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 455517.1986914267, 455517.1986914264, 125264.6544390645], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7588800.0000, 
sim time next is 7589400.0000, 
raw observation next is [19.5, 90.5, 1.0, 2.0, 0.4020710243887273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 453342.5116791227, 453342.511679123, 125174.537225702], 
processed observation next is [0.0, 0.8695652173913043, 0.5227272727272727, 0.905, 1.0, 1.0, 0.2525887804859091, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16790463395523061, 0.16790463395523073, 0.3053037493309805], 
reward next is 0.6947, 
noisyNet noise sample is [array([0.9712102], dtype=float32), 1.3892719]. 
=============================================
[2019-03-23 14:37:19,309] A3C_AGENT_WORKER-Thread-9 INFO:Local step 79000, global step 1263174: loss -265.9621
[2019-03-23 14:37:19,311] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 79000, global step 1263175: learning rate 0.0000
[2019-03-23 14:37:19,734] A3C_AGENT_WORKER-Thread-3 INFO:Local step 79000, global step 1263399: loss -222.7887
[2019-03-23 14:37:19,739] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 79000, global step 1263400: learning rate 0.0000
[2019-03-23 14:37:20,025] A3C_AGENT_WORKER-Thread-10 INFO:Local step 79000, global step 1263555: loss -218.7930
[2019-03-23 14:37:20,028] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 79000, global step 1263556: learning rate 0.0000
[2019-03-23 14:37:20,036] A3C_AGENT_WORKER-Thread-22 INFO:Local step 79000, global step 1263558: loss -157.8582
[2019-03-23 14:37:20,037] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 79000, global step 1263558: learning rate 0.0000
[2019-03-23 14:37:20,291] A3C_AGENT_WORKER-Thread-14 INFO:Local step 79000, global step 1263695: loss -235.4018
[2019-03-23 14:37:20,291] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 79000, global step 1263695: learning rate 0.0000
[2019-03-23 14:37:20,327] A3C_AGENT_WORKER-Thread-13 INFO:Local step 79000, global step 1263716: loss -93.3242
[2019-03-23 14:37:20,329] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 79000, global step 1263717: learning rate 0.0000
[2019-03-23 14:37:20,430] A3C_AGENT_WORKER-Thread-21 INFO:Local step 79000, global step 1263769: loss -136.0264
[2019-03-23 14:37:20,432] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 79000, global step 1263769: learning rate 0.0000
[2019-03-23 14:37:20,722] A3C_AGENT_WORKER-Thread-20 INFO:Local step 79000, global step 1263921: loss -230.2736
[2019-03-23 14:37:20,724] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 79000, global step 1263922: learning rate 0.0000
[2019-03-23 14:37:20,951] A3C_AGENT_WORKER-Thread-16 INFO:Local step 79000, global step 1264044: loss -127.8388
[2019-03-23 14:37:20,953] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 79000, global step 1264044: learning rate 0.0000
[2019-03-23 14:37:21,045] A3C_AGENT_WORKER-Thread-11 INFO:Local step 79000, global step 1264097: loss -177.0123
[2019-03-23 14:37:21,049] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 79000, global step 1264097: learning rate 0.0000
[2019-03-23 14:37:21,326] A3C_AGENT_WORKER-Thread-19 INFO:Local step 79000, global step 1264241: loss -198.7057
[2019-03-23 14:37:21,328] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 79000, global step 1264241: learning rate 0.0000
[2019-03-23 14:37:21,446] A3C_AGENT_WORKER-Thread-2 INFO:Local step 79000, global step 1264302: loss -304.2977
[2019-03-23 14:37:21,447] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 79000, global step 1264302: learning rate 0.0000
[2019-03-23 14:37:21,493] A3C_AGENT_WORKER-Thread-17 INFO:Local step 79000, global step 1264331: loss -165.8125
[2019-03-23 14:37:21,495] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 79000, global step 1264331: learning rate 0.0000
[2019-03-23 14:37:21,496] A3C_AGENT_WORKER-Thread-12 INFO:Local step 79000, global step 1264332: loss -260.9335
[2019-03-23 14:37:21,501] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 79000, global step 1264332: learning rate 0.0000
[2019-03-23 14:37:21,851] A3C_AGENT_WORKER-Thread-18 INFO:Local step 79000, global step 1264517: loss -254.3817
[2019-03-23 14:37:21,852] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 79000, global step 1264517: learning rate 0.0000
[2019-03-23 14:37:23,180] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.3938934e-11 1.0000000e+00 5.2690882e-23 5.9226542e-17 1.0627853e-13], sum to 1.0000
[2019-03-23 14:37:23,187] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4622
[2019-03-23 14:37:23,196] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.61666666666667, 96.83333333333334, 1.0, 2.0, 0.3734280505161777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415332.7577665207, 415332.7577665207, 119950.142007505], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7711800.0000, 
sim time next is 7712400.0000, 
raw observation next is [17.53333333333333, 96.66666666666667, 1.0, 2.0, 0.3558018869267291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 395138.3647459169, 395138.3647459169, 118283.0189331946], 
processed observation next is [1.0, 0.2608695652173913, 0.43333333333333324, 0.9666666666666667, 1.0, 1.0, 0.19475235865841134, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14634754249848775, 0.14634754249848775, 0.2884951681297429], 
reward next is 0.7115, 
noisyNet noise sample is [array([-0.47173548], dtype=float32), -0.50831074]. 
=============================================
[2019-03-23 14:37:23,358] A3C_AGENT_WORKER-Thread-15 INFO:Local step 79000, global step 1265274: loss -108.5822
[2019-03-23 14:37:23,360] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 79000, global step 1265275: learning rate 0.0000
[2019-03-23 14:37:23,525] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.4257228e-11 1.0000000e+00 3.9644582e-22 6.4530841e-17 6.9218952e-13], sum to 1.0000
[2019-03-23 14:37:23,533] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3897
[2019-03-23 14:37:23,541] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.8, 93.66666666666666, 1.0, 2.0, 0.5063576331457396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 574613.7184427315, 574613.7184427315, 137527.2552847932], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7697400.0000, 
sim time next is 7698000.0000, 
raw observation next is [19.6, 94.33333333333334, 1.0, 2.0, 0.4588634166211459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 520272.7894332585, 520272.7894332582, 132238.5515237719], 
processed observation next is [1.0, 0.08695652173913043, 0.5272727272727273, 0.9433333333333335, 1.0, 1.0, 0.32357927077643234, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19269362571602167, 0.19269362571602155, 0.32253305249700465], 
reward next is 0.6775, 
noisyNet noise sample is [array([-0.08484319], dtype=float32), 0.87238955]. 
=============================================
[2019-03-23 14:37:23,551] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[66.93987]
 [67.11462]
 [67.07341]
 [67.13453]
 [67.15915]], R is [[66.89041901]
 [66.88607788]
 [66.90399933]
 [66.92134094]
 [66.93808746]].
[2019-03-23 14:37:29,819] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.231503e-13 1.000000e+00 3.503281e-23 9.606515e-19 8.203719e-15], sum to 1.0000
[2019-03-23 14:37:29,827] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4414
[2019-03-23 14:37:29,830] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.18333333333334, 73.83333333333333, 1.0, 2.0, 0.7333824059678621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 825843.2890131812, 825843.2890131812, 161846.2028531401], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7812600.0000, 
sim time next is 7813200.0000, 
raw observation next is [21.26666666666667, 69.66666666666667, 1.0, 2.0, 0.6979559926925302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 781838.4249082619, 781838.4249082622, 155302.7693514767], 
processed observation next is [1.0, 0.43478260869565216, 0.6030303030303031, 0.6966666666666668, 1.0, 1.0, 0.6224449908656626, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.28956978700305996, 0.2895697870030601, 0.37878724232067484], 
reward next is 0.6212, 
noisyNet noise sample is [array([-0.11420596], dtype=float32), 1.9133632]. 
=============================================
[2019-03-23 14:37:30,937] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.9693205e-12 1.0000000e+00 3.4996079e-23 2.8667929e-19 2.5370649e-14], sum to 1.0000
[2019-03-23 14:37:30,946] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8508
[2019-03-23 14:37:30,952] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.21666666666667, 43.0, 1.0, 2.0, 0.658294241503346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 717886.6077662612, 717886.6077662612, 143384.1920293745], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7834200.0000, 
sim time next is 7834800.0000, 
raw observation next is [24.03333333333333, 44.0, 1.0, 2.0, 0.6658318052701703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 726453.9206971168, 726453.920697117, 144318.6525982331], 
processed observation next is [1.0, 0.6956521739130435, 0.7287878787878787, 0.44, 1.0, 1.0, 0.5822897565877128, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2690570076655988, 0.26905700766559887, 0.3519967136542271], 
reward next is 0.6480, 
noisyNet noise sample is [array([-0.10515603], dtype=float32), 0.4244685]. 
=============================================
[2019-03-23 14:37:32,675] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.0701134e-11 1.0000000e+00 5.1829509e-22 4.4615733e-17 1.4894337e-14], sum to 1.0000
[2019-03-23 14:37:32,683] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7213
[2019-03-23 14:37:32,686] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.51666666666667, 87.5, 1.0, 2.0, 0.8826518129777015, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1006955.876459009, 1006955.876459009, 193130.7600985365], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7920600.0000, 
sim time next is 7921200.0000, 
raw observation next is [21.43333333333334, 88.0, 1.0, 2.0, 0.8733974489607427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 996346.8347847409, 996346.8347847413, 191512.4740860644], 
processed observation next is [1.0, 0.6956521739130435, 0.6106060606060609, 0.88, 1.0, 1.0, 0.8417468112009282, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.36901734621657073, 0.36901734621657084, 0.4671035953318644], 
reward next is 0.5329, 
noisyNet noise sample is [array([0.7796526], dtype=float32), -0.5755973]. 
=============================================
[2019-03-23 14:37:33,319] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3752488e-10 1.0000000e+00 3.9199453e-22 3.8887822e-17 1.4459132e-13], sum to 1.0000
[2019-03-23 14:37:33,324] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0190
[2019-03-23 14:37:33,332] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 91.0, 1.0, 2.0, 0.4547307470520704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 518340.2670173858, 518340.2670173855, 134344.5361713012], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7933200.0000, 
sim time next is 7933800.0000, 
raw observation next is [21.1, 90.5, 1.0, 2.0, 0.4536342119900378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516995.0050236951, 516995.0050236951, 134091.8540924099], 
processed observation next is [1.0, 0.8260869565217391, 0.5954545454545456, 0.905, 1.0, 1.0, 0.3170427649875472, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19147963149025746, 0.19147963149025746, 0.32705330266441435], 
reward next is 0.6729, 
noisyNet noise sample is [array([-0.24081881], dtype=float32), -0.14028531]. 
=============================================
[2019-03-23 14:37:35,104] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:37:35,105] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:37:35,152] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run7
[2019-03-23 14:37:35,499] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:37:35,499] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:37:35,524] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run7
[2019-03-23 14:37:35,610] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:37:35,611] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:37:35,622] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run7
[2019-03-23 14:37:35,771] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:37:35,771] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:37:35,775] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run7
[2019-03-23 14:37:35,834] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:37:35,835] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:37:35,839] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run7
[2019-03-23 14:37:35,923] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:37:35,923] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:37:35,926] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run7
[2019-03-23 14:37:36,095] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:37:36,096] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:37:36,099] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run7
[2019-03-23 14:37:36,271] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:37:36,271] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:37:36,275] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run7
[2019-03-23 14:37:36,312] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:37:36,313] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:37:36,316] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run7
[2019-03-23 14:37:36,453] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:37:36,453] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:37:36,456] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run7
[2019-03-23 14:37:36,581] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:37:36,581] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:37:36,584] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run7
[2019-03-23 14:37:36,649] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:37:36,650] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:37:36,653] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:37:36,653] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:37:36,654] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run7
[2019-03-23 14:37:36,707] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:37:36,708] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:37:36,655] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:37:36,717] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:37:36,720] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run7
[2019-03-23 14:37:36,787] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run7
[2019-03-23 14:37:36,882] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run7
[2019-03-23 14:37:37,057] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:37:37,057] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:37:37,060] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run7
[2019-03-23 14:37:41,695] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.5332629e-15 1.0000000e+00 7.3687552e-24 6.7863578e-20 1.4517267e-14], sum to 1.0000
[2019-03-23 14:37:41,702] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4430
[2019-03-23 14:37:41,706] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 73.0, 1.0, 2.0, 0.3782040714470072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 423174.3957404856, 423174.3957404859, 121431.5779579887], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 68400.0000, 
sim time next is 69000.0000, 
raw observation next is [20.83333333333333, 73.83333333333334, 1.0, 2.0, 0.3763281603577686, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 420665.4928172526, 420665.4928172523, 121089.0112137131], 
processed observation next is [1.0, 0.8260869565217391, 0.5833333333333331, 0.7383333333333334, 1.0, 1.0, 0.22041020044721074, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1558020343767602, 0.1558020343767601, 0.29533905174076364], 
reward next is 0.7047, 
noisyNet noise sample is [array([0.3261159], dtype=float32), 1.5635682]. 
=============================================
[2019-03-23 14:37:41,722] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[74.605545]
 [74.78904 ]
 [74.51273 ]
 [74.764   ]
 [74.79312 ]], R is [[74.45458984]
 [74.41387177]
 [74.3715744 ]
 [74.32749939]
 [74.28128052]].
[2019-03-23 14:37:42,288] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.9591933e-13 1.0000000e+00 6.8717338e-25 1.1795667e-20 4.4749216e-16], sum to 1.0000
[2019-03-23 14:37:42,296] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7474
[2019-03-23 14:37:42,307] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.83333333333333, 73.83333333333334, 1.0, 2.0, 0.3763281603577111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 420665.4928172526, 420665.4928172523, 121089.0112137369], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 69000.0000, 
sim time next is 69600.0000, 
raw observation next is [20.66666666666667, 74.66666666666667, 1.0, 2.0, 0.3759939554177519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 420021.8151526044, 420021.8151526047, 120941.1537187028], 
processed observation next is [1.0, 0.8260869565217391, 0.575757575757576, 0.7466666666666667, 1.0, 1.0, 0.21999244427218984, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15556363524170536, 0.15556363524170544, 0.29497842370415317], 
reward next is 0.7050, 
noisyNet noise sample is [array([-0.0084531], dtype=float32), 1.0660816]. 
=============================================
[2019-03-23 14:37:43,722] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 14:37:43,728] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:37:43,729] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:37:43,731] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:37:43,732] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:37:43,732] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:37:43,733] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:37:43,733] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:37:43,733] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:37:43,734] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:37:43,734] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:37:43,747] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run52
[2019-03-23 14:37:43,777] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run52
[2019-03-23 14:37:43,778] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run52
[2019-03-23 14:37:43,830] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run52
[2019-03-23 14:37:43,864] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run52
[2019-03-23 14:37:46,582] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06405987], dtype=float32), 0.23760751]
[2019-03-23 14:37:46,583] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.30347933, 43.9061277, 1.0, 2.0, 0.6083742893939068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 675709.4098935878, 675709.4098935875, 146579.2414458642]
[2019-03-23 14:37:46,584] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:37:46,585] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.1552839e-13 1.0000000e+00 2.9855601e-24 4.0510850e-19 3.3554139e-15], sampled 0.6096166155564524
[2019-03-23 14:37:58,610] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06405987], dtype=float32), 0.23760751]
[2019-03-23 14:37:58,613] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.884229865, 92.080851885, 1.0, 2.0, 0.6668862726818524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 749346.9661036357, 749346.9661036354, 172885.3806855181]
[2019-03-23 14:37:58,613] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:37:58,616] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.12333245e-13 1.00000000e+00 9.03289617e-25 1.58863811e-19
 1.60369298e-15], sampled 0.6893162392431382
[2019-03-23 14:38:02,613] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06405987], dtype=float32), 0.23760751]
[2019-03-23 14:38:02,614] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [28.49484410333334, 53.71084853333334, 1.0, 2.0, 0.637394594231142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 726475.6905925489, 726475.6905925486, 164460.4561965564]
[2019-03-23 14:38:02,615] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:38:02,616] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.6442853e-14 1.0000000e+00 6.8280704e-25 1.2763021e-19 1.3494150e-15], sampled 0.38604873501730286
[2019-03-23 14:38:04,530] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06405987], dtype=float32), 0.23760751]
[2019-03-23 14:38:04,531] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.5, 60.5, 1.0, 2.0, 0.3796495727040436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 426926.7532092319, 426926.7532092319, 126901.2550895038]
[2019-03-23 14:38:04,534] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:38:04,539] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.2578462e-14 1.0000000e+00 3.0872121e-25 6.8565647e-20 8.2671427e-16], sampled 0.12664777043801356
[2019-03-23 14:38:07,882] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06405987], dtype=float32), 0.23760751]
[2019-03-23 14:38:07,885] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.63333333333333, 44.83333333333333, 1.0, 2.0, 0.3215896093353873, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 349183.3182892282, 349183.3182892282, 116969.3741327404]
[2019-03-23 14:38:07,886] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:38:07,889] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.0484851e-14 1.0000000e+00 3.8413503e-25 8.1352309e-20 9.4606973e-16], sampled 0.3961914718069304
[2019-03-23 14:38:14,814] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06405987], dtype=float32), 0.23760751]
[2019-03-23 14:38:14,816] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.48333333333333, 59.5, 1.0, 2.0, 0.5164035301277834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 588579.9461207337, 588579.9461207337, 148726.4581476031]
[2019-03-23 14:38:14,817] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:38:14,820] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.2145395e-14 1.0000000e+00 4.5924086e-26 1.5424468e-20 2.5497920e-16], sampled 0.45805132133846205
[2019-03-23 14:38:26,536] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06405987], dtype=float32), 0.23760751]
[2019-03-23 14:38:26,537] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 88.66666666666667, 1.0, 2.0, 0.3629785348502321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 405791.1541639228, 405791.1541639225, 120003.0243966886]
[2019-03-23 14:38:26,538] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:38:26,543] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.2425385e-13 1.0000000e+00 1.0867940e-24 1.8364594e-19 1.7976343e-15], sampled 0.31783000395047933
[2019-03-23 14:38:35,911] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06405987], dtype=float32), 0.23760751]
[2019-03-23 14:38:35,913] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.29809396, 85.52666199999999, 1.0, 2.0, 0.5087978050353733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 552548.2088007074, 552548.2088007069, 131970.1092958612]
[2019-03-23 14:38:35,918] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:38:35,920] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.5567753e-13 1.0000000e+00 1.6434078e-24 2.5386075e-19 2.3206568e-15], sampled 0.040397706374465936
[2019-03-23 14:38:51,819] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06405987], dtype=float32), 0.23760751]
[2019-03-23 14:38:51,819] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.72001027, 87.30379953333335, 1.0, 2.0, 0.3512508777143628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 390882.5287780241, 390882.5287780241, 122575.6715185401]
[2019-03-23 14:38:51,820] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:38:51,825] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.4746643e-14 1.0000000e+00 2.4162026e-25 5.6591503e-20 7.1043290e-16], sampled 0.7328383360262278
[2019-03-23 14:38:53,278] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06405987], dtype=float32), 0.23760751]
[2019-03-23 14:38:53,279] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.99109245333333, 84.84295913, 1.0, 2.0, 0.4825615035158207, 0.0, 1.0, 0.0, 1.0, 1.0, 0.883971689062914, 7.040749905898154, 6.9112, 95.55298439537285, 1092279.851680695, 1040288.55510652, 254272.6100724981]
[2019-03-23 14:38:53,281] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:38:53,283] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.52327547e-13 1.00000000e+00 1.16343675e-23 1.17468684e-18
 7.76996960e-15], sampled 0.7563768854750723
[2019-03-23 14:38:53,285] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1092279.851680695 W.
[2019-03-23 14:38:58,269] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06405987], dtype=float32), 0.23760751]
[2019-03-23 14:38:58,271] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.6, 44.0, 1.0, 2.0, 0.2637696549332583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 286403.298783711, 286403.298783711, 85351.95854995919]
[2019-03-23 14:38:58,273] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:38:58,276] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.6619180e-13 1.0000000e+00 4.3972827e-24 5.4854581e-19 4.2614270e-15], sampled 0.5504291705044423
[2019-03-23 14:39:12,157] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06405987], dtype=float32), 0.23760751]
[2019-03-23 14:39:12,158] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.70473477666667, 84.14821430666666, 1.0, 2.0, 0.6394392739191048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 696530.478360748, 696530.478360748, 145436.8751358982]
[2019-03-23 14:39:12,160] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:39:12,163] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.6010785e-13 1.0000000e+00 1.7301719e-24 2.6427870e-19 2.3954827e-15], sampled 0.7770503711987057
[2019-03-23 14:39:26,709] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:39:26,875] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 14:39:27,083] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 14:39:27,340] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 14:39:27,445] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 14:39:28,461] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1275000, evaluation results [1275000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 14:39:29,137] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.8988959e-13 1.0000000e+00 3.9907514e-23 2.7695550e-18 1.5411038e-15], sum to 1.0000
[2019-03-23 14:39:29,144] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5817
[2019-03-23 14:39:29,149] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 39.5, 1.0, 2.0, 0.6923010863515708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 752066.2527857721, 752066.2527857721, 136747.2544038418], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 142200.0000, 
sim time next is 142800.0000, 
raw observation next is [23.0, 39.0, 1.0, 2.0, 0.6723338292170249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 730358.9541540021, 730358.9541540021, 133656.6394845964], 
processed observation next is [1.0, 0.6521739130434783, 0.6818181818181818, 0.39, 1.0, 1.0, 0.5904172865212811, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.27050331635333413, 0.27050331635333413, 0.32599180362096686], 
reward next is 0.6740, 
noisyNet noise sample is [array([-0.5559667], dtype=float32), -1.8058076]. 
=============================================
[2019-03-23 14:39:38,096] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9502628e-09 1.0000000e+00 1.3835858e-26 2.8272058e-20 1.4614155e-16], sum to 1.0000
[2019-03-23 14:39:38,105] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8784
[2019-03-23 14:39:38,109] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 42.66666666666667, 1.0, 2.0, 0.2670070200367589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 289919.5046458542, 289919.5046458539, 87507.28186709319], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 313800.0000, 
sim time next is 314400.0000, 
raw observation next is [22.33333333333334, 42.33333333333334, 1.0, 2.0, 0.2689309280928402, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 292009.1348101647, 292009.134810165, 88314.71492694085], 
processed observation next is [0.0, 0.6521739130434783, 0.6515151515151518, 0.42333333333333345, 1.0, 1.0, 0.08616366011605023, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1081515314111721, 0.10815153141117222, 0.21540174372424598], 
reward next is 0.7846, 
noisyNet noise sample is [array([-0.33324993], dtype=float32), 1.3153522]. 
=============================================
[2019-03-23 14:39:38,840] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4589065e-08 1.0000000e+00 1.6054784e-25 7.9475405e-19 3.6582090e-16], sum to 1.0000
[2019-03-23 14:39:38,848] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9536
[2019-03-23 14:39:38,858] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 43.0, 1.0, 2.0, 0.2565753464624639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 278589.4210932271, 278589.4210932271, 81429.55145406425], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 322800.0000, 
sim time next is 323400.0000, 
raw observation next is [21.0, 43.0, 1.0, 2.0, 0.257015590082591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 279067.5746047622, 279067.5746047622, 81471.72061061558], 
processed observation next is [0.0, 0.7391304347826086, 0.5909090909090909, 0.43, 1.0, 1.0, 0.07126948760323874, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10335836096472674, 0.10335836096472674, 0.19871151368442824], 
reward next is 0.8013, 
noisyNet noise sample is [array([-2.1576157], dtype=float32), 1.3465236]. 
=============================================
[2019-03-23 14:39:39,097] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.7945568e-09 1.0000000e+00 3.9121939e-21 3.3642942e-16 3.9314153e-15], sum to 1.0000
[2019-03-23 14:39:39,104] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3247
[2019-03-23 14:39:39,112] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 41.33333333333334, 1.0, 2.0, 0.2761803158064278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 299883.0528836349, 299883.0528836349, 89969.1218817681], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 317400.0000, 
sim time next is 318000.0000, 
raw observation next is [22.33333333333334, 41.66666666666667, 1.0, 2.0, 0.2735728022063413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 297050.8888861133, 297050.8888861136, 88080.07464487173], 
processed observation next is [0.0, 0.6956521739130435, 0.6515151515151518, 0.41666666666666674, 1.0, 1.0, 0.09196600275792659, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11001884773559752, 0.11001884773559763, 0.21482945035334566], 
reward next is 0.7852, 
noisyNet noise sample is [array([-0.86756265], dtype=float32), -0.012769131]. 
=============================================
[2019-03-23 14:39:39,127] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[70.960594]
 [70.92228 ]
 [70.86494 ]
 [70.8127  ]
 [70.78451 ]], R is [[71.00132751]
 [71.07187653]
 [71.1370163 ]
 [71.20379639]
 [71.2721405 ]].
[2019-03-23 14:39:39,366] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.6366156e-08 1.0000000e+00 8.0843286e-23 2.3980871e-16 2.3202610e-13], sum to 1.0000
[2019-03-23 14:39:39,376] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4792
[2019-03-23 14:39:39,382] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.83333333333334, 59.0, 1.0, 2.0, 0.2093555380137662, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 227306.1888886215, 227306.1888886212, 72564.33804525726], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 335400.0000, 
sim time next is 336000.0000, 
raw observation next is [16.66666666666667, 59.0, 1.0, 2.0, 0.2076063550417309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 225406.5866796119, 225406.5866796119, 72083.1499659738], 
processed observation next is [0.0, 0.9130434782608695, 0.39393939393939414, 0.59, 1.0, 1.0, 0.009507943802163597, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08348392099244885, 0.08348392099244885, 0.17581256089261904], 
reward next is 0.8242, 
noisyNet noise sample is [array([2.1005857], dtype=float32), 1.0088432]. 
=============================================
[2019-03-23 14:39:39,396] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[73.05047 ]
 [73.22797 ]
 [73.41613 ]
 [73.619354]
 [73.868286]], R is [[72.88610077]
 [72.98025513]
 [73.07221985]
 [73.16278839]
 [73.25191498]].
[2019-03-23 14:39:42,320] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.1373817e-06 9.9999392e-01 2.3439164e-23 1.5272878e-16 8.6834511e-14], sum to 1.0000
[2019-03-23 14:39:42,328] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0901
[2019-03-23 14:39:42,334] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.5, 74.5, 1.0, 2.0, 0.22582559641307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 245192.9372653615, 245192.9372653618, 74010.20968543316], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 376200.0000, 
sim time next is 376800.0000, 
raw observation next is [14.66666666666667, 75.33333333333333, 1.0, 2.0, 0.2125060812246954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 230727.6786211746, 230727.6786211746, 72815.23500315244], 
processed observation next is [1.0, 0.34782608695652173, 0.30303030303030315, 0.7533333333333333, 1.0, 1.0, 0.01563260153086922, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08545469578562022, 0.08545469578562022, 0.17759813415403033], 
reward next is 0.8224, 
noisyNet noise sample is [array([-1.866063], dtype=float32), 0.3377805]. 
=============================================
[2019-03-23 14:39:48,143] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.9481160e-07 9.9999976e-01 7.4411878e-22 4.5052031e-16 2.0128110e-13], sum to 1.0000
[2019-03-23 14:39:48,152] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2093
[2019-03-23 14:39:48,158] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.66666666666667, 90.0, 1.0, 2.0, 0.4353905934543444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 472841.3550010739, 472841.3550010739, 108059.5044780867], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 492000.0000, 
sim time next is 492600.0000, 
raw observation next is [15.83333333333333, 89.0, 1.0, 2.0, 0.4504520351727818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489206.5587321426, 489206.5587321426, 110241.8111255531], 
processed observation next is [1.0, 0.6956521739130435, 0.3560606060606059, 0.89, 1.0, 1.0, 0.31306504396597723, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.181187614345238, 0.181187614345238, 0.2688824661598856], 
reward next is 0.7311, 
noisyNet noise sample is [array([1.8129203], dtype=float32), -1.1934795]. 
=============================================
[2019-03-23 14:39:51,832] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.9017497e-08 1.0000000e+00 1.0506096e-21 2.2280355e-16 2.1776899e-12], sum to 1.0000
[2019-03-23 14:39:51,839] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6430
[2019-03-23 14:39:51,842] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.33333333333333, 98.0, 1.0, 2.0, 0.2074671117674582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 225255.3696382814, 225255.3696382817, 74909.51026548362], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 535200.0000, 
sim time next is 535800.0000, 
raw observation next is [13.16666666666667, 99.0, 1.0, 2.0, 0.2057826546386372, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 223426.0668872434, 223426.0668872432, 74489.98207946787], 
processed observation next is [1.0, 0.17391304347826086, 0.23484848484848497, 0.99, 1.0, 1.0, 0.007228318298296496, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08275039514342347, 0.08275039514342342, 0.18168288312065334], 
reward next is 0.8183, 
noisyNet noise sample is [array([-0.5265648], dtype=float32), -0.40568113]. 
=============================================
[2019-03-23 14:39:53,705] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.24484789e-11 1.00000000e+00 1.21836865e-24 2.55258114e-19
 1.16397929e-14], sum to 1.0000
[2019-03-23 14:39:53,713] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2646
[2019-03-23 14:39:53,718] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 83.0, 1.0, 2.0, 0.3053011844579351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 332273.9157875156, 332273.9157875153, 111814.7644030474], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 604200.0000, 
sim time next is 604800.0000, 
raw observation next is [18.0, 83.0, 1.0, 2.0, 0.3051854132995366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 332148.1158842784, 332148.1158842781, 111806.9727754394], 
processed observation next is [1.0, 0.0, 0.45454545454545453, 0.83, 1.0, 1.0, 0.1314817666244207, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12301782069788088, 0.12301782069788077, 0.27269993359863265], 
reward next is 0.7273, 
noisyNet noise sample is [array([-1.246622], dtype=float32), 0.3469737]. 
=============================================
[2019-03-23 14:39:54,253] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.3904257e-10 1.0000000e+00 1.0536473e-22 4.1106330e-17 6.6813222e-13], sum to 1.0000
[2019-03-23 14:39:54,260] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2723
[2019-03-23 14:39:54,264] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 88.0, 1.0, 2.0, 0.2573261025882052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 279404.8259869761, 279404.8259869761, 90078.32843174775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 614400.0000, 
sim time next is 615000.0000, 
raw observation next is [16.0, 88.0, 1.0, 2.0, 0.2569655577532808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 279013.2339095657, 279013.2339095654, 90017.54396814435], 
processed observation next is [1.0, 0.08695652173913043, 0.36363636363636365, 0.88, 1.0, 1.0, 0.07120694719160096, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10333823478132063, 0.10333823478132051, 0.21955498528815695], 
reward next is 0.7804, 
noisyNet noise sample is [array([1.7341183], dtype=float32), -1.2499297]. 
=============================================
[2019-03-23 14:39:54,290] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[73.10119 ]
 [73.162735]
 [73.37383 ]
 [73.52264 ]
 [73.51557 ]], R is [[72.85400391]
 [72.90576172]
 [72.95622253]
 [73.00334167]
 [73.04614258]].
[2019-03-23 14:39:57,103] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.2038140e-10 1.0000000e+00 1.2555183e-19 1.1589151e-14 6.5166232e-13], sum to 1.0000
[2019-03-23 14:39:57,113] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7316
[2019-03-23 14:39:57,120] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 73.5, 1.0, 2.0, 0.6263821843945577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 702160.2685829282, 702160.2685829282, 146858.4834015763], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 639000.0000, 
sim time next is 639600.0000, 
raw observation next is [21.33333333333334, 72.0, 1.0, 2.0, 0.543780329211016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 610141.3501846641, 610141.3501846641, 137899.1877324431], 
processed observation next is [1.0, 0.391304347826087, 0.6060606060606063, 0.72, 1.0, 1.0, 0.42972541151377003, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2259782778461719, 0.2259782778461719, 0.3363394822742515], 
reward next is 0.6637, 
noisyNet noise sample is [array([1.2896438], dtype=float32), 0.5485658]. 
=============================================
[2019-03-23 14:39:57,836] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2221082e-10 1.0000000e+00 2.5473341e-22 7.0319807e-18 1.2567608e-13], sum to 1.0000
[2019-03-23 14:39:57,843] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0892
[2019-03-23 14:39:57,846] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 48.66666666666666, 1.0, 2.0, 0.3753601836898731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344263955, 422256.6804954663, 422256.6804954666, 122284.8712419098], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 667200.0000, 
sim time next is 667800.0000, 
raw observation next is [25.5, 49.0, 1.0, 2.0, 0.3564421868543718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344353547, 400359.9418260562, 400359.9418260559, 120363.4972218216], 
processed observation next is [1.0, 0.7391304347826086, 0.7954545454545454, 0.49, 1.0, 1.0, 0.1955527335679647, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206175, 0.14828145993557637, 0.14828145993557626, 0.29356950541907706], 
reward next is 0.7064, 
noisyNet noise sample is [array([-1.2439584], dtype=float32), -0.21504925]. 
=============================================
[2019-03-23 14:39:58,146] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.6280215e-10 1.0000000e+00 2.6971185e-22 2.0624508e-17 4.8630143e-13], sum to 1.0000
[2019-03-23 14:39:58,154] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9661
[2019-03-23 14:39:58,161] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.16666666666666, 53.33333333333333, 1.0, 2.0, 0.3605377086762815, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 402877.183753643, 402877.1837536432, 119718.6053422446], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 672600.0000, 
sim time next is 673200.0000, 
raw observation next is [24.0, 54.0, 1.0, 2.0, 0.3584930911593608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 400406.3172751041, 400406.3172751044, 119468.2654617459], 
processed observation next is [1.0, 0.8260869565217391, 0.7272727272727273, 0.54, 1.0, 1.0, 0.19811636394920096, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14829863602781634, 0.14829863602781646, 0.29138601332133146], 
reward next is 0.7086, 
noisyNet noise sample is [array([-1.7885697], dtype=float32), 0.24802473]. 
=============================================
[2019-03-23 14:40:06,714] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.6910523e-08 1.0000000e+00 1.1849205e-19 1.4500979e-16 2.3195983e-12], sum to 1.0000
[2019-03-23 14:40:06,719] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1560
[2019-03-23 14:40:06,722] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 85.5, 1.0, 2.0, 0.4124280132177587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 466851.8336241831, 466851.8336241828, 127181.856096478], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 858600.0000, 
sim time next is 859200.0000, 
raw observation next is [20.33333333333333, 86.33333333333334, 1.0, 2.0, 0.4098445050295269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 463695.3907161072, 463695.3907161069, 126794.846538188], 
processed observation next is [0.0, 0.9565217391304348, 0.5606060606060604, 0.8633333333333334, 1.0, 1.0, 0.2623056312869086, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17173903359855822, 0.17173903359855813, 0.3092557232638732], 
reward next is 0.6907, 
noisyNet noise sample is [array([0.7840694], dtype=float32), 1.1315577]. 
=============================================
[2019-03-23 14:40:06,737] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2968725e-09 1.0000000e+00 2.2155467e-20 9.3327255e-17 5.2924050e-12], sum to 1.0000
[2019-03-23 14:40:06,743] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6474
[2019-03-23 14:40:06,750] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666667, 87.16666666666667, 1.0, 2.0, 0.4085660867090964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 462008.6005344385, 462008.6005344385, 126529.0438079971], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 859800.0000, 
sim time next is 860400.0000, 
raw observation next is [20.0, 88.0, 1.0, 2.0, 0.4078587928325908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 460958.8036760605, 460958.8036760602, 126314.4069201697], 
processed observation next is [0.0, 1.0, 0.5454545454545454, 0.88, 1.0, 1.0, 0.2598234910407385, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1707254828429854, 0.17072548284298528, 0.3080839193174871], 
reward next is 0.6919, 
noisyNet noise sample is [array([0.12350069], dtype=float32), -1.4598758]. 
=============================================
[2019-03-23 14:40:15,114] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.7297832e-10 1.0000000e+00 7.0789285e-23 7.3017655e-17 3.4436085e-13], sum to 1.0000
[2019-03-23 14:40:15,120] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5336
[2019-03-23 14:40:15,123] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 99.00000000000001, 1.0, 2.0, 0.2544552948523932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 276286.8159499725, 276286.8159499723, 83346.77965551271], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1015800.0000, 
sim time next is 1016400.0000, 
raw observation next is [14.0, 98.0, 1.0, 2.0, 0.2497246155963872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 271148.8263791167, 271148.8263791164, 82320.99427396923], 
processed observation next is [1.0, 0.782608695652174, 0.2727272727272727, 0.98, 1.0, 1.0, 0.06215576949548399, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1004254912515247, 0.10042549125152458, 0.2007829128633396], 
reward next is 0.7992, 
noisyNet noise sample is [array([-0.36597252], dtype=float32), -0.5856078]. 
=============================================
[2019-03-23 14:40:16,800] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 14:40:16,801] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:40:16,802] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:40:16,803] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:40:16,804] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:40:16,804] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:40:16,807] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:40:16,808] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:40:16,808] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:40:16,809] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:40:16,810] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:40:16,836] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run53
[2019-03-23 14:40:16,865] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run53
[2019-03-23 14:40:16,866] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run53
[2019-03-23 14:40:16,921] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run53
[2019-03-23 14:40:16,951] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run53
[2019-03-23 14:40:21,085] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05531754], dtype=float32), 0.24360208]
[2019-03-23 14:40:21,085] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.7, 69.0, 1.0, 2.0, 0.2184304613733413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 237150.5933750929, 237150.5933750925, 78352.44673063087]
[2019-03-23 14:40:21,086] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:40:21,088] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.6955664e-08 1.0000000e+00 1.1952382e-21 1.3770373e-16 6.3724841e-12], sampled 0.3467782699028453
[2019-03-23 14:41:15,919] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05531754], dtype=float32), 0.24360208]
[2019-03-23 14:41:15,920] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [13.65548855666666, 82.80662883166666, 1.0, 2.0, 0.2020090387469504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 219318.5540162996, 219318.5540162996, 75814.56435925215]
[2019-03-23 14:41:15,920] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:41:15,922] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.6628238e-08 1.0000000e+00 2.3770253e-20 1.3584898e-15 3.2278246e-11], sampled 0.840967454692135
[2019-03-23 14:41:38,166] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05531754], dtype=float32), 0.24360208]
[2019-03-23 14:41:38,167] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [28.85, 62.83333333333334, 1.0, 2.0, 0.5923491792506491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 667118.7158944302, 667118.7158944304, 157521.1133748182]
[2019-03-23 14:41:38,168] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:41:38,172] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.8463573e-09 1.0000000e+00 1.2219819e-22 2.4007678e-17 1.8527343e-12], sampled 0.6868537191262961
[2019-03-23 14:41:56,703] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05531754], dtype=float32), 0.24360208]
[2019-03-23 14:41:56,705] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.24125873, 97.92891054333333, 1.0, 2.0, 0.3990047249791869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 452063.4798574846, 452063.4798574846, 130533.0155041071]
[2019-03-23 14:41:56,706] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:41:56,712] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.7203765e-09 1.0000000e+00 2.4738149e-23 7.1229639e-18 7.8312915e-13], sampled 0.5879595335195372
[2019-03-23 14:42:00,217] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 14:42:00,277] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:42:00,301] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 14:42:00,302] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 14:42:00,552] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 14:42:01,571] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1300000, evaluation results [1300000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 14:42:04,069] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7744624e-08 1.0000000e+00 1.7271948e-20 1.1818854e-14 2.8244496e-10], sum to 1.0000
[2019-03-23 14:42:04,076] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5013
[2019-03-23 14:42:04,081] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 75.5, 1.0, 2.0, 0.3454476053062811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 383219.7862357486, 383219.7862357483, 117297.4686762034], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1110600.0000, 
sim time next is 1111200.0000, 
raw observation next is [19.66666666666667, 76.33333333333334, 1.0, 2.0, 0.3399436354999159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 375863.8556903786, 375863.8556903786, 116371.155125581], 
processed observation next is [1.0, 0.8695652173913043, 0.5303030303030305, 0.7633333333333334, 1.0, 1.0, 0.17492954437489486, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13920883544088095, 0.13920883544088095, 0.2838320856721488], 
reward next is 0.7162, 
noisyNet noise sample is [array([0.5993599], dtype=float32), -1.1604278]. 
=============================================
[2019-03-23 14:42:08,523] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6776280e-09 1.0000000e+00 1.3510811e-19 9.7767751e-16 5.1846383e-12], sum to 1.0000
[2019-03-23 14:42:08,534] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1595
[2019-03-23 14:42:08,537] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.524425208064203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 597025.8363248658, 597025.8363248655, 146092.7566254341], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1202400.0000, 
sim time next is 1203000.0000, 
raw observation next is [23.83333333333333, 84.0, 1.0, 2.0, 0.5249379835318629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 597658.9955382376, 597658.9955382376, 146118.8507153082], 
processed observation next is [1.0, 0.9565217391304348, 0.7196969696969695, 0.84, 1.0, 1.0, 0.40617247941482865, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2213551835326806, 0.2213551835326806, 0.3563874407690444], 
reward next is 0.6436, 
noisyNet noise sample is [array([-0.30691648], dtype=float32), -2.0776968]. 
=============================================
[2019-03-23 14:42:08,550] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[58.910946]
 [58.90757 ]
 [58.92442 ]
 [58.929504]
 [58.936108]], R is [[58.97797012]
 [59.03186798]
 [59.08542252]
 [59.13875961]
 [59.19185257]].
[2019-03-23 14:42:16,290] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.8952368e-07 9.9999964e-01 1.8799688e-16 1.0607179e-12 5.5292215e-10], sum to 1.0000
[2019-03-23 14:42:16,297] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2166
[2019-03-23 14:42:16,303] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1252319.895100971 W.
[2019-03-23 14:42:16,306] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 84.0, 1.0, 2.0, 0.3712704149946183, 1.0, 2.0, 0.3712704149946183, 1.0, 1.0, 0.7512209219873256, 6.9112, 6.9112, 77.3421103, 1252319.895100971, 1252319.895100971, 293987.3931541865], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1333800.0000, 
sim time next is 1334400.0000, 
raw observation next is [25.33333333333333, 82.33333333333334, 1.0, 2.0, 0.676191448418501, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9851790871317386, 6.911200000000001, 6.9112, 77.32846344354104, 1308554.557282788, 1308554.557282788, 295345.4663172151], 
processed observation next is [1.0, 0.43478260869565216, 0.7878787878787876, 0.8233333333333335, 1.0, 1.0, 0.5952393105231262, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9788272673310553, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4846498360306622, 0.4846498360306622, 0.7203547958956467], 
reward next is 0.2796, 
noisyNet noise sample is [array([-0.16077566], dtype=float32), -1.0985088]. 
=============================================
[2019-03-23 14:42:18,666] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.5397376e-09 1.0000000e+00 2.6621799e-22 6.1013628e-18 2.8872808e-13], sum to 1.0000
[2019-03-23 14:42:18,672] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8365
[2019-03-23 14:42:18,684] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4897925180367891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 558829.2895103826, 558829.2895103829, 140312.9875769284], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1390800.0000, 
sim time next is 1391400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4897040472589142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558728.3080988756, 558728.3080988756, 140302.8022483607], 
processed observation next is [0.0, 0.08695652173913043, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3621300590736427, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20693641040699096, 0.20693641040699096, 0.3422019567033188], 
reward next is 0.6578, 
noisyNet noise sample is [array([0.03992039], dtype=float32), -0.46120438]. 
=============================================
[2019-03-23 14:42:20,223] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.7363359e-08 9.9999988e-01 5.2077883e-20 9.4137430e-18 1.2296199e-11], sum to 1.0000
[2019-03-23 14:42:20,230] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7768
[2019-03-23 14:42:20,234] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4861667195887431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 554690.6103559606, 554690.6103559608, 139897.1356486845], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1406400.0000, 
sim time next is 1407000.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4858005534883408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 554272.6958953524, 554272.6958953522, 139855.083125778], 
processed observation next is [0.0, 0.2608695652173913, 0.5909090909090909, 1.0, 1.0, 1.0, 0.35725069186042596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20528618366494533, 0.20528618366494525, 0.341109958843361], 
reward next is 0.6589, 
noisyNet noise sample is [array([0.9114031], dtype=float32), 1.3173014]. 
=============================================
[2019-03-23 14:42:20,258] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[64.078896]
 [64.08095 ]
 [64.07939 ]
 [64.075745]
 [64.08782 ]], R is [[64.10280609]
 [64.12056732]
 [64.1379776 ]
 [64.15496826]
 [64.17160034]].
[2019-03-23 14:42:22,544] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.03192918e-09 1.00000000e+00 1.34117489e-20 1.07202814e-17
 1.30769028e-12], sum to 1.0000
[2019-03-23 14:42:22,555] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0692
[2019-03-23 14:42:22,560] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 97.0, 1.0, 2.0, 0.47712883238344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 544440.3679564478, 544440.3679564478, 138197.7518135987], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1449000.0000, 
sim time next is 1449600.0000, 
raw observation next is [21.0, 96.0, 1.0, 2.0, 0.4724862141768345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 539107.2107068903, 539107.2107068903, 137425.6236727647], 
processed observation next is [0.0, 0.782608695652174, 0.5909090909090909, 0.96, 1.0, 1.0, 0.3406077677210431, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19966933729884828, 0.19966933729884828, 0.3351844479823529], 
reward next is 0.6648, 
noisyNet noise sample is [array([-0.0060307], dtype=float32), 1.3657871]. 
=============================================
[2019-03-23 14:42:34,246] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.1579656e-09 1.0000000e+00 1.7268786e-20 2.7803020e-16 2.6068991e-13], sum to 1.0000
[2019-03-23 14:42:34,252] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0925
[2019-03-23 14:42:34,256] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.91666666666667, 67.16666666666666, 1.0, 2.0, 0.4458920869386437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 484705.3270421228, 484705.3270421231, 122316.9655155373], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1687800.0000, 
sim time next is 1688400.0000, 
raw observation next is [20.1, 66.0, 1.0, 2.0, 0.4489745472747571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 488190.2820966896, 488190.2820966899, 122617.3074822302], 
processed observation next is [1.0, 0.5652173913043478, 0.55, 0.66, 1.0, 1.0, 0.31121818409344637, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18081121559136654, 0.18081121559136665, 0.2990666036151956], 
reward next is 0.7009, 
noisyNet noise sample is [array([0.43076554], dtype=float32), -0.45186695]. 
=============================================
[2019-03-23 14:42:37,700] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2302704e-06 9.9999881e-01 5.5853993e-16 2.6301413e-12 1.6145353e-10], sum to 1.0000
[2019-03-23 14:42:37,709] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2537
[2019-03-23 14:42:37,715] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.0, 71.83333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 195663.5666720213, 195663.5666720216, 64329.63792762972], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1723800.0000, 
sim time next is 1724400.0000, 
raw observation next is [12.0, 71.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 193097.2009683561, 193097.2009683564, 63867.30099917544], 
processed observation next is [1.0, 1.0, 0.18181818181818182, 0.71, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07151748184013189, 0.071517481840132, 0.15577390487603765], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.733964], dtype=float32), -0.38595456]. 
=============================================
[2019-03-23 14:42:41,886] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.8848130e-09 1.0000000e+00 1.2261798e-22 6.0276380e-17 2.2518958e-13], sum to 1.0000
[2019-03-23 14:42:41,892] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7420
[2019-03-23 14:42:41,895] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 68.0, 1.0, 2.0, 0.209392923091588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 227346.7889397249, 227346.7889397249, 73326.79340555574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1843200.0000, 
sim time next is 1843800.0000, 
raw observation next is [16.33333333333334, 67.33333333333334, 1.0, 2.0, 0.2345534403954939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 254671.7828878961, 254671.7828878959, 76336.01778100972], 
processed observation next is [1.0, 0.34782608695652173, 0.37878787878787906, 0.6733333333333335, 1.0, 1.0, 0.04319180049436735, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09432288255107263, 0.09432288255107256, 0.18618540922197493], 
reward next is 0.8138, 
noisyNet noise sample is [array([-1.3367195], dtype=float32), 1.7400123]. 
=============================================
[2019-03-23 14:42:49,525] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.876921e-08 1.000000e+00 3.964657e-21 9.868497e-17 9.903816e-13], sum to 1.0000
[2019-03-23 14:42:49,531] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5381
[2019-03-23 14:42:49,534] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 62.0, 1.0, 2.0, 0.3182419799620467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 346880.1961164483, 346880.196116448, 112885.2548457385], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1981800.0000, 
sim time next is 1982400.0000, 
raw observation next is [21.0, 62.66666666666667, 1.0, 2.0, 0.3185895329045737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 347899.4605713063, 347899.4605713063, 113135.4576459969], 
processed observation next is [1.0, 0.9565217391304348, 0.5909090909090909, 0.6266666666666667, 1.0, 1.0, 0.1482369161307171, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1288516520634468, 0.1288516520634468, 0.27594014059999245], 
reward next is 0.7241, 
noisyNet noise sample is [array([0.02470542], dtype=float32), -0.43925577]. 
=============================================
[2019-03-23 14:42:50,113] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 14:42:50,114] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:42:50,115] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:42:50,115] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:42:50,116] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:42:50,117] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:42:50,117] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:42:50,117] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:42:50,118] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:42:50,118] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:42:50,118] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:42:50,141] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run54
[2019-03-23 14:42:50,171] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run54
[2019-03-23 14:42:50,201] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run54
[2019-03-23 14:42:50,201] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run54
[2019-03-23 14:42:50,226] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run54
[2019-03-23 14:43:01,889] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05616467], dtype=float32), 0.24784559]
[2019-03-23 14:43:01,890] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.83333333333333, 100.0, 1.0, 2.0, 0.6203586964080868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 696488.7595957062, 696488.7595957065, 146640.0992897169]
[2019-03-23 14:43:01,892] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:43:01,895] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.1404966e-08 1.0000000e+00 1.0753554e-22 1.6275102e-18 2.7756662e-12], sampled 0.788964957026283
[2019-03-23 14:43:01,999] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05616467], dtype=float32), 0.24784559]
[2019-03-23 14:43:01,999] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.0, 53.33333333333333, 1.0, 2.0, 0.6804184896071593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 775762.723140723, 775762.723140723, 166218.4847536548]
[2019-03-23 14:43:02,000] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:43:02,001] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.2072910e-08 1.0000000e+00 1.2564027e-22 1.8465056e-18 3.0132387e-12], sampled 0.7227154048692955
[2019-03-23 14:43:13,187] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05616467], dtype=float32), 0.24784559]
[2019-03-23 14:43:13,188] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.23333333333333, 89.66666666666667, 1.0, 2.0, 0.57930617925496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 657131.6905166904, 657131.69051669, 149952.8853121737]
[2019-03-23 14:43:13,190] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:43:13,195] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.3331213e-08 1.0000000e+00 1.6449461e-22 2.2977415e-18 3.4738970e-12], sampled 0.048162594907623424
[2019-03-23 14:43:26,423] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05616467], dtype=float32), 0.24784559]
[2019-03-23 14:43:26,427] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [28.06666666666667, 50.0, 1.0, 2.0, 0.4961389264578232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 565868.318668318, 565868.3186683176, 143799.0606115795]
[2019-03-23 14:43:26,428] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:43:26,432] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.8585910e-09 1.0000000e+00 2.7025034e-23 5.3073469e-19 1.3389618e-12], sampled 0.7844433840903413
[2019-03-23 14:44:20,020] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05616467], dtype=float32), 0.24784559]
[2019-03-23 14:44:20,021] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.572085855, 84.34213494833334, 1.0, 2.0, 0.3098052267634861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 336384.2062691808, 336384.2062691808, 116159.7456003585]
[2019-03-23 14:44:20,023] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:44:20,027] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.2161328e-09 1.0000000e+00 7.1788362e-24 1.8101891e-19 6.6511374e-13], sampled 0.33741375669449936
[2019-03-23 14:44:31,778] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05616467], dtype=float32), 0.24784559]
[2019-03-23 14:44:31,779] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.73159687, 88.79979638333333, 1.0, 2.0, 0.3931314747435851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 443659.4115166347, 443659.4115166343, 128916.6211941352]
[2019-03-23 14:44:31,781] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:44:31,783] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.5683448e-09 1.0000000e+00 8.9299804e-24 2.1612958e-19 7.4636965e-13], sampled 0.969038781253423
[2019-03-23 14:44:33,658] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 14:44:34,100] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 14:44:34,138] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 14:44:34,161] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:44:34,377] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 14:44:35,394] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1325000, evaluation results [1325000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 14:44:36,061] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.4275785e-07 9.9999952e-01 5.2243907e-24 3.3119504e-20 4.5577935e-13], sum to 1.0000
[2019-03-23 14:44:36,071] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2096
[2019-03-23 14:44:36,078] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 60.0, 1.0, 2.0, 0.3151583562743213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 342221.2135630365, 342221.2135630362, 112220.2752537371], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1980000.0000, 
sim time next is 1980600.0000, 
raw observation next is [21.0, 60.66666666666666, 1.0, 2.0, 0.3152274113490412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 342328.436152829, 342328.4361528287, 112236.7747084488], 
processed observation next is [1.0, 0.9565217391304348, 0.5909090909090909, 0.6066666666666666, 1.0, 1.0, 0.14403426418630147, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12678830968623295, 0.12678830968623284, 0.2737482309962166], 
reward next is 0.7263, 
noisyNet noise sample is [array([1.7798152], dtype=float32), -0.17867377]. 
=============================================
[2019-03-23 14:44:37,261] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3406687e-06 9.9999869e-01 2.7414833e-20 2.0452675e-16 5.2375108e-11], sum to 1.0000
[2019-03-23 14:44:37,267] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9799
[2019-03-23 14:44:37,276] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666666, 49.0, 1.0, 2.0, 0.3021953445136928, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 328140.3102178193, 328140.3102178196, 110007.4883088957], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2032800.0000, 
sim time next is 2033400.0000, 
raw observation next is [22.83333333333334, 48.0, 1.0, 2.0, 0.3041348351580997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 330247.0308303389, 330247.0308303392, 109679.3331105577], 
processed observation next is [0.0, 0.5217391304347826, 0.6742424242424245, 0.48, 1.0, 1.0, 0.1301685439476246, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12231371512234773, 0.12231371512234784, 0.26751056856233585], 
reward next is 0.7325, 
noisyNet noise sample is [array([-1.8821232], dtype=float32), 0.17846556]. 
=============================================
[2019-03-23 14:44:37,505] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.2186954e-09 1.0000000e+00 1.8558203e-25 9.6964866e-21 1.3914390e-13], sum to 1.0000
[2019-03-23 14:44:37,514] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7790
[2019-03-23 14:44:37,518] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666666, 49.0, 1.0, 2.0, 0.3021953445136928, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 328140.3102178193, 328140.3102178196, 110007.4883088957], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2032800.0000, 
sim time next is 2033400.0000, 
raw observation next is [22.83333333333334, 48.0, 1.0, 2.0, 0.3041348351580997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 330247.0308303389, 330247.0308303392, 109679.3331105577], 
processed observation next is [0.0, 0.5217391304347826, 0.6742424242424245, 0.48, 1.0, 1.0, 0.1301685439476246, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12231371512234773, 0.12231371512234784, 0.26751056856233585], 
reward next is 0.7325, 
noisyNet noise sample is [array([-0.10714352], dtype=float32), -0.17322278]. 
=============================================
[2019-03-23 14:44:44,558] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.0971998e-10 1.0000000e+00 8.0735420e-23 8.7117958e-20 4.9865411e-12], sum to 1.0000
[2019-03-23 14:44:44,568] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2891
[2019-03-23 14:44:44,576] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 53.0, 1.0, 2.0, 0.3035255726471639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 329585.23449695, 329585.2344969503, 111427.4679995431], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2154000.0000, 
sim time next is 2154600.0000, 
raw observation next is [22.0, 53.0, 1.0, 2.0, 0.2997755373016985, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 325511.8711854767, 325511.8711854764, 111175.7599243176], 
processed observation next is [0.0, 0.9565217391304348, 0.6363636363636364, 0.53, 1.0, 1.0, 0.12471942162712309, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1205599522909173, 0.12055995229091719, 0.2711603900593112], 
reward next is 0.7288, 
noisyNet noise sample is [array([0.33306196], dtype=float32), -0.2835086]. 
=============================================
[2019-03-23 14:44:48,840] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.6894486e-08 9.9999988e-01 1.4059177e-23 4.2482243e-18 2.8828741e-12], sum to 1.0000
[2019-03-23 14:44:48,843] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9133
[2019-03-23 14:44:48,849] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 86.0, 1.0, 2.0, 0.2007183842717476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 217926.3638899961, 217926.3638899961, 72695.78707766421], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2259600.0000, 
sim time next is 2260200.0000, 
raw observation next is [14.0, 84.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 215326.2861729199, 215326.2861729202, 71776.16138737391], 
processed observation next is [1.0, 0.13043478260869565, 0.2727272727272727, 0.84, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0797504763603407, 0.07975047636034081, 0.17506380826188758], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3639275], dtype=float32), -1.424294]. 
=============================================
[2019-03-23 14:44:55,097] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.9097866e-06 9.9999714e-01 2.0743525e-16 1.7737785e-14 1.4196287e-09], sum to 1.0000
[2019-03-23 14:44:55,107] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8491
[2019-03-23 14:44:55,110] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.16666666666667, 75.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 215276.7118204366, 215276.7118204366, 70261.29068350175], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2339400.0000, 
sim time next is 2340000.0000, 
raw observation next is [14.0, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 213660.4955176907, 213660.495517691, 70021.81739961472], 
processed observation next is [1.0, 0.08695652173913043, 0.2727272727272727, 0.77, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07913351685840396, 0.07913351685840407, 0.17078492048686517], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4793315], dtype=float32), -1.6074563]. 
=============================================
[2019-03-23 14:44:55,123] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[54.85772 ]
 [55.197052]
 [55.55087 ]
 [56.18501 ]
 [56.601482]], R is [[53.84793854]
 [53.30945969]
 [52.77636719]
 [53.07618713]
 [53.37262726]].
[2019-03-23 14:45:03,914] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0807823e-08 1.0000000e+00 1.0870688e-22 7.3262549e-19 4.6174935e-11], sum to 1.0000
[2019-03-23 14:45:03,923] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7650
[2019-03-23 14:45:03,929] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.83333333333333, 60.66666666666666, 1.0, 2.0, 0.475152046355885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516045.8670383243, 516045.8670383243, 124672.7901416243], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2551800.0000, 
sim time next is 2552400.0000, 
raw observation next is [21.0, 60.0, 1.0, 2.0, 0.4411395788840875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 479180.5530418289, 479180.5530418291, 121808.9940024942], 
processed observation next is [1.0, 0.5652173913043478, 0.5909090909090909, 0.6, 1.0, 1.0, 0.3014244736051093, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17747427890438108, 0.17747427890438114, 0.2970951073231566], 
reward next is 0.7029, 
noisyNet noise sample is [array([0.59573954], dtype=float32), -0.019893346]. 
=============================================
[2019-03-23 14:45:07,188] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.6798988e-10 1.0000000e+00 6.4195746e-23 2.7360227e-20 5.0297050e-13], sum to 1.0000
[2019-03-23 14:45:07,195] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0442
[2019-03-23 14:45:07,199] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 72.0, 1.0, 2.0, 0.2599453010548506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 282249.5783781422, 282249.5783781422, 88431.9095859092], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2592000.0000, 
sim time next is 2592600.0000, 
raw observation next is [17.63333333333333, 74.66666666666667, 1.0, 2.0, 0.2628124082844532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 285363.6074281866, 285363.6074281869, 91146.83642162471], 
processed observation next is [0.0, 0.0, 0.4378787878787877, 0.7466666666666667, 1.0, 1.0, 0.07851551035556646, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10569022497340244, 0.10569022497340257, 0.22230935712591393], 
reward next is 0.7777, 
noisyNet noise sample is [array([1.1788853], dtype=float32), -1.2090132]. 
=============================================
[2019-03-23 14:45:13,772] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.89142715e-10 1.00000000e+00 3.69959735e-22 5.97372132e-20
 1.01278985e-11], sum to 1.0000
[2019-03-23 14:45:13,781] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9974
[2019-03-23 14:45:13,791] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 63.66666666666667, 1.0, 2.0, 0.4520698171639598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 515553.430843838, 515553.4308438377, 134490.9865649538], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2733600.0000, 
sim time next is 2734200.0000, 
raw observation next is [25.5, 63.0, 1.0, 2.0, 0.453147782187876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516829.2896218686, 516829.2896218686, 134701.3770174593], 
processed observation next is [0.0, 0.6521739130434783, 0.7954545454545454, 0.63, 1.0, 1.0, 0.31643472773484493, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1914182554155069, 0.1914182554155069, 0.3285399439450227], 
reward next is 0.6715, 
noisyNet noise sample is [array([-0.2948082], dtype=float32), 0.123544976]. 
=============================================
[2019-03-23 14:45:14,673] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.4556015e-09 1.0000000e+00 2.4960652e-21 5.4570164e-17 9.3976493e-11], sum to 1.0000
[2019-03-23 14:45:14,678] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2995
[2019-03-23 14:45:14,686] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 63.66666666666667, 1.0, 2.0, 0.4520698171639598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 515553.430843838, 515553.4308438377, 134490.9865649538], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2733600.0000, 
sim time next is 2734200.0000, 
raw observation next is [25.5, 63.0, 1.0, 2.0, 0.453147782187876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516829.2896218686, 516829.2896218686, 134701.3770174593], 
processed observation next is [0.0, 0.6521739130434783, 0.7954545454545454, 0.63, 1.0, 1.0, 0.31643472773484493, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1914182554155069, 0.1914182554155069, 0.3285399439450227], 
reward next is 0.6715, 
noisyNet noise sample is [array([1.4270593], dtype=float32), 0.77342737]. 
=============================================
[2019-03-23 14:45:16,407] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1209600e-07 9.9999988e-01 7.1283653e-20 2.4871193e-15 6.2491484e-11], sum to 1.0000
[2019-03-23 14:45:16,414] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7823
[2019-03-23 14:45:16,416] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.416297274591592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 472807.5207987658, 472807.5207987658, 128647.4236175954], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2761200.0000, 
sim time next is 2761800.0000, 
raw observation next is [21.83333333333334, 78.0, 1.0, 2.0, 0.4134509686490962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 469183.6117769734, 469183.6117769731, 128075.1103911718], 
processed observation next is [0.0, 1.0, 0.628787878787879, 0.78, 1.0, 1.0, 0.26681371081137023, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1737717080655457, 0.1737717080655456, 0.3123783180272483], 
reward next is 0.6876, 
noisyNet noise sample is [array([1.143331], dtype=float32), -0.8494379]. 
=============================================
[2019-03-23 14:45:21,210] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.30640146e-05 9.99986887e-01 2.17090872e-13 1.18830015e-11
 1.08693792e-08], sum to 1.0000
[2019-03-23 14:45:21,214] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3543
[2019-03-23 14:45:21,217] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1575373.844604214 W.
[2019-03-23 14:45:21,225] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.83333333333333, 74.0, 1.0, 2.0, 0.700367740381705, 1.0, 1.0, 0.700367740381705, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1575373.844604214, 1575373.844604214, 291913.2775464331], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2890200.0000, 
sim time next is 2890800.0000, 
raw observation next is [27.0, 74.0, 1.0, 2.0, 0.852709873671752, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9865530188920543, 6.911200000000001, 6.9112, 77.32846344354104, 1507298.085876968, 1507298.085876968, 325262.3625383931], 
processed observation next is [1.0, 0.4782608695652174, 0.8636363636363636, 0.74, 1.0, 1.0, 0.81588734208969, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9807900269886491, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.558258550324803, 0.558258550324803, 0.7933228354594954], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.6015537], dtype=float32), 2.084592]. 
=============================================
[2019-03-23 14:45:23,693] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 14:45:23,698] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:45:23,701] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:45:23,702] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:45:23,703] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:45:23,703] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:45:23,704] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:45:23,704] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:45:23,704] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:45:23,706] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:45:23,708] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:45:23,728] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run55
[2019-03-23 14:45:23,729] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run55
[2019-03-23 14:45:23,729] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run55
[2019-03-23 14:45:23,811] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run55
[2019-03-23 14:45:23,840] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run55
[2019-03-23 14:45:41,295] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05410876], dtype=float32), 0.2510466]
[2019-03-23 14:45:41,297] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.78333333333333, 81.0, 1.0, 2.0, 0.4293511203427302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 488071.9362528394, 488071.9362528394, 134622.1771459594]
[2019-03-23 14:45:41,298] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:45:41,301] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.3645506e-09 1.0000000e+00 8.7198706e-21 6.2231966e-18 4.4849088e-13], sampled 0.9930143685986851
[2019-03-23 14:45:42,918] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05410876], dtype=float32), 0.2510466]
[2019-03-23 14:45:42,920] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.58649640166666, 97.62947360500002, 1.0, 2.0, 0.4979275678713441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 566198.0207203416, 566198.0207203416, 147594.0369568203]
[2019-03-23 14:45:42,921] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:45:42,926] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.2749779e-09 1.0000000e+00 1.2661036e-20 8.5747776e-18 5.6485377e-13], sampled 0.5829447649343314
[2019-03-23 14:46:05,475] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05410876], dtype=float32), 0.2510466]
[2019-03-23 14:46:05,477] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.723101025, 68.64992071, 1.0, 2.0, 0.2254291697051243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 244750.6585768914, 244750.6585768914, 81720.79251093967]
[2019-03-23 14:46:05,478] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:46:05,480] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.6764033e-09 1.0000000e+00 6.2836828e-21 4.6958133e-18 3.6617608e-13], sampled 0.823433149753756
[2019-03-23 14:46:16,526] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05410876], dtype=float32), 0.2510466]
[2019-03-23 14:46:16,526] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.83333333333334, 73.83333333333334, 1.0, 2.0, 0.827882781854829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 942637.6356048082, 942637.6356048082, 181884.8839131138]
[2019-03-23 14:46:16,527] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:46:16,530] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.3642669e-08 1.0000000e+00 2.1040187e-18 6.9377721e-16 1.3356364e-11], sampled 0.3349975032584068
[2019-03-23 14:46:55,589] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05410876], dtype=float32), 0.2510466]
[2019-03-23 14:46:55,591] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.8, 49.0, 1.0, 2.0, 0.3768955605950806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 424435.3962518426, 424435.3962518422, 126978.5948332862]
[2019-03-23 14:46:55,593] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:46:55,596] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.5817656e-09 1.0000000e+00 5.9884803e-21 4.5049592e-18 3.5545945e-13], sampled 0.5274816304828336
[2019-03-23 14:47:07,119] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:47:07,701] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 14:47:07,872] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5896 1663766061.8834 105.0000
[2019-03-23 14:47:07,913] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 14:47:08,054] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 14:47:09,072] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1350000, evaluation results [1350000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.58956291602, 1663766061.8834455, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 14:47:14,067] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.3153835e-09 1.0000000e+00 9.5799584e-24 8.4144050e-20 1.5155339e-11], sum to 1.0000
[2019-03-23 14:47:14,077] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1341
[2019-03-23 14:47:14,082] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 83.0, 1.0, 2.0, 0.3846391377603145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 432053.4160753345, 432053.4160753342, 122768.0491574353], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3022200.0000, 
sim time next is 3022800.0000, 
raw observation next is [19.66666666666667, 84.66666666666667, 1.0, 2.0, 0.3806071205500096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 426934.1949744721, 426934.1949744718, 122132.9241656498], 
processed observation next is [1.0, 1.0, 0.5303030303030305, 0.8466666666666667, 1.0, 1.0, 0.225758900687512, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15812377591647114, 0.15812377591647103, 0.2978851808918288], 
reward next is 0.7021, 
noisyNet noise sample is [array([0.7866997], dtype=float32), 0.6334482]. 
=============================================
[2019-03-23 14:47:20,631] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.3462898e-08 1.0000000e+00 5.1454161e-17 1.0613728e-14 9.6378316e-10], sum to 1.0000
[2019-03-23 14:47:20,640] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3995
[2019-03-23 14:47:20,644] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4963411889535252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 565576.4362925092, 565576.4362925094, 138552.6535543191], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3125400.0000, 
sim time next is 3126000.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4583725908524844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 522268.3428816432, 522268.3428816429, 134418.4125466612], 
processed observation next is [1.0, 0.17391304347826086, 0.6363636363636364, 0.83, 1.0, 1.0, 0.32296573856560545, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19343271958579378, 0.19343271958579367, 0.32784978669917364], 
reward next is 0.6722, 
noisyNet noise sample is [array([1.0359048], dtype=float32), -0.9160998]. 
=============================================
[2019-03-23 14:47:20,649] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.7076245e-06 9.9999416e-01 8.7670087e-15 4.4340720e-12 1.6032972e-07], sum to 1.0000
[2019-03-23 14:47:20,656] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1932
[2019-03-23 14:47:20,664] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[51.53492 ]
 [51.4213  ]
 [51.4027  ]
 [51.32124 ]
 [51.266094]], R is [[51.9385643 ]
 [52.08124542]
 [52.21848679]
 [52.3535347 ]
 [52.48332596]].
[2019-03-23 14:47:20,672] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1256223.428367987 W.
[2019-03-23 14:47:20,676] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.33333333333334, 72.0, 1.0, 2.0, 0.5514825713355642, 1.0, 1.0, 0.5514825713355642, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1256223.428367987, 1256223.428367987, 243014.7274500247], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3162000.0000, 
sim time next is 3162600.0000, 
raw observation next is [24.0, 73.5, 1.0, 2.0, 0.6707521064996801, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9709050392613212, 6.9112, 6.9112, 77.32846344354104, 1313849.849395435, 1313849.849395435, 281415.2270296354], 
processed observation next is [1.0, 0.6086956521739131, 0.7272727272727273, 0.735, 1.0, 1.0, 0.5884401331246001, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9584357703733161, 0.0, 0.0, 0.5084288129206541, 0.4866110553316426, 0.4866110553316426, 0.6863786025113059], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.16631754], dtype=float32), 0.08650736]. 
=============================================
[2019-03-23 14:47:21,430] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7050788e-04 9.9982846e-01 3.9431425e-13 9.2442096e-11 9.2080654e-07], sum to 1.0000
[2019-03-23 14:47:21,437] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4772
[2019-03-23 14:47:21,444] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1295347.507500761 W.
[2019-03-23 14:47:21,448] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 74.0, 1.0, 2.0, 0.3794007290811726, 1.0, 2.0, 0.3794007290811726, 1.0, 1.0, 0.7684759300545951, 6.911199999999999, 6.9112, 77.3421103, 1295347.507500761, 1295347.507500762, 290608.7544171299], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3168000.0000, 
sim time next is 3168600.0000, 
raw observation next is [24.0, 74.0, 1.0, 2.0, 0.5652511574001677, 1.0, 2.0, 0.5652511574001677, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1287161.111456948, 1287161.111456948, 246889.0637508043], 
processed observation next is [1.0, 0.6956521739130435, 0.7272727272727273, 0.74, 1.0, 1.0, 0.4565639467502096, 1.0, 1.0, 0.4565639467502096, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.47672633757664745, 0.47672633757664745, 0.6021684481726933], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.18775824], dtype=float32), 1.6277174]. 
=============================================
[2019-03-23 14:47:24,298] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.4931892e-10 1.0000000e+00 6.2577733e-22 1.0609786e-17 7.8973974e-09], sum to 1.0000
[2019-03-23 14:47:24,305] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7287
[2019-03-23 14:47:24,308] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 71.0, 1.0, 2.0, 0.3689228108112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 413402.8777354102, 413402.8777354102, 120938.5450274333], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3227400.0000, 
sim time next is 3228000.0000, 
raw observation next is [21.66666666666667, 70.33333333333334, 1.0, 2.0, 0.3696899764353451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 414581.7063083567, 414581.706308357, 121154.4849319177], 
processed observation next is [0.0, 0.34782608695652173, 0.6212121212121214, 0.7033333333333335, 1.0, 1.0, 0.2121124705441814, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1535487801142062, 0.1535487801142063, 0.29549874373638463], 
reward next is 0.7045, 
noisyNet noise sample is [array([-1.7331798], dtype=float32), 1.9277017]. 
=============================================
[2019-03-23 14:47:24,332] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[68.719765]
 [68.765976]
 [68.81577 ]
 [68.87622 ]
 [68.93873 ]], R is [[68.71643066]
 [68.73429108]
 [68.7527771 ]
 [68.7723999 ]
 [68.79309845]].
[2019-03-23 14:47:30,158] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2590132e-10 1.0000000e+00 2.5209545e-21 3.8475380e-18 2.5321101e-10], sum to 1.0000
[2019-03-23 14:47:30,167] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7926
[2019-03-23 14:47:30,173] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 57.0, 1.0, 2.0, 0.3366505400989062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 373613.8982195219, 373613.8982195219, 116683.702732262], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3324600.0000, 
sim time next is 3325200.0000, 
raw observation next is [23.33333333333334, 56.0, 1.0, 2.0, 0.3393437718448544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 377375.5865507106, 377375.5865507109, 117213.4527857926], 
processed observation next is [0.0, 0.4782608695652174, 0.6969696969696972, 0.56, 1.0, 1.0, 0.174179714806068, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13976873575952245, 0.13976873575952256, 0.28588647020925023], 
reward next is 0.7141, 
noisyNet noise sample is [array([-0.0212567], dtype=float32), -0.57574415]. 
=============================================
[2019-03-23 14:47:33,126] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.8631368e-06 9.9999714e-01 9.3276046e-18 3.8320063e-15 5.7996299e-08], sum to 1.0000
[2019-03-23 14:47:33,133] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8977
[2019-03-23 14:47:33,136] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3354254870604151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369209.5817493914, 369209.5817493914, 115391.4560911812], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3376800.0000, 
sim time next is 3377400.0000, 
raw observation next is [18.0, 88.00000000000001, 1.0, 2.0, 0.4266226241942785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469892.1434817704, 469892.1434817704, 122759.1205755852], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 0.8800000000000001, 1.0, 1.0, 0.28327828024284807, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1740341272154705, 0.1740341272154705, 0.2994124892087444], 
reward next is 0.7006, 
noisyNet noise sample is [array([0.19368136], dtype=float32), -1.4427382]. 
=============================================
[2019-03-23 14:47:38,370] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.6692853e-04 9.9901044e-01 3.8325105e-13 1.6887607e-10 8.2251424e-04], sum to 1.0000
[2019-03-23 14:47:38,375] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6575
[2019-03-23 14:47:38,379] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1301409.837847872 W.
[2019-03-23 14:47:38,383] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.33333333333334, 72.66666666666667, 1.0, 2.0, 0.5787107146547953, 1.0, 1.0, 0.5787107146547953, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1301409.837847872, 1301409.837847873, 256064.1488801088], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3496800.0000, 
sim time next is 3497400.0000, 
raw observation next is [26.5, 72.0, 1.0, 2.0, 0.5967157347242888, 1.0, 2.0, 0.5967157347242888, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1341947.659926348, 1341947.659926348, 261058.1433470844], 
processed observation next is [1.0, 0.4782608695652174, 0.8409090909090909, 0.72, 1.0, 1.0, 0.495894668405361, 1.0, 1.0, 0.495894668405361, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4970176518245733, 0.4970176518245733, 0.6367271788953278], 
reward next is 0.3633, 
noisyNet noise sample is [array([1.2958015], dtype=float32), 0.5652986]. 
=============================================
[2019-03-23 14:47:41,757] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.7931757e-06 9.9990880e-01 2.3888756e-16 2.2774117e-13 8.5320455e-05], sum to 1.0000
[2019-03-23 14:47:41,772] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0947
[2019-03-23 14:47:41,778] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5558705054222167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 633948.4382147196, 633948.4382147196, 148901.4920265753], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3555600.0000, 
sim time next is 3556200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5512157317161007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 628639.2317115108, 628639.2317115108, 148314.9625726976], 
processed observation next is [1.0, 0.13043478260869565, 0.6363636363636364, 0.94, 1.0, 1.0, 0.4390196646451259, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23282934507833733, 0.23282934507833733, 0.361743811152921], 
reward next is 0.6383, 
noisyNet noise sample is [array([-0.99519163], dtype=float32), 1.527808]. 
=============================================
[2019-03-23 14:47:57,931] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 14:47:57,932] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:47:57,932] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:47:57,933] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:47:57,937] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:47:57,935] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:47:57,938] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:47:57,937] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:47:57,940] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:47:57,940] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:47:57,940] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:47:57,962] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run56
[2019-03-23 14:47:57,990] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run56
[2019-03-23 14:47:57,991] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run56
[2019-03-23 14:47:58,019] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run56
[2019-03-23 14:47:58,071] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run56
[2019-03-23 14:48:05,062] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05410876], dtype=float32), 0.2566214]
[2019-03-23 14:48:05,065] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [13.45, 73.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 31.85675028, 181848.3144887299, 181848.3144887299, 50194.41830421897]
[2019-03-23 14:48:05,067] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:48:05,072] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.5816697e-06 9.9968052e-01 5.6084641e-18 8.7125495e-13 3.1591038e-04], sampled 0.6008213644080195
[2019-03-23 14:48:08,473] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05410876], dtype=float32), 0.2566214]
[2019-03-23 14:48:08,474] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.36666666666667, 62.66666666666667, 1.0, 2.0, 0.3000083746288785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 325743.974426015, 325743.9744260153, 115156.4309477769]
[2019-03-23 14:48:08,475] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:48:08,476] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.4299001e-06 9.9982339e-01 3.2756378e-19 1.1897873e-13 1.7518601e-04], sampled 0.9621088576487278
[2019-03-23 14:48:10,042] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05410876], dtype=float32), 0.2566214]
[2019-03-23 14:48:10,043] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.0, 100.0, 1.0, 2.0, 0.502706830734828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 564774.1228476957, 564774.122847696, 133954.3022511934]
[2019-03-23 14:48:10,043] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:48:10,045] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.7624358e-06 9.9972981e-01 2.5109591e-18 4.9605112e-13 2.6737983e-04], sampled 0.8347530166832595
[2019-03-23 14:48:19,227] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05410876], dtype=float32), 0.2566214]
[2019-03-23 14:48:19,227] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.6, 75.33333333333334, 1.0, 2.0, 0.3636799410535052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 406125.6884028686, 406125.6884028683, 124179.9888733144]
[2019-03-23 14:48:19,230] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:48:19,233] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.4851482e-06 9.9981910e-01 3.6828407e-19 1.2916294e-13 1.7949143e-04], sampled 0.9583916266465354
[2019-03-23 14:48:28,277] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05410876], dtype=float32), 0.2566214]
[2019-03-23 14:48:28,279] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.5, 91.0, 1.0, 2.0, 0.226443354031475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 245863.8447757002, 245863.8447757004, 78708.98932339865]
[2019-03-23 14:48:28,280] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:48:28,283] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.9895865e-06 9.9978143e-01 9.0988637e-19 2.4349606e-13 2.1658491e-04], sampled 0.8887207092047757
[2019-03-23 14:48:43,867] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05410876], dtype=float32), 0.2566214]
[2019-03-23 14:48:43,868] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.83333333333334, 70.66666666666667, 1.0, 2.0, 0.7616922082852932, 1.0, 2.0, 0.7616922082852932, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1713522.98331768, 1713522.98331768, 311862.0123710592]
[2019-03-23 14:48:43,869] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:48:43,872] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.2539073e-06 9.9964273e-01 9.5582076e-18 1.2658519e-12 3.5296095e-04], sampled 0.22653173448123887
[2019-03-23 14:48:43,873] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 1713522.98331768 W.
[2019-03-23 14:49:05,081] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05410876], dtype=float32), 0.2566214]
[2019-03-23 14:49:05,083] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.4694721, 83.08203352000001, 1.0, 2.0, 0.4369320117819759, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 498204.8355911853, 498204.8355911849, 137157.7362567103]
[2019-03-23 14:49:05,087] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:49:05,089] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.8850467e-06 9.9978894e-01 7.6984278e-19 2.1658348e-13 2.0919980e-04], sampled 0.9141952176897011
[2019-03-23 14:49:09,909] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05410876], dtype=float32), 0.2566214]
[2019-03-23 14:49:09,910] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.7, 79.0, 1.0, 2.0, 0.4558791881559908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 519652.1754336376, 519652.1754336376, 134469.0918500514]
[2019-03-23 14:49:09,910] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:49:09,912] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.7416035e-06 9.9979943e-01 6.0278021e-19 1.8244542e-13 1.9882435e-04], sampled 0.5216392552878218
[2019-03-23 14:49:14,978] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05410876], dtype=float32), 0.2566214]
[2019-03-23 14:49:14,980] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.2, 39.0, 1.0, 2.0, 0.3038888432643019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 329958.4776811024, 329958.4776811024, 88930.4339254289]
[2019-03-23 14:49:14,982] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:49:14,986] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.0501670e-06 9.9977714e-01 9.9841124e-19 2.5986540e-13 2.2079045e-04], sampled 0.3646017138603974
[2019-03-23 14:49:41,854] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8588.2260 1706332107.9874 465.0000
[2019-03-23 14:49:42,070] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683344126.8149 214.0000
[2019-03-23 14:49:42,157] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9055.6355 1656491361.5105 80.0000
[2019-03-23 14:49:42,289] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 14:49:42,320] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8507.2958 1773464082.9995 173.0000
[2019-03-23 14:49:43,337] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1375000, evaluation results [1375000.0, 8507.29577790628, 1773464082.9995422, 173.0, 9055.635522243152, 1656491361.5105107, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8588.226011853312, 1706332107.9874103, 465.0, 8575.160988882117, 1683344126.8148801, 214.0]
[2019-03-23 14:49:50,628] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.0489435e-05 9.9989808e-01 4.1016290e-14 4.6633486e-10 7.1364208e-05], sum to 1.0000
[2019-03-23 14:49:50,634] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1311
[2019-03-23 14:49:50,639] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333333, 92.0, 1.0, 2.0, 0.495852651193795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 544945.3850678536, 544945.385067854, 128541.2374050813], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4009200.0000, 
sim time next is 4009800.0000, 
raw observation next is [17.16666666666667, 93.0, 1.0, 2.0, 0.5041218993263257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 553572.0051103639, 553572.0051103639, 129158.6977863342], 
processed observation next is [1.0, 0.391304347826087, 0.4166666666666669, 0.93, 1.0, 1.0, 0.38015237415790704, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20502666855939405, 0.20502666855939405, 0.31502121411301026], 
reward next is 0.6850, 
noisyNet noise sample is [array([0.4983539], dtype=float32), 0.26256284]. 
=============================================
[2019-03-23 14:49:51,353] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.1979681e-07 9.9999857e-01 1.8930182e-19 2.1206503e-15 6.1335453e-07], sum to 1.0000
[2019-03-23 14:49:51,361] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0779
[2019-03-23 14:49:51,368] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 98.0, 1.0, 2.0, 0.3424978221246138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 377523.6845637545, 377523.6845637548, 116118.183218466], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4041600.0000, 
sim time next is 4042200.0000, 
raw observation next is [17.0, 99.0, 1.0, 2.0, 0.3427276462786484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 378459.847034556, 378459.8470345563, 116396.366917481], 
processed observation next is [1.0, 0.782608695652174, 0.4090909090909091, 0.99, 1.0, 1.0, 0.17840955784831045, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1401703137165022, 0.14017031371650235, 0.2838935778475146], 
reward next is 0.7161, 
noisyNet noise sample is [array([0.7677025], dtype=float32), -0.18174584]. 
=============================================
[2019-03-23 14:49:51,612] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.0903915e-07 9.9981588e-01 9.4721478e-21 8.3984204e-14 1.8352809e-04], sum to 1.0000
[2019-03-23 14:49:51,619] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1227
[2019-03-23 14:49:51,624] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 99.0, 1.0, 2.0, 0.4153773102625614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 460660.4165697526, 460660.4165697526, 122970.6909750915], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4020600.0000, 
sim time next is 4021200.0000, 
raw observation next is [17.0, 100.0, 1.0, 2.0, 0.4199678482831342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 465310.3075974668, 465310.3075974665, 123199.001691594], 
processed observation next is [1.0, 0.5652173913043478, 0.4090909090909091, 1.0, 1.0, 1.0, 0.27495981035391776, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17233715096202473, 0.17233715096202462, 0.3004853699794976], 
reward next is 0.6995, 
noisyNet noise sample is [array([-1.2352482], dtype=float32), -0.10105978]. 
=============================================
[2019-03-23 14:49:52,313] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.5571344e-07 9.9995017e-01 1.9841312e-21 8.8186785e-15 4.9413200e-05], sum to 1.0000
[2019-03-23 14:49:52,321] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8488
[2019-03-23 14:49:52,326] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 94.0, 1.0, 2.0, 0.3625333764933286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 401890.6257552498, 401890.6257552495, 118527.8610583792], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4036800.0000, 
sim time next is 4037400.0000, 
raw observation next is [17.5, 94.0, 1.0, 2.0, 0.3502312029572296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 387083.2220995162, 387083.2220995162, 117098.7535242938], 
processed observation next is [1.0, 0.7391304347826086, 0.4318181818181818, 0.94, 1.0, 1.0, 0.18778900369653698, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14336415633315414, 0.14336415633315414, 0.2856067159129117], 
reward next is 0.7144, 
noisyNet noise sample is [array([-1.2006508], dtype=float32), 0.37563533]. 
=============================================
[2019-03-23 14:49:52,735] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3332942e-07 9.9998903e-01 1.5100417e-21 1.7122429e-15 1.0800488e-05], sum to 1.0000
[2019-03-23 14:49:52,744] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1420
[2019-03-23 14:49:52,749] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 100.0, 1.0, 2.0, 0.3423917957058382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 378940.7548002168, 378940.7548002166, 116703.7724823179], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4047000.0000, 
sim time next is 4047600.0000, 
raw observation next is [17.0, 100.0, 1.0, 2.0, 0.3414959803010829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 377945.7247698671, 377945.7247698671, 116633.8486564676], 
processed observation next is [1.0, 0.8695652173913043, 0.4090909090909091, 1.0, 1.0, 1.0, 0.17686997537635363, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13997989806291372, 0.13997989806291372, 0.28447280160114047], 
reward next is 0.7155, 
noisyNet noise sample is [array([-1.0927324], dtype=float32), -0.7166284]. 
=============================================
[2019-03-23 14:49:52,964] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.9550318e-06 9.9990845e-01 1.8448219e-19 1.4254254e-13 8.3547144e-05], sum to 1.0000
[2019-03-23 14:49:52,975] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2515
[2019-03-23 14:49:52,981] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.16666666666667, 99.0, 1.0, 2.0, 0.3087723506458695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 335869.6510956623, 335869.651095662, 111987.3702567573], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4060200.0000, 
sim time next is 4060800.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.3066434216676769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 333101.3832790264, 333101.3832790267, 111684.9778994275], 
processed observation next is [1.0, 0.0, 0.36363636363636365, 1.0, 1.0, 1.0, 0.13330427708459608, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12337088269593571, 0.12337088269593582, 0.27240238512055487], 
reward next is 0.7276, 
noisyNet noise sample is [array([0.43813044], dtype=float32), 1.1151115]. 
=============================================
[2019-03-23 14:49:53,682] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5761682e-07 9.9999654e-01 5.5088414e-19 1.7344611e-13 3.3153203e-06], sum to 1.0000
[2019-03-23 14:49:53,689] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7692
[2019-03-23 14:49:53,695] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.83333333333334, 100.0, 1.0, 2.0, 0.3337089775873599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 367950.3294165458, 367950.3294165461, 115503.9377212311], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4085400.0000, 
sim time next is 4086000.0000, 
raw observation next is [17.0, 100.0, 1.0, 2.0, 0.3528872444011014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 390249.0375321093, 390249.037532109, 117393.9512162487], 
processed observation next is [1.0, 0.30434782608695654, 0.4090909090909091, 1.0, 1.0, 1.0, 0.19110905550137675, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1445366805674479, 0.14453668056744778, 0.2863267102835334], 
reward next is 0.7137, 
noisyNet noise sample is [array([0.5289638], dtype=float32), -0.9910502]. 
=============================================
[2019-03-23 14:49:53,709] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[69.18171 ]
 [69.233604]
 [69.30951 ]
 [69.41159 ]
 [69.46769 ]], R is [[69.06371307]
 [69.091362  ]
 [69.12036133]
 [69.15055847]
 [69.18234253]].
[2019-03-23 14:49:53,805] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.4857162e-07 9.9944788e-01 2.1804709e-17 1.4353637e-12 5.5151107e-04], sum to 1.0000
[2019-03-23 14:49:53,812] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6187
[2019-03-23 14:49:53,815] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.622074511099224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 699572.9680630157, 699572.968063016, 147379.2489082561], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4027200.0000, 
sim time next is 4027800.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.6248095502053795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 702660.8492792225, 702660.8492792229, 147708.136990939], 
processed observation next is [1.0, 0.6086956521739131, 0.45454545454545453, 1.0, 1.0, 1.0, 0.5310119377567244, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.26024475899230465, 0.26024475899230476, 0.3602637487583878], 
reward next is 0.6397, 
noisyNet noise sample is [array([0.84513533], dtype=float32), 0.37371802]. 
=============================================
[2019-03-23 14:49:58,354] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.9626992e-07 9.9993789e-01 1.3137306e-17 4.8480984e-13 6.1916362e-05], sum to 1.0000
[2019-03-23 14:49:58,359] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8305
[2019-03-23 14:49:58,364] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3751508713937937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 421150.57210872, 421150.5721087197, 121830.67542349], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4146000.0000, 
sim time next is 4146600.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3737615759361241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 419586.8975941552, 419586.8975941552, 121710.3512431394], 
processed observation next is [1.0, 1.0, 0.45454545454545453, 1.0, 1.0, 1.0, 0.21720196992015509, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15540255466450192, 0.15540255466450192, 0.29685451522716927], 
reward next is 0.7031, 
noisyNet noise sample is [array([0.49367666], dtype=float32), -0.6478581]. 
=============================================
[2019-03-23 14:50:02,958] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.6817472e-08 9.9999869e-01 1.3523420e-20 2.6383193e-13 1.2261039e-06], sum to 1.0000
[2019-03-23 14:50:02,963] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9407
[2019-03-23 14:50:02,968] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 73.0, 1.0, 2.0, 0.3722995342442969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416520.5610183658, 416520.5610183658, 120913.6645891307], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4219200.0000, 
sim time next is 4219800.0000, 
raw observation next is [21.0, 73.0, 1.0, 2.0, 0.3694187056996227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 413068.2036801926, 413068.2036801929, 120569.4749687512], 
processed observation next is [1.0, 0.8695652173913043, 0.5909090909090909, 0.73, 1.0, 1.0, 0.21177338212452837, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15298822358525652, 0.15298822358525663, 0.2940718901676858], 
reward next is 0.7059, 
noisyNet noise sample is [array([-1.2342076], dtype=float32), -0.7057355]. 
=============================================
[2019-03-23 14:50:03,623] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.2802468e-09 9.9986923e-01 6.6325603e-20 1.4387088e-14 1.3073701e-04], sum to 1.0000
[2019-03-23 14:50:03,631] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6977
[2019-03-23 14:50:03,634] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 94.0, 1.0, 2.0, 0.3544610466926438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 391102.2250125874, 391102.2250125874, 117176.3702294802], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4260600.0000, 
sim time next is 4261200.0000, 
raw observation next is [17.66666666666667, 94.0, 1.0, 2.0, 0.3575343182176052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 395582.9043864358, 395582.9043864358, 117831.3101160513], 
processed observation next is [1.0, 0.30434782608695654, 0.4393939393939396, 0.94, 1.0, 1.0, 0.19691789777200644, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14651218680979103, 0.14651218680979103, 0.2873934393074422], 
reward next is 0.7126, 
noisyNet noise sample is [array([1.6573195], dtype=float32), 0.26649156]. 
=============================================
[2019-03-23 14:50:05,900] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.9331112e-06 9.9672180e-01 1.7251839e-17 3.5609340e-14 3.2763069e-03], sum to 1.0000
[2019-03-23 14:50:05,906] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1597
[2019-03-23 14:50:05,910] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 53.00000000000001, 1.0, 2.0, 0.3971470042931016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 449556.1270071462, 449556.1270071465, 125764.4707361278], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4299600.0000, 
sim time next is 4300200.0000, 
raw observation next is [25.5, 54.0, 1.0, 2.0, 0.3979046242125559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 450511.6468039312, 450511.6468039314, 125896.8714815975], 
processed observation next is [1.0, 0.782608695652174, 0.7954545454545454, 0.54, 1.0, 1.0, 0.24738078026569485, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1668561654829375, 0.16685616548293755, 0.30706554019901827], 
reward next is 0.6929, 
noisyNet noise sample is [array([-0.47158894], dtype=float32), -1.1476579]. 
=============================================
[2019-03-23 14:50:17,416] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.7373583e-10 1.0000000e+00 6.1362048e-20 4.0901401e-18 6.3091660e-10], sum to 1.0000
[2019-03-23 14:50:17,425] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0113
[2019-03-23 14:50:17,430] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 73.0, 1.0, 2.0, 0.4259073460238201, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 484444.0094282533, 484444.009428253, 130191.6383685889], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4539600.0000, 
sim time next is 4540200.0000, 
raw observation next is [22.66666666666667, 73.0, 1.0, 2.0, 0.4193948231185016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476367.6687076163, 476367.6687076163, 128979.2088886736], 
processed observation next is [0.0, 0.5652173913043478, 0.6666666666666669, 0.73, 1.0, 1.0, 0.274243528898127, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17643246989170974, 0.17643246989170974, 0.31458343631383806], 
reward next is 0.6854, 
noisyNet noise sample is [array([-0.60615593], dtype=float32), 1.0439057]. 
=============================================
[2019-03-23 14:50:17,512] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8816981e-09 1.0000000e+00 1.8706720e-21 1.0041043e-17 3.7191366e-08], sum to 1.0000
[2019-03-23 14:50:17,521] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3464
[2019-03-23 14:50:17,524] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666667, 94.0, 1.0, 2.0, 0.4383851029291707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 498627.5137633288, 498627.5137633288, 131425.3319345372], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4499400.0000, 
sim time next is 4500000.0000, 
raw observation next is [20.0, 94.0, 1.0, 2.0, 0.4320873064960606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 491014.4479761011, 491014.4479761011, 130404.7890287598], 
processed observation next is [0.0, 0.08695652173913043, 0.5454545454545454, 0.94, 1.0, 1.0, 0.2901091331200757, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1818572029541115, 0.1818572029541115, 0.3180604610457556], 
reward next is 0.6819, 
noisyNet noise sample is [array([-2.4727118], dtype=float32), 0.7006515]. 
=============================================
[2019-03-23 14:50:17,537] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[73.468025]
 [73.57522 ]
 [73.63918 ]
 [73.62323 ]
 [73.66877 ]], R is [[73.36762238]
 [73.31340027]
 [73.25728607]
 [73.1993866 ]
 [73.13977814]].
[2019-03-23 14:50:18,068] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.1725842e-09 9.9999857e-01 6.9006339e-21 4.0284321e-16 1.4071942e-06], sum to 1.0000
[2019-03-23 14:50:18,076] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3875
[2019-03-23 14:50:18,078] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 61.0, 1.0, 2.0, 0.3913310162916228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 442412.4555508365, 442412.4555508365, 124884.4574292805], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4551600.0000, 
sim time next is 4552200.0000, 
raw observation next is [24.0, 61.0, 1.0, 2.0, 0.3923125423979942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 443523.9316239403, 443523.9316239406, 124974.3645226565], 
processed observation next is [0.0, 0.6956521739130435, 0.7272727272727273, 0.61, 1.0, 1.0, 0.2403906779974927, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16426812282368158, 0.1642681228236817, 0.3048155232259915], 
reward next is 0.6952, 
noisyNet noise sample is [array([-0.1668695], dtype=float32), -1.1878325]. 
=============================================
[2019-03-23 14:50:18,988] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2817781e-09 1.0000000e+00 9.9717859e-21 1.7733590e-16 2.9207321e-08], sum to 1.0000
[2019-03-23 14:50:18,994] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0228
[2019-03-23 14:50:19,000] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.4984969799084182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 568504.6540156854, 568504.6540156854, 141909.1799212786], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4527600.0000, 
sim time next is 4528200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5000855555840359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 570316.6669871402, 570316.6669871402, 142096.0399269016], 
processed observation next is [0.0, 0.391304347826087, 0.6363636363636364, 0.94, 1.0, 1.0, 0.37510694448004483, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2112283951804223, 0.2112283951804223, 0.3465757071387844], 
reward next is 0.6534, 
noisyNet noise sample is [array([-1.5628737], dtype=float32), 0.22552761]. 
=============================================
[2019-03-23 14:50:21,709] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.3510017e-08 9.9999857e-01 3.1842561e-19 9.5088046e-16 1.4695395e-06], sum to 1.0000
[2019-03-23 14:50:21,716] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2528
[2019-03-23 14:50:21,720] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 49.00000000000001, 1.0, 2.0, 0.5942862474110323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 648388.5955138078, 648388.5955138078, 136728.8734153759], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4623000.0000, 
sim time next is 4623600.0000, 
raw observation next is [23.0, 48.0, 1.0, 2.0, 0.4815633115062282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 523468.1698106312, 523468.1698106312, 125371.9344960197], 
processed observation next is [1.0, 0.5217391304347826, 0.6818181818181818, 0.48, 1.0, 1.0, 0.35195413938278525, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1938770999298634, 0.1938770999298634, 0.3057852060878529], 
reward next is 0.6942, 
noisyNet noise sample is [array([-1.1772043], dtype=float32), 0.6361442]. 
=============================================
[2019-03-23 14:50:22,180] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.06788205e-08 9.99999881e-01 8.71059394e-21 5.18164401e-15
 1.18845627e-07], sum to 1.0000
[2019-03-23 14:50:22,190] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0738
[2019-03-23 14:50:22,195] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 94.0, 1.0, 2.0, 0.2495449837612767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 270953.7293570595, 270953.7293570595, 86077.36931079661], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4590000.0000, 
sim time next is 4590600.0000, 
raw observation next is [14.83333333333333, 95.0, 1.0, 2.0, 0.2497509547084188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 271177.4331319206, 271177.4331319203, 85594.7251138538], 
processed observation next is [1.0, 0.13043478260869565, 0.3106060606060605, 0.95, 1.0, 1.0, 0.06218869338552348, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10043608634515577, 0.10043608634515566, 0.2087676222289117], 
reward next is 0.7912, 
noisyNet noise sample is [array([-1.6530324], dtype=float32), -0.8005665]. 
=============================================
[2019-03-23 14:50:24,971] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.23932621e-08 9.99998927e-01 1.13162815e-20 8.25543788e-17
 9.54552206e-07], sum to 1.0000
[2019-03-23 14:50:24,976] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9065
[2019-03-23 14:50:24,979] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.33333333333333, 80.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 216861.2004299085, 216861.2004299085, 71890.0118729576], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4688400.0000, 
sim time next is 4689000.0000, 
raw observation next is [14.5, 79.5, 1.0, 2.0, 0.2019267439237125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 219238.6142463947, 219238.6142463947, 72282.81792010613], 
processed observation next is [1.0, 0.2608695652173913, 0.29545454545454547, 0.795, 1.0, 1.0, 0.002408429904640595, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08119948675792396, 0.08119948675792396, 0.17629955590269789], 
reward next is 0.8237, 
noisyNet noise sample is [array([1.4611146], dtype=float32), -0.5048861]. 
=============================================
[2019-03-23 14:50:25,003] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[66.45816 ]
 [66.527016]
 [66.60144 ]
 [66.69612 ]
 [66.77574 ]], R is [[66.53134918]
 [65.86603546]
 [65.20737457]
 [64.55529785]
 [64.73389435]].
[2019-03-23 14:50:29,753] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.5205624e-08 9.9999642e-01 1.9307335e-19 1.5567629e-14 3.5341072e-06], sum to 1.0000
[2019-03-23 14:50:29,761] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3778
[2019-03-23 14:50:29,766] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333334, 63.66666666666666, 1.0, 2.0, 0.4124664948903213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468780.5607435126, 468780.5607435126, 128544.1994983271], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4729200.0000, 
sim time next is 4729800.0000, 
raw observation next is [24.16666666666666, 64.33333333333334, 1.0, 2.0, 0.4144184863130537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 470867.8784925463, 470867.8784925466, 128623.0556648894], 
processed observation next is [1.0, 0.7391304347826086, 0.7348484848484845, 0.6433333333333334, 1.0, 1.0, 0.2680231078913171, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17439551055279492, 0.17439551055279504, 0.31371476991436437], 
reward next is 0.6863, 
noisyNet noise sample is [array([-0.18461138], dtype=float32), 2.1621184]. 
=============================================
[2019-03-23 14:50:31,763] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 14:50:31,764] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:50:31,764] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:50:31,765] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:50:31,768] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:50:31,768] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:50:31,769] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:50:31,770] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:50:31,770] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:50:31,773] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:50:31,774] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:50:31,788] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run57
[2019-03-23 14:50:31,820] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run57
[2019-03-23 14:50:31,821] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run57
[2019-03-23 14:50:31,878] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run57
[2019-03-23 14:50:31,910] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run57
[2019-03-23 14:50:34,258] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05410876], dtype=float32), 0.2598022]
[2019-03-23 14:50:34,259] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.0, 79.5, 1.0, 2.0, 0.2164002898243642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 234956.8221804311, 234956.8221804308, 72691.25004909304]
[2019-03-23 14:50:34,259] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:50:34,262] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.2555334e-08 9.9999988e-01 1.3511743e-18 2.0346343e-14 1.3602012e-07], sampled 0.7769931182635401
[2019-03-23 14:50:39,708] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05410876], dtype=float32), 0.2598022]
[2019-03-23 14:50:39,710] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.91677156333333, 81.84437011666667, 1.0, 2.0, 0.3918168310420336, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 440107.2465748069, 440107.2465748069, 127712.8024767546]
[2019-03-23 14:50:39,711] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:50:39,713] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.8747278e-08 9.9999988e-01 8.8360705e-19 1.4679875e-14 1.1531136e-07], sampled 0.06457344489333461
[2019-03-23 14:50:46,153] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05410876], dtype=float32), 0.2598022]
[2019-03-23 14:50:46,154] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.62203224333333, 69.68971532333333, 1.0, 2.0, 0.5870415565917502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 663091.065479442, 663091.0654794417, 160596.0692259275]
[2019-03-23 14:50:46,154] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:50:46,156] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.0273772e-08 9.9999988e-01 1.0576038e-18 1.6853208e-14 1.2365936e-07], sampled 0.9200135949031795
[2019-03-23 14:50:52,232] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05410876], dtype=float32), 0.2598022]
[2019-03-23 14:50:52,233] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.13333333333333, 57.33333333333334, 1.0, 2.0, 0.3366624222103108, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 369375.3395733525, 369375.3395733525, 119358.1906457753]
[2019-03-23 14:50:52,234] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:50:52,236] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.7326331e-08 9.9999988e-01 7.3723723e-19 1.2772891e-14 1.0747790e-07], sampled 0.6393583082000894
[2019-03-23 14:50:52,582] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05410876], dtype=float32), 0.2598022]
[2019-03-23 14:50:52,584] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.41666666666667, 55.16666666666666, 1.0, 2.0, 0.6190446177836253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 702236.8796992177, 702236.8796992177, 154761.4413155811]
[2019-03-23 14:50:52,585] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:50:52,587] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.6649877e-08 9.9999988e-01 1.9820089e-18 2.7309213e-14 1.5785774e-07], sampled 0.003526805642116604
[2019-03-23 14:50:56,230] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05410876], dtype=float32), 0.2598022]
[2019-03-23 14:50:56,233] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.10273423, 49.10558169, 1.0, 2.0, 0.2859635029704174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 310490.3532329378, 310490.3532329375, 94943.96698060357]
[2019-03-23 14:50:56,233] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:50:56,235] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.4926689e-08 9.9999988e-01 5.2351387e-19 9.8181156e-15 9.4086204e-08], sampled 0.6392776574773871
[2019-03-23 14:51:04,265] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05410876], dtype=float32), 0.2598022]
[2019-03-23 14:51:04,266] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.07747038, 66.04747885166667, 1.0, 2.0, 0.370677406302547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 414408.576269206, 414408.576269206, 124965.8241996924]
[2019-03-23 14:51:04,267] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:51:04,272] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.5008910e-08 9.9999988e-01 5.3019635e-19 9.9140116e-15 9.4544752e-08], sampled 0.3583194328450471
[2019-03-23 14:51:06,956] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05410876], dtype=float32), 0.2598022]
[2019-03-23 14:51:06,957] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.0, 92.0, 1.0, 2.0, 0.3363004282628039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 372735.5079221652, 372735.5079221652, 116456.1069791395]
[2019-03-23 14:51:06,960] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:51:06,964] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.9543373e-08 9.9999988e-01 9.7214215e-19 1.5797766e-14 1.1967933e-07], sampled 0.4208471116101765
[2019-03-23 14:51:14,309] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05410876], dtype=float32), 0.2598022]
[2019-03-23 14:51:14,309] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.34164755666667, 72.61613313000001, 1.0, 2.0, 0.4075857751401327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 461688.4918175293, 461688.4918175289, 131267.5978866806]
[2019-03-23 14:51:14,310] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:51:14,316] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.3359440e-08 9.9999988e-01 4.0578743e-19 8.0723417e-15 8.5209855e-08], sampled 0.7668548072631856
[2019-03-23 14:51:27,462] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05410876], dtype=float32), 0.2598022]
[2019-03-23 14:51:27,464] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.15765099333333, 92.43221131333334, 1.0, 2.0, 0.3869785959067691, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 436206.5441280147, 436206.5441280147, 128083.3360711461]
[2019-03-23 14:51:27,466] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:51:27,470] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.33483855e-08 9.99999881e-01 4.04953946e-19 8.06006483e-15
 8.51490896e-08], sampled 0.6802449737359294
[2019-03-23 14:51:52,066] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05410876], dtype=float32), 0.2598022]
[2019-03-23 14:51:52,068] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.7, 53.0, 1.0, 2.0, 0.295298957558185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 320649.3655085969, 320649.3655085969, 104978.7847091586]
[2019-03-23 14:51:52,071] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:51:52,074] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.1669255e-08 9.9999988e-01 1.2325930e-18 1.8957138e-14 1.3123660e-07], sampled 0.04726331600605915
[2019-03-23 14:52:05,765] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05410876], dtype=float32), 0.2598022]
[2019-03-23 14:52:05,766] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.35710127666667, 75.84200171333333, 1.0, 2.0, 0.2200820366334811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 238944.069890949, 238944.069890949, 79751.68980900048]
[2019-03-23 14:52:05,766] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:52:05,770] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.93797138e-08 9.99999881e-01 9.53611964e-19 1.55649521e-14
 1.18782175e-07], sampled 0.45198257489283067
[2019-03-23 14:52:15,084] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:52:15,320] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05410876], dtype=float32), 0.2598022]
[2019-03-23 14:52:15,321] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.8, 45.0, 1.0, 2.0, 0.7149662754331695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 779818.9437451613, 779818.9437451615, 149795.5314819246]
[2019-03-23 14:52:15,321] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:52:15,326] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.0286324e-08 9.9999976e-01 8.5208760e-18 8.3756793e-14 2.7828079e-07], sampled 0.46661602267004776
[2019-03-23 14:52:15,905] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 14:52:15,934] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 14:52:16,215] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 14:52:16,228] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 14:52:17,246] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1400000, evaluation results [1400000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 14:52:29,779] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5544188e-10 1.0000000e+00 1.1531235e-24 1.1315312e-18 1.0664537e-11], sum to 1.0000
[2019-03-23 14:52:29,789] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4871
[2019-03-23 14:52:29,796] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 100.0, 1.0, 2.0, 0.2598901086342762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 282189.6328559078, 282189.6328559081, 93032.21892820136], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5036400.0000, 
sim time next is 5037000.0000, 
raw observation next is [15.33333333333333, 99.00000000000001, 1.0, 2.0, 0.2691842994999393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 292284.3318605743, 292284.331860574, 97367.85252260222], 
processed observation next is [0.0, 0.30434782608695654, 0.3333333333333332, 0.9900000000000001, 1.0, 1.0, 0.08648037437492408, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10825345624465715, 0.10825345624465704, 0.2374825671282981], 
reward next is 0.7625, 
noisyNet noise sample is [array([-0.12465558], dtype=float32), -2.3142943]. 
=============================================
[2019-03-23 14:52:29,813] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[78.25331]
 [78.3348 ]
 [78.38588]
 [78.44049]
 [78.50587]], R is [[78.15190125]
 [78.14347839]
 [78.14732361]
 [78.16094208]
 [78.18239594]].
[2019-03-23 14:52:33,402] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.7249345e-09 1.0000000e+00 9.6773407e-22 3.0452356e-16 1.8167261e-08], sum to 1.0000
[2019-03-23 14:52:33,408] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5306
[2019-03-23 14:52:33,412] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 53.00000000000001, 1.0, 2.0, 0.4112358447509502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 467335.4641109086, 467335.4641109086, 128386.9231319708], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5070000.0000, 
sim time next is 5070600.0000, 
raw observation next is [26.5, 52.5, 1.0, 2.0, 0.4127024564124548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 469149.0581890019, 469149.0581890022, 128653.1548879705], 
processed observation next is [0.0, 0.6956521739130435, 0.8409090909090909, 0.525, 1.0, 1.0, 0.26587807051556844, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1737589104403711, 0.1737589104403712, 0.31378818265358654], 
reward next is 0.6862, 
noisyNet noise sample is [array([0.8665026], dtype=float32), 2.0196707]. 
=============================================
[2019-03-23 14:52:42,032] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.1620701e-07 9.9986041e-01 1.1087084e-17 1.9827820e-12 1.3926810e-04], sum to 1.0000
[2019-03-23 14:52:42,040] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6346
[2019-03-23 14:52:42,047] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.05, 84.0, 1.0, 2.0, 0.346177790417595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 384225.0844092862, 384225.084409286, 117434.7359149652], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5283000.0000, 
sim time next is 5283600.0000, 
raw observation next is [18.96666666666667, 86.0, 1.0, 2.0, 0.3464860035917539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385471.2029143482, 385471.2029143482, 117835.1506809322], 
processed observation next is [1.0, 0.13043478260869565, 0.4984848484848486, 0.86, 1.0, 1.0, 0.18310750448969237, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14276711219049934, 0.14276711219049934, 0.287402806538859], 
reward next is 0.7126, 
noisyNet noise sample is [array([-2.1916013], dtype=float32), 0.25102526]. 
=============================================
[2019-03-23 14:52:45,036] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.3220434e-08 9.9999976e-01 8.5415982e-20 5.8975211e-15 1.8880000e-07], sum to 1.0000
[2019-03-23 14:52:45,047] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3162
[2019-03-23 14:52:45,054] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 79.0, 1.0, 2.0, 0.4677389748796388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 533698.0382902558, 533698.0382902558, 136965.1974531228], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5360400.0000, 
sim time next is 5361000.0000, 
raw observation next is [23.11666666666667, 79.33333333333334, 1.0, 2.0, 0.4659635051582689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 531633.2535090592, 531633.2535090592, 136582.0090406086], 
processed observation next is [1.0, 0.043478260869565216, 0.6871212121212124, 0.7933333333333334, 1.0, 1.0, 0.33245438144783607, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19690120500335526, 0.19690120500335526, 0.33312685131855757], 
reward next is 0.6669, 
noisyNet noise sample is [array([-0.73361695], dtype=float32), 1.0942919]. 
=============================================
[2019-03-23 14:52:45,084] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[69.02336]
 [69.01965]
 [69.17473]
 [69.3943 ]
 [69.66285]], R is [[68.85796356]
 [68.83532715]
 [68.81342316]
 [68.7922287 ]
 [68.7717514 ]].
[2019-03-23 14:52:54,542] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.8486071e-09 9.9999976e-01 2.7911894e-19 7.4903987e-15 2.5726359e-07], sum to 1.0000
[2019-03-23 14:52:54,551] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4060
[2019-03-23 14:52:54,558] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.6, 87.0, 1.0, 2.0, 0.4160188427884585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 471924.7984616075, 471924.7984616075, 128195.2314588226], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5536200.0000, 
sim time next is 5536800.0000, 
raw observation next is [20.5, 87.0, 1.0, 2.0, 0.4124618238421465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 467560.6498604667, 467560.6498604665, 127625.4587998891], 
processed observation next is [1.0, 0.08695652173913043, 0.5681818181818182, 0.87, 1.0, 1.0, 0.26557727980268314, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17317061105943213, 0.17317061105943202, 0.3112816068289978], 
reward next is 0.6887, 
noisyNet noise sample is [array([0.75821126], dtype=float32), -0.35178182]. 
=============================================
[2019-03-23 14:52:54,585] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.0727102e-06 9.9616325e-01 1.0558762e-17 8.4837557e-13 3.8347028e-03], sum to 1.0000
[2019-03-23 14:52:54,597] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6825
[2019-03-23 14:52:54,601] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 87.0, 1.0, 2.0, 0.4124618238421465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 467560.6498604667, 467560.6498604665, 127625.4587998891], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5536800.0000, 
sim time next is 5537400.0000, 
raw observation next is [20.5, 87.0, 1.0, 2.0, 0.6371087214155073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 81.63991234897068, 722549.597620219, 722549.5976202186, 154066.5050945131], 
processed observation next is [1.0, 0.08695652173913043, 0.5681818181818182, 0.87, 1.0, 1.0, 0.5463859017693842, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5367762641868508, 0.2676109620815626, 0.2676109620815625, 0.37577196364515386], 
reward next is 0.6242, 
noisyNet noise sample is [array([-1.4452678], dtype=float32), -0.37067395]. 
=============================================
[2019-03-23 14:52:58,946] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.1763021e-06 9.9997270e-01 1.7332546e-18 6.0284317e-12 2.5098858e-05], sum to 1.0000
[2019-03-23 14:52:58,952] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2644
[2019-03-23 14:52:58,955] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 96.0, 1.0, 2.0, 0.4285491876280844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 487476.4004411264, 487476.4004411267, 130478.5189374761], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5623200.0000, 
sim time next is 5623800.0000, 
raw observation next is [19.9, 96.0, 1.0, 2.0, 0.4266431829515718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 485119.504198365, 485119.5041983647, 130118.1576941789], 
processed observation next is [0.0, 0.08695652173913043, 0.5409090909090909, 0.96, 1.0, 1.0, 0.28330397868946466, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17967389044383889, 0.17967389044383877, 0.3173613602297046], 
reward next is 0.6826, 
noisyNet noise sample is [array([-0.4307448], dtype=float32), -0.45240703]. 
=============================================
[2019-03-23 14:53:03,188] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.3219938e-06 9.9611354e-01 9.1328095e-14 3.7348367e-11 3.8781003e-03], sum to 1.0000
[2019-03-23 14:53:03,193] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5387
[2019-03-23 14:53:03,199] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 86.0, 1.0, 2.0, 0.2410237734496106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 261698.9855944676, 261698.9855944673, 82758.16179115641], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5667000.0000, 
sim time next is 5667600.0000, 
raw observation next is [15.5, 85.0, 1.0, 2.0, 0.237670296663694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 258056.8789274671, 258056.8789274668, 81764.46842105639], 
processed observation next is [0.0, 0.6086956521739131, 0.3409090909090909, 0.85, 1.0, 1.0, 0.047087870829617476, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09557662182498781, 0.0955766218249877, 0.19942553273428387], 
reward next is 0.8006, 
noisyNet noise sample is [array([1.1130491], dtype=float32), -0.9024488]. 
=============================================
[2019-03-23 14:53:05,636] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 14:53:05,637] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:53:05,639] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:53:05,639] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:53:05,641] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:53:05,641] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:53:05,641] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:53:05,641] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:53:05,642] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:53:05,642] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:53:05,643] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:53:05,667] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run58
[2019-03-23 14:53:05,696] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run58
[2019-03-23 14:53:05,726] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run58
[2019-03-23 14:53:05,727] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run58
[2019-03-23 14:53:05,786] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run58
[2019-03-23 14:53:37,795] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05511156], dtype=float32), 0.26341182]
[2019-03-23 14:53:37,796] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.38333333333333, 77.66666666666666, 1.0, 2.0, 0.4730096420734682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 539622.3153959563, 539622.3153959559, 141670.8604146102]
[2019-03-23 14:53:37,798] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:53:37,802] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.6891914e-08 9.9997675e-01 9.1535942e-20 7.6141506e-14 2.3147530e-05], sampled 0.0803532604429612
[2019-03-23 14:53:48,980] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05511156], dtype=float32), 0.26341182]
[2019-03-23 14:53:48,981] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.55686085, 85.97171002, 1.0, 2.0, 0.4304090915804478, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 489997.924776966, 489997.9247769656, 135424.1270068458]
[2019-03-23 14:53:48,982] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:53:48,985] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.5141672e-08 9.9997079e-01 2.2881829e-19 1.4326120e-13 2.9051005e-05], sampled 0.4517168118459275
[2019-03-23 14:53:54,006] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05511156], dtype=float32), 0.26341182]
[2019-03-23 14:53:54,007] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.85, 73.5, 1.0, 2.0, 0.6560211275831194, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 745039.2429256842, 745039.2429256842, 168900.6311907125]
[2019-03-23 14:53:54,008] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:53:54,011] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.5425840e-07 9.9996030e-01 8.0041796e-19 3.3947704e-13 3.9619539e-05], sampled 0.39109747050097876
[2019-03-23 14:54:49,575] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.1075 1705984735.8565 465.0000
[2019-03-23 14:54:49,854] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8855.9603 1663827238.8538 105.0000
[2019-03-23 14:54:49,895] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8510.8651 1773269506.0279 173.0000
[2019-03-23 14:54:49,969] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 14:54:50,124] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:54:51,143] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1425000, evaluation results [1425000.0, 8510.865130870703, 1773269506.0278945, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8855.960256017452, 1663827238.8538203, 105.0, 8596.107540542158, 1705984735.8564615, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 14:54:54,449] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.2599968e-07 9.9997663e-01 4.7477546e-19 6.9900460e-13 2.2499333e-05], sum to 1.0000
[2019-03-23 14:54:54,459] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8208
[2019-03-23 14:54:54,465] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.23333333333333, 45.66666666666667, 1.0, 2.0, 0.2675941709372677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 290557.2307562046, 290557.2307562043, 85578.18071126458], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5768400.0000, 
sim time next is 5769000.0000, 
raw observation next is [21.05, 46.5, 1.0, 2.0, 0.2654252192183975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 288201.4569698457, 288201.4569698454, 85206.4301533498], 
processed observation next is [0.0, 0.782608695652174, 0.5931818181818183, 0.465, 1.0, 1.0, 0.08178152402299688, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1067412803592021, 0.106741280359202, 0.20782056134963364], 
reward next is 0.7922, 
noisyNet noise sample is [array([0.61798424], dtype=float32), -0.7160497]. 
=============================================
[2019-03-23 14:54:54,477] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[66.51166]
 [66.8638 ]
 [67.10632]
 [67.33557]
 [67.48439]], R is [[66.34597015]
 [66.4737854 ]
 [66.59945679]
 [66.72304535]
 [66.84421539]].
[2019-03-23 14:54:57,818] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.7342197e-07 9.9995720e-01 9.9709559e-18 1.7393805e-11 4.2166928e-05], sum to 1.0000
[2019-03-23 14:54:57,826] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9311
[2019-03-23 14:54:57,830] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 53.00000000000001, 1.0, 2.0, 0.3272190541156034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 359948.7914783374, 359948.7914783377, 114700.7885944955], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5862000.0000, 
sim time next is 5862600.0000, 
raw observation next is [23.0, 54.0, 1.0, 2.0, 0.327586524279858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 360808.2389943374, 360808.2389943374, 114900.092701756], 
processed observation next is [1.0, 0.8695652173913043, 0.6818181818181818, 0.54, 1.0, 1.0, 0.1594831553498225, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13363268110901386, 0.13363268110901386, 0.2802441285408683], 
reward next is 0.7198, 
noisyNet noise sample is [array([-1.1710722], dtype=float32), 1.1479977]. 
=============================================
[2019-03-23 14:55:06,561] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.3653658e-07 9.9946445e-01 1.4453377e-20 3.3359834e-15 5.3494994e-04], sum to 1.0000
[2019-03-23 14:55:06,567] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7300
[2019-03-23 14:55:06,574] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.45, 77.5, 1.0, 2.0, 0.2741875837665258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 297718.6354806091, 297718.6354806094, 94223.52150847187], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6046200.0000, 
sim time next is 6046800.0000, 
raw observation next is [17.36666666666667, 78.33333333333333, 1.0, 2.0, 0.2750171712288932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 298619.6955191426, 298619.6955191426, 94540.1360560606], 
processed observation next is [1.0, 1.0, 0.42575757575757595, 0.7833333333333333, 1.0, 1.0, 0.09377146403611647, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11059988722931208, 0.11059988722931208, 0.23058569769770879], 
reward next is 0.7694, 
noisyNet noise sample is [array([0.27845016], dtype=float32), 0.39535284]. 
=============================================
[2019-03-23 14:55:17,937] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.10647726e-07 9.99950409e-01 3.08592929e-17 7.00543844e-13
 4.94350352e-05], sum to 1.0000
[2019-03-23 14:55:17,945] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9910
[2019-03-23 14:55:17,952] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.45, 69.5, 1.0, 2.0, 0.5602523232433757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 632681.0035386332, 632681.0035386332, 152762.1672090777], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6269400.0000, 
sim time next is 6270000.0000, 
raw observation next is [27.0, 73.66666666666667, 1.0, 2.0, 0.5730497937783862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 645584.5932702341, 645584.5932702341, 154848.4161341115], 
processed observation next is [0.0, 0.5652173913043478, 0.8636363636363636, 0.7366666666666667, 1.0, 1.0, 0.4663122422229827, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2391054049149015, 0.2391054049149015, 0.3776790637417354], 
reward next is 0.6223, 
noisyNet noise sample is [array([0.6098491], dtype=float32), 0.3115389]. 
=============================================
[2019-03-23 14:55:17,968] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[64.3356  ]
 [64.25984 ]
 [64.201675]
 [64.1781  ]
 [64.13079 ]], R is [[64.36623383]
 [64.34998322]
 [64.33901215]
 [64.33310699]
 [64.33058929]].
[2019-03-23 14:55:20,061] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.644604e-08 9.999951e-01 7.408087e-18 2.950460e-12 4.920162e-06], sum to 1.0000
[2019-03-23 14:55:20,072] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1783
[2019-03-23 14:55:20,080] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 76.0, 1.0, 2.0, 0.4941707069433646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 563648.1612180007, 563648.1612180007, 141264.3354765124], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6310800.0000, 
sim time next is 6311400.0000, 
raw observation next is [24.21666666666667, 77.0, 1.0, 2.0, 0.4942403274583709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 563745.7384933794, 563745.7384933794, 141237.1387376797], 
processed observation next is [0.0, 0.043478260869565216, 0.7371212121212122, 0.77, 1.0, 1.0, 0.36780040932296354, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2087947179605109, 0.2087947179605109, 0.3444808261894627], 
reward next is 0.6555, 
noisyNet noise sample is [array([0.56470793], dtype=float32), -1.0115741]. 
=============================================
[2019-03-23 14:55:26,461] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.7852523e-08 9.9996829e-01 4.6321478e-19 8.5537453e-14 3.1720378e-05], sum to 1.0000
[2019-03-23 14:55:26,469] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9506
[2019-03-23 14:55:26,473] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 93.0, 1.0, 2.0, 0.7178274986643071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 815842.5020098819, 815842.5020098822, 164335.5356254702], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6432000.0000, 
sim time next is 6432600.0000, 
raw observation next is [20.0, 93.0, 1.0, 2.0, 0.7080396247433547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 804678.0197907799, 804678.0197907799, 162959.0832743647], 
processed observation next is [1.0, 0.43478260869565216, 0.5454545454545454, 0.93, 1.0, 1.0, 0.6350495309291934, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.29802889621880735, 0.29802889621880735, 0.3974611787179627], 
reward next is 0.6025, 
noisyNet noise sample is [array([1.6594037], dtype=float32), 0.5627176]. 
=============================================
[2019-03-23 14:55:31,076] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.6967035e-12 1.0000000e+00 3.9796822e-24 6.1773385e-17 1.4812593e-08], sum to 1.0000
[2019-03-23 14:55:31,086] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8533
[2019-03-23 14:55:31,092] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.58333333333334, 51.83333333333334, 1.0, 2.0, 0.4776530114824568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518763.5263250472, 518763.5263250472, 105929.3504304951], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6531000.0000, 
sim time next is 6531600.0000, 
raw observation next is [19.76666666666667, 51.66666666666667, 1.0, 2.0, 0.4704479462345661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 510934.2250188418, 510934.2250188418, 105642.5587535322], 
processed observation next is [1.0, 0.6086956521739131, 0.534848484848485, 0.5166666666666667, 1.0, 1.0, 0.33805993279320756, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1892348981551266, 0.1892348981551266, 0.2576647774476395], 
reward next is 0.7423, 
noisyNet noise sample is [array([-0.6969802], dtype=float32), -0.011265461]. 
=============================================
[2019-03-23 14:55:38,701] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.8916376e-08 9.9999964e-01 2.0159390e-20 3.4325981e-16 3.1324788e-07], sum to 1.0000
[2019-03-23 14:55:38,706] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4774
[2019-03-23 14:55:38,712] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.2, 88.0, 1.0, 2.0, 0.3787567044704468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 424442.3541211619, 424442.3541211621, 121777.8712016514], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6679200.0000, 
sim time next is 6679800.0000, 
raw observation next is [19.1, 88.5, 1.0, 2.0, 0.3735551285688242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 418395.6395305334, 418395.6395305331, 121235.2961611246], 
processed observation next is [1.0, 0.30434782608695654, 0.5045454545454546, 0.885, 1.0, 1.0, 0.21694391071103025, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15496134797427163, 0.15496134797427152, 0.29569584429542584], 
reward next is 0.7043, 
noisyNet noise sample is [array([0.59286267], dtype=float32), 2.9637804]. 
=============================================
[2019-03-23 14:55:39,426] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 14:55:39,428] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:55:39,429] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:55:39,430] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:55:39,431] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:55:39,431] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:55:39,432] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:55:39,432] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:55:39,433] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:55:39,434] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:55:39,435] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:55:39,454] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run59
[2019-03-23 14:55:39,481] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run59
[2019-03-23 14:55:39,482] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run59
[2019-03-23 14:55:39,536] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run59
[2019-03-23 14:55:39,567] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run59
[2019-03-23 14:56:22,193] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05572412], dtype=float32), 0.26758918]
[2019-03-23 14:56:22,195] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.0, 88.0, 1.0, 2.0, 0.3358244572849747, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 369647.3685958107, 369647.368595811, 115420.5526834254]
[2019-03-23 14:56:22,197] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:56:22,200] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.0856554e-08 9.9999893e-01 1.5845942e-18 7.1691358e-14 1.0303370e-06], sampled 0.14811315514733536
[2019-03-23 14:56:32,029] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05572412], dtype=float32), 0.26758918]
[2019-03-23 14:56:32,030] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.841866355, 97.84201514166668, 1.0, 2.0, 0.4524395862195262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 515340.3453511599, 515340.3453511595, 137959.4466192338]
[2019-03-23 14:56:32,031] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:56:32,037] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.6202509e-09 9.9999964e-01 7.9827194e-20 7.8426264e-15 3.7089609e-07], sampled 0.5916741271577084
[2019-03-23 14:56:37,989] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05572412], dtype=float32), 0.26758918]
[2019-03-23 14:56:37,990] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.1, 72.0, 1.0, 2.0, 0.5434951380688686, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 617423.8078952405, 617423.8078952401, 153519.2622340564]
[2019-03-23 14:56:37,991] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:56:37,997] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.4864784e-09 9.9999964e-01 7.5570213e-20 7.5288710e-15 3.6400928e-07], sampled 0.733322621617688
[2019-03-23 14:56:39,905] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05572412], dtype=float32), 0.26758918]
[2019-03-23 14:56:39,906] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.5, 72.0, 1.0, 2.0, 0.2532941036787239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 275010.8115666869, 275010.8115666865, 90735.13811711805]
[2019-03-23 14:56:39,907] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:56:39,910] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.1757447e-08 9.9999893e-01 1.7453891e-18 7.6993005e-14 1.0648515e-06], sampled 0.6327418101246058
[2019-03-23 14:56:45,957] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05572412], dtype=float32), 0.26758918]
[2019-03-23 14:56:45,958] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.41302163, 88.02532669, 1.0, 2.0, 0.521540831913888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 593310.4710241278, 593310.4710241278, 150294.8367195631]
[2019-03-23 14:56:45,963] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:56:45,967] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.7131797e-09 9.9999964e-01 8.2856233e-20 8.0606162e-15 3.7567884e-07], sampled 0.6621475185734633
[2019-03-23 14:56:49,735] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05572412], dtype=float32), 0.26758918]
[2019-03-23 14:56:49,736] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.8, 50.66666666666667, 1.0, 2.0, 0.8719565090542244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 994937.0121023188, 994937.0121023188, 196506.273393096]
[2019-03-23 14:56:49,737] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:56:49,741] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.9898956e-09 9.9999964e-01 6.0893334e-20 6.4161954e-15 3.3810662e-07], sampled 0.8373460355128647
[2019-03-23 14:56:57,585] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05572412], dtype=float32), 0.26758918]
[2019-03-23 14:56:57,586] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.23333333333333, 46.66666666666666, 1.0, 2.0, 0.328899983320567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 357123.3108556796, 357123.3108556793, 117479.8290437466]
[2019-03-23 14:56:57,587] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:56:57,590] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.6972608e-09 9.9999940e-01 2.7682002e-19 1.9687646e-14 5.6732722e-07], sampled 0.5590082441389608
[2019-03-23 14:57:23,589] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 14:57:23,812] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:57:23,823] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 14:57:23,903] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 14:57:24,027] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5599 1663815647.6096 105.0000
[2019-03-23 14:57:25,046] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1450000, evaluation results [1450000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.559925897878, 1663815647.6095803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 14:57:25,297] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.3531162e-10 9.9996126e-01 8.6361129e-21 1.9196685e-15 3.8698545e-05], sum to 1.0000
[2019-03-23 14:57:25,311] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7483
[2019-03-23 14:57:25,314] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.9, 95.66666666666666, 1.0, 2.0, 0.6780129081224632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 757637.1788000731, 757637.1788000731, 152033.282560957], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6694800.0000, 
sim time next is 6695400.0000, 
raw observation next is [17.8, 96.33333333333334, 1.0, 2.0, 0.6760204261429124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 755151.3326825527, 755151.3326825525, 151683.4661439443], 
processed observation next is [1.0, 0.4782608695652174, 0.4454545454545455, 0.9633333333333334, 1.0, 1.0, 0.5950255326786404, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.27968567877131584, 0.2796856787713157, 0.36995967352181536], 
reward next is 0.6300, 
noisyNet noise sample is [array([0.8981311], dtype=float32), -0.73110545]. 
=============================================
[2019-03-23 14:57:25,356] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.2447376e-08 9.9999893e-01 2.5914408e-19 3.8263019e-15 1.0262800e-06], sum to 1.0000
[2019-03-23 14:57:25,364] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9588
[2019-03-23 14:57:25,369] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.2, 93.66666666666666, 1.0, 2.0, 0.6518664969328933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 728779.9248950768, 728779.9248950768, 149041.7657164647], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6693000.0000, 
sim time next is 6693600.0000, 
raw observation next is [18.1, 94.33333333333334, 1.0, 2.0, 0.6693770697184795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 748370.1171846767, 748370.117184677, 151145.9321541288], 
processed observation next is [1.0, 0.4782608695652174, 0.45909090909090916, 0.9433333333333335, 1.0, 1.0, 0.5867213371480994, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.27717411747580617, 0.27717411747580634, 0.36864861501007024], 
reward next is 0.6314, 
noisyNet noise sample is [array([0.846837], dtype=float32), 1.0160451]. 
=============================================
[2019-03-23 14:57:39,914] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.1900204e-11 1.0000000e+00 2.1046314e-23 9.9455498e-18 1.7038095e-09], sum to 1.0000
[2019-03-23 14:57:39,923] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8388
[2019-03-23 14:57:39,927] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 57.0, 1.0, 2.0, 0.5077266587197536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 578725.3312198841, 578725.3312198845, 143413.3084323728], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6967800.0000, 
sim time next is 6968400.0000, 
raw observation next is [27.9, 57.33333333333333, 1.0, 2.0, 0.5057429721508258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576512.5992629589, 576512.5992629589, 143119.6784064651], 
processed observation next is [0.0, 0.6521739130434783, 0.9045454545454544, 0.5733333333333333, 1.0, 1.0, 0.38217871518853214, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21352318491220698, 0.21352318491220698, 0.349072386357232], 
reward next is 0.6509, 
noisyNet noise sample is [array([0.8662004], dtype=float32), 1.119654]. 
=============================================
[2019-03-23 14:57:46,765] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0599796e-08 9.9999952e-01 3.6834490e-19 1.0431012e-14 4.9061060e-07], sum to 1.0000
[2019-03-23 14:57:46,773] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1090
[2019-03-23 14:57:46,779] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3456071815157438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 384740.9426356054, 384740.9426356054, 117871.1779221092], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7099200.0000, 
sim time next is 7099800.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.3475163027314106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 386869.5431521937, 386869.5431521937, 118022.9771777035], 
processed observation next is [1.0, 0.17391304347826086, 0.44090909090909086, 0.97, 1.0, 1.0, 0.18439537841426323, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14328501598229396, 0.14328501598229396, 0.2878609199456183], 
reward next is 0.7121, 
noisyNet noise sample is [array([0.30661535], dtype=float32), -0.014669351]. 
=============================================
[2019-03-23 14:58:00,162] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4092132e-10 9.9999619e-01 3.9829099e-20 1.2014581e-16 3.7782993e-06], sum to 1.0000
[2019-03-23 14:58:00,176] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7691
[2019-03-23 14:58:00,182] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 87.0, 1.0, 2.0, 0.3199884337881482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 349480.3518388549, 349480.3518388549, 113252.5082287371], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7364400.0000, 
sim time next is 7365000.0000, 
raw observation next is [17.7, 87.0, 1.0, 2.0, 0.3226155095210239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 352360.7723392691, 352360.7723392688, 113441.8773758516], 
processed observation next is [1.0, 0.21739130434782608, 0.44090909090909086, 0.87, 1.0, 1.0, 0.15326938690127986, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13050398975528485, 0.13050398975528474, 0.27668750579476004], 
reward next is 0.7233, 
noisyNet noise sample is [array([-0.83050126], dtype=float32), -0.59983975]. 
=============================================
[2019-03-23 14:58:00,197] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[70.87885 ]
 [70.889244]
 [70.9215  ]
 [70.88323 ]
 [70.885666]], R is [[70.89322662]
 [70.90807343]
 [70.92323303]
 [70.9378891 ]
 [70.95027924]].
[2019-03-23 14:58:08,138] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1075767e-08 1.0000000e+00 2.1813120e-22 2.4564445e-17 6.6016415e-10], sum to 1.0000
[2019-03-23 14:58:08,140] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9240
[2019-03-23 14:58:08,144] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 93.0, 1.0, 2.0, 0.4586636368492726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 523120.3138738351, 523120.3138738351, 135282.0197497554], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7531200.0000, 
sim time next is 7531800.0000, 
raw observation next is [20.91666666666667, 94.16666666666666, 1.0, 2.0, 0.457272754421011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 521494.2436956788, 521494.2436956788, 135051.8565328335], 
processed observation next is [0.0, 0.17391304347826086, 0.5871212121212124, 0.9416666666666665, 1.0, 1.0, 0.32159094302626373, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19314601618358473, 0.19314601618358473, 0.32939477203130124], 
reward next is 0.6706, 
noisyNet noise sample is [array([-1.0621871], dtype=float32), -2.2836714]. 
=============================================
[2019-03-23 14:58:10,690] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.4238738e-09 9.9999988e-01 3.5862138e-20 3.6350906e-15 1.4023176e-07], sum to 1.0000
[2019-03-23 14:58:10,699] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5377
[2019-03-23 14:58:10,705] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.93333333333334, 57.33333333333333, 1.0, 2.0, 0.5049499030672342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 575592.5826675138, 575592.5826675138, 143044.3132764056], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7566000.0000, 
sim time next is 7566600.0000, 
raw observation next is [28.11666666666667, 56.66666666666667, 1.0, 2.0, 0.5063164206200538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 577075.5427733784, 577075.5427733784, 143292.5276372742], 
processed observation next is [0.0, 0.5652173913043478, 0.9143939393939395, 0.5666666666666668, 1.0, 1.0, 0.3828955257750672, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21373168250865868, 0.21373168250865868, 0.34949396984701026], 
reward next is 0.6505, 
noisyNet noise sample is [array([2.2892005], dtype=float32), -0.83903104]. 
=============================================
[2019-03-23 14:58:13,394] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 14:58:13,396] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:58:13,397] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:58:13,398] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:58:13,398] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:58:13,398] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:58:13,398] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:58:13,399] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:58:13,399] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:58:13,403] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:58:13,404] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:58:13,423] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run60
[2019-03-23 14:58:13,450] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run60
[2019-03-23 14:58:13,452] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run60
[2019-03-23 14:58:13,452] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run60
[2019-03-23 14:58:13,534] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run60
[2019-03-23 14:58:15,253] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05572412], dtype=float32), 0.27250427]
[2019-03-23 14:58:15,254] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.2, 46.33333333333334, 1.0, 2.0, 0.2551499808771689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 277026.270705029, 277026.2707050286, 80605.52174075703]
[2019-03-23 14:58:15,255] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:58:15,259] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.3538872e-09 9.9999988e-01 7.5040548e-19 3.1771081e-15 7.8048124e-08], sampled 0.6200680235073706
[2019-03-23 14:58:16,201] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05572412], dtype=float32), 0.27250427]
[2019-03-23 14:58:16,202] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.65856357, 65.87544214, 1.0, 2.0, 0.405949743423364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 445212.813582665, 445212.8135826646, 124674.8843031783]
[2019-03-23 14:58:16,205] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:58:16,207] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.1624751e-09 9.9999988e-01 1.2922738e-18 4.9144610e-15 9.6889877e-08], sampled 0.7816460799875163
[2019-03-23 14:58:21,915] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05572412], dtype=float32), 0.27250427]
[2019-03-23 14:58:21,917] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.71666666666667, 51.0, 1.0, 2.0, 0.2836968839311821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 308028.6975125758, 308028.6975125758, 86032.24780663438]
[2019-03-23 14:58:21,918] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:58:21,921] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.6246385e-09 9.9999988e-01 5.7580161e-19 2.5694384e-15 7.0256213e-08], sampled 0.025846513943131977
[2019-03-23 14:58:54,152] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05572412], dtype=float32), 0.27250427]
[2019-03-23 14:58:54,154] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.776066175, 85.79997368, 1.0, 2.0, 0.3427048744163328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 379559.4244376539, 379559.4244376535, 121154.717676839]
[2019-03-23 14:58:54,155] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:58:54,160] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.3384496e-09 1.0000000e+00 3.2741551e-19 1.6341195e-15 5.6144060e-08], sampled 0.01382448654053825
[2019-03-23 14:59:32,375] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05572412], dtype=float32), 0.27250427]
[2019-03-23 14:59:32,377] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.45, 52.0, 1.0, 2.0, 0.7178607787494842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 804581.1556219546, 804581.1556219546, 162387.7574493868]
[2019-03-23 14:59:32,377] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:59:32,380] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0189841e-08 9.9999988e-01 2.0918699e-18 7.2314472e-15 1.1733396e-07], sampled 0.25088531194151864
[2019-03-23 14:59:38,024] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05572412], dtype=float32), 0.27250427]
[2019-03-23 14:59:38,026] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [12.04867000833334, 91.56005786666667, 1.0, 2.0, 0.3488690171573995, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 378812.7468892559, 378812.7468892556, 88604.83265903145]
[2019-03-23 14:59:38,029] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:59:38,033] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.048613e-09 9.999999e-01 1.253442e-18 4.795895e-15 9.572035e-08], sampled 0.5033776686928609
[2019-03-23 14:59:57,194] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 14:59:57,349] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:59:57,522] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 14:59:57,688] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 14:59:57,937] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 14:59:58,954] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1475000, evaluation results [1475000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 14:59:59,824] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.6537879e-08 9.9999988e-01 8.2132640e-16 5.0852890e-12 1.3786821e-07], sum to 1.0000
[2019-03-23 14:59:59,835] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5525
[2019-03-23 14:59:59,844] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.93333333333333, 83.83333333333334, 1.0, 2.0, 0.8079926957404957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 922250.2736525857, 922250.2736525853, 184109.0277798601], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7635000.0000, 
sim time next is 7635600.0000, 
raw observation next is [23.3, 82.0, 1.0, 2.0, 0.8237619252601417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 940137.6226850963, 940137.6226850963, 187097.6129869782], 
processed observation next is [1.0, 0.391304347826087, 0.6954545454545454, 0.82, 1.0, 1.0, 0.779702406575177, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.34819911951299864, 0.34819911951299864, 0.45633564143165417], 
reward next is 0.5437, 
noisyNet noise sample is [array([-0.9345926], dtype=float32), -1.0525306]. 
=============================================
[2019-03-23 15:00:03,327] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.3117336e-11 1.0000000e+00 1.6721000e-22 2.8995155e-17 3.8530268e-09], sum to 1.0000
[2019-03-23 15:00:03,331] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3171
[2019-03-23 15:00:03,337] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.46666666666667, 99.0, 1.0, 2.0, 0.3847707133363872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 433706.648248483, 433706.6482484833, 123556.1284471774], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7702800.0000, 
sim time next is 7703400.0000, 
raw observation next is [18.38333333333333, 99.5, 1.0, 2.0, 0.3832308131274851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 431840.4271786676, 431840.4271786679, 123349.950129686], 
processed observation next is [1.0, 0.13043478260869565, 0.47196969696969676, 0.995, 1.0, 1.0, 0.22903851640935632, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15994089895506208, 0.1599408989550622, 0.30085353690167316], 
reward next is 0.6991, 
noisyNet noise sample is [array([1.0687925], dtype=float32), -0.44629207]. 
=============================================
[2019-03-23 15:00:06,817] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.4014241e-10 1.0000000e+00 6.2370698e-20 2.3017081e-17 3.7383352e-10], sum to 1.0000
[2019-03-23 15:00:06,826] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5261
[2019-03-23 15:00:06,830] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.35, 57.0, 1.0, 2.0, 0.6170866881585764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 670601.268183653, 670601.268183653, 138265.6083048681], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7731000.0000, 
sim time next is 7731600.0000, 
raw observation next is [21.26666666666667, 57.0, 1.0, 2.0, 0.5771885391951107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 626935.5696254858, 626935.5696254858, 134145.8263412662], 
processed observation next is [1.0, 0.4782608695652174, 0.6030303030303031, 0.57, 1.0, 1.0, 0.47148567399388835, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23219835912055029, 0.23219835912055029, 0.3271849422957712], 
reward next is 0.6728, 
noisyNet noise sample is [array([1.4392916], dtype=float32), -1.9723746]. 
=============================================
[2019-03-23 15:00:11,500] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.03361764e-09 9.99999881e-01 4.09227349e-20 6.78787269e-16
 1.12517135e-07], sum to 1.0000
[2019-03-23 15:00:11,504] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3471
[2019-03-23 15:00:11,510] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 44.0, 1.0, 2.0, 0.6423345621142275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 705066.7608673584, 705066.7608673584, 143122.9401458373], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7831800.0000, 
sim time next is 7832400.0000, 
raw observation next is [24.4, 43.33333333333334, 1.0, 2.0, 0.6594605788468885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 722403.1578411605, 722403.1578411605, 144541.3338368236], 
processed observation next is [1.0, 0.6521739130434783, 0.7454545454545454, 0.4333333333333334, 1.0, 1.0, 0.5743257235586106, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.26755672512635575, 0.26755672512635575, 0.35253983862639904], 
reward next is 0.6475, 
noisyNet noise sample is [array([-0.5149779], dtype=float32), 2.47615]. 
=============================================
[2019-03-23 15:00:11,757] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3768077e-10 9.9999988e-01 2.0850381e-22 6.6697434e-18 1.5009347e-07], sum to 1.0000
[2019-03-23 15:00:11,764] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6772
[2019-03-23 15:00:11,770] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 68.0, 1.0, 2.0, 0.2726796226387009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 296080.7612035716, 296080.7612035716, 95141.36949731369], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7866000.0000, 
sim time next is 7866600.0000, 
raw observation next is [18.8, 68.33333333333334, 1.0, 2.0, 0.2739158470385495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 297423.4878119642, 297423.4878119639, 95807.72775943864], 
processed observation next is [1.0, 0.043478260869565216, 0.49090909090909096, 0.6833333333333335, 1.0, 1.0, 0.09239480879818684, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11015684733776451, 0.1101568473377644, 0.23367738477911865], 
reward next is 0.7663, 
noisyNet noise sample is [array([-2.7093801], dtype=float32), -0.15842962]. 
=============================================
[2019-03-23 15:00:15,175] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.7145807e-09 1.0000000e+00 7.6730396e-21 1.5242232e-17 1.7182047e-09], sum to 1.0000
[2019-03-23 15:00:15,181] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1521
[2019-03-23 15:00:15,185] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.51666666666667, 91.33333333333334, 1.0, 2.0, 0.4671092429498302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 532929.5211347294, 532929.5211347296, 136661.2884619397], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7927800.0000, 
sim time next is 7928400.0000, 
raw observation next is [21.43333333333334, 91.66666666666667, 1.0, 2.0, 0.4672763517472082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 533096.4240530259, 533096.4240530255, 136594.9872231246], 
processed observation next is [1.0, 0.782608695652174, 0.6106060606060609, 0.9166666666666667, 1.0, 1.0, 0.33409543968401023, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19744312001963923, 0.1974431200196391, 0.3331585054222551], 
reward next is 0.6668, 
noisyNet noise sample is [array([-1.1268581], dtype=float32), 1.634768]. 
=============================================
[2019-03-23 15:00:16,502] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:00:16,503] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:00:16,521] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run8
[2019-03-23 15:00:16,549] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:00:16,550] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:00:16,555] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run8
[2019-03-23 15:00:16,705] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:00:16,705] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:00:16,708] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run8
[2019-03-23 15:00:16,732] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:00:16,733] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:00:16,737] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run8
[2019-03-23 15:00:16,774] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:00:16,775] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:00:16,779] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run8
[2019-03-23 15:00:16,897] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:00:16,897] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:00:16,900] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run8
[2019-03-23 15:00:17,039] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:00:17,039] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:00:17,042] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run8
[2019-03-23 15:00:17,207] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:00:17,207] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:00:17,210] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run8
[2019-03-23 15:00:17,288] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:00:17,289] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:00:17,292] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run8
[2019-03-23 15:00:17,330] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:00:17,330] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:00:17,334] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run8
[2019-03-23 15:00:17,368] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:00:17,369] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:00:17,373] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run8
[2019-03-23 15:00:17,462] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:00:17,462] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:00:17,494] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run8
[2019-03-23 15:00:17,597] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:00:17,598] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:00:17,633] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:00:17,633] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:00:17,636] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run8
[2019-03-23 15:00:17,733] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:00:17,733] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:00:17,736] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run8
[2019-03-23 15:00:17,835] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:00:17,835] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:00:17,837] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run8
[2019-03-23 15:00:17,903] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run8
[2019-03-23 15:00:22,698] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.9730593e-12 9.9999988e-01 1.8330129e-22 2.5694037e-19 8.6337700e-08], sum to 1.0000
[2019-03-23 15:00:22,705] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9764
[2019-03-23 15:00:22,712] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 77.0, 1.0, 2.0, 0.2288639656649875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 248492.7270186672, 248492.7270186672, 78791.02726619762], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 88200.0000, 
sim time next is 88800.0000, 
raw observation next is [16.0, 77.0, 1.0, 2.0, 0.2282252819928097, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 247799.0893108515, 247799.0893108512, 78725.62246343035], 
processed observation next is [1.0, 0.0, 0.36363636363636365, 0.77, 1.0, 1.0, 0.03528160249101211, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09177744048550056, 0.09177744048550045, 0.19201371332543987], 
reward next is 0.8080, 
noisyNet noise sample is [array([-1.2939886], dtype=float32), 0.50943685]. 
=============================================
[2019-03-23 15:00:23,566] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.4601662e-09 9.9999952e-01 1.6388769e-21 1.1583603e-17 4.1747958e-07], sum to 1.0000
[2019-03-23 15:00:23,574] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1205
[2019-03-23 15:00:23,588] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 77.0, 1.0, 2.0, 0.2292064699319111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 248864.7016678198, 248864.7016678198, 78834.05167137709], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 86400.0000, 
sim time next is 87000.0000, 
raw observation next is [16.0, 77.0, 1.0, 2.0, 0.2291025372818392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 248751.8262234036, 248751.8262234039, 78813.02835690317], 
processed observation next is [1.0, 0.0, 0.36363636363636365, 0.77, 1.0, 1.0, 0.036378171602299, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09213030600866799, 0.09213030600866812, 0.19222689843147114], 
reward next is 0.8078, 
noisyNet noise sample is [array([-0.27013078], dtype=float32), 0.6935315]. 
=============================================
[2019-03-23 15:00:23,603] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[66.42371 ]
 [67.655525]
 [67.69085 ]
 [67.741905]
 [67.809166]], R is [[65.73653412]
 [65.88689423]
 [66.03540802]
 [66.18182373]
 [66.3264389 ]].
[2019-03-23 15:00:24,976] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.1193965e-10 9.9999964e-01 4.2548196e-20 4.5783822e-17 3.0292162e-07], sum to 1.0000
[2019-03-23 15:00:24,984] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2147
[2019-03-23 15:00:24,988] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 60.0, 1.0, 2.0, 0.5101543297622095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 554082.277599553, 554082.277599553, 116287.1031650459], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 120600.0000, 
sim time next is 121200.0000, 
raw observation next is [20.0, 58.66666666666666, 1.0, 2.0, 0.5304738862748387, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 576164.57383426, 576164.5738342602, 120820.400270242], 
processed observation next is [1.0, 0.391304347826087, 0.5454545454545454, 0.5866666666666666, 1.0, 1.0, 0.41309235784354836, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21339428660528148, 0.21339428660528156, 0.29468390309815123], 
reward next is 0.7053, 
noisyNet noise sample is [array([-1.4542911], dtype=float32), 0.24003434]. 
=============================================
[2019-03-23 15:00:25,170] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.1657999e-13 1.0000000e+00 5.5724352e-27 3.9412856e-20 1.6116636e-10], sum to 1.0000
[2019-03-23 15:00:25,179] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6283
[2019-03-23 15:00:25,182] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 43.50000000000001, 1.0, 2.0, 0.774345672805553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 841270.7749014953, 841270.7749014953, 152232.3588122404], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 137400.0000, 
sim time next is 138000.0000, 
raw observation next is [23.0, 43.0, 1.0, 2.0, 0.6700114689624965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 727834.2753663481, 727834.2753663477, 138823.3388079054], 
processed observation next is [1.0, 0.6086956521739131, 0.6818181818181818, 0.43, 1.0, 1.0, 0.5875143362031207, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2695682501356845, 0.26956825013568436, 0.3385935092875742], 
reward next is 0.6614, 
noisyNet noise sample is [array([0.32904637], dtype=float32), 0.61812055]. 
=============================================
[2019-03-23 15:00:25,191] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[85.192444]
 [85.36638 ]
 [85.4204  ]
 [85.382324]
 [85.447586]], R is [[85.35494995]
 [85.13010406]
 [84.93992615]
 [84.766716  ]
 [84.60354614]].
[2019-03-23 15:00:25,528] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.3911098e-10 9.9999905e-01 8.3444534e-21 3.2129484e-16 9.6123290e-07], sum to 1.0000
[2019-03-23 15:00:25,541] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4393
[2019-03-23 15:00:25,547] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 38.5, 1.0, 2.0, 0.6701915350130709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 728030.0278762782, 728030.0278762782, 132763.0217126779], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 143400.0000, 
sim time next is 144000.0000, 
raw observation next is [23.0, 38.0, 1.0, 2.0, 0.684321446331434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 743391.1127446236, 743391.1127446236, 133954.4976473619], 
processed observation next is [1.0, 0.6956521739130435, 0.6818181818181818, 0.38, 1.0, 1.0, 0.6054018079142924, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.275330041757268, 0.275330041757268, 0.3267182869447851], 
reward next is 0.6733, 
noisyNet noise sample is [array([-0.31255376], dtype=float32), -1.7496438]. 
=============================================
[2019-03-23 15:00:25,556] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[72.34686 ]
 [72.37761 ]
 [72.315125]
 [72.19803 ]
 [72.18533 ]], R is [[72.30319214]
 [72.25634766]
 [72.20779419]
 [72.15219116]
 [72.09050751]].
[2019-03-23 15:00:33,650] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.00000000e+00 1.06983333e-19 0.00000000e+00 3.37595529e-38
 2.29019307e-30], sum to 1.0000
[2019-03-23 15:00:33,656] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4933
[2019-03-23 15:00:33,662] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.5, 60.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4401926251533454, 6.9112, 6.9112, 77.32846344354104, 256028.9262640737, 256028.9262640737, 86046.80171027336], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 300600.0000, 
sim time next is 301200.0000, 
raw observation next is [19.66666666666666, 58.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4451883905009746, 6.911199999999999, 6.9112, 77.32846344354104, 258935.3832114002, 258935.3832114004, 86115.96029777204], 
processed observation next is [0.0, 0.4782608695652174, 0.53030303030303, 0.5866666666666666, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.20741198642996372, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09590199378200008, 0.09590199378200015, 0.21003892755554154], 
reward next is 0.7900, 
noisyNet noise sample is [array([0.7210806], dtype=float32), 0.54303217]. 
=============================================
[2019-03-23 15:00:37,092] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9998450e-01 1.5190978e-05 8.0628781e-11 1.3917867e-09 3.0893958e-07], sum to 1.0000
[2019-03-23 15:00:37,099] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0195
[2019-03-23 15:00:37,103] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [13.0, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7426941873970825, 7.219170746004342, 6.9112, 77.32747635281945, 532172.25862205, 432150.9361902042, 97280.98673862008], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 370800.0000, 
sim time next is 371400.0000, 
raw observation next is [13.16666666666667, 76.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7446113479392694, 7.062533835212805, 6.9112, 68.48662830293067, 476762.4073374685, 433232.1620255879, 92478.82444361449], 
processed observation next is [1.0, 0.30434782608695654, 0.23484848484848497, 0.7616666666666667, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6351590684846706, 0.015133383521280486, 0.0, 0.45029441396336894, 0.1765786693842476, 0.16045635630577332, 0.22555810839905974], 
reward next is 0.0178, 
noisyNet noise sample is [array([-0.00533611], dtype=float32), -0.117872864]. 
=============================================
[2019-03-23 15:00:37,170] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.9999249e-01 7.1758359e-06 9.1523483e-11 1.1120703e-09 3.8056513e-07], sum to 1.0000
[2019-03-23 15:00:37,177] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3902
[2019-03-23 15:00:37,187] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [13.16666666666667, 76.16666666666667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7167490232146848, 6.911199999999999, 6.9112, 68.48716777491154, 416974.3018530942, 416974.3018530945, 80772.6768761981], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 371400.0000, 
sim time next is 372000.0000, 
raw observation next is [13.33333333333333, 75.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7193702304668158, 7.022616779767872, 6.9112, 77.32813036496418, 454677.9871730609, 418492.2518359761, 93077.47171738587], 
processed observation next is [1.0, 0.30434782608695654, 0.2424242424242423, 0.7533333333333334, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5991003292383084, 0.011141677976787178, 0.0, 0.5084266229541411, 0.16839925450854107, 0.15499713030962078, 0.22701822370094113], 
reward next is 0.2159, 
noisyNet noise sample is [array([-0.94362694], dtype=float32), 1.269674]. 
=============================================
[2019-03-23 15:00:37,203] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[24.232002]
 [24.695383]
 [25.535309]
 [23.817322]
 [23.187365]], R is [[25.5044651 ]
 [25.24942017]
 [25.75839996]
 [25.50081635]
 [25.24580765]].
[2019-03-23 15:00:46,694] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 9.4135446e-22 4.3792652e-34 3.8531253e-30 1.9297276e-23], sum to 1.0000
[2019-03-23 15:00:46,701] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6008
[2019-03-23 15:00:46,707] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.0, 94.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.607651477276844, 6.911199999999999, 6.9112, 77.32846344354104, 353463.2955960758, 353463.2955960761, 84394.06266775241], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 541800.0000, 
sim time next is 542400.0000, 
raw observation next is [14.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4162421473935778, 6.911200000000001, 6.9112, 77.32846344354104, 242095.1598567934, 242095.1598567931, 75739.33243804947], 
processed observation next is [1.0, 0.2608695652173913, 0.2727272727272727, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.166060210562254, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0896648740210346, 0.08966487402103449, 0.18473007911719383], 
reward next is 0.8153, 
noisyNet noise sample is [array([-0.83030313], dtype=float32), -2.00799]. 
=============================================
[2019-03-23 15:00:49,310] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 15:00:49,314] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:00:49,315] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:00:49,315] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:00:49,315] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:00:49,317] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:00:49,318] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:00:49,316] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:00:49,321] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:00:49,321] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:00:49,321] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:00:49,338] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run61
[2019-03-23 15:00:49,370] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run61
[2019-03-23 15:00:49,399] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run61
[2019-03-23 15:00:49,442] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run61
[2019-03-23 15:00:49,479] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run61
[2019-03-23 15:01:16,156] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05474765], dtype=float32), 0.27965045]
[2019-03-23 15:01:16,157] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.11666666666667, 89.83333333333333, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7301082101351654, 7.25663838368162, 6.9112, 95.55228484999081, 556339.9211857725, 417708.7284759731, 134944.2764111388]
[2019-03-23 15:01:16,157] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:01:16,161] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 3.6260157e-17 1.0261439e-27 1.8752705e-24 9.0242448e-19], sampled 0.3177994303321481
[2019-03-23 15:01:16,161] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 556339.9211857725 W.
[2019-03-23 15:01:18,921] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05474765], dtype=float32), 0.27965045]
[2019-03-23 15:01:18,922] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.80017600333334, 49.32109537666668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6923368985553954, 6.984824798616439, 6.9112, 95.5530412756471, 429108.5601561965, 399561.2517875436, 128357.4441739456]
[2019-03-23 15:01:18,924] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:01:18,927] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0000000e+00 2.4996517e-18 1.0988670e-31 1.2372748e-27 1.7187818e-20], sampled 0.9350497041319052
[2019-03-23 15:02:00,294] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05474765], dtype=float32), 0.27965045]
[2019-03-23 15:02:00,295] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.33333333333334, 60.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6872995055929838, 6.950672019798883, 6.9112, 95.55310650786252, 413122.1165463115, 397281.0852762342, 127385.7672726161]
[2019-03-23 15:02:00,297] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:02:00,299] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0000000e+00 1.5466906e-18 2.4802572e-32 3.7183470e-28 8.7367180e-21], sampled 0.043142677076338565
[2019-03-23 15:02:37,126] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6294.9961 1685630448.6673 3228.0000
[2019-03-23 15:02:37,600] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6862.2842 1793014293.7888 2409.0000
[2019-03-23 15:02:37,614] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6328.7217 1723294598.4314 3425.0000
[2019-03-23 15:02:37,622] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6481.6076 1678885180.2952 3057.0000
[2019-03-23 15:02:37,645] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6553.1725 1698634175.0084 2957.0000
[2019-03-23 15:02:38,658] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1500000, evaluation results [1500000.0, 6862.284208925443, 1793014293.78876, 2409.0, 6481.607577760913, 1678885180.2951708, 3057.0, 6294.9960618483565, 1685630448.6673346, 3228.0, 6328.721692698646, 1723294598.4313502, 3425.0, 6553.172466661831, 1698634175.0084193, 2957.0]
[2019-03-23 15:02:39,744] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 4.1892556e-20 1.4813683e-32 1.4401105e-29 1.1460567e-20], sum to 1.0000
[2019-03-23 15:02:39,754] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8065
[2019-03-23 15:02:39,758] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.16666666666667, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4857638998157879, 6.911199999999999, 6.9112, 77.32846344354104, 282542.2118609317, 282542.211860932, 91399.35267469345], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 611400.0000, 
sim time next is 612000.0000, 
raw observation next is [16.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4830296821712108, 6.9112, 6.9112, 77.32846344354104, 280951.4092715901, 280951.4092715901, 90655.41209874717], 
processed observation next is [1.0, 0.08695652173913043, 0.36363636363636365, 0.88, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.26147097453030116, 0.0, 0.0, 0.5084288129206541, 0.10405607750799634, 0.10405607750799634, 0.2211107612164565], 
reward next is 0.7789, 
noisyNet noise sample is [array([-1.1007909], dtype=float32), 0.05625714]. 
=============================================
[2019-03-23 15:02:39,773] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[73.015686]
 [72.567024]
 [72.18537 ]
 [72.05198 ]
 [72.14827 ]], R is [[73.17570496]
 [73.22102356]
 [73.26374817]
 [73.30365753]
 [73.34108734]].
[2019-03-23 15:02:44,150] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 5.8686420e-14 1.7099292e-25 1.3254530e-21 4.3717485e-14], sum to 1.0000
[2019-03-23 15:02:44,157] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0016
[2019-03-23 15:02:44,164] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.66666666666667, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6234242162641953, 6.911199999999999, 6.9112, 77.32846344354104, 362311.4906720745, 362311.4906720748, 115678.5251423779], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 699600.0000, 
sim time next is 700200.0000, 
raw observation next is [16.5, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5864416109890361, 6.911199999999999, 6.9112, 77.32846344354104, 340999.5972446789, 340999.5972446792, 111052.4064490775], 
processed observation next is [1.0, 0.08695652173913043, 0.38636363636363635, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4092023014129088, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12629614712765885, 0.12629614712765896, 0.2708595279245793], 
reward next is 0.7291, 
noisyNet noise sample is [array([0.9704144], dtype=float32), -1.3293405]. 
=============================================
[2019-03-23 15:03:01,936] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.3125410e-07 9.9999940e-01 1.3244695e-13 1.4737058e-12 1.4675497e-07], sum to 1.0000
[2019-03-23 15:03:01,947] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3301
[2019-03-23 15:03:01,954] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.16666666666667, 99.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 189535.1636603689, 189535.1636603691, 66614.60605883678], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1039800.0000, 
sim time next is 1040400.0000, 
raw observation next is [12.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 187160.2473436404, 187160.2473436404, 66059.97599449342], 
processed observation next is [1.0, 0.043478260869565216, 0.18181818181818182, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.06931861012727422, 0.06931861012727422, 0.16112189266949614], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3000971], dtype=float32), 1.0138355]. 
=============================================
[2019-03-23 15:03:05,176] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2583332e-07 9.9999988e-01 4.7345564e-18 5.1259618e-17 1.2243999e-09], sum to 1.0000
[2019-03-23 15:03:05,183] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6952
[2019-03-23 15:03:05,187] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 75.5, 1.0, 2.0, 0.3454476053062811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 383219.7862357486, 383219.7862357483, 117297.4686762034], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1110600.0000, 
sim time next is 1111200.0000, 
raw observation next is [19.66666666666667, 76.33333333333334, 1.0, 2.0, 0.3399436354999159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 375863.8556903786, 375863.8556903786, 116371.155125581], 
processed observation next is [1.0, 0.8695652173913043, 0.5303030303030305, 0.7633333333333334, 1.0, 1.0, 0.17492954437489486, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13920883544088095, 0.13920883544088095, 0.2838320856721488], 
reward next is 0.7162, 
noisyNet noise sample is [array([-0.91934675], dtype=float32), -0.42346555]. 
=============================================
[2019-03-23 15:03:06,549] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.1397242e-05 9.9998856e-01 5.5019442e-14 6.5514689e-13 5.2404037e-08], sum to 1.0000
[2019-03-23 15:03:06,557] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8151
[2019-03-23 15:03:06,561] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 96.0, 1.0, 2.0, 0.3527698955115632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 393637.8619383592, 393637.8619383589, 118837.7467651146], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1146000.0000, 
sim time next is 1146600.0000, 
raw observation next is [18.0, 97.0, 1.0, 2.0, 0.3559486853877217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 397760.2995952362, 397760.2995952365, 119350.112718232], 
processed observation next is [1.0, 0.2608695652173913, 0.45454545454545453, 0.97, 1.0, 1.0, 0.19493585673465208, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1473186294797171, 0.14731862947971722, 0.2910978358981268], 
reward next is 0.7089, 
noisyNet noise sample is [array([1.1253484], dtype=float32), 1.3557119]. 
=============================================
[2019-03-23 15:03:08,573] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9405076e-07 9.9999976e-01 2.6599454e-15 1.1791504e-12 2.8867342e-10], sum to 1.0000
[2019-03-23 15:03:08,578] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8347
[2019-03-23 15:03:08,585] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1201040.435037719 W.
[2019-03-23 15:03:08,590] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.83333333333333, 66.66666666666666, 1.0, 2.0, 0.3555619951852268, 1.0, 2.0, 0.3555619951852268, 1.0, 1.0, 0.7185376147916526, 6.911199999999999, 6.9112, 77.3421103, 1201040.435037719, 1201040.43503772, 285981.6310879065], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1173000.0000, 
sim time next is 1173600.0000, 
raw observation next is [27.0, 66.0, 1.0, 2.0, 0.379231408201241, 1.0, 2.0, 0.379231408201241, 1.0, 2.0, 0.7659516940723059, 6.911199999999999, 6.9112, 77.3421103, 1279412.439119192, 1279412.439119192, 296872.5315082897], 
processed observation next is [1.0, 0.6086956521739131, 0.8636363636363636, 0.66, 1.0, 1.0, 0.22403926025155124, 1.0, 1.0, 0.22403926025155124, 1.0, 1.0, 0.6656452772461513, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4738564589330341, 0.4738564589330341, 0.72407934514217], 
reward next is 0.2759, 
noisyNet noise sample is [array([1.1984082], dtype=float32), 0.6235845]. 
=============================================
[2019-03-23 15:03:08,706] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.4817614e-08 9.9999988e-01 1.1248701e-16 8.8208032e-14 7.0932531e-12], sum to 1.0000
[2019-03-23 15:03:08,714] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6671
[2019-03-23 15:03:08,717] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 72.0, 1.0, 2.0, 0.5160260420135643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 587798.0108775267, 587798.0108775267, 144795.2132463963], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1193400.0000, 
sim time next is 1194000.0000, 
raw observation next is [25.33333333333333, 72.66666666666666, 1.0, 2.0, 0.5150250510274917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 586775.8781582294, 586775.8781582294, 144566.8110241953], 
processed observation next is [1.0, 0.8260869565217391, 0.7878787878787876, 0.7266666666666666, 1.0, 1.0, 0.39378131378436465, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21732439931786274, 0.21732439931786274, 0.3526019781077934], 
reward next is 0.6474, 
noisyNet noise sample is [array([-0.71724135], dtype=float32), 1.662616]. 
=============================================
[2019-03-23 15:03:08,728] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[55.47373 ]
 [55.2488  ]
 [54.38357 ]
 [53.900562]
 [53.5386  ]], R is [[55.64480591]
 [55.73519897]
 [55.82411957]
 [55.91146851]
 [55.9975853 ]].
[2019-03-23 15:03:10,938] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.4221149e-08 9.9999988e-01 3.9505640e-17 1.4804440e-14 1.8607013e-13], sum to 1.0000
[2019-03-23 15:03:10,945] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9841
[2019-03-23 15:03:10,953] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 94.0, 1.0, 2.0, 0.4987709794572391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 569120.9531664018, 569120.9531664016, 141165.5338775147], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1237200.0000, 
sim time next is 1237800.0000, 
raw observation next is [21.83333333333334, 94.0, 1.0, 2.0, 0.4951394823610286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564880.0538195468, 564880.0538195468, 141093.6761205566], 
processed observation next is [1.0, 0.30434782608695654, 0.628787878787879, 0.94, 1.0, 1.0, 0.36892435295128573, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2092148347479803, 0.2092148347479803, 0.34413091736721124], 
reward next is 0.6559, 
noisyNet noise sample is [array([1.8606619], dtype=float32), -0.7613221]. 
=============================================
[2019-03-23 15:03:13,758] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.5483648e-08 1.0000000e+00 5.0531736e-18 2.4521555e-14 6.8777359e-11], sum to 1.0000
[2019-03-23 15:03:13,767] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9249
[2019-03-23 15:03:13,775] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 98.0, 1.0, 2.0, 0.3772304345175962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 422557.2128306634, 422557.2128306631, 121566.4605765723], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1290000.0000, 
sim time next is 1290600.0000, 
raw observation next is [18.0, 97.0, 1.0, 2.0, 0.3749921202029073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 419469.2839158336, 419469.2839158339, 121110.6124046775], 
processed observation next is [1.0, 0.9565217391304348, 0.45454545454545453, 0.97, 1.0, 1.0, 0.21874015025363408, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15535899404290135, 0.15535899404290146, 0.2953917375723841], 
reward next is 0.7046, 
noisyNet noise sample is [array([-0.8057661], dtype=float32), 0.894933]. 
=============================================
[2019-03-23 15:03:19,145] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.6184255e-07 9.9999952e-01 1.5422146e-15 1.0071197e-12 5.5350530e-11], sum to 1.0000
[2019-03-23 15:03:19,150] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6129
[2019-03-23 15:03:19,156] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.490379154807042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 559498.8892290741, 559498.8892290745, 140380.5317260057], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1389000.0000, 
sim time next is 1389600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4900668913768946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 559142.439666166, 559142.439666166, 140344.6633350509], 
processed observation next is [0.0, 0.08695652173913043, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3625836142211182, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20708979246895035, 0.20708979246895035, 0.3423040569147583], 
reward next is 0.6577, 
noisyNet noise sample is [array([-0.14482291], dtype=float32), -0.37795824]. 
=============================================
[2019-03-23 15:03:20,389] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.3701626e-07 9.9999940e-01 7.4384587e-15 3.7155678e-12 1.8880039e-08], sum to 1.0000
[2019-03-23 15:03:20,399] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9623
[2019-03-23 15:03:20,405] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 84.0, 1.0, 2.0, 0.5163759435443515, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 587938.3514546127, 587938.3514546123, 145049.4242709595], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1421400.0000, 
sim time next is 1422000.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.5168726633754579, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 588438.3445232944, 588438.3445232946, 145159.603319414], 
processed observation next is [0.0, 0.4782608695652174, 0.7272727272727273, 0.83, 1.0, 1.0, 0.3960908292193223, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21794012760122014, 0.21794012760122022, 0.3540478129741805], 
reward next is 0.6460, 
noisyNet noise sample is [array([-1.584276], dtype=float32), 0.5069349]. 
=============================================
[2019-03-23 15:03:20,423] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[55.611088]
 [55.613873]
 [55.63911 ]
 [55.64906 ]
 [55.681614]], R is [[55.69281006]
 [55.78210449]
 [55.87065506]
 [55.95843124]
 [56.04566193]].
[2019-03-23 15:03:22,116] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.7335257e-08 1.0000000e+00 9.5203145e-18 1.3044449e-15 1.3203760e-10], sum to 1.0000
[2019-03-23 15:03:22,124] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9449
[2019-03-23 15:03:22,130] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 70.66666666666666, 1.0, 2.0, 0.5396908300497921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 612925.105788076, 612925.105788076, 148852.7752533819], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1435200.0000, 
sim time next is 1435800.0000, 
raw observation next is [26.16666666666667, 70.83333333333334, 1.0, 2.0, 0.534872312052363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 607918.1474693981, 607918.1474693984, 148009.5001500405], 
processed observation next is [0.0, 0.6086956521739131, 0.825757575757576, 0.7083333333333335, 1.0, 1.0, 0.4185903900654537, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22515486943311042, 0.22515486943311053, 0.3609987808537573], 
reward next is 0.6390, 
noisyNet noise sample is [array([0.29055753], dtype=float32), -1.6900904]. 
=============================================
[2019-03-23 15:03:22,677] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.1158504e-07 9.9999964e-01 3.7802106e-16 1.8004699e-13 1.2913085e-09], sum to 1.0000
[2019-03-23 15:03:22,685] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4647
[2019-03-23 15:03:22,691] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4905421189656052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 559684.3520230559, 559684.3520230555, 140401.2826040942], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1446000.0000, 
sim time next is 1446600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.490452797617602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 559582.2575641157, 559582.2575641157, 140391.499718064], 
processed observation next is [0.0, 0.7391304347826086, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3630659970220025, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2072526879867095, 0.2072526879867095, 0.34241829199527807], 
reward next is 0.6576, 
noisyNet noise sample is [array([-1.4440566], dtype=float32), -0.79594547]. 
=============================================
[2019-03-23 15:03:25,222] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.9844458e-08 1.0000000e+00 4.3029157e-16 7.9846191e-14 1.4687532e-09], sum to 1.0000
[2019-03-23 15:03:25,227] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4621
[2019-03-23 15:03:25,230] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 66.0, 1.0, 2.0, 0.6119603859703205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 687686.9316760901, 687686.9316760901, 160575.2946647007], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1515600.0000, 
sim time next is 1516200.0000, 
raw observation next is [27.66666666666667, 71.66666666666666, 1.0, 2.0, 0.6060597401118228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 681051.468577749, 681051.468577749, 159741.1430270525], 
processed observation next is [0.0, 0.5652173913043478, 0.8939393939393941, 0.7166666666666666, 1.0, 1.0, 0.5075746751397785, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25224128465842555, 0.25224128465842555, 0.3896125439684207], 
reward next is 0.6104, 
noisyNet noise sample is [array([0.31921917], dtype=float32), 1.1803355]. 
=============================================
[2019-03-23 15:03:26,953] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 15:03:26,955] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:03:26,957] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:03:26,958] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:03:26,958] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:03:26,959] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:03:26,959] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:03:26,960] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:03:26,961] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:03:26,961] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:03:26,965] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:03:26,984] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run62
[2019-03-23 15:03:26,984] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run62
[2019-03-23 15:03:27,045] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run62
[2019-03-23 15:03:27,078] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run62
[2019-03-23 15:03:27,106] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run62
[2019-03-23 15:03:33,576] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05027472], dtype=float32), 0.27934664]
[2019-03-23 15:03:33,577] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.1, 61.0, 1.0, 2.0, 0.2621326459960944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 284609.4171608681, 284609.4171608681, 83597.99146229922]
[2019-03-23 15:03:33,579] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:03:33,580] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.2953357e-08 9.9999988e-01 5.3311532e-17 2.9408411e-14 8.6368246e-10], sampled 0.9513288068481223
[2019-03-23 15:03:49,180] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05027472], dtype=float32), 0.27934664]
[2019-03-23 15:03:49,181] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [9.097426009666668, 71.02277569666667, 1.0, 2.0, 0.363111364838545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 394282.6009847439, 394282.6009847436, 84711.83979962507]
[2019-03-23 15:03:49,184] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:03:49,187] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.8122070e-07 9.9999976e-01 2.4116547e-16 1.0363989e-13 2.0124085e-09], sampled 0.12644996610596804
[2019-03-23 15:04:18,742] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05027472], dtype=float32), 0.27934664]
[2019-03-23 15:04:18,744] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.98818207166667, 49.76946028, 1.0, 2.0, 0.3291463148387804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 363244.0999744862, 363244.0999744859, 119607.6499433657]
[2019-03-23 15:04:18,746] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:04:18,752] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.93188396e-08 1.00000000e+00 1.93262131e-17 1.26095965e-14
 4.89096486e-10], sampled 0.6542968347895937
[2019-03-23 15:04:36,291] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05027472], dtype=float32), 0.27934664]
[2019-03-23 15:04:36,293] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.8, 42.33333333333333, 1.0, 2.0, 0.3719248682305198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 417126.8421716834, 417126.8421716827, 125683.8684261098]
[2019-03-23 15:04:36,295] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:04:36,297] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.9775602e-08 1.0000000e+00 4.0573817e-18 3.4282174e-15 2.0399545e-10], sampled 0.31597736434261936
[2019-03-23 15:04:45,329] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05027472], dtype=float32), 0.27934664]
[2019-03-23 15:04:45,331] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.26386951, 68.17700409, 1.0, 2.0, 0.282075855400887, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 306268.1898715393, 306268.1898715393, 107395.6185160978]
[2019-03-23 15:04:45,332] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:04:45,334] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.3541983e-08 9.9999988e-01 3.1380906e-17 1.8896634e-14 6.4186373e-10], sampled 0.2633055379806678
[2019-03-23 15:05:12,241] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 15:05:12,389] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 15:05:12,566] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 15:05:12,635] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 15:05:12,682] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 15:05:13,699] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1525000, evaluation results [1525000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 15:05:14,623] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.7508486e-07 9.9999917e-01 8.9220032e-17 1.3733302e-12 1.0148267e-08], sum to 1.0000
[2019-03-23 15:05:14,634] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6747
[2019-03-23 15:05:14,639] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4277156209456487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 484910.3825891308, 484910.3825891311, 129125.0218332801], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1573200.0000, 
sim time next is 1573800.0000, 
raw observation next is [19.16666666666667, 99.00000000000001, 1.0, 2.0, 0.4335074854461131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 491628.1959008322, 491628.1959008322, 129792.3254815027], 
processed observation next is [1.0, 0.21739130434782608, 0.5075757575757578, 0.9900000000000001, 1.0, 1.0, 0.29188435680764135, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18208451700030823, 0.18208451700030823, 0.3165666475158603], 
reward next is 0.6834, 
noisyNet noise sample is [array([-0.62916607], dtype=float32), -0.83776444]. 
=============================================
[2019-03-23 15:05:15,481] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5375163e-07 9.9999988e-01 8.7652769e-17 7.9103152e-13 1.6763572e-10], sum to 1.0000
[2019-03-23 15:05:15,489] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6561
[2019-03-23 15:05:15,496] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1082566.313423659 W.
[2019-03-23 15:05:15,500] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 65.0, 1.0, 2.0, 0.9486058312516326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1082566.313423659, 1082566.313423659, 209241.1008362806], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1598400.0000, 
sim time next is 1599000.0000, 
raw observation next is [26.1, 64.66666666666667, 1.0, 2.0, 0.3753210564654008, 1.0, 1.0, 0.3753210564654008, 1.0, 1.0, 0.7602838050075266, 6.9112, 6.9112, 81.25881066886622, 1279201.036242193, 1279201.036242193, 292220.8902154204], 
processed observation next is [1.0, 0.5217391304347826, 0.8227272727272728, 0.6466666666666667, 1.0, 1.0, 0.219151320581751, 1.0, 0.5, 0.219151320581751, 1.0, 0.5, 0.6575482928678952, 0.0, 0.0, 0.5342705493932411, 0.47377816157118263, 0.47377816157118263, 0.7127338785741961], 
reward next is 0.2873, 
noisyNet noise sample is [array([-1.4681621], dtype=float32), 0.3969966]. 
=============================================
[2019-03-23 15:05:15,522] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[58.89771 ]
 [58.57564 ]
 [58.370293]
 [58.391766]
 [58.356033]], R is [[56.76074982]
 [56.68279648]
 [56.62384796]
 [56.57408905]
 [56.53583527]].
[2019-03-23 15:05:19,210] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.0071884e-06 9.9999404e-01 1.4070373e-14 3.2649363e-12 1.1525829e-08], sum to 1.0000
[2019-03-23 15:05:19,218] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6641
[2019-03-23 15:05:19,222] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 90.0, 1.0, 2.0, 0.3651545496331129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 403473.9780956352, 403473.9780956352, 118224.0372055824], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1650000.0000, 
sim time next is 1650600.0000, 
raw observation next is [18.0, 91.0, 1.0, 2.0, 0.3445507262609159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 381313.802067222, 381313.802067222, 116863.0281022471], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 0.91, 1.0, 1.0, 0.18068840782614481, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14122733409897112, 0.14122733409897112, 0.2850317758591393], 
reward next is 0.7150, 
noisyNet noise sample is [array([1.4056922], dtype=float32), 0.008026703]. 
=============================================
[2019-03-23 15:05:22,240] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.5104580e-08 1.0000000e+00 9.7313015e-17 2.4414133e-17 2.1898807e-09], sum to 1.0000
[2019-03-23 15:05:22,250] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8214
[2019-03-23 15:05:22,253] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 63.0, 1.0, 2.0, 0.2089981045601468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 226918.017700214, 226918.0177002137, 69433.30445470197], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1713600.0000, 
sim time next is 1714200.0000, 
raw observation next is [13.83333333333333, 63.66666666666666, 1.0, 2.0, 0.2044478307794261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 221976.4670809778, 221976.4670809781, 68940.18049824938], 
processed observation next is [1.0, 0.8695652173913043, 0.265151515151515, 0.6366666666666666, 1.0, 1.0, 0.005559788474282616, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08221350632628807, 0.08221350632628818, 0.16814678170304725], 
reward next is 0.8319, 
noisyNet noise sample is [array([-1.3850746], dtype=float32), -0.2791846]. 
=============================================
[2019-03-23 15:05:23,199] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.1036496e-04 9.9888664e-01 5.8435334e-10 1.4506092e-07 3.0295539e-04], sum to 1.0000
[2019-03-23 15:05:23,209] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5070
[2019-03-23 15:05:23,215] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333334, 51.33333333333333, 1.0, 2.0, 0.2600535916776568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 282367.1948742966, 282367.1948742969, 78477.53859958496], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1705200.0000, 
sim time next is 1705800.0000, 
raw observation next is [18.16666666666666, 50.16666666666667, 1.0, 2.0, 0.2567836095984893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 278815.6179521171, 278815.6179521173, 77385.68872876599], 
processed observation next is [1.0, 0.7391304347826086, 0.4621212121212119, 0.5016666666666667, 1.0, 1.0, 0.07097951199811159, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1032650436859693, 0.10326504368596937, 0.1887455822652829], 
reward next is 0.8113, 
noisyNet noise sample is [array([-0.29679427], dtype=float32), -0.024989368]. 
=============================================
[2019-03-23 15:05:26,831] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.4703561e-03 9.9848527e-01 3.0133812e-10 1.8463538e-08 4.4388034e-05], sum to 1.0000
[2019-03-23 15:05:26,846] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0154
[2019-03-23 15:05:26,853] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 52.5, 1.0, 2.0, 0.2264883734366213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 245912.7375428199, 245912.7375428199, 72921.81225249138], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1804200.0000, 
sim time next is 1804800.0000, 
raw observation next is [17.0, 53.0, 1.0, 2.0, 0.227627174603489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 247149.520073736, 247149.520073736, 73143.03669706995], 
processed observation next is [1.0, 0.9130434782608695, 0.4090909090909091, 0.53, 1.0, 1.0, 0.03453396825436123, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09153685928656889, 0.09153685928656889, 0.17839765048065842], 
reward next is 0.8216, 
noisyNet noise sample is [array([0.9947726], dtype=float32), 0.8041007]. 
=============================================
[2019-03-23 15:05:27,749] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5940368e-07 9.9999988e-01 4.9243054e-18 6.4973573e-14 1.2079883e-09], sum to 1.0000
[2019-03-23 15:05:27,757] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8507
[2019-03-23 15:05:27,761] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 63.0, 1.0, 2.0, 0.2039200223960056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221403.2758436803, 221403.2758436801, 70055.96774573112], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1812600.0000, 
sim time next is 1813200.0000, 
raw observation next is [14.66666666666667, 64.33333333333333, 1.0, 2.0, 0.200303200491539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 217475.4848199889, 217475.4848199886, 69516.88564728231], 
processed observation next is [1.0, 1.0, 0.30303030303030315, 0.6433333333333333, 1.0, 1.0, 0.00037900061442372457, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08054647585925515, 0.08054647585925503, 0.16955337962751782], 
reward next is 0.8304, 
noisyNet noise sample is [array([-0.17348145], dtype=float32), -1.2138357]. 
=============================================
[2019-03-23 15:05:28,868] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.0719922e-06 9.9999797e-01 5.6818985e-19 3.0479854e-15 1.0999514e-08], sum to 1.0000
[2019-03-23 15:05:28,878] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7982
[2019-03-23 15:05:28,884] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [10.0, 100.0, 1.0, 2.0, 0.3357778452716052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 364619.7060892756, 364619.7060892756, 81022.57781605952], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1830600.0000, 
sim time next is 1831200.0000, 
raw observation next is [10.0, 100.0, 1.0, 2.0, 0.3314272290982486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 359893.6425757739, 359893.6425757742, 80618.18309258496], 
processed observation next is [1.0, 0.17391304347826086, 0.09090909090909091, 1.0, 1.0, 1.0, 0.16428403637281075, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13329394169473108, 0.1332939416947312, 0.19662971485996333], 
reward next is 0.8034, 
noisyNet noise sample is [array([0.43791902], dtype=float32), 0.116206884]. 
=============================================
[2019-03-23 15:05:30,068] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.52739716e-07 9.99999881e-01 4.12105558e-18 1.17121245e-14
 3.00285818e-09], sum to 1.0000
[2019-03-23 15:05:30,082] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5060
[2019-03-23 15:05:30,087] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 44.0, 1.0, 2.0, 0.5164838740018253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 560960.8078911242, 560960.8078911239, 123035.3416437762], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1867200.0000, 
sim time next is 1867800.0000, 
raw observation next is [23.0, 42.5, 1.0, 2.0, 0.4933380775828102, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 535807.9591235622, 535807.9591235622, 117700.0027288965], 
processed observation next is [1.0, 0.6086956521739131, 0.6818181818181818, 0.425, 1.0, 1.0, 0.3666725969785127, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.198447392267986, 0.198447392267986, 0.28707317738755245], 
reward next is 0.7129, 
noisyNet noise sample is [array([-0.75039244], dtype=float32), -0.22029436]. 
=============================================
[2019-03-23 15:05:32,919] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.0780662e-07 9.9999976e-01 5.2774257e-19 6.1990847e-15 2.7785143e-09], sum to 1.0000
[2019-03-23 15:05:32,932] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4171
[2019-03-23 15:05:32,937] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333334, 87.0, 1.0, 2.0, 0.3211747654772793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 354297.1214537145, 354297.1214537142, 114645.689879502], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1910400.0000, 
sim time next is 1911000.0000, 
raw observation next is [18.16666666666666, 90.5, 1.0, 2.0, 0.3263422665157338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 361429.7216484712, 361429.7216484712, 115593.9044069666], 
processed observation next is [1.0, 0.08695652173913043, 0.4621212121212119, 0.905, 1.0, 1.0, 0.1579278331446672, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13386285986980415, 0.13386285986980415, 0.28193635221211366], 
reward next is 0.7181, 
noisyNet noise sample is [array([0.4998126], dtype=float32), -2.3706288]. 
=============================================
[2019-03-23 15:05:32,953] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[73.01382 ]
 [73.14512 ]
 [73.46404 ]
 [73.715096]
 [73.83706 ]], R is [[72.63822174]
 [72.63221741]
 [72.62787628]
 [72.62333679]
 [72.61608124]].
[2019-03-23 15:05:37,144] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.3729039e-05 9.9800402e-01 2.2190899e-15 2.2478468e-13 1.9222405e-03], sum to 1.0000
[2019-03-23 15:05:37,151] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4692
[2019-03-23 15:05:37,155] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 57.0, 1.0, 2.0, 0.3545202920188469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 393953.4190368927, 393953.4190368929, 118279.6427159524], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1971000.0000, 
sim time next is 1971600.0000, 
raw observation next is [22.66666666666666, 58.0, 1.0, 2.0, 0.3520429252817643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 390381.2948844421, 390381.2948844418, 117749.3924900749], 
processed observation next is [1.0, 0.8260869565217391, 0.6666666666666664, 0.58, 1.0, 1.0, 0.19005365660220533, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1445856647720156, 0.14458566477201548, 0.28719364021969485], 
reward next is 0.7128, 
noisyNet noise sample is [array([0.34855354], dtype=float32), 0.14806207]. 
=============================================
[2019-03-23 15:05:43,431] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9087219e-07 9.9999821e-01 4.1556072e-17 4.9134616e-14 8.5610424e-07], sum to 1.0000
[2019-03-23 15:05:43,441] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7573
[2019-03-23 15:05:43,451] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.33333333333333, 82.66666666666666, 1.0, 2.0, 0.2244963918065948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 243749.3752787963, 243749.375278796, 78251.42679656901], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2097600.0000, 
sim time next is 2098200.0000, 
raw observation next is [15.66666666666667, 79.83333333333333, 1.0, 2.0, 0.2248548737818495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 244138.6986297634, 244138.6986297632, 78346.63371404054], 
processed observation next is [0.0, 0.2608695652173913, 0.3484848484848486, 0.7983333333333333, 1.0, 1.0, 0.031068592227311877, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09042174023324571, 0.09042174023324563, 0.1910893505220501], 
reward next is 0.8089, 
noisyNet noise sample is [array([-2.0333686], dtype=float32), -1.5707891]. 
=============================================
[2019-03-23 15:05:49,988] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.1569336e-08 9.9999285e-01 6.1684169e-17 1.9117341e-15 7.1646582e-06], sum to 1.0000
[2019-03-23 15:05:49,996] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5707
[2019-03-23 15:05:49,999] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333333, 81.33333333333333, 1.0, 2.0, 0.3885246665298808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 436880.5888211131, 436880.5888211131, 123336.2082242311], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2230800.0000, 
sim time next is 2231400.0000, 
raw observation next is [20.16666666666667, 82.16666666666667, 1.0, 2.0, 0.3864951044014738, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 434329.1635730913, 434329.1635730913, 123023.7290326406], 
processed observation next is [1.0, 0.8260869565217391, 0.5530303030303032, 0.8216666666666668, 1.0, 1.0, 0.2331188805018422, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.160862653175219, 0.160862653175219, 0.3000578756893673], 
reward next is 0.6999, 
noisyNet noise sample is [array([0.11408157], dtype=float32), -1.2291764]. 
=============================================
[2019-03-23 15:06:01,913] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 15:06:01,916] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:06:01,917] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:06:01,918] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:06:01,919] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:06:01,919] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:06:01,920] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:06:01,922] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:06:01,924] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:06:01,925] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:06:01,925] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:06:01,944] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run63
[2019-03-23 15:06:01,975] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run63
[2019-03-23 15:06:02,008] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run63
[2019-03-23 15:06:02,038] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run63
[2019-03-23 15:06:02,039] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run63
[2019-03-23 15:06:51,364] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05303794], dtype=float32), 0.2847768]
[2019-03-23 15:06:51,368] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.36666666666667, 60.66666666666666, 1.0, 2.0, 0.6107924878615465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 695987.7447078973, 695987.7447078973, 160988.4215431175]
[2019-03-23 15:06:51,369] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:06:51,371] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.6906715e-08 9.9999952e-01 6.2964546e-18 4.3700268e-15 3.3401648e-07], sampled 0.8581188417650482
[2019-03-23 15:07:17,331] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05303794], dtype=float32), 0.2847768]
[2019-03-23 15:07:17,332] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.125927585, 70.311014995, 1.0, 2.0, 0.2215525438301847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 240540.9257080298, 240540.9257080294, 80280.01530713389]
[2019-03-23 15:07:17,333] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:07:17,337] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.5223070e-08 9.9999952e-01 5.9117234e-18 4.1449460e-15 3.2607991e-07], sampled 0.0936153231794028
[2019-03-23 15:07:47,344] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 15:07:47,768] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 15:07:47,793] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 15:07:47,812] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 15:07:47,818] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 15:07:48,833] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1550000, evaluation results [1550000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 15:07:49,507] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.1542515e-10 1.0000000e+00 1.7198313e-20 1.0653749e-17 5.1694098e-09], sum to 1.0000
[2019-03-23 15:07:49,513] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5125
[2019-03-23 15:07:49,516] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2377534444961131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 258147.1828682377, 258147.1828682374, 79191.94463458599], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2488800.0000, 
sim time next is 2489400.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2349145027109725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 255063.917381247, 255063.9173812467, 78855.94837509532], 
processed observation next is [1.0, 0.8260869565217391, 0.2727272727272727, 0.94, 1.0, 1.0, 0.04364312838871561, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09446811754861001, 0.09446811754860988, 0.1923315814026715], 
reward next is 0.8077, 
noisyNet noise sample is [array([1.1575536], dtype=float32), -0.4357128]. 
=============================================
[2019-03-23 15:08:00,708] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.3797115e-09 9.9999988e-01 6.8470861e-17 5.0278194e-15 1.0031369e-07], sum to 1.0000
[2019-03-23 15:08:00,716] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8209
[2019-03-23 15:08:00,723] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.7, 99.66666666666666, 1.0, 2.0, 0.329066468494219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 361942.5240247414, 361942.5240247414, 114821.4729871996], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2698800.0000, 
sim time next is 2699400.0000, 
raw observation next is [16.75, 99.83333333333334, 1.0, 2.0, 0.3300053771294053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 363412.8142403244, 363412.8142403247, 115055.3755422898], 
processed observation next is [0.0, 0.21739130434782608, 0.3977272727272727, 0.9983333333333334, 1.0, 1.0, 0.16250672141175662, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13459733860752757, 0.13459733860752768, 0.28062286717631657], 
reward next is 0.7194, 
noisyNet noise sample is [array([-0.40022716], dtype=float32), 1.6198162]. 
=============================================
[2019-03-23 15:08:04,212] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.2056126e-09 1.0000000e+00 1.5226300e-18 7.6700453e-16 6.7720790e-10], sum to 1.0000
[2019-03-23 15:08:04,218] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6334
[2019-03-23 15:08:04,221] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.00000000000001, 1.0, 2.0, 0.3291918319589067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 362298.4303757624, 362298.4303757624, 114912.5727955784], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2779800.0000, 
sim time next is 2780400.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3240954672385231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 356684.2885806834, 356684.2885806834, 114538.0181005221], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 0.88, 1.0, 1.0, 0.15511933404815387, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1321052920669198, 0.1321052920669198, 0.279361019757371], 
reward next is 0.7206, 
noisyNet noise sample is [array([0.9534504], dtype=float32), 0.21483667]. 
=============================================
[2019-03-23 15:08:04,476] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.0994747e-08 9.9999964e-01 3.8315134e-18 4.4324089e-14 3.7923132e-07], sum to 1.0000
[2019-03-23 15:08:04,482] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3716
[2019-03-23 15:08:04,490] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 86.66666666666666, 1.0, 2.0, 0.3869789184427027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 436247.6738616541, 436247.6738616538, 123780.0883427072], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2792400.0000, 
sim time next is 2793000.0000, 
raw observation next is [20.5, 84.83333333333333, 1.0, 2.0, 0.3911393975285686, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 442039.9838692523, 442039.983869252, 124774.3818494017], 
processed observation next is [1.0, 0.30434782608695654, 0.5681818181818182, 0.8483333333333333, 1.0, 1.0, 0.2389242469107107, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16371851254416753, 0.16371851254416742, 0.30432776060829686], 
reward next is 0.6957, 
noisyNet noise sample is [array([0.6125156], dtype=float32), 0.34266767]. 
=============================================
[2019-03-23 15:08:04,512] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[71.599846]
 [71.66517 ]
 [71.77241 ]
 [71.85494 ]
 [71.91428 ]], R is [[71.51830292]
 [71.5012207 ]
 [71.48648071]
 [71.47689819]
 [71.47186279]].
[2019-03-23 15:08:09,528] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.1366548e-07 9.9999964e-01 2.0381724e-14 4.0282833e-12 5.8665623e-09], sum to 1.0000
[2019-03-23 15:08:09,534] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4166
[2019-03-23 15:08:09,540] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1510091.725593291 W.
[2019-03-23 15:08:09,544] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.16666666666667, 69.33333333333334, 1.0, 2.0, 0.8551906645144322, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9865530188920543, 6.911199999999999, 6.9112, 77.32846344354104, 1510091.725593291, 1510091.725593291, 325709.9137439418], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2895000.0000, 
sim time next is 2895600.0000, 
raw observation next is [28.33333333333334, 68.66666666666667, 1.0, 2.0, 0.5717635209376118, 1.0, 1.0, 0.5717635209376118, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1285769.192396021, 1285769.192396022, 254184.6019640608], 
processed observation next is [1.0, 0.5217391304347826, 0.9242424242424245, 0.6866666666666668, 1.0, 1.0, 0.4647044011720148, 1.0, 0.5, 0.4647044011720148, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4762108119985263, 0.47621081199852666, 0.6199624438147824], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6311051], dtype=float32), -0.4491988]. 
=============================================
[2019-03-23 15:08:11,785] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.6648601e-08 1.0000000e+00 2.9930756e-16 4.4831106e-14 1.3600494e-09], sum to 1.0000
[2019-03-23 15:08:11,794] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8740
[2019-03-23 15:08:11,798] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 79.83333333333333, 1.0, 2.0, 0.5333515446638628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 606677.4370725044, 606677.4370725042, 147540.5185456763], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2915400.0000, 
sim time next is 2916000.0000, 
raw observation next is [25.0, 78.0, 1.0, 2.0, 0.5380185374941796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 611799.1720338035, 611799.1720338032, 148236.7405332084], 
processed observation next is [1.0, 0.782608695652174, 0.7727272727272727, 0.78, 1.0, 1.0, 0.4225231718677245, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22659228593844574, 0.22659228593844563, 0.36155302569075215], 
reward next is 0.6384, 
noisyNet noise sample is [array([-0.64064264], dtype=float32), -0.054922406]. 
=============================================
[2019-03-23 15:08:11,817] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[63.086727]
 [62.52253 ]
 [62.328663]
 [61.726433]
 [61.416588]], R is [[62.60459137]
 [62.61869049]
 [62.63534927]
 [62.65489197]
 [62.0283432 ]].
[2019-03-23 15:08:16,101] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.5290736e-08 9.9999881e-01 3.6842812e-16 4.9003319e-11 1.1138812e-06], sum to 1.0000
[2019-03-23 15:08:16,103] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9016
[2019-03-23 15:08:16,110] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 83.0, 1.0, 2.0, 0.3846391377603145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 432053.4160753345, 432053.4160753342, 122768.0491574353], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3022200.0000, 
sim time next is 3022800.0000, 
raw observation next is [19.66666666666667, 84.66666666666667, 1.0, 2.0, 0.3806071205500096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 426934.1949744721, 426934.1949744718, 122132.9241656498], 
processed observation next is [1.0, 1.0, 0.5303030303030305, 0.8466666666666667, 1.0, 1.0, 0.225758900687512, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15812377591647114, 0.15812377591647103, 0.2978851808918288], 
reward next is 0.7021, 
noisyNet noise sample is [array([-1.757872], dtype=float32), 0.7379514]. 
=============================================
[2019-03-23 15:08:19,286] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3026183e-06 9.9989307e-01 9.5675480e-15 2.8583440e-09 1.0557097e-04], sum to 1.0000
[2019-03-23 15:08:19,294] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1203
[2019-03-23 15:08:19,298] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 72.66666666666666, 1.0, 2.0, 0.5633153236390975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 638532.9432765454, 638532.9432765451, 152405.0113330044], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3091200.0000, 
sim time next is 3091800.0000, 
raw observation next is [26.16666666666667, 73.33333333333334, 1.0, 2.0, 0.5621985041666009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 637518.8441695552, 637518.8441695552, 152161.6553945482], 
processed observation next is [1.0, 0.782608695652174, 0.825757575757576, 0.7333333333333334, 1.0, 1.0, 0.45274813020825105, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23611809043316861, 0.23611809043316861, 0.3711259887671907], 
reward next is 0.6289, 
noisyNet noise sample is [array([-0.7715666], dtype=float32), -0.6543421]. 
=============================================
[2019-03-23 15:08:23,200] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0288365e-03 9.7401512e-01 5.7485350e-09 1.7226177e-05 2.4938816e-02], sum to 1.0000
[2019-03-23 15:08:23,207] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4496
[2019-03-23 15:08:23,217] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1486521.883235924 W.
[2019-03-23 15:08:23,221] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.66666666666667, 70.5, 1.0, 2.0, 0.653071370892107, 1.0, 1.0, 0.653071370892107, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 87.96040739985936, 1486521.883235924, 1486521.883235924, 276439.5482592538], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3161400.0000, 
sim time next is 3162000.0000, 
raw observation next is [24.33333333333334, 72.0, 1.0, 2.0, 0.6204674683501161, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9715451063321894, 6.911200000000001, 6.9112, 77.32846344354104, 1256223.429202042, 1256223.429202042, 275098.5958344645], 
processed observation next is [1.0, 0.6086956521739131, 0.7424242424242427, 0.72, 1.0, 1.0, 0.5255843354376452, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9593501519031277, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4652679367414971, 0.4652679367414971, 0.6709721849621085], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.03629577], dtype=float32), -1.2837756]. 
=============================================
[2019-03-23 15:08:23,239] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[42.046585]
 [42.595512]
 [42.56278 ]
 [41.92447 ]
 [42.255436]], R is [[41.94107437]
 [41.52166367]
 [41.44036865]
 [41.41792679]
 [41.00374603]].
[2019-03-23 15:08:23,971] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.0260594e-05 9.9864095e-01 1.4512534e-10 5.6143097e-08 1.2988197e-03], sum to 1.0000
[2019-03-23 15:08:23,979] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2724
[2019-03-23 15:08:23,985] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1306507.227663122 W.
[2019-03-23 15:08:23,988] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.33333333333334, 76.66666666666667, 1.0, 2.0, 0.6640470124140266, 0.0, 2.0, 0.0, 1.0, 2.0, 0.968899989744666, 6.9112, 6.9112, 77.32846344336892, 1306507.227663122, 1306507.227663122, 278336.5860115604], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3165600.0000, 
sim time next is 3166200.0000, 
raw observation next is [23.5, 76.0, 1.0, 2.0, 0.5657654004447097, 1.0, 1.0, 0.5657654004447097, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344353997, 1290183.038458703, 1290183.038458703, 245544.845716013], 
processed observation next is [1.0, 0.6521739130434783, 0.7045454545454546, 0.76, 1.0, 1.0, 0.45720675055588705, 1.0, 0.5, 0.45720675055588705, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206471, 0.47784556979951964, 0.47784556979951964, 0.5988898676000317], 
reward next is 0.4011, 
noisyNet noise sample is [array([-0.93959695], dtype=float32), -0.51863265]. 
=============================================
[2019-03-23 15:08:36,568] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 15:08:36,570] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:08:36,571] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:08:36,571] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:08:36,572] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:08:36,573] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:08:36,575] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:08:36,575] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:08:36,578] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:08:36,577] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:08:36,579] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:08:36,597] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run64
[2019-03-23 15:08:36,598] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run64
[2019-03-23 15:08:36,651] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run64
[2019-03-23 15:08:36,653] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run64
[2019-03-23 15:08:36,690] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run64
[2019-03-23 15:08:49,833] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05328782], dtype=float32), 0.28936827]
[2019-03-23 15:08:49,836] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.33333333333333, 71.0, 1.0, 2.0, 0.3926859716286761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 426443.0925432954, 426443.0925432954, 107328.3723739961]
[2019-03-23 15:08:49,836] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:08:49,839] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.8722882e-04 7.6196891e-01 2.4726546e-10 5.0818389e-06 2.3773880e-01], sampled 0.47688545498136414
[2019-03-23 15:08:58,786] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05328782], dtype=float32), 0.28936827]
[2019-03-23 15:08:58,787] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [7.596160510333333, 75.26133716666666, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 1.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 131848.8558223798, 131848.8558223798, 99069.27778713191]
[2019-03-23 15:08:58,788] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:08:58,792] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.1874184e-04 7.7038747e-01 1.1735704e-10 3.3889964e-06 2.2939040e-01], sampled 0.5324189180654197
[2019-03-23 15:09:10,000] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05328782], dtype=float32), 0.28936827]
[2019-03-23 15:09:10,001] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.16666666666666, 55.5, 1.0, 2.0, 0.2924630954518112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 317569.0488895091, 317569.0488895094, 103209.5154551289]
[2019-03-23 15:09:10,002] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:09:10,004] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.3314142e-05 7.9457051e-01 1.1646452e-11 9.5985354e-07 2.0533529e-01], sampled 0.913430953893938
[2019-03-23 15:09:14,253] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05328782], dtype=float32), 0.28936827]
[2019-03-23 15:09:14,255] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.5, 74.0, 1.0, 2.0, 0.8586877010625884, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9837923109895534, 6.9112, 6.9112, 77.32846344354104, 1515587.266594391, 1515587.266594391, 324477.6000670217]
[2019-03-23 15:09:14,255] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:09:14,258] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.8359201e-04 7.5319469e-01 5.4208538e-10 7.8261046e-06 2.4641387e-01], sampled 0.8394509596804698
[2019-03-23 15:09:27,189] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05328782], dtype=float32), 0.28936827]
[2019-03-23 15:09:27,190] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.197643975, 88.21561511499999, 1.0, 2.0, 0.2991427404209899, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 324803.8295918764, 324803.8295918764, 115441.325741632]
[2019-03-23 15:09:27,191] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:09:27,193] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.11818685e-04 7.89436519e-01 1.90660092e-11 1.25454642e-06
 2.10450396e-01], sampled 0.5995936954253492
[2019-03-23 15:09:40,680] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05328782], dtype=float32), 0.28936827]
[2019-03-23 15:09:40,681] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.15306038666667, 96.15689287666666, 1.0, 2.0, 0.4929050421847718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 561803.0929355298, 561803.0929355294, 145925.8280150335]
[2019-03-23 15:09:40,682] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:09:40,686] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.4532921e-04 7.8216422e-01 3.8821418e-11 1.8520878e-06 2.1768861e-01], sampled 0.43763729549316466
[2019-03-23 15:09:58,249] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05328782], dtype=float32), 0.28936827]
[2019-03-23 15:09:58,251] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.7, 78.0, 1.0, 2.0, 0.276352657292869, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 300070.2430361009, 300070.2430361011, 97076.91947750878]
[2019-03-23 15:09:58,254] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:09:58,257] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.3109482e-04 7.6860970e-01 1.3648174e-10 3.6773615e-06 2.3115553e-01], sampled 0.9781188244308506
[2019-03-23 15:10:17,366] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05328782], dtype=float32), 0.28936827]
[2019-03-23 15:10:17,368] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.75830521, 75.74570709, 1.0, 2.0, 0.3806461475136407, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 430245.7387672913, 430245.7387672913, 128201.9110685749]
[2019-03-23 15:10:17,369] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:10:17,371] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.10990535e-04 7.89766371e-01 1.86565936e-11 1.24104372e-06
 2.10121378e-01], sampled 0.28786783348332745
[2019-03-23 15:10:21,790] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 5814.7370 1862217280.2949 367.0000
[2019-03-23 15:10:22,338] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 5751.4238 1934052281.1309 134.0000
[2019-03-23 15:10:22,660] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 5859.3366 1840399202.0988 85.0000
[2019-03-23 15:10:22,686] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 5729.9456 1850971085.3319 152.0000
[2019-03-23 15:10:22,800] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 5984.0825 1829482058.2383 60.0000
[2019-03-23 15:10:23,815] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1575000, evaluation results [1575000.0, 5751.423753334956, 1934052281.1309235, 134.0, 5984.08247219756, 1829482058.2382615, 60.0, 5859.3366304410965, 1840399202.098779, 85.0, 5814.73700834299, 1862217280.2948747, 367.0, 5729.945625994179, 1850971085.3318517, 152.0]
[2019-03-23 15:10:29,167] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.96597577e-04 9.89380121e-01 4.79508516e-11 8.75862315e-06
 1.02144275e-02], sum to 1.0000
[2019-03-23 15:10:29,177] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3197
[2019-03-23 15:10:29,187] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1445117.760683857 W.
[2019-03-23 15:10:29,191] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 70.0, 1.0, 2.0, 0.6425332936039498, 1.0, 2.0, 0.6425332936039498, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1445117.760683857, 1445117.760683857, 274253.4266074665], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3499200.0000, 
sim time next is 3499800.0000, 
raw observation next is [27.0, 70.0, 1.0, 2.0, 0.8970715533231762, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9840956697402027, 6.9112, 6.9112, 79.1257293240942, 1558307.218359454, 1558307.218359454, 332456.398282547], 
processed observation next is [1.0, 0.5217391304347826, 0.8636363636363636, 0.7, 1.0, 1.0, 0.8713394416539701, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9772795282002897, 0.0, 0.0, 0.5202457004865063, 0.5771508216146126, 0.5771508216146126, 0.8108692641037732], 
reward next is 0.1891, 
noisyNet noise sample is [array([-1.0423962], dtype=float32), 0.29565132]. 
=============================================
[2019-03-23 15:10:40,411] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.9048692e-06 9.9739361e-01 1.7353100e-13 1.4441922e-04 2.4590085e-03], sum to 1.0000
[2019-03-23 15:10:40,421] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9218
[2019-03-23 15:10:40,434] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333333, 78.0, 1.0, 2.0, 0.4888824931881497, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 556274.6391539354, 556274.639153935, 136864.7911040619], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3739200.0000, 
sim time next is 3739800.0000, 
raw observation next is [22.66666666666667, 75.5, 1.0, 2.0, 0.4907917864464533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 558387.7113814827, 558387.711381483, 137015.1288580284], 
processed observation next is [1.0, 0.2608695652173913, 0.6666666666666669, 0.755, 1.0, 1.0, 0.36348973305806664, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2068102634746232, 0.20681026347462333, 0.3341832411171424], 
reward next is 0.6658, 
noisyNet noise sample is [array([0.39868233], dtype=float32), 0.7679812]. 
=============================================
[2019-03-23 15:10:41,238] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.5602916e-05 9.9895018e-01 1.6317683e-12 1.3595402e-04 8.9822634e-04], sum to 1.0000
[2019-03-23 15:10:41,244] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5927
[2019-03-23 15:10:41,248] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.5800362820060895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 661512.9430783585, 661512.9430783583, 151997.870027162], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3726600.0000, 
sim time next is 3727200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5301341103938689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 604587.7899913214, 604587.7899913216, 145709.2042170083], 
processed observation next is [1.0, 0.13043478260869565, 0.6363636363636364, 0.94, 1.0, 1.0, 0.41266763799233613, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2239214037004894, 0.2239214037004895, 0.3553883029683129], 
reward next is 0.6446, 
noisyNet noise sample is [array([-1.2457669], dtype=float32), -0.8482456]. 
=============================================
[2019-03-23 15:10:41,694] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.27738802e-06 8.95010531e-01 1.92822299e-12 2.71952653e-04
 1.04708254e-01], sum to 1.0000
[2019-03-23 15:10:41,703] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2277
[2019-03-23 15:10:41,709] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1177169.23908223 W.
[2019-03-23 15:10:41,715] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 71.0, 1.0, 2.0, 0.515512478725817, 1.0, 2.0, 0.515512478725817, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1177169.23908223, 1177169.23908223, 228450.2713347566], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3769800.0000, 
sim time next is 3770400.0000, 
raw observation next is [23.0, 69.0, 1.0, 2.0, 0.4831765923697888, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9338563801596927, 6.960986318559462, 6.9112, 77.32833722967582, 1098525.978908523, 1082356.427338365, 243303.5743922133], 
processed observation next is [1.0, 0.6521739130434783, 0.6818181818181818, 0.69, 1.0, 1.0, 0.353970740462236, 0.0, 0.5, -0.25, 1.0, 0.5, 0.905509114513847, 0.004978631855946158, 0.0, 0.5084279830740128, 0.40686147366982334, 0.4008727508660611, 0.5934233521761301], 
reward next is 0.1576, 
noisyNet noise sample is [array([0.42785552], dtype=float32), 1.4328328]. 
=============================================
[2019-03-23 15:10:42,712] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.7757913e-05 9.9324930e-01 6.5740843e-13 9.5206531e-05 6.6377083e-03], sum to 1.0000
[2019-03-23 15:10:42,722] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7274
[2019-03-23 15:10:42,729] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 64.83333333333334, 1.0, 2.0, 0.336105115981941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 369068.6144974165, 369068.6144974168, 115112.5203436216], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3780600.0000, 
sim time next is 3781200.0000, 
raw observation next is [21.0, 65.66666666666667, 1.0, 2.0, 0.3375207171056591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 371336.5749049825, 371336.5749049828, 115480.4110241539], 
processed observation next is [1.0, 0.782608695652174, 0.5909090909090909, 0.6566666666666667, 1.0, 1.0, 0.17190089638207387, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13753206477962315, 0.13753206477962326, 0.2816595390833022], 
reward next is 0.7183, 
noisyNet noise sample is [array([1.5893201], dtype=float32), -2.6611738]. 
=============================================
[2019-03-23 15:10:48,872] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.8758865e-07 9.9941504e-01 3.8638457e-17 2.3513671e-06 5.8233010e-04], sum to 1.0000
[2019-03-23 15:10:48,878] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5632
[2019-03-23 15:10:48,884] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 65.33333333333334, 1.0, 2.0, 0.2840134948467581, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 308391.1988514668, 308391.1988514665, 102675.9337175592], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3882000.0000, 
sim time next is 3882600.0000, 
raw observation next is [19.5, 66.0, 1.0, 2.0, 0.2814211360805137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 305575.4460447518, 305575.4460447515, 101777.7954219796], 
processed observation next is [0.0, 0.9565217391304348, 0.5227272727272727, 0.66, 1.0, 1.0, 0.10177642010064214, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11317609112768585, 0.11317609112768574, 0.24823852541946242], 
reward next is 0.7518, 
noisyNet noise sample is [array([-0.04283752], dtype=float32), -1.5503588]. 
=============================================
[2019-03-23 15:10:49,142] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.9484260e-09 9.9999821e-01 8.8537608e-21 3.4429608e-08 1.8127270e-06], sum to 1.0000
[2019-03-23 15:10:49,150] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5924
[2019-03-23 15:10:49,156] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 82.0, 1.0, 2.0, 0.2640019069780849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 286655.5543171617, 286655.5543171617, 94194.81369049005], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3910800.0000, 
sim time next is 3911400.0000, 
raw observation next is [17.0, 82.0, 1.0, 2.0, 0.2645436420970055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 287243.9487040465, 287243.9487040462, 94250.26446434991], 
processed observation next is [0.0, 0.2608695652173913, 0.4090909090909091, 0.82, 1.0, 1.0, 0.08067955262125684, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10638664766816537, 0.10638664766816526, 0.2298786938154876], 
reward next is 0.7701, 
noisyNet noise sample is [array([0.24851272], dtype=float32), 0.31279394]. 
=============================================
[2019-03-23 15:10:56,673] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2206008e-10 9.9999988e-01 7.5584323e-21 1.7109421e-08 6.3403441e-08], sum to 1.0000
[2019-03-23 15:10:56,680] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7281
[2019-03-23 15:10:56,683] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 94.0, 1.0, 2.0, 0.3625333764933286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 401890.6257552498, 401890.6257552495, 118527.8610583792], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4036800.0000, 
sim time next is 4037400.0000, 
raw observation next is [17.5, 94.0, 1.0, 2.0, 0.3502312029572296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 387083.2220995162, 387083.2220995162, 117098.7535242938], 
processed observation next is [1.0, 0.7391304347826086, 0.4318181818181818, 0.94, 1.0, 1.0, 0.18778900369653698, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14336415633315414, 0.14336415633315414, 0.2856067159129117], 
reward next is 0.7144, 
noisyNet noise sample is [array([0.32895926], dtype=float32), -0.9262262]. 
=============================================
[2019-03-23 15:10:56,809] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.4404087e-07 9.9995899e-01 3.1132577e-17 5.4470902e-06 3.5209243e-05], sum to 1.0000
[2019-03-23 15:10:56,818] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9420
[2019-03-23 15:10:56,826] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 100.0, 1.0, 2.0, 0.304583825721208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 330734.7363008813, 330734.7363008813, 111501.1913396614], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4065000.0000, 
sim time next is 4065600.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.3042525488142872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 330374.8944817313, 330374.8944817311, 111478.8519045375], 
processed observation next is [1.0, 0.043478260869565216, 0.36363636363636365, 1.0, 1.0, 1.0, 0.13031568601785898, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12236107203027084, 0.12236107203027079, 0.2718996387915549], 
reward next is 0.7281, 
noisyNet noise sample is [array([0.6709181], dtype=float32), -2.5376432]. 
=============================================
[2019-03-23 15:11:01,327] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1982037e-07 9.9998188e-01 7.2382682e-16 1.0711416e-05 7.3087040e-06], sum to 1.0000
[2019-03-23 15:11:01,334] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0970
[2019-03-23 15:11:01,340] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 100.0, 1.0, 2.0, 0.3476129454877033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 384745.5986814389, 384745.5986814389, 117115.3510552561], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4164000.0000, 
sim time next is 4164600.0000, 
raw observation next is [17.0, 100.0, 1.0, 2.0, 0.3414421557515168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 377893.0332580754, 377893.0332580751, 116632.4574402677], 
processed observation next is [1.0, 0.17391304347826086, 0.4090909090909091, 1.0, 1.0, 1.0, 0.176802694689396, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1399603826881761, 0.13996038268817598, 0.2844694083908968], 
reward next is 0.7155, 
noisyNet noise sample is [array([-1.4456874], dtype=float32), 0.5579401]. 
=============================================
[2019-03-23 15:11:08,995] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.4656630e-08 9.9999762e-01 1.4828405e-17 3.2847993e-08 2.3978469e-06], sum to 1.0000
[2019-03-23 15:11:09,003] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4605
[2019-03-23 15:11:09,005] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 78.0, 1.0, 2.0, 0.3879534177026969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 437139.9138610353, 437139.913861035, 123754.4845167187], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4314600.0000, 
sim time next is 4315200.0000, 
raw observation next is [21.0, 78.0, 1.0, 2.0, 0.387885406690665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 437062.427105518, 437062.4271055183, 123748.0137970932], 
processed observation next is [1.0, 0.9565217391304348, 0.5909090909090909, 0.78, 1.0, 1.0, 0.23485675836333125, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1618749730020437, 0.16187497300204381, 0.30182442389534925], 
reward next is 0.6982, 
noisyNet noise sample is [array([-1.0516787], dtype=float32), -0.86184716]. 
=============================================
[2019-03-23 15:11:10,001] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.9206814e-08 9.9999523e-01 7.0784843e-17 1.0166580e-07 4.5315942e-06], sum to 1.0000
[2019-03-23 15:11:10,007] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2926
[2019-03-23 15:11:10,015] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3801155654502506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 426827.45278115, 426827.45278115, 122306.0024549569], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4327200.0000, 
sim time next is 4327800.0000, 
raw observation next is [18.0, 99.00000000000001, 1.0, 2.0, 0.5022717021895925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 563683.4274932903, 563683.4274932906, 133631.7807083645], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 0.9900000000000001, 1.0, 1.0, 0.3778396277369906, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20877163981232974, 0.20877163981232985, 0.3259311724594256], 
reward next is 0.6741, 
noisyNet noise sample is [array([-0.0717037], dtype=float32), -1.2071348]. 
=============================================
[2019-03-23 15:11:12,104] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 15:11:12,107] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:11:12,107] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:11:12,111] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:11:12,112] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:11:12,113] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:11:12,113] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:11:12,113] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:11:12,114] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:11:12,114] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:11:12,114] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:11:12,130] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run65
[2019-03-23 15:11:12,166] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run65
[2019-03-23 15:11:12,195] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run65
[2019-03-23 15:11:12,197] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run65
[2019-03-23 15:11:12,271] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run65
[2019-03-23 15:11:19,665] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05817081], dtype=float32), 0.29277027]
[2019-03-23 15:11:19,667] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.76768779, 69.79145202999999, 1.0, 2.0, 0.3932264669581655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 436444.1581301268, 436444.1581301264, 125551.7064330988]
[2019-03-23 15:11:19,667] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:11:19,669] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.4295959e-10 1.0000000e+00 3.3555624e-18 1.8941637e-10 9.5614121e-09], sampled 0.6126518451810825
[2019-03-23 15:12:08,087] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05817081], dtype=float32), 0.29277027]
[2019-03-23 15:12:08,088] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.23042651, 97.62856286333333, 1.0, 2.0, 0.3520520190543696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 388486.835408016, 388486.835408016, 121325.5637485137]
[2019-03-23 15:12:08,089] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:12:08,091] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.3607731e-10 1.0000000e+00 2.5943627e-18 1.6397780e-10 8.4972536e-09], sampled 0.27276292965300764
[2019-03-23 15:12:14,166] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05817081], dtype=float32), 0.29277027]
[2019-03-23 15:12:14,167] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.83333333333333, 63.33333333333334, 1.0, 2.0, 0.3210170473124585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 350365.2871754362, 350365.2871754362, 117555.4989208504]
[2019-03-23 15:12:14,169] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:12:14,173] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.2203700e-10 1.0000000e+00 3.9824429e-18 2.0848483e-10 1.0349084e-08], sampled 0.4679965688139348
[2019-03-23 15:12:22,228] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05817081], dtype=float32), 0.29277027]
[2019-03-23 15:12:22,229] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.86666666666667, 73.0, 1.0, 2.0, 0.3270730392961699, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 359857.6206719745, 359857.6206719745, 114715.9419171454]
[2019-03-23 15:12:22,231] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:12:22,234] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.3516431e-10 1.0000000e+00 1.9595832e-18 1.4007906e-10 7.4620319e-09], sampled 0.9308833870773716
[2019-03-23 15:12:28,362] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05817081], dtype=float32), 0.29277027]
[2019-03-23 15:12:28,363] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.03333333333333, 79.33333333333334, 1.0, 2.0, 0.2927075466375137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 317814.7639718594, 317814.7639718594, 113767.2898008032]
[2019-03-23 15:12:28,365] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:12:28,367] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.6285537e-10 1.0000000e+00 1.5574484e-18 1.2316440e-10 6.7073196e-09], sampled 0.14488393950542533
[2019-03-23 15:12:46,181] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05817081], dtype=float32), 0.29277027]
[2019-03-23 15:12:46,182] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.9, 85.0, 1.0, 2.0, 0.6221943614585355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 706401.734163595, 706401.734163595, 151191.0956468932]
[2019-03-23 15:12:46,183] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:12:46,185] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.8288070e-09 1.0000000e+00 5.9702674e-17 9.5238406e-10 3.6165492e-08], sampled 0.8162209116722668
[2019-03-23 15:12:48,959] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05817081], dtype=float32), 0.29277027]
[2019-03-23 15:12:48,960] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.2, 63.66666666666666, 1.0, 2.0, 0.2774105260154257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 301219.2576093861, 301219.2576093858, 93323.63514415467]
[2019-03-23 15:12:48,962] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:12:48,964] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.8441172e-09 1.0000000e+00 1.4893804e-17 4.3692647e-10 1.9043123e-08], sampled 0.5218625089463247
[2019-03-23 15:12:51,690] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05817081], dtype=float32), 0.29277027]
[2019-03-23 15:12:51,691] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.0, 81.0, 1.0, 2.0, 0.2049771786315231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 222541.6209374441, 222541.6209374434, 78884.5404042597]
[2019-03-23 15:12:51,691] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:12:51,695] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.5316503e-10 1.0000000e+00 2.7117115e-18 1.6810320e-10 8.6628473e-09], sampled 0.7814232660920488
[2019-03-23 15:12:57,245] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 15:12:57,411] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 15:12:57,588] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 15:12:57,821] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 15:12:57,821] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 15:12:58,840] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1600000, evaluation results [1600000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 15:13:12,158] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.4580938e-10 1.0000000e+00 2.3024345e-19 1.6458546e-09 3.3131267e-09], sum to 1.0000
[2019-03-23 15:13:12,161] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0599
[2019-03-23 15:13:12,167] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 54.0, 1.0, 2.0, 0.4536748712723688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 492708.4444126735, 492708.4444126735, 122828.4902551141], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4620000.0000, 
sim time next is 4620600.0000, 
raw observation next is [22.0, 53.0, 1.0, 2.0, 0.4506843349609758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489458.971376766, 489458.971376766, 122577.3872089795], 
processed observation next is [1.0, 0.4782608695652174, 0.6363636363636364, 0.53, 1.0, 1.0, 0.31335541870121975, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18128110050991333, 0.18128110050991333, 0.29896923709507195], 
reward next is 0.7010, 
noisyNet noise sample is [array([0.89675117], dtype=float32), 0.007833403]. 
=============================================
[2019-03-23 15:13:16,061] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.2344492e-12 1.0000000e+00 6.9779354e-22 3.4762915e-11 2.2407069e-11], sum to 1.0000
[2019-03-23 15:13:16,070] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4595
[2019-03-23 15:13:16,077] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 87.00000000000001, 1.0, 2.0, 0.2194727158757639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 238293.528875358, 238293.528875358, 74672.27844658685], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4684200.0000, 
sim time next is 4684800.0000, 
raw observation next is [14.0, 86.0, 1.0, 2.0, 0.2105302754364159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 228581.9508431006, 228581.9508431003, 73724.72356642838], 
processed observation next is [1.0, 0.21739130434782608, 0.2727272727272727, 0.86, 1.0, 1.0, 0.013162844295519852, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08465998179374097, 0.08465998179374085, 0.17981639894250825], 
reward next is 0.8202, 
noisyNet noise sample is [array([0.03827764], dtype=float32), 1.8909729]. 
=============================================
[2019-03-23 15:13:19,601] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.3202150e-10 1.0000000e+00 1.0757514e-18 2.4367328e-10 7.7899225e-09], sum to 1.0000
[2019-03-23 15:13:19,609] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9223
[2019-03-23 15:13:19,612] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3663806582901976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 411285.1430031187, 411285.143003119, 121077.9564935384], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4772400.0000, 
sim time next is 4773000.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3663540995795839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 411254.8178266307, 411254.8178266307, 121075.4712814174], 
processed observation next is [1.0, 0.21739130434782608, 0.45454545454545453, 1.0, 1.0, 1.0, 0.2079426244744799, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15231659919504842, 0.15231659919504842, 0.2953060275156522], 
reward next is 0.7047, 
noisyNet noise sample is [array([-0.4193468], dtype=float32), -0.95028836]. 
=============================================
[2019-03-23 15:13:19,630] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[68.19911 ]
 [68.196045]
 [68.24759 ]
 [68.2468  ]
 [68.23308 ]], R is [[68.17233276]
 [68.19529724]
 [68.21800232]
 [68.240242  ]
 [68.26091766]].
[2019-03-23 15:13:19,638] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2916360e-10 1.0000000e+00 9.6491135e-20 7.7251550e-10 9.3680939e-09], sum to 1.0000
[2019-03-23 15:13:19,645] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2350
[2019-03-23 15:13:19,650] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 88.0, 1.0, 2.0, 0.3631303394337053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 405833.5393905484, 405833.5393905484, 119957.6590568011], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4758000.0000, 
sim time next is 4758600.0000, 
raw observation next is [19.0, 88.0, 1.0, 2.0, 0.3626766045012074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 405324.367637117, 405324.3676371168, 119919.4738540799], 
processed observation next is [1.0, 0.043478260869565216, 0.5, 0.88, 1.0, 1.0, 0.20334575562650925, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15012013616189518, 0.15012013616189512, 0.29248652159531685], 
reward next is 0.7075, 
noisyNet noise sample is [array([-0.18005984], dtype=float32), -0.29711]. 
=============================================
[2019-03-23 15:13:21,365] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.8915663e-10 1.0000000e+00 1.1978600e-18 3.4646119e-09 9.5975849e-10], sum to 1.0000
[2019-03-23 15:13:21,374] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9475
[2019-03-23 15:13:21,380] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.83333333333334, 90.0, 1.0, 2.0, 0.3917875098594686, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 438228.1907088398, 438228.1907088398, 122526.0570459832], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4763400.0000, 
sim time next is 4764000.0000, 
raw observation next is [18.66666666666667, 92.0, 1.0, 2.0, 0.3766391310395173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 421621.7667289701, 421621.7667289701, 121390.6721093046], 
processed observation next is [1.0, 0.13043478260869565, 0.4848484848484851, 0.92, 1.0, 1.0, 0.2207989137993966, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15615620989961856, 0.15615620989961856, 0.29607481002269415], 
reward next is 0.7039, 
noisyNet noise sample is [array([-1.2764919], dtype=float32), 0.6800518]. 
=============================================
[2019-03-23 15:13:21,397] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[62.564827]
 [62.62542 ]
 [62.770145]
 [62.83439 ]
 [62.889317]], R is [[62.54946518]
 [62.62512589]
 [62.70434952]
 [62.78261948]
 [62.85907364]].
[2019-03-23 15:13:23,157] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7980847e-10 1.0000000e+00 7.9122423e-18 2.1226347e-09 1.6873065e-09], sum to 1.0000
[2019-03-23 15:13:23,163] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5940
[2019-03-23 15:13:23,168] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4568896393274866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 518029.3505497647, 518029.3505497644, 132035.9268510284], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4864800.0000, 
sim time next is 4865400.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4661425616334453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 528543.5336695788, 528543.5336695788, 132989.8579308875], 
processed observation next is [1.0, 0.30434782608695654, 0.5, 1.0, 1.0, 1.0, 0.3326782020418066, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19575686432206624, 0.19575686432206624, 0.3243655071485061], 
reward next is 0.6756, 
noisyNet noise sample is [array([-1.3793497], dtype=float32), 0.122708134]. 
=============================================
[2019-03-23 15:13:29,177] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.0764034e-10 1.0000000e+00 1.5212012e-19 8.5556495e-10 2.0960843e-10], sum to 1.0000
[2019-03-23 15:13:29,184] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3905
[2019-03-23 15:13:29,189] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 97.0, 1.0, 2.0, 0.3777030424279411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 419500.1296384802, 419500.1296384802, 120062.5292917263], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4937400.0000, 
sim time next is 4938000.0000, 
raw observation next is [17.33333333333333, 98.0, 1.0, 2.0, 0.3634933020144666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 403301.4005478691, 403301.4005478694, 118742.8143810297], 
processed observation next is [1.0, 0.13043478260869565, 0.42424242424242403, 0.98, 1.0, 1.0, 0.20436662751808324, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14937088909180338, 0.1493708890918035, 0.28961662044153585], 
reward next is 0.7104, 
noisyNet noise sample is [array([-1.8845463], dtype=float32), 0.6500039]. 
=============================================
[2019-03-23 15:13:29,213] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[62.778175]
 [62.82366 ]
 [62.726505]
 [62.8091  ]
 [62.855247]], R is [[62.85604477]
 [62.93465042]
 [63.01006317]
 [63.0763855 ]
 [63.15090942]].
[2019-03-23 15:13:39,712] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.8077958e-10 1.0000000e+00 3.9871532e-19 3.3722514e-10 2.0602328e-10], sum to 1.0000
[2019-03-23 15:13:39,720] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5895
[2019-03-23 15:13:39,726] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 77.0, 1.0, 2.0, 0.5006073544442183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 570390.3987810084, 570390.3987810081, 142797.5310649717], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5138400.0000, 
sim time next is 5139000.0000, 
raw observation next is [24.5, 78.5, 1.0, 2.0, 0.5036350978861786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 573724.5070343501, 573724.5070343501, 143266.2989881079], 
processed observation next is [0.0, 0.4782608695652174, 0.75, 0.785, 1.0, 1.0, 0.37954387235772313, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2124905581608704, 0.2124905581608704, 0.3494299975319705], 
reward next is 0.6506, 
noisyNet noise sample is [array([0.7763008], dtype=float32), -0.4235119]. 
=============================================
[2019-03-23 15:13:39,741] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[64.43697]
 [64.42738]
 [64.44034]
 [64.4271 ]
 [64.43122]], R is [[64.4535675 ]
 [64.46074677]
 [64.46915436]
 [64.47927094]
 [64.49201202]].
[2019-03-23 15:13:43,232] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.3195960e-10 1.0000000e+00 4.3928196e-18 3.2531440e-09 3.0827301e-09], sum to 1.0000
[2019-03-23 15:13:43,242] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8648
[2019-03-23 15:13:43,246] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 100.0, 1.0, 2.0, 0.5091433106194566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 580323.253879287, 580323.2538792868, 143602.2588631997], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5263200.0000, 
sim time next is 5263800.0000, 
raw observation next is [21.43333333333333, 100.0, 1.0, 2.0, 0.5077729129636704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 578833.6500893852, 578833.6500893852, 143353.6001958245], 
processed observation next is [1.0, 0.9565217391304348, 0.6106060606060605, 1.0, 1.0, 1.0, 0.384716141204588, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21438283336643896, 0.21438283336643896, 0.349642927306889], 
reward next is 0.6504, 
noisyNet noise sample is [array([0.11512418], dtype=float32), 1.7434628]. 
=============================================
[2019-03-23 15:13:43,522] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.2932600e-09 1.0000000e+00 4.5117375e-17 7.6689748e-09 7.9945748e-09], sum to 1.0000
[2019-03-23 15:13:43,537] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0427
[2019-03-23 15:13:43,544] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.4200482109279168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 477907.2206717658, 477907.2206717655, 129736.5721575049], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5194800.0000, 
sim time next is 5195400.0000, 
raw observation next is [21.16666666666667, 87.16666666666667, 1.0, 2.0, 0.4787663135441901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 544860.7374841576, 544860.7374841576, 135875.6213869433], 
processed observation next is [1.0, 0.13043478260869565, 0.5984848484848487, 0.8716666666666667, 1.0, 1.0, 0.3484578919302376, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20180027314228058, 0.20180027314228058, 0.3314039546023007], 
reward next is 0.6686, 
noisyNet noise sample is [array([0.54898363], dtype=float32), -0.39652652]. 
=============================================
[2019-03-23 15:13:45,009] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.7202143e-09 1.0000000e+00 6.2640196e-18 1.1163077e-09 1.1235447e-09], sum to 1.0000
[2019-03-23 15:13:45,015] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6053
[2019-03-23 15:13:45,022] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.6899946006261096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344315566, 786958.2313845264, 786958.2313845267, 167182.0625068035], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5229600.0000, 
sim time next is 5230200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.7278931114242033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344353865, 830202.4288318651, 830202.4288318651, 172833.3298808995], 
processed observation next is [1.0, 0.5217391304347826, 0.6363636363636364, 0.94, 1.0, 1.0, 0.6598663892802542, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206385, 0.3074823810488389, 0.3074823810488389, 0.42154470702658414], 
reward next is 0.5785, 
noisyNet noise sample is [array([0.9190176], dtype=float32), -0.14308852]. 
=============================================
[2019-03-23 15:13:46,905] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 15:13:46,906] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:13:46,907] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:13:46,907] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:13:46,908] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:13:46,909] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:13:46,910] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:13:46,909] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:13:46,911] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:13:46,910] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:13:46,914] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:13:46,940] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run66
[2019-03-23 15:13:46,972] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run66
[2019-03-23 15:13:46,974] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run66
[2019-03-23 15:13:47,031] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run66
[2019-03-23 15:13:47,067] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run66
[2019-03-23 15:13:53,956] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05817081], dtype=float32), 0.29908022]
[2019-03-23 15:13:53,958] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.32016878, 88.733474535, 1.0, 2.0, 0.2829716635641891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 307241.075945747, 307241.0759457474, 93879.25057671792]
[2019-03-23 15:13:53,959] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:13:53,963] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.2306190e-10 1.0000000e+00 2.2449169e-18 2.7401690e-09 2.1971156e-08], sampled 0.659239117270617
[2019-03-23 15:14:09,094] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05817081], dtype=float32), 0.29908022]
[2019-03-23 15:14:09,095] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.704676715, 45.90766487, 1.0, 2.0, 0.2293956223437908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 249057.9672742407, 249057.9672742403, 75270.48452685443]
[2019-03-23 15:14:09,097] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:14:09,100] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.1694075e-09 1.0000000e+00 4.3946468e-18 3.8055310e-09 2.9456054e-08], sampled 0.18139906539685113
[2019-03-23 15:14:38,494] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05817081], dtype=float32), 0.29908022]
[2019-03-23 15:14:38,495] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.15616912333333, 84.75465313166667, 1.0, 2.0, 0.3205793610370263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 351552.364082423, 351552.364082423, 118124.8889215633]
[2019-03-23 15:14:38,496] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:14:38,500] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.0484719e-10 1.0000000e+00 2.1490144e-18 2.6827705e-09 2.1550880e-08], sampled 0.6346349133707642
[2019-03-23 15:15:29,164] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05817081], dtype=float32), 0.29908022]
[2019-03-23 15:15:29,166] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.93333333333333, 62.33333333333334, 1.0, 2.0, 0.2563652437589785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 278346.0344687219, 278346.0344687215, 86412.2255790278]
[2019-03-23 15:15:29,167] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:15:29,172] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.0406355e-10 1.0000000e+00 2.6861886e-18 2.9907468e-09 2.3751317e-08], sampled 0.4420516923611111
[2019-03-23 15:15:32,800] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 15:15:32,804] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 15:15:32,932] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 15:15:32,960] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 15:15:33,003] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 15:15:34,018] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1625000, evaluation results [1625000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 15:15:35,825] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.5200407e-08 9.9999893e-01 1.3302532e-14 7.7449130e-07 3.0170389e-07], sum to 1.0000
[2019-03-23 15:15:35,829] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5377
[2019-03-23 15:15:35,837] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1483385.764294495 W.
[2019-03-23 15:15:35,841] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.48333333333333, 54.66666666666667, 1.0, 2.0, 0.6543325948204046, 1.0, 1.0, 0.6543325948204046, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 79.72364909326161, 1483385.764294495, 1483385.764294496, 276214.2782875751], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5314200.0000, 
sim time next is 5314800.0000, 
raw observation next is [28.66666666666667, 54.33333333333334, 1.0, 2.0, 0.5350863973894312, 1.0, 2.0, 0.5350863973894312, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846235425431, 1211046.498219927, 1211046.498219927, 242430.7017185586], 
processed observation next is [1.0, 0.5217391304347826, 0.9393939393939396, 0.5433333333333334, 1.0, 1.0, 0.418857996736789, 1.0, 1.0, 0.418857996736789, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288057586761, 0.44853574008145447, 0.44853574008145447, 0.5912943944355088], 
reward next is 0.4087, 
noisyNet noise sample is [array([0.3473349], dtype=float32), -0.64271855]. 
=============================================
[2019-03-23 15:15:36,426] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.9287771e-09 9.9999988e-01 1.0458731e-17 7.2422395e-08 3.1262686e-09], sum to 1.0000
[2019-03-23 15:15:36,434] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7433
[2019-03-23 15:15:36,436] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.93333333333333, 79.66666666666667, 1.0, 2.0, 0.4624986099105453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 527594.4086957108, 527594.4086957106, 135930.1338090384], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5361600.0000, 
sim time next is 5362200.0000, 
raw observation next is [22.75, 80.0, 1.0, 2.0, 0.4584245981881368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522824.5514198895, 522824.5514198895, 135207.3185086852], 
processed observation next is [1.0, 0.043478260869565216, 0.6704545454545454, 0.8, 1.0, 1.0, 0.323030747735171, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19363872274810723, 0.19363872274810723, 0.329773947582159], 
reward next is 0.6702, 
noisyNet noise sample is [array([-0.2316106], dtype=float32), -0.19646993]. 
=============================================
[2019-03-23 15:15:56,611] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.5692249e-06 9.9960893e-01 1.4900355e-11 3.2298799e-04 5.8583009e-05], sum to 1.0000
[2019-03-23 15:15:56,617] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6840
[2019-03-23 15:15:56,621] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [9.183333333333334, 95.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 129751.6756300665, 129751.6756300668, 55218.20899264651], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5724600.0000, 
sim time next is 5725200.0000, 
raw observation next is [9.566666666666668, 93.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 133835.645153397, 133835.6451533973, 55749.80378612505], 
processed observation next is [0.0, 0.2608695652173913, 0.07121212121212128, 0.9333333333333335, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.04956875746422111, 0.049568757464221215, 0.13597513118567084], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.65023875], dtype=float32), 0.50581896]. 
=============================================
[2019-03-23 15:15:56,973] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.9329479e-06 9.9987781e-01 5.9523997e-11 1.1003376e-04 8.2506504e-06], sum to 1.0000
[2019-03-23 15:15:56,979] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4640
[2019-03-23 15:15:56,987] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 49.0, 1.0, 2.0, 0.2596190249128819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 281895.2038535417, 281895.2038535417, 84106.78456096363], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5770800.0000, 
sim time next is 5771400.0000, 
raw observation next is [19.66666666666667, 52.5, 1.0, 2.0, 0.2534744484480352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 275221.5144522157, 275221.5144522155, 82446.5283090443], 
processed observation next is [0.0, 0.8260869565217391, 0.5303030303030305, 0.525, 1.0, 1.0, 0.06684306056004397, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10193389424156137, 0.1019338942415613, 0.2010890934366934], 
reward next is 0.7989, 
noisyNet noise sample is [array([-0.6337691], dtype=float32), 2.4405007]. 
=============================================
[2019-03-23 15:15:57,319] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.8885372e-04 9.9645740e-01 3.5627492e-09 2.7778018e-03 2.7594052e-04], sum to 1.0000
[2019-03-23 15:15:57,327] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1375
[2019-03-23 15:15:57,333] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.1, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 166398.1885972237, 166398.1885972237, 59998.32447174075], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5706600.0000, 
sim time next is 5707200.0000, 
raw observation next is [11.1, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 165897.7790384853, 165897.7790384855, 59932.16171255521], 
processed observation next is [0.0, 0.043478260869565216, 0.1409090909090909, 0.77, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.06144362186610567, 0.06144362186610574, 0.14617600417696391], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.34178045], dtype=float32), 1.1705852]. 
=============================================
[2019-03-23 15:15:59,625] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.2670787e-07 9.9991083e-01 5.3764649e-17 8.8081390e-05 3.5376908e-07], sum to 1.0000
[2019-03-23 15:15:59,630] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3727
[2019-03-23 15:15:59,634] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.2, 83.0, 1.0, 2.0, 0.3812226539453882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 413989.0346568893, 413989.0346568896, 86404.76461195367], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5803200.0000, 
sim time next is 5803800.0000, 
raw observation next is [12.1, 83.5, 1.0, 2.0, 0.387967420999512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 421316.6930899168, 421316.6930899168, 86952.07883430725], 
processed observation next is [1.0, 0.17391304347826086, 0.18636363636363634, 0.835, 1.0, 1.0, 0.23495927624938995, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15604321966293214, 0.15604321966293214, 0.21207824105928597], 
reward next is 0.7879, 
noisyNet noise sample is [array([-0.0319971], dtype=float32), -1.0098758]. 
=============================================
[2019-03-23 15:16:00,844] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.4542852e-09 9.9999881e-01 5.5103520e-17 1.2185841e-06 5.1316507e-09], sum to 1.0000
[2019-03-23 15:16:00,849] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8627
[2019-03-23 15:16:00,855] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.76666666666667, 60.0, 1.0, 2.0, 0.3182910001368539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 345624.0684881623, 345624.0684881625, 97775.17653572572], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5821800.0000, 
sim time next is 5822400.0000, 
raw observation next is [20.13333333333333, 59.0, 1.0, 2.0, 0.3142310908145375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 341213.9699479532, 341213.9699479535, 99467.04455876775], 
processed observation next is [1.0, 0.391304347826087, 0.5515151515151513, 0.59, 1.0, 1.0, 0.14278886351817183, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12637554442516785, 0.12637554442516796, 0.24260254770431158], 
reward next is 0.7574, 
noisyNet noise sample is [array([0.24182326], dtype=float32), 0.32352674]. 
=============================================
[2019-03-23 15:16:04,193] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.1294555e-09 9.9999821e-01 7.3733443e-19 1.7691317e-06 3.2097844e-09], sum to 1.0000
[2019-03-23 15:16:04,205] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1125
[2019-03-23 15:16:04,209] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.41666666666666, 45.0, 1.0, 2.0, 0.682811130539594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 760887.1853665427, 760887.1853665427, 151762.0927216847], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5842200.0000, 
sim time next is 5842800.0000, 
raw observation next is [25.5, 45.0, 1.0, 2.0, 0.6393107077218401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 712999.961651657, 712999.9616516572, 146848.5457720732], 
processed observation next is [1.0, 0.6521739130434783, 0.7954545454545454, 0.45, 1.0, 1.0, 0.5491383846523, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2640740598709841, 0.26407405987098415, 0.35816718480993465], 
reward next is 0.6418, 
noisyNet noise sample is [array([-2.2844834], dtype=float32), -0.11888107]. 
=============================================
[2019-03-23 15:16:07,035] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.1251914e-07 9.9999928e-01 1.9027601e-16 4.4852530e-07 1.4784807e-08], sum to 1.0000
[2019-03-23 15:16:07,040] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6984
[2019-03-23 15:16:07,043] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.6, 53.0, 1.0, 2.0, 0.4637302022581887, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9242533880051601, 6.924318841571189, 6.9112, 77.32843024391451, 1058259.672773971, 1053998.943187633, 242233.9709386625], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5918400.0000, 
sim time next is 5919000.0000, 
raw observation next is [26.51666666666667, 53.16666666666667, 1.0, 2.0, 0.7848502711737385, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32845556031951, 894216.8927069157, 894216.8927069154, 175957.5475988475], 
processed observation next is [1.0, 0.5217391304347826, 0.8416666666666668, 0.5316666666666667, 1.0, 1.0, 0.7310628389671731, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084287610890673, 0.3311914417433021, 0.331191441743302, 0.42916475024109146], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.40708727], dtype=float32), -0.32141587]. 
=============================================
[2019-03-23 15:16:07,072] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[64.01063 ]
 [63.269333]
 [63.476147]
 [63.339993]
 [63.25324 ]], R is [[64.01968384]
 [63.37948608]
 [63.20637512]
 [63.07631683]
 [62.95435715]].
[2019-03-23 15:16:07,729] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.18012004e-07 9.99999881e-01 1.55905316e-18 3.20903233e-08
 2.23287717e-08], sum to 1.0000
[2019-03-23 15:16:07,735] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2116
[2019-03-23 15:16:07,741] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.56666666666667, 91.0, 1.0, 2.0, 0.3430250219261102, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 376856.0284211306, 376856.0284211303, 115693.736817917], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5984400.0000, 
sim time next is 5985000.0000, 
raw observation next is [17.75, 90.0, 1.0, 2.0, 0.3482243493289059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 383055.9358081593, 383055.9358081593, 116261.6501106934], 
processed observation next is [1.0, 0.2608695652173913, 0.4431818181818182, 0.9, 1.0, 1.0, 0.18528043666113234, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14187256881783677, 0.14187256881783677, 0.2835650002699839], 
reward next is 0.7164, 
noisyNet noise sample is [array([0.593544], dtype=float32), -0.57733536]. 
=============================================
[2019-03-23 15:16:07,756] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[66.94021]
 [67.04659]
 [67.1976 ]
 [67.17919]
 [67.15494]], R is [[66.82491302]
 [66.8744812 ]
 [66.92401886]
 [66.97699738]
 [67.02858734]].
[2019-03-23 15:16:08,400] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.7976742e-07 9.9999869e-01 2.3131226e-16 3.3091661e-07 7.1953383e-07], sum to 1.0000
[2019-03-23 15:16:08,415] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4056
[2019-03-23 15:16:08,422] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 93.0, 1.0, 2.0, 0.3224905115041716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 353491.0056981635, 353491.0056981635, 113889.0135778924], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5983200.0000, 
sim time next is 5983800.0000, 
raw observation next is [17.38333333333333, 92.0, 1.0, 2.0, 0.3429192450554173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 376239.8284291545, 376239.8284291545, 115504.2677320517], 
processed observation next is [1.0, 0.2608695652173913, 0.42651515151515135, 0.92, 1.0, 1.0, 0.17864905631927164, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13934808460339057, 0.13934808460339057, 0.2817177261757358], 
reward next is 0.7183, 
noisyNet noise sample is [array([-1.9581199], dtype=float32), -0.6623345]. 
=============================================
[2019-03-23 15:16:13,137] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.7932244e-09 9.9999952e-01 1.5077632e-18 6.0843042e-09 4.2015566e-07], sum to 1.0000
[2019-03-23 15:16:13,150] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7227
[2019-03-23 15:16:13,156] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.6, 72.0, 1.0, 2.0, 0.2315449773833165, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 251404.4308814825, 251404.4308814825, 78960.16244624881], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6076800.0000, 
sim time next is 6077400.0000, 
raw observation next is [16.78333333333333, 70.83333333333333, 1.0, 2.0, 0.2493784773031968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 270772.8877954859, 270772.8877954859, 80916.13507585571], 
processed observation next is [1.0, 0.34782608695652173, 0.3992424242424242, 0.7083333333333333, 1.0, 1.0, 0.06172309662899597, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10028625473906885, 0.10028625473906885, 0.19735642701428222], 
reward next is 0.8026, 
noisyNet noise sample is [array([-0.8633326], dtype=float32), 0.82980406]. 
=============================================
[2019-03-23 15:16:14,083] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.4247534e-07 9.9990165e-01 1.0315790e-15 1.5496011e-06 9.5900235e-05], sum to 1.0000
[2019-03-23 15:16:14,091] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9292
[2019-03-23 15:16:14,097] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.8, 76.0, 1.0, 2.0, 0.2216784694222283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 240689.0286765649, 240689.0286765649, 76799.35049337146], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6075000.0000, 
sim time next is 6075600.0000, 
raw observation next is [16.06666666666667, 74.66666666666667, 1.0, 2.0, 0.2244057218486411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 243650.9047374635, 243650.9047374635, 77441.49270844988], 
processed observation next is [1.0, 0.30434782608695654, 0.3666666666666668, 0.7466666666666667, 1.0, 1.0, 0.030507152310801366, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09024107582869019, 0.09024107582869019, 0.18888168953280457], 
reward next is 0.8111, 
noisyNet noise sample is [array([-1.6467052], dtype=float32), -0.2246328]. 
=============================================
[2019-03-23 15:16:18,833] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.5536868e-09 9.9999964e-01 2.5515788e-18 7.5596191e-08 1.9438171e-07], sum to 1.0000
[2019-03-23 15:16:18,842] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6532
[2019-03-23 15:16:18,846] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.1, 64.0, 1.0, 2.0, 0.268730529744953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 291791.4740767277, 291791.4740767274, 91850.72468579937], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6125400.0000, 
sim time next is 6126000.0000, 
raw observation next is [19.0, 64.33333333333333, 1.0, 2.0, 0.2682923149222408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 291315.511611458, 291315.5116114577, 91331.52316341303], 
processed observation next is [1.0, 0.9130434782608695, 0.5, 0.6433333333333333, 1.0, 1.0, 0.085365393652801, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10789463393016963, 0.10789463393016951, 0.22275981259369032], 
reward next is 0.7772, 
noisyNet noise sample is [array([-0.09592732], dtype=float32), 1.0127803]. 
=============================================
[2019-03-23 15:16:18,866] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[71.34868 ]
 [71.343155]
 [71.35609 ]
 [71.36216 ]
 [71.3193  ]], R is [[71.40181732]
 [71.46376801]
 [71.52370453]
 [71.58140564]
 [71.63680267]].
[2019-03-23 15:16:21,958] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1469484e-08 9.9999917e-01 1.9143494e-17 7.7132604e-08 7.3235555e-07], sum to 1.0000
[2019-03-23 15:16:21,965] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3576
[2019-03-23 15:16:21,969] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 60.0, 1.0, 2.0, 0.7907690574075777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 889596.4403636695, 889596.4403636693, 169272.0546560945], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6188400.0000, 
sim time next is 6189000.0000, 
raw observation next is [23.2, 60.66666666666666, 1.0, 2.0, 0.8480711552539869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 954207.6555969612, 954207.6555969614, 177579.8105158625], 
processed observation next is [1.0, 0.6521739130434783, 0.6909090909090909, 0.6066666666666666, 1.0, 1.0, 0.8100889440674836, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3534102428136893, 0.3534102428136894, 0.4331214890630793], 
reward next is 0.5669, 
noisyNet noise sample is [array([-1.2523797], dtype=float32), 0.386725]. 
=============================================
[2019-03-23 15:16:21,981] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[67.82388 ]
 [67.61793 ]
 [67.502884]
 [67.40483 ]
 [67.35405 ]], R is [[67.65284729]
 [67.5634613 ]
 [67.47332764]
 [67.38193512]
 [67.2909317 ]].
[2019-03-23 15:16:22,236] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 15:16:22,237] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:16:22,238] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:16:22,238] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:16:22,238] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:16:22,239] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:16:22,242] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:16:22,243] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:16:22,244] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:16:22,244] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:16:22,244] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:16:22,267] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run67
[2019-03-23 15:16:22,267] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run67
[2019-03-23 15:16:22,324] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run67
[2019-03-23 15:16:22,356] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run67
[2019-03-23 15:16:22,388] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run67
[2019-03-23 15:17:30,956] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06006972], dtype=float32), 0.30186027]
[2019-03-23 15:17:30,958] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.47235671333333, 85.94965132333333, 1.0, 2.0, 0.6274823375895882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 705044.7338443177, 705044.7338443174, 167100.8656726146]
[2019-03-23 15:17:30,959] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:17:30,963] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.3798681e-09 9.9999940e-01 2.3385665e-19 5.0323217e-09 6.1012946e-07], sampled 0.009750685859848507
[2019-03-23 15:17:33,005] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06006972], dtype=float32), 0.30186027]
[2019-03-23 15:17:33,006] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.919557, 89.32088430666667, 1.0, 2.0, 0.3529712485791848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 394726.9151588255, 394726.9151588255, 123563.12239275]
[2019-03-23 15:17:33,008] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:17:33,012] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.2240212e-09 9.9999940e-01 2.0259461e-19 4.7172604e-09 5.8124590e-07], sampled 0.09198682927571866
[2019-03-23 15:17:36,901] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06006972], dtype=float32), 0.30186027]
[2019-03-23 15:17:36,902] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.55, 65.5, 1.0, 2.0, 0.4680858852696997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 533216.1645497042, 533216.1645497042, 139668.0258879975]
[2019-03-23 15:17:36,903] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:17:36,906] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.4722084e-09 9.9999940e-01 2.5345998e-19 5.2145741e-09 6.2662792e-07], sampled 0.5311874006803751
[2019-03-23 15:17:54,732] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06006972], dtype=float32), 0.30186027]
[2019-03-23 15:17:54,733] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [29.80221395, 42.35395446, 1.0, 2.0, 0.4508381485788904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 514080.7502695856, 514080.7502695852, 138636.1317265019]
[2019-03-23 15:17:54,733] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:17:54,738] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.8406725e-09 9.9999952e-01 1.3548997e-19 3.9370609e-09 5.0764572e-07], sampled 0.49650614920404235
[2019-03-23 15:17:58,702] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06006972], dtype=float32), 0.30186027]
[2019-03-23 15:17:58,703] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.38333333333333, 46.0, 1.0, 2.0, 0.3236758041212436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 351473.4027506759, 351473.4027506756, 112807.9031664972]
[2019-03-23 15:17:58,705] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:17:58,708] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.2387138e-09 9.9999905e-01 7.9656526e-19 8.7185352e-09 9.2069320e-07], sampled 0.13490347210117648
[2019-03-23 15:17:59,542] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06006972], dtype=float32), 0.30186027]
[2019-03-23 15:17:59,544] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.56666666666667, 57.0, 1.0, 2.0, 0.6270755336945258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 693664.7661393736, 693664.7661393736, 143293.7111834965]
[2019-03-23 15:17:59,546] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:17:59,550] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.5494226e-09 9.9999833e-01 4.4763437e-18 1.8925085e-08 1.6457052e-06], sampled 0.3659398452440643
[2019-03-23 15:18:05,744] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06006972], dtype=float32), 0.30186027]
[2019-03-23 15:18:05,745] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.02917426333333, 100.0, 1.0, 2.0, 0.3153719229340254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 342699.8440625538, 342699.8440625535, 116634.1742926946]
[2019-03-23 15:18:05,746] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:18:05,748] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.3337750e-09 9.9999940e-01 2.2441868e-19 4.9384719e-09 6.0155077e-07], sampled 0.8757112305828247
[2019-03-23 15:18:08,299] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 15:18:08,384] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 15:18:08,387] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 15:18:08,604] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 15:18:08,643] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 15:18:09,661] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1650000, evaluation results [1650000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 15:18:09,824] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.9872873e-10 9.9999738e-01 4.3810390e-20 1.2555724e-08 2.6588352e-06], sum to 1.0000
[2019-03-23 15:18:09,830] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8143
[2019-03-23 15:18:09,834] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 89.0, 1.0, 2.0, 0.3765322358075529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 423331.5924755787, 423331.5924755787, 122262.1229737289], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6219600.0000, 
sim time next is 6220200.0000, 
raw observation next is [19.4, 89.5, 1.0, 2.0, 0.3784707132982763, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 425790.6824987381, 425790.6824987384, 122571.9032183845], 
processed observation next is [1.0, 1.0, 0.5181818181818181, 0.895, 1.0, 1.0, 0.22308839162284536, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15770025277731042, 0.1577002527773105, 0.29895586150825487], 
reward next is 0.7010, 
noisyNet noise sample is [array([-0.43027636], dtype=float32), 2.3384109]. 
=============================================
[2019-03-23 15:18:16,047] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6592097e-07 9.9999154e-01 1.8973310e-16 6.7615481e-08 8.1940379e-06], sum to 1.0000
[2019-03-23 15:18:16,057] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7660
[2019-03-23 15:18:16,066] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 61.0, 1.0, 2.0, 0.5522878624225768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 626536.1941695438, 626536.1941695438, 150769.1194935606], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6364800.0000, 
sim time next is 6365400.0000, 
raw observation next is [28.3, 61.0, 1.0, 2.0, 0.5513584524414625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 625508.7500763036, 625508.7500763036, 150638.0677154756], 
processed observation next is [0.0, 0.6956521739130435, 0.9227272727272727, 0.61, 1.0, 1.0, 0.4391980655518281, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.231669907435668, 0.231669907435668, 0.3674099212572576], 
reward next is 0.6326, 
noisyNet noise sample is [array([-0.3534731], dtype=float32), 0.07089902]. 
=============================================
[2019-03-23 15:18:17,732] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4993133e-08 9.9999678e-01 2.5304141e-16 3.0116854e-07 2.8442000e-06], sum to 1.0000
[2019-03-23 15:18:17,746] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2427
[2019-03-23 15:18:17,751] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 61.0, 1.0, 2.0, 0.550748862446027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 624818.803120832, 624818.803120832, 150558.7741364893], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6366000.0000, 
sim time next is 6366600.0000, 
raw observation next is [28.3, 61.0, 1.0, 2.0, 0.5507339376808824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 624802.3237914469, 624802.3237914469, 150556.6629894989], 
processed observation next is [0.0, 0.6956521739130435, 0.9227272727272727, 0.61, 1.0, 1.0, 0.43841742210110296, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23140826807090625, 0.23140826807090625, 0.36721137314511926], 
reward next is 0.6328, 
noisyNet noise sample is [array([1.0685761], dtype=float32), -1.7999909]. 
=============================================
[2019-03-23 15:18:18,247] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.0632240e-08 9.9999952e-01 4.8368021e-18 5.2294924e-10 5.0655854e-07], sum to 1.0000
[2019-03-23 15:18:18,253] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1887
[2019-03-23 15:18:18,260] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 69.5, 1.0, 2.0, 0.4823267385159533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 550341.9150289552, 550341.9150289549, 138518.8678782719], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6413400.0000, 
sim time next is 6414000.0000, 
raw observation next is [24.6, 70.0, 1.0, 2.0, 0.4789006623566301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 546422.0181290058, 546422.0181290058, 138093.8233336702], 
processed observation next is [1.0, 0.21739130434782608, 0.7545454545454546, 0.7, 1.0, 1.0, 0.34862582794578756, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20237852523296512, 0.20237852523296512, 0.33681420325285416], 
reward next is 0.6632, 
noisyNet noise sample is [array([0.9928027], dtype=float32), -0.5190763]. 
=============================================
[2019-03-23 15:18:18,277] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[66.008934]
 [66.13215 ]
 [66.09014 ]
 [66.025314]
 [65.96333 ]], R is [[66.07886505]
 [66.08022308]
 [66.07868958]
 [66.07038116]
 [66.06761169]].
[2019-03-23 15:18:22,187] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1425878e-10 1.0000000e+00 3.1278457e-19 1.6685420e-10 2.6556350e-09], sum to 1.0000
[2019-03-23 15:18:22,193] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4123
[2019-03-23 15:18:22,196] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 75.0, 1.0, 2.0, 0.2184418313415192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 237173.9682709924, 237173.9682709927, 75164.1622824411], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6474600.0000, 
sim time next is 6475200.0000, 
raw observation next is [15.5, 75.0, 1.0, 2.0, 0.2184371739126332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 237168.9102187116, 237168.9102187113, 75161.89417478954], 
processed observation next is [1.0, 0.9565217391304348, 0.3409090909090909, 0.75, 1.0, 1.0, 0.02304646739079149, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08784033711804133, 0.08784033711804122, 0.1833216931092428], 
reward next is 0.8167, 
noisyNet noise sample is [array([-1.8133008], dtype=float32), 1.211858]. 
=============================================
[2019-03-23 15:18:22,499] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0466404e-08 1.0000000e+00 2.9629133e-17 4.4337853e-08 5.5574805e-08], sum to 1.0000
[2019-03-23 15:18:22,509] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4229
[2019-03-23 15:18:22,517] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.58333333333333, 85.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 216157.9581074132, 216157.9581074132, 71347.53201714577], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6490200.0000, 
sim time next is 6490800.0000, 
raw observation next is [13.3, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 211046.5767506244, 211046.5767506247, 70257.56040618251], 
processed observation next is [1.0, 0.13043478260869565, 0.24090909090909093, 0.87, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07816539879652755, 0.07816539879652766, 0.17135990342971344], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9898374], dtype=float32), 0.81134325]. 
=============================================
[2019-03-23 15:18:23,069] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.7626053e-07 9.9999928e-01 8.8238853e-16 1.3568136e-07 4.4061414e-07], sum to 1.0000
[2019-03-23 15:18:23,078] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4083
[2019-03-23 15:18:23,084] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.3, 89.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 208061.2876685137, 208061.2876685134, 70068.54522730455], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6505200.0000, 
sim time next is 6505800.0000, 
raw observation next is [13.66666666666667, 87.16666666666667, 1.0, 2.0, 0.223853908428028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 243051.6177355375, 243051.6177355375, 74184.69881013637], 
processed observation next is [1.0, 0.30434782608695654, 0.25757575757575774, 0.8716666666666667, 1.0, 1.0, 0.029817385535034976, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.0900191176798287, 0.0900191176798287, 0.1809382897808204], 
reward next is 0.8191, 
noisyNet noise sample is [array([-0.60009694], dtype=float32), -0.62938833]. 
=============================================
[2019-03-23 15:18:25,175] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.3143879e-11 1.0000000e+00 7.2979878e-22 3.2595690e-11 3.0001794e-09], sum to 1.0000
[2019-03-23 15:18:25,181] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5177
[2019-03-23 15:18:25,189] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.13333333333333, 50.66666666666667, 1.0, 2.0, 0.3584756192848139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 389276.9864472219, 389276.9864472222, 94203.81656419524], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6525600.0000, 
sim time next is 6526200.0000, 
raw observation next is [20.31666666666667, 49.83333333333334, 1.0, 2.0, 0.3697447049840054, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 401519.4005609863, 401519.4005609865, 95596.18491284885], 
processed observation next is [1.0, 0.5217391304347826, 0.559848484848485, 0.4983333333333334, 1.0, 1.0, 0.21218088123000675, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1487108890966616, 0.14871088909666166, 0.23316142661670453], 
reward next is 0.7668, 
noisyNet noise sample is [array([0.02276525], dtype=float32), 0.6274065]. 
=============================================
[2019-03-23 15:18:27,488] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.08000095e-05 9.99972343e-01 9.98354524e-12 6.17074591e-07
 1.61773496e-05], sum to 1.0000
[2019-03-23 15:18:27,501] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1465
[2019-03-23 15:18:27,508] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.96666666666667, 73.66666666666667, 1.0, 2.0, 0.3678214348612278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 399429.9927994924, 399429.9927994921, 96388.193403829], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6597600.0000, 
sim time next is 6598200.0000, 
raw observation next is [17.33333333333333, 71.83333333333333, 1.0, 2.0, 0.3781113532694693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 410608.8886253374, 410608.8886253377, 98293.68233338895], 
processed observation next is [1.0, 0.34782608695652173, 0.42424242424242403, 0.7183333333333333, 1.0, 1.0, 0.22263919158683662, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15207736615753237, 0.15207736615753248, 0.23974068861802184], 
reward next is 0.7603, 
noisyNet noise sample is [array([0.22608241], dtype=float32), 0.6639991]. 
=============================================
[2019-03-23 15:18:30,527] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.7779025e-10 1.0000000e+00 1.8209668e-18 1.7963271e-09 2.6161542e-09], sum to 1.0000
[2019-03-23 15:18:30,533] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4746
[2019-03-23 15:18:30,536] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 87.0, 1.0, 2.0, 0.3502069593019382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 389632.5390544949, 389632.5390544952, 118137.1348939269], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6650400.0000, 
sim time next is 6651000.0000, 
raw observation next is [18.8, 87.0, 1.0, 2.0, 0.3500655896860268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 389475.6455335013, 389475.645533501, 118126.1265674346], 
processed observation next is [1.0, 1.0, 0.49090909090909096, 0.87, 1.0, 1.0, 0.1875819871075335, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14425023908648196, 0.14425023908648185, 0.28811250382301123], 
reward next is 0.7119, 
noisyNet noise sample is [array([-0.84930575], dtype=float32), 1.4290133]. 
=============================================
[2019-03-23 15:18:30,556] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[72.132576]
 [72.18457 ]
 [72.17607 ]
 [72.14217 ]
 [72.16287 ]], R is [[72.13982391]
 [72.13028717]
 [72.12094879]
 [72.11170959]
 [72.10235596]].
[2019-03-23 15:18:30,724] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.8827995e-10 1.0000000e+00 3.3262357e-19 1.0218188e-10 1.5809119e-08], sum to 1.0000
[2019-03-23 15:18:30,732] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0126
[2019-03-23 15:18:30,736] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 87.0, 1.0, 2.0, 0.348391766578425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 387608.488432583, 387608.4884325833, 117991.9545155769], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6652200.0000, 
sim time next is 6652800.0000, 
raw observation next is [18.8, 87.0, 1.0, 2.0, 0.3477462285939625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 386887.5301668422, 386887.5301668419, 117939.9378192123], 
processed observation next is [1.0, 0.0, 0.49090909090909096, 0.87, 1.0, 1.0, 0.1846827857424531, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1432916778395712, 0.14329167783957109, 0.28765838492490803], 
reward next is 0.7123, 
noisyNet noise sample is [array([1.020793], dtype=float32), 0.94353515]. 
=============================================
[2019-03-23 15:18:32,293] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1259914e-11 1.0000000e+00 1.1741301e-20 3.1549815e-12 6.2728089e-10], sum to 1.0000
[2019-03-23 15:18:32,301] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7293
[2019-03-23 15:18:32,306] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.3690773463738448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 411839.8879447641, 411839.8879447641, 120165.9961733421], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6665400.0000, 
sim time next is 6666000.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.3637565167132937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 405897.243199237, 405897.2431992373, 119727.26358986], 
processed observation next is [1.0, 0.13043478260869565, 0.4681818181818182, 0.93, 1.0, 1.0, 0.20469564589161707, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1503323122960137, 0.1503323122960138, 0.2920177160728293], 
reward next is 0.7080, 
noisyNet noise sample is [array([1.5907929], dtype=float32), 0.28248316]. 
=============================================
[2019-03-23 15:18:32,326] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[78.29831]
 [78.22604]
 [78.01529]
 [78.18189]
 [78.12355]], R is [[78.25920868]
 [78.18352509]
 [78.11000061]
 [78.03370667]
 [77.96369934]].
[2019-03-23 15:18:35,571] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.7816521e-10 9.9999976e-01 4.4492308e-18 1.3796629e-09 2.8665144e-07], sum to 1.0000
[2019-03-23 15:18:35,581] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1683
[2019-03-23 15:18:35,585] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 76.5, 1.0, 2.0, 0.2693123685302059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 292423.4329327657, 292423.4329327655, 95112.60975720838], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6766200.0000, 
sim time next is 6766800.0000, 
raw observation next is [17.7, 77.0, 1.0, 2.0, 0.2714148173358436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 294706.9952499595, 294706.9952499595, 96153.59685177337], 
processed observation next is [1.0, 0.30434782608695654, 0.44090909090909086, 0.77, 1.0, 1.0, 0.0892685216698045, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10915073898146649, 0.10915073898146649, 0.23452096793115457], 
reward next is 0.7655, 
noisyNet noise sample is [array([-0.0061843], dtype=float32), -0.059743177]. 
=============================================
[2019-03-23 15:18:39,718] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5440254e-08 9.9998295e-01 6.8818718e-18 5.8700994e-10 1.7038230e-05], sum to 1.0000
[2019-03-23 15:18:39,727] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1412
[2019-03-23 15:18:39,736] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1100127.931836795 W.
[2019-03-23 15:18:39,744] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.1, 52.0, 1.0, 2.0, 0.484525021382036, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9344965085097485, 6.960119426678044, 6.9112, 77.32834209100223, 1100127.931836795, 1084239.927560362, 243688.2883700158], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6798600.0000, 
sim time next is 6799200.0000, 
raw observation next is [26.1, 52.0, 1.0, 2.0, 0.4797035281203563, 1.0, 1.0, 0.4797035281203563, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32843404653065, 1094615.079203158, 1094615.079203158, 218228.5256896886], 
processed observation next is [1.0, 0.6956521739130435, 0.8227272727272728, 0.52, 1.0, 1.0, 0.34962941015044535, 1.0, 0.5, 0.34962941015044535, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084286196375287, 0.4054129922974659, 0.4054129922974659, 0.5322646968041186], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.402037], dtype=float32), -0.032151256]. 
=============================================
[2019-03-23 15:18:47,298] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.5549019e-08 9.9982387e-01 1.0349148e-17 1.3269009e-07 1.7587998e-04], sum to 1.0000
[2019-03-23 15:18:47,308] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0903
[2019-03-23 15:18:47,313] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 84.0, 1.0, 2.0, 0.4558320862769702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 519827.3944477831, 519827.3944477831, 134852.8113471532], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7001400.0000, 
sim time next is 7002000.0000, 
raw observation next is [22.2, 84.0, 1.0, 2.0, 0.455536713533977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 519490.2371871269, 519490.2371871266, 134821.1300346398], 
processed observation next is [1.0, 0.043478260869565216, 0.6454545454545454, 0.84, 1.0, 1.0, 0.31942089191747125, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19240379155078774, 0.19240379155078763, 0.3288320244747312], 
reward next is 0.6712, 
noisyNet noise sample is [array([0.56336707], dtype=float32), 0.26973063]. 
=============================================
[2019-03-23 15:18:47,338] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[69.46693]
 [69.49732]
 [69.7829 ]
 [69.75679]
 [69.63218]], R is [[69.36714935]
 [69.34456635]
 [69.32213593]
 [69.29985046]
 [69.27770996]].
[2019-03-23 15:18:49,786] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.1307878e-09 9.9963415e-01 6.9072440e-17 2.4454661e-08 3.6589685e-04], sum to 1.0000
[2019-03-23 15:18:49,791] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3259
[2019-03-23 15:18:49,796] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.3, 96.16666666666666, 1.0, 2.0, 0.4143946617976223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 469377.3114757981, 469377.3114757978, 127558.6720745941], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7020600.0000, 
sim time next is 7021200.0000, 
raw observation next is [19.2, 96.33333333333333, 1.0, 2.0, 0.400390416878474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 453208.6510685413, 453208.6510685413, 126050.6941320844], 
processed observation next is [1.0, 0.2608695652173913, 0.509090909090909, 0.9633333333333333, 1.0, 1.0, 0.25048802109809243, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1678550559513116, 0.1678550559513116, 0.3074407173953278], 
reward next is 0.6926, 
noisyNet noise sample is [array([2.0593123], dtype=float32), 0.4329021]. 
=============================================
[2019-03-23 15:18:51,285] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0183712e-08 9.9997234e-01 7.5051156e-17 1.1840494e-08 2.7704320e-05], sum to 1.0000
[2019-03-23 15:18:51,293] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4347
[2019-03-23 15:18:51,297] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.3, 85.0, 1.0, 2.0, 0.3687039892438077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 411688.2088338785, 411688.2088338782, 120251.252898724], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7067400.0000, 
sim time next is 7068000.0000, 
raw observation next is [19.2, 86.0, 1.0, 2.0, 0.3685294152907144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 411601.8235565195, 411601.8235565192, 120284.757312756], 
processed observation next is [1.0, 0.8260869565217391, 0.509090909090909, 0.86, 1.0, 1.0, 0.21066176911339302, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15244511983574796, 0.15244511983574785, 0.29337745686038047], 
reward next is 0.7066, 
noisyNet noise sample is [array([-0.7356645], dtype=float32), 0.772876]. 
=============================================
[2019-03-23 15:18:51,311] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[74.43758 ]
 [74.26342 ]
 [74.369835]
 [74.413635]
 [74.18901 ]], R is [[74.47676849]
 [74.43870544]
 [74.4006958 ]
 [74.36172485]
 [74.32159424]].
[2019-03-23 15:18:54,543] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2143510e-08 9.9930024e-01 3.2029949e-17 2.0233897e-07 6.9954060e-04], sum to 1.0000
[2019-03-23 15:18:54,555] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7797
[2019-03-23 15:18:54,561] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 90.0, 1.0, 2.0, 0.3495772888626847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 388214.0501200749, 388214.0501200752, 117787.9330521604], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7081200.0000, 
sim time next is 7081800.0000, 
raw observation next is [18.2, 90.5, 1.0, 2.0, 0.3473662740136099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 385482.9183934183, 385482.9183934185, 117501.7799569425], 
processed observation next is [1.0, 1.0, 0.4636363636363636, 0.905, 1.0, 1.0, 0.1842078425170124, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14277145125682159, 0.14277145125682167, 0.28658970721205484], 
reward next is 0.7134, 
noisyNet noise sample is [array([0.3842084], dtype=float32), 1.6627626]. 
=============================================
[2019-03-23 15:18:57,626] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 15:18:57,630] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:18:57,631] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:18:57,632] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:18:57,633] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:18:57,634] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:18:57,632] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:18:57,642] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:18:57,643] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:18:57,642] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:18:57,645] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:18:57,656] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run68
[2019-03-23 15:18:57,686] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run68
[2019-03-23 15:18:57,731] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run68
[2019-03-23 15:18:57,732] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run68
[2019-03-23 15:18:57,758] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run68
[2019-03-23 15:19:22,878] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06006972], dtype=float32), 0.30600378]
[2019-03-23 15:19:22,881] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.33333333333334, 61.0, 1.0, 2.0, 0.6011610217082869, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9660747153803927, 6.911199999999999, 6.9112, 77.32846344354104, 1234448.426111216, 1234448.426111216, 266816.2511982731]
[2019-03-23 15:19:22,882] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:19:22,885] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.7424863e-07 9.9934465e-01 1.0126803e-15 1.2571687e-06 6.5391493e-04], sampled 0.1653288180348198
[2019-03-23 15:19:22,885] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1234448.426111216 W.
[2019-03-23 15:19:32,807] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06006972], dtype=float32), 0.30600378]
[2019-03-23 15:19:32,807] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.2, 54.0, 1.0, 2.0, 0.435518858250547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 495174.2074916391, 495174.2074916388, 135314.0356567302]
[2019-03-23 15:19:32,809] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:19:32,813] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.6347408e-07 9.9936348e-01 8.8530592e-16 1.1904765e-06 6.3523522e-04], sampled 0.45857769214227306
[2019-03-23 15:19:36,455] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06006972], dtype=float32), 0.30600378]
[2019-03-23 15:19:36,456] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.7379346, 88.07583788, 1.0, 2.0, 0.4917567964433071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 560809.161717957, 560809.1617179567, 145333.2894873108]
[2019-03-23 15:19:36,457] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:19:36,461] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.15940274e-07 9.99458849e-01 4.20352911e-16 8.85552367e-07
 5.40166744e-04], sampled 0.16930800470010965
[2019-03-23 15:20:04,902] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06006972], dtype=float32), 0.30600378]
[2019-03-23 15:20:04,904] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.377411255, 90.587738805, 1.0, 2.0, 0.3490266218146661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 391740.1970297527, 391740.1970297524, 123929.3499154574]
[2019-03-23 15:20:04,904] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:20:04,908] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.8526115e-07 9.9883717e-01 1.4025790e-14 3.5662365e-06 1.1586613e-03], sampled 0.9313670275126101
[2019-03-23 15:20:34,098] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06006972], dtype=float32), 0.30600378]
[2019-03-23 15:20:34,100] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.5, 86.0, 1.0, 2.0, 0.4865964941827433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 555193.3424435989, 555193.3424435986, 143768.8184624894]
[2019-03-23 15:20:34,101] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:20:34,103] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.3868319e-07 9.9941099e-01 6.1981737e-16 1.0332194e-06 5.8782456e-04], sampled 0.21696530663451796
[2019-03-23 15:20:43,618] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8496.4353 1773912328.4245 172.0000
[2019-03-23 15:20:43,642] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8846.1329 1664322883.6001 105.0000
[2019-03-23 15:20:43,875] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9049.6841 1656711244.6254 80.0000
[2019-03-23 15:20:44,055] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8557.5206 1684209630.0289 214.0000
[2019-03-23 15:20:44,112] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8586.5486 1706405431.9213 465.0000
[2019-03-23 15:20:45,131] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1675000, evaluation results [1675000.0, 8496.435284180998, 1773912328.424501, 172.0, 9049.684100704257, 1656711244.6254332, 80.0, 8846.132879854425, 1664322883.6000936, 105.0, 8586.548553783627, 1706405431.9213123, 465.0, 8557.520577430774, 1684209630.0288608, 214.0]
[2019-03-23 15:20:52,328] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.4145075e-07 9.9986410e-01 6.5603430e-17 6.6444341e-07 1.3454421e-04], sum to 1.0000
[2019-03-23 15:20:52,336] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1777
[2019-03-23 15:20:52,345] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.8, 79.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 213585.0310434536, 213585.0310434533, 70039.07985765905], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7278600.0000, 
sim time next is 7279200.0000, 
raw observation next is [13.8, 78.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 214352.9149994753, 214352.9149994756, 69981.9586707609], 
processed observation next is [1.0, 0.2608695652173913, 0.26363636363636367, 0.78, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07938996851832418, 0.07938996851832429, 0.1706877040750266], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.86786216], dtype=float32), 0.3929249]. 
=============================================
[2019-03-23 15:20:58,920] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.1710473e-08 9.9999869e-01 2.3667910e-18 4.8492699e-10 1.3144582e-06], sum to 1.0000
[2019-03-23 15:20:58,928] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2257
[2019-03-23 15:20:58,935] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.8, 98.66666666666667, 1.0, 2.0, 0.3296632341862664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 362638.0339752765, 362638.0339752762, 114879.7906836944], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7453200.0000, 
sim time next is 7453800.0000, 
raw observation next is [16.9, 98.0, 1.0, 2.0, 0.3303368309730801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 363572.8956297837, 363572.8956297837, 115002.1656544499], 
processed observation next is [0.0, 0.2608695652173913, 0.4045454545454545, 0.98, 1.0, 1.0, 0.16292103871635008, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13465662801103098, 0.13465662801103098, 0.2804930869620729], 
reward next is 0.7195, 
noisyNet noise sample is [array([-1.1738566], dtype=float32), -1.0880057]. 
=============================================
[2019-03-23 15:20:59,397] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.7694968e-08 9.9998724e-01 3.1651133e-17 2.6389788e-09 1.2731609e-05], sum to 1.0000
[2019-03-23 15:20:59,402] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7370
[2019-03-23 15:20:59,411] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 83.0, 1.0, 2.0, 0.4389912615326718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499356.6161539679, 499356.6161539679, 131523.0054827354], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7414200.0000, 
sim time next is 7414800.0000, 
raw observation next is [21.6, 82.66666666666667, 1.0, 2.0, 0.4370383350716713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 497024.8540977551, 497024.8540977548, 131226.2247135266], 
processed observation next is [1.0, 0.8260869565217391, 0.6181818181818183, 0.8266666666666667, 1.0, 1.0, 0.29629791883958906, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18408327929546486, 0.18408327929546475, 0.3200639627159186], 
reward next is 0.6799, 
noisyNet noise sample is [array([-1.0729088], dtype=float32), -0.031630594]. 
=============================================
[2019-03-23 15:21:10,763] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.2913429e-09 1.0000000e+00 6.5186204e-18 4.9309618e-10 1.6497770e-09], sum to 1.0000
[2019-03-23 15:21:10,771] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8198
[2019-03-23 15:21:10,776] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.15, 59.0, 1.0, 2.0, 0.4697651417394652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 535888.337443922, 535888.337443922, 138280.9944323242], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7666200.0000, 
sim time next is 7666800.0000, 
raw observation next is [26.96666666666667, 59.33333333333334, 1.0, 2.0, 0.4702786757371666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 536552.4441047359, 536552.4441047359, 138108.8229264068], 
processed observation next is [1.0, 0.7391304347826086, 0.8621212121212122, 0.5933333333333334, 1.0, 1.0, 0.3378483446714582, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19872312744619847, 0.19872312744619847, 0.33685078762538245], 
reward next is 0.6631, 
noisyNet noise sample is [array([0.5839514], dtype=float32), 1.2583137]. 
=============================================
[2019-03-23 15:21:12,914] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7927238e-08 1.0000000e+00 3.1186138e-18 1.5396013e-09 2.2800186e-09], sum to 1.0000
[2019-03-23 15:21:12,920] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8348
[2019-03-23 15:21:12,929] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 48.0, 1.0, 2.0, 0.7390443687676425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 807286.2870434107, 807286.2870434107, 152998.9282638567], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7743600.0000, 
sim time next is 7744200.0000, 
raw observation next is [23.2, 47.66666666666666, 1.0, 2.0, 0.7840678050338042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 856104.6265578347, 856104.6265578347, 158361.3364550613], 
processed observation next is [1.0, 0.6521739130434783, 0.6909090909090909, 0.47666666666666657, 1.0, 1.0, 0.7300847562922552, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.31707578761401284, 0.31707578761401284, 0.38624716208551535], 
reward next is 0.6138, 
noisyNet noise sample is [array([-0.34933972], dtype=float32), -0.3208813]. 
=============================================
[2019-03-23 15:21:14,927] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.0804083e-10 1.0000000e+00 4.3104805e-20 4.0207414e-11 1.4338363e-11], sum to 1.0000
[2019-03-23 15:21:14,937] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1920
[2019-03-23 15:21:14,940] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 57.0, 1.0, 2.0, 0.2634095527107171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 286012.1818046219, 286012.1818046216, 82874.43580390759], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7765200.0000, 
sim time next is 7765800.0000, 
raw observation next is [18.61666666666667, 58.0, 1.0, 2.0, 0.2620948233396426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 284584.2205589421, 284584.2205589418, 82636.52113082484], 
processed observation next is [1.0, 0.9130434782608695, 0.48257575757575777, 0.58, 1.0, 1.0, 0.07761852917455327, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10540156316997856, 0.10540156316997844, 0.2015524905629874], 
reward next is 0.7984, 
noisyNet noise sample is [array([2.0373373], dtype=float32), 0.03189316]. 
=============================================
[2019-03-23 15:21:18,705] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2906767e-12 1.0000000e+00 5.9410099e-23 1.1694542e-13 1.7346160e-13], sum to 1.0000
[2019-03-23 15:21:18,711] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9130
[2019-03-23 15:21:18,715] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.38333333333333, 50.5, 1.0, 2.0, 0.308035639032129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 334484.2039011743, 334484.2039011743, 110329.1182433779], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7840200.0000, 
sim time next is 7840800.0000, 
raw observation next is [22.2, 51.0, 1.0, 2.0, 0.3078338686020184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 334265.0337525255, 334265.0337525257, 108549.3515038055], 
processed observation next is [1.0, 0.782608695652174, 0.6454545454545454, 0.51, 1.0, 1.0, 0.13479233575252297, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12380186435278723, 0.1238018643527873, 0.26475451586294024], 
reward next is 0.7352, 
noisyNet noise sample is [array([0.434069], dtype=float32), 0.35725793]. 
=============================================
[2019-03-23 15:21:24,042] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:21:24,043] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:21:24,077] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run9
[2019-03-23 15:21:24,798] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:21:24,799] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:21:24,827] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run9
[2019-03-23 15:21:24,979] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:21:24,979] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:21:24,984] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run9
[2019-03-23 15:21:25,034] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:21:25,036] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:21:25,050] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run9
[2019-03-23 15:21:25,217] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:21:25,217] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:21:25,219] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run9
[2019-03-23 15:21:25,249] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:21:25,250] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:21:25,254] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run9
[2019-03-23 15:21:25,509] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:21:25,509] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:21:25,513] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run9
[2019-03-23 15:21:25,549] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:21:25,549] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:21:25,553] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run9
[2019-03-23 15:21:25,645] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:21:25,645] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:21:25,648] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run9
[2019-03-23 15:21:25,685] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:21:25,685] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:21:25,686] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:21:25,686] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:21:25,692] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run9
[2019-03-23 15:21:25,695] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run9
[2019-03-23 15:21:25,877] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:21:25,877] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:21:25,880] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run9
[2019-03-23 15:21:26,057] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:21:26,058] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:21:26,066] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run9
[2019-03-23 15:21:26,176] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:21:26,176] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:21:26,179] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run9
[2019-03-23 15:21:26,288] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:21:26,289] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:21:26,293] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run9
[2019-03-23 15:21:26,368] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:21:26,369] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:21:26,372] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run9
[2019-03-23 15:21:29,085] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.9431531e-12 1.0000000e+00 2.3299382e-20 4.9054944e-13 2.9188343e-11], sum to 1.0000
[2019-03-23 15:21:29,093] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7323
[2019-03-23 15:21:29,098] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3739914995077335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 419612.9914524262, 419612.991452426, 121617.5915209842], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 25200.0000, 
sim time next is 25800.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3935469098603551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 441822.4729225896, 441822.4729225896, 123431.0642626979], 
processed observation next is [1.0, 0.30434782608695654, 0.45454545454545453, 1.0, 1.0, 1.0, 0.24193363732544387, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16363795293429242, 0.16363795293429242, 0.30105137625048267], 
reward next is 0.6989, 
noisyNet noise sample is [array([-1.1743394], dtype=float32), 0.20408997]. 
=============================================
[2019-03-23 15:21:29,532] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.2972528e-10 1.0000000e+00 2.4789236e-17 1.5503948e-10 1.9560706e-09], sum to 1.0000
[2019-03-23 15:21:29,539] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6425
[2019-03-23 15:21:29,542] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 78.0, 1.0, 2.0, 0.8371726994250901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 950568.2620622276, 950568.2620622278, 181073.6768760546], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 42600.0000, 
sim time next is 43200.0000, 
raw observation next is [21.6, 78.0, 1.0, 2.0, 0.8591395504853007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 975145.7126544139, 975145.7126544139, 184206.3070806656], 
processed observation next is [1.0, 0.5217391304347826, 0.6181818181818183, 0.78, 1.0, 1.0, 0.8239244381066257, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.36116507876089404, 0.36116507876089404, 0.44928367580650147], 
reward next is 0.5507, 
noisyNet noise sample is [array([1.5542976], dtype=float32), -2.6107516]. 
=============================================
[2019-03-23 15:21:34,431] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.5407831e-13 1.0000000e+00 9.1948049e-24 8.0700068e-14 1.5501892e-12], sum to 1.0000
[2019-03-23 15:21:34,442] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8674
[2019-03-23 15:21:34,454] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666666, 44.66666666666667, 1.0, 2.0, 0.593983510324191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 645190.1837516251, 645190.1837516251, 129358.9700383859], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 135600.0000, 
sim time next is 136200.0000, 
raw observation next is [22.83333333333334, 44.33333333333334, 1.0, 2.0, 0.615678024693145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 668771.1730655148, 668771.1730655144, 132765.3942347151], 
processed observation next is [1.0, 0.5652173913043478, 0.6742424242424245, 0.4433333333333334, 1.0, 1.0, 0.5195975308664312, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24769302706130178, 0.24769302706130164, 0.32381803471881726], 
reward next is 0.6762, 
noisyNet noise sample is [array([0.24560082], dtype=float32), 1.3464266]. 
=============================================
[2019-03-23 15:21:34,916] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 15:21:34,918] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:21:34,918] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:21:34,919] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:21:34,919] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:21:34,919] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:21:34,920] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:21:34,920] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:21:34,921] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:21:34,927] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:21:34,929] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:21:34,942] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run69
[2019-03-23 15:21:34,971] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run69
[2019-03-23 15:21:34,972] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run69
[2019-03-23 15:21:35,033] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run69
[2019-03-23 15:21:35,064] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run69
[2019-03-23 15:22:02,097] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06006972], dtype=float32), 0.31026328]
[2019-03-23 15:22:02,098] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.83734375666667, 78.77062701, 1.0, 2.0, 0.255844869191755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 277780.9123549872, 277780.9123549872, 92365.43532536564]
[2019-03-23 15:22:02,100] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:22:02,102] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.5855967e-12 1.0000000e+00 2.8853079e-22 2.5603711e-13 1.6930712e-12], sampled 0.41063321192201085
[2019-03-23 15:22:26,069] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06006972], dtype=float32), 0.31026328]
[2019-03-23 15:22:26,069] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.0, 57.0, 1.0, 2.0, 0.3381894273817744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 375465.8424185775, 375465.8424185772, 116860.9377328211]
[2019-03-23 15:22:26,071] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:22:26,072] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.0104682e-12 1.0000000e+00 2.2445185e-22 2.2109700e-13 1.4749524e-12], sampled 0.08894777070333748
[2019-03-23 15:22:49,882] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06006972], dtype=float32), 0.31026328]
[2019-03-23 15:22:49,885] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.13333333333333, 64.33333333333334, 1.0, 2.0, 0.6104433383144474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 696140.4737579589, 696140.4737579585, 157259.1458747083]
[2019-03-23 15:22:49,886] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:22:49,888] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.1942910e-12 1.0000000e+00 1.4657267e-22 1.7228020e-13 1.1671818e-12], sampled 0.6874058488037157
[2019-03-23 15:22:56,518] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06006972], dtype=float32), 0.31026328]
[2019-03-23 15:22:56,521] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.53333333333333, 58.33333333333333, 1.0, 2.0, 0.2844201548684587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 308832.903891407, 308832.9038914067, 99936.35684911539]
[2019-03-23 15:22:56,522] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:22:56,524] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.0464734e-12 1.0000000e+00 1.3413271e-22 1.6360922e-13 1.1122891e-12], sampled 0.8961585872488994
[2019-03-23 15:23:02,543] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06006972], dtype=float32), 0.31026328]
[2019-03-23 15:23:02,544] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.3, 59.0, 1.0, 2.0, 0.43548178511842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 495187.1661395642, 495187.1661395638, 135359.603584446]
[2019-03-23 15:23:02,546] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:23:02,548] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0738154e-12 1.0000000e+00 1.9018621e-23 5.2099113e-14 3.8047538e-13], sampled 0.5906006991088424
[2019-03-23 15:23:12,143] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06006972], dtype=float32), 0.31026328]
[2019-03-23 15:23:12,144] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.4, 81.0, 1.0, 2.0, 0.2048276249673534, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 222388.9177503901, 222388.9177503898, 72705.15761029624]
[2019-03-23 15:23:12,145] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:23:12,148] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.3956934e-11 1.0000000e+00 2.3211722e-21 8.6848833e-13 5.3197100e-12], sampled 0.7923958783380329
[2019-03-23 15:23:21,156] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 15:23:21,321] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 15:23:21,463] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 15:23:21,569] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 15:23:21,606] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 15:23:22,620] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1700000, evaluation results [1700000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 15:23:24,804] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5019313e-07 9.9999988e-01 2.7152344e-15 1.0084080e-08 1.2444959e-08], sum to 1.0000
[2019-03-23 15:23:24,811] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1325
[2019-03-23 15:23:24,816] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333333, 74.33333333333333, 1.0, 2.0, 0.2716875572680008, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 295003.2308975053, 295003.2308975056, 100566.8172112323], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 207600.0000, 
sim time next is 208200.0000, 
raw observation next is [18.66666666666667, 73.66666666666667, 1.0, 2.0, 0.2787468689384963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 302670.7435698491, 302670.7435698488, 105995.5114823953], 
processed observation next is [0.0, 0.391304347826087, 0.4848484848484851, 0.7366666666666667, 1.0, 1.0, 0.09843358617312038, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11210027539624041, 0.1121002753962403, 0.25852563776193976], 
reward next is 0.7415, 
noisyNet noise sample is [array([1.682372], dtype=float32), 1.4786013]. 
=============================================
[2019-03-23 15:23:28,548] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.6664064e-08 1.0000000e+00 1.2993983e-16 6.2425520e-10 6.6824157e-10], sum to 1.0000
[2019-03-23 15:23:28,554] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2892
[2019-03-23 15:23:28,563] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 97.0, 1.0, 2.0, 0.2568880097113039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 278929.0080905815, 278929.0080905817, 89540.55562876145], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 250200.0000, 
sim time next is 250800.0000, 
raw observation next is [15.0, 96.0, 1.0, 2.0, 0.2540198137738221, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 275813.8377897964, 275813.8377897966, 88275.81035013038], 
processed observation next is [0.0, 0.9130434782608695, 0.3181818181818182, 0.96, 1.0, 1.0, 0.06752476721727761, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10215327325548015, 0.10215327325548022, 0.21530685451251314], 
reward next is 0.7847, 
noisyNet noise sample is [array([-1.6741031], dtype=float32), 0.28215408]. 
=============================================
[2019-03-23 15:23:33,786] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.6395247e-10 1.0000000e+00 1.2304766e-22 2.0598054e-13 1.4955272e-12], sum to 1.0000
[2019-03-23 15:23:33,796] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3911
[2019-03-23 15:23:33,800] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.83333333333333, 95.0, 1.0, 2.0, 0.2057056913406607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 223342.4857182912, 223342.4857182915, 75463.77293023281], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 425400.0000, 
sim time next is 426000.0000, 
raw observation next is [13.66666666666667, 96.0, 1.0, 2.0, 0.2038937499029703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 221374.7443653102, 221374.7443653105, 75030.54034139331], 
processed observation next is [1.0, 0.9565217391304348, 0.25757575757575774, 0.96, 1.0, 1.0, 0.004867187378712855, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.081990646061226, 0.08199064606122611, 0.18300131790583735], 
reward next is 0.8170, 
noisyNet noise sample is [array([-0.1628807], dtype=float32), 0.18199202]. 
=============================================
[2019-03-23 15:23:33,814] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[77.99326 ]
 [78.08156 ]
 [78.14705 ]
 [78.22054 ]
 [78.354805]], R is [[77.87500763]
 [77.91220093]
 [77.94831848]
 [77.98493958]
 [78.02232361]].
[2019-03-23 15:23:43,151] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.0782988e-09 1.0000000e+00 1.9814099e-20 3.3189516e-13 2.0525550e-12], sum to 1.0000
[2019-03-23 15:23:43,161] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1378
[2019-03-23 15:23:43,167] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 64.0, 1.0, 2.0, 0.5417743230980001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595820.1037126207, 595820.1037126207, 133064.7583131954], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 571200.0000, 
sim time next is 571800.0000, 
raw observation next is [21.0, 64.0, 1.0, 2.0, 0.5364596549620316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 589915.9088544135, 589915.9088544132, 132523.0247310922], 
processed observation next is [1.0, 0.6086956521739131, 0.5909090909090909, 0.64, 1.0, 1.0, 0.4205745687025395, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2184873736497828, 0.21848737364978266, 0.3232268895880298], 
reward next is 0.6768, 
noisyNet noise sample is [array([0.41035533], dtype=float32), 1.8398755]. 
=============================================
[2019-03-23 15:23:46,391] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8072099e-10 1.0000000e+00 1.3788420e-21 2.6749180e-12 1.1651761e-11], sum to 1.0000
[2019-03-23 15:23:46,399] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2953
[2019-03-23 15:23:46,403] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 83.0, 1.0, 2.0, 0.3060921251622884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 333142.4779044439, 333142.4779044439, 111871.2333116482], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 601200.0000, 
sim time next is 601800.0000, 
raw observation next is [18.0, 83.0, 1.0, 2.0, 0.3052154306531891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 332183.1740020692, 332183.1740020695, 111809.8501142641], 
processed observation next is [1.0, 1.0, 0.45454545454545453, 0.83, 1.0, 1.0, 0.13151928831648638, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12303080518595157, 0.12303080518595168, 0.2727069514982051], 
reward next is 0.7273, 
noisyNet noise sample is [array([0.9660515], dtype=float32), -0.8491431]. 
=============================================
[2019-03-23 15:23:51,472] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.1695010e-09 1.0000000e+00 7.6476539e-19 2.0270185e-11 1.4964340e-09], sum to 1.0000
[2019-03-23 15:23:51,481] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6132
[2019-03-23 15:23:51,485] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 83.0, 1.0, 2.0, 0.3493435257538567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 386739.8287158114, 386739.8287158117, 117280.6073838424], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 717600.0000, 
sim time next is 718200.0000, 
raw observation next is [19.5, 80.5, 1.0, 2.0, 0.3491592253923145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 387596.0403818791, 387596.0403818791, 117692.6068584705], 
processed observation next is [1.0, 0.30434782608695654, 0.5227272727272727, 0.805, 1.0, 1.0, 0.18644903174039307, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1435540890303256, 0.1435540890303256, 0.28705513867919635], 
reward next is 0.7129, 
noisyNet noise sample is [array([-1.7528596], dtype=float32), -0.24499877]. 
=============================================
[2019-03-23 15:23:53,149] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.4030327e-08 9.9999857e-01 9.7587222e-17 1.0094256e-10 1.4144516e-06], sum to 1.0000
[2019-03-23 15:23:53,157] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6322
[2019-03-23 15:23:53,160] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 60.0, 1.0, 2.0, 0.4657025786124231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 531362.204993338, 531362.204993338, 136678.2583837443], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 762000.0000, 
sim time next is 762600.0000, 
raw observation next is [26.16666666666667, 60.5, 1.0, 2.0, 0.4639747001695172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 529359.0094150781, 529359.0094150781, 136349.8160107474], 
processed observation next is [1.0, 0.8260869565217391, 0.825757575757576, 0.605, 1.0, 1.0, 0.3299683752118965, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19605889237595486, 0.19605889237595486, 0.33256052685548143], 
reward next is 0.6674, 
noisyNet noise sample is [array([-0.41571996], dtype=float32), -0.7518676]. 
=============================================
[2019-03-23 15:23:58,002] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7874001e-09 1.0000000e+00 5.0794302e-21 7.6614447e-13 4.7029607e-09], sum to 1.0000
[2019-03-23 15:23:58,012] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7543
[2019-03-23 15:23:58,018] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.66666666666667, 56.0, 1.0, 2.0, 0.5269135342478408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 599606.5609894237, 599606.5609894239, 146576.8106912754], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 840000.0000, 
sim time next is 840600.0000, 
raw observation next is [28.5, 56.5, 1.0, 2.0, 0.5262265342406446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 598977.2748829927, 598977.2748829927, 146386.5614491903], 
processed observation next is [0.0, 0.7391304347826086, 0.9318181818181818, 0.565, 1.0, 1.0, 0.4077831678008057, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22184343514184915, 0.22184343514184915, 0.35704039377851293], 
reward next is 0.6430, 
noisyNet noise sample is [array([-0.38643712], dtype=float32), 0.25518075]. 
=============================================
[2019-03-23 15:24:07,428] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2939702e-06 9.9999344e-01 6.7217110e-16 1.5846723e-08 5.2398846e-06], sum to 1.0000
[2019-03-23 15:24:07,438] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8153
[2019-03-23 15:24:07,442] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 96.0, 1.0, 2.0, 0.2102306734810386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 228256.5835378567, 228256.5835378567, 73638.5525125235], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1028400.0000, 
sim time next is 1029000.0000, 
raw observation next is [13.0, 95.0, 1.0, 2.0, 0.2053587974279573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 222965.7634913434, 222965.7634913431, 72912.94879738631], 
processed observation next is [1.0, 0.9130434782608695, 0.22727272727272727, 0.95, 1.0, 1.0, 0.006698496784946599, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08257991240420126, 0.08257991240420115, 0.17783646048143004], 
reward next is 0.8222, 
noisyNet noise sample is [array([0.15855563], dtype=float32), 0.22981119]. 
=============================================
[2019-03-23 15:24:07,461] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[55.473167]
 [55.579197]
 [55.660366]
 [55.795082]
 [55.865944]], R is [[55.63018799]
 [55.89427948]
 [56.15424347]
 [56.41035461]
 [56.66300583]].
[2019-03-23 15:24:10,310] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 15:24:10,311] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:24:10,312] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:24:10,312] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:24:10,313] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:24:10,313] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:24:10,314] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:24:10,314] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:24:10,315] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:24:10,315] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:24:10,316] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:24:10,336] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run70
[2019-03-23 15:24:10,366] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run70
[2019-03-23 15:24:10,396] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run70
[2019-03-23 15:24:10,441] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run70
[2019-03-23 15:24:10,442] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run70
[2019-03-23 15:24:30,854] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06097956], dtype=float32), 0.31436074]
[2019-03-23 15:24:30,855] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.88333333333333, 71.66666666666667, 1.0, 2.0, 0.4713837679833714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 537514.0687587123, 537514.0687587119, 140826.9773312362]
[2019-03-23 15:24:30,857] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:24:30,862] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.5854050e-08 9.9999988e-01 1.0591784e-18 2.0957232e-11 1.6147121e-07], sampled 0.7325397961287864
[2019-03-23 15:25:07,220] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06097956], dtype=float32), 0.31436074]
[2019-03-23 15:25:07,222] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [29.13333333333333, 52.5, 1.0, 2.0, 0.5217996854242306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 594325.6703092434, 594325.6703092434, 149787.3971457455]
[2019-03-23 15:25:07,223] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:25:07,226] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.2716677e-08 9.9999988e-01 7.8385744e-19 1.7522216e-11 1.4388691e-07], sampled 0.7994479351585597
[2019-03-23 15:25:10,321] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06097956], dtype=float32), 0.31436074]
[2019-03-23 15:25:10,322] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.0, 80.5, 1.0, 2.0, 0.4780033534584129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 545401.8148420979, 545401.8148420979, 138014.8854261381]
[2019-03-23 15:25:10,323] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:25:10,326] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.1138431e-08 9.9999976e-01 3.1164129e-18 3.9832537e-11 2.4414300e-07], sampled 0.0035334036028563665
[2019-03-23 15:25:27,246] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06097956], dtype=float32), 0.31436074]
[2019-03-23 15:25:27,248] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [10.98680840933333, 78.15627055333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 169078.5257322423, 169078.5257322419, 64762.79725159123]
[2019-03-23 15:25:27,249] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:25:27,252] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.5252445e-08 9.9999976e-01 3.8846130e-18 4.5377185e-11 2.6559766e-07], sampled 0.8406506480143765
[2019-03-23 15:25:43,455] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06097956], dtype=float32), 0.31436074]
[2019-03-23 15:25:43,456] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.45, 82.16666666666666, 1.0, 2.0, 0.3319628650937617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 363381.0720785471, 363381.0720785471, 118711.2164929967]
[2019-03-23 15:25:43,459] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:25:43,464] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.6909928e-08 9.9999976e-01 4.2264024e-18 4.7743923e-11 2.7433299e-07], sampled 0.4966312871865084
[2019-03-23 15:25:53,245] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06097956], dtype=float32), 0.31436074]
[2019-03-23 15:25:53,247] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.58333333333333, 66.16666666666667, 1.0, 2.0, 0.2279292302317155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 247465.5575474779, 247465.5575474779, 84077.17385985257]
[2019-03-23 15:25:53,248] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:25:53,251] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.8472802e-09 9.9999988e-01 8.7700797e-20 4.7565567e-12 6.2178408e-08], sampled 0.08382553519580216
[2019-03-23 15:25:57,062] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 15:25:57,116] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 15:25:57,201] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 15:25:57,341] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 15:25:57,464] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 15:25:58,482] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1725000, evaluation results [1725000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 15:25:59,542] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.5383986e-09 1.0000000e+00 1.6124918e-20 3.9237129e-12 9.1945944e-09], sum to 1.0000
[2019-03-23 15:25:59,548] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4466
[2019-03-23 15:25:59,553] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 73.0, 1.0, 2.0, 0.3630574169508348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 406049.6113048053, 406049.611304805, 120086.2134075195], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1108800.0000, 
sim time next is 1109400.0000, 
raw observation next is [20.66666666666667, 73.83333333333334, 1.0, 2.0, 0.357559324975247, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 399014.3422017279, 399014.3422017282, 119237.2258075907], 
processed observation next is [1.0, 0.8695652173913043, 0.575757575757576, 0.7383333333333334, 1.0, 1.0, 0.19694915621905873, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14778308970434367, 0.14778308970434378, 0.2908225019697334], 
reward next is 0.7092, 
noisyNet noise sample is [array([1.3956832], dtype=float32), 0.027985265]. 
=============================================
[2019-03-23 15:26:01,450] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.7004031e-09 1.0000000e+00 5.2687195e-18 8.4692767e-13 4.1108534e-09], sum to 1.0000
[2019-03-23 15:26:01,458] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0583
[2019-03-23 15:26:01,463] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.3493457461764113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 388736.953873524, 388736.953873524, 118095.5957368955], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1139400.0000, 
sim time next is 1140000.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.3455424176505399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 384502.208079229, 384502.208079229, 117794.9896252893], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 0.94, 1.0, 1.0, 0.18192802206317485, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14240822521452925, 0.14240822521452925, 0.28730485274460804], 
reward next is 0.7127, 
noisyNet noise sample is [array([-0.2735646], dtype=float32), 0.27047274]. 
=============================================
[2019-03-23 15:26:01,489] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[61.58459 ]
 [61.634468]
 [61.66623 ]
 [61.72376 ]
 [61.769665]], R is [[61.6619072 ]
 [61.75725174]
 [61.85253143]
 [61.9462204 ]
 [62.04103088]].
[2019-03-23 15:26:02,357] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.8325194e-07 9.9999964e-01 4.1690321e-16 2.3668797e-10 7.7743977e-08], sum to 1.0000
[2019-03-23 15:26:02,365] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5614
[2019-03-23 15:26:02,368] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 76.0, 1.0, 2.0, 0.8189185861640287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 933726.490103601, 933726.4901036014, 182030.4712396182], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1161000.0000, 
sim time next is 1161600.0000, 
raw observation next is [23.33333333333334, 75.33333333333333, 1.0, 2.0, 0.8411577743911002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 959684.2462771804, 959684.2462771804, 186521.4232363807], 
processed observation next is [1.0, 0.43478260869565216, 0.6969696969696972, 0.7533333333333333, 1.0, 1.0, 0.8014472179888751, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.355438609732289, 0.355438609732289, 0.4549303005765383], 
reward next is 0.5451, 
noisyNet noise sample is [array([1.066529], dtype=float32), 1.4880911]. 
=============================================
[2019-03-23 15:26:02,371] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.5836429e-08 9.9999964e-01 6.3556780e-17 2.4130121e-12 3.4173408e-07], sum to 1.0000
[2019-03-23 15:26:02,379] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4260
[2019-03-23 15:26:02,383] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666666, 69.66666666666667, 1.0, 2.0, 0.6368251089217385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 726023.0572199603, 726023.0572199603, 159971.5686288901], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1168800.0000, 
sim time next is 1169400.0000, 
raw observation next is [25.83333333333334, 69.83333333333333, 1.0, 2.0, 0.6295202847422946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 717292.5309884605, 717292.5309884608, 159374.6049242349], 
processed observation next is [1.0, 0.5217391304347826, 0.8106060606060609, 0.6983333333333333, 1.0, 1.0, 0.5369003559278682, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2656639003660965, 0.26566390036609655, 0.3887185485956949], 
reward next is 0.6113, 
noisyNet noise sample is [array([-2.0545304], dtype=float32), -0.447703]. 
=============================================
[2019-03-23 15:26:05,845] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.4872327e-07 9.9999249e-01 5.2876752e-15 7.3317136e-10 6.7397755e-06], sum to 1.0000
[2019-03-23 15:26:05,851] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2311
[2019-03-23 15:26:05,858] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1208383.249709629 W.
[2019-03-23 15:26:05,861] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.0, 78.0, 1.0, 2.0, 0.579391958916233, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9740691702223307, 6.911199999999999, 6.9112, 77.32846344354067, 1208383.249709629, 1208383.24970963, 271778.8098544321], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1245600.0000, 
sim time next is 1246200.0000, 
raw observation next is [24.33333333333333, 75.83333333333333, 1.0, 2.0, 0.4806458607833268, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9435998316386595, 6.961850375934607, 6.9112, 77.32834179933148, 1095910.376782115, 1079460.196535464, 253164.6871730644], 
processed observation next is [1.0, 0.43478260869565216, 0.7424242424242422, 0.7583333333333333, 1.0, 1.0, 0.3508073259791584, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9194283309123709, 0.005065037593460708, 0.0, 0.508428013119154, 0.4058927321415241, 0.39980007279091256, 0.6174748467635717], 
reward next is 0.1293, 
noisyNet noise sample is [array([0.25715968], dtype=float32), 0.818424]. 
=============================================
[2019-03-23 15:26:06,538] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.5874938e-06 9.9999583e-01 4.3675941e-15 1.4706308e-09 1.5753203e-06], sum to 1.0000
[2019-03-23 15:26:06,546] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1764
[2019-03-23 15:26:06,548] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1095859.219516291 W.
[2019-03-23 15:26:06,552] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.33333333333333, 75.83333333333333, 1.0, 2.0, 0.4809302303547787, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9445459072822382, 6.961799380578194, 6.9112, 77.32834192180411, 1095859.219516291, 1079425.601466286, 254050.4670442709], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1246200.0000, 
sim time next is 1246800.0000, 
raw observation next is [24.66666666666666, 73.66666666666667, 1.0, 2.0, 0.314922293909019, 1.0, 1.0, 0.314922293909019, 1.0, 2.0, 0.6379372875340164, 6.911199999999999, 6.9112, 77.3421103, 1073357.449146737, 1073357.449146737, 265478.5481135053], 
processed observation next is [1.0, 0.43478260869565216, 0.7575757575757573, 0.7366666666666667, 1.0, 1.0, 0.14365286738627372, 1.0, 0.5, 0.14365286738627372, 1.0, 1.0, 0.4827675536200234, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.397539795980273, 0.397539795980273, 0.6475086539353788], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3319373], dtype=float32), 0.976826]. 
=============================================
[2019-03-23 15:26:08,898] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.6999836e-07 9.9999774e-01 8.9359172e-18 1.7985806e-11 2.1324636e-06], sum to 1.0000
[2019-03-23 15:26:08,906] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5650
[2019-03-23 15:26:08,913] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.3665586320666241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 408176.8406723777, 408176.8406723777, 119593.271257356], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1292400.0000, 
sim time next is 1293000.0000, 
raw observation next is [18.0, 94.00000000000001, 1.0, 2.0, 0.3639872931602225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 405132.3000985034, 405132.3000985034, 119308.4334931591], 
processed observation next is [1.0, 1.0, 0.45454545454545453, 0.9400000000000002, 1.0, 1.0, 0.2049841164502781, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15004900003648275, 0.15004900003648275, 0.29099617925160753], 
reward next is 0.7090, 
noisyNet noise sample is [array([-0.37158322], dtype=float32), 1.7438067]. 
=============================================
[2019-03-23 15:26:08,937] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[66.817406]
 [66.88944 ]
 [67.020805]
 [67.14515 ]
 [67.27442 ]], R is [[66.80725861]
 [66.8474884 ]
 [66.88601685]
 [66.92292023]
 [66.95829773]].
[2019-03-23 15:26:10,455] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.8732287e-07 9.9999499e-01 4.9631731e-16 1.6873832e-11 4.1850440e-06], sum to 1.0000
[2019-03-23 15:26:10,464] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8996
[2019-03-23 15:26:10,469] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 100.0, 1.0, 2.0, 0.3743346130256268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 417309.5399422572, 417309.5399422575, 120430.5047031719], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1305000.0000, 
sim time next is 1305600.0000, 
raw observation next is [17.66666666666667, 100.0, 1.0, 2.0, 0.3697365058869241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 413093.7886491502, 413093.7886491502, 120448.6072540106], 
processed observation next is [1.0, 0.08695652173913043, 0.4393939393939396, 1.0, 1.0, 1.0, 0.21217063235865508, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15299769949968528, 0.15299769949968528, 0.2937770908634405], 
reward next is 0.7062, 
noisyNet noise sample is [array([-1.2728013], dtype=float32), -0.8461191]. 
=============================================
[2019-03-23 15:26:14,468] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.4466163e-08 9.9999893e-01 5.1749375e-17 1.9526969e-11 1.1293807e-06], sum to 1.0000
[2019-03-23 15:26:14,475] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9779
[2019-03-23 15:26:14,482] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 97.0, 1.0, 2.0, 0.4900244048897847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558994.3929380787, 558994.3929380787, 140621.804668209], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1409400.0000, 
sim time next is 1410000.0000, 
raw observation next is [21.66666666666667, 96.0, 1.0, 2.0, 0.4916316129795459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560784.0707178062, 560784.0707178062, 140904.2710894223], 
processed observation next is [0.0, 0.30434782608695654, 0.6212121212121214, 0.96, 1.0, 1.0, 0.3645395162244323, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20769780396955786, 0.20769780396955786, 0.34366895387663976], 
reward next is 0.6563, 
noisyNet noise sample is [array([-0.27552348], dtype=float32), 0.19172402]. 
=============================================
[2019-03-23 15:26:14,497] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[57.41399 ]
 [57.45057 ]
 [57.475243]
 [57.495293]
 [57.50097 ]], R is [[57.47977829]
 [57.56200027]
 [57.64413452]
 [57.72618103]
 [57.80787659]].
[2019-03-23 15:26:14,604] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.0491575e-08 9.9999917e-01 3.3923061e-17 5.4028605e-12 7.9141364e-07], sum to 1.0000
[2019-03-23 15:26:14,612] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4466
[2019-03-23 15:26:14,618] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4883470567773606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 557179.3461798659, 557179.3461798656, 140147.019480595], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1404600.0000, 
sim time next is 1405200.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4876475508965436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 556380.8326810932, 556380.8326810932, 140067.0071839688], 
processed observation next is [0.0, 0.2608695652173913, 0.5909090909090909, 1.0, 1.0, 1.0, 0.35955943862067946, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20606697506707158, 0.20606697506707158, 0.34162684679016775], 
reward next is 0.6584, 
noisyNet noise sample is [array([-0.18749297], dtype=float32), -0.7520897]. 
=============================================
[2019-03-23 15:26:17,273] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.9660664e-09 1.0000000e+00 2.4749502e-21 3.9837200e-14 1.5448675e-08], sum to 1.0000
[2019-03-23 15:26:17,280] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8997
[2019-03-23 15:26:17,283] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.83333333333333, 100.0, 1.0, 2.0, 0.471285870222412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 537772.483578591, 537772.4835785913, 137771.0508602276], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1471800.0000, 
sim time next is 1472400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4764415412839292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 543612.5043320791, 543612.5043320791, 138700.404861814], 
processed observation next is [0.0, 0.043478260869565216, 0.5909090909090909, 1.0, 1.0, 1.0, 0.34555192660491146, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2013379645674367, 0.2013379645674367, 0.3382936703946683], 
reward next is 0.6617, 
noisyNet noise sample is [array([0.02334242], dtype=float32), -0.51445174]. 
=============================================
[2019-03-23 15:26:21,027] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.3693473e-08 9.9999976e-01 6.7084000e-18 3.6296710e-12 1.6706107e-07], sum to 1.0000
[2019-03-23 15:26:21,032] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6333
[2019-03-23 15:26:21,039] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.5173895005407687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588991.8875350053, 588991.8875350053, 145248.3893840361], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1524600.0000, 
sim time next is 1525200.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.5171125550062422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588677.044754659, 588677.044754659, 145214.2793242243], 
processed observation next is [0.0, 0.6521739130434783, 0.7272727272727273, 0.83, 1.0, 1.0, 0.3963906937578027, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21802853509431813, 0.21802853509431813, 0.3541811690834739], 
reward next is 0.6458, 
noisyNet noise sample is [array([-0.85486627], dtype=float32), -1.2895486]. 
=============================================
[2019-03-23 15:26:25,669] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4409255e-08 1.0000000e+00 2.6303744e-20 4.5651737e-13 1.5435862e-08], sum to 1.0000
[2019-03-23 15:26:25,681] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6113
[2019-03-23 15:26:25,689] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1192284.261424597 W.
[2019-03-23 15:26:25,693] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 62.0, 1.0, 2.0, 0.351241517540508, 1.0, 2.0, 0.351241517540508, 1.0, 2.0, 0.7110157943364723, 6.9112, 6.9112, 77.3421103, 1192284.261424597, 1192284.261424597, 282219.6884008338], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1610400.0000, 
sim time next is 1611000.0000, 
raw observation next is [27.0, 62.0, 1.0, 2.0, 0.5487772884278777, 1.0, 2.0, 0.5487772884278777, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1243208.486245486, 1243208.486245486, 245602.3489152996], 
processed observation next is [1.0, 0.6521739130434783, 0.8636363636363636, 0.62, 1.0, 1.0, 0.435971610534847, 1.0, 1.0, 0.435971610534847, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.46044758749832815, 0.46044758749832815, 0.5990301193056088], 
reward next is 0.4010, 
noisyNet noise sample is [array([0.37940654], dtype=float32), 0.05442454]. 
=============================================
[2019-03-23 15:26:25,703] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[68.33062]
 [67.26539]
 [66.86234]
 [66.25265]
 [65.52851]], R is [[67.47501373]
 [67.11192322]
 [66.76152039]
 [66.39777374]
 [65.73379517]].
[2019-03-23 15:26:28,034] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.7129452e-10 1.0000000e+00 8.8401717e-22 1.3494356e-15 5.0475517e-09], sum to 1.0000
[2019-03-23 15:26:28,042] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3083
[2019-03-23 15:26:28,052] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 88.5, 1.0, 2.0, 0.5868703835635005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 657681.9496089137, 657681.949608914, 142259.283505335], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1672200.0000, 
sim time next is 1672800.0000, 
raw observation next is [18.66666666666667, 90.33333333333334, 1.0, 2.0, 0.5613529638372038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 628282.2577421727, 628282.2577421725, 139104.2321385372], 
processed observation next is [1.0, 0.34782608695652173, 0.4848484848484851, 0.9033333333333334, 1.0, 1.0, 0.4516912047965047, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.232697132497101, 0.23269713249710092, 0.3392786149720419], 
reward next is 0.6607, 
noisyNet noise sample is [array([-2.0475492], dtype=float32), 0.687141]. 
=============================================
[2019-03-23 15:26:29,256] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.7614866e-09 1.0000000e+00 2.7255537e-20 7.1219157e-15 2.6671123e-09], sum to 1.0000
[2019-03-23 15:26:29,260] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6701
[2019-03-23 15:26:29,265] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.16666666666667, 70.33333333333334, 1.0, 2.0, 0.386572323170292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 419801.0200664452, 419801.0200664452, 84104.13901031851], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1753800.0000, 
sim time next is 1754400.0000, 
raw observation next is [11.33333333333333, 69.66666666666667, 1.0, 2.0, 0.3586642030801516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 389481.8559815711, 389481.8559815714, 81651.76439962516], 
processed observation next is [1.0, 0.30434782608695654, 0.15151515151515138, 0.6966666666666668, 1.0, 1.0, 0.19833025385018951, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14425253925243373, 0.14425253925243386, 0.19915064487713452], 
reward next is 0.8008, 
noisyNet noise sample is [array([-0.32352614], dtype=float32), -0.5109387]. 
=============================================
[2019-03-23 15:26:37,657] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.7473425e-01 2.5261026e-02 7.6011159e-13 4.0791601e-09 4.6742325e-06], sum to 1.0000
[2019-03-23 15:26:37,663] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4420
[2019-03-23 15:26:37,668] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.16666666666667, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7430748981585036, 7.153082278048271, 6.9112, 77.32764187763011, 506116.039110592, 427558.4571820514, 130340.4572149951], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1919400.0000, 
sim time next is 1920000.0000, 
raw observation next is [18.33333333333334, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7428981867725902, 7.147074655556323, 6.9112, 77.32768065907504, 503747.4486075285, 427140.9604377282, 130552.8755026149], 
processed observation next is [1.0, 0.21739130434782608, 0.46969696969696995, 1.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6327116953894146, 0.023587465555632292, 0.0, 0.5084236661718491, 0.18657312911389945, 0.15820035571767713, 0.3184216475673534], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.83432907], dtype=float32), -0.3579156]. 
=============================================
[2019-03-23 15:26:37,685] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[44.108242]
 [44.072414]
 [44.088543]
 [44.190258]
 [44.38615 ]], R is [[43.67287445]
 [43.23614502]
 [42.80378342]
 [42.37574768]
 [41.95199203]].
[2019-03-23 15:26:38,869] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.3815162e-05 9.9996495e-01 3.2154631e-16 2.6066264e-11 1.1900974e-06], sum to 1.0000
[2019-03-23 15:26:38,877] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0778
[2019-03-23 15:26:38,885] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1225861.502457764 W.
[2019-03-23 15:26:38,890] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.0, 81.0, 1.0, 2.0, 0.5937795526588603, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9710581258215304, 6.9112, 6.9112, 77.3284628587958, 1225861.502457764, 1225861.502457764, 270924.9719812863], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1942200.0000, 
sim time next is 1942800.0000, 
raw observation next is [23.33333333333334, 78.66666666666666, 1.0, 2.0, 0.3574924918057245, 1.0, 1.0, 0.3574924918057245, 1.0, 2.0, 0.724017761684797, 6.911199999999999, 6.9112, 77.3421103, 1221114.404719862, 1221114.404719863, 280703.6384230283], 
processed observation next is [1.0, 0.4782608695652174, 0.6969696969696972, 0.7866666666666666, 1.0, 1.0, 0.1968656147571556, 1.0, 0.5, 0.1968656147571556, 1.0, 1.0, 0.6057396595497101, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4522645943406896, 0.45226459434069005, 0.6846430205439714], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.13160235], dtype=float32), -2.202947]. 
=============================================
[2019-03-23 15:26:41,763] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.2818356e-05 9.9997723e-01 2.3858787e-16 7.0753516e-12 4.7938190e-08], sum to 1.0000
[2019-03-23 15:26:41,770] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7854
[2019-03-23 15:26:41,783] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1234448.424528813 W.
[2019-03-23 15:26:41,790] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.33333333333334, 61.0, 1.0, 2.0, 0.601160114408531, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9660803379619471, 6.9112, 6.9112, 77.32846344354104, 1234448.424528813, 1234448.424528813, 266822.1882522173], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1956000.0000, 
sim time next is 1956600.0000, 
raw observation next is [25.5, 61.0, 1.0, 2.0, 0.3697220291864501, 1.0, 1.0, 0.3697220291864501, 1.0, 2.0, 0.7476805288949995, 6.9112, 6.9112, 77.3421103, 1265663.945284196, 1265663.945284196, 282684.875264363], 
processed observation next is [1.0, 0.6521739130434783, 0.7954545454545454, 0.61, 1.0, 1.0, 0.2121525364830626, 1.0, 0.5, 0.2121525364830626, 1.0, 1.0, 0.6395436127071422, 0.0, 0.0, 0.5085185399722538, 0.46876442417933184, 0.46876442417933184, 0.6894753055228366], 
reward next is 0.3105, 
noisyNet noise sample is [array([-1.222866], dtype=float32), -0.30945283]. 
=============================================
[2019-03-23 15:26:41,825] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.1793555e-05 9.9995804e-01 1.1793223e-15 5.1032355e-12 8.2027157e-08], sum to 1.0000
[2019-03-23 15:26:41,827] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5033
[2019-03-23 15:26:41,830] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.425520233957176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482393.6736496646, 482393.6736496646, 128893.9076146498], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1925400.0000, 
sim time next is 1926000.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4128967064460563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468074.2903677356, 468074.2903677356, 127681.0306112205], 
processed observation next is [1.0, 0.30434782608695654, 0.5, 1.0, 1.0, 1.0, 0.26612088305757037, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17336084828434653, 0.17336084828434653, 0.3114171478322451], 
reward next is 0.6886, 
noisyNet noise sample is [array([0.57876223], dtype=float32), 1.8571664]. 
=============================================
[2019-03-23 15:26:41,852] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[54.42939 ]
 [54.568146]
 [54.67176 ]
 [54.734642]
 [54.824154]], R is [[54.49491119]
 [54.63558578]
 [54.77792358]
 [54.92222977]
 [55.06473541]].
[2019-03-23 15:26:46,176] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 15:26:46,177] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:26:46,177] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:26:46,178] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:26:46,179] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:26:46,179] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:26:46,178] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:26:46,180] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:26:46,179] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:26:46,181] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:26:46,182] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:26:46,203] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run71
[2019-03-23 15:26:46,236] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run71
[2019-03-23 15:26:46,267] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run71
[2019-03-23 15:26:46,268] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run71
[2019-03-23 15:26:46,268] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run71
[2019-03-23 15:26:53,267] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06319892], dtype=float32), 0.31743848]
[2019-03-23 15:26:53,268] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [11.40187323, 96.43339832666666, 1.0, 2.0, 0.4775731335079581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 518623.9602315073, 518623.9602315069, 101915.7987408841]
[2019-03-23 15:26:53,269] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:26:53,273] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.9831496e-06 9.9999797e-01 1.0266594e-18 1.0571728e-13 3.6153072e-08], sampled 0.17528002663711462
[2019-03-23 15:26:53,486] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06319892], dtype=float32), 0.31743848]
[2019-03-23 15:26:53,487] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.5, 78.0, 1.0, 2.0, 0.5128874074495675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558800.7929176929, 558800.7929176929, 128573.0938578495]
[2019-03-23 15:26:53,489] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:26:53,493] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.7244791e-06 9.9999726e-01 2.6984853e-18 2.1277115e-13 5.4165426e-08], sampled 0.8055143856997578
[2019-03-23 15:27:49,450] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06319892], dtype=float32), 0.31743848]
[2019-03-23 15:27:49,450] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.0, 54.00000000000001, 1.0, 2.0, 0.8390791499291833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 954640.4026530492, 954640.402653049, 182918.123536824]
[2019-03-23 15:27:49,451] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:27:49,454] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.97178189e-06 9.99994874e-01 1.67688006e-17 7.97704730e-13
 1.16293336e-07], sampled 0.4153569758293145
[2019-03-23 15:28:03,572] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06319892], dtype=float32), 0.31743848]
[2019-03-23 15:28:03,575] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.16666666666666, 63.0, 1.0, 2.0, 0.2291503457256591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 248803.7482998749, 248803.7482998746, 76695.37963900328]
[2019-03-23 15:28:03,577] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:28:03,580] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.8669135e-06 9.9999499e-01 1.0503139e-17 5.6726081e-13 9.4397436e-08], sampled 0.48599006261308253
[2019-03-23 15:28:11,536] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06319892], dtype=float32), 0.31743848]
[2019-03-23 15:28:11,537] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.28459020333334, 66.7917664, 1.0, 2.0, 0.4953688192146268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 564700.341931513, 564700.3419315127, 146103.3299252888]
[2019-03-23 15:28:11,541] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:28:11,544] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.3476896e-06 9.9999869e-01 3.0982365e-19 4.4523253e-14 2.1894278e-08], sampled 0.6744888504498393
[2019-03-23 15:28:18,564] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06319892], dtype=float32), 0.31743848]
[2019-03-23 15:28:18,566] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.2, 54.0, 1.0, 2.0, 0.4497993159976334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 512976.8877901407, 512976.887790141, 134279.9053980983]
[2019-03-23 15:28:18,567] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:28:18,571] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.7778522e-06 9.9999821e-01 6.7493792e-19 7.8233162e-14 3.0303749e-08], sampled 0.20657318419762216
[2019-03-23 15:28:32,916] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 15:28:32,916] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 15:28:32,951] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 15:28:32,989] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3791 1683296663.2329 214.0000
[2019-03-23 15:28:33,279] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 15:28:34,298] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1750000, evaluation results [1750000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.379088229873, 1683296663.232874, 214.0]
[2019-03-23 15:28:37,097] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6367805e-07 9.9999988e-01 1.9649085e-22 5.1904056e-16 2.8457225e-10], sum to 1.0000
[2019-03-23 15:28:37,107] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7403
[2019-03-23 15:28:37,111] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 57.5, 1.0, 2.0, 0.3249471836196448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 359167.3560122128, 359167.3560122125, 115200.8644636252], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2109000.0000, 
sim time next is 2109600.0000, 
raw observation next is [23.0, 57.0, 1.0, 2.0, 0.3304445191273721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 366509.7883467098, 366509.7883467101, 116121.0082909612], 
processed observation next is [0.0, 0.43478260869565216, 0.6818181818181818, 0.57, 1.0, 1.0, 0.16305564890921512, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13574436605433696, 0.13574436605433707, 0.2832219714413688], 
reward next is 0.7168, 
noisyNet noise sample is [array([0.11802083], dtype=float32), 0.38637727]. 
=============================================
[2019-03-23 15:28:37,944] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.3855671e-08 1.0000000e+00 2.2776144e-21 1.6815922e-15 2.2859539e-09], sum to 1.0000
[2019-03-23 15:28:37,956] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7855
[2019-03-23 15:28:37,963] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 92.0, 1.0, 2.0, 0.2106513761663518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 228713.4661285006, 228713.4661285003, 75462.56329061836], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2094000.0000, 
sim time next is 2094600.0000, 
raw observation next is [14.0, 93.0, 1.0, 2.0, 0.2134942502499442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 231800.8350799306, 231800.8350799303, 76127.80210908984], 
processed observation next is [0.0, 0.21739130434782608, 0.2727272727272727, 0.93, 1.0, 1.0, 0.016867812812430237, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08585216114071503, 0.08585216114071492, 0.18567756611973132], 
reward next is 0.8143, 
noisyNet noise sample is [array([-0.54086864], dtype=float32), -1.1815143]. 
=============================================
[2019-03-23 15:28:48,167] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.3187536e-08 9.9999988e-01 2.3134512e-24 8.2873100e-18 7.5992643e-11], sum to 1.0000
[2019-03-23 15:28:48,174] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3009
[2019-03-23 15:28:48,179] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 55.0, 1.0, 2.0, 0.2337984651036744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 253851.8372110259, 253851.8372110259, 74190.99049524065], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2325600.0000, 
sim time next is 2326200.0000, 
raw observation next is [17.0, 54.5, 1.0, 2.0, 0.2335437166608098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 253575.1663700052, 253575.1663700052, 74039.31417070846], 
processed observation next is [1.0, 0.9565217391304348, 0.4090909090909091, 0.545, 1.0, 1.0, 0.041929645826012246, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09391672828518711, 0.09391672828518711, 0.18058369309928893], 
reward next is 0.8194, 
noisyNet noise sample is [array([1.295178], dtype=float32), 0.82247037]. 
=============================================
[2019-03-23 15:28:49,371] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.0841843e-08 1.0000000e+00 6.0186846e-22 9.5463991e-16 2.5165068e-09], sum to 1.0000
[2019-03-23 15:28:49,383] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5552
[2019-03-23 15:28:49,387] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 47.0, 1.0, 2.0, 0.2933454701880447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 318527.4832324717, 318527.4832324717, 87266.30587697738], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2308800.0000, 
sim time next is 2309400.0000, 
raw observation next is [20.5, 47.5, 1.0, 2.0, 0.2851328501412347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 309607.0185587883, 309607.0185587886, 85784.4771730993], 
processed observation next is [1.0, 0.7391304347826086, 0.5681818181818182, 0.475, 1.0, 1.0, 0.10641606267654334, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11466926613288456, 0.11466926613288465, 0.20923043212951048], 
reward next is 0.7908, 
noisyNet noise sample is [array([1.772973], dtype=float32), -0.95149153]. 
=============================================
[2019-03-23 15:28:57,731] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4390688e-08 1.0000000e+00 3.3655768e-24 3.9099660e-16 4.9541238e-10], sum to 1.0000
[2019-03-23 15:28:57,738] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6680
[2019-03-23 15:28:57,752] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 62.0, 1.0, 2.0, 0.7750995563830971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 852048.0049246709, 852048.0049246709, 159149.7442285513], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2478600.0000, 
sim time next is 2479200.0000, 
raw observation next is [21.06666666666667, 61.33333333333334, 1.0, 2.0, 0.7715382515918809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 846300.1983953983, 846300.1983953986, 158083.3251378278], 
processed observation next is [1.0, 0.6956521739130435, 0.5939393939393941, 0.6133333333333334, 1.0, 1.0, 0.7144228144898512, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3134445179242216, 0.3134445179242217, 0.38556908570201903], 
reward next is 0.6144, 
noisyNet noise sample is [array([-0.72985226], dtype=float32), -0.22872971]. 
=============================================
[2019-03-23 15:29:07,644] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.5233525e-08 1.0000000e+00 1.5438647e-21 2.7425802e-16 3.3075181e-10], sum to 1.0000
[2019-03-23 15:29:07,650] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8611
[2019-03-23 15:29:07,656] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.63333333333333, 98.33333333333333, 1.0, 2.0, 0.3277014372788051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 359346.2200642646, 359346.2200642646, 114315.7964074698], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2695800.0000, 
sim time next is 2696400.0000, 
raw observation next is [16.5, 99.0, 1.0, 2.0, 0.3260297360557623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 357079.1318651711, 357079.1318651711, 114037.292357631], 
processed observation next is [0.0, 0.21739130434782608, 0.38636363636363635, 0.99, 1.0, 1.0, 0.15753717006970286, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13225153032043374, 0.13225153032043374, 0.2781397374576366], 
reward next is 0.7219, 
noisyNet noise sample is [array([1.7355281], dtype=float32), 0.66219956]. 
=============================================
[2019-03-23 15:29:07,846] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.6323659e-08 9.9999988e-01 1.1873592e-19 2.4202421e-14 3.1524174e-09], sum to 1.0000
[2019-03-23 15:29:07,855] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3936
[2019-03-23 15:29:07,859] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.88333333333333, 88.33333333333333, 1.0, 2.0, 0.3306548613151244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 363395.7837197646, 363395.7837197646, 114828.211519462], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2689800.0000, 
sim time next is 2690400.0000, 
raw observation next is [17.76666666666667, 89.66666666666667, 1.0, 2.0, 0.3312273639096962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 364245.3130400533, 364245.313040053, 114952.2467255724], 
processed observation next is [0.0, 0.13043478260869565, 0.4439393939393941, 0.8966666666666667, 1.0, 1.0, 0.16403420488712023, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13490567149631605, 0.13490567149631594, 0.2803713334770059], 
reward next is 0.7196, 
noisyNet noise sample is [array([-0.8198962], dtype=float32), -0.8874494]. 
=============================================
[2019-03-23 15:29:10,860] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.8074171e-08 1.0000000e+00 4.3485492e-20 1.0805903e-14 1.2220226e-09], sum to 1.0000
[2019-03-23 15:29:10,866] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4263
[2019-03-23 15:29:10,868] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 54.33333333333334, 1.0, 2.0, 0.4421034195596192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 503747.2401522909, 503747.2401522909, 132754.2429366854], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2738400.0000, 
sim time next is 2739000.0000, 
raw observation next is [26.83333333333333, 52.66666666666666, 1.0, 2.0, 0.4366209719422482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 497230.5490192752, 497230.5490192752, 131865.859725251], 
processed observation next is [0.0, 0.6956521739130435, 0.8560606060606059, 0.5266666666666666, 1.0, 1.0, 0.2957762149278102, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18415946259973154, 0.18415946259973154, 0.3216240481103683], 
reward next is 0.6784, 
noisyNet noise sample is [array([0.05947585], dtype=float32), 0.91602325]. 
=============================================
[2019-03-23 15:29:10,881] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[64.67884 ]
 [64.664566]
 [64.65331 ]
 [64.656   ]
 [64.642494]], R is [[64.71646118]
 [64.74550629]
 [64.77226257]
 [64.79695892]
 [64.81987   ]].
[2019-03-23 15:29:16,832] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.2425514e-06 9.9999678e-01 4.8812557e-18 1.5309248e-14 3.2178484e-08], sum to 1.0000
[2019-03-23 15:29:16,843] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3655
[2019-03-23 15:29:16,849] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 88.0, 1.0, 2.0, 0.4513329158994209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 514407.4622188335, 514407.4622188335, 133902.852251743], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2874600.0000, 
sim time next is 2875200.0000, 
raw observation next is [21.66666666666667, 88.0, 1.0, 2.0, 0.4568739922390603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 520956.4313941489, 520956.4313941486, 134852.4873883026], 
processed observation next is [1.0, 0.2608695652173913, 0.6212121212121214, 0.88, 1.0, 1.0, 0.3210924902988253, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19294682644227737, 0.19294682644227726, 0.3289085058251283], 
reward next is 0.6711, 
noisyNet noise sample is [array([-0.92701584], dtype=float32), -0.33774817]. 
=============================================
[2019-03-23 15:29:17,657] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.3520401e-04 9.9964750e-01 1.4014202e-12 2.5895850e-09 1.7249287e-05], sum to 1.0000
[2019-03-23 15:29:17,663] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3758
[2019-03-23 15:29:17,669] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1433201.747115366 W.
[2019-03-23 15:29:17,674] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.33333333333334, 74.0, 1.0, 2.0, 0.7856557695103862, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9838030134534353, 6.9112, 6.9112, 77.32846344354104, 1433201.747115366, 1433201.747115366, 311792.2638082381], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2888400.0000, 
sim time next is 2889000.0000, 
raw observation next is [26.5, 74.0, 1.0, 2.0, 0.6738236854942565, 1.0, 1.0, 0.6738236854942565, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1515586.986902066, 1515586.986902066, 283667.6933220466], 
processed observation next is [1.0, 0.43478260869565216, 0.8409090909090909, 0.74, 1.0, 1.0, 0.5922796068678207, 1.0, 0.5, 0.5922796068678207, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5613285136674319, 0.5613285136674319, 0.691872422736699], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6869044], dtype=float32), -1.3311607]. 
=============================================
[2019-03-23 15:29:17,697] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[39.847595]
 [39.482697]
 [39.32334 ]
 [38.36934 ]
 [37.9227  ]], R is [[39.29666901]
 [38.90370178]
 [38.76613998]
 [38.64748764]
 [38.4968605 ]].
[2019-03-23 15:29:21,938] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 15:29:21,939] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:29:21,939] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:29:21,939] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:29:21,940] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:29:21,940] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:29:21,941] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:29:21,941] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:29:21,941] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:29:21,942] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:29:21,943] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:29:21,960] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run72
[2019-03-23 15:29:21,992] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run72
[2019-03-23 15:29:22,024] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run72
[2019-03-23 15:29:22,025] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run72
[2019-03-23 15:29:22,051] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run72
[2019-03-23 15:29:26,439] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05766981], dtype=float32), 0.31873372]
[2019-03-23 15:29:26,441] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.84625275333333, 99.36665595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4577705862759259, 6.911199999999999, 6.9112, 95.55338769695034, 266241.6828790276, 266241.682879028, 93193.17870131329]
[2019-03-23 15:29:26,442] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:29:26,444] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 2.6855588e-14 7.1443027e-17 3.3748488e-15 1.0326417e-14], sampled 0.9089789713967283
[2019-03-23 15:30:07,034] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05766981], dtype=float32), 0.31873372]
[2019-03-23 15:30:07,035] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.23333333333333, 41.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5689017119693154, 6.911200000000001, 6.9112, 95.55338769695034, 330893.8987850789, 330893.8987850785, 103545.7907519811]
[2019-03-23 15:30:07,037] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:30:07,041] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0000000e+00 1.6056137e-13 4.0750533e-16 1.7418128e-14 5.5758532e-14], sampled 0.40439774626555647
[2019-03-23 15:30:27,654] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05766981], dtype=float32), 0.31873372]
[2019-03-23 15:30:27,657] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.69672245, 75.80329115500001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5929053506236992, 6.9112, 6.9112, 95.55338769665262, 344839.0855838109, 344839.0855838109, 116185.641882273]
[2019-03-23 15:30:27,659] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:30:27,661] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 1.6215078e-15 3.8268696e-18 2.2445682e-16 6.7065406e-16], sampled 0.8400987464413578
[2019-03-23 15:31:08,729] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6294.9961 1685630448.6673 3228.0000
[2019-03-23 15:31:08,744] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6862.2842 1793014293.7888 2409.0000
[2019-03-23 15:31:08,820] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6553.1725 1698634175.0084 2957.0000
[2019-03-23 15:31:08,887] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6328.7217 1723294598.4314 3425.0000
[2019-03-23 15:31:08,952] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6481.6076 1678885180.2952 3057.0000
[2019-03-23 15:31:09,968] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1775000, evaluation results [1775000.0, 6862.284208925443, 1793014293.78876, 2409.0, 6481.607577760913, 1678885180.2951708, 3057.0, 6294.9960618483565, 1685630448.6673346, 3228.0, 6328.721692698646, 1723294598.4313502, 3425.0, 6553.172466661831, 1698634175.0084193, 2957.0]
[2019-03-23 15:31:11,623] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.6592930e-11 1.3765923e-14 2.2505819e-13 1.9600079e-12], sum to 1.0000
[2019-03-23 15:31:11,634] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7696
[2019-03-23 15:31:11,644] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 558948.3361581377 W.
[2019-03-23 15:31:11,648] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.33333333333334, 58.33333333333334, 1.0, 2.0, 0.2453514967230067, 1.0, 2.0, 0.2453514967230067, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344344448, 558948.3361581377, 558948.3361581377, 178984.5701130505], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3003600.0000, 
sim time next is 3004200.0000, 
raw observation next is [27.0, 60.0, 1.0, 2.0, 0.2456712346547614, 0.0, 1.0, 0.0, 1.0, 1.0, 0.496868677443179, 6.9112, 6.9112, 77.32846344354044, 560242.5676205556, 560242.5676205556, 177651.6924625103], 
processed observation next is [1.0, 0.782608695652174, 0.8636363636363636, 0.6, 1.0, 1.0, 0.057089043318451736, 0.0, 0.5, -0.25, 1.0, 0.5, 0.28124096777597, 0.0, 0.0, 0.5084288129206502, 0.20749724726687246, 0.20749724726687246, 0.4332968108841715], 
reward next is 0.5667, 
noisyNet noise sample is [array([0.04475522], dtype=float32), -1.2421563]. 
=============================================
[2019-03-23 15:31:19,132] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 4.3938532e-13 2.2928006e-13 6.9267552e-13 9.0652963e-13], sum to 1.0000
[2019-03-23 15:31:19,139] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3198
[2019-03-23 15:31:19,145] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 902786.268456763 W.
[2019-03-23 15:31:19,150] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.33333333333334, 71.66666666666667, 1.0, 2.0, 0.7923043763951524, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846331257524, 902786.268456763, 902786.2684567632, 177168.2237157427], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3144000.0000, 
sim time next is 3144600.0000, 
raw observation next is [23.5, 71.0, 1.0, 2.0, 0.4069812332433486, 0.0, 2.0, 0.0, 1.0, 1.0, 0.816428818064366, 6.9112, 6.9112, 77.32846344273035, 928186.0528617151, 928186.0528617151, 220513.8510744128], 
processed observation next is [1.0, 0.391304347826087, 0.7045454545454546, 0.71, 1.0, 1.0, 0.25872654155418573, 0.0, 1.0, -0.25, 1.0, 0.5, 0.7377554543776657, 0.0, 0.0, 0.5084288129153239, 0.3437726121710056, 0.3437726121710056, 0.5378386611571044], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1099889], dtype=float32), -2.5564535]. 
=============================================
[2019-03-23 15:31:23,206] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.5500692e-18 2.6389829e-31 8.5584600e-28 9.0995595e-21], sum to 1.0000
[2019-03-23 15:31:23,213] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9271
[2019-03-23 15:31:23,218] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6302058477228892, 6.9112, 6.9112, 77.32846344354104, 365292.9741728421, 365292.9741728421, 116991.2355848063], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3218400.0000, 
sim time next is 3219000.0000, 
raw observation next is [18.16666666666667, 87.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6315553628950239, 6.911199999999999, 6.9112, 77.32846344354104, 366025.4479945272, 366025.4479945275, 117147.2854474765], 
processed observation next is [0.0, 0.2608695652173913, 0.4621212121212123, 0.8716666666666667, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4736505184214628, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13556498073871376, 0.1355649807387139, 0.28572508645725975], 
reward next is 0.7143, 
noisyNet noise sample is [array([-0.11605712], dtype=float32), 0.15691334]. 
=============================================
[2019-03-23 15:31:23,234] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[68.53146]
 [68.27027]
 [68.3898 ]
 [68.48025]
 [68.79407]], R is [[68.05878448]
 [68.09284973]
 [68.12631226]
 [68.15913391]
 [68.19119263]].
[2019-03-23 15:31:29,277] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9999809e-01 1.9159893e-06 4.6254381e-25 2.7680379e-19 1.5390822e-12], sum to 1.0000
[2019-03-23 15:31:29,285] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5880
[2019-03-23 15:31:29,305] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.0, 50.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6958868784703126, 6.911199999999999, 6.9112, 77.32846344354104, 400990.074234243, 400990.0742342432, 124880.9447723431], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3336600.0000, 
sim time next is 3337200.0000, 
raw observation next is [25.0, 50.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6957230234833708, 6.9112, 6.9112, 77.32846344354104, 400895.4613829636, 400895.4613829636, 124864.474261433], 
processed observation next is [0.0, 0.6521739130434783, 0.7727272727272727, 0.5, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.565318604976244, 0.0, 0.0, 0.5084288129206541, 0.14847980051220874, 0.14847980051220874, 0.3045474981986171], 
reward next is 0.6955, 
noisyNet noise sample is [array([1.6721594], dtype=float32), 0.56545454]. 
=============================================
[2019-03-23 15:31:31,306] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 4.2195556e-11 2.0960575e-24 2.9680543e-21 1.3580552e-14], sum to 1.0000
[2019-03-23 15:31:31,312] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4304
[2019-03-23 15:31:31,317] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.0, 57.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7257030209318409, 7.010089301893653, 6.9112, 77.32813170195111, 449738.8410176107, 417621.7561824759, 128394.5543165573], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3348000.0000, 
sim time next is 3348600.0000, 
raw observation next is [23.83333333333333, 57.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7277904204504829, 7.027098463827527, 6.9112, 77.32807097362186, 456444.9979269432, 418803.7384532704, 128634.3801907791], 
processed observation next is [0.0, 0.782608695652174, 0.7196969696969695, 0.5766666666666665, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6111291720721185, 0.01158984638275271, 0.0, 0.5084262324605463, 0.16905370293590488, 0.15511249572343347, 0.31374239070921733], 
reward next is 0.1068, 
noisyNet noise sample is [array([0.10311398], dtype=float32), 1.7656479]. 
=============================================
[2019-03-23 15:31:33,424] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.6435645e-09 4.4966201e-12 2.3027207e-11 1.6356969e-08], sum to 1.0000
[2019-03-23 15:31:33,430] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7478
[2019-03-23 15:31:33,437] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1328490.508401092 W.
[2019-03-23 15:31:33,441] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.66666666666667, 57.33333333333334, 1.0, 2.0, 0.585665292156919, 1.0, 2.0, 0.585665292156919, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1328490.508401092, 1328490.508401091, 254857.6665691829], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3428400.0000, 
sim time next is 3429000.0000, 
raw observation next is [27.5, 58.5, 1.0, 2.0, 0.3953392442655949, 1.0, 2.0, 0.3953392442655949, 1.0, 1.0, 0.8003416875614218, 6.911199999999999, 6.9112, 77.3421103, 1342523.846471914, 1342523.846471914, 301625.285387998], 
processed observation next is [1.0, 0.6956521739130435, 0.8863636363636364, 0.585, 1.0, 1.0, 0.24417405533199363, 1.0, 1.0, 0.24417405533199363, 1.0, 0.5, 0.7147738393734596, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.49723105424885705, 0.49723105424885705, 0.7356714277756048], 
reward next is 0.2643, 
noisyNet noise sample is [array([0.9786018], dtype=float32), 2.20734]. 
=============================================
[2019-03-23 15:31:33,455] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[20.10669 ]
 [20.212484]
 [21.042189]
 [20.457384]
 [20.385826]], R is [[21.30001831]
 [21.46541405]
 [21.25076103]
 [21.03825378]
 [20.82787132]].
[2019-03-23 15:31:37,301] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9999964e-01 2.0758463e-08 3.3114372e-10 7.5692058e-10 3.7362366e-07], sum to 1.0000
[2019-03-23 15:31:37,305] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5890
[2019-03-23 15:31:37,314] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 613209.8646324903 W.
[2019-03-23 15:31:37,320] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.66666666666667, 68.66666666666667, 1.0, 2.0, 0.2701597960337476, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5472456511339263, 6.9112, 6.9112, 77.32846344354104, 613209.8646324903, 613209.8646324903, 186146.5354414379], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3525600.0000, 
sim time next is 3526200.0000, 
raw observation next is [26.5, 70.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3680336306481616, 6.911199999999999, 6.9112, 77.3421103, 616750.4522852702, 616750.4522852706, 222112.1454139077], 
processed observation next is [1.0, 0.8260869565217391, 0.8409090909090909, 0.7, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.09719090092594514, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.22842609343898895, 0.2284260934389891, 0.5417369400339213], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.10802861], dtype=float32), 1.7939267]. 
=============================================
[2019-03-23 15:31:38,345] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9999022e-01 4.5593734e-07 1.3679581e-09 2.8072012e-08 9.2730143e-06], sum to 1.0000
[2019-03-23 15:31:38,350] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6412
[2019-03-23 15:31:38,360] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 624771.5419407645 W.
[2019-03-23 15:31:38,364] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 72.66666666666667, 1.0, 2.0, 0.2757028692433619, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5583517264567771, 6.9112, 6.9112, 77.32846344354104, 624771.5419407645, 624771.5419407645, 188119.0764314183], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3527400.0000, 
sim time next is 3528000.0000, 
raw observation next is [26.0, 74.0, 1.0, 2.0, 0.553907100829781, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 628302.8408297021, 628302.8408297021, 151007.0221465794], 
processed observation next is [1.0, 0.8695652173913043, 0.8181818181818182, 0.74, 1.0, 1.0, 0.44238387603722623, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23270475586285264, 0.23270475586285264, 0.3683098101136083], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.97334844], dtype=float32), -0.8879618]. 
=============================================
[2019-03-23 15:31:38,375] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[19.580635]
 [19.93257 ]
 [19.677095]
 [19.975416]
 [20.184351]], R is [[19.46614647]
 [19.27148438]
 [19.07876968]
 [19.43276787]
 [19.23843956]].
[2019-03-23 15:31:44,354] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 4.5521271e-11 3.3417253e-12 3.1550838e-12 2.1875774e-08], sum to 1.0000
[2019-03-23 15:31:44,360] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6459
[2019-03-23 15:31:44,360] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 586161.4995285486 W.
[2019-03-23 15:31:44,364] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.2571452087982132, 1.0, 1.0, 0.2571452087982132, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 586161.4995285486, 586161.4995285483, 180462.65441695], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3645000.0000, 
sim time next is 3645600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.2544370921012912, 1.0, 2.0, 0.2544370921012912, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 579896.0741118559, 579896.0741118556, 180147.2111691247], 
processed observation next is [1.0, 0.17391304347826086, 0.5909090909090909, 1.0, 1.0, 1.0, 0.06804636512661395, 1.0, 1.0, 0.06804636512661395, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21477632374513184, 0.2147763237451317, 0.4393834418759139], 
reward next is 0.5606, 
noisyNet noise sample is [array([-1.0538762], dtype=float32), -1.2923787]. 
=============================================
[2019-03-23 15:31:48,326] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.5251045e-01 4.9219139e-02 1.7151768e-06 9.1688726e-06 9.8259553e-02], sum to 1.0000
[2019-03-23 15:31:48,334] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3555
[2019-03-23 15:31:48,349] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 576584.975855879 W.
[2019-03-23 15:31:48,352] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 78.83333333333333, 1.0, 2.0, 0.25321806387117, 1.0, 2.0, 0.25321806387117, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576584.975855879, 576584.975855879, 180559.7652745228], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3705000.0000, 
sim time next is 3705600.0000, 
raw observation next is [24.0, 79.66666666666667, 1.0, 2.0, 0.2545867265765328, 1.0, 2.0, 0.2545867265765328, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 579501.6678221963, 579501.6678221965, 180973.9282550469], 
processed observation next is [1.0, 0.9130434782608695, 0.7272727272727273, 0.7966666666666667, 1.0, 1.0, 0.068233408220666, 1.0, 1.0, 0.068233408220666, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21463024734155417, 0.21463024734155425, 0.4413998250123095], 
reward next is 0.5586, 
noisyNet noise sample is [array([-0.02311863], dtype=float32), -0.4530034]. 
=============================================
[2019-03-23 15:31:48,464] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.1962267e-01 5.1024605e-02 8.2511151e-06 6.7099747e-05 2.2927731e-01], sum to 1.0000
[2019-03-23 15:31:48,472] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5938
[2019-03-23 15:31:48,482] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 604566.6112791798 W.
[2019-03-23 15:31:48,490] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5303467654603476, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 604566.6112791798, 604566.6112791798, 146089.9904947915], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3727200.0000, 
sim time next is 3727800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.519264286305183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592191.3629497242, 592191.3629497242, 144384.8841806896], 
processed observation next is [1.0, 0.13043478260869565, 0.6363636363636364, 0.94, 1.0, 1.0, 0.39908035788147866, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21933013442582378, 0.21933013442582378, 0.35215825409924295], 
reward next is 0.6478, 
noisyNet noise sample is [array([1.7699714], dtype=float32), 0.36228693]. 
=============================================
[2019-03-23 15:31:51,877] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 3.6551805e-13 3.5733386e-19 1.8368666e-18 4.7578101e-08], sum to 1.0000
[2019-03-23 15:31:51,885] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2925
[2019-03-23 15:31:51,891] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.0, 64.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6361875842712115, 6.9112, 6.9112, 77.32846344354104, 369068.6863550889, 369068.6863550889, 117285.5400569265], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3780600.0000, 
sim time next is 3781200.0000, 
raw observation next is [21.0, 65.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6403608211666217, 6.911199999999999, 6.9112, 77.32846344354104, 371336.5753512202, 371336.5753512205, 117771.488287765], 
processed observation next is [1.0, 0.782608695652174, 0.5909090909090909, 0.6566666666666667, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4862297445237454, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13753206494489637, 0.13753206494489648, 0.28724753240918294], 
reward next is 0.7128, 
noisyNet noise sample is [array([0.81088144], dtype=float32), -1.0837669]. 
=============================================
[2019-03-23 15:31:51,912] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 2.3000013e-13 1.6817876e-19 8.9556229e-19 3.6548066e-08], sum to 1.0000
[2019-03-23 15:31:51,924] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6359
[2019-03-23 15:31:51,930] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.0, 65.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6403608211666217, 6.911199999999999, 6.9112, 77.32846344354104, 371336.5753512202, 371336.5753512205, 117771.488287765], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3781200.0000, 
sim time next is 3781800.0000, 
raw observation next is [21.0, 66.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6436527083200126, 6.911199999999999, 6.9112, 77.32846344354104, 373045.5172357789, 373045.5172357791, 118217.0533740707], 
processed observation next is [1.0, 0.782608695652174, 0.5909090909090909, 0.665, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.49093244045716095, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1381650063836218, 0.1381650063836219, 0.2883342765221237], 
reward next is 0.7117, 
noisyNet noise sample is [array([0.81088144], dtype=float32), -1.0837669]. 
=============================================
[2019-03-23 15:31:52,200] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9997878e-01 4.2407827e-11 2.1168043e-20 9.0067199e-19 2.1205162e-05], sum to 1.0000
[2019-03-23 15:31:52,205] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7905
[2019-03-23 15:31:52,211] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.0, 88.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.554176196618597, 6.911199999999998, 6.9112, 77.32846344354104, 322347.0812970271, 322347.0812970276, 106335.0459536776], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3823800.0000, 
sim time next is 3824400.0000, 
raw observation next is [17.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.554545390329066, 6.911199999999999, 6.9112, 77.32846344354104, 322561.9010367031, 322561.9010367034, 106364.7907593264], 
processed observation next is [0.0, 0.2608695652173913, 0.4090909090909091, 0.88, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.36363627189866576, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11946737075433447, 0.11946737075433458, 0.2594263189251863], 
reward next is 0.7406, 
noisyNet noise sample is [array([-0.5771769], dtype=float32), 0.50194657]. 
=============================================
[2019-03-23 15:31:52,234] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9862850e-01 8.3585940e-07 4.8171709e-14 5.4323370e-13 1.3706525e-03], sum to 1.0000
[2019-03-23 15:31:52,243] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4887
[2019-03-23 15:31:52,251] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1062369.359576682 W.
[2019-03-23 15:31:52,256] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333333, 78.16666666666667, 1.0, 2.0, 0.3102077466533055, 1.0, 2.0, 0.3102077466533055, 1.0, 2.0, 0.6246930886173612, 6.9112, 6.9112, 77.3421103, 1062369.359576682, 1062369.359576682, 255344.2006076831], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3765000.0000, 
sim time next is 3765600.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.8738845196124178, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 994139.0059914902, 994139.0059914902, 188325.7682535519], 
processed observation next is [1.0, 0.6086956521739131, 0.5909090909090909, 0.83, 1.0, 1.0, 0.8423556495155221, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3681996318487001, 0.3681996318487001, 0.45933114208183395], 
reward next is 0.5407, 
noisyNet noise sample is [array([-1.270389], dtype=float32), -1.0252087]. 
=============================================
[2019-03-23 15:31:58,150] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 15:31:58,154] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:31:58,155] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:31:58,156] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:31:58,157] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:31:58,157] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:31:58,158] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:31:58,160] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:31:58,160] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:31:58,160] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:31:58,165] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:31:58,184] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run73
[2019-03-23 15:31:58,214] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run73
[2019-03-23 15:31:58,215] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run73
[2019-03-23 15:31:58,274] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run73
[2019-03-23 15:31:58,315] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run73
[2019-03-23 15:31:59,551] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05898248], dtype=float32), 0.3255378]
[2019-03-23 15:31:59,552] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [13.2, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3623901733801786, 6.911200000000001, 6.9112, 95.55338769695034, 210758.2279783613, 210758.227978361, 68918.06023062908]
[2019-03-23 15:31:59,552] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:31:59,554] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.9998999e-01 2.1910264e-11 1.0754887e-21 4.5473311e-20 9.9897425e-06], sampled 0.1277833451145719
[2019-03-23 15:32:24,067] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05898248], dtype=float32), 0.3255378]
[2019-03-23 15:32:24,071] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.88585595333333, 91.55233389, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7327495347818922, 7.276993056606167, 6.9112, 95.55221752654094, 565867.5245493504, 419067.7061483212, 135347.5847619331]
[2019-03-23 15:32:24,071] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:32:24,075] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.9999177e-01 1.5257402e-10 7.5243816e-17 6.4940761e-16 8.1787066e-06], sampled 0.12407607932137454
[2019-03-23 15:32:24,078] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 565867.5245493504 W.
[2019-03-23 15:33:25,595] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05898248], dtype=float32), 0.3255378]
[2019-03-23 15:33:25,597] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [12.28333333333333, 88.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3350923146745098, 6.911199999999999, 6.9112, 77.32846344354104, 195017.1006400827, 195017.100640083, 59678.50900689229]
[2019-03-23 15:33:25,598] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:33:25,603] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.9998307e-01 6.5601552e-11 8.5225735e-21 3.1027180e-19 1.6978282e-05], sampled 0.12506509107102082
[2019-03-23 15:33:29,210] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05898248], dtype=float32), 0.3255378]
[2019-03-23 15:33:29,211] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.7, 90.83333333333334, 1.0, 2.0, 0.6052947259127062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 690687.0686229962, 690687.0686229962, 157856.6992991889]
[2019-03-23 15:33:29,213] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:33:29,215] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.9999940e-01 5.0991949e-12 1.8740174e-17 1.0613387e-16 6.3839258e-07], sampled 0.4757812003507178
[2019-03-23 15:33:29,217] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 690687.0686229962 W.
[2019-03-23 15:33:44,191] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6294.9961 1685630448.6673 3228.0000
[2019-03-23 15:33:44,715] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6328.0364 1723360970.2339 3425.0000
[2019-03-23 15:33:44,750] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6553.1725 1698634175.0084 2957.0000
[2019-03-23 15:33:44,762] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6860.7133 1793061556.0640 2409.0000
[2019-03-23 15:33:44,831] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6480.9370 1678937502.6944 3056.0000
[2019-03-23 15:33:45,846] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1800000, evaluation results [1800000.0, 6860.713318844425, 1793061556.0640304, 2409.0, 6480.937032861142, 1678937502.6944199, 3056.0, 6294.9960618483565, 1685630448.6673346, 3228.0, 6328.036411955742, 1723360970.2339125, 3425.0, 6553.172466661831, 1698634175.0084193, 2957.0]
[2019-03-23 15:33:58,169] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9998295e-01 1.5504639e-07 6.0800160e-09 1.5773370e-08 1.6892567e-05], sum to 1.0000
[2019-03-23 15:33:58,173] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5619
[2019-03-23 15:33:58,175] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.731613206842875, 7.060136420335058, 6.9112, 77.32795249712015, 469470.7615430784, 421099.5781086843, 128979.2520764925], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4152600.0000, 
sim time next is 4153200.0000, 
raw observation next is [18.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7320528917903123, 7.063787305462887, 6.9112, 77.32794600378453, 470910.178312325, 421353.2740579973, 129026.6870732334], 
processed observation next is [1.0, 0.043478260869565216, 0.45454545454545453, 1.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6172184168433034, 0.015258730546288657, 0.0, 0.5084254107932945, 0.17441117715271295, 0.15605676816962863, 0.3146992367639839], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1529628], dtype=float32), 0.012250244]. 
=============================================
[2019-03-23 15:34:03,378] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.2978917e-32 1.3926304e-33 4.0101558e-34 2.9941141e-24], sum to 1.0000
[2019-03-23 15:34:03,389] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0549
[2019-03-23 15:34:03,396] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.0, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5432680085643693, 6.9112, 6.9112, 77.32846344354104, 316000.0656435633, 316000.0656435633, 105279.5980293214], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4253400.0000, 
sim time next is 4254000.0000, 
raw observation next is [16.0, 98.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5498991011601639, 6.911199999999999, 6.9112, 77.32846344354104, 319858.4095461225, 319858.4095461228, 107008.0816327486], 
processed observation next is [1.0, 0.21739130434782608, 0.36363636363636365, 0.98, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3569987159430914, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.118466077609675, 0.11846607760967512, 0.2609953210554844], 
reward next is 0.7390, 
noisyNet noise sample is [array([1.2642282], dtype=float32), 0.19746733]. 
=============================================
[2019-03-23 15:34:03,424] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[64.985016]
 [64.99594 ]
 [65.01228 ]
 [65.01863 ]
 [65.1427  ]], R is [[64.9160614 ]
 [65.01011658]
 [65.10670471]
 [65.20306396]
 [65.29644775]].
[2019-03-23 15:34:03,902] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 4.5349617e-25 2.2751584e-27 8.1087737e-27 1.2013562e-18], sum to 1.0000
[2019-03-23 15:34:04,018] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7761
[2019-03-23 15:34:04,033] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.637175416852973, 6.911199999999999, 6.9112, 77.32846344354104, 370044.9473056495, 370044.9473056498, 117065.9400971658], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4258800.0000, 
sim time next is 4259400.0000, 
raw observation next is [17.16666666666667, 94.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7088694576461019, 6.921809678097543, 6.9112, 77.32843781637254, 414932.9461279142, 411487.1408292404, 123937.5102765031], 
processed observation next is [1.0, 0.30434782608695654, 0.4166666666666669, 0.9400000000000002, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.584099225208717, 0.0010609678097543095, 0.0, 0.5084286444239547, 0.1536788689362645, 0.1524026447515705, 0.3022866104304954], 
reward next is 0.6447, 
noisyNet noise sample is [array([-1.3623627], dtype=float32), -2.07456]. 
=============================================
[2019-03-23 15:34:05,661] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.4109568e-01 1.3979618e-03 2.7714597e-10 1.2369831e-08 5.5750638e-01], sum to 1.0000
[2019-03-23 15:34:05,662] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0086
[2019-03-23 15:34:05,662] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1175737.578453925 W.
[2019-03-23 15:34:05,667] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.06666666666667, 48.66666666666666, 1.0, 2.0, 0.5148794738319717, 1.0, 2.0, 0.5148794738319717, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344353672, 1175737.578453925, 1175737.578453925, 228410.6637352753], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4286400.0000, 
sim time next is 4287000.0000, 
raw observation next is [27.08333333333334, 48.83333333333334, 1.0, 2.0, 0.5548415956533955, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9609471389340035, 6.916380669698109, 6.9112, 77.32845073454399, 1180952.431841359, 1179269.856562966, 257749.0070214929], 
processed observation next is [1.0, 0.6086956521739131, 0.8674242424242427, 0.48833333333333345, 1.0, 1.0, 0.4435519945667444, 0.0, 0.5, -0.25, 1.0, 0.5, 0.944210198477148, 0.0005180669698108709, 0.0, 0.5084287293599574, 0.4373897895708737, 0.43676661354183927, 0.628656114686568], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.48556176], dtype=float32), -1.0859773]. 
=============================================
[2019-03-23 15:34:05,682] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[42.402565]
 [43.445385]
 [42.653194]
 [42.351704]
 [40.556103]], R is [[42.3238678 ]
 [42.34353256]
 [42.26413727]
 [42.1920433 ]
 [42.13179779]].
[2019-03-23 15:34:06,334] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9999523e-01 7.6010592e-10 2.8150377e-12 4.5487355e-12 4.7844560e-06], sum to 1.0000
[2019-03-23 15:34:06,346] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9087
[2019-03-23 15:34:06,350] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.66666666666667, 58.33333333333334, 1.0, 1.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 498240.3200865973, 498240.3200865973, 195961.76332628], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4303200.0000, 
sim time next is 4303800.0000, 
raw observation next is [24.5, 59.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7510867912020366, 7.167502598148953, 6.9112, 77.32780716611127, 511801.4192866811, 428560.2841661717, 133833.1747478274], 
processed observation next is [1.0, 0.8260869565217391, 0.75, 0.59, 0.0, 0.5, -0.25, 0.0, 0.5, -0.25, 1.0, 1.0, 0.6444097017171951, 0.025630259814895327, 0.0, 0.5084244979460677, 0.18955608121728929, 0.15872603117265618, 0.3264223774337254], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.07717177], dtype=float32), 1.7833143]. 
=============================================
[2019-03-23 15:34:10,418] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 5.0100525e-15 7.6199795e-14 8.9442085e-14 1.2990448e-11], sum to 1.0000
[2019-03-23 15:34:10,424] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2128
[2019-03-23 15:34:10,431] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 555923.6936237278 W.
[2019-03-23 15:34:10,435] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.43333333333334, 67.33333333333334, 1.0, 2.0, 0.2436488229312023, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4922329210666246, 6.9112, 6.9112, 77.32846344354104, 555923.6936237278, 555923.6936237278, 176483.1252326348], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4393200.0000, 
sim time next is 4393800.0000, 
raw observation next is [25.15, 68.5, 1.0, 2.0, 0.2421846395431742, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4890892085443034, 6.911199999999999, 6.9112, 77.32846344354104, 552635.2829253053, 552635.2829253055, 175942.3203320997], 
processed observation next is [1.0, 0.8695652173913043, 0.7795454545454544, 0.685, 1.0, 1.0, 0.052730799428967745, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2701274407775763, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20467973441677975, 0.20467973441677983, 0.4291276105660969], 
reward next is 0.5709, 
noisyNet noise sample is [array([0.03199952], dtype=float32), 0.11304168]. 
=============================================
[2019-03-23 15:34:14,586] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.00000000e+00 3.00880085e-26 1.04225426e-22 2.80952774e-22
 1.52587965e-19], sum to 1.0000
[2019-03-23 15:34:14,587] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 8.6371397e-21 1.6266235e-17 2.1702868e-17 1.7779389e-15], sum to 1.0000
[2019-03-23 15:34:14,591] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1793
[2019-03-23 15:34:14,595] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3337
[2019-03-23 15:34:14,600] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 569394.4700441526 W.
[2019-03-23 15:34:14,603] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.83333333333333, 74.66666666666667, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 1.0, 0.3162258650062468, 6.9112, 6.9112, 77.3421103, 535393.5194280304, 535393.5194280304, 205944.7251595048], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4441800.0000, 
sim time next is 4442400.0000, 
raw observation next is [24.0, 74.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8045808967438735, 7.548585762882986, 6.9112, 77.32691764842433, 662047.390969397, 455041.6701031277, 143153.8754701914], 
processed observation next is [0.0, 0.43478260869565216, 0.7272727272727273, 0.74, 0.0, 0.5, -0.25, 0.0, 0.5, -0.25, 1.0, 1.0, 0.7208298524912478, 0.06373857628829863, 0.0, 0.5084186494343877, 0.24520273739607298, 0.1685339518900473, 0.3491557938297351], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.05790583], dtype=float32), -0.3063036]. 
=============================================
[2019-03-23 15:34:14,606] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 78.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3373432312422162, 6.9112, 6.9112, 77.3421103, 569394.4700441526, 569394.4700441526, 211906.1245801742], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4470600.0000, 
sim time next is 4471200.0000, 
raw observation next is [24.0, 78.0, 1.0, 2.0, 0.2502361134000718, 1.0, 2.0, 0.2502361134000718, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 570031.3036695499, 570031.3036695496, 179822.9467002123], 
processed observation next is [0.0, 0.782608695652174, 0.7272727272727273, 0.78, 1.0, 1.0, 0.06279514175008973, 1.0, 1.0, 0.06279514175008973, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21112270506279626, 0.21112270506279615, 0.4385925529273471], 
reward next is 0.5614, 
noisyNet noise sample is [array([0.35465237], dtype=float32), 1.397821]. 
=============================================
[2019-03-23 15:34:19,113] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 4.8247944e-16 3.1124341e-14 6.4864618e-14 1.0312812e-11], sum to 1.0000
[2019-03-23 15:34:19,119] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9944
[2019-03-23 15:34:19,127] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 574076.801192652 W.
[2019-03-23 15:34:19,131] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7668358904625291, 7.325457035026426, 6.9112, 77.3272186649615, 574076.801192652, 439536.7550025063, 134269.4099319936], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4546800.0000, 
sim time next is 4547400.0000, 
raw observation next is [23.16666666666667, 67.66666666666667, 1.0, 1.0, 0.2195353091689965, 1.0, 1.0, 0.2195353091689965, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32821330605597, 499469.7510336387, 499469.7510336387, 168972.0233996204], 
processed observation next is [0.0, 0.6521739130434783, 0.6893939393939396, 0.6766666666666667, 1.0, 0.5, 0.024419136461245605, 1.0, 0.5, 0.024419136461245605, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.508427168285562, 0.18498879667912546, 0.18498879667912546, 0.41212688634053757], 
reward next is 0.5879, 
noisyNet noise sample is [array([0.48998672], dtype=float32), -1.4479517]. 
=============================================
[2019-03-23 15:34:22,823] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 7.9254656e-20 3.5556718e-21 1.3065332e-20 6.3915980e-15], sum to 1.0000
[2019-03-23 15:34:22,830] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2470
[2019-03-23 15:34:22,845] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 730793.0205138329 W.
[2019-03-23 15:34:22,847] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 47.00000000000001, 1.0, 2.0, 0.3315914510058013, 1.0, 1.0, 0.3315914510058013, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 730793.0205138329, 730793.0205138329, 173547.5951436754], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4633800.0000, 
sim time next is 4634400.0000, 
raw observation next is [23.33333333333334, 47.0, 1.0, 2.0, 0.6467846466674513, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 707274.7643804061, 707274.7643804058, 142744.3762213875], 
processed observation next is [1.0, 0.6521739130434783, 0.6969696969696972, 0.47, 1.0, 1.0, 0.558480808334314, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.26195361643718745, 0.26195361643718734, 0.34815701517411585], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.37374952], dtype=float32), 0.7915675]. 
=============================================
[2019-03-23 15:34:27,010] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9994385e-01 1.0046531e-10 2.2253759e-19 2.9341562e-17 5.6182289e-05], sum to 1.0000
[2019-03-23 15:34:27,017] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8947
[2019-03-23 15:34:27,024] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3847360504331819, 6.911199999999999, 6.9112, 77.32846344354104, 223766.3381759086, 223766.3381759089, 67426.81381967019], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4686000.0000, 
sim time next is 4686600.0000, 
raw observation next is [14.0, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.377467841953645, 6.911199999999999, 6.9112, 77.32846344354104, 219538.1213852293, 219538.1213852295, 66406.67474035645], 
processed observation next is [1.0, 0.21739130434782608, 0.2727272727272727, 0.83, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.11066834564806434, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08131041532786269, 0.08131041532786278, 0.16196749936672306], 
reward next is 0.8380, 
noisyNet noise sample is [array([0.6197574], dtype=float32), -0.040200826]. 
=============================================
[2019-03-23 15:34:28,908] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.4576851e-01 2.3406349e-06 1.2053242e-10 7.2221862e-10 1.5422918e-01], sum to 1.0000
[2019-03-23 15:34:28,917] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0007
[2019-03-23 15:34:28,925] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1178559.343176826 W.
[2019-03-23 15:34:28,932] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 54.0, 1.0, 2.0, 0.3440681151201956, 1.0, 2.0, 0.3440681151201956, 1.0, 2.0, 0.6941533837248346, 6.9112, 6.9112, 77.3421103, 1178559.343176826, 1178559.343176826, 269439.6164132772], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4722000.0000, 
sim time next is 4722600.0000, 
raw observation next is [26.0, 54.0, 1.0, 2.0, 0.3469565776107147, 1.0, 2.0, 0.3469565776107147, 1.0, 2.0, 0.7001058851557272, 6.911199999999999, 6.9112, 77.3421103, 1188450.030814335, 1188450.030814335, 270743.5715520619], 
processed observation next is [1.0, 0.6521739130434783, 0.8181818181818182, 0.54, 1.0, 1.0, 0.18369572201339335, 1.0, 1.0, 0.18369572201339335, 1.0, 1.0, 0.5715798359367532, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4401666780793833, 0.4401666780793833, 0.6603501745172241], 
reward next is 0.3396, 
noisyNet noise sample is [array([-0.8272043], dtype=float32), 0.17675552]. 
=============================================
[2019-03-23 15:34:29,721] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9999976e-01 1.2196332e-09 6.9499797e-09 1.4913882e-08 2.6100733e-07], sum to 1.0000
[2019-03-23 15:34:29,726] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7979
[2019-03-23 15:34:29,732] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 576840.6640959614 W.
[2019-03-23 15:34:29,735] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.66666666666667, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7676909116359826, 7.332467173147771, 6.9112, 77.32728555754477, 576840.6640959614, 440023.7867210885, 134371.7221060161], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4776000.0000, 
sim time next is 4776600.0000, 
raw observation next is [18.83333333333333, 100.0, 1.0, 1.0, 0.2294464492876617, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4553382734906579, 6.911199999999999, 6.9112, 77.32820942917718, 520429.3319591862, 520429.3319591865, 167502.5211294268], 
processed observation next is [1.0, 0.2608695652173913, 0.4924242424242422, 1.0, 1.0, 0.5, 0.03680806160957711, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2219118192723685, -8.881784197001253e-17, 0.0, 0.5084271427953764, 0.1927516044293282, 0.19275160442932832, 0.4085427344620166], 
reward next is 0.5915, 
noisyNet noise sample is [array([0.32473457], dtype=float32), 1.4002497]. 
=============================================
[2019-03-23 15:34:29,812] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.6698401e-11 3.5483746e-10 9.2656433e-10 9.8778026e-09], sum to 1.0000
[2019-03-23 15:34:29,820] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5297
[2019-03-23 15:34:29,824] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7346981358081713, 7.085718694954628, 6.9112, 77.32784049697855, 479556.9859247562, 422877.3399345484, 129314.376577363], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4771800.0000, 
sim time next is 4772400.0000, 
raw observation next is [18.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7314159165479024, 7.058487129302633, 6.9112, 77.32793407487684, 468820.5151700191, 420984.9955858933, 128958.5187824522], 
processed observation next is [1.0, 0.21739130434782608, 0.45454545454545453, 1.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6163084522112892, 0.014728712930263298, 0.0, 0.5084253323616263, 0.1736372278407478, 0.15592036873551604, 0.3145329726401273], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5270255], dtype=float32), -1.3397565]. 
=============================================
[2019-03-23 15:34:30,183] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9999714e-01 2.3376153e-08 7.3299412e-07 1.0679209e-06 1.0811060e-06], sum to 1.0000
[2019-03-23 15:34:30,193] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4781
[2019-03-23 15:34:30,200] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 550925.7996713674 W.
[2019-03-23 15:34:30,207] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [19.0, 100.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7617914053993488, 7.266736826779663, 6.9112, 77.32757447171653, 550925.7996713674, 435456.0377803502, 134534.5115430368], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4777200.0000, 
sim time next is 4777800.0000, 
raw observation next is [19.0, 100.0, 1.0, 1.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 500000.0981418489, 500000.0981418492, 196550.6819414371], 
processed observation next is [1.0, 0.30434782608695654, 0.5, 1.0, 1.0, 0.5, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.18518522153401812, 0.18518522153401823, 0.47939190717423685], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7056829], dtype=float32), 0.68808806]. 
=============================================
[2019-03-23 15:34:33,889] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 15:34:33,892] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:34:33,893] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:34:33,893] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:34:33,894] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:34:33,895] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:34:33,896] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:34:33,897] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:34:33,896] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:34:33,899] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:34:33,900] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:34:33,924] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run74
[2019-03-23 15:34:33,955] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run74
[2019-03-23 15:34:33,988] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run74
[2019-03-23 15:34:34,019] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run74
[2019-03-23 15:34:34,048] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run74
[2019-03-23 15:34:51,724] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06071934], dtype=float32), 0.3219843]
[2019-03-23 15:34:51,727] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.15, 92.0, 1.0, 2.0, 0.401894981208997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 452514.276662729, 452514.2766627286, 129151.9319856693]
[2019-03-23 15:34:51,728] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:34:51,731] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.3161367e-02 4.6162185e-01 2.7893557e-05 3.4245200e-04 5.2484649e-01], sampled 0.704864348401202
[2019-03-23 15:35:03,583] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06071934], dtype=float32), 0.3219843]
[2019-03-23 15:35:03,585] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.58333333333333, 50.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4545935197662498, 6.9112, 6.9112, 95.55338769695034, 264393.5062483661, 264393.5062483661, 78213.39211474896]
[2019-03-23 15:35:03,585] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:35:03,588] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.9226308e-01 1.0370541e-03 1.3928543e-05 6.6483852e-05 6.6195042e-03], sampled 0.14424075433578543
[2019-03-23 15:35:31,206] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06071934], dtype=float32), 0.3219843]
[2019-03-23 15:35:31,209] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.03333333333333, 67.0, 1.0, 2.0, 0.5170655484794257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 589440.5643561084, 589440.5643561081, 148676.3315607735]
[2019-03-23 15:35:31,211] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:35:31,213] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.9909663e-01 6.6363595e-05 2.2876928e-07 1.6723773e-06 8.3519402e-04], sampled 0.9748289178039332
[2019-03-23 15:35:31,215] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 589440.5643561084 W.
[2019-03-23 15:35:41,589] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06071934], dtype=float32), 0.3219843]
[2019-03-23 15:35:41,592] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.96248627666667, 75.86714298833333, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 1.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 313025.5262070022, 313025.5262070018, 162681.3483684912]
[2019-03-23 15:35:41,593] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:35:41,596] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.4084384e-02 4.7618121e-01 4.2528849e-05 4.8520954e-04 5.0920671e-01], sampled 0.575384855386963
[2019-03-23 15:35:46,980] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06071934], dtype=float32), 0.3219843]
[2019-03-23 15:35:46,981] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.46666666666667, 60.16666666666667, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3158372361581402, 6.911199999999999, 6.9112, 95.55338769695034, 536945.0968756989, 536945.0968756992, 208825.8264859401]
[2019-03-23 15:35:46,984] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:35:46,987] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.5418861e-02 4.7005013e-01 4.9409009e-05 5.3947693e-04 5.1394206e-01], sampled 0.2159622750883844
[2019-03-23 15:36:05,551] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06071934], dtype=float32), 0.3219843]
[2019-03-23 15:36:05,552] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.08333054666667, 90.88284089666666, 1.0, 2.0, 0.3293794507985566, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 360681.9979525185, 360681.9979525182, 118567.8042867774]
[2019-03-23 15:36:05,554] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:36:05,558] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.2361834e-02 4.4812694e-01 8.9429683e-05 8.2866492e-04 5.2859318e-01], sampled 0.613467431233553
[2019-03-23 15:36:20,563] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 4911.3532 1935583470.7913 1304.0000
[2019-03-23 15:36:20,969] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 5584.7151 1892513849.9759 1856.0000
[2019-03-23 15:36:21,024] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 4700.5884 1935189909.2659 1298.0000
[2019-03-23 15:36:21,122] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 5388.2076 1878268205.1409 1720.0000
[2019-03-23 15:36:21,149] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 5470.7939 1981438763.7770 1193.0000
[2019-03-23 15:36:22,166] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1825000, evaluation results [1825000.0, 5470.793874500419, 1981438763.7769916, 1193.0, 5388.207624037702, 1878268205.1408947, 1720.0, 4700.588383630071, 1935189909.2659016, 1298.0, 5584.715110477553, 1892513849.9758801, 1856.0, 4911.353240401777, 1935583470.7913296, 1304.0]
[2019-03-23 15:36:24,620] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.12347664e-07 9.99934554e-01 6.44157333e-16 4.65013705e-12
 6.53512980e-05], sum to 1.0000
[2019-03-23 15:36:24,627] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0781
[2019-03-23 15:36:24,632] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 73.83333333333333, 1.0, 2.0, 0.4243785082288179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482522.1380333376, 482522.1380333376, 129875.9130781598], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4902600.0000, 
sim time next is 4903200.0000, 
raw observation next is [23.0, 73.0, 1.0, 2.0, 0.4250963599607506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 483440.7220294932, 483440.7220294935, 130037.9016244518], 
processed observation next is [1.0, 0.782608695652174, 0.6818181818181818, 0.73, 1.0, 1.0, 0.28137044995093824, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17905211927018266, 0.17905211927018277, 0.31716561371817514], 
reward next is 0.6828, 
noisyNet noise sample is [array([0.03804616], dtype=float32), -2.0662885]. 
=============================================
[2019-03-23 15:36:39,312] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.1951938e-09 9.9999523e-01 3.6345433e-17 2.7419595e-13 4.7199433e-06], sum to 1.0000
[2019-03-23 15:36:39,317] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1653
[2019-03-23 15:36:39,324] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 78.0, 1.0, 2.0, 0.4993054600977946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 569531.4665262802, 569531.4665262805, 141815.3494741013], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5166000.0000, 
sim time next is 5166600.0000, 
raw observation next is [23.83333333333333, 78.0, 1.0, 2.0, 0.4912791992394012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560515.1873600933, 560515.1873600933, 140522.1648048894], 
processed observation next is [0.0, 0.8260869565217391, 0.7196969696969695, 0.78, 1.0, 1.0, 0.36409899904925147, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20759821754077531, 0.20759821754077531, 0.34273698732899854], 
reward next is 0.6573, 
noisyNet noise sample is [array([-2.3429863], dtype=float32), 0.28236896]. 
=============================================
[2019-03-23 15:36:48,095] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.8315005e-10 1.0000000e+00 3.2563645e-21 8.5839877e-15 1.5364579e-11], sum to 1.0000
[2019-03-23 15:36:48,100] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2452
[2019-03-23 15:36:48,108] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.71666666666667, 74.83333333333334, 1.0, 2.0, 0.4610610962403355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 525971.9838480285, 525971.9838480287, 135827.6107193257], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5357400.0000, 
sim time next is 5358000.0000, 
raw observation next is [23.63333333333334, 75.66666666666667, 1.0, 2.0, 0.4628868659906479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 528084.7556871596, 528084.7556871596, 136114.5039508115], 
processed observation next is [1.0, 0.0, 0.7106060606060609, 0.7566666666666667, 1.0, 1.0, 0.3286085824883098, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19558694655079986, 0.19558694655079986, 0.33198659500197925], 
reward next is 0.6680, 
noisyNet noise sample is [array([1.4248654], dtype=float32), -0.8011187]. 
=============================================
[2019-03-23 15:36:48,129] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[65.32584 ]
 [65.85119 ]
 [66.683975]
 [66.73402 ]
 [66.75515 ]], R is [[65.15169525]
 [65.16889191]
 [65.18693542]
 [65.20652008]
 [65.22768402]].
[2019-03-23 15:36:49,133] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.9758652e-12 1.0000000e+00 1.6654866e-21 1.0410386e-14 2.9307556e-11], sum to 1.0000
[2019-03-23 15:36:49,140] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8541
[2019-03-23 15:36:49,143] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 73.16666666666667, 1.0, 2.0, 0.4542541373852049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518036.5411738124, 518036.5411738124, 134704.3665189638], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5356200.0000, 
sim time next is 5356800.0000, 
raw observation next is [23.8, 74.0, 1.0, 2.0, 0.4584147193921645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522902.7746323407, 522902.7746323407, 135410.8662569273], 
processed observation next is [1.0, 0.0, 0.7181818181818183, 0.74, 1.0, 1.0, 0.3230183992402056, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19366769430827432, 0.19366769430827432, 0.3302704055047007], 
reward next is 0.6697, 
noisyNet noise sample is [array([-1.4034786], dtype=float32), -1.3250775]. 
=============================================
[2019-03-23 15:36:50,822] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.5793984e-10 1.0000000e+00 2.8676568e-19 3.1513637e-14 2.3970678e-12], sum to 1.0000
[2019-03-23 15:36:50,828] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9074
[2019-03-23 15:36:50,835] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 93.0, 1.0, 2.0, 0.4020107353878155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 454242.0378813867, 454242.0378813867, 125712.9460819937], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5423400.0000, 
sim time next is 5424000.0000, 
raw observation next is [19.4, 93.0, 1.0, 2.0, 0.4008838219828682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 452965.4090535752, 452965.4090535752, 125607.9082780731], 
processed observation next is [1.0, 0.782608695652174, 0.5181818181818181, 0.93, 1.0, 1.0, 0.25110477747858523, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16776496631613896, 0.16776496631613896, 0.30636075189773926], 
reward next is 0.6936, 
noisyNet noise sample is [array([1.4728109], dtype=float32), 0.5877537]. 
=============================================
[2019-03-23 15:36:50,852] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[57.396313]
 [57.42891 ]
 [57.664455]
 [57.397198]
 [57.33346 ]], R is [[57.80506516]
 [57.92039871]
 [58.03420639]
 [58.14662933]
 [58.25790405]].
[2019-03-23 15:36:51,086] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0618205e-10 1.0000000e+00 1.0816810e-18 4.1759082e-13 8.5653229e-12], sum to 1.0000
[2019-03-23 15:36:51,095] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5176
[2019-03-23 15:36:51,099] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.9, 90.5, 1.0, 2.0, 0.5743281911008, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 651009.7746375822, 651009.7746375825, 144689.7533210787], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5418600.0000, 
sim time next is 5419200.0000, 
raw observation next is [19.8, 91.0, 1.0, 2.0, 0.4115276655780587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 465876.6869733659, 465876.6869733659, 127125.0886097813], 
processed observation next is [1.0, 0.7391304347826086, 0.5363636363636364, 0.91, 1.0, 1.0, 0.26440958197257336, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17254692110124664, 0.17254692110124664, 0.3100611917311739], 
reward next is 0.6899, 
noisyNet noise sample is [array([-1.1860187], dtype=float32), -0.75191957]. 
=============================================
[2019-03-23 15:36:58,448] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.2874585e-09 1.0000000e+00 3.9306934e-16 1.4771021e-10 1.8126316e-08], sum to 1.0000
[2019-03-23 15:36:58,453] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2144
[2019-03-23 15:36:58,457] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1428649.24633681 W.
[2019-03-23 15:36:58,459] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.61666666666667, 56.0, 1.0, 2.0, 0.633283670398089, 1.0, 2.0, 0.633283670398089, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344353783, 1428649.24633681, 1428649.24633681, 270570.7510829865], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5579400.0000, 
sim time next is 5580000.0000, 
raw observation next is [28.8, 55.0, 1.0, 2.0, 0.6462531175361883, 1.0, 2.0, 0.6462531175361883, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354103, 1457960.672777497, 1457960.672777497, 274369.4886804956], 
processed observation next is [1.0, 0.6086956521739131, 0.9454545454545454, 0.55, 1.0, 1.0, 0.5578163969202353, 1.0, 1.0, 0.5578163969202353, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.508428812920654, 0.5399854343620359, 0.5399854343620359, 0.6691938748304771], 
reward next is 0.3308, 
noisyNet noise sample is [array([0.7330705], dtype=float32), -0.32565543]. 
=============================================
[2019-03-23 15:36:58,481] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[50.511806]
 [49.512573]
 [50.102573]
 [49.89363 ]
 [50.473568]], R is [[49.85216141]
 [49.69371414]
 [49.53567123]
 [49.29283524]
 [49.09155273]].
[2019-03-23 15:37:01,987] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.3841614e-12 1.0000000e+00 3.2616308e-24 8.9906883e-16 2.8818640e-15], sum to 1.0000
[2019-03-23 15:37:01,993] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6553
[2019-03-23 15:37:02,001] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 97.0, 1.0, 2.0, 0.3921399272784256, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 442490.9611027878, 442490.961102788, 124472.212070962], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5631000.0000, 
sim time next is 5631600.0000, 
raw observation next is [18.8, 97.0, 1.0, 2.0, 0.3902530965073587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 440350.7056432623, 440350.7056432626, 124297.0913699289], 
processed observation next is [0.0, 0.17391304347826086, 0.49090909090909096, 0.97, 1.0, 1.0, 0.23781637063419833, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.163092853941949, 0.1630928539419491, 0.3031636374876314], 
reward next is 0.6968, 
noisyNet noise sample is [array([1.361953], dtype=float32), 0.045549802]. 
=============================================
[2019-03-23 15:37:09,917] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 15:37:09,918] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:37:09,919] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:37:09,919] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:37:09,919] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:37:09,920] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:37:09,920] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:37:09,921] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:37:09,922] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:37:09,925] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:37:09,921] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:37:09,947] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run75
[2019-03-23 15:37:09,980] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run75
[2019-03-23 15:37:09,980] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run75
[2019-03-23 15:37:10,010] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run75
[2019-03-23 15:37:10,068] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run75
[2019-03-23 15:37:18,522] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05616476], dtype=float32), 0.32924202]
[2019-03-23 15:37:18,525] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.66666666666667, 94.0, 1.0, 2.0, 0.2734251764158167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 296890.5448853461, 296890.5448853464, 95360.93956748018]
[2019-03-23 15:37:18,527] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:37:18,529] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.0474541e-14 1.0000000e+00 8.3239025e-26 4.6993074e-18 2.7583501e-16], sampled 0.5013388113842525
[2019-03-23 15:37:19,130] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05616476], dtype=float32), 0.32924202]
[2019-03-23 15:37:19,131] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.18410893833333, 52.94512087333334, 1.0, 2.0, 0.4616177654358044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 524575.2088462615, 524575.2088462615, 137736.7578235455]
[2019-03-23 15:37:19,132] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:37:19,135] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.3016290e-14 1.0000000e+00 7.2165267e-26 4.5354623e-18 2.7095014e-16], sampled 0.13941678584567596
[2019-03-23 15:37:25,930] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05616476], dtype=float32), 0.32924202]
[2019-03-23 15:37:25,933] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.91779486, 100.0, 1.0, 2.0, 0.4049263717852317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 458850.8567456995, 458850.8567456992, 131135.8685245741]
[2019-03-23 15:37:25,934] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:37:25,937] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.9459562e-14 1.0000000e+00 2.5782608e-26 2.0565654e-18 1.3179993e-16], sampled 0.4998526471886462
[2019-03-23 15:37:43,504] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05616476], dtype=float32), 0.32924202]
[2019-03-23 15:37:43,504] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.65, 50.0, 1.0, 2.0, 0.4555114029482745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 519076.4067366584, 519076.406736658, 138586.9149775719]
[2019-03-23 15:37:43,505] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:37:43,507] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.1877572e-13 1.0000000e+00 1.2980647e-25 6.8670942e-18 3.9412787e-16], sampled 0.6736117543955659
[2019-03-23 15:37:49,985] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05616476], dtype=float32), 0.32924202]
[2019-03-23 15:37:49,986] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.172784985, 100.0, 1.0, 2.0, 0.8768335291441743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 103.6860763553979, 996379.3869020363, 996379.3869020366, 204950.908886284]
[2019-03-23 15:37:49,987] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:37:49,990] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.7336436e-14 1.0000000e+00 1.2294284e-25 6.0682859e-18 3.4911935e-16], sampled 0.5523411679270517
[2019-03-23 15:37:57,549] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05616476], dtype=float32), 0.32924202]
[2019-03-23 15:37:57,550] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.78333333333333, 85.66666666666667, 1.0, 2.0, 0.4971629565317022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 566758.6743432826, 566758.6743432826, 143387.5243116202]
[2019-03-23 15:37:57,550] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:37:57,556] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.4814392e-13 1.0000000e+00 2.6836185e-25 1.1080893e-17 6.0073715e-16], sampled 0.0840616713211283
[2019-03-23 15:38:20,335] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05616476], dtype=float32), 0.32924202]
[2019-03-23 15:38:20,336] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 94.0, 1.0, 2.0, 0.8076127051787395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354103, 921169.9455094717, 921169.9455094717, 185435.452770373]
[2019-03-23 15:38:20,339] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:38:20,341] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.2972975e-13 1.0000000e+00 1.0645835e-23 1.3374583e-16 5.6408235e-15], sampled 0.21815326844287397
[2019-03-23 15:38:28,008] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05616476], dtype=float32), 0.32924202]
[2019-03-23 15:38:28,012] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.2, 82.5, 1.0, 2.0, 0.3032737142136486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 72.46276211267944, 329319.1471886617, 329319.147188662, 76369.17988295808]
[2019-03-23 15:38:28,012] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:38:28,015] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.4318457e-12 1.0000000e+00 1.8270782e-23 2.2457670e-16 9.0949714e-15], sampled 0.2072555971542901
[2019-03-23 15:38:51,122] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05616476], dtype=float32), 0.32924202]
[2019-03-23 15:38:51,123] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.2, 49.0, 1.0, 2.0, 0.2828542469189017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 307113.5563449013, 307113.5563449006, 95271.26289916394]
[2019-03-23 15:38:51,125] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:38:51,129] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.44439477e-14 1.00000000e+00 1.60140382e-26 1.57667904e-18
 1.04488085e-16], sampled 0.5727146085401539
[2019-03-23 15:38:56,762] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 15:38:56,967] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 15:38:56,980] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05616476], dtype=float32), 0.32924202]
[2019-03-23 15:38:56,980] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.9, 67.5, 1.0, 2.0, 0.4229649538390489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 478239.335457508, 478239.3354575077, 132181.6675312636]
[2019-03-23 15:38:56,980] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:38:56,983] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.2286263e-14 1.0000000e+00 4.4855463e-26 3.1677853e-18 1.9334334e-16], sampled 0.40471128439576143
[2019-03-23 15:38:57,021] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 15:38:57,082] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 15:38:57,155] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 15:38:58,172] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1850000, evaluation results [1850000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 15:39:02,771] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.479665e-14 1.000000e+00 8.424432e-26 9.625705e-18 3.292509e-16], sum to 1.0000
[2019-03-23 15:39:02,780] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3404
[2019-03-23 15:39:02,783] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 82.5, 1.0, 2.0, 0.3087588959168041, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 335957.4329119865, 335957.4329119863, 112022.0065145998], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5880600.0000, 
sim time next is 5881200.0000, 
raw observation next is [17.9, 82.0, 1.0, 2.0, 0.3041012219265842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 330210.5192655005, 330210.5192655002, 111467.7311645482], 
processed observation next is [1.0, 0.043478260869565216, 0.44999999999999996, 0.82, 1.0, 1.0, 0.1301265274082302, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12230019232055574, 0.12230019232055563, 0.27187251503548343], 
reward next is 0.7281, 
noisyNet noise sample is [array([0.3500854], dtype=float32), -0.5765047]. 
=============================================
[2019-03-23 15:39:03,626] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.4594266e-13 1.0000000e+00 2.6818391e-24 8.7681831e-18 2.1293687e-14], sum to 1.0000
[2019-03-23 15:39:03,633] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9776
[2019-03-23 15:39:03,639] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.46666666666667, 86.0, 1.0, 2.0, 0.2722627157717675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 295627.938148035, 295627.938148035, 94429.1354195259], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5890800.0000, 
sim time next is 5891400.0000, 
raw observation next is [16.65, 84.0, 1.0, 2.0, 0.2680755004307636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 291080.0209821147, 291080.0209821144, 93363.86196085908], 
processed observation next is [1.0, 0.17391304347826086, 0.39318181818181813, 0.84, 1.0, 1.0, 0.0850943755384545, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.107807415178561, 0.10780741517856089, 0.2277167364899002], 
reward next is 0.7723, 
noisyNet noise sample is [array([0.292979], dtype=float32), 0.247777]. 
=============================================
[2019-03-23 15:39:05,000] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.8793194e-14 1.0000000e+00 3.3532326e-26 2.2371813e-17 3.3935793e-16], sum to 1.0000
[2019-03-23 15:39:05,010] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5828
[2019-03-23 15:39:05,015] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.86666666666667, 74.66666666666667, 1.0, 2.0, 0.3623670596627815, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 405554.8100595456, 405554.8100595456, 120156.9756900971], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5964000.0000, 
sim time next is 5964600.0000, 
raw observation next is [20.68333333333334, 76.33333333333333, 1.0, 2.0, 0.3634879502381314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 407050.6037130427, 407050.6037130427, 120361.6338385402], 
processed observation next is [1.0, 0.0, 0.5765151515151519, 0.7633333333333333, 1.0, 1.0, 0.20435993779766423, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15075948285668248, 0.15075948285668248, 0.29356496058180537], 
reward next is 0.7064, 
noisyNet noise sample is [array([0.06378397], dtype=float32), 1.169478]. 
=============================================
[2019-03-23 15:39:06,449] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6757234e-11 1.0000000e+00 5.8115480e-20 8.2811294e-15 1.5551734e-12], sum to 1.0000
[2019-03-23 15:39:06,451] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1539
[2019-03-23 15:39:06,457] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.88333333333334, 70.16666666666667, 1.0, 2.0, 0.8066620956301606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 908669.5095606619, 908669.5095606619, 172111.9295485898], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5994600.0000, 
sim time next is 5995200.0000, 
raw observation next is [22.16666666666667, 69.33333333333334, 1.0, 2.0, 0.8210308949896408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 926386.3388723459, 926386.3388723456, 174983.2539286408], 
processed observation next is [1.0, 0.391304347826087, 0.6439393939393941, 0.6933333333333335, 1.0, 1.0, 0.776288618737051, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3431060514342022, 0.3431060514342021, 0.42678842421619706], 
reward next is 0.5732, 
noisyNet noise sample is [array([-1.8400364], dtype=float32), -0.7709835]. 
=============================================
[2019-03-23 15:39:06,655] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.5509649e-11 1.0000000e+00 4.1061871e-22 3.4027717e-15 1.3620066e-13], sum to 1.0000
[2019-03-23 15:39:06,661] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9839
[2019-03-23 15:39:06,664] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.36666666666667, 67.33333333333333, 1.0, 2.0, 0.3797133451596539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 427045.0660358286, 427045.0660358286, 122605.7993183209], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5956800.0000, 
sim time next is 5957400.0000, 
raw observation next is [22.28333333333333, 67.66666666666667, 1.0, 2.0, 0.377997542754421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 424977.6338917382, 424977.6338917382, 122387.42099642], 
processed observation next is [1.0, 0.9565217391304348, 0.6492424242424242, 0.6766666666666667, 1.0, 1.0, 0.2224969284430262, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15739912366360673, 0.15739912366360673, 0.29850590486931705], 
reward next is 0.7015, 
noisyNet noise sample is [array([0.5446964], dtype=float32), -0.39957678]. 
=============================================
[2019-03-23 15:39:08,310] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.2345313e-13 1.0000000e+00 5.0807041e-23 8.3610794e-17 1.1212540e-13], sum to 1.0000
[2019-03-23 15:39:08,315] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6649
[2019-03-23 15:39:08,320] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.9, 86.0, 1.0, 2.0, 0.3596648097439566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 400047.4688087259, 400047.4688087259, 118845.3233514278], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5971800.0000, 
sim time next is 5972400.0000, 
raw observation next is [18.8, 87.0, 1.0, 2.0, 0.3623252315029062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 403125.8987719535, 403125.8987719535, 119108.6854888294], 
processed observation next is [1.0, 0.13043478260869565, 0.49090909090909096, 0.87, 1.0, 1.0, 0.2029065393786327, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14930588843405684, 0.14930588843405684, 0.2905089889971449], 
reward next is 0.7095, 
noisyNet noise sample is [array([1.0695094], dtype=float32), 0.48283452]. 
=============================================
[2019-03-23 15:39:08,804] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.8378090e-12 1.0000000e+00 4.6866946e-22 2.3563389e-15 1.8536206e-13], sum to 1.0000
[2019-03-23 15:39:08,808] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6458
[2019-03-23 15:39:08,812] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.45, 67.0, 1.0, 2.0, 0.3823334690987885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 430128.3348658252, 430128.3348658252, 122902.8666439461], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5956200.0000, 
sim time next is 5956800.0000, 
raw observation next is [22.36666666666667, 67.33333333333333, 1.0, 2.0, 0.3797133451596539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 427045.0660358286, 427045.0660358286, 122605.7993183209], 
processed observation next is [1.0, 0.9565217391304348, 0.6530303030303032, 0.6733333333333333, 1.0, 1.0, 0.22464168144956734, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1581648392725291, 0.1581648392725291, 0.2990385349227339], 
reward next is 0.7010, 
noisyNet noise sample is [array([-0.05643288], dtype=float32), -0.36537424]. 
=============================================
[2019-03-23 15:39:09,803] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.4037590e-12 1.0000000e+00 3.0370244e-22 2.2309624e-15 1.8932659e-12], sum to 1.0000
[2019-03-23 15:39:09,817] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2821
[2019-03-23 15:39:09,818] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1165719.773210011 W.
[2019-03-23 15:39:09,824] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.35, 55.0, 1.0, 2.0, 0.9964960894708761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.002162354637602, 6.9112, 77.32828295426684, 1165719.773210011, 1136177.129880079, 211809.8106033439], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6003000.0000, 
sim time next is 6003600.0000, 
raw observation next is [26.43333333333334, 54.66666666666667, 1.0, 2.0, 0.3358564905549975, 1.0, 1.0, 0.3358564905549975, 1.0, 1.0, 0.6781607655097491, 6.9112, 6.9112, 77.3421103, 1150289.474616917, 1150289.474616917, 267166.6383836674], 
processed observation next is [1.0, 0.4782608695652174, 0.8378787878787882, 0.5466666666666667, 1.0, 1.0, 0.16982061319374686, 1.0, 0.5, 0.16982061319374686, 1.0, 0.5, 0.5402296650139273, 0.0, 0.0, 0.5085185399722538, 0.4260331387470063, 0.4260331387470063, 0.6516259472772375], 
reward next is 0.3484, 
noisyNet noise sample is [array([0.02376455], dtype=float32), -1.209743]. 
=============================================
[2019-03-23 15:39:11,728] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.4120683e-13 1.0000000e+00 7.7176442e-25 2.9036220e-17 3.9652890e-15], sum to 1.0000
[2019-03-23 15:39:11,731] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3419
[2019-03-23 15:39:11,736] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.9, 80.5, 1.0, 2.0, 0.2683883528177039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 291419.8221314339, 291419.8221314336, 91676.42151350972], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6049800.0000, 
sim time next is 6050400.0000, 
raw observation next is [16.8, 80.66666666666667, 1.0, 2.0, 0.2660170825341912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 288844.2991395907, 288844.2991395904, 90645.80184322884], 
processed observation next is [1.0, 0.0, 0.4, 0.8066666666666668, 1.0, 1.0, 0.082521353167739, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10697937005170026, 0.10697937005170015, 0.22108732156885083], 
reward next is 0.7789, 
noisyNet noise sample is [array([-0.7194215], dtype=float32), -1.6063817]. 
=============================================
[2019-03-23 15:39:12,747] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.6733557e-11 1.0000000e+00 4.2347079e-21 1.4310412e-15 2.5183696e-13], sum to 1.0000
[2019-03-23 15:39:12,761] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9571
[2019-03-23 15:39:12,765] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 80.0, 1.0, 2.0, 0.2748472348612717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 298435.1182567113, 298435.118256711, 94964.16681037647], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6048000.0000, 
sim time next is 6048600.0000, 
raw observation next is [17.1, 80.16666666666667, 1.0, 2.0, 0.2730965157344402, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 296533.5697231401, 296533.5697231398, 93868.29329156093], 
processed observation next is [1.0, 0.0, 0.4136363636363637, 0.8016666666666667, 1.0, 1.0, 0.09137064466805025, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10982724804560745, 0.10982724804560734, 0.22894705680868518], 
reward next is 0.7711, 
noisyNet noise sample is [array([0.0284042], dtype=float32), -0.76578707]. 
=============================================
[2019-03-23 15:39:13,126] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.1210592e-13 1.0000000e+00 4.7149355e-23 1.2204436e-16 2.3949162e-15], sum to 1.0000
[2019-03-23 15:39:13,135] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5462
[2019-03-23 15:39:13,140] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.4, 83.0, 1.0, 2.0, 0.2025419094327117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 219906.6709796646, 219906.6709796643, 73033.27918472176], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6068400.0000, 
sim time next is 6069000.0000, 
raw observation next is [14.4, 83.0, 1.0, 2.0, 0.2018805477832065, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 219188.4462517985, 219188.4462517988, 72964.42160537581], 
processed observation next is [1.0, 0.21739130434782608, 0.29090909090909095, 0.83, 1.0, 1.0, 0.0023506847290081026, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08118090601918464, 0.08118090601918473, 0.17796200391555075], 
reward next is 0.8220, 
noisyNet noise sample is [array([-1.7708913], dtype=float32), 1.0909657]. 
=============================================
[2019-03-23 15:39:13,165] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[70.10662 ]
 [70.223595]
 [70.31388 ]
 [70.42571 ]
 [70.55368 ]], R is [[70.13228607]
 [70.25283051]
 [70.37194824]
 [70.48949432]
 [70.60475159]].
[2019-03-23 15:39:14,320] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.9996125e-13 1.0000000e+00 1.8101914e-24 6.5566777e-18 3.3822210e-15], sum to 1.0000
[2019-03-23 15:39:14,326] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1763
[2019-03-23 15:39:14,333] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.91666666666667, 55.5, 1.0, 2.0, 0.5271158934589044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 572515.2029371652, 572515.2029371648, 124113.1219107649], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6090600.0000, 
sim time next is 6091200.0000, 
raw observation next is [21.1, 55.0, 1.0, 2.0, 0.4977544149131917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 540607.1519146184, 540607.1519146188, 122045.1718060002], 
processed observation next is [1.0, 0.5217391304347826, 0.5954545454545456, 0.55, 1.0, 1.0, 0.3721930186414896, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2002248710794883, 0.20022487107948844, 0.297671150746342], 
reward next is 0.7023, 
noisyNet noise sample is [array([-1.1834124], dtype=float32), -0.06921271]. 
=============================================
[2019-03-23 15:39:20,823] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.9032112e-14 1.0000000e+00 5.0683874e-25 2.8309333e-17 2.9189142e-17], sum to 1.0000
[2019-03-23 15:39:20,829] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4203
[2019-03-23 15:39:20,834] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.08333333333334, 80.16666666666666, 1.0, 2.0, 0.3656271909393284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 409072.3771126928, 409072.3771126931, 120366.3853666437], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6213000.0000, 
sim time next is 6213600.0000, 
raw observation next is [20.0, 81.0, 1.0, 2.0, 0.3684006970480711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 412313.3411917799, 412313.3411917799, 120659.7958539372], 
processed observation next is [1.0, 0.9565217391304348, 0.5454545454545454, 0.81, 1.0, 1.0, 0.21050087131008885, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1527086448858444, 0.1527086448858444, 0.2942921850096029], 
reward next is 0.7057, 
noisyNet noise sample is [array([-0.4787049], dtype=float32), -3.4235058]. 
=============================================
[2019-03-23 15:39:25,561] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.1426064e-13 1.0000000e+00 1.0554410e-23 1.2354800e-16 6.1439528e-14], sum to 1.0000
[2019-03-23 15:39:25,568] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7853
[2019-03-23 15:39:25,573] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 59.0, 1.0, 2.0, 0.5271187211059866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 599308.8364742039, 599308.8364742039, 146928.7751619645], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6289200.0000, 
sim time next is 6289800.0000, 
raw observation next is [28.11666666666667, 59.5, 1.0, 2.0, 0.5262799226725623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 598523.477499717, 598523.4774997167, 146726.761548842], 
processed observation next is [0.0, 0.8260869565217391, 0.9143939393939395, 0.595, 1.0, 1.0, 0.4078499033407028, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22167536203693222, 0.2216753620369321, 0.3578701501191269], 
reward next is 0.6421, 
noisyNet noise sample is [array([-0.6687868], dtype=float32), 1.731498]. 
=============================================
[2019-03-23 15:39:28,711] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.5074578e-12 1.0000000e+00 9.3764202e-21 3.3981797e-15 1.0969338e-13], sum to 1.0000
[2019-03-23 15:39:28,719] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9801
[2019-03-23 15:39:28,729] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.78333333333333, 77.33333333333334, 1.0, 2.0, 0.5693124610246515, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 644481.2851287612, 644481.2851287612, 153494.4402720658], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6378600.0000, 
sim time next is 6379200.0000, 
raw observation next is [25.5, 79.0, 1.0, 2.0, 0.5680139854327776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 643140.6616727517, 643140.6616727517, 153279.1389862543], 
processed observation next is [0.0, 0.8695652173913043, 0.7954545454545454, 0.79, 1.0, 1.0, 0.46001748179097196, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2382002450639821, 0.2382002450639821, 0.37385155850305923], 
reward next is 0.6261, 
noisyNet noise sample is [array([-0.42049497], dtype=float32), -0.37682873]. 
=============================================
[2019-03-23 15:39:33,250] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5568673e-13 1.0000000e+00 1.7109162e-23 1.1123844e-16 1.4874778e-14], sum to 1.0000
[2019-03-23 15:39:33,256] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3605
[2019-03-23 15:39:33,259] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 93.0, 1.0, 2.0, 0.6495083322504661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 721513.1577291093, 721513.1577291093, 146925.5657910567], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6444000.0000, 
sim time next is 6444600.0000, 
raw observation next is [17.8, 92.5, 1.0, 2.0, 0.7128423349808054, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 791521.0735766836, 791521.0735766839, 154353.9156968214], 
processed observation next is [1.0, 0.6086956521739131, 0.4454545454545455, 0.925, 1.0, 1.0, 0.6410529187260067, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2931559531765495, 0.2931559531765496, 0.37647296511419853], 
reward next is 0.6235, 
noisyNet noise sample is [array([-1.2354364], dtype=float32), -0.70271724]. 
=============================================
[2019-03-23 15:39:36,115] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.3982622e-15 1.0000000e+00 7.7311912e-27 1.4699445e-20 4.2317452e-17], sum to 1.0000
[2019-03-23 15:39:36,120] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5090
[2019-03-23 15:39:36,125] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.13333333333333, 50.66666666666667, 1.0, 2.0, 0.3584756192848139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 389276.9864472219, 389276.9864472222, 94203.81656419524], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6525600.0000, 
sim time next is 6526200.0000, 
raw observation next is [20.31666666666667, 49.83333333333334, 1.0, 2.0, 0.3697447049840054, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 401519.4005609863, 401519.4005609865, 95596.18491284885], 
processed observation next is [1.0, 0.5217391304347826, 0.559848484848485, 0.4983333333333334, 1.0, 1.0, 0.21218088123000675, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1487108890966616, 0.14871088909666166, 0.23316142661670453], 
reward next is 0.7668, 
noisyNet noise sample is [array([0.20403083], dtype=float32), -1.0583467]. 
=============================================
[2019-03-23 15:39:38,403] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.8283951e-09 1.0000000e+00 3.9547389e-18 6.0665917e-12 4.0317995e-11], sum to 1.0000
[2019-03-23 15:39:38,413] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0079
[2019-03-23 15:39:38,421] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.46666666666667, 91.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 213229.7428170878, 213229.7428170875, 69955.14635742223], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6578400.0000, 
sim time next is 6579000.0000, 
raw observation next is [12.25, 93.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 212931.5424045164, 212931.5424045164, 69719.75198297734], 
processed observation next is [1.0, 0.13043478260869565, 0.19318181818181818, 0.93, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07886353422389496, 0.07886353422389496, 0.1700481755682374], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3366138], dtype=float32), 0.9510052]. 
=============================================
[2019-03-23 15:39:38,439] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[53.593323]
 [52.96106 ]
 [52.8925  ]
 [52.61528 ]
 [53.29982 ]], R is [[52.94758987]
 [52.41811371]
 [52.72132111]
 [52.19410706]
 [51.67216492]].
[2019-03-23 15:39:41,923] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.8103662e-10 1.0000000e+00 9.9423862e-21 7.9048630e-15 2.3003665e-12], sum to 1.0000
[2019-03-23 15:39:41,931] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5807
[2019-03-23 15:39:41,934] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 66.0, 1.0, 2.0, 0.7734218524552373, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 868862.4218855026, 868862.4218855026, 166278.4429413839], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6625800.0000, 
sim time next is 6626400.0000, 
raw observation next is [22.2, 66.0, 1.0, 2.0, 0.7894240661689729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 886903.5721799568, 886903.5721799568, 168515.6236227381], 
processed observation next is [1.0, 0.6956521739130435, 0.6454545454545454, 0.66, 1.0, 1.0, 0.7367800827112161, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.32848280451109513, 0.32848280451109513, 0.41101371615301974], 
reward next is 0.5890, 
noisyNet noise sample is [array([1.7644218], dtype=float32), -0.7165124]. 
=============================================
[2019-03-23 15:39:43,295] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.3410916e-10 1.0000000e+00 6.7836595e-22 3.1608718e-16 1.6966628e-12], sum to 1.0000
[2019-03-23 15:39:43,302] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5843
[2019-03-23 15:39:43,306] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.5664040618459283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 633144.556611079, 633144.556611079, 139317.4142005707], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6702600.0000, 
sim time next is 6703200.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.588407992488113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 657791.8063237346, 657791.8063237349, 141743.084320453], 
processed observation next is [1.0, 0.6086956521739131, 0.4681818181818182, 0.93, 1.0, 1.0, 0.4855099906101413, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2436265949347165, 0.24362659493471664, 0.34571483980598294], 
reward next is 0.6543, 
noisyNet noise sample is [array([-1.118255], dtype=float32), 1.0687394]. 
=============================================
[2019-03-23 15:39:46,036] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 15:39:46,037] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:39:46,037] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:39:46,038] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:39:46,040] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:39:46,041] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:39:46,041] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:39:46,042] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:39:46,042] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:39:46,042] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:39:46,043] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:39:46,066] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run76
[2019-03-23 15:39:46,099] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run76
[2019-03-23 15:39:46,100] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run76
[2019-03-23 15:39:46,157] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run76
[2019-03-23 15:39:46,192] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run76
[2019-03-23 15:39:47,953] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05616431], dtype=float32), 0.33430043]
[2019-03-23 15:39:47,954] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [14.63333333333333, 57.33333333333334, 1.0, 2.0, 0.386070496086945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 419221.351288302, 419221.3512883016, 90190.62278056981]
[2019-03-23 15:39:47,955] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:39:47,958] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.7249465e-08 1.0000000e+00 3.1001085e-19 1.1602915e-13 2.4175197e-11], sampled 0.5626211891323414
[2019-03-23 15:39:53,281] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05616431], dtype=float32), 0.33430043]
[2019-03-23 15:39:53,283] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.725428285, 83.47636995833334, 1.0, 2.0, 0.2300873406594226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 249809.1313812401, 249809.1313812394, 81573.82215865156]
[2019-03-23 15:39:53,284] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:39:53,291] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0292504e-09 1.0000000e+00 2.3309683e-21 2.7769541e-15 1.0230210e-12], sampled 0.9703659487666558
[2019-03-23 15:40:05,321] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05616431], dtype=float32), 0.33430043]
[2019-03-23 15:40:05,322] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.26385577333333, 100.0, 1.0, 2.0, 0.5031446041794155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 573816.0158119414, 573816.0158119414, 146634.1485409313]
[2019-03-23 15:40:05,323] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:40:05,326] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.6950470e-10 1.0000000e+00 1.8331879e-22 4.4460976e-16 2.2353134e-13], sampled 0.9776927826684716
[2019-03-23 15:40:20,286] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05616431], dtype=float32), 0.33430043]
[2019-03-23 15:40:20,289] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.0, 100.0, 1.0, 2.0, 0.2305882589000048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 250365.3879533222, 250365.3879533225, 76651.73877833421]
[2019-03-23 15:40:20,290] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:40:20,293] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.7649936e-07 9.9999940e-01 8.5701950e-18 1.3949040e-12 1.9972982e-10], sampled 0.03376412914037885
[2019-03-23 15:40:41,547] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05616431], dtype=float32), 0.33430043]
[2019-03-23 15:40:41,548] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [29.03333333333333, 52.33333333333333, 1.0, 2.0, 0.996885542773242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.158614465556218, 6.9112, 95.5527078681294, 1235302.964833221, 1136010.251804722, 224673.3608099023]
[2019-03-23 15:40:41,550] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:40:41,554] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.94315508e-10 1.00000000e+00 1.05131064e-22 2.98590258e-16
 1.60654489e-13], sampled 0.20852776154389774
[2019-03-23 15:40:41,556] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1235302.964833221 W.
[2019-03-23 15:41:14,411] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05616431], dtype=float32), 0.33430043]
[2019-03-23 15:41:14,412] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.46466728, 52.39380458333333, 1.0, 2.0, 0.2701435720571186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 293309.3687451446, 293309.3687451449, 84568.86298900924]
[2019-03-23 15:41:14,412] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:41:14,414] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.8711058e-10 1.0000000e+00 5.7019199e-22 1.0374701e-15 4.5305282e-13], sampled 0.9812423585367003
[2019-03-23 15:41:33,160] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8600.3031 1705904541.7703 465.0000
[2019-03-23 15:41:33,230] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8858.2439 1663722118.4404 105.0000
[2019-03-23 15:41:33,250] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9063.6594 1656156420.2851 80.0000
[2019-03-23 15:41:33,324] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8517.2994 1773086655.6926 173.0000
[2019-03-23 15:41:33,395] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8576.9161 1683245026.5224 214.0000
[2019-03-23 15:41:34,410] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1875000, evaluation results [1875000.0, 8517.29939762047, 1773086655.692615, 173.0, 9063.659437284377, 1656156420.2851133, 80.0, 8858.243935128237, 1663722118.440433, 105.0, 8600.303089052964, 1705904541.7702854, 465.0, 8576.916145865529, 1683245026.5224423, 214.0]
[2019-03-23 15:41:40,082] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.8858992e-09 1.0000000e+00 5.5506367e-23 6.3964209e-17 1.7610361e-12], sum to 1.0000
[2019-03-23 15:41:40,090] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4318
[2019-03-23 15:41:40,096] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.26666666666667, 75.33333333333334, 1.0, 2.0, 0.3856502247825531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 434209.9446052766, 434209.9446052763, 123373.477355076], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6824400.0000, 
sim time next is 6825000.0000, 
raw observation next is [21.18333333333334, 75.16666666666666, 1.0, 2.0, 0.3825667395971869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 430270.9172479619, 430270.9172479616, 122861.7447723635], 
processed observation next is [1.0, 1.0, 0.5992424242424246, 0.7516666666666666, 1.0, 1.0, 0.2282084244964836, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15935959898072663, 0.15935959898072652, 0.29966279212771585], 
reward next is 0.7003, 
noisyNet noise sample is [array([-2.4231193], dtype=float32), 1.640008]. 
=============================================
[2019-03-23 15:41:40,122] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[71.278656]
 [71.273544]
 [71.25282 ]
 [71.24536 ]
 [71.236946]], R is [[71.2747345 ]
 [71.26107788]
 [71.24622345]
 [71.23007202]
 [71.21264648]].
[2019-03-23 15:41:41,390] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.1260740e-08 1.0000000e+00 1.0337313e-18 6.2973986e-13 1.6078449e-09], sum to 1.0000
[2019-03-23 15:41:41,398] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3874
[2019-03-23 15:41:41,403] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.26666666666667, 90.16666666666666, 1.0, 2.0, 0.3839326271964281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 431948.1401891761, 431948.1401891761, 123052.6574553733], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6915000.0000, 
sim time next is 6915600.0000, 
raw observation next is [18.8, 93.0, 1.0, 2.0, 0.3808597878185616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 427870.1591296836, 427870.1591296839, 122471.7808062917], 
processed observation next is [0.0, 0.043478260869565216, 0.49090909090909096, 0.93, 1.0, 1.0, 0.226074734773202, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15847042930729024, 0.15847042930729033, 0.2987116605031505], 
reward next is 0.7013, 
noisyNet noise sample is [array([0.06408411], dtype=float32), 2.0846846]. 
=============================================
[2019-03-23 15:41:46,784] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.8134581e-11 1.0000000e+00 1.2082615e-22 1.7954952e-16 1.2150552e-12], sum to 1.0000
[2019-03-23 15:41:46,796] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0133
[2019-03-23 15:41:46,803] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.38333333333333, 89.5, 1.0, 2.0, 0.3476153779725142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 386112.6780707614, 386112.6780707617, 117666.3810964994], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6933000.0000, 
sim time next is 6933600.0000, 
raw observation next is [18.3, 90.0, 1.0, 2.0, 0.347171654251284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 385474.2293832683, 385474.229383268, 117571.6329238588], 
processed observation next is [0.0, 0.2608695652173913, 0.4681818181818182, 0.9, 1.0, 1.0, 0.18396456781410497, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14276823310491418, 0.14276823310491407, 0.2867600803020946], 
reward next is 0.7132, 
noisyNet noise sample is [array([0.1479594], dtype=float32), 0.5239991]. 
=============================================
[2019-03-23 15:41:47,275] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.6219324e-09 1.0000000e+00 1.0408687e-20 1.3680704e-13 7.2249318e-10], sum to 1.0000
[2019-03-23 15:41:47,287] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6087
[2019-03-23 15:41:47,295] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.13333333333333, 96.66666666666667, 1.0, 2.0, 0.4949376889714114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 563780.6078286021, 563780.6078286018, 138157.9651305439], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7010400.0000, 
sim time next is 7011000.0000, 
raw observation next is [19.95, 96.5, 1.0, 2.0, 0.464215126152724, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 528285.532033658, 528285.5320336582, 134325.9432580135], 
processed observation next is [1.0, 0.13043478260869565, 0.5431818181818181, 0.965, 1.0, 1.0, 0.33026890769090494, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19566130816061408, 0.19566130816061417, 0.3276242518488134], 
reward next is 0.6724, 
noisyNet noise sample is [array([-0.08350055], dtype=float32), -0.91168404]. 
=============================================
[2019-03-23 15:41:47,306] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[65.27253]
 [64.9573 ]
 [64.82199]
 [64.52634]
 [64.62757]], R is [[65.38320923]
 [65.39241028]
 [65.38644409]
 [65.39205933]
 [65.40033722]].
[2019-03-23 15:41:51,151] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.7803095e-10 1.0000000e+00 6.5837140e-20 7.9370740e-15 1.4206676e-09], sum to 1.0000
[2019-03-23 15:41:51,156] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5513
[2019-03-23 15:41:51,161] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 76.0, 1.0, 2.0, 0.7086916550124525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 805507.714498811, 805507.714498811, 163118.4114025596], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7052400.0000, 
sim time next is 7053000.0000, 
raw observation next is [22.2, 76.5, 1.0, 2.0, 0.7687209031150306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 873949.4792933979, 873949.4792933981, 171752.1616715092], 
processed observation next is [1.0, 0.6521739130434783, 0.6454545454545454, 0.765, 1.0, 1.0, 0.7109011288937883, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3236849923308881, 0.3236849923308882, 0.4189077113939249], 
reward next is 0.5811, 
noisyNet noise sample is [array([-0.16390441], dtype=float32), 0.14623515]. 
=============================================
[2019-03-23 15:41:51,191] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[61.969536]
 [61.576   ]
 [61.47886 ]
 [61.427822]
 [61.634663]], R is [[61.83163834]
 [61.81547165]
 [61.76203918]
 [61.69586563]
 [61.61418152]].
[2019-03-23 15:41:56,643] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5507348e-07 9.9999940e-01 1.3490694e-15 2.4431789e-12 5.2447484e-07], sum to 1.0000
[2019-03-23 15:41:56,658] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6211
[2019-03-23 15:41:56,663] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.2, 89.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 198965.7004254084, 198965.7004254087, 66788.58316135872], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7190400.0000, 
sim time next is 7191000.0000, 
raw observation next is [12.2, 89.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 196085.2716404065, 196085.2716404062, 66283.59816943774], 
processed observation next is [1.0, 0.21739130434782608, 0.1909090909090909, 0.89, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07262417468163204, 0.07262417468163192, 0.16166731260838474], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.05918395], dtype=float32), -0.20482531]. 
=============================================
[2019-03-23 15:41:56,679] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[57.282467]
 [57.36474 ]
 [57.391426]
 [57.40293 ]
 [57.46778 ]], R is [[56.70000076]
 [56.13299942]
 [55.57167053]
 [55.01595306]
 [54.46579361]].
[2019-03-23 15:42:00,159] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.5886205e-07 9.9999988e-01 7.0234137e-22 3.3563752e-14 2.8745697e-10], sum to 1.0000
[2019-03-23 15:42:00,164] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6928
[2019-03-23 15:42:00,167] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 46.0, 1.0, 2.0, 0.3238283348723071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 351639.0928795944, 351639.0928795941, 112629.0480092889], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7236000.0000, 
sim time next is 7236600.0000, 
raw observation next is [23.01666666666667, 47.5, 1.0, 2.0, 0.3227348043717687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 350451.2208084617, 350451.2208084614, 112741.8211606803], 
processed observation next is [1.0, 0.782608695652174, 0.6825757575757577, 0.475, 1.0, 1.0, 0.15341850546471086, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1297967484475784, 0.1297967484475783, 0.27498005161141537], 
reward next is 0.7250, 
noisyNet noise sample is [array([1.2147954], dtype=float32), -1.271888]. 
=============================================
[2019-03-23 15:42:07,147] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.8849986e-08 9.9999988e-01 1.4695070e-20 4.1901928e-15 3.7749343e-10], sum to 1.0000
[2019-03-23 15:42:07,153] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6314
[2019-03-23 15:42:07,156] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.4, 83.0, 1.0, 2.0, 0.3289440033748863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 360843.0956374518, 360843.0956374521, 114454.8269818503], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7350000.0000, 
sim time next is 7350600.0000, 
raw observation next is [18.3, 83.5, 1.0, 2.0, 0.3270519445584236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 358512.8753445192, 358512.8753445194, 114224.7501328862], 
processed observation next is [1.0, 0.043478260869565216, 0.4681818181818182, 0.835, 1.0, 1.0, 0.15881493069802952, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.132782546423896, 0.13278254642389606, 0.27859695154362485], 
reward next is 0.7214, 
noisyNet noise sample is [array([-0.47164053], dtype=float32), -0.3511156]. 
=============================================
[2019-03-23 15:42:08,402] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.6985216e-07 9.9999821e-01 1.4059907e-15 4.6913788e-12 9.1125128e-07], sum to 1.0000
[2019-03-23 15:42:08,412] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9642
[2019-03-23 15:42:08,422] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1106993.931919557 W.
[2019-03-23 15:42:08,428] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.9, 53.0, 1.0, 2.0, 0.4898149705933356, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9455107736988219, 6.956403840159918, 6.9112, 77.32835255099572, 1106993.931919557, 1092312.670267668, 253429.4960606113], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7388400.0000, 
sim time next is 7389000.0000, 
raw observation next is [28.0, 53.0, 1.0, 2.0, 0.4219193184840769, 1.0, 1.0, 0.4219193184840769, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32843628017004, 961433.4220749671, 961433.4220749671, 212015.4011035268], 
processed observation next is [1.0, 0.5217391304347826, 0.9090909090909091, 0.53, 1.0, 1.0, 0.2773991481050961, 1.0, 0.5, 0.2773991481050961, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084286343235391, 0.35608645262035815, 0.35608645262035815, 0.5171107343988458], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1914213], dtype=float32), 0.4231924]. 
=============================================
[2019-03-23 15:42:08,440] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[58.282326]
 [57.744   ]
 [57.536728]
 [57.61394 ]
 [57.74417 ]], R is [[57.93371582]
 [57.51023865]
 [57.30558395]
 [57.13001251]
 [56.87175751]].
[2019-03-23 15:42:09,489] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.5700261e-08 1.0000000e+00 2.1210962e-17 9.4273290e-14 3.4620224e-09], sum to 1.0000
[2019-03-23 15:42:09,495] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4768
[2019-03-23 15:42:09,499] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.61666666666667, 91.16666666666666, 1.0, 2.0, 0.3697969050487659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 413300.8027555678, 413300.8027555681, 120515.3480078931], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7427400.0000, 
sim time next is 7428000.0000, 
raw observation next is [18.43333333333333, 92.33333333333334, 1.0, 2.0, 0.3687074003136087, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 411824.6662205631, 411824.6662205628, 120309.9391517507], 
processed observation next is [1.0, 1.0, 0.4742424242424241, 0.9233333333333335, 1.0, 1.0, 0.21088425039201086, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1525276541557641, 0.152527654155764, 0.2934388759798798], 
reward next is 0.7066, 
noisyNet noise sample is [array([-1.5927455], dtype=float32), 0.019307997]. 
=============================================
[2019-03-23 15:42:09,526] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[54.904007]
 [54.900772]
 [54.879726]
 [54.834152]
 [54.787407]], R is [[55.05147171]
 [55.20701599]
 [55.36045456]
 [55.51187515]
 [55.66128922]].
[2019-03-23 15:42:10,260] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.7885282e-09 1.0000000e+00 1.4478233e-20 1.7442631e-14 7.0803796e-10], sum to 1.0000
[2019-03-23 15:42:10,264] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6095
[2019-03-23 15:42:10,270] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666667, 68.0, 1.0, 2.0, 0.4791110972736695, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 546665.5590504933, 546665.5590504933, 138972.9242067425], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7406400.0000, 
sim time next is 7407000.0000, 
raw observation next is [24.15, 72.0, 1.0, 2.0, 0.4443709645400798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 506986.7406969809, 506986.7406969809, 134269.7506132828], 
processed observation next is [1.0, 0.7391304347826086, 0.734090909090909, 0.72, 1.0, 1.0, 0.30546370567509973, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18777286692480774, 0.18777286692480774, 0.32748719661776293], 
reward next is 0.6725, 
noisyNet noise sample is [array([0.87052184], dtype=float32), -0.95973307]. 
=============================================
[2019-03-23 15:42:10,289] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[66.95395 ]
 [64.605865]
 [62.4795  ]
 [62.82432 ]
 [61.646446]], R is [[68.15563965]
 [67.47408295]
 [67.26444244]
 [66.87709808]
 [66.20832825]].
[2019-03-23 15:42:12,778] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.6083652e-10 1.0000000e+00 2.9389190e-21 3.8608476e-16 4.8232490e-12], sum to 1.0000
[2019-03-23 15:42:12,792] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2744
[2019-03-23 15:42:12,798] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.38333333333334, 54.66666666666667, 1.0, 2.0, 0.5048221253907265, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 575562.6685907962, 575562.6685907962, 142884.5579963353], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7485000.0000, 
sim time next is 7485600.0000, 
raw observation next is [28.46666666666667, 54.33333333333334, 1.0, 2.0, 0.5028904477980398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 573344.2699462919, 573344.2699462919, 142676.0274035898], 
processed observation next is [0.0, 0.6521739130434783, 0.9303030303030304, 0.5433333333333334, 1.0, 1.0, 0.3786130597475497, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21234972960973775, 0.21234972960973775, 0.34799031074046294], 
reward next is 0.6520, 
noisyNet noise sample is [array([0.1875745], dtype=float32), -0.2631098]. 
=============================================
[2019-03-23 15:42:17,602] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.7113929e-09 1.0000000e+00 3.1140797e-21 6.8597997e-15 3.6838751e-10], sum to 1.0000
[2019-03-23 15:42:17,610] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2048
[2019-03-23 15:42:17,618] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.28333333333334, 63.33333333333334, 1.0, 2.0, 0.487714885848062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 556447.5246820886, 556447.524682089, 140110.5229976424], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7560600.0000, 
sim time next is 7561200.0000, 
raw observation next is [26.46666666666667, 62.66666666666667, 1.0, 2.0, 0.4884524469851122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 557252.7068112912, 557252.7068112908, 140307.8201673405], 
processed observation next is [0.0, 0.5217391304347826, 0.8393939393939395, 0.6266666666666667, 1.0, 1.0, 0.36056555873139023, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2063898914115893, 0.2063898914115892, 0.3422141955300988], 
reward next is 0.6578, 
noisyNet noise sample is [array([-1.62968], dtype=float32), 1.0320224]. 
=============================================
[2019-03-23 15:42:18,614] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.3783353e-11 1.0000000e+00 1.1811324e-22 1.1948634e-15 6.5173721e-12], sum to 1.0000
[2019-03-23 15:42:18,620] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5888
[2019-03-23 15:42:18,623] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.46666666666667, 62.66666666666667, 1.0, 2.0, 0.4884524469851122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 557252.7068112912, 557252.7068112908, 140307.8201673405], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7561200.0000, 
sim time next is 7561800.0000, 
raw observation next is [26.65, 62.0, 1.0, 2.0, 0.4898847983986672, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558843.8468794656, 558843.8468794656, 140585.0938699219], 
processed observation next is [0.0, 0.5217391304347826, 0.8477272727272727, 0.62, 1.0, 1.0, 0.362355997998334, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20697920254795024, 0.20697920254795024, 0.342890472853468], 
reward next is 0.6571, 
noisyNet noise sample is [array([-0.08273888], dtype=float32), -0.6268544]. 
=============================================
[2019-03-23 15:42:22,037] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 15:42:22,039] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:42:22,040] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:42:22,040] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:42:22,041] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:42:22,040] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:42:22,043] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:42:22,045] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:42:22,042] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:42:22,046] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:42:22,043] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:42:22,062] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run77
[2019-03-23 15:42:22,094] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run77
[2019-03-23 15:42:22,094] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run77
[2019-03-23 15:42:22,123] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run77
[2019-03-23 15:42:22,158] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run77
[2019-03-23 15:42:50,951] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05601924], dtype=float32), 0.33879283]
[2019-03-23 15:42:50,954] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.88396676, 74.82829517500001, 1.0, 2.0, 0.2634398368254293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 286029.0318173999, 286029.0318173999, 98507.82872647315]
[2019-03-23 15:42:50,955] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:42:50,958] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5112518e-09 1.0000000e+00 2.9793656e-20 2.5534335e-15 6.4729472e-12], sampled 0.3354910563206914
[2019-03-23 15:43:01,411] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05601924], dtype=float32), 0.33879283]
[2019-03-23 15:43:01,413] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.33333333333333, 87.0, 1.0, 2.0, 0.5265713231073174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 599735.8448234516, 599735.8448234514, 146147.5086131894]
[2019-03-23 15:43:01,414] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:43:01,417] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.9454851e-09 1.0000000e+00 5.1921778e-20 3.8751330e-15 8.9382824e-12], sampled 0.7157358549909009
[2019-03-23 15:43:30,317] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05601924], dtype=float32), 0.33879283]
[2019-03-23 15:43:30,318] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.03333333333333, 72.66666666666666, 1.0, 2.0, 0.6251457889011455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 713240.7509754876, 713240.7509754873, 159927.4175512358]
[2019-03-23 15:43:30,320] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:43:30,322] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.6218039e-09 1.0000000e+00 9.8970209e-20 6.2851162e-15 1.2972942e-11], sampled 0.781706928550422
[2019-03-23 15:43:51,205] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05601924], dtype=float32), 0.33879283]
[2019-03-23 15:43:51,208] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.4244316, 58.83368259, 1.0, 2.0, 0.2668668242300206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 289750.7702555669, 289750.7702555669, 92447.34166253092]
[2019-03-23 15:43:51,210] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:43:51,212] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5393459e-09 1.0000000e+00 3.1203599e-20 2.6444767e-15 6.6454342e-12], sampled 0.9982283606174476
[2019-03-23 15:44:09,091] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 15:44:09,554] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 15:44:09,708] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 15:44:09,781] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 15:44:09,827] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 15:44:10,847] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1900000, evaluation results [1900000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 15:44:17,116] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.2574914e-10 1.0000000e+00 1.5059108e-21 3.2561723e-17 2.4272893e-13], sum to 1.0000
[2019-03-23 15:44:17,126] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0565
[2019-03-23 15:44:17,133] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 46.33333333333334, 1.0, 2.0, 0.7112697710806226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 772688.8569868888, 772688.8569868888, 147475.7732130621], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7746600.0000, 
sim time next is 7747200.0000, 
raw observation next is [22.7, 46.0, 1.0, 2.0, 0.7376124579519449, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 801329.8700781842, 801329.8700781844, 149229.4499231108], 
processed observation next is [1.0, 0.6956521739130435, 0.6681818181818181, 0.46, 1.0, 1.0, 0.6720155724399309, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.29678884076969786, 0.2967888407696979, 0.3639742681051483], 
reward next is 0.6360, 
noisyNet noise sample is [array([0.8386093], dtype=float32), 0.53190017]. 
=============================================
[2019-03-23 15:44:19,365] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.3348335e-11 1.0000000e+00 1.4762022e-23 5.2237113e-18 3.8055233e-13], sum to 1.0000
[2019-03-23 15:44:19,375] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2747
[2019-03-23 15:44:19,378] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 45.16666666666666, 1.0, 2.0, 0.6861997191501938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 750143.1150832915, 750143.1150832915, 147050.9495919729], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7827000.0000, 
sim time next is 7827600.0000, 
raw observation next is [24.0, 45.33333333333334, 1.0, 2.0, 0.6271621381716037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 686461.1098702074, 686461.1098702074, 140838.9315818353], 
processed observation next is [1.0, 0.6086956521739131, 0.7272727272727273, 0.4533333333333334, 1.0, 1.0, 0.5339526727145046, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2542448555074842, 0.2542448555074842, 0.3435095892239885], 
reward next is 0.6565, 
noisyNet noise sample is [array([0.48067534], dtype=float32), -1.6684368]. 
=============================================
[2019-03-23 15:44:19,745] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.0746382e-11 1.0000000e+00 4.3780367e-23 2.4002368e-17 1.0090646e-11], sum to 1.0000
[2019-03-23 15:44:19,752] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5566
[2019-03-23 15:44:19,756] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.25, 63.0, 1.0, 2.0, 0.2954138028958656, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 320774.1110550169, 320774.1110550172, 108687.6703947672], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7849800.0000, 
sim time next is 7850400.0000, 
raw observation next is [20.16666666666666, 63.0, 1.0, 2.0, 0.2944654911343861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 319744.0513143305, 319744.0513143305, 106910.2749285213], 
processed observation next is [1.0, 0.8695652173913043, 0.5530303030303028, 0.63, 1.0, 1.0, 0.11808186391798259, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11842372270901129, 0.11842372270901129, 0.26075676811834464], 
reward next is 0.7392, 
noisyNet noise sample is [array([1.1505985], dtype=float32), -0.5858141]. 
=============================================
[2019-03-23 15:44:22,634] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2500927e-10 1.0000000e+00 3.8547562e-23 5.2590587e-19 1.7812186e-14], sum to 1.0000
[2019-03-23 15:44:22,642] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6144
[2019-03-23 15:44:22,651] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 93.0, 1.0, 2.0, 0.4583523198040245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522770.6323288757, 522770.6323288757, 135260.804753147], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7930800.0000, 
sim time next is 7931400.0000, 
raw observation next is [21.1, 92.5, 1.0, 2.0, 0.4560260818112321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 520056.2126763794, 520056.2126763794, 134887.9234615777], 
processed observation next is [1.0, 0.8260869565217391, 0.5954545454545456, 0.925, 1.0, 1.0, 0.3200326022640401, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19261341210236274, 0.19261341210236274, 0.32899493527214074], 
reward next is 0.6710, 
noisyNet noise sample is [array([0.10449547], dtype=float32), -0.8360748]. 
=============================================
[2019-03-23 15:44:23,829] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:44:23,829] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:44:23,880] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run10
[2019-03-23 15:44:24,497] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:44:24,497] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:44:24,538] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run10
[2019-03-23 15:44:25,633] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:44:25,634] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:44:25,653] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run10
[2019-03-23 15:44:25,853] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:44:25,853] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:44:25,862] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run10
[2019-03-23 15:44:26,105] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:44:26,105] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:44:26,110] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run10
[2019-03-23 15:44:26,295] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:44:26,297] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:44:26,304] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run10
[2019-03-23 15:44:26,345] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.1233394e-09 1.0000000e+00 4.5689205e-20 7.3945544e-15 1.3347501e-11], sum to 1.0000
[2019-03-23 15:44:26,346] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4987
[2019-03-23 15:44:26,348] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 79.5, 1.0, 2.0, 0.2190560116758759, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 237840.9797195049, 237840.9797195052, 75330.24258267494], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 91800.0000, 
sim time next is 92400.0000, 
raw observation next is [14.66666666666667, 80.33333333333333, 1.0, 2.0, 0.2163740384530835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 234928.3128455211, 234928.3128455208, 74393.54969384018], 
processed observation next is [1.0, 0.043478260869565216, 0.30303030303030315, 0.8033333333333332, 1.0, 1.0, 0.02046754806635437, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08701048623908189, 0.08701048623908178, 0.181447682180098], 
reward next is 0.8186, 
noisyNet noise sample is [array([-0.72161984], dtype=float32), -0.34855112]. 
=============================================
[2019-03-23 15:44:26,377] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:44:26,377] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:44:26,380] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run10
[2019-03-23 15:44:26,409] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:44:26,409] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:44:26,423] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run10
[2019-03-23 15:44:26,453] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:44:26,455] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:44:26,464] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run10
[2019-03-23 15:44:26,505] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:44:26,506] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:44:26,513] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run10
[2019-03-23 15:44:26,561] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:44:26,562] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:44:26,590] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run10
[2019-03-23 15:44:26,652] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:44:26,653] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:44:26,662] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run10
[2019-03-23 15:44:26,707] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:44:26,708] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:44:26,712] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run10
[2019-03-23 15:44:26,755] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:44:26,758] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:44:26,780] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run10
[2019-03-23 15:44:26,865] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:44:26,865] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:44:26,869] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run10
[2019-03-23 15:44:26,966] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:44:26,966] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:44:26,970] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run10
[2019-03-23 15:44:29,635] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4910435e-09 1.0000000e+00 3.6125766e-20 3.5466760e-14 1.1538902e-11], sum to 1.0000
[2019-03-23 15:44:29,644] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0562
[2019-03-23 15:44:29,652] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 100.0, 1.0, 2.0, 0.3747450626513554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 419585.2738013638, 419585.2738013638, 121269.8549739173], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 24600.0000, 
sim time next is 25200.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3739914995077335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 419612.9914524262, 419612.991452426, 121617.5915209842], 
processed observation next is [1.0, 0.30434782608695654, 0.45454545454545453, 1.0, 1.0, 1.0, 0.2174893743846669, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15541221905645414, 0.15541221905645408, 0.2966282720024005], 
reward next is 0.7034, 
noisyNet noise sample is [array([-0.09740938], dtype=float32), 1.1480701]. 
=============================================
[2019-03-23 15:44:39,492] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 8.8693719e-11 8.7779149e-27 8.3466902e-21 2.6020183e-15], sum to 1.0000
[2019-03-23 15:44:39,501] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0090
[2019-03-23 15:44:39,511] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.66666666666667, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5289234204407994, 6.911199999999999, 6.9112, 77.32846344354104, 307653.67948689, 307653.6794868903, 103872.4818285924], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 235200.0000, 
sim time next is 235800.0000, 
raw observation next is [18.0, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5290171247028502, 6.911199999999999, 6.9112, 77.32846344354104, 307708.2007657506, 307708.2007657509, 103639.1967005643], 
processed observation next is [0.0, 0.7391304347826086, 0.45454545454545453, 0.79, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3271673210040718, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11396600028361134, 0.11396600028361144, 0.2527785285379617], 
reward next is 0.7472, 
noisyNet noise sample is [array([-1.0376083], dtype=float32), 0.23186354]. 
=============================================
[2019-03-23 15:44:39,859] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 5.5417851e-11 6.3295450e-26 7.0548045e-22 1.6990979e-16], sum to 1.0000
[2019-03-23 15:44:39,871] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8727
[2019-03-23 15:44:39,875] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.73333333333333, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4771517038694991, 6.9112, 6.9112, 77.32846344354104, 277531.5424294111, 277531.5424294111, 90591.59158536514], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 227400.0000, 
sim time next is 228000.0000, 
raw observation next is [17.96666666666667, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.480100759549238, 6.911199999999998, 6.9112, 77.32846344354104, 279247.3299489315, 279247.3299489321, 91765.23515644681], 
processed observation next is [0.0, 0.6521739130434783, 0.4530303030303031, 0.73, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2572867993560543, -1.7763568394002506e-16, 0.0, 0.5084288129206541, 0.10342493701812279, 0.103424937018123, 0.223817646723041], 
reward next is 0.7762, 
noisyNet noise sample is [array([0.35745752], dtype=float32), 0.50120276]. 
=============================================
[2019-03-23 15:44:39,896] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[77.28779 ]
 [77.33393 ]
 [77.406075]
 [77.4849  ]
 [77.624596]], R is [[77.27310944]
 [77.27942657]
 [77.28890228]
 [77.30183411]
 [77.31797791]].
[2019-03-23 15:44:41,552] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9999464e-01 5.4081825e-06 1.5168785e-23 9.5737308e-17 1.4852912e-12], sum to 1.0000
[2019-03-23 15:44:41,559] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7091
[2019-03-23 15:44:41,563] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [12.66666666666667, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7210364944328149, 7.050233835127525, 6.9112, 77.32812124815344, 465566.4288052972, 420411.2827118817, 86315.27034044302], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 354000.0000, 
sim time next is 354600.0000, 
raw observation next is [12.5, 71.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7337956210176505, 7.151000520316103, 6.9112, 77.32776079319395, 505295.2582628144, 427413.6617158488, 91329.8103765077], 
processed observation next is [1.0, 0.08695652173913043, 0.20454545454545456, 0.715, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.619708030025215, 0.02398005203161029, 0.0, 0.508424193047635, 0.1871463919491905, 0.1583013561910551, 0.22275563506465293], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5765811], dtype=float32), -0.8212715]. 
=============================================
[2019-03-23 15:44:48,039] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.1360076e-05 9.9996865e-01 6.5978381e-20 6.6637126e-14 7.4890032e-09], sum to 1.0000
[2019-03-23 15:44:48,048] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4664
[2019-03-23 15:44:48,061] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 58.0, 1.0, 2.0, 0.3857302730052026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 418886.1956699531, 418886.1956699534, 97621.5353858297], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 401400.0000, 
sim time next is 402000.0000, 
raw observation next is [19.0, 58.66666666666667, 1.0, 2.0, 0.3880111625603052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 421364.2152126575, 421364.2152126572, 98429.66559663616], 
processed observation next is [1.0, 0.6521739130434783, 0.5, 0.5866666666666667, 1.0, 1.0, 0.2350139532003815, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15606082044913241, 0.15606082044913228, 0.24007235511374672], 
reward next is 0.7599, 
noisyNet noise sample is [array([-1.8589152], dtype=float32), 0.64960295]. 
=============================================
[2019-03-23 15:44:48,080] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[70.70846 ]
 [70.75998 ]
 [70.80344 ]
 [70.86163 ]
 [70.848465]], R is [[70.7317276 ]
 [70.78631592]
 [70.84286499]
 [70.90009308]
 [70.96130371]].
[2019-03-23 15:44:51,248] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.6190721e-06 9.9999738e-01 5.2217599e-20 1.6113794e-14 1.5304821e-10], sum to 1.0000
[2019-03-23 15:44:51,254] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1833
[2019-03-23 15:44:51,258] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.3681233474996012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 399757.9849311399, 399757.9849311399, 95971.25747050457], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 471600.0000, 
sim time next is 472200.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.3989033388670831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 433197.9416390546, 433197.9416390546, 99172.37076848646], 
processed observation next is [1.0, 0.4782608695652174, 0.2727272727272727, 1.0, 1.0, 1.0, 0.2486291735838539, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16044368208853876, 0.16044368208853876, 0.2418838311426499], 
reward next is 0.7581, 
noisyNet noise sample is [array([0.03960743], dtype=float32), -0.8461835]. 
=============================================
[2019-03-23 15:44:59,927] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 15:44:59,930] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:44:59,933] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:44:59,933] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:44:59,935] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:44:59,935] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:44:59,936] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:44:59,937] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:44:59,938] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:44:59,939] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:44:59,937] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:44:59,966] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run78
[2019-03-23 15:44:59,967] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run78
[2019-03-23 15:45:00,025] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run78
[2019-03-23 15:45:00,054] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run78
[2019-03-23 15:45:00,094] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run78
[2019-03-23 15:45:01,908] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05952753], dtype=float32), 0.3447579]
[2019-03-23 15:45:01,909] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.3359323, 75.78627952333333, 1.0, 2.0, 0.2777889355413163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 301612.4328984717, 301612.4328984714, 95840.39536240682]
[2019-03-23 15:45:01,909] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:45:01,911] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0548451e-06 9.9999893e-01 4.9764370e-19 2.8924244e-14 8.4869556e-10], sampled 0.7626123760189919
[2019-03-23 15:45:03,119] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05952753], dtype=float32), 0.3447579]
[2019-03-23 15:45:03,120] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.21666666666667, 31.16666666666667, 1.0, 2.0, 0.3180837696977593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 345375.5693770743, 345375.5693770739, 91085.97751337824]
[2019-03-23 15:45:03,120] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:45:03,123] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.5740597e-07 9.9999905e-01 3.7403543e-19 2.3405618e-14 7.3547735e-10], sampled 0.12338423767358542
[2019-03-23 15:45:26,874] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05952753], dtype=float32), 0.3447579]
[2019-03-23 15:45:26,875] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.9, 77.66666666666667, 1.0, 2.0, 0.3581015443724918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 398083.7652216214, 398083.7652216211, 122945.6931556475]
[2019-03-23 15:45:26,877] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:45:26,881] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.6869796e-07 9.9999928e-01 1.3352480e-19 1.0894844e-14 4.3750908e-10], sampled 0.10695320905310524
[2019-03-23 15:45:52,676] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05952753], dtype=float32), 0.3447579]
[2019-03-23 15:45:52,678] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.554012375, 94.743621185, 1.0, 2.0, 0.2850326081919992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 309479.3561565661, 309479.3561565657, 114510.4707717394]
[2019-03-23 15:45:52,682] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:45:52,687] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.0069526e-07 9.9999917e-01 2.2516035e-19 1.6040841e-14 5.6862237e-10], sampled 0.42829872596288554
[2019-03-23 15:46:45,838] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05952753], dtype=float32), 0.3447579]
[2019-03-23 15:46:45,841] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.93333333333333, 72.66666666666667, 1.0, 2.0, 0.3712863399912225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 403194.2129442195, 403194.2129442192, 102465.6731922593]
[2019-03-23 15:46:45,842] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:46:45,848] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.2394383e-06 9.9999881e-01 8.4515871e-19 4.2797922e-14 1.1031558e-09], sampled 0.8839681756788746
[2019-03-23 15:46:46,609] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 15:46:47,077] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 15:46:47,375] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 15:46:47,547] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 15:46:47,564] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 15:46:48,581] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1925000, evaluation results [1925000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 15:46:50,670] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.7386034e-07 9.9999928e-01 1.6055817e-17 4.4903558e-14 7.1007961e-10], sum to 1.0000
[2019-03-23 15:46:50,677] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5821
[2019-03-23 15:46:50,684] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333333, 49.33333333333333, 1.0, 2.0, 0.3570670416986099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 400628.2014295148, 400628.2014295151, 120200.3058400835], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 668400.0000, 
sim time next is 669000.0000, 
raw observation next is [25.16666666666667, 49.66666666666667, 1.0, 2.0, 0.3557345761528102, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 398734.2405109353, 398734.240510935, 119896.6310829284], 
processed observation next is [1.0, 0.7391304347826086, 0.7803030303030305, 0.4966666666666667, 1.0, 1.0, 0.1946682201910127, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14767934833738344, 0.14767934833738333, 0.2924308075193376], 
reward next is 0.7076, 
noisyNet noise sample is [array([-1.2113191], dtype=float32), 0.38955095]. 
=============================================
[2019-03-23 15:46:50,698] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[67.8496  ]
 [67.48612 ]
 [67.048676]
 [66.28913 ]
 [64.91843 ]], R is [[68.21024323]
 [68.23497009]
 [68.25905609]
 [68.27823639]
 [68.2559967 ]].
[2019-03-23 15:46:57,038] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.7417400e-11 1.0000000e+00 9.4765466e-25 1.2188140e-18 6.0459975e-15], sum to 1.0000
[2019-03-23 15:46:57,047] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7159
[2019-03-23 15:46:57,052] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.00000000000001, 1.0, 2.0, 0.3863486345789148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 435344.8144455772, 435344.8144455772, 123619.7698330344], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 796200.0000, 
sim time next is 796800.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.3857514582467097, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 434671.0595375159, 434671.0595375162, 123566.6399241136], 
processed observation next is [0.0, 0.21739130434782608, 0.5, 0.94, 1.0, 1.0, 0.2321893228083871, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16098928131019108, 0.1609892813101912, 0.301382048595399], 
reward next is 0.6986, 
noisyNet noise sample is [array([-1.4277841], dtype=float32), 0.8564952]. 
=============================================
[2019-03-23 15:47:06,597] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.15477364e-10 1.00000000e+00 8.91106492e-23 3.99112500e-19
 1.79521539e-15], sum to 1.0000
[2019-03-23 15:47:06,604] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1961
[2019-03-23 15:47:06,608] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.66666666666667, 100.0, 1.0, 2.0, 0.4861336854954781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 527979.1147949683, 527979.1147949683, 113955.497117058], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1002000.0000, 
sim time next is 1002600.0000, 
raw observation next is [14.5, 100.0, 1.0, 2.0, 0.4953611908813154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 538006.4516882706, 538006.4516882702, 113552.9743452042], 
processed observation next is [1.0, 0.6086956521739131, 0.29545454545454547, 1.0, 1.0, 1.0, 0.36920148860164426, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19926164877343353, 0.19926164877343341, 0.2769584740126932], 
reward next is 0.7230, 
noisyNet noise sample is [array([-0.49536696], dtype=float32), -0.7359912]. 
=============================================
[2019-03-23 15:47:17,194] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.8310810e-08 1.0000000e+00 4.5451397e-20 6.6820987e-17 1.4449931e-12], sum to 1.0000
[2019-03-23 15:47:17,202] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1357
[2019-03-23 15:47:17,207] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3944510228895281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 442886.4674956352, 442886.4674956352, 123533.9798800577], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1312800.0000, 
sim time next is 1313400.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3899382528635771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 437812.0924361501, 437812.0924361504, 123135.3189202837], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 1.0, 1.0, 1.0, 0.23742281607947133, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16215262682820375, 0.16215262682820386, 0.3003300461470334], 
reward next is 0.6997, 
noisyNet noise sample is [array([-0.2713359], dtype=float32), -0.92683285]. 
=============================================
[2019-03-23 15:47:19,122] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2490857e-08 1.0000000e+00 7.6448578e-18 9.9497013e-15 2.2887033e-12], sum to 1.0000
[2019-03-23 15:47:19,127] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9080
[2019-03-23 15:47:19,128] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1382188.249365842 W.
[2019-03-23 15:47:19,134] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 65.0, 1.0, 2.0, 0.4055270398151236, 1.0, 2.0, 0.4055270398151236, 1.0, 1.0, 0.8214677211547018, 6.911199999999999, 6.9112, 77.3421103, 1382188.249365842, 1382188.249365842, 304080.4957332813], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1251600.0000, 
sim time next is 1252200.0000, 
raw observation next is [26.0, 65.0, 1.0, 2.0, 0.3986694414187532, 1.0, 2.0, 0.3986694414187532, 1.0, 2.0, 0.8072970280825836, 6.911199999999999, 6.9112, 77.3421103, 1355360.120493928, 1355360.120493928, 302554.6135244595], 
processed observation next is [1.0, 0.4782608695652174, 0.8181818181818182, 0.65, 1.0, 1.0, 0.2483368017734415, 1.0, 1.0, 0.2483368017734415, 1.0, 1.0, 0.7247100401179768, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5019852298125659, 0.5019852298125659, 0.7379380817669743], 
reward next is 0.2621, 
noisyNet noise sample is [array([-0.05786084], dtype=float32), 0.39252883]. 
=============================================
[2019-03-23 15:47:25,992] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2333613e-08 1.0000000e+00 9.3650436e-23 1.6128080e-17 2.2724708e-11], sum to 1.0000
[2019-03-23 15:47:25,999] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0979
[2019-03-23 15:47:26,006] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 84.66666666666667, 1.0, 2.0, 0.4656338014396282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 531204.357967501, 531204.357967501, 136361.7063720849], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1363200.0000, 
sim time next is 1363800.0000, 
raw observation next is [22.16666666666667, 86.33333333333334, 1.0, 2.0, 0.4678891035009882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 533813.967694544, 533813.9676945438, 136725.107706903], 
processed observation next is [1.0, 0.782608695652174, 0.6439393939393941, 0.8633333333333334, 1.0, 1.0, 0.3348613793762352, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19770887692390518, 0.1977088769239051, 0.333475872455861], 
reward next is 0.6665, 
noisyNet noise sample is [array([-0.78895414], dtype=float32), -0.7907265]. 
=============================================
[2019-03-23 15:47:26,751] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.6358231e-09 1.0000000e+00 2.0847361e-22 3.4845372e-18 4.6724756e-11], sum to 1.0000
[2019-03-23 15:47:26,757] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0065
[2019-03-23 15:47:26,764] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 88.0, 1.0, 2.0, 0.4723908245916151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 538987.4454171299, 538987.4454171297, 137360.7091459497], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1377600.0000, 
sim time next is 1378200.0000, 
raw observation next is [22.0, 88.0, 1.0, 2.0, 0.4718678408199585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 538390.3324297393, 538390.3324297395, 137302.8325949929], 
processed observation next is [1.0, 0.9565217391304348, 0.6363636363636364, 0.88, 1.0, 1.0, 0.33983480102494806, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19940382682582936, 0.19940382682582947, 0.3348849575487632], 
reward next is 0.6651, 
noisyNet noise sample is [array([-1.0173215], dtype=float32), 1.0179254]. 
=============================================
[2019-03-23 15:47:27,471] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.7036134e-06 9.9999630e-01 2.2489211e-17 2.0071101e-14 3.8619152e-09], sum to 1.0000
[2019-03-23 15:47:27,478] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0046
[2019-03-23 15:47:27,481] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5106320915119257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 581764.8880698587, 581764.8880698587, 144042.1791593184], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1414800.0000, 
sim time next is 1415400.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5113325899784171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 582533.6119282111, 582533.6119282111, 144153.6722260344], 
processed observation next is [0.0, 0.391304347826087, 0.6818181818181818, 0.89, 1.0, 1.0, 0.38916573747302136, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21575318960304113, 0.21575318960304113, 0.3515943225025229], 
reward next is 0.6484, 
noisyNet noise sample is [array([0.4684146], dtype=float32), 0.09898498]. 
=============================================
[2019-03-23 15:47:36,322] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 15:47:36,324] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:47:36,325] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:47:36,326] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:47:36,326] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:47:36,327] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:47:36,326] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:47:36,328] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:47:36,334] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:47:36,334] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:47:36,334] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:47:36,357] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run79
[2019-03-23 15:47:36,358] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run79
[2019-03-23 15:47:36,415] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run79
[2019-03-23 15:47:36,417] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run79
[2019-03-23 15:47:36,450] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run79
[2019-03-23 15:47:45,237] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05952753], dtype=float32), 0.34845072]
[2019-03-23 15:47:45,238] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [12.33333333333333, 80.16666666666667, 1.0, 2.0, 0.265545617532704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 288315.9254415872, 288315.9254415868, 79982.57430326176]
[2019-03-23 15:47:45,240] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:47:45,243] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.6047874e-08 1.0000000e+00 1.3017380e-19 7.4299231e-16 3.6827794e-10], sampled 0.43792097799207863
[2019-03-23 15:47:49,428] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05952753], dtype=float32), 0.34845072]
[2019-03-23 15:47:49,431] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.36666666666667, 63.0, 1.0, 2.0, 0.3540073381584267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 394758.6194784385, 394758.6194784385, 123143.05324211]
[2019-03-23 15:47:49,432] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:47:49,438] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.5935448e-08 1.0000000e+00 1.8364305e-20 1.5396223e-16 1.3736601e-10], sampled 0.9904581660505072
[2019-03-23 15:48:39,900] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05952753], dtype=float32), 0.34845072]
[2019-03-23 15:48:39,901] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.09355089166667, 69.77234528166667, 1.0, 2.0, 0.2178469649255668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 236516.9649304108, 236516.9649304108, 77274.03861454721]
[2019-03-23 15:48:39,902] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:48:39,906] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.1622968e-08 1.0000000e+00 6.1030090e-20 4.0409973e-16 2.5137231e-10], sampled 0.8789596026694275
[2019-03-23 15:48:48,194] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05952753], dtype=float32), 0.34845072]
[2019-03-23 15:48:48,195] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.5, 50.33333333333334, 1.0, 2.0, 0.3614340411856619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 402767.3926867509, 402767.3926867509, 123624.6788499973]
[2019-03-23 15:48:48,195] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:48:48,202] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.9251617e-08 1.0000000e+00 8.6001193e-21 8.3661841e-17 9.3719983e-11], sampled 0.9001704728531948
[2019-03-23 15:49:23,334] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 15:49:24,173] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 15:49:24,180] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 15:49:24,276] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 15:49:24,318] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 15:49:25,334] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1950000, evaluation results [1950000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 15:49:30,571] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.9287992e-06 9.9999535e-01 5.4494316e-20 1.3253656e-14 1.6650596e-06], sum to 1.0000
[2019-03-23 15:49:30,583] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7260
[2019-03-23 15:49:30,587] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 91.0, 1.0, 2.0, 0.3445507262609159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 381313.802067222, 381313.802067222, 116863.0281022471], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1650600.0000, 
sim time next is 1651200.0000, 
raw observation next is [18.0, 92.0, 1.0, 2.0, 0.3436711812197031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 380977.3221764624, 380977.3221764621, 117050.2469174409], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 0.92, 1.0, 1.0, 0.17958897652462882, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1411027119172083, 0.1411027119172082, 0.28548840711570955], 
reward next is 0.7145, 
noisyNet noise sample is [array([-0.11563258], dtype=float32), -1.8920022]. 
=============================================
[2019-03-23 15:49:31,211] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.9892105e-07 9.9999952e-01 6.5638753e-20 4.4792771e-15 1.5026176e-08], sum to 1.0000
[2019-03-23 15:49:31,222] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3551
[2019-03-23 15:49:31,224] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 76.33333333333334, 1.0, 2.0, 0.6350833653754611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 696763.5983335066, 696763.5983335066, 142217.7627203243], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1682400.0000, 
sim time next is 1683000.0000, 
raw observation next is [19.0, 75.5, 1.0, 2.0, 0.654140211462652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 716540.4773454223, 716540.4773454226, 143941.5887809334], 
processed observation next is [1.0, 0.4782608695652174, 0.5, 0.755, 1.0, 1.0, 0.5676752643283149, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.265385361979786, 0.2653853619797861, 0.35107704580715465], 
reward next is 0.6489, 
noisyNet noise sample is [array([1.0862045], dtype=float32), 0.58979475]. 
=============================================
[2019-03-23 15:49:31,244] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[66.313324]
 [66.3545  ]
 [66.2601  ]
 [66.20894 ]
 [65.98609 ]], R is [[66.18521118]
 [66.17649078]
 [66.17539215]
 [66.17532349]
 [66.17796326]].
[2019-03-23 15:49:38,609] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 6.5057674e-21 1.3647570e-33 1.8862058e-30 1.3278910e-23], sum to 1.0000
[2019-03-23 15:49:38,617] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0512
[2019-03-23 15:49:38,621] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.0, 54.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4290825093206192, 6.9112, 6.9112, 77.32846344354104, 249565.2995614377, 249565.2995614377, 68309.9767645687], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1806000.0000, 
sim time next is 1806600.0000, 
raw observation next is [17.0, 54.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4277123758541852, 6.9112, 6.9112, 77.32846344354104, 248768.1912962368, 248768.1912962368, 68482.98506217319], 
processed observation next is [1.0, 0.9130434782608695, 0.4090909090909091, 0.545, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1824462512202646, 0.0, 0.0, 0.5084288129206541, 0.09213636714675437, 0.09213636714675437, 0.16703167088334925], 
reward next is 0.8330, 
noisyNet noise sample is [array([-2.2254555], dtype=float32), 0.065991856]. 
=============================================
[2019-03-23 15:49:41,976] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 5.2681748e-19 4.9742090e-24 6.2873724e-22 2.1709481e-18], sum to 1.0000
[2019-03-23 15:49:41,982] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7939
[2019-03-23 15:49:41,989] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 576907.4547532377 W.
[2019-03-23 15:49:41,994] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 48.0, 1.0, 1.0, 0.5311574489636065, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32821222463785, 576907.4547532377, 576907.4547532373, 129722.6037272767], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1863000.0000, 
sim time next is 1863600.0000, 
raw observation next is [22.66666666666666, 48.66666666666666, 1.0, 2.0, 0.521687763794977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846188845434, 566616.1242579394, 566616.1242579394, 128843.7839110365], 
processed observation next is [1.0, 0.5652173913043478, 0.6666666666666664, 0.4866666666666666, 1.0, 1.0, 0.40210970474372126, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288026960764, 0.20985782379923681, 0.20985782379923681, 0.3142531314903329], 
reward next is 0.6857, 
noisyNet noise sample is [array([-0.3008214], dtype=float32), 0.9570023]. 
=============================================
[2019-03-23 15:49:45,292] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9999917e-01 7.9064796e-07 2.1114924e-20 3.1857680e-17 3.0686844e-12], sum to 1.0000
[2019-03-23 15:49:45,297] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7785
[2019-03-23 15:49:45,302] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.33333333333334, 75.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4252587974109671, 6.911199999999999, 6.9112, 77.32846344354104, 247340.765989279, 247340.7659892793, 77375.13534392504], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2010000.0000, 
sim time next is 2010600.0000, 
raw observation next is [16.5, 74.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4289602105825989, 6.911199999999999, 6.9112, 77.32846344354104, 249494.1492610908, 249494.149261091, 78037.56639346841], 
processed observation next is [0.0, 0.2608695652173913, 0.38636363636363635, 0.745, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.18422887226085563, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09240524046707066, 0.09240524046707074, 0.19033552778894736], 
reward next is 0.8097, 
noisyNet noise sample is [array([0.17828244], dtype=float32), 0.5104728]. 
=============================================
[2019-03-23 15:49:45,677] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.8049783e-13 9.9413526e-23 9.1415930e-20 1.3213981e-15], sum to 1.0000
[2019-03-23 15:49:45,682] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0077
[2019-03-23 15:49:45,688] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.0, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5314722269182691, 6.911200000000001, 6.9112, 77.32846344354104, 309136.6898619929, 309136.6898619926, 99123.24033429653], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2019600.0000, 
sim time next is 2020200.0000, 
raw observation next is [19.33333333333334, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5333932677035242, 6.9112, 6.9112, 77.32846344354104, 310254.4408793988, 310254.4408793988, 99747.8096869626], 
processed observation next is [0.0, 0.391304347826087, 0.5151515151515155, 0.66, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3334189538621775, 0.0, 0.0, 0.5084288129206541, 0.11490905217755511, 0.11490905217755511, 0.2432873406999088], 
reward next is 0.7567, 
noisyNet noise sample is [array([0.22824883], dtype=float32), -1.3518497]. 
=============================================
[2019-03-23 15:49:46,983] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.0453199e-15 3.8716476e-29 3.7027543e-25 3.7282638e-19], sum to 1.0000
[2019-03-23 15:49:46,990] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8462
[2019-03-23 15:49:46,996] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 60.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6473352745647525, 6.9112, 6.9112, 77.32846344354104, 374998.6748250818, 374998.6748250818, 118685.9187825132], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1974600.0000, 
sim time next is 1975200.0000, 
raw observation next is [22.0, 60.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6456196044940712, 6.911199999999999, 6.9112, 77.32846344354104, 374010.8483404958, 374010.8483404961, 118525.8447334273], 
processed observation next is [1.0, 0.8695652173913043, 0.6363636363636364, 0.6, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4937422921343875, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13852253642240583, 0.13852253642240595, 0.28908742617909094], 
reward next is 0.7109, 
noisyNet noise sample is [array([-0.48852974], dtype=float32), 0.09673928]. 
=============================================
[2019-03-23 15:49:47,114] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 4.6279696e-18 2.4133670e-31 1.6119587e-25 4.7926098e-20], sum to 1.0000
[2019-03-23 15:49:47,122] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6977
[2019-03-23 15:49:47,129] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.0, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4431038121323656, 6.9112, 6.9112, 77.32846344354104, 257722.6065076809, 257722.6065076809, 80506.21806137056], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2004000.0000, 
sim time next is 2004600.0000, 
raw observation next is [17.0, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4419180426158013, 6.911199999999998, 6.9112, 77.32846344354104, 257032.7447809586, 257032.7447809592, 80405.83443336902], 
processed observation next is [0.0, 0.17391304347826086, 0.4090909090909091, 0.72, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2027400608797162, -1.7763568394002506e-16, 0.0, 0.5084288129206541, 0.09519731288183651, 0.09519731288183675, 0.19611179130090003], 
reward next is 0.8039, 
noisyNet noise sample is [array([-0.6152583], dtype=float32), -0.5207593]. 
=============================================
[2019-03-23 15:49:59,420] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.7934789e-20 5.2358794e-26 2.1639654e-22 1.4289715e-18], sum to 1.0000
[2019-03-23 15:49:59,430] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8029
[2019-03-23 15:49:59,435] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.0, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5373846550638643, 6.911199999999999, 6.9112, 77.32846344354104, 312576.6527137465, 312576.6527137468, 98274.13176082066], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2244600.0000, 
sim time next is 2245200.0000, 
raw observation next is [16.0, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5289971838490753, 6.911199999999999, 6.9112, 77.32846344354104, 307696.5416729864, 307696.5416729866, 96548.62925630927], 
processed observation next is [1.0, 1.0, 0.36363636363636365, 0.9, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3271388340701077, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11396168210110608, 0.11396168210110615, 0.2354844616007543], 
reward next is 0.7645, 
noisyNet noise sample is [array([0.4558713], dtype=float32), 0.097233325]. 
=============================================
[2019-03-23 15:50:00,590] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.6619562e-23 1.3783031e-32 4.4162819e-30 5.5960680e-24], sum to 1.0000
[2019-03-23 15:50:00,599] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8392
[2019-03-23 15:50:00,605] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.66666666666667, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.612792845467294, 6.911199999999999, 6.9112, 77.32846344354104, 356100.1434121841, 356100.1434121844, 114804.7457959682], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2240400.0000, 
sim time next is 2241000.0000, 
raw observation next is [16.5, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6001155487297003, 6.911200000000001, 6.9112, 77.32846344354104, 348943.5878562254, 348943.5878562251, 112147.8953159389], 
processed observation next is [1.0, 0.9565217391304348, 0.38636363636363635, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4287364981852862, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12923836587267606, 0.12923836587267595, 0.2735314519900949], 
reward next is 0.7265, 
noisyNet noise sample is [array([-0.9396107], dtype=float32), 1.3973384]. 
=============================================
[2019-03-23 15:50:00,620] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[78.79535]
 [78.8037 ]
 [77.90396]
 [76.84158]
 [77.15002]], R is [[79.29626465]
 [79.22328949]
 [79.14792633]
 [79.06990051]
 [78.98868561]].
[2019-03-23 15:50:02,525] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 7.0917238e-20 3.7395172e-26 2.3725194e-23 3.9343478e-19], sum to 1.0000
[2019-03-23 15:50:02,531] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1686
[2019-03-23 15:50:02,535] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.0, 64.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.491833212961494, 6.911199999999999, 6.9112, 77.32846344354104, 286073.4384067006, 286073.4384067009, 90953.90528700809], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2408400.0000, 
sim time next is 2409000.0000, 
raw observation next is [18.83333333333334, 64.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4880201599769866, 6.911199999999999, 6.9112, 77.32846344354104, 283854.9393759249, 283854.9393759252, 90099.39124811842], 
processed observation next is [1.0, 0.9130434782608695, 0.4924242424242427, 0.6466666666666667, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2686002285385523, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10513145902812032, 0.10513145902812046, 0.21975461280028885], 
reward next is 0.7802, 
noisyNet noise sample is [array([1.0390999], dtype=float32), -3.0534463]. 
=============================================
[2019-03-23 15:50:02,555] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[52.88476 ]
 [52.73516 ]
 [52.54729 ]
 [52.667892]
 [52.03673 ]], R is [[53.27072144]
 [53.51617432]
 [53.75894547]
 [53.99913406]
 [54.23682785]].
[2019-03-23 15:50:10,240] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 9.8387168e-19 7.6188033e-25 1.5739423e-21 5.1961261e-18], sum to 1.0000
[2019-03-23 15:50:10,246] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4235
[2019-03-23 15:50:10,251] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4699301942136316, 6.911199999999999, 6.9112, 77.32846344354104, 273330.027738332, 273330.0277383323, 81765.0709196858], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2446200.0000, 
sim time next is 2446800.0000, 
raw observation next is [15.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4663020109126259, 6.9112, 6.9112, 77.32846344354104, 271219.1441083864, 271219.1441083864, 81616.41017825014], 
processed observation next is [1.0, 0.30434782608695654, 0.3181818181818182, 0.88, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.23757430130375132, 0.0, 0.0, 0.5084288129206541, 0.10045153485495793, 0.10045153485495793, 0.19906441506890277], 
reward next is 0.8009, 
noisyNet noise sample is [array([1.0964279], dtype=float32), 2.0721858]. 
=============================================
[2019-03-23 15:50:10,518] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 4.3760013e-11 4.2436042e-20 8.2394601e-18 1.9912912e-12], sum to 1.0000
[2019-03-23 15:50:10,528] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2230
[2019-03-23 15:50:10,536] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 572246.894864747 W.
[2019-03-23 15:50:10,542] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [15.83333333333333, 84.0, 1.0, 1.0, 0.2634345028839677, 0.0, 2.0, 0.0, 1.0, 2.0, 0.491774504702957, 6.9112, 6.9112, 77.32815284062268, 572246.894864747, 572246.894864747, 152682.9462543473], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2454600.0000, 
sim time next is 2455200.0000, 
raw observation next is [16.0, 82.0, 1.0, 2.0, 0.2430573020870641, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4537347349711089, 6.911200000000001, 6.9112, 77.32846152085135, 527958.3797440268, 527958.3797440266, 144188.6659274576], 
processed observation next is [1.0, 0.43478260869565216, 0.36363636363636365, 0.82, 1.0, 1.0, 0.05382162760883012, 0.0, 1.0, -0.25, 1.0, 1.0, 0.21962104995872703, 8.881784197001253e-17, 0.0, 0.5084288002791144, 0.19554014064593586, 0.19554014064593578, 0.351679672993799], 
reward next is 0.6483, 
noisyNet noise sample is [array([-0.5325644], dtype=float32), -0.096258566]. 
=============================================
[2019-03-23 15:50:13,168] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 15:50:13,170] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:50:13,171] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:50:13,172] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:50:13,172] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:50:13,173] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:50:13,178] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:50:13,177] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:50:13,173] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:50:13,180] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:50:13,183] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:50:13,198] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run80
[2019-03-23 15:50:13,198] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run80
[2019-03-23 15:50:13,235] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run80
[2019-03-23 15:50:13,299] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run80
[2019-03-23 15:50:13,321] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run80
[2019-03-23 15:50:23,935] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06100547], dtype=float32), 0.35091147]
[2019-03-23 15:50:23,936] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 100.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7582766212316208, 7.239448241961507, 6.9112, 77.32764637142427, 540166.9414038929, 433559.7527028401, 134041.6512910354]
[2019-03-23 15:50:23,937] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:50:23,940] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.9999988e-01 1.7320392e-07 1.4906837e-22 5.5324495e-18 1.5228510e-10], sampled 0.7245659054104363
[2019-03-23 15:50:40,785] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06100547], dtype=float32), 0.35091147]
[2019-03-23 15:50:40,788] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.64308086, 93.04800256, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4592644227721046, 6.9112, 6.9112, 95.55338769695034, 267110.6876272209, 267110.6876272209, 86301.02542358541]
[2019-03-23 15:50:40,789] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:50:40,793] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0000000e+00 2.9146869e-09 1.9010521e-28 1.2175057e-22 3.5765542e-13], sampled 0.22212361722877683
[2019-03-23 15:50:49,150] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06100547], dtype=float32), 0.35091147]
[2019-03-23 15:50:49,152] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.691649225, 88.55523604666666, 1.0, 2.0, 0.7581102303594348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 862036.1426689938, 862036.1426689934, 183918.8107794783]
[2019-03-23 15:50:49,154] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:50:49,156] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0000000e+00 3.2466597e-13 1.1360989e-25 1.9450427e-21 1.1437629e-14], sampled 0.5814428409111864
[2019-03-23 15:50:49,158] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 862036.1426689938 W.
[2019-03-23 15:50:54,885] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06100547], dtype=float32), 0.35091147]
[2019-03-23 15:50:54,889] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.9, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6288546046818789, 6.9112, 6.9112, 95.55338769695034, 364395.2810193694, 364395.2810193694, 121245.8115786185]
[2019-03-23 15:50:54,893] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:50:54,896] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 7.0170832e-14 1.1359368e-28 9.3621097e-24 7.2131235e-16], sampled 0.9293782115190942
[2019-03-23 15:50:59,946] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06100547], dtype=float32), 0.35091147]
[2019-03-23 15:50:59,947] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.26666666666667, 63.5, 1.0, 2.0, 0.5391153806988076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 613330.3274213398, 613330.3274213402, 152462.2987001101]
[2019-03-23 15:50:59,949] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:50:59,952] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0000000e+00 1.6512342e-13 5.3354140e-29 6.5861374e-24 9.6314814e-16], sampled 0.9385897223479335
[2019-03-23 15:50:59,954] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 613330.3274213398 W.
[2019-03-23 15:51:27,733] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06100547], dtype=float32), 0.35091147]
[2019-03-23 15:51:27,735] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [8.279881166666668, 93.26268868666668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 138380.0454823854, 138380.0454823854, 55950.99372962178]
[2019-03-23 15:51:27,737] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:51:27,742] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0000000e+00 2.6094533e-15 7.8403856e-30 6.7168794e-25 5.1861879e-17], sampled 0.07865852636304493
[2019-03-23 15:51:38,254] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06100547], dtype=float32), 0.35091147]
[2019-03-23 15:51:38,254] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [11.14149069833333, 97.27260458500001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6856911912155177, 6.97422721856444, 6.9112, 95.5528872610493, 424148.0562650267, 398853.8388835917, 95780.2262715266]
[2019-03-23 15:51:38,256] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:51:38,260] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0000000e+00 2.0084101e-12 3.8434148e-26 1.3018410e-21 2.4209120e-14], sampled 0.6778850073436744
[2019-03-23 15:51:57,441] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6862.2842 1793014293.7888 2409.0000
[2019-03-23 15:51:57,617] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6294.9961 1685630448.6673 3228.0000
[2019-03-23 15:51:57,890] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6328.7217 1723294598.4314 3425.0000
[2019-03-23 15:51:57,934] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6481.6076 1678885180.2952 3057.0000
[2019-03-23 15:51:58,291] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6553.1725 1698634175.0084 2957.0000
[2019-03-23 15:51:59,310] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1975000, evaluation results [1975000.0, 6862.284208925443, 1793014293.78876, 2409.0, 6481.607577760913, 1678885180.2951708, 3057.0, 6294.9960618483565, 1685630448.6673346, 3228.0, 6328.721692698646, 1723294598.4313502, 3425.0, 6553.172466661831, 1698634175.0084193, 2957.0]
[2019-03-23 15:52:00,242] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9993026e-01 6.9695881e-05 3.2743764e-19 6.1476944e-15 2.3407147e-09], sum to 1.0000
[2019-03-23 15:52:00,253] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5669
[2019-03-23 15:52:00,256] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [13.83333333333333, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7049562092425519, 6.911199999999999, 6.9112, 77.32842493705368, 410088.1142418568, 410088.1142418571, 102778.1841072426], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2537400.0000, 
sim time next is 2538000.0000, 
raw observation next is [14.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.707044465505496, 6.919180690742309, 6.9112, 77.32839680625227, 413896.47067181, 411304.507785671, 103639.7114509726], 
processed observation next is [1.0, 0.391304347826087, 0.2727272727272727, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5814920935792801, 0.000798069074230856, 0.0, 0.5084283747855081, 0.1532949891377074, 0.15233500288358184, 0.25277978402676243], 
reward next is 0.7073, 
noisyNet noise sample is [array([-1.110186], dtype=float32), 0.6365268]. 
=============================================
[2019-03-23 15:52:00,266] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[66.26813 ]
 [66.45216 ]
 [66.83883 ]
 [67.44497 ]
 [68.126175]], R is [[66.55684662]
 [66.64060211]
 [66.72930908]
 [66.82857513]
 [66.95613861]].
[2019-03-23 15:52:00,408] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.5216012e-01 4.7836769e-02 3.3986191e-17 5.2964046e-13 3.0278718e-06], sum to 1.0000
[2019-03-23 15:52:00,413] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3908
[2019-03-23 15:52:00,418] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [13.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4009484534533809, 6.911199999999999, 6.9112, 77.32846344354104, 233197.8944412584, 233197.8944412587, 71386.1542468041], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2533800.0000, 
sim time next is 2534400.0000, 
raw observation next is [13.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4051426757145111, 6.9112, 6.9112, 77.32846344354104, 235637.9106405984, 235637.9106405984, 71598.55723486429], 
processed observation next is [1.0, 0.34782608695652173, 0.22727272727272727, 1.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.15020382244930164, 0.0, 0.0, 0.5084288129206541, 0.08727330023725867, 0.08727330023725867, 0.17463062740210802], 
reward next is 0.8254, 
noisyNet noise sample is [array([0.30772164], dtype=float32), 0.6969903]. 
=============================================
[2019-03-23 15:52:05,591] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 1.6245399e-17 2.6898204e-24 1.6162854e-20 4.8066235e-17], sum to 1.0000
[2019-03-23 15:52:05,597] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6470
[2019-03-23 15:52:05,603] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.66666666666667, 74.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.739419474144173, 7.110224307644699, 6.9112, 77.3278464770674, 489218.6590601751, 424580.1504118087, 130575.3778060965], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2623800.0000, 
sim time next is 2624400.0000, 
raw observation next is [22.0, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7462859210010914, 7.163981194104593, 6.9112, 77.32768214626948, 510413.073161844, 428315.7410746914, 131495.3372637834], 
processed observation next is [0.0, 0.391304347826087, 0.6363636363636364, 0.73, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6375513157158449, 0.025278119410459342, 0.0, 0.5084236759500403, 0.1890418789488311, 0.15863545965729312, 0.3207203347897156], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.07858589], dtype=float32), 1.94559]. 
=============================================
[2019-03-23 15:52:06,232] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.4893327e-20 1.8217723e-26 1.2012706e-23 1.3923687e-20], sum to 1.0000
[2019-03-23 15:52:06,241] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7251
[2019-03-23 15:52:06,248] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.83333333333333, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5501038654548133, 6.911199999999999, 6.9112, 77.32846344354104, 319977.553459277, 319977.5534592773, 107474.18177018], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2613000.0000, 
sim time next is 2613600.0000, 
raw observation next is [16.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5605768444145927, 6.911199999999999, 6.9112, 77.32846344354104, 326071.369698946, 326071.3696989462, 110409.4145668634], 
processed observation next is [0.0, 0.2608695652173913, 0.36363636363636365, 1.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.37225263487798954, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1207671739625726, 0.12076717396257267, 0.2692912550411303], 
reward next is 0.7307, 
noisyNet noise sample is [array([0.05783559], dtype=float32), -1.5018915]. 
=============================================
[2019-03-23 15:52:09,546] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 4.2845982e-26 8.5654209e-27 8.4837066e-26 3.0604105e-23], sum to 1.0000
[2019-03-23 15:52:09,549] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6518
[2019-03-23 15:52:09,554] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.0, 66.33333333333333, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3164547818894828, 6.911199999999999, 6.9112, 77.3421103, 535901.1681567862, 535901.1681567865, 205890.6285218786], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2731200.0000, 
sim time next is 2731800.0000, 
raw observation next is [25.0, 65.66666666666667, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7977087354324649, 7.499511948244522, 6.9112, 77.32703140013741, 642699.6843948823, 451631.5351159655, 141934.1438395163], 
processed observation next is [0.0, 0.6086956521739131, 0.7727272727272727, 0.6566666666666667, 0.0, 0.5, -0.25, 0.0, 0.5, -0.25, 1.0, 1.0, 0.7110124791892356, 0.058831194824452204, 0.0, 0.508419397343319, 0.2380369201462527, 0.16727093893183909, 0.34618083863296656], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6263104], dtype=float32), 0.84537405]. 
=============================================
[2019-03-23 15:52:11,007] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 2.9397720e-28 4.1650311e-22 1.2117695e-22 1.1523897e-23], sum to 1.0000
[2019-03-23 15:52:11,015] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3187
[2019-03-23 15:52:11,021] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 568436.1145742385 W.
[2019-03-23 15:52:11,028] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 85.33333333333334, 1.0, 2.0, 0.2496568298293803, 1.0, 2.0, 0.2496568298293803, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 568436.1145742385, 568436.1145742383, 180019.2386920975], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2751600.0000, 
sim time next is 2752200.0000, 
raw observation next is [23.0, 83.5, 1.0, 2.0, 0.2456999799048354, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4966792433132556, 6.9112, 6.9112, 77.32846344354104, 560473.4759123817, 560473.4759123817, 177318.2642156124], 
processed observation next is [0.0, 0.8695652173913043, 0.6818181818181818, 0.835, 1.0, 1.0, 0.05712497488104425, 0.0, 0.5, -0.25, 1.0, 0.5, 0.28097034759036515, 0.0, 0.0, 0.5084288129206541, 0.20758276885643764, 0.20758276885643764, 0.43248357125759124], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.12669839], dtype=float32), -0.36597675]. 
=============================================
[2019-03-23 15:52:11,878] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 4.5149239e-24 3.2304226e-19 2.6267459e-19 4.6056156e-20], sum to 1.0000
[2019-03-23 15:52:11,887] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9653
[2019-03-23 15:52:11,891] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.5, 80.5, 1.0, 1.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 469022.2810232054, 469022.2810232057, 189220.2360503628], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2766600.0000, 
sim time next is 2767200.0000, 
raw observation next is [20.33333333333333, 81.33333333333333, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7330726414386362, 7.041874656203077, 6.9112, 77.32809907650243, 462270.7116171813, 419830.4560182118, 130666.2442570886], 
processed observation next is [1.0, 0.0, 0.5606060606060604, 0.8133333333333332, 0.0, 0.5, -0.25, 0.0, 0.5, -0.25, 1.0, 1.0, 0.6186752020551946, 0.013067465620307672, 0.0, 0.5084264172348657, 0.1712113746730301, 0.15549276148822658, 0.31869815672460633], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.743475], dtype=float32), 1.0886692]. 
=============================================
[2019-03-23 15:52:14,143] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.2603772e-15 1.1352760e-17 3.2688934e-16 6.3166547e-14], sum to 1.0000
[2019-03-23 15:52:14,151] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1479
[2019-03-23 15:52:14,157] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1101464.487556883 W.
[2019-03-23 15:52:14,161] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 65.0, 1.0, 2.0, 0.3233503002994325, 1.0, 2.0, 0.3233503002994325, 1.0, 2.0, 0.6549909583749569, 6.911199999999999, 6.9112, 77.3421103, 1101464.487556883, 1101464.487556883, 269058.3442764083], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2804400.0000, 
sim time next is 2805000.0000, 
raw observation next is [26.16666666666667, 64.5, 1.0, 2.0, 0.2927100195015581, 1.0, 2.0, 0.2927100195015581, 1.0, 2.0, 0.5929324163455075, 6.9112, 6.9112, 77.3421103, 997191.2068016435, 997191.2068016435, 257599.8664952428], 
processed observation next is [1.0, 0.4782608695652174, 0.825757575757576, 0.645, 1.0, 1.0, 0.11588752437694763, 1.0, 1.0, 0.11588752437694763, 1.0, 1.0, 0.4184748804935822, 0.0, 0.0, 0.5085185399722538, 0.3693300765932013, 0.3693300765932013, 0.6282923573054703], 
reward next is 0.3717, 
noisyNet noise sample is [array([-1.1889585], dtype=float32), 1.1540976]. 
=============================================
[2019-03-23 15:52:14,172] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[28.11737 ]
 [28.828064]
 [28.706203]
 [29.04877 ]
 [29.483082]], R is [[28.49209785]
 [28.55093575]
 [28.26542664]
 [28.32505989]
 [28.37287331]].
[2019-03-23 15:52:23,748] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 6.7760367e-35 6.0344875e-34 6.6170216e-36], sum to 1.0000
[2019-03-23 15:52:23,754] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6158
[2019-03-23 15:52:23,758] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1131614.750889174 W.
[2019-03-23 15:52:23,763] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.3338530970797237, 1.0, 2.0, 0.3338530970797237, 1.0, 2.0, 0.6755363676228922, 6.9112, 6.9112, 77.3421103, 1131614.750889174, 1131614.750889174, 275665.2843692595], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2982600.0000, 
sim time next is 2983200.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.4764059682509991, 1.0, 2.0, 0.4764059682509991, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1078618.910359565, 1078618.910359565, 227757.689470091], 
processed observation next is [1.0, 0.5217391304347826, 0.9090909090909091, 0.58, 1.0, 1.0, 0.34550746031374885, 1.0, 1.0, 0.34550746031374885, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3994884853183574, 0.3994884853183574, 0.5555065596831488], 
reward next is 0.4445, 
noisyNet noise sample is [array([-0.38663504], dtype=float32), -1.5380808]. 
=============================================
[2019-03-23 15:52:25,606] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 3.1798926e-33 1.4095530e-31 1.6611419e-34], sum to 1.0000
[2019-03-23 15:52:25,611] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1341
[2019-03-23 15:52:25,618] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 631819.7509884739 W.
[2019-03-23 15:52:25,620] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.73333333333334, 70.66666666666667, 1.0, 2.0, 0.2805272251717937, 1.0, 2.0, 0.2805272251717937, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 631819.7509884739, 631819.7509884739, 188458.2867312665], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3086400.0000, 
sim time next is 3087000.0000, 
raw observation next is [26.8, 70.5, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 1.0, 0.367086310711928, 6.9112, 6.9112, 77.3421103, 613457.8838168528, 613457.8838168528, 223111.3995448929], 
processed observation next is [1.0, 0.7391304347826086, 0.8545454545454546, 0.705, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.09583758673132572, 0.0, 0.0, 0.5085185399722538, 0.2272066236358714, 0.2272066236358714, 0.544174145231446], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.22946104], dtype=float32), 0.7187404]. 
=============================================
[2019-03-23 15:52:25,636] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[19.116804]
 [19.172182]
 [19.105772]
 [18.969995]
 [19.26099 ]], R is [[19.07043839]
 [19.42008018]
 [19.62523651]
 [19.7231884 ]
 [19.52595711]].
[2019-03-23 15:52:29,305] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 3.5199721e-23 7.2778040e-22 7.8538020e-21 4.8613275e-20], sum to 1.0000
[2019-03-23 15:52:29,313] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1753
[2019-03-23 15:52:29,318] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 609229.1270679939 W.
[2019-03-23 15:52:29,324] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.5353023244271775, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 609229.1270679939, 609229.1270679939, 147567.7149405607], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3096000.0000, 
sim time next is 3096600.0000, 
raw observation next is [24.0, 84.0, 1.0, 2.0, 0.2691629904552079, 1.0, 1.0, 0.2691629904552079, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 610872.8878028897, 610872.8878028893, 184636.6657231208], 
processed observation next is [1.0, 0.8695652173913043, 0.7272727272727273, 0.84, 1.0, 1.0, 0.08645373806900988, 1.0, 0.5, 0.08645373806900988, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22624921770477396, 0.22624921770477383, 0.45033333103200196], 
reward next is 0.5497, 
noisyNet noise sample is [array([-0.2773966], dtype=float32), -0.85324186]. 
=============================================
[2019-03-23 15:52:29,851] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 3.8129020e-22 6.0530407e-21 9.6901314e-20 1.3359883e-18], sum to 1.0000
[2019-03-23 15:52:29,854] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5440
[2019-03-23 15:52:29,859] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 632574.3129987149 W.
[2019-03-23 15:52:29,864] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.66666666666666, 89.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3779076083499215, 6.911199999999999, 6.9112, 77.3421103, 632574.3129987149, 632574.3129987152, 224940.3445665879], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3100800.0000, 
sim time next is 3101400.0000, 
raw observation next is [23.5, 89.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3741960366622083, 6.9112, 6.9112, 77.3421103, 626965.8018741757, 626965.8018741757, 223627.5703348723], 
processed observation next is [1.0, 0.9130434782608695, 0.7045454545454546, 0.89, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.10599433808886902, 0.0, 0.0, 0.5085185399722538, 0.2322095562496947, 0.2322095562496947, 0.5454330983777372], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6987609], dtype=float32), -0.36876187]. 
=============================================
[2019-03-23 15:52:47,304] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 15:52:47,304] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:52:47,305] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:52:47,308] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:52:47,309] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:52:47,313] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:52:47,316] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:52:47,316] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:52:47,317] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:52:47,318] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:52:47,320] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:52:47,338] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run81
[2019-03-23 15:52:47,366] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run81
[2019-03-23 15:52:47,401] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run81
[2019-03-23 15:52:47,433] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run81
[2019-03-23 15:52:47,434] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run81
[2019-03-23 15:53:25,885] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05833324], dtype=float32), 0.35047314]
[2019-03-23 15:53:25,885] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.25499604666667, 77.27672165000001, 1.0, 1.0, 0.457932037796335, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 95.55295453253798, 511967.6807231289, 511967.6807231285, 132718.2773193354]
[2019-03-23 15:53:25,886] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:53:25,888] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 8.8017260e-11 1.4118724e-16 1.1927857e-13 5.1179866e-11], sampled 0.216969608585586
[2019-03-23 15:53:30,347] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05833324], dtype=float32), 0.35047314]
[2019-03-23 15:53:30,352] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.53632285, 88.878927805, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.6842486592091294, 6.93316802036212, 6.9112, 95.55319470765922, 404928.6966307489, 396112.4156173342, 126637.6661499181]
[2019-03-23 15:53:30,354] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:53:30,356] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0000000e+00 5.2651824e-11 5.8345668e-18 1.2829147e-14 1.6007931e-11], sampled 0.5367040274494137
[2019-03-23 15:53:35,759] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05833324], dtype=float32), 0.35047314]
[2019-03-23 15:53:35,760] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [27.80072326333333, 74.59211691, 1.0, 2.0, 0.788639835072382, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9772595157338462, 6.924066954878273, 6.9112, 95.55334678407897, 1434806.310682163, 1429642.4921557, 316815.9381113462]
[2019-03-23 15:53:35,763] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:53:35,765] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 1.2071942e-12 2.2688098e-16 5.1538123e-14 4.3647542e-12], sampled 0.7276670802175186
[2019-03-23 15:53:35,767] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1434806.310682163 W.
[2019-03-23 15:53:45,583] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05833324], dtype=float32), 0.35047314]
[2019-03-23 15:53:45,585] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.1, 80.0, 1.0, 2.0, 0.5636622501100076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 639288.1786841933, 639288.178684193, 156584.1650927943]
[2019-03-23 15:53:45,587] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:53:45,592] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 2.7859610e-16 2.6122952e-20 1.5577345e-17 2.3741224e-15], sampled 0.7319786430904826
[2019-03-23 15:53:45,593] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 639288.1786841933 W.
[2019-03-23 15:54:33,870] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6294.9961 1685630448.6673 3228.0000
[2019-03-23 15:54:33,883] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6328.7217 1723294598.4314 3425.0000
[2019-03-23 15:54:34,158] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6862.2842 1793014293.7888 2409.0000
[2019-03-23 15:54:34,179] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6553.1725 1698634175.0084 2957.0000
[2019-03-23 15:54:34,271] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6481.6076 1678885180.2952 3057.0000
[2019-03-23 15:54:35,291] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 2000000, evaluation results [2000000.0, 6862.284208925443, 1793014293.78876, 2409.0, 6481.607577760913, 1678885180.2951708, 3057.0, 6294.9960618483565, 1685630448.6673346, 3228.0, 6328.721692698646, 1723294598.4313502, 3425.0, 6553.172466661831, 1698634175.0084193, 2957.0]
[2019-03-23 15:54:36,271] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9987924e-01 6.8990834e-05 1.8606910e-08 1.6402839e-06 5.0051178e-05], sum to 1.0000
[2019-03-23 15:54:36,281] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5204
[2019-03-23 15:54:36,289] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1029107.037115317 W.
[2019-03-23 15:54:36,293] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.302048809449418, 1.0, 2.0, 0.302048809449418, 1.0, 1.0, 0.6118520100058857, 6.911199999999999, 6.9112, 77.3421103, 1029107.037115317, 1029107.037115318, 260914.8893205833], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3486600.0000, 
sim time next is 3487200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.4640578435841273, 1.0, 2.0, 0.4640578435841273, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1054091.816976688, 1054091.816976688, 223477.6792331267], 
processed observation next is [1.0, 0.34782608695652173, 0.6363636363636364, 0.94, 1.0, 1.0, 0.3300723044801591, 1.0, 1.0, 0.3300723044801591, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3904043766580326, 0.3904043766580326, 0.5450675103246992], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.46313155], dtype=float32), 0.3219627]. 
=============================================
[2019-03-23 15:54:36,942] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 5.6367775e-12 5.6343317e-14 7.2086542e-12 3.5947360e-11], sum to 1.0000
[2019-03-23 15:54:36,947] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4859
[2019-03-23 15:54:36,953] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 599843.4277004539 W.
[2019-03-23 15:54:36,955] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.33333333333333, 87.0, 1.0, 2.0, 0.2634972232773716, 0.0, 2.0, 0.0, 1.0, 1.0, 0.533604997563119, 6.911200000000001, 6.9112, 77.32846344354104, 599843.4277004539, 599843.4277004537, 183201.0055387035], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3537600.0000, 
sim time next is 3538200.0000, 
raw observation next is [23.16666666666667, 88.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3551492234382568, 6.911199999999999, 6.9112, 77.3421103, 597344.8753419169, 597344.8753419173, 217485.7130357064], 
processed observation next is [1.0, 0.9565217391304348, 0.6893939393939396, 0.88, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.07878460491179543, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.2212388427192285, 0.2212388427192286, 0.5304529586236741], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.07894423], dtype=float32), 0.79790026]. 
=============================================
[2019-03-23 15:54:44,389] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.3875383e-20 4.4379019e-21 3.5617282e-20 9.5303291e-21], sum to 1.0000
[2019-03-23 15:54:44,395] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0719
[2019-03-23 15:54:44,402] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 573936.993044916 W.
[2019-03-23 15:54:44,406] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.5032580013459319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 573936.993044916, 573936.9930449163, 142467.6417668924], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3618600.0000, 
sim time next is 3619200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 1.0, 0.3415108250322626, 6.911199999999999, 6.9112, 77.3421103, 575979.3791484954, 575979.3791484956, 213182.5407961962], 
processed observation next is [1.0, 0.9130434782608695, 0.6363636363636364, 0.94, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.5, 0.05930117861751802, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.2133256959809242, 0.2133256959809243, 0.5199574165760883], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.48639017], dtype=float32), -0.747763]. 
=============================================
[2019-03-23 15:54:50,499] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.5099386e-21 5.4217521e-21 1.1719605e-19 2.8638075e-20], sum to 1.0000
[2019-03-23 15:54:50,505] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8104
[2019-03-23 15:54:50,509] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 548233.2775421429 W.
[2019-03-23 15:54:50,514] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 89.0, 1.0, 2.0, 0.240364256937167, 1.0, 1.0, 0.240364256937167, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 548233.2775421429, 548233.2775421429, 174119.4683185463], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3736200.0000, 
sim time next is 3736800.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.4778357907014849, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 544091.191234209, 544091.191234209, 136070.3457126881], 
processed observation next is [1.0, 0.2608695652173913, 0.5909090909090909, 0.88, 1.0, 1.0, 0.3472947383768561, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20151525601267, 0.20151525601267, 0.33187889198216614], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.36434865], dtype=float32), -1.2515246]. 
=============================================
[2019-03-23 15:54:51,060] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 8.2364934e-21 1.4509305e-20 2.5451624e-19 2.8361823e-20], sum to 1.0000
[2019-03-23 15:54:51,070] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7717
[2019-03-23 15:54:51,076] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 603722.9901659493 W.
[2019-03-23 15:54:51,084] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 73.0, 1.0, 2.0, 0.2647142939397769, 1.0, 2.0, 0.2647142939397769, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 603722.9901659493, 603722.9901659493, 177658.3830324924], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3744000.0000, 
sim time next is 3744600.0000, 
raw observation next is [23.0, 72.33333333333334, 1.0, 2.0, 0.3612828902971191, 1.0, 2.0, 0.3612828902971191, 0.0, 2.0, 0.0, 6.9112, 6.9112, 81.5106177893273, 824230.5757761069, 824230.5757761069, 196298.9661534341], 
processed observation next is [1.0, 0.34782608695652173, 0.6818181818181818, 0.7233333333333334, 1.0, 1.0, 0.20160361287139883, 1.0, 1.0, 0.20160361287139883, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5359261622121156, 0.30527058362078036, 0.30527058362078036, 0.47877796622788804], 
reward next is 0.5212, 
noisyNet noise sample is [array([-0.18934827], dtype=float32), -0.13181683]. 
=============================================
[2019-03-23 15:54:52,797] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.5827895e-18 0.0000000e+00 8.2299732e-33 6.7497497e-27], sum to 1.0000
[2019-03-23 15:54:52,807] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3858
[2019-03-23 15:54:52,814] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6086713041665125, 6.911199999999999, 6.9112, 77.32846344354104, 353391.2034483018, 353391.2034483021, 114700.6490723632], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3810000.0000, 
sim time next is 3810600.0000, 
raw observation next is [17.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6083203290779883, 6.9112, 6.9112, 77.32846344354104, 353187.3552911631, 353187.3552911631, 114671.4185189826], 
processed observation next is [0.0, 0.08695652173913043, 0.4090909090909091, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.44045761296855473, 0.0, 0.0, 0.5084288129206541, 0.13081013158931967, 0.13081013158931967, 0.27968638663166484], 
reward next is 0.7203, 
noisyNet noise sample is [array([-0.3284367], dtype=float32), 0.32459393]. 
=============================================
[2019-03-23 15:54:56,581] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9999189e-01 8.1523403e-06 7.1288413e-23 1.1521729e-17 1.6617523e-12], sum to 1.0000
[2019-03-23 15:54:56,590] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6073
[2019-03-23 15:54:56,595] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.5, 65.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6280779515138533, 6.9112, 6.9112, 77.32846344354104, 363649.5897527278, 363649.5897527278, 117113.0470368665], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3851400.0000, 
sim time next is 3852000.0000, 
raw observation next is [22.0, 64.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6454944362696852, 6.911199999999999, 6.9112, 77.32846344354104, 373262.5345427081, 373262.5345427084, 119020.2582992526], 
processed observation next is [0.0, 0.6086956521739131, 0.6363636363636364, 0.64, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4935634803852646, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13824538316396595, 0.1382453831639661, 0.2902933129250063], 
reward next is 0.7097, 
noisyNet noise sample is [array([0.2693603], dtype=float32), -0.19955109]. 
=============================================
[2019-03-23 15:54:56,619] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[75.499725]
 [75.48205 ]
 [75.47203 ]
 [75.46086 ]
 [75.46419 ]], R is [[75.48591614]
 [75.44541168]
 [75.40991211]
 [75.37911224]
 [75.35240936]].
[2019-03-23 15:54:57,173] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9998665e-01 1.3406736e-05 9.9516539e-23 1.9558305e-18 5.2685021e-13], sum to 1.0000
[2019-03-23 15:54:57,186] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6668
[2019-03-23 15:54:57,192] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.83333333333334, 69.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5133450820598364, 6.911199999999999, 6.9112, 77.32846344354104, 298589.5943064843, 298589.5943064846, 98004.2171980097], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3885000.0000, 
sim time next is 3885600.0000, 
raw observation next is [18.66666666666667, 71.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5156279300378109, 6.9112, 6.9112, 77.32846344354104, 299917.8362301583, 299917.8362301583, 98541.51851362003], 
processed observation next is [0.0, 1.0, 0.4848484848484851, 0.71, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.30803990005401566, 0.0, 0.0, 0.5084288129206541, 0.11108068008524381, 0.11108068008524381, 0.2403451671063903], 
reward next is 0.7597, 
noisyNet noise sample is [array([-1.4093273], dtype=float32), -0.84622353]. 
=============================================
[2019-03-23 15:55:04,103] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 2.3835500e-12 3.0533587e-21 1.4266948e-18 2.9874407e-16], sum to 1.0000
[2019-03-23 15:55:04,110] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6412
[2019-03-23 15:55:04,113] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.5, 85.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5544561929362533, 6.9112, 6.9112, 77.32846344354104, 322510.0004704634, 322510.0004704634, 108862.723014708], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4001400.0000, 
sim time next is 4002000.0000, 
raw observation next is [17.66666666666667, 84.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5583705508901254, 6.9112, 6.9112, 77.32846344354104, 324787.6216207044, 324787.6216207044, 109994.6742970334], 
processed observation next is [1.0, 0.30434782608695654, 0.4393939393939396, 0.8466666666666666, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.36910078698589355, 0.0, 0.0, 0.5084288129206541, 0.12029171171137201, 0.12029171171137201, 0.26827969340739855], 
reward next is 0.7317, 
noisyNet noise sample is [array([1.6622679], dtype=float32), 0.8521605]. 
=============================================
[2019-03-23 15:55:04,133] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[49.22099 ]
 [49.382874]
 [49.53114 ]
 [49.771442]
 [49.972248]], R is [[49.29432297]
 [49.53586197]
 [49.77780914]
 [50.01844788]
 [50.26267624]].
[2019-03-23 15:55:08,493] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.4378366e-31 4.8930701e-34 4.8108084e-31 1.2168693e-30], sum to 1.0000
[2019-03-23 15:55:08,499] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8368
[2019-03-23 15:55:08,507] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 879270.9926027141 W.
[2019-03-23 15:55:08,519] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.83333333333334, 73.0, 1.0, 2.0, 0.3852976704067729, 1.0, 2.0, 0.3852976704067729, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 879270.9926027141, 879270.9926027141, 199298.5687395303], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4104600.0000, 
sim time next is 4105200.0000, 
raw observation next is [22.66666666666667, 73.0, 1.0, 2.0, 0.2205311387567006, 1.0, 2.0, 0.2205311387567006, 1.0, 1.0, 0.4433309593821393, 6.911199999999999, 6.9112, 77.3421103, 754767.2491616667, 754767.249161667, 226919.3043611563], 
processed observation next is [1.0, 0.5217391304347826, 0.6666666666666669, 0.73, 1.0, 1.0, 0.025663923445875744, 1.0, 1.0, 0.025663923445875744, 1.0, 0.5, 0.20475851340305615, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.2795434256154321, 0.2795434256154322, 0.5534617179540398], 
reward next is 0.4465, 
noisyNet noise sample is [array([-3.1197581], dtype=float32), 0.19554722]. 
=============================================
[2019-03-23 15:55:16,532] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.2273060e-17 1.7697718e-22 1.9217380e-20 2.5784962e-19], sum to 1.0000
[2019-03-23 15:55:16,538] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8502
[2019-03-23 15:55:16,546] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5727291741020031, 6.911199999999999, 6.9112, 77.32846344354104, 333142.4682113059, 333142.4682113062, 104380.0610647231], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4251600.0000, 
sim time next is 4252200.0000, 
raw observation next is [16.0, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5492436785952155, 6.9112, 6.9112, 77.32846344354104, 319477.0462490141, 319477.0462490141, 103552.9479126946], 
processed observation next is [1.0, 0.21739130434782608, 0.36363636363636365, 0.95, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.356062397993165, 0.0, 0.0, 0.5084288129206541, 0.11832483194407929, 0.11832483194407929, 0.25256816564071854], 
reward next is 0.7474, 
noisyNet noise sample is [array([1.9371847], dtype=float32), -0.6254294]. 
=============================================
[2019-03-23 15:55:20,435] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 6.3270759e-13 3.0031105e-13 1.5595399e-12 8.4781981e-13], sum to 1.0000
[2019-03-23 15:55:20,445] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6580
[2019-03-23 15:55:20,450] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.5, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7440725881643488, 7.173959027233613, 6.9112, 77.32765558178191, 514346.967117195, 429009.1009697106, 129801.7239022266], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4343400.0000, 
sim time next is 4344000.0000, 
raw observation next is [18.66666666666667, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7515284167884102, 7.230490158588736, 6.9112, 77.32747824505847, 536635.0766144805, 432937.4848875269, 130903.6808265128], 
processed observation next is [1.0, 0.2608695652173913, 0.4848484848484851, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6450405954120146, 0.031929015858873554, 0.0, 0.5084223353149617, 0.19875373207943722, 0.16034721662500995, 0.31927727030856784], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.46912536], dtype=float32), -0.26741624]. 
=============================================
[2019-03-23 15:55:20,470] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[18.78528 ]
 [19.190802]
 [19.429773]
 [20.052841]
 [19.900116]], R is [[18.1101265 ]
 [17.92902565]
 [17.74973488]
 [17.57223701]
 [18.09893036]].
[2019-03-23 15:55:23,280] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 15:55:23,282] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:55:23,284] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:55:23,284] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:55:23,286] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:55:23,286] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:55:23,289] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:55:23,289] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:55:23,290] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:55:23,290] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:55:23,292] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:55:23,315] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run82
[2019-03-23 15:55:23,346] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run82
[2019-03-23 15:55:23,375] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run82
[2019-03-23 15:55:23,376] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run82
[2019-03-23 15:55:23,376] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run82
[2019-03-23 15:56:23,516] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05417401], dtype=float32), 0.3535356]
[2019-03-23 15:56:23,519] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.4, 80.66666666666667, 1.0, 2.0, 0.528071289607877, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 600971.1010563745, 600971.1010563741, 150945.9777029967]
[2019-03-23 15:56:23,521] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:56:23,524] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.5548990e-04 9.9974424e-01 3.2251187e-13 4.9577714e-10 2.3814606e-07], sampled 0.025362627426111173
[2019-03-23 15:56:23,877] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05417401], dtype=float32), 0.3535356]
[2019-03-23 15:56:23,879] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.63333333333333, 79.0, 1.0, 2.0, 0.5299296545111871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 603192.7551957308, 603192.7551957308, 151100.0890920353]
[2019-03-23 15:56:23,881] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:56:23,883] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.7851586e-04 9.9972123e-01 4.3367022e-13 6.1937105e-10 2.7970421e-07], sampled 0.9054171496750176
[2019-03-23 15:56:40,589] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05417401], dtype=float32), 0.3535356]
[2019-03-23 15:56:40,592] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.183662725, 58.88291814, 1.0, 2.0, 0.2051609763188914, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 222741.2051740127, 222741.2051740124, 74269.02674017267]
[2019-03-23 15:56:40,593] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:56:40,595] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.9143041e-04 9.9940753e-01 4.9416643e-12 3.8579042e-09 1.0289855e-06], sampled 0.29315877331615003
[2019-03-23 15:56:51,549] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05417401], dtype=float32), 0.3535356]
[2019-03-23 15:56:51,550] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [11.7450373445, 99.29226450833335, 1.0, 2.0, 0.4517386645977936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 490557.3805523637, 490557.3805523637, 100131.7913154994]
[2019-03-23 15:56:51,551] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:56:51,555] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.4112816e-04 9.9955827e-01 1.9405655e-12 1.8981876e-09 6.2512578e-07], sampled 0.9409032132540401
[2019-03-23 15:56:55,287] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05417401], dtype=float32), 0.3535356]
[2019-03-23 15:56:55,290] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.36041133166667, 52.93062296666667, 1.0, 2.0, 0.4762193134538692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 543194.0443326746, 543194.0443326746, 141722.1507337477]
[2019-03-23 15:56:55,292] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:56:55,294] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.6042512e-04 9.9973935e-01 3.4676084e-13 5.2397919e-10 2.4803188e-07], sampled 0.5605950267738362
[2019-03-23 15:57:04,128] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05417401], dtype=float32), 0.3535356]
[2019-03-23 15:57:04,129] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [28.43333333333333, 53.0, 1.0, 2.0, 0.4944716995893358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564060.1758542956, 564060.1758542956, 141158.0246377012]
[2019-03-23 15:57:04,130] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:57:04,134] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.1242202e-04 9.9968719e-01 6.4189826e-13 8.3202872e-10 3.4616758e-07], sampled 0.877574603094144
[2019-03-23 15:57:09,206] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8507.8557 1773192252.0884 176.0000
[2019-03-23 15:57:09,500] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8593.3700 1705971665.3929 468.0000
[2019-03-23 15:57:09,627] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8853.8870 1663789829.7861 107.0000
[2019-03-23 15:57:09,637] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8571.4859 1683286213.1971 215.0000
[2019-03-23 15:57:09,666] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9057.6361 1656195127.1072 82.0000
[2019-03-23 15:57:10,683] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 2025000, evaluation results [2025000.0, 8507.855667642265, 1773192252.0883822, 176.0, 9057.636092974226, 1656195127.1072328, 82.0, 8853.886960296688, 1663789829.7860894, 107.0, 8593.369991442276, 1705971665.3928819, 468.0, 8571.485906692045, 1683286213.197115, 215.0]
[2019-03-23 15:57:14,842] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.294146e-06 9.999957e-01 5.070564e-20 9.663421e-16 1.535590e-11], sum to 1.0000
[2019-03-23 15:57:14,852] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6643
[2019-03-23 15:57:14,856] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 68.33333333333333, 1.0, 2.0, 0.5085512780601159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 579590.9812909074, 579590.9812909076, 143594.8234199145], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4462800.0000, 
sim time next is 4463400.0000, 
raw observation next is [26.0, 69.16666666666667, 1.0, 2.0, 0.5144028676903374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 585999.9553724402, 585999.9553724402, 144553.6983886851], 
processed observation next is [0.0, 0.6521739130434783, 0.8181818181818182, 0.6916666666666668, 1.0, 1.0, 0.3930035846129217, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21703702050831117, 0.21703702050831117, 0.35256999606996364], 
reward next is 0.6474, 
noisyNet noise sample is [array([0.4165652], dtype=float32), 1.6216674]. 
=============================================
[2019-03-23 15:57:16,668] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.8685305e-06 9.9999011e-01 3.0804754e-18 5.1380375e-14 7.6011905e-11], sum to 1.0000
[2019-03-23 15:57:16,675] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3544
[2019-03-23 15:57:16,681] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.4629191740116289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 527994.0726728784, 527994.0726728784, 135777.4656362268], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4491600.0000, 
sim time next is 4492200.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.4627444766950154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 527794.5967232791, 527794.5967232793, 135758.4011907847], 
processed observation next is [0.0, 1.0, 0.5909090909090909, 0.94, 1.0, 1.0, 0.3284305958687692, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19547948026788114, 0.19547948026788123, 0.3311180516848407], 
reward next is 0.6689, 
noisyNet noise sample is [array([-1.7416207], dtype=float32), 0.25446483]. 
=============================================
[2019-03-23 15:57:22,736] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.7328744e-07 9.9999976e-01 1.0701800e-19 2.5155627e-15 3.3461338e-11], sum to 1.0000
[2019-03-23 15:57:22,745] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3370
[2019-03-23 15:57:22,749] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.33333333333333, 82.0, 1.0, 2.0, 0.227278084272239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 246770.3940097448, 246770.3940097448, 78350.76937467974], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4675200.0000, 
sim time next is 4675800.0000, 
raw observation next is [15.16666666666667, 82.0, 1.0, 2.0, 0.2225859754265449, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 241674.6047906237, 241674.6047906234, 77198.79126156302], 
processed observation next is [1.0, 0.08695652173913043, 0.3257575757575759, 0.82, 1.0, 1.0, 0.028232469283181114, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08950911288541619, 0.08950911288541608, 0.18828973478430006], 
reward next is 0.8117, 
noisyNet noise sample is [array([1.8160205], dtype=float32), 2.255347]. 
=============================================
[2019-03-23 15:57:28,920] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0581424e-07 9.9999988e-01 1.6825236e-21 1.2248424e-15 7.4681997e-12], sum to 1.0000
[2019-03-23 15:57:28,928] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1743
[2019-03-23 15:57:28,932] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.16666666666666, 64.33333333333334, 1.0, 2.0, 0.4144185396213124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 470867.8784972291, 470867.8784972294, 128623.0111929598], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4729800.0000, 
sim time next is 4730400.0000, 
raw observation next is [24.0, 65.0, 1.0, 2.0, 0.415798769009755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 472301.2863818326, 472301.2863818329, 128646.9898317592], 
processed observation next is [1.0, 0.782608695652174, 0.7272727272727273, 0.65, 1.0, 1.0, 0.2697484612621937, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1749264023636417, 0.17492640236364182, 0.31377314593112], 
reward next is 0.6862, 
noisyNet noise sample is [array([-1.5537322], dtype=float32), 0.31783015]. 
=============================================
[2019-03-23 15:57:46,138] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.1429859e-09 1.0000000e+00 4.7964895e-19 1.6061970e-15 4.2116094e-12], sum to 1.0000
[2019-03-23 15:57:46,149] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1832
[2019-03-23 15:57:46,154] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666667, 87.16666666666667, 1.0, 2.0, 0.3944512875533671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 445882.5616214953, 445882.561621495, 125132.8079156119], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5105400.0000, 
sim time next is 5106000.0000, 
raw observation next is [20.33333333333334, 86.33333333333334, 1.0, 2.0, 0.3943896596013369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 446032.0009268151, 446032.0009268151, 125259.8898420177], 
processed observation next is [0.0, 0.08695652173913043, 0.5606060606060609, 0.8633333333333334, 1.0, 1.0, 0.24298707450167106, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1651970373803019, 0.1651970373803019, 0.3055119264439456], 
reward next is 0.6945, 
noisyNet noise sample is [array([-0.4279574], dtype=float32), -0.06024957]. 
=============================================
[2019-03-23 15:57:46,177] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[67.814735]
 [67.72932 ]
 [67.67152 ]
 [67.64393 ]
 [67.63682 ]], R is [[67.77459717]
 [67.79165649]
 [67.80819702]
 [67.82252502]
 [67.83496094]].
[2019-03-23 15:57:48,627] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2997921e-07 9.9999988e-01 8.4061951e-19 5.4390472e-14 1.6998387e-10], sum to 1.0000
[2019-03-23 15:57:48,633] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8912
[2019-03-23 15:57:48,638] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 80.83333333333334, 1.0, 2.0, 0.5184935019522673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 589895.922885592, 589895.922885592, 145625.873598064], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5141400.0000, 
sim time next is 5142000.0000, 
raw observation next is [25.0, 78.66666666666667, 1.0, 2.0, 0.5256338423851808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 597475.9917698953, 597475.9917698953, 146825.0516508891], 
processed observation next is [0.0, 0.5217391304347826, 0.7727272727272727, 0.7866666666666667, 1.0, 1.0, 0.40704230298147603, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22128740435922048, 0.22128740435922048, 0.3581098820753393], 
reward next is 0.6419, 
noisyNet noise sample is [array([1.4017978], dtype=float32), -1.1333455]. 
=============================================
[2019-03-23 15:57:48,647] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[63.60969 ]
 [63.634823]
 [63.621403]
 [63.62723 ]
 [63.61616 ]], R is [[63.58967209]
 [63.59859085]
 [63.60986328]
 [63.62216568]
 [63.63544846]].
[2019-03-23 15:57:48,864] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.2769632e-08 1.0000000e+00 1.2614844e-21 8.5818546e-16 1.7975480e-12], sum to 1.0000
[2019-03-23 15:57:48,872] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8261
[2019-03-23 15:57:48,876] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.83333333333333, 1.0, 2.0, 0.4222681988924745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 479958.2522027525, 479958.2522027525, 129526.2586143676], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5097000.0000, 
sim time next is 5097600.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.4198812988407658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 476935.7398152747, 476935.739815275, 129039.0891290468], 
processed observation next is [0.0, 0.0, 0.6363636363636364, 0.78, 1.0, 1.0, 0.2748516235509572, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1766428665982499, 0.17664286659825001, 0.31472948568060194], 
reward next is 0.6853, 
noisyNet noise sample is [array([0.3034093], dtype=float32), -0.10899868]. 
=============================================
[2019-03-23 15:57:50,324] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.2448529e-09 1.0000000e+00 1.0413134e-20 4.9480743e-16 1.3909250e-12], sum to 1.0000
[2019-03-23 15:57:50,330] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4030
[2019-03-23 15:57:50,333] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.66666666666666, 67.33333333333334, 1.0, 2.0, 0.5678783334034964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 641775.3716497252, 641775.3716497252, 153637.9433136864], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5146800.0000, 
sim time next is 5147400.0000, 
raw observation next is [27.83333333333334, 66.66666666666666, 1.0, 2.0, 0.5685388362369502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 642269.2685259467, 642269.2685259467, 153797.1257965445], 
processed observation next is [0.0, 0.5652173913043478, 0.9015151515151518, 0.6666666666666665, 1.0, 1.0, 0.46067354529618776, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23787750686146172, 0.23787750686146172, 0.37511494096718173], 
reward next is 0.6249, 
noisyNet noise sample is [array([-0.19195119], dtype=float32), 0.3594261]. 
=============================================
[2019-03-23 15:57:50,657] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.7004479e-08 9.9999988e-01 3.4914239e-21 3.6745602e-15 2.2238197e-12], sum to 1.0000
[2019-03-23 15:57:50,664] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7546
[2019-03-23 15:57:50,669] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 74.66666666666667, 1.0, 2.0, 0.4548495096989603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 518936.3414274746, 518936.3414274749, 135341.0234782863], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5133000.0000, 
sim time next is 5133600.0000, 
raw observation next is [24.0, 74.0, 1.0, 2.0, 0.457347639388105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 521818.2474313041, 521818.2474313041, 135740.8212650963], 
processed observation next is [0.0, 0.43478260869565216, 0.7272727272727273, 0.74, 1.0, 1.0, 0.32168454923513123, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19326601756714964, 0.19326601756714964, 0.33107517381730805], 
reward next is 0.6689, 
noisyNet noise sample is [array([-1.8973098], dtype=float32), 0.722668]. 
=============================================
[2019-03-23 15:57:52,168] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.0769498e-09 1.0000000e+00 2.8641584e-19 1.9152286e-16 1.1269426e-12], sum to 1.0000
[2019-03-23 15:57:52,176] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2892
[2019-03-23 15:57:52,180] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 84.66666666666667, 1.0, 2.0, 0.5113176646236545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 582506.7669803014, 582506.7669803011, 140050.2541670307], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5192400.0000, 
sim time next is 5193000.0000, 
raw observation next is [21.5, 85.5, 1.0, 2.0, 0.4549093991982819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 518049.1965510637, 518049.196551064, 133730.0767880293], 
processed observation next is [1.0, 0.08695652173913043, 0.6136363636363636, 0.855, 1.0, 1.0, 0.3186367489978523, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19187007279669024, 0.19187007279669036, 0.32617091899519346], 
reward next is 0.6738, 
noisyNet noise sample is [array([0.9146932], dtype=float32), 0.19781525]. 
=============================================
[2019-03-23 15:57:52,200] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[69.394775]
 [69.243355]
 [69.0792  ]
 [68.755775]
 [68.62426 ]], R is [[69.58088684]
 [69.54349518]
 [69.47037506]
 [69.45320892]
 [69.43610382]].
[2019-03-23 15:57:53,154] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.3573469e-08 9.9999988e-01 5.4303911e-18 2.2335274e-13 2.4279756e-12], sum to 1.0000
[2019-03-23 15:57:53,160] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1774
[2019-03-23 15:57:53,165] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 83.83333333333333, 1.0, 2.0, 0.458946535330046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 523514.5916442605, 523514.5916442605, 135479.6243041419], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5181000.0000, 
sim time next is 5181600.0000, 
raw observation next is [22.26666666666667, 83.66666666666667, 1.0, 2.0, 0.4555483154006109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 519554.9521824036, 519554.9521824033, 134926.8970514923], 
processed observation next is [0.0, 1.0, 0.6484848484848486, 0.8366666666666667, 1.0, 1.0, 0.3194353942507636, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19242776006755688, 0.19242776006755677, 0.3290899928085178], 
reward next is 0.6709, 
noisyNet noise sample is [array([1.1592467], dtype=float32), 0.37944928]. 
=============================================
[2019-03-23 15:57:58,587] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 15:57:58,590] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:57:58,593] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:57:58,593] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:57:58,594] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:57:58,595] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:57:58,595] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:57:58,595] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:57:58,596] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:57:58,597] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:57:58,599] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:57:58,619] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run83
[2019-03-23 15:57:58,620] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run83
[2019-03-23 15:57:58,620] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run83
[2019-03-23 15:57:58,713] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run83
[2019-03-23 15:57:58,740] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run83
[2019-03-23 15:57:59,835] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05737866], dtype=float32), 0.35782042]
[2019-03-23 15:57:59,836] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [13.0, 81.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3541918855814386, 6.9112, 6.9112, 95.55338769695034, 206049.6229381434, 206049.6229381434, 64822.96482876038]
[2019-03-23 15:57:59,836] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:57:59,837] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 1.1878683e-24 1.2982876e-25 1.8486285e-24 1.4736110e-27], sampled 0.4096832241134283
[2019-03-23 15:58:14,322] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05737866], dtype=float32), 0.35782042]
[2019-03-23 15:58:14,324] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.05, 81.83333333333334, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7639630972896921, 7.515774496050845, 6.9112, 95.55150884617989, 677635.5093914395, 435009.8870996157, 140286.6334107801]
[2019-03-23 15:58:14,326] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:58:14,328] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0000000e+00 2.5037183e-32 3.6229003e-27 3.8335878e-27 1.2005511e-31], sampled 0.1673786566519121
[2019-03-23 15:58:14,329] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 677635.5093914395 W.
[2019-03-23 15:58:23,587] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05737866], dtype=float32), 0.35782042]
[2019-03-23 15:58:23,589] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 72.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5391961642354114, 6.911199999999999, 6.9112, 77.32846344354104, 313630.8520011691, 313630.8520011694, 105619.9899584889]
[2019-03-23 15:58:23,591] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:58:23,592] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 1.3765499e-22 6.9082182e-24 9.9934818e-23 1.5867013e-25], sampled 0.2676556854911766
[2019-03-23 15:58:34,205] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05737866], dtype=float32), 0.35782042]
[2019-03-23 15:58:34,206] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [27.20840807833333, 45.00797547000001, 1.0, 1.0, 0.4162183746449603, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 95.5531857483034, 470412.2862774308, 470412.2862774308, 131428.8924395707]
[2019-03-23 15:58:34,207] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:58:34,210] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 2.2817108e-28 2.7783582e-26 1.0227762e-25 1.4478001e-29], sampled 0.6450747516775442
[2019-03-23 15:58:56,409] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05737866], dtype=float32), 0.35782042]
[2019-03-23 15:58:56,409] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.56666666666667, 93.0, 1.0, 2.0, 0.4715985180736599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338695195744, 538073.438888766, 538073.438888766, 141972.4535659984]
[2019-03-23 15:58:56,412] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:58:56,414] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 1.6284389e-29 1.4774287e-25 2.2504222e-25 1.8029164e-29], sampled 0.8489967323436243
[2019-03-23 15:59:12,892] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05737866], dtype=float32), 0.35782042]
[2019-03-23 15:59:12,893] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.78333333333333, 89.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8065330405329525, 7.622771918819991, 6.9112, 77.32683273839741, 691295.8842126778, 460196.7526713553, 140578.7753428235]
[2019-03-23 15:59:12,895] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:59:12,904] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 6.9348560e-25 7.5391353e-22 1.2206175e-21 4.6057797e-25], sampled 0.2933964252943818
[2019-03-23 15:59:12,908] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 691295.8842126778 W.
[2019-03-23 15:59:24,543] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05737866], dtype=float32), 0.35782042]
[2019-03-23 15:59:24,545] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.25557392, 74.98332886333333, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7912894273573577, 7.698931270474901, 6.9112, 95.55097122580807, 763365.9731434354, 447238.3237164061, 145931.7644822321]
[2019-03-23 15:59:24,545] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:59:24,549] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 1.6276778e-33 2.4325867e-28 2.8344941e-28 5.9549794e-33], sampled 0.02500216160262958
[2019-03-23 15:59:24,550] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 763365.9731434354 W.
[2019-03-23 15:59:45,027] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6481.6076 1678885180.2952 3057.0000
[2019-03-23 15:59:45,150] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6328.7217 1723294598.4314 3425.0000
[2019-03-23 15:59:45,167] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6862.2842 1793014293.7888 2409.0000
[2019-03-23 15:59:45,186] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6294.9961 1685630448.6673 3228.0000
[2019-03-23 15:59:45,319] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6553.1725 1698634175.0084 2957.0000
[2019-03-23 15:59:46,336] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 2050000, evaluation results [2050000.0, 6862.284208925443, 1793014293.78876, 2409.0, 6481.607577760913, 1678885180.2951708, 3057.0, 6294.9960618483565, 1685630448.6673346, 3228.0, 6328.721692698646, 1723294598.4313502, 3425.0, 6553.172466661831, 1698634175.0084193, 2957.0]
[2019-03-23 15:59:52,015] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 8.1138233e-33 7.2955792e-26 8.1152143e-26 2.1301951e-31], sum to 1.0000
[2019-03-23 15:59:52,024] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6422
[2019-03-23 15:59:52,029] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.4, 93.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7541210675282539, 7.199366179122396, 6.9112, 77.32773394922212, 524364.0691332506, 430774.4710774206, 133847.4102896545], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5422200.0000, 
sim time next is 5422800.0000, 
raw observation next is [19.4, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7669363281382925, 7.322897339266633, 6.9112, 77.32725558725515, 573067.6312390377, 439358.8446511698, 134451.4110632594], 
processed observation next is [1.0, 0.782608695652174, 0.5181818181818181, 0.93, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6670518973404179, 0.041169733926663274, 0.0, 0.5084208713567039, 0.21224727082927322, 0.16272549801895178, 0.3279302708859986], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0752461], dtype=float32), 0.59315187]. 
=============================================
[2019-03-23 15:59:57,819] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.8228965e-28 3.1922830e-22 4.8393992e-21 6.8132622e-26], sum to 1.0000
[2019-03-23 15:59:57,825] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5856
[2019-03-23 15:59:57,828] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.18333333333334, 86.5, 1.0, 1.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3167296724938682, 6.911199999999999, 6.9112, 77.3421103, 538755.0906845533, 538755.0906845535, 203919.680844755], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5532600.0000, 
sim time next is 5533200.0000, 
raw observation next is [21.1, 87.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.77895421337944, 7.370082455556578, 6.9112, 77.32733985635993, 591670.9615109564, 442637.4912121895, 138432.5859817752], 
processed observation next is [1.0, 0.043478260869565216, 0.5954545454545456, 0.87, 0.0, 0.5, -0.25, 0.0, 0.5, -0.25, 1.0, 1.0, 0.6842203048277715, 0.045888245555657826, 0.0, 0.5084214254197099, 0.21913739315220607, 0.16393981156007018, 0.33764045361408584], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9089028], dtype=float32), -1.806983]. 
=============================================
[2019-03-23 16:00:01,923] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 4.4838355e-11 7.6657897e-27 1.2837123e-22 5.5043629e-20], sum to 1.0000
[2019-03-23 16:00:01,939] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6006
[2019-03-23 16:00:01,950] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.5, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3642376379980528, 6.911200000000001, 6.9112, 77.32846344354104, 212319.0148919453, 212319.014891945, 60573.61583696151], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5734800.0000, 
sim time next is 5735400.0000, 
raw observation next is [15.78333333333333, 61.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3693625190242615, 6.911199999999998, 6.9112, 77.32846344354104, 215113.5776730375, 215113.5776730381, 60968.15010052484], 
processed observation next is [0.0, 0.391304347826087, 0.3537878787878786, 0.61, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.09908931289180214, -1.7763568394002506e-16, 0.0, 0.5084288129206541, 0.07967169543445833, 0.07967169543445855, 0.14870280512323134], 
reward next is 0.8513, 
noisyNet noise sample is [array([-1.6321939], dtype=float32), 0.6722103]. 
=============================================
[2019-03-23 16:00:02,647] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 2.0448775e-11 3.9393216e-25 8.5837932e-22 5.2702019e-20], sum to 1.0000
[2019-03-23 16:00:02,655] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7476
[2019-03-23 16:00:02,663] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.8, 97.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7437398687293157, 7.130656698861264, 6.9112, 77.32789371876466, 497274.3989326417, 425999.8769338996, 131824.4098390299], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5630400.0000, 
sim time next is 5631000.0000, 
raw observation next is [18.8, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.753110170552833, 7.217570513427861, 6.9112, 77.32754747522951, 531541.3537326631, 432039.6559598289, 132409.6894914016], 
processed observation next is [0.0, 0.17391304347826086, 0.49090909090909096, 0.97, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6473002436469044, 0.030637051342786138, 0.0, 0.5084227904981131, 0.19686716804913448, 0.16001468739252922, 0.32295046217415024], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6602473], dtype=float32), 2.059011]. 
=============================================
[2019-03-23 16:00:02,674] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[64.185776]
 [62.303364]
 [62.27473 ]
 [61.030632]
 [58.840237]], R is [[65.99546814]
 [65.33551788]
 [65.28171539]
 [64.62889862]
 [63.9826088 ]].
[2019-03-23 16:00:04,360] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.2493423e-13 1.4797576e-26 3.8119109e-23 1.9508536e-21], sum to 1.0000
[2019-03-23 16:00:04,369] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9655
[2019-03-23 16:00:04,374] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.78333333333333, 61.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3991355522576067, 6.911199999999999, 6.9112, 77.32846344354104, 232143.2311165886, 232143.2311165889, 68497.47382288388], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5781000.0000, 
sim time next is 5781600.0000, 
raw observation next is [16.6, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3949699622631889, 6.9112, 6.9112, 77.32846344354104, 229719.8892953692, 229719.8892953692, 67979.30591968344], 
processed observation next is [0.0, 0.9565217391304348, 0.390909090909091, 0.62, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.13567137466169849, 0.0, 0.0, 0.5084288129206541, 0.08508144047976637, 0.08508144047976637, 0.1658031851699596], 
reward next is 0.8342, 
noisyNet noise sample is [array([-0.12300998], dtype=float32), 0.5684534]. 
=============================================
[2019-03-23 16:00:07,086] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.4796056e-14 6.7316065e-24 1.6279362e-21 9.8346120e-22], sum to 1.0000
[2019-03-23 16:00:07,092] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8206
[2019-03-23 16:00:07,103] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.6, 43.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4932568084516842, 6.911199999999999, 6.9112, 77.32846344354104, 286901.7130519141, 286901.7130519144, 85281.2480215299], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5755200.0000, 
sim time next is 5755800.0000, 
raw observation next is [21.6, 42.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4953139201771897, 6.9112, 6.9112, 77.32846344354104, 288098.5818561611, 288098.5818561611, 84751.48002740832], 
processed observation next is [0.0, 0.6086956521739131, 0.6181818181818183, 0.4266666666666666, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.27901988596741395, 0.0, 0.0, 0.5084288129206541, 0.10670317846524487, 0.10670317846524487, 0.20671092689611786], 
reward next is 0.7933, 
noisyNet noise sample is [array([1.3415465], dtype=float32), -0.019426221]. 
=============================================
[2019-03-23 16:00:09,090] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.6260303e-14 1.6315907e-30 1.6262401e-23 5.4085875e-23], sum to 1.0000
[2019-03-23 16:00:09,096] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6973
[2019-03-23 16:00:09,099] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.31666666666667, 44.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4589452019811264, 6.911199999999999, 6.9112, 77.32846344354104, 266938.9674412486, 266938.9674412489, 76769.69985447769], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5748600.0000, 
sim time next is 5749200.0000, 
raw observation next is [20.5, 44.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4631500264001044, 6.911199999999999, 6.9112, 77.32846344354104, 269385.3212347715, 269385.3212347718, 77794.11878037686], 
processed observation next is [0.0, 0.5652173913043478, 0.5681818181818182, 0.44, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.23307146628586345, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09977234119806352, 0.09977234119806364, 0.18974175312287037], 
reward next is 0.8103, 
noisyNet noise sample is [array([-0.770796], dtype=float32), -0.99565816]. 
=============================================
[2019-03-23 16:00:13,766] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9997389e-01 2.6129546e-05 4.7582001e-13 1.8799467e-11 2.8343217e-10], sum to 1.0000
[2019-03-23 16:00:13,772] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6924
[2019-03-23 16:00:13,777] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.3, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.601739340444491, 6.911199999999999, 6.9112, 77.32846344354104, 349075.7616993653, 349075.7616993656, 114346.5963640981], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5878800.0000, 
sim time next is 5879400.0000, 
raw observation next is [18.2, 83.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5963775744492756, 6.911200000000001, 6.9112, 77.32846344354104, 346088.1246260702, 346088.12462607, 113812.3011738235], 
processed observation next is [1.0, 0.043478260869565216, 0.4636363636363636, 0.835, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.42339653492753665, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1281807868985445, 0.12818078689854445, 0.2775909784727403], 
reward next is 0.7224, 
noisyNet noise sample is [array([-0.293625], dtype=float32), 0.24587563]. 
=============================================
[2019-03-23 16:00:16,827] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 7.4798262e-10 1.4535468e-18 4.0743869e-15 9.8256847e-15], sum to 1.0000
[2019-03-23 16:00:16,832] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7398
[2019-03-23 16:00:16,839] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 542644.0550776119 W.
[2019-03-23 16:00:16,843] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [20.71666666666667, 73.5, 1.0, 2.0, 0.2413082136881865, 1.0, 2.0, 0.2413082136881865, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846157330184, 542644.0550776119, 542644.0550776119, 166918.6584390421], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5907000.0000, 
sim time next is 5907600.0000, 
raw observation next is [21.1, 73.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 1.0, 0.3182923952288731, 6.911200000000001, 6.9112, 77.3421103, 547658.3667656991, 547658.3667656989, 198483.3897762413], 
processed observation next is [1.0, 0.391304347826087, 0.5954545454545456, 0.73, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.026131993184104436, 8.881784197001253e-17, 0.0, 0.5085185399722538, 0.2028364321354441, 0.20283643213544403, 0.48410582872253977], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7646481], dtype=float32), -1.8025233]. 
=============================================
[2019-03-23 16:00:17,654] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.2278323e-29 2.0871568e-28 4.0700435e-27 1.5184278e-29], sum to 1.0000
[2019-03-23 16:00:17,661] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4945
[2019-03-23 16:00:17,669] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1076423.334711607 W.
[2019-03-23 16:00:17,675] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.53333333333333, 57.66666666666667, 1.0, 2.0, 0.4720251312723551, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9284305996416439, 6.942424992153958, 6.9112, 77.32838533978006, 1076423.334711607, 1066282.106164453, 242515.922754479], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5916000.0000, 
sim time next is 5916600.0000, 
raw observation next is [25.8, 56.5, 1.0, 2.0, 0.472638795973854, 1.0, 1.0, 0.472638795973854, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.3284446801801, 1079160.125642324, 1079160.125642324, 218562.1193014392], 
processed observation next is [1.0, 0.4782608695652174, 0.8090909090909091, 0.565, 1.0, 1.0, 0.34079849496731746, 1.0, 0.5, 0.34079849496731746, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084286895529716, 0.399688935423083, 0.399688935423083, 0.5330783397596078], 
reward next is 0.4669, 
noisyNet noise sample is [array([-1.9998089], dtype=float32), 0.7311981]. 
=============================================
[2019-03-23 16:00:22,258] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.7446650e-11 2.6248675e-23 1.8803387e-20 5.0132948e-18], sum to 1.0000
[2019-03-23 16:00:22,267] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0733
[2019-03-23 16:00:22,274] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.4, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5379190632742361, 6.9112, 6.9112, 77.32846344354104, 312887.7697249712, 312887.7697249712, 103486.5620308422], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6134400.0000, 
sim time next is 6135000.0000, 
raw observation next is [19.21666666666667, 69.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5394548457229056, 6.911199999999999, 6.9112, 77.32846344354104, 313781.3661821026, 313781.3661821029, 103437.0437879651], 
processed observation next is [1.0, 0.0, 0.5098484848484849, 0.6916666666666668, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3420783510327223, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11621532080818614, 0.11621532080818625, 0.25228547265357343], 
reward next is 0.7477, 
noisyNet noise sample is [array([-0.07866809], dtype=float32), 0.013814161]. 
=============================================
[2019-03-23 16:00:22,309] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[67.03039 ]
 [68.218254]
 [68.26662 ]
 [68.292435]
 [68.316315]], R is [[66.45025635]
 [66.53334808]
 [66.61803436]
 [66.70426178]
 [66.79197693]].
[2019-03-23 16:00:28,424] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.000000e+00 6.789626e-11 7.594839e-24 9.074987e-20 8.879767e-18], sum to 1.0000
[2019-03-23 16:00:28,431] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8987
[2019-03-23 16:00:28,439] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 812219.583904861 W.
[2019-03-23 16:00:28,442] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.8, 43.0, 1.0, 2.0, 0.3670035870839366, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7022577136730125, 6.911200000000001, 6.9112, 77.32846344354104, 812219.583904861, 812219.5839048608, 190837.9714054197], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6106200.0000, 
sim time next is 6106800.0000, 
raw observation next is [24.6, 44.0, 1.0, 2.0, 0.3539782301570319, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6772934312970961, 6.911200000000001, 6.9112, 77.32846344354104, 783334.3681749076, 783334.3681749074, 187341.2227540042], 
processed observation next is [1.0, 0.6956521739130435, 0.7545454545454546, 0.44, 1.0, 1.0, 0.19247278769628984, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5389906161387087, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2901238400647806, 0.29012384006478054, 0.45692981159513224], 
reward next is 0.5431, 
noisyNet noise sample is [array([0.44577932], dtype=float32), -1.7041183]. 
=============================================
[2019-03-23 16:00:34,434] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 16:00:34,436] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:00:34,436] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:00:34,437] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 4.4977083e-20 6.9349231e-21 1.9105764e-20 4.4265759e-20], sum to 1.0000
[2019-03-23 16:00:34,439] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:00:34,439] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:00:34,439] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:00:34,440] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:00:34,439] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:00:34,443] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:00:34,443] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:00:34,444] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:00:34,444] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9564
[2019-03-23 16:00:34,448] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 598467.3688348107 W.
[2019-03-23 16:00:34,450] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.66666666666667, 57.0, 1.0, 2.0, 0.5267330027221492, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 598467.3688348107, 598467.3688348109, 147094.4861719355], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6288000.0000, 
sim time next is 6288600.0000, 
raw observation next is [28.48333333333333, 58.0, 1.0, 2.0, 0.2641584263818297, 1.0, 1.0, 0.2641584263818297, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 598867.7800447822, 598867.7800447822, 184127.1159810601], 
processed observation next is [0.0, 0.782608695652174, 0.9310606060606059, 0.58, 1.0, 1.0, 0.08019803297728709, 1.0, 0.5, 0.08019803297728709, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22180288149806748, 0.22180288149806748, 0.44909052678307343], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.636016], dtype=float32), -0.6056237]. 
=============================================
[2019-03-23 16:00:34,463] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run84
[2019-03-23 16:00:34,494] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run84
[2019-03-23 16:00:34,540] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run84
[2019-03-23 16:00:34,572] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run84
[2019-03-23 16:00:34,603] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run84
[2019-03-23 16:00:47,612] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05119367], dtype=float32), 0.3564151]
[2019-03-23 16:00:47,614] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.5, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.424237430184017, 6.9112, 6.9112, 77.32846344354104, 246746.5635085895, 246746.5635085895, 74618.86074280177]
[2019-03-23 16:00:47,615] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:00:47,618] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 2.6972466e-11 2.1799982e-14 2.6596645e-13 1.3552619e-12], sampled 0.8781904204767144
[2019-03-23 16:00:56,384] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05119367], dtype=float32), 0.3564151]
[2019-03-23 16:00:56,385] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.26598036, 75.0324045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7030770367905728, 7.11786394375229, 6.9112, 95.55244318960088, 491382.1172943244, 408443.6893664601, 127417.5142736202]
[2019-03-23 16:00:56,387] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:00:56,388] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0000000e+00 1.1045045e-13 3.8249761e-16 3.8442429e-15 1.3297118e-14], sampled 0.10457022387609705
[2019-03-23 16:01:11,985] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05119367], dtype=float32), 0.3564151]
[2019-03-23 16:01:11,988] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.7, 84.5, 1.0, 2.0, 0.4452128297939335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338710743975, 507011.8885789234, 507011.888578923, 137101.0306001609]
[2019-03-23 16:01:11,989] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:01:11,991] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 2.1971171e-14 7.2245200e-17 7.7553077e-16 2.7344959e-15], sampled 0.2975829581389857
[2019-03-23 16:01:15,777] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05119367], dtype=float32), 0.3564151]
[2019-03-23 16:01:15,778] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.16666666666667, 88.16666666666667, 1.0, 2.0, 0.4892360523177286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558267.7261279454, 558267.7261279454, 139754.2107660244]
[2019-03-23 16:01:15,778] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:01:15,782] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 2.1871061e-19 3.7691579e-21 3.8668684e-20 8.0564180e-20], sampled 0.19592205019699505
[2019-03-23 16:01:15,783] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 558267.7261279454 W.
[2019-03-23 16:01:17,376] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05119367], dtype=float32), 0.3564151]
[2019-03-23 16:01:17,378] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 68.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7297631342210609, 7.045237330016673, 6.9112, 77.32800883445347, 463596.5496257573, 420064.2222991189, 128756.3896450421]
[2019-03-23 16:01:17,379] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:01:17,383] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 4.8112123e-16 1.0605618e-17 7.9370958e-17 1.6436214e-16], sampled 0.9661554754097131
[2019-03-23 16:01:32,401] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05119367], dtype=float32), 0.3564151]
[2019-03-23 16:01:32,401] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.62467742333333, 94.50987772833334, 1.0, 1.0, 0.436558930022913, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 95.55316843159184, 495146.0087233016, 495146.0087233016, 134471.258447335]
[2019-03-23 16:01:32,402] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:01:32,404] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 1.4687417e-17 2.5478169e-17 7.2362150e-17 4.3282328e-17], sampled 0.03918382308160473
[2019-03-23 16:01:38,856] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05119367], dtype=float32), 0.3564151]
[2019-03-23 16:01:38,858] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.92875753, 98.40118048, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7570174077222972, 7.477664653985784, 6.9112, 95.55160799865057, 659797.2571970761, 432465.5012335647, 138466.5743920297]
[2019-03-23 16:01:38,858] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:01:38,862] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 3.1707335e-19 9.2507938e-21 8.2453622e-20 1.5248206e-19], sampled 0.26223994562868047
[2019-03-23 16:01:38,864] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 659797.2571970761 W.
[2019-03-23 16:01:47,377] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05119367], dtype=float32), 0.3564151]
[2019-03-23 16:01:47,378] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.20134614, 100.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7658669520264797, 7.526055423035668, 6.9112, 95.55147277376463, 682447.7287262696, 435696.2956274939, 140792.3730075445]
[2019-03-23 16:01:47,382] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:01:47,387] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0000000e+00 2.1485678e-14 2.0240656e-16 1.6592960e-15 4.4159283e-15], sampled 0.17259595491025992
[2019-03-23 16:01:47,388] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 682447.7287262696 W.
[2019-03-23 16:01:48,744] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05119367], dtype=float32), 0.3564151]
[2019-03-23 16:01:48,745] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.33531969333333, 73.43360586333333, 1.0, 2.0, 0.6139301926641774, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 695380.3407365171, 695380.3407365171, 163708.9106104304]
[2019-03-23 16:01:48,746] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:01:48,748] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0000000e+00 8.8406051e-23 2.2591634e-23 1.4765690e-22 1.4656707e-22], sampled 0.20236836161435923
[2019-03-23 16:01:48,750] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 695380.3407365171 W.
[2019-03-23 16:02:20,280] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6294.9961 1685630448.6673 3228.0000
[2019-03-23 16:02:20,584] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6862.2842 1793014293.7888 2409.0000
[2019-03-23 16:02:20,714] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6328.7217 1723294598.4314 3425.0000
[2019-03-23 16:02:20,769] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6481.6076 1678885180.2952 3057.0000
[2019-03-23 16:02:20,774] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6553.1725 1698634175.0084 2957.0000
[2019-03-23 16:02:21,790] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 2075000, evaluation results [2075000.0, 6862.284208925443, 1793014293.78876, 2409.0, 6481.607577760913, 1678885180.2951708, 3057.0, 6294.9960618483565, 1685630448.6673346, 3228.0, 6328.721692698646, 1723294598.4313502, 3425.0, 6553.172466661831, 1698634175.0084193, 2957.0]
[2019-03-23 16:02:23,305] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.6968296e-25 6.5922992e-23 3.6696150e-23 1.2413336e-23], sum to 1.0000
[2019-03-23 16:02:23,317] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8585
[2019-03-23 16:02:23,324] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 545090.2236352444 W.
[2019-03-23 16:02:23,328] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.53333333333333, 85.66666666666667, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3224036309519158, 6.9112, 6.9112, 77.3421103, 545090.2236352444, 545090.2236352444, 207892.6733690698], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6322800.0000, 
sim time next is 6323400.0000, 
raw observation next is [22.45, 86.0, 1.0, 2.0, 0.2380535507968955, 1.0, 2.0, 0.2380535507968955, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 542944.2081205557, 542944.2081205557, 176853.8873506919], 
processed observation next is [0.0, 0.17391304347826086, 0.6568181818181817, 0.86, 1.0, 1.0, 0.04756693849611936, 1.0, 1.0, 0.04756693849611936, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20109044745205767, 0.20109044745205767, 0.43135094475778507], 
reward next is 0.5686, 
noisyNet noise sample is [array([-0.34741992], dtype=float32), -0.24635944]. 
=============================================
[2019-03-23 16:02:29,443] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.0949867e-16 1.0295446e-17 3.8240841e-17 7.0394996e-17], sum to 1.0000
[2019-03-23 16:02:29,450] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5202
[2019-03-23 16:02:29,458] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 591160.8039216563 W.
[2019-03-23 16:02:29,464] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.7, 77.5, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 1.0, 0.3515313427694771, 6.9112, 6.9112, 77.3421103, 591160.8039216563, 591160.8039216563, 216741.7749492402], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6391800.0000, 
sim time next is 6392400.0000, 
raw observation next is [24.6, 78.0, 1.0, 2.0, 0.2594663891248351, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5255113873362504, 6.9112, 6.9112, 77.32846344354104, 590387.259509206, 590387.259509206, 182438.4947167849], 
processed observation next is [0.0, 1.0, 0.7545454545454546, 0.78, 1.0, 1.0, 0.07433298640604387, 0.0, 0.5, -0.25, 1.0, 1.0, 0.322159124766072, 0.0, 0.0, 0.5084288129206541, 0.21866194796637262, 0.21866194796637262, 0.4449719383336217], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.47626528], dtype=float32), -0.45400947]. 
=============================================
[2019-03-23 16:02:32,150] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 4.3347024e-13 3.7732647e-25 6.1557252e-23 2.0299003e-19], sum to 1.0000
[2019-03-23 16:02:32,156] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0695
[2019-03-23 16:02:32,160] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.8, 73.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4186475234751079, 6.911199999999999, 6.9112, 77.32846344354104, 243494.5272061533, 243494.5272061536, 72836.31606580658], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6471000.0000, 
sim time next is 6471600.0000, 
raw observation next is [15.7, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4160623321020863, 6.9112, 6.9112, 77.32846344354104, 241990.5494963822, 241990.5494963822, 72431.38238823586], 
processed observation next is [1.0, 0.9130434782608695, 0.35, 0.74, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.16580333157440905, 0.0, 0.0, 0.5084288129206541, 0.08962612944310452, 0.08962612944310452, 0.1766619082639899], 
reward next is 0.8233, 
noisyNet noise sample is [array([-0.92196596], dtype=float32), 0.8175919]. 
=============================================
[2019-03-23 16:02:34,378] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 2.2340528e-12 1.0473113e-23 2.3600650e-21 2.0182578e-18], sum to 1.0000
[2019-03-23 16:02:34,387] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6726
[2019-03-23 16:02:34,390] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.43333333333334, 66.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5832401160556688, 6.9112, 6.9112, 77.32846344354104, 339227.5735735931, 339227.5735735931, 105529.1749657922], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6459600.0000, 
sim time next is 6460200.0000, 
raw observation next is [19.15, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.560715359792402, 6.9112, 6.9112, 77.32846344354104, 326141.9950388982, 326141.9950388982, 100755.1251704021], 
processed observation next is [1.0, 0.782608695652174, 0.5068181818181817, 0.66, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3724505139891457, 0.0, 0.0, 0.5084288129206541, 0.12079333149588822, 0.12079333149588822, 0.24574420773268804], 
reward next is 0.7543, 
noisyNet noise sample is [array([-2.8002286], dtype=float32), -0.008650765]. 
=============================================
[2019-03-23 16:02:35,958] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 8.3976524e-12 1.2489317e-18 4.4918342e-17 1.4409671e-15], sum to 1.0000
[2019-03-23 16:02:35,966] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7302
[2019-03-23 16:02:35,974] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 590478.3728763988 W.
[2019-03-23 16:02:35,978] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.5, 51.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7604073582470675, 7.36705755518265, 6.9112, 77.32736000382009, 590478.3728763988, 442427.2755001046, 105878.3071374098], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6534600.0000, 
sim time next is 6535200.0000, 
raw observation next is [20.5, 51.00000000000001, 1.0, 1.0, 0.2468102474563327, 1.0, 1.0, 0.2468102474563327, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32818950506679, 536114.8590441323, 536114.8590441325, 154907.8914733979], 
processed observation next is [1.0, 0.6521739130434783, 0.5681818181818182, 0.5100000000000001, 1.0, 0.5, 0.058512809320415866, 1.0, 0.5, 0.058512809320415866, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084270117958538, 0.19856105890523418, 0.19856105890523426, 0.37782412554487294], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.16405195], dtype=float32), 0.18631443]. 
=============================================
[2019-03-23 16:02:38,710] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 7.3046461e-14 1.8050437e-28 2.9382293e-25 6.7727704e-23], sum to 1.0000
[2019-03-23 16:02:38,717] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0251
[2019-03-23 16:02:38,721] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.8, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6831748991599884, 6.9112, 6.9112, 77.32846344354104, 394626.9148426816, 394626.9148426816, 122895.4196657019], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6646800.0000, 
sim time next is 6647400.0000, 
raw observation next is [18.8, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6817527564443145, 6.9112, 6.9112, 77.32846344354104, 393802.0928609809, 393802.0928609809, 122758.5893171837], 
processed observation next is [1.0, 0.9565217391304348, 0.49090909090909096, 0.87, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5453610806347351, 0.0, 0.0, 0.5084288129206541, 0.1458526269855485, 0.1458526269855485, 0.2994111934565456], 
reward next is 0.7006, 
noisyNet noise sample is [array([1.5830199], dtype=float32), 0.5907103]. 
=============================================
[2019-03-23 16:02:40,001] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 6.1904765e-10 1.2793053e-18 1.4293437e-16 5.7760484e-14], sum to 1.0000
[2019-03-23 16:02:40,008] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9251
[2019-03-23 16:02:40,016] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.11666666666667, 64.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6748709328436383, 6.911200000000001, 6.9112, 77.32841590966679, 392568.2226882135, 392568.2226882133, 109105.502030515], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6601800.0000, 
sim time next is 6602400.0000, 
raw observation next is [19.4, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7066479608893235, 6.915795212226994, 6.9112, 77.32843103129242, 412561.6533477081, 411069.2230302771, 113145.8854776646], 
processed observation next is [1.0, 0.43478260869565216, 0.5181818181818181, 0.63, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5809256584133193, 0.00045952122269943274, 0.0, 0.5084285998125648, 0.152800612351003, 0.1522478603815841, 0.27596557433576735], 
reward next is 0.7011, 
noisyNet noise sample is [array([-0.0502579], dtype=float32), -0.25189885]. 
=============================================
[2019-03-23 16:02:54,269] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.4640915e-26 7.1499388e-19 3.9950091e-19 3.6780113e-22], sum to 1.0000
[2019-03-23 16:02:54,275] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1928
[2019-03-23 16:02:54,280] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.71666666666667, 49.66666666666667, 1.0, 2.0, 0.2354097043419951, 0.0, 1.0, 0.0, 1.0, 2.0, 0.475515873643409, 6.911199999999999, 6.9112, 77.3284634291897, 537137.5671983435, 537137.5671983438, 174566.818320446], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6880200.0000, 
sim time next is 6880800.0000, 
raw observation next is [28.63333333333334, 49.33333333333334, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8055868785925343, 7.561216879125388, 6.9112, 77.32688478700717, 667027.2874587742, 455919.4101074709, 143074.9216219536], 
processed observation next is [0.0, 0.6521739130434783, 0.9378787878787882, 0.4933333333333334, 0.0, 0.5, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.7222669694179062, 0.06500168791253884, 0.0, 0.5084184333730493, 0.2470471435032497, 0.16885904078054476, 0.34896322346817954], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2533383], dtype=float32), -0.64275575]. 
=============================================
[2019-03-23 16:03:02,025] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.4055078e-19 2.6682625e-20 1.0837787e-19 2.3139956e-19], sum to 1.0000
[2019-03-23 16:03:02,056] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6196
[2019-03-23 16:03:02,059] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.7, 84.0, 1.0, 1.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 473808.8440426315, 473808.8440426318, 189107.4363809011], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7065000.0000, 
sim time next is 7065600.0000, 
raw observation next is [19.6, 84.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.73009750519838, 7.028572685844515, 6.9112, 77.32812398803586, 457026.1963027915, 418906.1159668592, 129775.6964996957], 
processed observation next is [1.0, 0.782608695652174, 0.5272727272727273, 0.84, 0.0, 0.5, -0.25, 0.0, 0.5, -0.25, 1.0, 1.0, 0.6144250074262572, 0.0117372685844515, 0.0, 0.5084265810263185, 0.16926896159362648, 0.15515041332105897, 0.31652608902364804], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.24591194], dtype=float32), 1.81909]. 
=============================================
[2019-03-23 16:03:05,521] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 5.1169207e-23 1.5390758e-24 7.9099856e-24 3.8485412e-23], sum to 1.0000
[2019-03-23 16:03:05,527] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8893
[2019-03-23 16:03:05,536] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 711793.2532715972 W.
[2019-03-23 16:03:05,549] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.1, 76.0, 1.0, 2.0, 0.2092894940454361, 1.0, 1.0, 0.2092894940454361, 1.0, 1.0, 0.4149127963305907, 6.911199999999999, 6.9112, 77.3421103, 711793.2532715972, 711793.2532715974, 218141.8927853864], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7122600.0000, 
sim time next is 7123200.0000, 
raw observation next is [21.46666666666667, 73.33333333333333, 1.0, 2.0, 0.3366470953513113, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6643805834240596, 6.911199999999999, 6.9112, 77.32846344354104, 761278.5011501836, 761278.5011501838, 191350.3180552715], 
processed observation next is [1.0, 0.43478260869565216, 0.6121212121212122, 0.7333333333333333, 1.0, 1.0, 0.17080886918913912, 0.0, 0.5, -0.25, 1.0, 1.0, 0.5205436906057994, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2819550004259939, 0.28195500042599403, 0.46670809281773534], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.07256833], dtype=float32), -0.19529437]. 
=============================================
[2019-03-23 16:03:09,431] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 9.8033713e-15 2.2175427e-27 3.0921303e-23 2.0398828e-19], sum to 1.0000
[2019-03-23 16:03:09,436] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6414
[2019-03-23 16:03:09,442] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [13.43333333333333, 86.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3682550960296678, 6.911199999999998, 6.9112, 77.32846344354104, 214178.7397427159, 214178.7397427165, 64656.08578602423], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7181400.0000, 
sim time next is 7182000.0000, 
raw observation next is [13.3, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3642499759978227, 6.9112, 6.9112, 77.32846344354104, 211848.837529889, 211848.837529889, 64099.6227502488], 
processed observation next is [1.0, 0.13043478260869565, 0.24090909090909093, 0.87, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.09178567999688962, 0.0, 0.0, 0.5084288129206541, 0.07846253241847741, 0.07846253241847741, 0.15634054329328975], 
reward next is 0.8437, 
noisyNet noise sample is [array([-0.8125357], dtype=float32), -0.17711991]. 
=============================================
[2019-03-23 16:03:09,468] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[68.78934]
 [68.96275]
 [68.93899]
 [69.24295]
 [69.21821]], R is [[68.9017334 ]
 [69.05501556]
 [69.20516205]
 [69.35166931]
 [69.49384308]].
[2019-03-23 16:03:09,882] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 16:03:09,883] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:03:09,883] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:03:09,884] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:03:09,884] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:03:09,884] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:03:09,885] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:03:09,885] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:03:09,886] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:03:09,886] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:03:09,887] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:03:09,908] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run85
[2019-03-23 16:03:09,937] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run85
[2019-03-23 16:03:09,970] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run85
[2019-03-23 16:03:10,000] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run85
[2019-03-23 16:03:10,032] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run85
[2019-03-23 16:03:24,045] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.04961136], dtype=float32), 0.3575521]
[2019-03-23 16:03:24,047] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.510584695, 68.20695871166667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7097603613058453, 7.118894434483979, 6.9112, 95.55266022191078, 491864.5071708238, 408512.3331122598, 130953.6816591253]
[2019-03-23 16:03:24,047] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:03:24,049] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0000000e+00 1.0481405e-12 9.0978538e-22 1.4234812e-19 2.5472351e-16], sampled 0.399937357332949
[2019-03-23 16:03:30,473] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04961136], dtype=float32), 0.3575521]
[2019-03-23 16:03:30,475] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.5, 94.0, 1.0, 1.0, 0.5057450333543324, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32812235978673, 577117.9124909253, 577117.912490925, 141617.7111544363]
[2019-03-23 16:03:30,476] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:03:30,480] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 9.9425557e-10 2.8723909e-16 1.0932446e-14 2.6093132e-12], sampled 0.9736767186284797
[2019-03-23 16:03:30,481] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 577117.9124909253 W.
[2019-03-23 16:04:03,842] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.04961136], dtype=float32), 0.3575521]
[2019-03-23 16:04:03,843] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.08959943, 95.68403028333333, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7439822863054895, 7.364458934666284, 6.9112, 95.55194527947049, 606808.3939116371, 424907.347636449, 137033.2691766079]
[2019-03-23 16:04:03,844] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:04:03,848] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.00000000e+00 2.45765994e-12 1.33771576e-20 1.34530111e-18
 1.29731386e-15], sampled 0.4471434519369728
[2019-03-23 16:04:03,849] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 606808.3939116371 W.
[2019-03-23 16:04:30,085] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.04961136], dtype=float32), 0.3575521]
[2019-03-23 16:04:30,087] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.2, 71.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5567426956839475, 6.9112, 6.9112, 95.55338769695034, 323819.8680144747, 323819.8680144747, 111762.5006950885]
[2019-03-23 16:04:30,088] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:04:30,090] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 1.3930385e-12 1.0472964e-21 1.7374584e-19 3.1008704e-16], sampled 0.010998300479780676
[2019-03-23 16:04:55,775] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6862.2842 1793014293.7888 2409.0000
[2019-03-23 16:04:55,828] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6294.9961 1685630448.6673 3228.0000
[2019-03-23 16:04:55,906] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6553.1725 1698634175.0084 2957.0000
[2019-03-23 16:04:56,027] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6328.7217 1723294598.4314 3425.0000
[2019-03-23 16:04:56,293] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6481.6076 1678885180.2952 3057.0000
[2019-03-23 16:04:57,309] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2100000, evaluation results [2100000.0, 6862.284208925443, 1793014293.78876, 2409.0, 6481.607577760913, 1678885180.2951708, 3057.0, 6294.9960618483565, 1685630448.6673346, 3228.0, 6328.721692698646, 1723294598.4313502, 3425.0, 6553.172466661831, 1698634175.0084193, 2957.0]
[2019-03-23 16:04:57,674] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 7.1990015e-14 2.2027602e-22 6.9136596e-21 1.6279714e-16], sum to 1.0000
[2019-03-23 16:04:57,679] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7772
[2019-03-23 16:04:57,688] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 570176.5438710868 W.
[2019-03-23 16:04:57,693] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.46666666666667, 51.66666666666667, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3272436662899898, 6.911199999999999, 6.9112, 77.3421103, 570176.5438710868, 570176.543871087, 192811.5174249244], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7208400.0000, 
sim time next is 7209000.0000, 
raw observation next is [21.65, 51.0, 1.0, 2.0, 0.2617124755887073, 1.0, 2.0, 0.2617124755887073, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 568925.223547636, 568925.2235476356, 160727.3624919711], 
processed observation next is [1.0, 0.43478260869565216, 0.6204545454545454, 0.51, 1.0, 1.0, 0.07714059448588412, 1.0, 1.0, 0.07714059448588412, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21071304575838368, 0.21071304575838357, 0.39201795729749045], 
reward next is 0.6080, 
noisyNet noise sample is [array([-0.8375266], dtype=float32), 2.0866885]. 
=============================================
[2019-03-23 16:04:57,708] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[59.620636]
 [58.116955]
 [56.575718]
 [55.0264  ]
 [52.787655]], R is [[61.87341309]
 [61.25468063]
 [60.64213562]
 [60.64076996]
 [60.63787079]].
[2019-03-23 16:05:01,200] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 3.4989698e-14 5.8784904e-25 7.3438122e-23 9.4848572e-19], sum to 1.0000
[2019-03-23 16:05:01,210] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2370
[2019-03-23 16:05:01,214] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.7, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5025726604816936, 6.911199999999999, 6.9112, 77.32846344354104, 292321.8858862549, 292321.8858862552, 93503.88584892632], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7257600.0000, 
sim time next is 7258200.0000, 
raw observation next is [17.25, 77.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5009425253455458, 6.9112, 6.9112, 77.32846344354104, 291373.4321352375, 291373.4321352375, 92269.56768012633], 
processed observation next is [1.0, 0.0, 0.42045454545454547, 0.775, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.28706075049363694, 0.0, 0.0, 0.5084288129206541, 0.10791608597601389, 0.10791608597601389, 0.22504772604908863], 
reward next is 0.7750, 
noisyNet noise sample is [array([0.65362394], dtype=float32), 0.52217114]. 
=============================================
[2019-03-23 16:05:05,476] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.1712105e-10 7.7144260e-20 4.7797610e-18 3.4321559e-15], sum to 1.0000
[2019-03-23 16:05:05,488] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1041
[2019-03-23 16:05:05,503] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 982396.0527472226 W.
[2019-03-23 16:05:05,511] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 43.16666666666667, 1.0, 2.0, 0.8752659075824916, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344313693, 982396.0527472226, 982396.0527472226, 180461.7781501742], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7308600.0000, 
sim time next is 7309200.0000, 
raw observation next is [25.9, 43.33333333333334, 1.0, 2.0, 0.2844062153418938, 1.0, 1.0, 0.2844062153418938, 1.0, 1.0, 0.5608864605426157, 6.911199999999999, 6.9112, 77.3421103, 964496.2721608839, 964496.2721608842, 235919.3703141419], 
processed observation next is [1.0, 0.6086956521739131, 0.8136363636363636, 0.4333333333333334, 1.0, 1.0, 0.10550776917736725, 1.0, 0.5, 0.10550776917736725, 1.0, 0.5, 0.3726949436323082, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.3572208415410681, 0.35722084154106826, 0.5754130983271754], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.97321033], dtype=float32), 0.19399016]. 
=============================================
[2019-03-23 16:05:07,259] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.5685128e-35 2.2357760e-30 8.3912786e-31 5.6964997e-32], sum to 1.0000
[2019-03-23 16:05:07,266] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9227
[2019-03-23 16:05:07,273] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 982524.4346396137 W.
[2019-03-23 16:05:07,278] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.1, 53.0, 1.0, 2.0, 0.2876526239972747, 1.0, 1.0, 0.2876526239972747, 1.0, 2.0, 0.5825430305892874, 6.911199999999999, 6.9112, 77.3421103, 982524.4346396137, 982524.434639614, 253973.2773733221], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7389600.0000, 
sim time next is 7390200.0000, 
raw observation next is [28.2, 53.0, 1.0, 2.0, 0.4417406829151639, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8937347211417942, 6.911199999999999, 6.9112, 77.32846344354104, 1007539.583337485, 1007539.583337486, 240625.8033097771], 
processed observation next is [1.0, 0.5217391304347826, 0.9181818181818181, 0.53, 1.0, 1.0, 0.30217585364395483, 0.0, 0.5, -0.25, 1.0, 1.0, 0.8481924587739919, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.373162808643513, 0.37316280864351337, 0.5868922031945784], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5037259], dtype=float32), -0.5296169]. 
=============================================
[2019-03-23 16:05:09,155] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 8.9604307e-10 9.9033330e-19 1.3288984e-17 3.4623751e-15], sum to 1.0000
[2019-03-23 16:05:09,162] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1810
[2019-03-23 16:05:09,167] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.2, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6526320266996136, 6.911199999999999, 6.9112, 77.32846344354104, 378102.042381981, 378102.0423819813, 119142.7433161617], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7443000.0000, 
sim time next is 7443600.0000, 
raw observation next is [17.2, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6488388451382384, 6.911199999999999, 6.9112, 77.32846344354104, 375903.6215838252, 375903.6215838254, 118797.062618383], 
processed observation next is [0.0, 0.13043478260869565, 0.41818181818181815, 0.96, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.49834120734034065, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1392235635495649, 0.13922356354956494, 0.28974893321556827], 
reward next is 0.7103, 
noisyNet noise sample is [array([-0.94913745], dtype=float32), -1.2149891]. 
=============================================
[2019-03-23 16:05:12,535] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.00000000e+00 5.28969756e-28 7.84248566e-21 7.36089670e-22
 1.27615346e-23], sum to 1.0000
[2019-03-23 16:05:12,543] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9284
[2019-03-23 16:05:12,555] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 557356.7273379378 W.
[2019-03-23 16:05:12,562] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.03333333333333, 77.33333333333333, 1.0, 2.0, 0.2443965585481135, 0.0, 1.0, 0.0, 1.0, 2.0, 0.4942617621594084, 6.911199999999999, 6.9112, 77.32846103011873, 557356.7273379378, 557356.7273379382, 177317.2699803923], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7552200.0000, 
sim time next is 7552800.0000, 
raw observation next is [24.4, 76.0, 1.0, 2.0, 0.2439342616311332, 0.0, 2.0, 0.0, 1.0, 2.0, 0.493341501843888, 6.911199999999999, 6.9112, 77.32846342860175, 556290.4464301511, 556290.4464301514, 177234.0681344534], 
processed observation next is [0.0, 0.43478260869565216, 0.7454545454545454, 0.76, 1.0, 1.0, 0.05491782703891647, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2762021454912686, -8.881784197001253e-17, 0.0, 0.5084288128224294, 0.20603349867783374, 0.20603349867783383, 0.43227821496208146], 
reward next is 0.5677, 
noisyNet noise sample is [array([-0.68883944], dtype=float32), 0.84125656]. 
=============================================
[2019-03-23 16:05:20,216] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 6.1429657e-30 3.2876017e-31 3.1266511e-35], sum to 1.0000
[2019-03-23 16:05:20,227] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3310
[2019-03-23 16:05:20,232] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.8, 97.0, 1.0, 1.0, 0.4458893328128478, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32819023051698, 503660.9677141521, 503660.9677141521, 129767.6857226057], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7700400.0000, 
sim time next is 7701000.0000, 
raw observation next is [18.71666666666667, 97.5, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7524179147423485, 7.209213436719447, 6.9112, 77.3277172642523, 528246.4808333096, 431458.7459758334, 132463.7320359602], 
processed observation next is [1.0, 0.13043478260869565, 0.48712121212121223, 0.975, 0.0, 0.5, -0.25, 0.0, 1.0, -0.25, 1.0, 0.5, 0.6463113067747837, 0.029801343671944737, 0.0, 0.5084239068481278, 0.19564684475307761, 0.15979953554660495, 0.32308227325843947], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0147136], dtype=float32), 2.7209394]. 
=============================================
[2019-03-23 16:05:20,250] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[12.102638]
 [12.130995]
 [12.143957]
 [12.165644]
 [11.54034 ]], R is [[12.06205273]
 [12.62492561]
 [12.4986763 ]
 [12.37368965]
 [12.24995327]].
[2019-03-23 16:05:26,639] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 8.1300635e-13 1.3524332e-25 1.4387649e-22 2.2316410e-17], sum to 1.0000
[2019-03-23 16:05:26,646] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1072
[2019-03-23 16:05:26,651] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.1, 69.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4200073104049765, 6.911199999999999, 6.9112, 77.32846344354104, 244285.6075412412, 244285.6075412415, 71996.21856694385], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7779000.0000, 
sim time next is 7779600.0000, 
raw observation next is [16.1, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4195095689905826, 6.911199999999999, 6.9112, 77.32846344354104, 243996.0374334352, 243996.0374334354, 71670.1371886691], 
processed observation next is [1.0, 0.043478260869565216, 0.3681818181818182, 0.69, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.17072795570083232, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09036890275312415, 0.09036890275312423, 0.1748052126552905], 
reward next is 0.8252, 
noisyNet noise sample is [array([0.7034008], dtype=float32), 0.007638427]. 
=============================================
[2019-03-23 16:05:26,798] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 5.1168153e-11 5.8617213e-24 3.2245361e-20 6.8457584e-16], sum to 1.0000
[2019-03-23 16:05:26,809] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5370
[2019-03-23 16:05:26,821] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.81666666666667, 76.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.429926618688844, 6.911199999999999, 6.9112, 77.32846344354104, 250056.3812419162, 250056.3812419164, 70778.1487619707], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7787400.0000, 
sim time next is 7788000.0000, 
raw observation next is [14.73333333333333, 77.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4102814033684786, 6.9112, 6.9112, 77.32846344354104, 238627.4157079212, 238627.4157079212, 69775.84957081702], 
processed observation next is [1.0, 0.13043478260869565, 0.3060606060606059, 0.7766666666666667, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1575448619549695, 0.0, 0.0, 0.5084288129206541, 0.08838052433626711, 0.08838052433626711, 0.17018499895321226], 
reward next is 0.8298, 
noisyNet noise sample is [array([-0.01727878], dtype=float32), 0.49496034]. 
=============================================
[2019-03-23 16:05:26,836] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[68.3429  ]
 [68.78254 ]
 [69.04874 ]
 [69.337006]
 [69.6557  ]], R is [[68.17585754]
 [68.32147217]
 [68.46872711]
 [68.61320496]
 [68.75422668]].
[2019-03-23 16:05:27,550] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 3.7820187e-14 1.4723622e-29 2.0942980e-25 3.6165341e-20], sum to 1.0000
[2019-03-23 16:05:27,556] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8364
[2019-03-23 16:05:27,562] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.78333333333333, 68.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4452513684360151, 6.911200000000001, 6.9112, 77.32846344354104, 258972.022884784, 258972.0228847837, 77199.80080968696], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7771800.0000, 
sim time next is 7772400.0000, 
raw observation next is [16.6, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4406678848318136, 6.911200000000001, 6.9112, 77.32846344354104, 256305.424050405, 256305.4240504047, 76612.55410097222], 
processed observation next is [1.0, 1.0, 0.390909090909091, 0.7, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.20095412118830522, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09492793483348334, 0.09492793483348322, 0.18685988805115175], 
reward next is 0.8131, 
noisyNet noise sample is [array([-0.66335785], dtype=float32), 0.7605594]. 
=============================================
[2019-03-23 16:05:30,147] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 3.2148407e-08 2.4613064e-22 1.1905069e-19 3.4287928e-15], sum to 1.0000
[2019-03-23 16:05:30,155] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4746
[2019-03-23 16:05:30,161] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.0, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.549150495800623, 6.911199999999999, 6.9112, 77.32846344354104, 319422.8271716443, 319422.8271716446, 103076.2096362691], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7852200.0000, 
sim time next is 7852800.0000, 
raw observation next is [20.0, 63.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5448126067501582, 6.9112, 6.9112, 77.32846344354104, 316898.7973132383, 316898.7973132383, 102739.2060106864], 
processed observation next is [1.0, 0.9130434782608695, 0.5454545454545454, 0.6300000000000001, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3497322953573689, 0.0, 0.0, 0.5084288129206541, 0.11736992493082901, 0.11736992493082901, 0.25058342929435706], 
reward next is 0.7494, 
noisyNet noise sample is [array([0.49689353], dtype=float32), -2.1711442]. 
=============================================
[2019-03-23 16:05:30,981] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:05:30,982] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:05:31,035] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run11
[2019-03-23 16:05:32,761] A3C_AGENT_WORKER-Thread-13 INFO:Local step 132500, global step 2118441: loss 12.9574
[2019-03-23 16:05:32,764] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 132500, global step 2118443: learning rate 0.0000
[2019-03-23 16:05:33,664] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:05:33,665] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:05:33,715] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run11
[2019-03-23 16:05:34,905] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:05:34,905] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:05:34,941] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run11
[2019-03-23 16:05:35,280] A3C_AGENT_WORKER-Thread-3 INFO:Local step 132500, global step 2119748: loss 3.1580
[2019-03-23 16:05:35,282] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 132500, global step 2119748: learning rate 0.0000
[2019-03-23 16:05:35,543] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:05:35,543] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:05:35,549] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run11
[2019-03-23 16:05:35,652] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:05:35,652] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:05:35,665] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run11
[2019-03-23 16:05:35,787] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:05:35,788] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:05:35,791] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run11
[2019-03-23 16:05:35,825] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:05:35,827] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:05:35,834] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run11
[2019-03-23 16:05:35,864] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:05:35,878] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:05:35,888] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run11
[2019-03-23 16:05:36,085] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:05:36,085] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:05:36,090] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run11
[2019-03-23 16:05:36,131] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:05:36,132] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:05:36,135] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run11
[2019-03-23 16:05:36,171] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:05:36,172] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:05:36,177] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run11
[2019-03-23 16:05:36,273] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:05:36,273] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:05:36,276] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run11
[2019-03-23 16:05:36,341] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:05:36,341] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:05:36,346] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run11
[2019-03-23 16:05:36,413] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:05:36,413] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:05:36,417] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run11
[2019-03-23 16:05:36,422] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:05:36,502] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:05:36,559] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run11
[2019-03-23 16:05:36,717] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:05:36,717] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:05:36,750] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run11
[2019-03-23 16:05:37,035] A3C_AGENT_WORKER-Thread-22 INFO:Local step 132500, global step 2120070: loss 1.0670
[2019-03-23 16:05:37,037] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 132500, global step 2120070: learning rate 0.0000
[2019-03-23 16:05:37,785] A3C_AGENT_WORKER-Thread-14 INFO:Local step 132500, global step 2120247: loss 0.1590
[2019-03-23 16:05:37,790] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 132500, global step 2120247: learning rate 0.0000
[2019-03-23 16:05:37,821] A3C_AGENT_WORKER-Thread-10 INFO:Local step 132500, global step 2120259: loss 0.1733
[2019-03-23 16:05:37,823] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 132500, global step 2120259: learning rate 0.0000
[2019-03-23 16:05:37,825] A3C_AGENT_WORKER-Thread-11 INFO:Local step 132500, global step 2120260: loss 0.2194
[2019-03-23 16:05:37,827] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 132500, global step 2120260: learning rate 0.0000
[2019-03-23 16:05:37,843] A3C_AGENT_WORKER-Thread-2 INFO:Local step 132500, global step 2120272: loss 0.3227
[2019-03-23 16:05:37,846] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 132500, global step 2120272: learning rate 0.0000
[2019-03-23 16:05:37,921] A3C_AGENT_WORKER-Thread-20 INFO:Local step 132500, global step 2120320: loss 0.3954
[2019-03-23 16:05:37,927] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 132500, global step 2120321: learning rate 0.0000
[2019-03-23 16:05:37,963] A3C_AGENT_WORKER-Thread-18 INFO:Local step 132500, global step 2120341: loss 0.5638
[2019-03-23 16:05:37,964] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 132500, global step 2120341: learning rate 0.0000
[2019-03-23 16:05:38,038] A3C_AGENT_WORKER-Thread-9 INFO:Local step 132500, global step 2120388: loss 0.6228
[2019-03-23 16:05:38,041] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 132500, global step 2120388: learning rate 0.0000
[2019-03-23 16:05:38,179] A3C_AGENT_WORKER-Thread-12 INFO:Local step 132500, global step 2120471: loss 0.0843
[2019-03-23 16:05:38,181] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 132500, global step 2120471: learning rate 0.0000
[2019-03-23 16:05:38,220] A3C_AGENT_WORKER-Thread-19 INFO:Local step 132500, global step 2120493: loss 0.0771
[2019-03-23 16:05:38,221] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 132500, global step 2120493: learning rate 0.0000
[2019-03-23 16:05:38,278] A3C_AGENT_WORKER-Thread-15 INFO:Local step 132500, global step 2120530: loss 0.1254
[2019-03-23 16:05:38,282] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 132500, global step 2120531: learning rate 0.0000
[2019-03-23 16:05:38,441] A3C_AGENT_WORKER-Thread-16 INFO:Local step 132500, global step 2120626: loss 1.4194
[2019-03-23 16:05:38,444] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 132500, global step 2120626: learning rate 0.0000
[2019-03-23 16:05:38,702] A3C_AGENT_WORKER-Thread-17 INFO:Local step 132500, global step 2120777: loss 0.3876
[2019-03-23 16:05:38,705] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 132500, global step 2120778: learning rate 0.0000
[2019-03-23 16:05:38,889] A3C_AGENT_WORKER-Thread-21 INFO:Local step 132500, global step 2120869: loss 0.1376
[2019-03-23 16:05:38,893] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 132500, global step 2120870: learning rate 0.0000
[2019-03-23 16:05:41,091] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9999106e-01 8.9775876e-06 2.5950753e-23 4.9571617e-21 6.6933410e-17], sum to 1.0000
[2019-03-23 16:05:41,105] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4004
[2019-03-23 16:05:41,109] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.33333333333334, 61.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4721498326252183, 6.9112, 6.9112, 77.32846344354104, 274621.4219119528, 274621.4219119528, 77187.21634553572], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 161400.0000, 
sim time next is 162000.0000, 
raw observation next is [17.0, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.468378725404901, 6.911199999999999, 6.9112, 77.32846344354104, 272427.379248172, 272427.3792481723, 76521.55051217928], 
processed observation next is [1.0, 0.9130434782608695, 0.4090909090909091, 0.63, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.24054103629271575, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10089902935117481, 0.10089902935117492, 0.18663792807848606], 
reward next is 0.8134, 
noisyNet noise sample is [array([-0.09077982], dtype=float32), 2.2933974]. 
=============================================
[2019-03-23 16:05:41,121] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[90.491554]
 [90.59551 ]
 [91.38799 ]
 [91.94857 ]
 [91.88471 ]], R is [[90.45834351]
 [90.3655014 ]
 [90.27217102]
 [90.17807007]
 [90.08304596]].
[2019-03-23 16:05:45,096] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133000, global step 2124136: loss 0.7304
[2019-03-23 16:05:45,100] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133000, global step 2124139: learning rate 0.0000
[2019-03-23 16:05:46,738] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 16:05:46,740] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:05:46,741] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:05:46,741] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:05:46,742] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:05:46,742] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:05:46,743] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:05:46,743] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:05:46,743] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:05:46,744] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:05:46,744] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:05:46,766] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run86
[2019-03-23 16:05:46,797] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run86
[2019-03-23 16:05:46,827] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run86
[2019-03-23 16:05:46,858] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run86
[2019-03-23 16:05:46,859] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run86
[2019-03-23 16:05:53,657] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05020032], dtype=float32), 0.35877055]
[2019-03-23 16:05:53,659] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.76666666666667, 60.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.498515429194029, 6.9112, 6.9112, 95.55338769695034, 289944.8050117342, 289944.8050117342, 81295.04895636113]
[2019-03-23 16:05:53,660] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:05:53,664] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 5.9456314e-13 9.5453728e-25 4.0925021e-23 8.2141258e-20], sampled 0.06686219676763594
[2019-03-23 16:05:56,868] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05020032], dtype=float32), 0.35877055]
[2019-03-23 16:05:56,870] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.37503732833333, 53.59338180499999, 1.0, 1.0, 0.5245916189093681, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 95.55298425949094, 596863.6524439603, 596863.65244396, 145130.338430333]
[2019-03-23 16:05:56,871] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:05:56,874] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0000000e+00 7.7124057e-10 1.8663767e-18 2.8130312e-17 7.5254566e-15], sampled 0.011029866803896171
[2019-03-23 16:05:56,875] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 596863.6524439603 W.
[2019-03-23 16:06:10,576] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05020032], dtype=float32), 0.35877055]
[2019-03-23 16:06:10,577] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.92416798666667, 40.91014680333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5062088210754302, 6.9112, 6.9112, 95.55338769695034, 295083.9571041185, 295083.9571041185, 72565.2038044813]
[2019-03-23 16:06:10,578] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:06:10,581] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 2.1735983e-12 1.2914328e-23 4.5934868e-22 6.4367525e-19], sampled 0.487423058126757
[2019-03-23 16:06:12,881] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05020032], dtype=float32), 0.35877055]
[2019-03-23 16:06:12,882] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.28333333333333, 79.00000000000001, 1.0, 2.0, 0.4759297594715343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 542992.3508520324, 542992.3508520321, 142181.1011371406]
[2019-03-23 16:06:12,883] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:06:12,888] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 3.8975934e-11 5.2874164e-21 1.1880979e-19 7.0203791e-17], sampled 0.3175609173117667
[2019-03-23 16:06:12,889] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 542992.3508520324 W.
[2019-03-23 16:06:31,337] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05020032], dtype=float32), 0.35877055]
[2019-03-23 16:06:31,338] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.41666666666667, 53.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5399290930603436, 6.9112, 6.9112, 95.55338769695034, 314037.2945439519, 314037.2945439519, 105800.464992489]
[2019-03-23 16:06:31,339] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:06:31,348] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 9.8333762e-14 2.8990158e-26 1.5697367e-24 5.0152001e-21], sampled 0.5389563545504605
[2019-03-23 16:06:55,580] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05020032], dtype=float32), 0.35877055]
[2019-03-23 16:06:55,581] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.675838095, 92.66338497000001, 1.0, 2.0, 0.5108161894391917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 581707.525399583, 581707.525399583, 148548.7735741172]
[2019-03-23 16:06:55,582] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:06:55,584] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 1.2799281e-10 5.8853487e-20 1.1090530e-18 4.6892665e-16], sampled 0.8026063802523327
[2019-03-23 16:06:55,586] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 581707.525399583 W.
[2019-03-23 16:07:07,915] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05020032], dtype=float32), 0.35877055]
[2019-03-23 16:07:07,917] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.05, 78.0, 1.0, 1.0, 0.4408294184306099, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32819498221613, 497581.7303159976, 497581.7303159979, 129074.4203598064]
[2019-03-23 16:07:07,917] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:07:07,922] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 6.0171998e-12 1.2308709e-22 3.6247361e-21 3.6015589e-18], sampled 0.5832203453380967
[2019-03-23 16:07:20,244] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05020032], dtype=float32), 0.35877055]
[2019-03-23 16:07:20,245] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.73333333333333, 87.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6197465856299886, 6.9112, 6.9112, 95.55338769695034, 359760.7765137604, 359760.7765137604, 119968.2469836941]
[2019-03-23 16:07:20,246] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:07:20,252] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 7.4992427e-13 1.4845932e-24 6.1887350e-23 1.1746772e-19], sampled 0.7344825074458664
[2019-03-23 16:07:20,872] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05020032], dtype=float32), 0.35877055]
[2019-03-23 16:07:20,872] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.5, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6865582766641104, 6.936614375363192, 6.9112, 95.5532329430595, 406541.8641574773, 396342.4760949154, 127691.710336426]
[2019-03-23 16:07:20,875] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:07:20,878] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0000000e+00 1.5513576e-12 5.7771873e-24 2.2160769e-22 3.5384370e-19], sampled 0.6842607962168022
[2019-03-23 16:07:33,449] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6553.1725 1698634175.0084 2957.0000
[2019-03-23 16:07:33,605] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6862.2842 1793014293.7888 2409.0000
[2019-03-23 16:07:33,896] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6328.7217 1723294598.4314 3425.0000
[2019-03-23 16:07:34,014] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6294.9961 1685630448.6673 3228.0000
[2019-03-23 16:07:34,036] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6481.6076 1678885180.2952 3057.0000
[2019-03-23 16:07:35,053] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 2125000, evaluation results [2125000.0, 6862.284208925443, 1793014293.78876, 2409.0, 6481.607577760913, 1678885180.2951708, 3057.0, 6294.9960618483565, 1685630448.6673346, 3228.0, 6328.721692698646, 1723294598.4313502, 3425.0, 6553.172466661831, 1698634175.0084193, 2957.0]
[2019-03-23 16:07:37,020] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.00000000e+00 8.37242263e-14 2.47049843e-28 1.14078416e-26
 3.64433701e-23], sum to 1.0000
[2019-03-23 16:07:37,029] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133000, global step 2125964: loss 0.0066
[2019-03-23 16:07:37,029] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6920
[2019-03-23 16:07:37,031] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133000, global step 2125964: learning rate 0.0000
[2019-03-23 16:07:37,038] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.0, 88.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4259211418042235, 6.911199999999999, 6.9112, 77.32846344354104, 247726.0995573319, 247726.0995573321, 78083.42780423148], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 199200.0000, 
sim time next is 199800.0000, 
raw observation next is [15.5, 85.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4354539443487986, 6.911199999999999, 6.9112, 77.32846344354104, 253272.0530720924, 253272.0530720927, 80248.00243557821], 
processed observation next is [0.0, 0.30434782608695654, 0.3409090909090909, 0.855, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.19350563478399802, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09380446410077496, 0.09380446410077507, 0.19572683520872733], 
reward next is 0.8043, 
noisyNet noise sample is [array([-2.1435857], dtype=float32), -1.2986766]. 
=============================================
[2019-03-23 16:07:40,575] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133000, global step 2127810: loss 0.4573
[2019-03-23 16:07:40,575] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133000, global step 2127810: learning rate 0.0000
[2019-03-23 16:07:41,109] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133000, global step 2128096: loss 0.0051
[2019-03-23 16:07:41,111] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133000, global step 2128096: learning rate 0.0000
[2019-03-23 16:07:41,257] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133000, global step 2128174: loss 0.2071
[2019-03-23 16:07:41,262] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133000, global step 2128175: learning rate 0.0000
[2019-03-23 16:07:41,404] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133000, global step 2128251: loss 0.0029
[2019-03-23 16:07:41,407] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133000, global step 2128251: learning rate 0.0000
[2019-03-23 16:07:41,412] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133000, global step 2128256: loss 0.0067
[2019-03-23 16:07:41,415] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133000, global step 2128257: learning rate 0.0000
[2019-03-23 16:07:41,426] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133000, global step 2128260: loss 0.0070
[2019-03-23 16:07:41,427] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133000, global step 2128260: learning rate 0.0000
[2019-03-23 16:07:41,444] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133000, global step 2128270: loss 0.0342
[2019-03-23 16:07:41,445] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133000, global step 2128270: learning rate 0.0000
[2019-03-23 16:07:41,533] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133000, global step 2128321: loss 0.1225
[2019-03-23 16:07:41,534] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133000, global step 2128321: learning rate 0.0000
[2019-03-23 16:07:41,908] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133000, global step 2128514: loss 0.1253
[2019-03-23 16:07:41,910] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133000, global step 2128516: learning rate 0.0000
[2019-03-23 16:07:41,995] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133000, global step 2128565: loss 0.0019
[2019-03-23 16:07:41,996] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133000, global step 2128565: learning rate 0.0000
[2019-03-23 16:07:42,101] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133000, global step 2128624: loss 0.0169
[2019-03-23 16:07:42,103] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133000, global step 2128625: learning rate 0.0000
[2019-03-23 16:07:42,115] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133000, global step 2128630: loss 0.0045
[2019-03-23 16:07:42,116] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133000, global step 2128631: learning rate 0.0000
[2019-03-23 16:07:42,321] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.1073986e-13 1.2500711e-25 3.4069921e-23 6.6801769e-20], sum to 1.0000
[2019-03-23 16:07:42,326] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9739
[2019-03-23 16:07:42,331] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.33333333333333, 42.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4911587286429077, 6.911199999999999, 6.9112, 77.32846344354104, 285681.011230287, 285681.0112302873, 83415.76143054635], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 319800.0000, 
sim time next is 320400.0000, 
raw observation next is [21.0, 43.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4841524475429147, 6.911199999999999, 6.9112, 77.32846344354104, 281604.6488869131, 281604.6488869134, 81515.98225568506], 
processed observation next is [0.0, 0.7391304347826086, 0.5909090909090909, 0.43, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.26307492506130675, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1042980181062641, 0.10429801810626421, 0.198819468916305], 
reward next is 0.8012, 
noisyNet noise sample is [array([-1.157329], dtype=float32), -0.36034405]. 
=============================================
[2019-03-23 16:07:42,679] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133000, global step 2128923: loss 0.0252
[2019-03-23 16:07:42,685] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133000, global step 2128925: learning rate 0.0000
[2019-03-23 16:07:42,786] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133000, global step 2128981: loss 0.0168
[2019-03-23 16:07:42,793] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133000, global step 2128983: learning rate 0.0000
[2019-03-23 16:07:44,945] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9999988e-01 7.3400585e-08 5.8854251e-13 2.0064343e-12 3.4145849e-11], sum to 1.0000
[2019-03-23 16:07:44,953] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1343
[2019-03-23 16:07:44,956] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.0, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4251000042594721, 6.9112, 6.9112, 77.32846344354104, 247248.3846550042, 247248.3846550042, 71272.20550948185], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 378000.0000, 
sim time next is 378600.0000, 
raw observation next is [15.33333333333333, 75.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4993020837645132, 6.911199999999999, 6.9112, 77.32846344354104, 290418.9837272667, 290418.983727267, 77549.82009818037], 
processed observation next is [1.0, 0.391304347826087, 0.3333333333333332, 0.755, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.28471726252073315, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10756258656565434, 0.10756258656565446, 0.18914590267848871], 
reward next is 0.8109, 
noisyNet noise sample is [array([-0.75291723], dtype=float32), 0.6753534]. 
=============================================
[2019-03-23 16:07:49,177] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133500, global step 2132286: loss 0.0575
[2019-03-23 16:07:49,181] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133500, global step 2132286: learning rate 0.0000
[2019-03-23 16:07:52,424] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133500, global step 2133997: loss 0.3787
[2019-03-23 16:07:52,427] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133500, global step 2133998: learning rate 0.0000
[2019-03-23 16:07:53,691] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9999964e-01 3.5619206e-07 7.8290264e-15 3.3558429e-14 3.7810549e-12], sum to 1.0000
[2019-03-23 16:07:53,696] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5076
[2019-03-23 16:07:53,701] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 590281.7209664641 W.
[2019-03-23 16:07:53,706] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.33333333333334, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7603484863923923, 7.366559181641064, 6.9112, 77.32712434908643, 590281.7209664641, 442392.9335049857, 119287.8217758467], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 552000.0000, 
sim time next is 552600.0000, 
raw observation next is [16.5, 88.0, 1.0, 1.0, 0.2382700144702696, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4449432688578617, 6.9112, 6.9112, 77.3281886033114, 517554.1093874937, 517554.1093874937, 157921.629123693], 
processed observation next is [1.0, 0.391304347826087, 0.38636363636363635, 0.88, 1.0, 0.5, 0.04783751808783699, 0.0, 1.0, -0.25, 1.0, 1.0, 0.20706181265408813, 0.0, 0.0, 0.5084270058668802, 0.19168670718055322, 0.19168670718055322, 0.38517470517973906], 
reward next is 0.6148, 
noisyNet noise sample is [array([0.7026007], dtype=float32), 0.0048855385]. 
=============================================
[2019-03-23 16:07:55,655] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.000000e+00 7.839288e-09 1.764552e-17 7.407849e-16 2.082818e-13], sum to 1.0000
[2019-03-23 16:07:55,664] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2063
[2019-03-23 16:07:55,669] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.66666666666667, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6758953513831973, 6.9112, 6.9112, 77.32846344354104, 390669.2071719625, 390669.2071719625, 122001.9106463064], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 584400.0000, 
sim time next is 585000.0000, 
raw observation next is [20.5, 73.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.675053863771607, 6.9112, 6.9112, 77.32846344354104, 390102.0357178021, 390102.0357178021, 121980.9022602974], 
processed observation next is [1.0, 0.782608695652174, 0.5681818181818182, 0.735, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5357912339594386, 0.0, 0.0, 0.5084288129206541, 0.14448223545103783, 0.14448223545103783, 0.2975143957568229], 
reward next is 0.7025, 
noisyNet noise sample is [array([1.582469], dtype=float32), 1.5446764]. 
=============================================
[2019-03-23 16:07:55,686] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[56.302315]
 [57.625294]
 [57.51582 ]
 [58.012604]
 [57.987522]], R is [[55.84919739]
 [55.99314117]
 [56.13612747]
 [56.27804565]
 [56.418293  ]].
[2019-03-23 16:07:56,085] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133500, global step 2135916: loss 1.0842
[2019-03-23 16:07:56,090] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133500, global step 2135916: learning rate 0.0000
[2019-03-23 16:07:56,259] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133500, global step 2136000: loss 0.7557
[2019-03-23 16:07:56,261] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133500, global step 2136002: learning rate 0.0000
[2019-03-23 16:07:56,600] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133500, global step 2136183: loss 0.2141
[2019-03-23 16:07:56,602] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133500, global step 2136183: learning rate 0.0000
[2019-03-23 16:07:56,632] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133500, global step 2136202: loss 0.2536
[2019-03-23 16:07:56,635] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133500, global step 2136202: learning rate 0.0000
[2019-03-23 16:07:56,657] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133500, global step 2136213: loss 0.4052
[2019-03-23 16:07:56,658] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133500, global step 2136213: learning rate 0.0000
[2019-03-23 16:07:56,698] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133500, global step 2136233: loss 0.4316
[2019-03-23 16:07:56,700] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133500, global step 2136233: learning rate 0.0000
[2019-03-23 16:07:56,724] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133500, global step 2136248: loss 0.3144
[2019-03-23 16:07:56,726] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133500, global step 2136248: learning rate 0.0000
[2019-03-23 16:07:56,826] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133500, global step 2136305: loss 0.5462
[2019-03-23 16:07:56,827] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133500, global step 2136305: learning rate 0.0000
[2019-03-23 16:07:57,013] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133500, global step 2136402: loss 0.2980
[2019-03-23 16:07:57,014] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133500, global step 2136402: learning rate 0.0000
[2019-03-23 16:07:57,377] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133500, global step 2136589: loss 0.4508
[2019-03-23 16:07:57,380] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133500, global step 2136590: learning rate 0.0000
[2019-03-23 16:07:57,383] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133500, global step 2136591: loss 0.4238
[2019-03-23 16:07:57,386] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133500, global step 2136593: learning rate 0.0000
[2019-03-23 16:07:57,651] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133500, global step 2136735: loss 0.3931
[2019-03-23 16:07:57,654] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133500, global step 2136735: learning rate 0.0000
[2019-03-23 16:07:57,953] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133500, global step 2136898: loss 0.4298
[2019-03-23 16:07:57,964] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133500, global step 2136898: learning rate 0.0000
[2019-03-23 16:07:58,082] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133500, global step 2136963: loss 0.5020
[2019-03-23 16:07:58,086] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133500, global step 2136964: learning rate 0.0000
[2019-03-23 16:08:01,695] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.00000000e+00 1.02864714e-14 3.78739063e-21 7.13094635e-21
 1.41037383e-19], sum to 1.0000
[2019-03-23 16:08:01,702] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1043
[2019-03-23 16:08:01,706] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.5, 60.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6776151224296622, 6.911199999999999, 6.9112, 77.32846344354104, 391542.7507208281, 391542.7507208284, 122257.989007017], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 682200.0000, 
sim time next is 682800.0000, 
raw observation next is [22.33333333333334, 61.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6844918204630394, 6.9112, 6.9112, 77.32846344354104, 395466.7579811975, 395466.7579811975, 122965.8204445907], 
processed observation next is [1.0, 0.9130434782608695, 0.6515151515151518, 0.6166666666666667, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5492740292329135, 0.0, 0.0, 0.5084288129206541, 0.14646916962266573, 0.14646916962266573, 0.29991663523070905], 
reward next is 0.7001, 
noisyNet noise sample is [array([0.59295344], dtype=float32), -0.5537966]. 
=============================================
[2019-03-23 16:08:02,887] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.2701838e-09 2.7894716e-15 1.6143093e-14 7.6916511e-13], sum to 1.0000
[2019-03-23 16:08:02,902] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7252
[2019-03-23 16:08:02,905] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.33333333333334, 92.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7466101831996514, 7.156150252836211, 6.9112, 77.32783420681011, 507325.598195257, 427771.4135262711, 132059.3011163255], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 873600.0000, 
sim time next is 874200.0000, 
raw observation next is [19.16666666666667, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7577070142145264, 7.257771833844532, 6.9112, 77.32743688578542, 547391.2026092937, 434833.2538556771, 132823.158920905], 
processed observation next is [0.0, 0.08695652173913043, 0.5075757575757578, 0.93, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6538671631636092, 0.034657183384453207, 0.0, 0.5084220633808618, 0.20273748244788659, 0.1610493532798804, 0.32395892419732925], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.18461612], dtype=float32), 0.75216234]. 
=============================================
[2019-03-23 16:08:04,751] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134000, global step 2140448: loss -5.7297
[2019-03-23 16:08:04,752] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134000, global step 2140448: learning rate 0.0000
[2019-03-23 16:08:06,124] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 2.8463987e-08 3.0078171e-09 1.7568744e-10 1.1859169e-09], sum to 1.0000
[2019-03-23 16:08:06,133] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7690
[2019-03-23 16:08:06,141] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 544553.0240531203 W.
[2019-03-23 16:08:06,146] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7616008552157855, 7.250573022601261, 6.9112, 77.32761680071668, 544553.0240531203, 434332.814467433, 135229.5151349301], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 783000.0000, 
sim time next is 783600.0000, 
raw observation next is [20.66666666666666, 84.66666666666667, 1.0, 1.0, 0.4394643467951019, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32825950244661, 498168.6344356343, 498168.6344356343, 130229.424503542], 
processed observation next is [0.0, 0.043478260869565216, 0.5757575757575755, 0.8466666666666667, 1.0, 0.5, 0.29933043349387733, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.508427472023345, 0.18450690164282751, 0.18450690164282751, 0.3176327426915659], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.050614], dtype=float32), 0.11313261]. 
=============================================
[2019-03-23 16:08:07,750] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134000, global step 2142031: loss -39.2271
[2019-03-23 16:08:07,751] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134000, global step 2142031: learning rate 0.0000
[2019-03-23 16:08:08,099] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 8.0704876e-17 3.3321224e-15 3.3796896e-17 3.8555768e-17], sum to 1.0000
[2019-03-23 16:08:08,106] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1381
[2019-03-23 16:08:08,112] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 652881.3656938974 W.
[2019-03-23 16:08:08,116] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 59.33333333333334, 1.0, 2.0, 0.5774853505386974, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 652881.3656938974, 652881.3656938977, 154848.5670395666], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 823800.0000, 
sim time next is 824400.0000, 
raw observation next is [29.0, 58.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 1.0, 0.3831600826070101, 6.9112, 6.9112, 77.3421103, 640689.1980006654, 640689.1980006654, 226667.8793298246], 
processed observation next is [0.0, 0.5652173913043478, 0.9545454545454546, 0.58, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.5, 0.11880011801001449, 0.0, 0.0, 0.5085185399722538, 0.237292295555802, 0.237292295555802, 0.5528484861703039], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.3752952], dtype=float32), 0.21647479]. 
=============================================
[2019-03-23 16:08:08,448] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 3.7499767e-17 6.1008365e-15 1.9023913e-16 1.9107689e-17], sum to 1.0000
[2019-03-23 16:08:08,457] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5967
[2019-03-23 16:08:08,462] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 661379.8770986944 W.
[2019-03-23 16:08:08,466] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [17.16666666666667, 100.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3838728780131982, 6.911199999999999, 6.9112, 77.3421103, 661379.8770986944, 661379.8770986948, 210692.4602368784], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 985800.0000, 
sim time next is 986400.0000, 
raw observation next is [17.0, 100.0, 1.0, 2.0, 0.2955693230173023, 1.0, 2.0, 0.2955693230173023, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 663426.0035457395, 663426.0035457397, 173959.7074357801], 
processed observation next is [1.0, 0.43478260869565216, 0.4090909090909091, 1.0, 1.0, 1.0, 0.11946165377162789, 1.0, 1.0, 0.11946165377162789, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24571333464657016, 0.24571333464657025, 0.4242919693555612], 
reward next is 0.5757, 
noisyNet noise sample is [array([-0.4556909], dtype=float32), -1.5178831]. 
=============================================
[2019-03-23 16:08:11,281] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134000, global step 2143888: loss -19.3776
[2019-03-23 16:08:11,283] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134000, global step 2143889: learning rate 0.0000
[2019-03-23 16:08:11,546] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134000, global step 2144030: loss -12.3550
[2019-03-23 16:08:11,547] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134000, global step 2144030: learning rate 0.0000
[2019-03-23 16:08:11,801] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134000, global step 2144159: loss -56.8992
[2019-03-23 16:08:11,802] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134000, global step 2144159: learning rate 0.0000
[2019-03-23 16:08:11,856] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134000, global step 2144192: loss -6.1565
[2019-03-23 16:08:11,858] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134000, global step 2144192: learning rate 0.0000
[2019-03-23 16:08:11,883] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134000, global step 2144205: loss 5.9037
[2019-03-23 16:08:11,885] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134000, global step 2144205: learning rate 0.0000
[2019-03-23 16:08:11,916] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134000, global step 2144218: loss -46.2458
[2019-03-23 16:08:11,919] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134000, global step 2144219: learning rate 0.0000
[2019-03-23 16:08:12,077] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134000, global step 2144305: loss -7.1713
[2019-03-23 16:08:12,080] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134000, global step 2144307: learning rate 0.0000
[2019-03-23 16:08:12,161] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134000, global step 2144350: loss -42.3279
[2019-03-23 16:08:12,163] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134000, global step 2144351: learning rate 0.0000
[2019-03-23 16:08:12,230] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134000, global step 2144387: loss -23.0786
[2019-03-23 16:08:12,232] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134000, global step 2144387: learning rate 0.0000
[2019-03-23 16:08:12,549] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134000, global step 2144553: loss -28.4426
[2019-03-23 16:08:12,552] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134000, global step 2144555: learning rate 0.0000
[2019-03-23 16:08:12,735] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134000, global step 2144648: loss -33.8134
[2019-03-23 16:08:12,742] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134000, global step 2144649: learning rate 0.0000
[2019-03-23 16:08:12,810] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134000, global step 2144688: loss -25.7901
[2019-03-23 16:08:12,811] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134000, global step 2144688: learning rate 0.0000
[2019-03-23 16:08:13,280] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134000, global step 2144937: loss -30.6131
[2019-03-23 16:08:13,284] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134000, global step 2144937: learning rate 0.0000
[2019-03-23 16:08:13,329] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134000, global step 2144963: loss -16.5474
[2019-03-23 16:08:13,330] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134000, global step 2144963: learning rate 0.0000
[2019-03-23 16:08:14,055] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9631292e-01 3.5742901e-03 4.1129115e-05 9.2220580e-06 6.2531486e-05], sum to 1.0000
[2019-03-23 16:08:14,066] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6852
[2019-03-23 16:08:14,068] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [12.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3218089186870935, 6.9112, 6.9112, 77.32846344354104, 187160.2473436401, 187160.2473436401, 60485.4799336532], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1040400.0000, 
sim time next is 1041000.0000, 
raw observation next is [12.16666666666667, 99.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3218407611304649, 6.911200000000001, 6.9112, 77.32846344354104, 187178.7700937754, 187178.7700937751, 60662.64933532174], 
processed observation next is [1.0, 0.043478260869565216, 0.18939393939393953, 0.9900000000000001, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.03120108732923558, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.06932547040510201, 0.06932547040510188, 0.14795768130566278], 
reward next is 0.8520, 
noisyNet noise sample is [array([0.42184114], dtype=float32), -0.05915357]. 
=============================================
[2019-03-23 16:08:14,082] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[16.598919]
 [16.354992]
 [16.032145]
 [15.725792]
 [15.599623]], R is [[17.61563301]
 [18.29195023]
 [18.95990181]
 [19.61934471]
 [20.27026367]].
[2019-03-23 16:08:20,173] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134500, global step 2148525: loss -131.6474
[2019-03-23 16:08:20,174] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134500, global step 2148525: learning rate 0.0000
[2019-03-23 16:08:20,902] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.3822220e-30 2.0869014e-21 3.5740603e-27 1.6048697e-28], sum to 1.0000
[2019-03-23 16:08:20,907] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2571
[2019-03-23 16:08:20,912] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 556838.8417970114 W.
[2019-03-23 16:08:20,921] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [19.66666666666666, 68.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 1.0, 0.3205159925441206, 6.9112, 6.9112, 77.3421103, 556838.8417970114, 556838.8417970114, 193407.4034827311], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1075200.0000, 
sim time next is 1075800.0000, 
raw observation next is [19.83333333333334, 68.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3158859850423921, 6.911199999999999, 6.9112, 77.3421103, 548319.1760500905, 548319.1760500908, 193088.4579657149], 
processed observation next is [1.0, 0.43478260869565216, 0.5378787878787882, 0.68, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.022694264346274483, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.20308117631484832, 0.20308117631484846, 0.47094745845296315], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.35878167], dtype=float32), -0.27840063]. 
=============================================
[2019-03-23 16:08:22,894] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134500, global step 2149960: loss -313.2103
[2019-03-23 16:08:22,898] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134500, global step 2149960: learning rate 0.0000
[2019-03-23 16:08:22,982] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 16:08:22,984] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:08:22,985] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:08:22,985] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:08:22,986] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:08:22,986] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:08:22,987] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:08:22,987] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:08:22,988] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:08:22,988] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:08:22,990] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:08:23,010] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run87
[2019-03-23 16:08:23,040] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run87
[2019-03-23 16:08:23,070] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run87
[2019-03-23 16:08:23,071] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run87
[2019-03-23 16:08:23,133] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run87
[2019-03-23 16:08:33,898] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05537751], dtype=float32), 0.3575881]
[2019-03-23 16:08:33,899] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.35018652333333, 53.45641482166666, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7636909281461263, 7.510061886672838, 6.9112, 95.5515107205409, 674961.5607011347, 434628.4971660541, 140411.3294564637]
[2019-03-23 16:08:33,900] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:08:33,903] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 4.4278372e-15 4.1884972e-16 2.6301724e-21 1.3550400e-19], sampled 0.4279765091094785
[2019-03-23 16:08:33,907] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 674961.5607011347 W.
[2019-03-23 16:09:05,367] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05537751], dtype=float32), 0.3575881]
[2019-03-23 16:09:05,367] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.824675055, 91.90643349999999, 1.0, 2.0, 0.4805401115081832, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 547803.6527264863, 547803.652726486, 141552.2321449668]
[2019-03-23 16:09:05,368] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:09:05,371] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 9.6542926e-15 7.2285209e-16 5.3281341e-21 2.8700864e-19], sampled 0.3272093570736051
[2019-03-23 16:09:05,373] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 547803.6527264863 W.
[2019-03-23 16:09:49,296] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05537751], dtype=float32), 0.3575881]
[2019-03-23 16:09:49,296] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [31.52808717333334, 72.51464192, 1.0, 2.0, 0.7879979941398462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 885534.530835166, 885534.5308351656, 192223.4940846948]
[2019-03-23 16:09:49,297] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:09:49,301] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0000000e+00 1.7673889e-16 3.7600486e-16 2.9620370e-21 5.1524599e-20], sampled 0.8634543204076539
[2019-03-23 16:09:49,302] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 885534.530835166 W.
[2019-03-23 16:09:50,301] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05537751], dtype=float32), 0.3575881]
[2019-03-23 16:09:50,303] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.68333333333334, 78.66666666666667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7382193018415039, 7.319322256422094, 6.9112, 95.55209432469577, 585680.9321919824, 421893.7995570457, 136178.2305678163]
[2019-03-23 16:09:50,305] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:09:50,310] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 2.9463185e-12 6.9746870e-15 8.1802605e-20 1.4144269e-17], sampled 0.9152026450894581
[2019-03-23 16:09:50,310] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 585680.9321919824 W.
[2019-03-23 16:09:53,423] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05537751], dtype=float32), 0.3575881]
[2019-03-23 16:09:53,423] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [29.3, 56.0, 1.0, 2.0, 0.778429198661488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 882833.8505256912, 882833.8505256912, 188297.6565498608]
[2019-03-23 16:09:53,424] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:09:53,428] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0000000e+00 5.3060741e-18 1.9315673e-17 5.8385375e-23 1.0717398e-21], sampled 0.7271639637328637
[2019-03-23 16:09:53,429] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 882833.8505256912 W.
[2019-03-23 16:10:09,960] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6481.6076 1678885180.2952 3057.0000
[2019-03-23 16:10:10,163] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6328.7217 1723294598.4314 3425.0000
[2019-03-23 16:10:10,456] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6294.9961 1685630448.6673 3228.0000
[2019-03-23 16:10:10,482] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6553.1725 1698634175.0084 2957.0000
[2019-03-23 16:10:10,601] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6862.2842 1793014293.7888 2409.0000
[2019-03-23 16:10:11,617] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 2150000, evaluation results [2150000.0, 6862.284208925443, 1793014293.78876, 2409.0, 6481.607577760913, 1678885180.2951708, 3057.0, 6294.9960618483565, 1685630448.6673346, 3228.0, 6328.721692698646, 1723294598.4313502, 3425.0, 6553.172466661831, 1698634175.0084193, 2957.0]
[2019-03-23 16:10:11,705] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.0022201e-20 5.0987881e-20 2.4729821e-25 4.3787026e-24], sum to 1.0000
[2019-03-23 16:10:11,709] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1411
[2019-03-23 16:10:11,711] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1634335.671154458 W.
[2019-03-23 16:10:11,724] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.0, 60.66666666666667, 1.0, 2.0, 0.9601911975334451, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9813202034787616, 6.911200000000001, 6.9112, 77.32846344354104, 1634335.671154458, 1634335.671154457, 341010.6612697769], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1264800.0000, 
sim time next is 1265400.0000, 
raw observation next is [28.0, 60.0, 1.0, 2.0, 0.4836897578731174, 1.0, 1.0, 0.4836897578731174, 1.0, 2.0, 0.9780394396792802, 6.911199999999999, 6.9112, 77.3421103, 1632064.257995749, 1632064.25799575, 350934.1888951145], 
processed observation next is [1.0, 0.6521739130434783, 0.9090909090909091, 0.6, 1.0, 1.0, 0.3546121973413967, 1.0, 0.5, 0.3546121973413967, 1.0, 1.0, 0.9686277709704003, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.6044682437021293, 0.6044682437021297, 0.8559370460856451], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.26584542], dtype=float32), -1.1185492]. 
=============================================
[2019-03-23 16:10:15,320] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134500, global step 2151850: loss -179.3700
[2019-03-23 16:10:15,324] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134500, global step 2151850: learning rate 0.0000
[2019-03-23 16:10:15,748] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134500, global step 2152071: loss -172.7206
[2019-03-23 16:10:15,750] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134500, global step 2152071: learning rate 0.0000
[2019-03-23 16:10:15,821] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134500, global step 2152108: loss -137.3728
[2019-03-23 16:10:15,824] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134500, global step 2152108: learning rate 0.0000
[2019-03-23 16:10:15,883] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134500, global step 2152141: loss -80.1157
[2019-03-23 16:10:15,886] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134500, global step 2152141: learning rate 0.0000
[2019-03-23 16:10:16,186] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134500, global step 2152298: loss -82.2658
[2019-03-23 16:10:16,190] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134500, global step 2152298: learning rate 0.0000
[2019-03-23 16:10:16,252] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134500, global step 2152336: loss -201.3766
[2019-03-23 16:10:16,254] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134500, global step 2152336: learning rate 0.0000
[2019-03-23 16:10:16,266] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134500, global step 2152341: loss -189.0681
[2019-03-23 16:10:16,267] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134500, global step 2152341: learning rate 0.0000
[2019-03-23 16:10:16,273] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134500, global step 2152344: loss -249.7305
[2019-03-23 16:10:16,276] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134500, global step 2152345: learning rate 0.0000
[2019-03-23 16:10:16,488] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134500, global step 2152454: loss -103.7564
[2019-03-23 16:10:16,491] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134500, global step 2152455: learning rate 0.0000
[2019-03-23 16:10:16,526] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134500, global step 2152476: loss -77.6853
[2019-03-23 16:10:16,529] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134500, global step 2152477: learning rate 0.0000
[2019-03-23 16:10:16,606] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134500, global step 2152513: loss -117.6413
[2019-03-23 16:10:16,608] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134500, global step 2152513: learning rate 0.0000
[2019-03-23 16:10:16,702] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134500, global step 2152569: loss -164.4415
[2019-03-23 16:10:16,706] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134500, global step 2152571: learning rate 0.0000
[2019-03-23 16:10:17,254] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134500, global step 2152850: loss -84.3867
[2019-03-23 16:10:17,254] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134500, global step 2152850: learning rate 0.0000
[2019-03-23 16:10:17,405] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134500, global step 2152932: loss -53.9732
[2019-03-23 16:10:17,405] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134500, global step 2152932: learning rate 0.0000
[2019-03-23 16:10:20,241] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.0427924e-07 9.9999964e-01 2.0142781e-13 1.2510205e-13 2.1737299e-12], sum to 1.0000
[2019-03-23 16:10:20,248] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9118
[2019-03-23 16:10:20,257] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1634335.671142574 W.
[2019-03-23 16:10:20,262] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 60.66666666666667, 1.0, 2.0, 0.7265427539150805, 1.0, 2.0, 0.7265427539150805, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1634335.671142574, 1634335.671142574, 300255.3730127903], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1264800.0000, 
sim time next is 1265400.0000, 
raw observation next is [28.0, 60.0, 1.0, 2.0, 0.7255075290984546, 1.0, 2.0, 0.7255075290984546, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1632003.607418859, 1632003.607418859, 299918.7826703832], 
processed observation next is [1.0, 0.6521739130434783, 0.9090909090909091, 0.6, 1.0, 1.0, 0.6568844113730682, 1.0, 1.0, 0.6568844113730682, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.6044457805255034, 0.6044457805255034, 0.731509226025325], 
reward next is 0.2685, 
noisyNet noise sample is [array([-0.07910377], dtype=float32), 1.2639524]. 
=============================================
[2019-03-23 16:10:22,762] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2444197e-04 9.9987555e-01 1.6160585e-10 8.3574220e-10 4.9209625e-10], sum to 1.0000
[2019-03-23 16:10:22,771] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0272
[2019-03-23 16:10:22,778] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3889833024767815, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 436733.5849284427, 436733.5849284427, 123049.007640969], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1314000.0000, 
sim time next is 1314600.0000, 
raw observation next is [18.16666666666667, 100.0, 1.0, 2.0, 0.3866448887817771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 434711.5299646939, 434711.5299646936, 123144.2789557678], 
processed observation next is [1.0, 0.21739130434782608, 0.4621212121212123, 1.0, 1.0, 1.0, 0.23330611097722137, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16100427035729403, 0.16100427035729392, 0.3003518998921166], 
reward next is 0.6996, 
noisyNet noise sample is [array([0.01896734], dtype=float32), 0.2120671]. 
=============================================
[2019-03-23 16:10:24,477] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135000, global step 2156599: loss 0.0961
[2019-03-23 16:10:24,480] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135000, global step 2156600: learning rate 0.0000
[2019-03-23 16:10:26,753] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135000, global step 2157805: loss 0.1691
[2019-03-23 16:10:26,756] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135000, global step 2157805: learning rate 0.0000
[2019-03-23 16:10:27,465] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.1198969e-08 1.0000000e+00 2.8955157e-16 5.9191003e-12 1.2985249e-18], sum to 1.0000
[2019-03-23 16:10:27,478] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5639
[2019-03-23 16:10:27,487] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 82.16666666666667, 1.0, 2.0, 0.5145919784696329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 586036.4200313567, 586036.4200313565, 144729.4359830565], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1422600.0000, 
sim time next is 1423200.0000, 
raw observation next is [24.0, 81.33333333333334, 1.0, 2.0, 0.510736751637036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 581893.1490161468, 581893.1490161468, 144045.7842508437], 
processed observation next is [0.0, 0.4782608695652174, 0.7272727272727273, 0.8133333333333335, 1.0, 1.0, 0.388420939546295, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2155159811170914, 0.2155159811170914, 0.35133118109961875], 
reward next is 0.6487, 
noisyNet noise sample is [array([-0.44375968], dtype=float32), 1.1125246]. 
=============================================
[2019-03-23 16:10:27,540] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.3377350e-08 9.9999988e-01 3.7952840e-15 7.7323842e-12 1.2078043e-16], sum to 1.0000
[2019-03-23 16:10:27,551] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7346
[2019-03-23 16:10:27,557] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 73.33333333333334, 1.0, 2.0, 0.5428640247439193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 615708.6832837347, 615708.6832837347, 149614.6593726249], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1429800.0000, 
sim time next is 1430400.0000, 
raw observation next is [26.33333333333334, 72.66666666666667, 1.0, 2.0, 0.5477072817372917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 620947.9421305477, 620947.9421305477, 150335.3972151533], 
processed observation next is [0.0, 0.5652173913043478, 0.8333333333333336, 0.7266666666666667, 1.0, 1.0, 0.4346341021716145, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22998071930761027, 0.22998071930761027, 0.3666717005247641], 
reward next is 0.6333, 
noisyNet noise sample is [array([-0.45084512], dtype=float32), -1.2401575]. 
=============================================
[2019-03-23 16:10:28,968] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.3502803e-08 9.9999988e-01 7.0546097e-16 4.9591902e-14 2.7423903e-17], sum to 1.0000
[2019-03-23 16:10:28,978] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1803
[2019-03-23 16:10:28,982] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.4606070201979109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 525358.3265889528, 525358.3265889531, 135535.27639735], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1452600.0000, 
sim time next is 1453200.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.4599466893450912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 524604.6407573385, 524604.6407573381, 135464.1299414535], 
processed observation next is [0.0, 0.8260869565217391, 0.5909090909090909, 0.94, 1.0, 1.0, 0.32493336168136394, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19429801509531056, 0.19429801509531042, 0.33040031693037436], 
reward next is 0.6696, 
noisyNet noise sample is [array([0.50694543], dtype=float32), -0.11370877]. 
=============================================
[2019-03-23 16:10:30,485] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135000, global step 2159775: loss 0.0021
[2019-03-23 16:10:30,486] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135000, global step 2159776: learning rate 0.0000
[2019-03-23 16:10:30,914] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135000, global step 2160002: loss 0.0022
[2019-03-23 16:10:30,918] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135000, global step 2160002: learning rate 0.0000
[2019-03-23 16:10:31,209] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135000, global step 2160161: loss 0.1868
[2019-03-23 16:10:31,214] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135000, global step 2160163: learning rate 0.0000
[2019-03-23 16:10:31,248] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135000, global step 2160181: loss 0.1424
[2019-03-23 16:10:31,251] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135000, global step 2160182: learning rate 0.0000
[2019-03-23 16:10:31,472] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135000, global step 2160293: loss 0.0396
[2019-03-23 16:10:31,473] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135000, global step 2160293: learning rate 0.0000
[2019-03-23 16:10:31,600] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135000, global step 2160361: loss 0.0103
[2019-03-23 16:10:31,605] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135000, global step 2160363: learning rate 0.0000
[2019-03-23 16:10:31,621] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135000, global step 2160373: loss 0.0134
[2019-03-23 16:10:31,624] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135000, global step 2160373: learning rate 0.0000
[2019-03-23 16:10:31,704] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135000, global step 2160410: loss 0.0124
[2019-03-23 16:10:31,707] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135000, global step 2160412: learning rate 0.0000
[2019-03-23 16:10:31,735] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135000, global step 2160427: loss 0.0152
[2019-03-23 16:10:31,736] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135000, global step 2160428: loss 0.0477
[2019-03-23 16:10:31,739] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135000, global step 2160429: learning rate 0.0000
[2019-03-23 16:10:31,741] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135000, global step 2160432: learning rate 0.0000
[2019-03-23 16:10:31,831] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135000, global step 2160469: loss 0.1287
[2019-03-23 16:10:31,832] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135000, global step 2160469: learning rate 0.0000
[2019-03-23 16:10:31,944] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135000, global step 2160530: loss 0.0787
[2019-03-23 16:10:31,946] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135000, global step 2160531: learning rate 0.0000
[2019-03-23 16:10:32,520] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135000, global step 2160834: loss 0.0626
[2019-03-23 16:10:32,522] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135000, global step 2160835: learning rate 0.0000
[2019-03-23 16:10:32,906] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135000, global step 2161042: loss 0.0397
[2019-03-23 16:10:32,908] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135000, global step 2161042: learning rate 0.0000
[2019-03-23 16:10:34,217] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.3231438e-09 1.0000000e+00 3.6613045e-18 3.1074068e-16 2.1146482e-18], sum to 1.0000
[2019-03-23 16:10:34,226] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9353
[2019-03-23 16:10:34,232] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 90.0, 1.0, 2.0, 0.4191381778622623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476680.6651168343, 476680.6651168343, 129467.9470314269], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1560000.0000, 
sim time next is 1560600.0000, 
raw observation next is [20.5, 91.0, 1.0, 2.0, 0.4179626575096686, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 475234.463349767, 475234.463349767, 129254.8174648503], 
processed observation next is [1.0, 0.043478260869565216, 0.5681818181818182, 0.91, 1.0, 1.0, 0.2724533218870857, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1760127642036174, 0.1760127642036174, 0.31525565235329345], 
reward next is 0.6847, 
noisyNet noise sample is [array([-0.67042804], dtype=float32), -1.0246001]. 
=============================================
[2019-03-23 16:10:34,683] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.3545256e-07 9.9999952e-01 1.2838007e-13 1.3610232e-11 1.0115567e-13], sum to 1.0000
[2019-03-23 16:10:34,692] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7423
[2019-03-23 16:10:34,695] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.16666666666667, 99.0, 1.0, 2.0, 0.4000487186854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 453715.7527065011, 453715.7527065013, 126619.8989452013], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1565400.0000, 
sim time next is 1566000.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.3976391974216755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 450795.6747357529, 450795.6747357529, 126263.4612949874], 
processed observation next is [1.0, 0.13043478260869565, 0.5, 1.0, 1.0, 1.0, 0.24704899677709438, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16696136101324183, 0.16696136101324183, 0.3079596616950912], 
reward next is 0.6920, 
noisyNet noise sample is [array([0.2664142], dtype=float32), 0.9572234]. 
=============================================
[2019-03-23 16:10:34,710] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[58.569252]
 [58.788765]
 [58.873466]
 [59.055206]
 [58.971264]], R is [[58.79027557]
 [58.89354324]
 [58.99467468]
 [59.09299088]
 [59.18125916]].
[2019-03-23 16:10:35,036] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.31413356e-06 9.99998689e-01 8.87440555e-18 1.35263504e-14
 8.96676423e-17], sum to 1.0000
[2019-03-23 16:10:35,046] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8469
[2019-03-23 16:10:35,049] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666666, 96.0, 1.0, 2.0, 0.4025317397211374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 456941.0463873246, 456941.0463873246, 127153.4772128882], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1575600.0000, 
sim time next is 1576200.0000, 
raw observation next is [19.83333333333334, 95.0, 1.0, 2.0, 0.4039323873078561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 458682.7693368315, 458682.7693368312, 127402.6261162955], 
processed observation next is [1.0, 0.21739130434782608, 0.5378787878787882, 0.95, 1.0, 1.0, 0.25491548413482007, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16988250716178946, 0.16988250716178932, 0.31073811247876953], 
reward next is 0.6893, 
noisyNet noise sample is [array([0.21650568], dtype=float32), 0.13127236]. 
=============================================
[2019-03-23 16:10:38,656] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.9949355e-06 9.9999595e-01 2.1233970e-15 3.6481330e-12 3.0430982e-16], sum to 1.0000
[2019-03-23 16:10:38,663] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3915
[2019-03-23 16:10:38,669] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 91.0, 1.0, 2.0, 0.3445507262609159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 381313.802067222, 381313.802067222, 116863.0281022471], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1650600.0000, 
sim time next is 1651200.0000, 
raw observation next is [18.0, 92.0, 1.0, 2.0, 0.3436711812197031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 380977.3221764624, 380977.3221764621, 117050.2469174409], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 0.92, 1.0, 1.0, 0.17958897652462882, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1411027119172083, 0.1411027119172082, 0.28548840711570955], 
reward next is 0.7145, 
noisyNet noise sample is [array([1.9587342], dtype=float32), 2.1605883]. 
=============================================
[2019-03-23 16:10:39,442] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135500, global step 2164470: loss 0.0628
[2019-03-23 16:10:39,445] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135500, global step 2164471: learning rate 0.0000
[2019-03-23 16:10:42,085] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135500, global step 2165872: loss 6.4485
[2019-03-23 16:10:42,086] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135500, global step 2165872: learning rate 0.0000
[2019-03-23 16:10:45,650] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135500, global step 2167753: loss 0.0268
[2019-03-23 16:10:45,661] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135500, global step 2167755: learning rate 0.0000
[2019-03-23 16:10:46,191] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135500, global step 2168030: loss 0.0610
[2019-03-23 16:10:46,194] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135500, global step 2168030: learning rate 0.0000
[2019-03-23 16:10:46,368] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135500, global step 2168129: loss 0.0128
[2019-03-23 16:10:46,369] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135500, global step 2168129: learning rate 0.0000
[2019-03-23 16:10:46,379] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135500, global step 2168134: loss 0.0206
[2019-03-23 16:10:46,381] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135500, global step 2168134: learning rate 0.0000
[2019-03-23 16:10:46,688] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135500, global step 2168296: loss 0.0777
[2019-03-23 16:10:46,693] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135500, global step 2168298: learning rate 0.0000
[2019-03-23 16:10:46,722] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135500, global step 2168317: loss 0.1316
[2019-03-23 16:10:46,726] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135500, global step 2168317: learning rate 0.0000
[2019-03-23 16:10:46,788] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135500, global step 2168347: loss 0.0856
[2019-03-23 16:10:46,790] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135500, global step 2168349: learning rate 0.0000
[2019-03-23 16:10:46,870] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135500, global step 2168394: loss 0.0028
[2019-03-23 16:10:46,877] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135500, global step 2168394: learning rate 0.0000
[2019-03-23 16:10:46,933] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135500, global step 2168423: loss 0.0127
[2019-03-23 16:10:46,936] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135500, global step 2168424: learning rate 0.0000
[2019-03-23 16:10:47,074] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135500, global step 2168498: loss 0.0024
[2019-03-23 16:10:47,081] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135500, global step 2168502: learning rate 0.0000
[2019-03-23 16:10:47,165] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135500, global step 2168549: loss 0.0111
[2019-03-23 16:10:47,166] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135500, global step 2168549: learning rate 0.0000
[2019-03-23 16:10:47,344] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135500, global step 2168643: loss 0.0153
[2019-03-23 16:10:47,347] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135500, global step 2168644: learning rate 0.0000
[2019-03-23 16:10:47,478] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135500, global step 2168712: loss 0.0568
[2019-03-23 16:10:47,480] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135500, global step 2168712: learning rate 0.0000
[2019-03-23 16:10:48,073] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135500, global step 2169031: loss 0.0656
[2019-03-23 16:10:48,075] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135500, global step 2169031: learning rate 0.0000
[2019-03-23 16:10:50,182] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.9421099e-10 1.6200821e-12 3.0300792e-12 4.4302868e-15], sum to 1.0000
[2019-03-23 16:10:50,189] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4724
[2019-03-23 16:10:50,190] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 591456.6478640685 W.
[2019-03-23 16:10:50,192] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.66666666666666, 47.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7607034285159829, 7.369539221873969, 6.9112, 77.32714371494004, 591456.6478640685, 442599.9837678915, 110378.4135616456], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1853400.0000, 
sim time next is 1854000.0000, 
raw observation next is [21.0, 46.0, 1.0, 1.0, 0.2247286106160142, 1.0, 1.0, 0.2247286106160142, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32818689915443, 488125.6146998561, 488125.6146998564, 150472.5446751594], 
processed observation next is [1.0, 0.4782608695652174, 0.5909090909090909, 0.46, 1.0, 0.5, 0.030910763270017745, 1.0, 0.5, 0.030910763270017745, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084269946621767, 0.1807872647036504, 0.1807872647036505, 0.36700620652477906], 
reward next is 0.6330, 
noisyNet noise sample is [array([0.97329265], dtype=float32), -0.020798758]. 
=============================================
[2019-03-23 16:10:50,204] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[37.96312 ]
 [37.411743]
 [37.72855 ]
 [38.28653 ]
 [38.27862 ]], R is [[36.61298752]
 [36.24685669]
 [35.88438797]
 [36.25841522]
 [35.89583206]].
[2019-03-23 16:10:54,172] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.4910146e-04 9.9915075e-01 3.9769524e-10 1.0023730e-07 4.7112497e-10], sum to 1.0000
[2019-03-23 16:10:54,177] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6819
[2019-03-23 16:10:54,181] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333333, 65.33333333333333, 1.0, 2.0, 0.757487521561972, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 864622.9810187614, 864622.9810187618, 175014.9798163967], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1946400.0000, 
sim time next is 1947000.0000, 
raw observation next is [25.66666666666667, 63.16666666666666, 1.0, 2.0, 0.7347787848942455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 838653.5260310317, 838653.5260310315, 171405.7657981765], 
processed observation next is [1.0, 0.5217391304347826, 0.8030303030303032, 0.6316666666666666, 1.0, 1.0, 0.6684734811178069, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.31061241704853026, 0.3106124170485302, 0.41806284341018657], 
reward next is 0.5819, 
noisyNet noise sample is [array([0.98045015], dtype=float32), 0.060628943]. 
=============================================
[2019-03-23 16:10:54,207] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[56.280045]
 [56.818096]
 [56.265076]
 [55.781384]
 [55.779423]], R is [[56.9513855 ]
 [56.95500946]
 [56.3854599 ]
 [55.82160568]
 [55.65987778]].
[2019-03-23 16:10:54,864] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136000, global step 2172579: loss 0.3655
[2019-03-23 16:10:54,866] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136000, global step 2172581: learning rate 0.0000
[2019-03-23 16:10:56,011] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.7997411e-04 9.9952006e-01 1.7447441e-13 1.0457425e-09 8.5823683e-12], sum to 1.0000
[2019-03-23 16:10:56,022] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3266
[2019-03-23 16:10:56,024] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 62.66666666666667, 1.0, 2.0, 0.3185895329045737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 347899.4605713063, 347899.4605713063, 113135.4576459969], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1982400.0000, 
sim time next is 1983000.0000, 
raw observation next is [21.0, 63.33333333333334, 1.0, 2.0, 0.3199383960239821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 350002.444053184, 350002.444053184, 113455.6366983611], 
processed observation next is [1.0, 0.9565217391304348, 0.5909090909090909, 0.6333333333333334, 1.0, 1.0, 0.1499229950299776, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1296305348345126, 0.1296305348345126, 0.2767210651179539], 
reward next is 0.7233, 
noisyNet noise sample is [array([1.1854258], dtype=float32), -2.274576]. 
=============================================
[2019-03-23 16:10:56,040] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[61.779926]
 [61.907288]
 [62.04925 ]
 [62.257397]
 [62.43115 ]], R is [[61.74687195]
 [61.85346222]
 [61.95959854]
 [62.06539536]
 [62.1709938 ]].
[2019-03-23 16:10:57,258] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136000, global step 2173845: loss 0.0031
[2019-03-23 16:10:57,260] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136000, global step 2173847: learning rate 0.0000
[2019-03-23 16:10:59,415] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 16:10:59,418] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:10:59,419] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:10:59,422] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:10:59,422] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:10:59,421] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:10:59,423] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:10:59,423] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:10:59,424] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:10:59,425] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:10:59,426] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:10:59,446] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run88
[2019-03-23 16:10:59,477] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run88
[2019-03-23 16:10:59,505] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run88
[2019-03-23 16:10:59,535] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run88
[2019-03-23 16:10:59,580] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run88
[2019-03-23 16:11:03,099] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05359066], dtype=float32), 0.3641769]
[2019-03-23 16:11:03,100] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.5, 59.0, 1.0, 2.0, 0.3316331766575343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 367342.7306682997, 367342.7306682994, 120329.2596410858]
[2019-03-23 16:11:03,102] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:11:03,106] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.4383644e-06 9.9999857e-01 3.6464706e-17 3.6815183e-13 3.7771076e-16], sampled 0.5187465875647983
[2019-03-23 16:11:05,393] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05359066], dtype=float32), 0.3641769]
[2019-03-23 16:11:05,394] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.681790935, 73.72945810499999, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 201494.7851925954, 201494.7851925954, 72950.62776112859]
[2019-03-23 16:11:05,395] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:11:05,399] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.2244686e-06 9.9999678e-01 3.9216344e-16 2.2730995e-12 3.5836134e-15], sampled 0.8212074333726697
[2019-03-23 16:11:07,160] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05359066], dtype=float32), 0.3641769]
[2019-03-23 16:11:07,161] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [13.87452565666667, 99.34872208166668, 1.0, 2.0, 0.6146645058767407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 667582.0390219998, 667582.0390219998, 127362.5421157091]
[2019-03-23 16:11:07,164] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:11:07,168] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.3228715e-06 9.9999571e-01 7.5185625e-16 3.6384520e-12 6.5695028e-15], sampled 0.5244840960316631
[2019-03-23 16:11:08,991] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05359066], dtype=float32), 0.3641769]
[2019-03-23 16:11:08,993] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.66666666666666, 61.0, 1.0, 2.0, 0.6305615294935858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 705571.0105563183, 705571.0105563183, 146796.8151831022]
[2019-03-23 16:11:08,994] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:11:08,997] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.6332970e-06 9.9999440e-01 1.5872635e-15 6.4390849e-12 1.3313564e-14], sampled 0.7213505456065589
[2019-03-23 16:11:09,491] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05359066], dtype=float32), 0.3641769]
[2019-03-23 16:11:09,493] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.77837295333334, 55.78469547166667, 1.0, 2.0, 0.3502318047821765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 380292.9719755654, 380292.971975565, 119005.963454999]
[2019-03-23 16:11:09,494] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:11:09,496] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.7778963e-06 9.9999821e-01 6.6920864e-17 5.8478743e-13 6.7061705e-16], sampled 0.7951407204121861
[2019-03-23 16:11:32,570] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05359066], dtype=float32), 0.3641769]
[2019-03-23 16:11:32,571] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.85005662, 79.91514625, 1.0, 2.0, 0.2225587233711257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 241633.5604473884, 241633.560447388, 83426.90101991313]
[2019-03-23 16:11:32,572] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:11:32,577] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.4442570e-06 9.9999857e-01 3.8676355e-17 3.8672749e-13 3.9934859e-16], sampled 0.964747260908161
[2019-03-23 16:11:50,410] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05359066], dtype=float32), 0.3641769]
[2019-03-23 16:11:50,411] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.393017935, 80.15639968, 1.0, 2.0, 0.6516683756611589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 738442.9298773159, 738442.9298773159, 168963.7037526172]
[2019-03-23 16:11:50,413] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:11:50,417] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.2205988e-06 9.9999583e-01 7.7707041e-16 3.8099177e-12 6.8406953e-15], sampled 0.5085775872793332
[2019-03-23 16:11:57,573] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05359066], dtype=float32), 0.3641769]
[2019-03-23 16:11:57,574] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.731232305, 98.311046575, 1.0, 2.0, 0.6283074660831108, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 715527.5294092164, 715527.529409216, 158224.2606173969]
[2019-03-23 16:11:57,575] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:11:57,579] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.9449648e-06 9.9999702e-01 2.6763438e-16 1.6711629e-12 2.4812934e-15], sampled 0.5783734260916604
[2019-03-23 16:12:11,626] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05359066], dtype=float32), 0.3641769]
[2019-03-23 16:12:11,627] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.43010922333333, 72.59760563666667, 1.0, 2.0, 0.4261043773566036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 484998.7566854608, 484998.7566854604, 134888.9368534117]
[2019-03-23 16:12:11,629] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:12:11,634] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.8118525e-06 9.9999821e-01 7.0689803e-17 6.0971790e-13 7.0606829e-16], sampled 0.09346992693070155
[2019-03-23 16:12:27,859] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05359066], dtype=float32), 0.3641769]
[2019-03-23 16:12:27,860] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [28.03333333333333, 45.66666666666667, 1.0, 2.0, 0.4607045932231943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 523922.9347250991, 523922.9347250988, 137973.8748305649]
[2019-03-23 16:12:27,861] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:12:27,864] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.1733949e-06 9.9999785e-01 1.1732613e-16 8.9762204e-13 1.1409710e-15], sampled 0.5979782387613228
[2019-03-23 16:12:31,680] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05359066], dtype=float32), 0.3641769]
[2019-03-23 16:12:31,681] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.13333333333333, 85.0, 1.0, 2.0, 0.3404472930623831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 373321.5264514853, 373321.5264514849, 119562.6776015247]
[2019-03-23 16:12:31,683] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:12:31,685] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.9944754e-06 9.9999702e-01 2.8707392e-16 1.7681897e-12 2.6549708e-15], sampled 0.7069861189669128
[2019-03-23 16:12:43,904] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05359066], dtype=float32), 0.3641769]
[2019-03-23 16:12:43,906] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.03333333333333, 81.0, 1.0, 2.0, 0.2400555107629277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 260634.0633365636, 260634.0633365633, 87002.0720014973]
[2019-03-23 16:12:43,906] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:12:43,910] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.0071905e-06 9.9999797e-01 1.0809169e-16 8.5757470e-13 1.0598974e-15], sampled 0.7960496201998162
[2019-03-23 16:12:45,762] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 16:12:46,131] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 16:12:46,706] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 16:12:46,754] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5896 1663766061.8834 105.0000
[2019-03-23 16:12:46,781] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 16:12:47,798] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 2175000, evaluation results [2175000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.58956291602, 1663766061.8834455, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 16:12:49,268] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136000, global step 2175771: loss 0.0041
[2019-03-23 16:12:49,269] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136000, global step 2175771: learning rate 0.0000
[2019-03-23 16:12:49,611] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136000, global step 2175958: loss 0.0381
[2019-03-23 16:12:49,614] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136000, global step 2175958: learning rate 0.0000
[2019-03-23 16:12:49,753] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.6695276e-05 9.9991333e-01 2.0774085e-13 9.1050195e-10 1.7586505e-13], sum to 1.0000
[2019-03-23 16:12:49,759] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9475
[2019-03-23 16:12:49,764] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 77.0, 1.0, 2.0, 0.4872025684478129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 529140.6369261009, 529140.6369261009, 113794.8034126491], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2193000.0000, 
sim time next is 2193600.0000, 
raw observation next is [17.33333333333334, 77.0, 1.0, 2.0, 0.4927005387749405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 535115.1555315019, 535115.1555315019, 115842.6351740007], 
processed observation next is [1.0, 0.391304347826087, 0.42424242424242453, 0.77, 1.0, 1.0, 0.3658756734686756, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1981907983450007, 0.1981907983450007, 0.28254301261951387], 
reward next is 0.7175, 
noisyNet noise sample is [array([-1.2757434], dtype=float32), 0.37161285]. 
=============================================
[2019-03-23 16:12:49,937] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136000, global step 2176126: loss 0.2659
[2019-03-23 16:12:49,944] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136000, global step 2176127: learning rate 0.0000
[2019-03-23 16:12:49,957] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136000, global step 2176136: loss 0.2359
[2019-03-23 16:12:49,958] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136000, global step 2176136: learning rate 0.0000
[2019-03-23 16:12:50,188] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136000, global step 2176258: loss 0.4134
[2019-03-23 16:12:50,190] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136000, global step 2176258: learning rate 0.0000
[2019-03-23 16:12:50,295] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136000, global step 2176317: loss 0.3100
[2019-03-23 16:12:50,299] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136000, global step 2176318: learning rate 0.0000
[2019-03-23 16:12:50,413] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136000, global step 2176378: loss 0.3447
[2019-03-23 16:12:50,418] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136000, global step 2176379: learning rate 0.0000
[2019-03-23 16:12:50,474] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136000, global step 2176411: loss 0.1990
[2019-03-23 16:12:50,477] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136000, global step 2176413: learning rate 0.0000
[2019-03-23 16:12:50,535] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136000, global step 2176441: loss 0.2042
[2019-03-23 16:12:50,538] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136000, global step 2176441: learning rate 0.0000
[2019-03-23 16:12:50,578] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136000, global step 2176466: loss 0.0720
[2019-03-23 16:12:50,580] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136000, global step 2176466: learning rate 0.0000
[2019-03-23 16:12:50,853] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136000, global step 2176612: loss 0.0111
[2019-03-23 16:12:50,855] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136000, global step 2176613: learning rate 0.0000
[2019-03-23 16:12:50,908] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136000, global step 2176640: loss 0.0096
[2019-03-23 16:12:50,911] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136000, global step 2176640: learning rate 0.0000
[2019-03-23 16:12:51,029] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136000, global step 2176707: loss 0.0185
[2019-03-23 16:12:51,040] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136000, global step 2176708: learning rate 0.0000
[2019-03-23 16:12:51,844] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136000, global step 2177130: loss 0.0369
[2019-03-23 16:12:51,847] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136000, global step 2177131: learning rate 0.0000
[2019-03-23 16:12:53,537] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.4398807e-06 9.9999559e-01 7.7546273e-15 1.9011860e-12 1.7043024e-13], sum to 1.0000
[2019-03-23 16:12:53,547] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5383
[2019-03-23 16:12:53,551] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.6, 94.66666666666666, 1.0, 2.0, 0.2433297415176441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 264203.4415010862, 264203.4415010859, 83101.83278522779], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2176800.0000, 
sim time next is 2177400.0000, 
raw observation next is [14.5, 94.83333333333333, 1.0, 2.0, 0.2415439697970765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 262263.9570853817, 262263.9570853817, 82407.35539867132], 
processed observation next is [1.0, 0.17391304347826086, 0.29545454545454547, 0.9483333333333333, 1.0, 1.0, 0.05192996224634563, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09713479892051174, 0.09713479892051174, 0.20099354975285688], 
reward next is 0.7990, 
noisyNet noise sample is [array([0.31545892], dtype=float32), 0.301329]. 
=============================================
[2019-03-23 16:12:57,887] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.3356427e-05 9.9993658e-01 9.3958559e-14 5.3087551e-10 1.6296554e-11], sum to 1.0000
[2019-03-23 16:12:57,896] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9924
[2019-03-23 16:12:57,912] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 53.0, 1.0, 2.0, 0.2901942914904586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 315104.685516066, 315104.6855160663, 95456.89653693823], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2400000.0000, 
sim time next is 2400600.0000, 
raw observation next is [21.0, 53.0, 1.0, 2.0, 0.289121032336005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 313938.9212085549, 313938.9212085546, 95333.56538328086], 
processed observation next is [1.0, 0.782608695652174, 0.5909090909090909, 0.53, 1.0, 1.0, 0.11140129042000624, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11627367452168699, 0.11627367452168688, 0.2325208911787338], 
reward next is 0.7675, 
noisyNet noise sample is [array([1.1307774], dtype=float32), 0.9388307]. 
=============================================
[2019-03-23 16:12:57,971] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2087350e-04 9.9987912e-01 6.7662245e-14 3.7033873e-10 5.4395030e-13], sum to 1.0000
[2019-03-23 16:12:57,978] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9238
[2019-03-23 16:12:57,983] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.83333333333333, 88.00000000000001, 1.0, 2.0, 0.2687942848003443, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 291860.7210048871, 291860.7210048871, 89865.63892751886], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2247000.0000, 
sim time next is 2247600.0000, 
raw observation next is [15.66666666666667, 88.0, 1.0, 2.0, 0.2629898698525951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 285556.3530469997, 285556.3530469994, 87853.07801256808], 
processed observation next is [1.0, 0.0, 0.3484848484848486, 0.88, 1.0, 1.0, 0.07873733731574385, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10576161223962953, 0.10576161223962939, 0.21427580003065386], 
reward next is 0.7857, 
noisyNet noise sample is [array([-0.0722253], dtype=float32), 0.87842065]. 
=============================================
[2019-03-23 16:12:58,500] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136500, global step 2180626: loss 0.1431
[2019-03-23 16:12:58,501] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136500, global step 2180627: learning rate 0.0000
[2019-03-23 16:13:00,872] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136500, global step 2181884: loss 0.0713
[2019-03-23 16:13:00,873] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136500, global step 2181885: learning rate 0.0000
[2019-03-23 16:13:04,174] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.7628450e-07 9.9999952e-01 5.1790681e-17 1.7609269e-13 1.6349213e-17], sum to 1.0000
[2019-03-23 16:13:04,187] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0033
[2019-03-23 16:13:04,192] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 46.50000000000001, 1.0, 2.0, 0.7323050347392256, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 795559.2531173266, 795559.253117327, 150832.9839539258], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2387400.0000, 
sim time next is 2388000.0000, 
raw observation next is [23.0, 46.0, 1.0, 2.0, 0.5948730965652815, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 646157.102633578, 646157.102633578, 135253.3509785558], 
processed observation next is [1.0, 0.6521739130434783, 0.6818181818181818, 0.46, 1.0, 1.0, 0.49359137070660186, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2393174454198437, 0.2393174454198437, 0.3298862218989166], 
reward next is 0.6701, 
noisyNet noise sample is [array([-0.16642512], dtype=float32), -0.5095264]. 
=============================================
[2019-03-23 16:13:04,205] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[80.55553 ]
 [80.7001  ]
 [80.60992 ]
 [80.46948 ]
 [80.239136]], R is [[80.92625427]
 [80.74910736]
 [80.60655975]
 [80.47657013]
 [80.35361481]].
[2019-03-23 16:13:04,681] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136500, global step 2183888: loss 0.0167
[2019-03-23 16:13:04,684] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136500, global step 2183888: learning rate 0.0000
[2019-03-23 16:13:04,766] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136500, global step 2183931: loss 0.0033
[2019-03-23 16:13:04,770] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136500, global step 2183932: learning rate 0.0000
[2019-03-23 16:13:04,821] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136500, global step 2183963: loss 0.0043
[2019-03-23 16:13:04,822] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136500, global step 2183963: learning rate 0.0000
[2019-03-23 16:13:05,261] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136500, global step 2184187: loss 0.0478
[2019-03-23 16:13:05,263] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136500, global step 2184188: learning rate 0.0000
[2019-03-23 16:13:05,406] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136500, global step 2184263: loss 0.0290
[2019-03-23 16:13:05,407] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136500, global step 2184263: learning rate 0.0000
[2019-03-23 16:13:05,529] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136500, global step 2184326: loss 0.0108
[2019-03-23 16:13:05,530] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136500, global step 2184326: learning rate 0.0000
[2019-03-23 16:13:05,643] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136500, global step 2184388: loss 0.0894
[2019-03-23 16:13:05,645] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136500, global step 2184389: learning rate 0.0000
[2019-03-23 16:13:05,657] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136500, global step 2184393: loss 0.0893
[2019-03-23 16:13:05,658] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136500, global step 2184393: learning rate 0.0000
[2019-03-23 16:13:05,692] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136500, global step 2184409: loss 0.0159
[2019-03-23 16:13:05,693] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136500, global step 2184409: learning rate 0.0000
[2019-03-23 16:13:05,782] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136500, global step 2184462: loss 0.0059
[2019-03-23 16:13:05,787] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136500, global step 2184463: learning rate 0.0000
[2019-03-23 16:13:06,087] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136500, global step 2184621: loss 0.0292
[2019-03-23 16:13:06,093] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136500, global step 2184621: learning rate 0.0000
[2019-03-23 16:13:06,247] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136500, global step 2184702: loss 0.0293
[2019-03-23 16:13:06,249] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136500, global step 2184702: learning rate 0.0000
[2019-03-23 16:13:06,354] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136500, global step 2184759: loss 0.0218
[2019-03-23 16:13:06,356] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136500, global step 2184759: learning rate 0.0000
[2019-03-23 16:13:07,042] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136500, global step 2185113: loss 0.0828
[2019-03-23 16:13:07,046] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136500, global step 2185113: learning rate 0.0000
[2019-03-23 16:13:08,640] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.1329520e-06 9.9999785e-01 1.3148668e-14 3.6463801e-12 4.0992383e-14], sum to 1.0000
[2019-03-23 16:13:08,652] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4845
[2019-03-23 16:13:08,658] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.00000000000001, 1.0, 2.0, 0.243904154298764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 264827.2992764861, 264827.2992764864, 79874.12600361701], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2488200.0000, 
sim time next is 2488800.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2377534444961131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 258147.1828682377, 258147.1828682374, 79191.94463458599], 
processed observation next is [1.0, 0.8260869565217391, 0.2727272727272727, 0.94, 1.0, 1.0, 0.047191805620141365, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09561006772897693, 0.09561006772897682, 0.19315108447459997], 
reward next is 0.8068, 
noisyNet noise sample is [array([-0.4152607], dtype=float32), 0.26957348]. 
=============================================
[2019-03-23 16:13:10,663] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.6072907e-08 9.9999988e-01 4.7126653e-17 1.5681481e-12 5.3124560e-17], sum to 1.0000
[2019-03-23 16:13:10,669] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3918
[2019-03-23 16:13:10,674] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2125509770481433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 230776.4356565973, 230776.4356565976, 74946.08539382317], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2526000.0000, 
sim time next is 2526600.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2118442468809993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 230008.9245678558, 230008.9245678558, 74871.7051435874], 
processed observation next is [1.0, 0.21739130434782608, 0.22727272727272727, 1.0, 1.0, 1.0, 0.014805308601249095, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08518849058068734, 0.08518849058068734, 0.18261391498435953], 
reward next is 0.8174, 
noisyNet noise sample is [array([0.526349], dtype=float32), -0.6886629]. 
=============================================
[2019-03-23 16:13:13,816] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.8225445e-06 9.9999321e-01 4.1486687e-15 4.7433092e-11 2.4938122e-13], sum to 1.0000
[2019-03-23 16:13:13,822] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8895
[2019-03-23 16:13:13,830] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333333, 55.0, 1.0, 2.0, 0.661007482750744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 718046.0071900651, 718046.0071900651, 142584.8938322072], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2556600.0000, 
sim time next is 2557200.0000, 
raw observation next is [21.66666666666667, 54.0, 1.0, 2.0, 0.6213901713829673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 674980.21726875, 674980.2172687497, 138619.527769909], 
processed observation next is [1.0, 0.6086956521739131, 0.6212121212121214, 0.54, 1.0, 1.0, 0.5267377142287091, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24999267306249998, 0.2499926730624999, 0.3380964091949], 
reward next is 0.6619, 
noisyNet noise sample is [array([0.67334306], dtype=float32), -0.35701996]. 
=============================================
[2019-03-23 16:13:14,280] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137000, global step 2188577: loss 0.0324
[2019-03-23 16:13:14,285] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137000, global step 2188577: learning rate 0.0000
[2019-03-23 16:13:16,309] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.7191806e-07 9.9999940e-01 9.9677355e-16 1.5837197e-13 3.9440327e-14], sum to 1.0000
[2019-03-23 16:13:16,316] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5677
[2019-03-23 16:13:16,319] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.2, 94.0, 1.0, 2.0, 0.2892572694090944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 314086.9005202745, 314086.9005202745, 105900.0223412015], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2604600.0000, 
sim time next is 2605200.0000, 
raw observation next is [16.13333333333333, 96.0, 1.0, 2.0, 0.2927701363924898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 317902.5561637745, 317902.5561637745, 109571.290003023], 
processed observation next is [0.0, 0.13043478260869565, 0.3696969696969695, 0.96, 1.0, 1.0, 0.11596267049061221, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11774168746806464, 0.11774168746806464, 0.267247048787861], 
reward next is 0.7328, 
noisyNet noise sample is [array([-0.3267353], dtype=float32), 0.7213468]. 
=============================================
[2019-03-23 16:13:16,410] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.1098822e-06 9.9999785e-01 1.9281337e-16 2.1200686e-13 4.3727520e-16], sum to 1.0000
[2019-03-23 16:13:16,419] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9550
[2019-03-23 16:13:16,423] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 74.66666666666667, 1.0, 2.0, 0.378938691397443, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 427656.3918078528, 427656.3918078525, 123335.7375337644], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2623800.0000, 
sim time next is 2624400.0000, 
raw observation next is [22.0, 73.0, 1.0, 2.0, 0.3822483048432085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 431749.2831178434, 431749.2831178437, 123833.5876164804], 
processed observation next is [0.0, 0.391304347826087, 0.6363636363636364, 0.73, 1.0, 1.0, 0.22781038105401058, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15990714189549754, 0.15990714189549765, 0.302033140528001], 
reward next is 0.6980, 
noisyNet noise sample is [array([1.8327286], dtype=float32), 1.8253814]. 
=============================================
[2019-03-23 16:13:16,552] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.6813385e-08 9.9999988e-01 7.3073135e-16 7.8479633e-13 1.3996425e-13], sum to 1.0000
[2019-03-23 16:13:16,559] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7936
[2019-03-23 16:13:16,564] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 47.0, 1.0, 2.0, 0.3458119661882273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 384911.9768175173, 384911.9768175173, 117862.3346858058], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2631600.0000, 
sim time next is 2632200.0000, 
raw observation next is [25.16666666666667, 46.16666666666667, 1.0, 2.0, 0.340944529215303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 379064.6791579946, 379064.6791579946, 117298.880895074], 
processed observation next is [0.0, 0.4782608695652174, 0.7803030303030305, 0.4616666666666667, 1.0, 1.0, 0.17618066151912873, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14039432561407206, 0.14039432561407206, 0.2860948314514], 
reward next is 0.7139, 
noisyNet noise sample is [array([-0.71289665], dtype=float32), 0.22921795]. 
=============================================
[2019-03-23 16:13:16,730] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137000, global step 2189862: loss 0.0010
[2019-03-23 16:13:16,731] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137000, global step 2189862: learning rate 0.0000
[2019-03-23 16:13:16,842] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.0426873e-07 9.9999940e-01 7.3544183e-12 3.3213782e-11 1.7663257e-13], sum to 1.0000
[2019-03-23 16:13:16,849] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1037
[2019-03-23 16:13:16,852] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.58333333333333, 79.33333333333333, 1.0, 2.0, 0.4395464346875617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 500903.0985221535, 500903.0985221535, 132586.4893216541], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2713800.0000, 
sim time next is 2714400.0000, 
raw observation next is [22.8, 78.0, 1.0, 2.0, 0.4400209042870921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 501486.5278626967, 501486.5278626967, 132694.670666012], 
processed observation next is [0.0, 0.43478260869565216, 0.6727272727272727, 0.78, 1.0, 1.0, 0.3000261303588651, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18573575106025803, 0.18573575106025803, 0.32364553820978537], 
reward next is 0.6764, 
noisyNet noise sample is [array([-0.15589085], dtype=float32), -0.24632445]. 
=============================================
[2019-03-23 16:13:18,924] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.2967641e-08 1.0000000e+00 2.0315215e-17 6.4026714e-13 6.7659289e-15], sum to 1.0000
[2019-03-23 16:13:18,930] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0362
[2019-03-23 16:13:18,937] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 40.0, 1.0, 2.0, 0.3717038527936875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 418934.3603253736, 418934.3603253736, 122391.5708868516], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2649600.0000, 
sim time next is 2650200.0000, 
raw observation next is [27.83333333333334, 40.83333333333334, 1.0, 2.0, 0.374101334003171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 421847.0886423514, 421847.0886423514, 122714.8092147776], 
processed observation next is [0.0, 0.6956521739130435, 0.9015151515151518, 0.40833333333333344, 1.0, 1.0, 0.21762666750396376, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15623966246013013, 0.15623966246013013, 0.2993044127189698], 
reward next is 0.7007, 
noisyNet noise sample is [array([-0.5443252], dtype=float32), -1.5044467]. 
=============================================
[2019-03-23 16:13:20,537] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137000, global step 2191867: loss 0.0018
[2019-03-23 16:13:20,540] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137000, global step 2191870: learning rate 0.0000
[2019-03-23 16:13:20,628] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137000, global step 2191913: loss 0.0101
[2019-03-23 16:13:20,630] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137000, global step 2191913: learning rate 0.0000
[2019-03-23 16:13:20,869] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137000, global step 2192046: loss 0.0034
[2019-03-23 16:13:20,872] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137000, global step 2192046: learning rate 0.0000
[2019-03-23 16:13:21,204] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137000, global step 2192219: loss 0.0006
[2019-03-23 16:13:21,215] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137000, global step 2192222: learning rate 0.0000
[2019-03-23 16:13:21,261] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137000, global step 2192248: loss 0.0097
[2019-03-23 16:13:21,262] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137000, global step 2192248: learning rate 0.0000
[2019-03-23 16:13:21,453] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137000, global step 2192353: loss 0.0004
[2019-03-23 16:13:21,454] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137000, global step 2192353: learning rate 0.0000
[2019-03-23 16:13:21,482] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137000, global step 2192365: loss 0.0193
[2019-03-23 16:13:21,485] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137000, global step 2192366: learning rate 0.0000
[2019-03-23 16:13:21,501] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137000, global step 2192374: loss 0.0152
[2019-03-23 16:13:21,504] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137000, global step 2192376: learning rate 0.0000
[2019-03-23 16:13:21,734] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137000, global step 2192497: loss 0.0005
[2019-03-23 16:13:21,736] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137000, global step 2192497: learning rate 0.0000
[2019-03-23 16:13:21,783] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137000, global step 2192523: loss 0.0232
[2019-03-23 16:13:21,785] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137000, global step 2192523: learning rate 0.0000
[2019-03-23 16:13:21,968] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137000, global step 2192621: loss 0.0293
[2019-03-23 16:13:21,970] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137000, global step 2192621: learning rate 0.0000
[2019-03-23 16:13:22,070] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137000, global step 2192676: loss 0.0017
[2019-03-23 16:13:22,072] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137000, global step 2192676: learning rate 0.0000
[2019-03-23 16:13:22,101] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137000, global step 2192692: loss 0.0276
[2019-03-23 16:13:22,102] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137000, global step 2192692: learning rate 0.0000
[2019-03-23 16:13:22,579] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137000, global step 2192943: loss 0.0742
[2019-03-23 16:13:22,579] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137000, global step 2192943: learning rate 0.0000
[2019-03-23 16:13:29,907] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137500, global step 2196805: loss -4.7880
[2019-03-23 16:13:29,908] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137500, global step 2196805: learning rate 0.0000
[2019-03-23 16:13:30,259] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6002904e-03 9.9839622e-01 1.0535157e-07 3.1962143e-06 1.5069718e-07], sum to 1.0000
[2019-03-23 16:13:30,266] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2489
[2019-03-23 16:13:30,275] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.4249515589527532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.3284620447416, 483504.1479370301, 483504.1479370301, 130236.7547078712], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2872200.0000, 
sim time next is 2872800.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.4206015177851903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846343488235, 478502.7461359515, 478502.7461359518, 129758.3610612794], 
processed observation next is [1.0, 0.2608695652173913, 0.5909090909090909, 0.88, 1.0, 1.0, 0.2757518972314878, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288128637239, 0.17722323930961167, 0.17722323930961176, 0.31648380746653515], 
reward next is 0.6835, 
noisyNet noise sample is [array([-0.8417331], dtype=float32), 0.4240583]. 
=============================================
[2019-03-23 16:13:30,447] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.8813896e-06 9.9999607e-01 1.4175917e-10 6.3330767e-09 8.2532349e-11], sum to 1.0000
[2019-03-23 16:13:30,454] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7785
[2019-03-23 16:13:30,460] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1091463.546386717 W.
[2019-03-23 16:13:30,469] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.0, 77.0, 1.0, 2.0, 0.958956368153405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1091463.546386717, 1091463.546386717, 214255.7161322108], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2882400.0000, 
sim time next is 2883000.0000, 
raw observation next is [25.5, 75.5, 1.0, 2.0, 0.3436677330303975, 1.0, 1.0, 0.3436677330303975, 1.0, 1.0, 0.6949822098726175, 6.911199999999999, 6.9112, 77.3421103, 1162901.556840966, 1162901.556840966, 280344.8398562991], 
processed observation next is [1.0, 0.34782608695652173, 0.7954545454545454, 0.755, 1.0, 1.0, 0.17958466628799685, 1.0, 0.5, 0.17958466628799685, 1.0, 0.5, 0.5642602998180251, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4307042803114689, 0.4307042803114689, 0.6837679020885344], 
reward next is 0.3162, 
noisyNet noise sample is [array([0.40031108], dtype=float32), -0.652801]. 
=============================================
[2019-03-23 16:13:30,480] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[33.871456]
 [33.6058  ]
 [34.079163]
 [33.110607]
 [32.919273]], R is [[33.62932205]
 [33.77045441]
 [33.96111298]
 [34.20584106]
 [34.50827789]].
[2019-03-23 16:13:31,391] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.8392073e-06 9.9999309e-01 3.3692789e-09 1.1976049e-07 2.4740279e-09], sum to 1.0000
[2019-03-23 16:13:31,397] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6060
[2019-03-23 16:13:31,401] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1899853.102688811 W.
[2019-03-23 16:13:31,405] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 64.66666666666667, 1.0, 2.0, 0.6383349573464397, 1.0, 2.0, 0.5629559156148273, 1.0, 2.0, 0.9865530188920543, 6.9112, 6.9112, 80.35710561192163, 1899853.102688811, 1899853.102688811, 384340.5153516266], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2902800.0000, 
sim time next is 2903400.0000, 
raw observation next is [29.0, 64.0, 1.0, 2.0, 0.8293604463756171, 1.0, 2.0, 0.8293604463756171, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1866002.243328273, 1866002.243328273, 335340.2972117421], 
processed observation next is [1.0, 0.6086956521739131, 0.9545454545454546, 0.64, 1.0, 1.0, 0.7867005579695213, 1.0, 1.0, 0.7867005579695213, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.6911119419734345, 0.6911119419734345, 0.8179031639310783], 
reward next is 0.1821, 
noisyNet noise sample is [array([-0.7786976], dtype=float32), 0.1386076]. 
=============================================
[2019-03-23 16:13:31,749] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.5907780e-07 9.9999952e-01 7.8424024e-11 1.4509691e-08 6.2559083e-11], sum to 1.0000
[2019-03-23 16:13:31,757] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7787
[2019-03-23 16:13:31,763] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1763378.604310401 W.
[2019-03-23 16:13:31,771] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 62.0, 1.0, 2.0, 0.7838194664576204, 1.0, 2.0, 0.7838194664576204, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1763378.604310401, 1763378.604310401, 319363.6012593086], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2905200.0000, 
sim time next is 2905800.0000, 
raw observation next is [28.5, 64.83333333333334, 1.0, 2.0, 0.7662647050524731, 1.0, 2.0, 0.7662647050524731, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 78.50082802356592, 1723785.852203644, 1723785.852203644, 314272.2227869785], 
processed observation next is [1.0, 0.6521739130434783, 0.9318181818181818, 0.6483333333333334, 1.0, 1.0, 0.7078308813155915, 1.0, 1.0, 0.7078308813155915, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5161370215826233, 0.6384392045198682, 0.6384392045198682, 0.7665176165536062], 
reward next is 0.2335, 
noisyNet noise sample is [array([1.1075935], dtype=float32), -1.0836167]. 
=============================================
[2019-03-23 16:13:32,102] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137500, global step 2197952: loss 1.2045
[2019-03-23 16:13:32,102] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137500, global step 2197952: learning rate 0.0000
[2019-03-23 16:13:35,870] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137500, global step 2199924: loss 0.2233
[2019-03-23 16:13:35,873] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137500, global step 2199924: learning rate 0.0000
[2019-03-23 16:13:36,015] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137500, global step 2199998: loss 0.1874
[2019-03-23 16:13:36,019] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137500, global step 2199998: learning rate 0.0000
[2019-03-23 16:13:36,022] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 16:13:36,024] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:13:36,026] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:13:36,026] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:13:36,028] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:13:36,028] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:13:36,029] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:13:36,029] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:13:36,031] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:13:36,036] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:13:36,037] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:13:36,058] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run89
[2019-03-23 16:13:36,090] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run89
[2019-03-23 16:13:36,119] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run89
[2019-03-23 16:13:36,120] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run89
[2019-03-23 16:13:36,120] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run89
[2019-03-23 16:13:44,213] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.052698], dtype=float32), 0.36698654]
[2019-03-23 16:13:44,214] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.46065806, 94.13832663, 1.0, 2.0, 0.2709925977848795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 294231.4271683095, 294231.4271683091, 97351.07290684157]
[2019-03-23 16:13:44,216] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:13:44,218] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.1220634e-12 1.0000000e+00 2.0010919e-19 1.0457507e-15 9.7519108e-20], sampled 0.1801203757396581
[2019-03-23 16:13:54,782] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.052698], dtype=float32), 0.36698654]
[2019-03-23 16:13:54,783] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.0, 93.0, 1.0, 2.0, 0.3799755041830584, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 427601.9288969035, 427601.9288969035, 127088.178836355]
[2019-03-23 16:13:54,785] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:13:54,788] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.8308246e-12 1.0000000e+00 7.6572833e-20 4.6912703e-16 3.3603880e-20], sampled 0.4974587811950626
[2019-03-23 16:14:06,730] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.052698], dtype=float32), 0.36698654]
[2019-03-23 16:14:06,733] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.33333333333334, 58.0, 1.0, 2.0, 0.3521479933679653, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 382402.9687910064, 382402.9687910064, 87790.83471499769]
[2019-03-23 16:14:06,733] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:14:06,736] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.8880218e-12 1.0000000e+00 8.0371448e-19 3.1236906e-15 3.6541588e-19], sampled 0.1713959404994615
[2019-03-23 16:14:10,014] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.052698], dtype=float32), 0.36698654]
[2019-03-23 16:14:10,016] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [28.7, 47.33333333333334, 1.0, 2.0, 0.6230520223903692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 710790.4410573079, 710790.4410573079, 159469.6775314159]
[2019-03-23 16:14:10,017] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:14:10,021] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.6578691e-12 1.0000000e+00 8.2965740e-19 3.4875480e-15 3.6693704e-19], sampled 0.007230169412731802
[2019-03-23 16:14:10,801] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.052698], dtype=float32), 0.36698654]
[2019-03-23 16:14:10,803] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.66666666666667, 64.0, 1.0, 2.0, 0.2588082139227862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 281014.5682281378, 281014.5682281381, 87291.93888083227]
[2019-03-23 16:14:10,803] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:14:10,807] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.2559181e-12 1.0000000e+00 3.0927027e-19 1.4316199e-15 1.4596248e-19], sampled 0.30792036406548295
[2019-03-23 16:14:11,158] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.052698], dtype=float32), 0.36698654]
[2019-03-23 16:14:11,160] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.5, 100.0, 1.0, 2.0, 0.284057640972706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 308439.1493688286, 308439.1493688286, 103729.7852761727]
[2019-03-23 16:14:11,161] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:14:11,164] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.7462155e-12 1.0000000e+00 7.0093165e-20 4.2104764e-16 3.1492630e-20], sampled 0.9775080942695731
[2019-03-23 16:14:30,374] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.052698], dtype=float32), 0.36698654]
[2019-03-23 16:14:30,376] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.2, 77.5, 1.0, 2.0, 0.3666667990304046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 409101.5013485519, 409101.5013485515, 124267.2609345665]
[2019-03-23 16:14:30,377] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:14:30,380] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.93230563e-13 1.00000000e+00 2.77512569e-20 1.96627184e-16
 1.22003615e-20], sampled 0.27700086683405534
[2019-03-23 16:14:40,043] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.052698], dtype=float32), 0.36698654]
[2019-03-23 16:14:40,045] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.10281362666667, 77.35314128, 1.0, 2.0, 0.3143740814731485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 341346.4435011492, 341346.4435011492, 113563.4789859168]
[2019-03-23 16:14:40,045] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:14:40,048] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.1753445e-12 1.0000000e+00 2.0446898e-19 1.0615869e-15 9.9049521e-20], sampled 0.10534054968709117
[2019-03-23 16:15:00,162] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.052698], dtype=float32), 0.36698654]
[2019-03-23 16:15:00,165] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.382912825, 68.519056495, 1.0, 2.0, 0.2875383148727588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 312200.6795453868, 312200.6795453868, 111115.4729540247]
[2019-03-23 16:15:00,166] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:15:00,171] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.9812895e-12 1.0000000e+00 9.0150189e-20 5.3290215e-16 4.1214135e-20], sampled 0.47372933836151687
[2019-03-23 16:15:06,243] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.052698], dtype=float32), 0.36698654]
[2019-03-23 16:15:06,244] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.63333333333333, 88.0, 1.0, 2.0, 0.34489874767107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 383503.622525898, 383503.622525898, 117624.9359307828]
[2019-03-23 16:15:06,247] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:15:06,250] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.3905452e-12 1.0000000e+00 2.0607028e-19 1.0367421e-15 9.2383492e-20], sampled 0.5231554080434472
[2019-03-23 16:15:17,863] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.052698], dtype=float32), 0.36698654]
[2019-03-23 16:15:17,864] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [31.33530023, 66.12446292, 1.0, 2.0, 0.7026324559730421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 789539.5792746848, 789539.5792746844, 178359.3442669215]
[2019-03-23 16:15:17,865] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:15:17,867] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.1182088e-12 1.0000000e+00 5.5768600e-19 2.4398797e-15 2.4750849e-19], sampled 0.6146147929021053
[2019-03-23 16:15:21,208] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.052698], dtype=float32), 0.36698654]
[2019-03-23 16:15:21,210] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.1, 70.5, 1.0, 2.0, 0.2257492172136047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 245109.9867078672, 245109.9867078669, 76062.45586000226]
[2019-03-23 16:15:21,212] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:15:21,215] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.7070993e-12 1.0000000e+00 3.7913405e-19 1.6982888e-15 1.8861371e-19], sampled 0.251501519780722
[2019-03-23 16:15:23,503] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 16:15:23,659] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 16:15:23,688] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 16:15:23,818] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 16:15:24,044] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 16:15:25,062] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 2200000, evaluation results [2200000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 16:15:25,290] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137500, global step 2200129: loss 1.0942
[2019-03-23 16:15:25,292] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137500, global step 2200130: learning rate 0.0000
[2019-03-23 16:15:25,332] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137500, global step 2200145: loss 0.0845
[2019-03-23 16:15:25,334] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137500, global step 2200146: learning rate 0.0000
[2019-03-23 16:15:25,477] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137500, global step 2200222: loss 0.0600
[2019-03-23 16:15:25,479] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137500, global step 2200222: learning rate 0.0000
[2019-03-23 16:15:25,635] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137500, global step 2200308: loss 0.0757
[2019-03-23 16:15:25,645] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137500, global step 2200308: learning rate 0.0000
[2019-03-23 16:15:25,685] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137500, global step 2200327: loss 0.0349
[2019-03-23 16:15:25,688] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137500, global step 2200327: learning rate 0.0000
[2019-03-23 16:15:25,699] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137500, global step 2200331: loss 0.1238
[2019-03-23 16:15:25,701] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137500, global step 2200331: learning rate 0.0000
[2019-03-23 16:15:26,046] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137500, global step 2200523: loss 0.0631
[2019-03-23 16:15:26,051] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137500, global step 2200523: learning rate 0.0000
[2019-03-23 16:15:26,071] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137500, global step 2200536: loss 0.1264
[2019-03-23 16:15:26,073] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137500, global step 2200539: learning rate 0.0000
[2019-03-23 16:15:26,110] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137500, global step 2200554: loss 0.0973
[2019-03-23 16:15:26,111] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137500, global step 2200554: learning rate 0.0000
[2019-03-23 16:15:26,239] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137500, global step 2200625: loss 0.0768
[2019-03-23 16:15:26,241] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137500, global step 2200625: learning rate 0.0000
[2019-03-23 16:15:26,600] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137500, global step 2200809: loss 0.0969
[2019-03-23 16:15:26,603] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137500, global step 2200810: learning rate 0.0000
[2019-03-23 16:15:26,671] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137500, global step 2200847: loss 0.2181
[2019-03-23 16:15:26,674] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137500, global step 2200849: learning rate 0.0000
[2019-03-23 16:15:29,437] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.0404537e-12 1.0000000e+00 3.5711154e-20 7.5167880e-16 1.2152618e-19], sum to 1.0000
[2019-03-23 16:15:29,439] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2491
[2019-03-23 16:15:29,446] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 86.0, 1.0, 2.0, 0.5477144383820408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 622356.1242882697, 622356.1242882697, 149718.7760765119], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3097800.0000, 
sim time next is 3098400.0000, 
raw observation next is [24.0, 87.0, 1.0, 2.0, 0.5514945123483702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 626132.3087438502, 626132.3087438504, 150452.4978109767], 
processed observation next is [1.0, 0.8695652173913043, 0.7272727272727273, 0.87, 1.0, 1.0, 0.43936814043546274, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23190085509031488, 0.23190085509031497, 0.3669573117340895], 
reward next is 0.6330, 
noisyNet noise sample is [array([-0.34204152], dtype=float32), 1.0937172]. 
=============================================
[2019-03-23 16:15:31,637] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.7301354e-13 1.0000000e+00 1.6535292e-20 2.7218173e-17 6.0480351e-20], sum to 1.0000
[2019-03-23 16:15:31,650] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5481
[2019-03-23 16:15:31,656] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.4899803472467422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 556593.6702485511, 556593.6702485511, 136194.3552544649], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3133800.0000, 
sim time next is 3134400.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.4635888842758006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 526575.5778957175, 526575.5778957175, 133400.264324098], 
processed observation next is [1.0, 0.2608695652173913, 0.6363636363636364, 0.78, 1.0, 1.0, 0.3294861053447507, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1950279918132287, 0.1950279918132287, 0.3253664983514586], 
reward next is 0.6746, 
noisyNet noise sample is [array([-0.7113122], dtype=float32), -1.4270356]. 
=============================================
[2019-03-23 16:15:34,137] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138000, global step 2204765: loss 0.0478
[2019-03-23 16:15:34,141] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138000, global step 2204765: learning rate 0.0000
[2019-03-23 16:15:35,832] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3666047e-13 1.0000000e+00 7.9646759e-22 1.0240023e-17 1.2428416e-21], sum to 1.0000
[2019-03-23 16:15:35,840] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1175
[2019-03-23 16:15:35,847] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.83333333333334, 51.16666666666667, 1.0, 2.0, 0.3623054975770358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 405847.7160408788, 405847.7160408791, 120320.6525217437], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3345000.0000, 
sim time next is 3345600.0000, 
raw observation next is [24.66666666666667, 52.33333333333334, 1.0, 2.0, 0.3641348376935905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 408162.8163545699, 408162.8163545696, 120598.2115141604], 
processed observation next is [0.0, 0.7391304347826086, 0.7575757575757578, 0.5233333333333334, 1.0, 1.0, 0.20516854711698812, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1511714134646555, 0.1511714134646554, 0.29414197930283026], 
reward next is 0.7059, 
noisyNet noise sample is [array([1.5003345], dtype=float32), -1.3188542]. 
=============================================
[2019-03-23 16:15:36,211] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138000, global step 2205865: loss 0.0317
[2019-03-23 16:15:36,212] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138000, global step 2205865: learning rate 0.0000
[2019-03-23 16:15:37,896] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4808452e-14 1.0000000e+00 2.0839398e-23 4.4454994e-18 1.1841015e-21], sum to 1.0000
[2019-03-23 16:15:37,902] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9859
[2019-03-23 16:15:37,907] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 50.0, 1.0, 2.0, 0.33871403506857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 374560.7746593205, 374560.7746593202, 116300.577616051], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3252600.0000, 
sim time next is 3253200.0000, 
raw observation next is [24.0, 50.0, 1.0, 2.0, 0.3394591249521024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 375388.7571360982, 375388.7571360982, 116358.7081522852], 
processed observation next is [0.0, 0.6521739130434783, 0.7272727272727273, 0.5, 1.0, 1.0, 0.17432390619012797, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13903287301336972, 0.13903287301336972, 0.2838017272006956], 
reward next is 0.7162, 
noisyNet noise sample is [array([0.5612533], dtype=float32), -0.13322979]. 
=============================================
[2019-03-23 16:15:40,279] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138000, global step 2207949: loss 0.2322
[2019-03-23 16:15:40,280] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138000, global step 2207949: learning rate 0.0000
[2019-03-23 16:15:40,591] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138000, global step 2208119: loss 0.0404
[2019-03-23 16:15:40,595] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138000, global step 2208119: learning rate 0.0000
[2019-03-23 16:15:40,598] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138000, global step 2208119: loss 0.0523
[2019-03-23 16:15:40,600] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138000, global step 2208119: learning rate 0.0000
[2019-03-23 16:15:40,623] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138000, global step 2208127: loss 0.0050
[2019-03-23 16:15:40,625] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138000, global step 2208127: learning rate 0.0000
[2019-03-23 16:15:40,777] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138000, global step 2208207: loss 0.0312
[2019-03-23 16:15:40,779] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138000, global step 2208207: learning rate 0.0000
[2019-03-23 16:15:40,828] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138000, global step 2208235: loss 0.0407
[2019-03-23 16:15:40,829] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138000, global step 2208235: learning rate 0.0000
[2019-03-23 16:15:40,935] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138000, global step 2208288: loss 0.0231
[2019-03-23 16:15:40,937] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138000, global step 2208288: learning rate 0.0000
[2019-03-23 16:15:41,071] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138000, global step 2208366: loss 0.0719
[2019-03-23 16:15:41,074] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138000, global step 2208366: learning rate 0.0000
[2019-03-23 16:15:41,085] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138000, global step 2208369: loss 0.0436
[2019-03-23 16:15:41,087] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138000, global step 2208369: learning rate 0.0000
[2019-03-23 16:15:41,208] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138000, global step 2208433: loss 0.0016
[2019-03-23 16:15:41,210] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138000, global step 2208434: learning rate 0.0000
[2019-03-23 16:15:41,443] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138000, global step 2208557: loss 0.0584
[2019-03-23 16:15:41,446] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138000, global step 2208558: learning rate 0.0000
[2019-03-23 16:15:41,497] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138000, global step 2208585: loss 0.0086
[2019-03-23 16:15:41,500] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138000, global step 2208585: learning rate 0.0000
[2019-03-23 16:15:41,934] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138000, global step 2208811: loss 0.0853
[2019-03-23 16:15:41,938] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138000, global step 2208811: learning rate 0.0000
[2019-03-23 16:15:42,084] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138000, global step 2208888: loss 0.0435
[2019-03-23 16:15:42,088] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138000, global step 2208889: learning rate 0.0000
[2019-03-23 16:15:49,795] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138500, global step 2212949: loss 0.1047
[2019-03-23 16:15:49,797] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138500, global step 2212950: learning rate 0.0000
[2019-03-23 16:15:51,443] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138500, global step 2213819: loss 0.2557
[2019-03-23 16:15:51,445] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138500, global step 2213821: learning rate 0.0000
[2019-03-23 16:15:52,658] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.3701766e-09 1.0000000e+00 9.6497170e-17 8.8525342e-12 2.2818650e-15], sum to 1.0000
[2019-03-23 16:15:52,670] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3886
[2019-03-23 16:15:52,674] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 98.0, 1.0, 2.0, 0.5157136097041771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588328.9887996375, 588328.9887996375, 143595.6812816309], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3559200.0000, 
sim time next is 3559800.0000, 
raw observation next is [21.16666666666666, 99.0, 1.0, 2.0, 0.5096937065575272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 581500.0774462606, 581500.0774462604, 142773.5865259874], 
processed observation next is [1.0, 0.17391304347826086, 0.5984848484848482, 0.99, 1.0, 1.0, 0.387117133196909, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2153703990541706, 0.21537039905417052, 0.34822825981948147], 
reward next is 0.6518, 
noisyNet noise sample is [array([0.6511773], dtype=float32), 1.6382482]. 
=============================================
[2019-03-23 16:15:53,273] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.7592256e-10 1.0000000e+00 1.4806219e-18 1.2075396e-12 1.7361890e-16], sum to 1.0000
[2019-03-23 16:15:53,279] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0125
[2019-03-23 16:15:53,283] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5888373240380265, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 671588.8333488803, 671588.8333488803, 153090.4632288702], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3571200.0000, 
sim time next is 3571800.0000, 
raw observation next is [22.0, 94.00000000000001, 1.0, 2.0, 0.6337993601147939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 722861.9095967278, 722861.909596728, 159170.2720467303], 
processed observation next is [1.0, 0.34782608695652173, 0.6363636363636364, 0.9400000000000002, 1.0, 1.0, 0.5422492001434923, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2677266331839733, 0.26772663318397333, 0.38822017572373246], 
reward next is 0.6118, 
noisyNet noise sample is [array([0.57487184], dtype=float32), 1.5664779]. 
=============================================
[2019-03-23 16:15:55,394] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138500, global step 2215899: loss 0.3022
[2019-03-23 16:15:55,396] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138500, global step 2215900: learning rate 0.0000
[2019-03-23 16:15:55,695] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138500, global step 2216062: loss 0.2206
[2019-03-23 16:15:55,698] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138500, global step 2216062: learning rate 0.0000
[2019-03-23 16:15:55,756] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138500, global step 2216097: loss 0.5122
[2019-03-23 16:15:55,760] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138500, global step 2216097: learning rate 0.0000
[2019-03-23 16:15:55,859] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138500, global step 2216148: loss 0.0420
[2019-03-23 16:15:55,862] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138500, global step 2216149: learning rate 0.0000
[2019-03-23 16:15:55,935] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138500, global step 2216189: loss 0.0719
[2019-03-23 16:15:55,937] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138500, global step 2216189: learning rate 0.0000
[2019-03-23 16:15:56,013] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138500, global step 2216231: loss 0.1320
[2019-03-23 16:15:56,017] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138500, global step 2216231: learning rate 0.0000
[2019-03-23 16:15:56,090] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138500, global step 2216270: loss 0.1500
[2019-03-23 16:15:56,093] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138500, global step 2216270: learning rate 0.0000
[2019-03-23 16:15:56,329] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138500, global step 2216396: loss 0.1352
[2019-03-23 16:15:56,331] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138500, global step 2216397: learning rate 0.0000
[2019-03-23 16:15:56,372] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138500, global step 2216417: loss 0.1254
[2019-03-23 16:15:56,373] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138500, global step 2216417: learning rate 0.0000
[2019-03-23 16:15:56,444] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138500, global step 2216457: loss 0.0351
[2019-03-23 16:15:56,446] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138500, global step 2216459: learning rate 0.0000
[2019-03-23 16:15:56,840] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138500, global step 2216668: loss 1.8782
[2019-03-23 16:15:56,841] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138500, global step 2216668: learning rate 0.0000
[2019-03-23 16:15:56,903] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138500, global step 2216700: loss 1.6781
[2019-03-23 16:15:56,905] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138500, global step 2216700: learning rate 0.0000
[2019-03-23 16:15:56,911] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138500, global step 2216703: loss 0.8134
[2019-03-23 16:15:56,914] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138500, global step 2216703: learning rate 0.0000
[2019-03-23 16:15:57,290] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138500, global step 2216906: loss 1.1289
[2019-03-23 16:15:57,292] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138500, global step 2216906: learning rate 0.0000
[2019-03-23 16:15:57,501] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0317938e-09 1.0000000e+00 2.0652142e-17 1.2347616e-12 3.3917801e-16], sum to 1.0000
[2019-03-23 16:15:57,502] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3235
[2019-03-23 16:15:57,517] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.491369333766301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560629.6346433408, 560629.6346433408, 140492.7289641036], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3633000.0000, 
sim time next is 3633600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4910758108554579, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 560294.6409624402, 560294.6409624405, 140458.7367836387], 
processed observation next is [1.0, 0.043478260869565216, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3638447635693223, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20751653368979264, 0.20751653368979278, 0.3425822848381432], 
reward next is 0.6574, 
noisyNet noise sample is [array([1.0718652], dtype=float32), 0.6678342]. 
=============================================
[2019-03-23 16:16:05,076] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139000, global step 2220987: loss 0.0050
[2019-03-23 16:16:05,077] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139000, global step 2220988: learning rate 0.0000
[2019-03-23 16:16:06,662] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139000, global step 2221829: loss 0.0565
[2019-03-23 16:16:06,663] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139000, global step 2221830: learning rate 0.0000
[2019-03-23 16:16:10,074] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0242755e-10 1.0000000e+00 2.9128004e-22 1.0306892e-15 2.2185005e-18], sum to 1.0000
[2019-03-23 16:16:10,083] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3349
[2019-03-23 16:16:10,085] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 77.0, 1.0, 2.0, 0.2812653472231958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 305406.2327507673, 305406.2327507673, 101637.6843283391], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3894000.0000, 
sim time next is 3894600.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.281362457399602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 305511.7109732488, 305511.710973249, 101643.3464513569], 
processed observation next is [0.0, 0.043478260869565216, 0.45454545454545453, 0.77, 1.0, 1.0, 0.10170307174950245, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1131524855456477, 0.11315248554564777, 0.2479106011008705], 
reward next is 0.7521, 
noisyNet noise sample is [array([1.2787172], dtype=float32), -0.56804854]. 
=============================================
[2019-03-23 16:16:10,414] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139000, global step 2223812: loss 0.1371
[2019-03-23 16:16:10,418] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139000, global step 2223813: learning rate 0.0000
[2019-03-23 16:16:10,814] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139000, global step 2224024: loss 0.0178
[2019-03-23 16:16:10,817] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139000, global step 2224025: learning rate 0.0000
[2019-03-23 16:16:10,841] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139000, global step 2224037: loss 0.0006
[2019-03-23 16:16:10,843] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139000, global step 2224037: learning rate 0.0000
[2019-03-23 16:16:10,917] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139000, global step 2224078: loss 0.0012
[2019-03-23 16:16:10,919] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139000, global step 2224078: learning rate 0.0000
[2019-03-23 16:16:10,937] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139000, global step 2224088: loss 0.0041
[2019-03-23 16:16:10,940] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139000, global step 2224089: learning rate 0.0000
[2019-03-23 16:16:11,301] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139000, global step 2224276: loss 0.0248
[2019-03-23 16:16:11,303] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139000, global step 2224277: learning rate 0.0000
[2019-03-23 16:16:11,351] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139000, global step 2224302: loss 0.0287
[2019-03-23 16:16:11,354] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139000, global step 2224303: learning rate 0.0000
[2019-03-23 16:16:11,631] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139000, global step 2224450: loss 0.0910
[2019-03-23 16:16:11,632] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139000, global step 2224450: learning rate 0.0000
[2019-03-23 16:16:11,696] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139000, global step 2224479: loss 0.0350
[2019-03-23 16:16:11,698] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139000, global step 2224481: learning rate 0.0000
[2019-03-23 16:16:11,859] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139000, global step 2224570: loss 0.0479
[2019-03-23 16:16:11,860] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139000, global step 2224571: learning rate 0.0000
[2019-03-23 16:16:11,867] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139000, global step 2224573: loss 0.0530
[2019-03-23 16:16:11,869] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139000, global step 2224573: learning rate 0.0000
[2019-03-23 16:16:12,009] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139000, global step 2224649: loss 0.0616
[2019-03-23 16:16:12,012] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139000, global step 2224651: learning rate 0.0000
[2019-03-23 16:16:12,111] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139000, global step 2224707: loss 0.0040
[2019-03-23 16:16:12,113] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139000, global step 2224708: learning rate 0.0000
[2019-03-23 16:16:12,612] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 16:16:12,615] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:16:12,615] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:16:12,616] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:16:12,616] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:16:12,617] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:16:12,618] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:16:12,617] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:16:12,618] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:16:12,619] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:16:12,620] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:16:12,634] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run90
[2019-03-23 16:16:12,656] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run90
[2019-03-23 16:16:12,657] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run90
[2019-03-23 16:16:12,714] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run90
[2019-03-23 16:16:12,751] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run90
[2019-03-23 16:16:31,966] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.052698], dtype=float32), 0.37309483]
[2019-03-23 16:16:31,968] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [29.13285540166667, 81.194261775, 1.0, 2.0, 0.9480205043381007, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9865530188920543, 6.911200000000001, 6.9112, 95.55338702151406, 1614199.113387125, 1614199.113387125, 347381.2584879888]
[2019-03-23 16:16:31,969] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:16:31,972] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.9089251e-10 1.0000000e+00 5.6742985e-22 3.9640962e-14 8.5382813e-19], sampled 0.19783199279361552
[2019-03-23 16:16:31,975] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1614199.113387125 W.
[2019-03-23 16:16:55,645] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.052698], dtype=float32), 0.37309483]
[2019-03-23 16:16:55,646] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.37604813, 64.38583902666667, 1.0, 2.0, 0.6950664026804041, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 785941.7159834026, 785941.7159834022, 162937.8927111446]
[2019-03-23 16:16:55,648] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:16:55,652] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.1577869e-11 1.0000000e+00 6.6144662e-23 9.1847154e-15 1.3008992e-19], sampled 0.8265944078511658
[2019-03-23 16:17:23,665] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.052698], dtype=float32), 0.37309483]
[2019-03-23 16:17:23,665] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.01666666666667, 61.0, 1.0, 2.0, 0.3278744652999211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 362468.0236394685, 362468.0236394685, 119760.1463422435]
[2019-03-23 16:17:23,667] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:17:23,670] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.1570386e-11 1.0000000e+00 2.0166210e-23 4.2316690e-15 4.6742548e-20], sampled 0.13714923048387107
[2019-03-23 16:17:28,645] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.052698], dtype=float32), 0.37309483]
[2019-03-23 16:17:28,649] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.8, 62.5, 1.0, 2.0, 0.4442048419038973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 505421.9475876069, 505421.9475876069, 136530.8044127746]
[2019-03-23 16:17:28,651] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:17:28,654] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.3204081e-11 1.0000000e+00 1.7464513e-24 9.2098665e-16 5.7763367e-21], sampled 0.4022110531132359
[2019-03-23 16:17:45,778] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.052698], dtype=float32), 0.37309483]
[2019-03-23 16:17:45,779] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.6, 67.5, 1.0, 2.0, 0.4192918578129749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 476210.1208011585, 476210.1208011585, 133279.283393573]
[2019-03-23 16:17:45,780] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:17:45,782] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.1658489e-11 1.0000000e+00 2.0254564e-23 4.2438091e-15 4.6954323e-20], sampled 0.961637989173578
[2019-03-23 16:17:50,548] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.052698], dtype=float32), 0.37309483]
[2019-03-23 16:17:50,549] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [12.38333333333333, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 198747.9993375249, 198747.9993375252, 66794.83978422373]
[2019-03-23 16:17:50,550] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:17:50,553] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.9327614e-11 1.0000000e+00 8.1408994e-23 1.0241289e-14 1.5419710e-19], sampled 0.5447793556276472
[2019-03-23 16:18:00,377] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 16:18:00,600] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 16:18:00,637] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 16:18:00,830] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 16:18:00,910] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 16:18:01,926] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 2225000, evaluation results [2225000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 16:18:02,011] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139000, global step 2225045: loss 0.0325
[2019-03-23 16:18:02,012] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139000, global step 2225045: learning rate 0.0000
[2019-03-23 16:18:06,266] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.5219669e-12 1.0000000e+00 8.0848016e-28 3.8888116e-17 1.8632837e-24], sum to 1.0000
[2019-03-23 16:18:06,272] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.8761685e-12 1.0000000e+00 1.7678644e-27 1.7250058e-16 4.4988854e-23], sum to 1.0000
[2019-03-23 16:18:06,278] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8278
[2019-03-23 16:18:06,281] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 96.0, 1.0, 2.0, 0.5108839362330245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 562216.6156760076, 562216.6156760076, 130203.6899639429], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4011600.0000, 
sim time next is 4012200.0000, 
raw observation next is [17.0, 97.0, 1.0, 2.0, 0.5091410610646961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 561298.4172938638, 561298.4172938638, 130380.9520428471], 
processed observation next is [1.0, 0.43478260869565216, 0.4090909090909091, 0.97, 1.0, 1.0, 0.38642632633087015, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20788830270143105, 0.20788830270143105, 0.31800232205572465], 
reward next is 0.6820, 
noisyNet noise sample is [array([-0.6631437], dtype=float32), -0.81174904]. 
=============================================
[2019-03-23 16:18:06,282] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0056
[2019-03-23 16:18:06,286] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 95.0, 1.0, 2.0, 0.5553195161069149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 620338.562764078, 620338.562764078, 137956.9396493528], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4031400.0000, 
sim time next is 4032000.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.5530507929478597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 616866.6354456866, 616866.6354456866, 137335.2318505767], 
processed observation next is [1.0, 0.6956521739130435, 0.45454545454545453, 0.94, 1.0, 1.0, 0.44131349118482466, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2284691242391432, 0.2284691242391432, 0.3349639801233578], 
reward next is 0.6650, 
noisyNet noise sample is [array([-1.0184836], dtype=float32), 0.065095216]. 
=============================================
[2019-03-23 16:18:06,298] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[95.25628 ]
 [95.179665]
 [95.0286  ]
 [95.12126 ]
 [95.247025]], R is [[95.15171814]
 [94.86372375]
 [94.5759964 ]
 [94.28799438]
 [94.01095581]].
[2019-03-23 16:18:08,358] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.8206547e-09 1.0000000e+00 8.6604986e-21 1.3853755e-12 1.5881065e-17], sum to 1.0000
[2019-03-23 16:18:08,367] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0182
[2019-03-23 16:18:08,371] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 100.0, 1.0, 2.0, 0.304583825721208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 330734.7363008813, 330734.7363008813, 111501.1913396614], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4065000.0000, 
sim time next is 4065600.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.3042525488142872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 330374.8944817313, 330374.8944817311, 111478.8519045375], 
processed observation next is [1.0, 0.043478260869565216, 0.36363636363636365, 1.0, 1.0, 1.0, 0.13031568601785898, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12236107203027084, 0.12236107203027079, 0.2718996387915549], 
reward next is 0.7281, 
noisyNet noise sample is [array([0.40499806], dtype=float32), 0.3043818]. 
=============================================
[2019-03-23 16:18:09,611] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139500, global step 2229040: loss 4.4795
[2019-03-23 16:18:09,612] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139500, global step 2229041: learning rate 0.0000
[2019-03-23 16:18:10,228] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.8026338e-07 9.9999976e-01 1.2878114e-16 3.0130254e-12 5.5857910e-15], sum to 1.0000
[2019-03-23 16:18:10,237] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0923
[2019-03-23 16:18:10,243] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.7209779027254604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 818119.9863140483, 818119.9863140483, 163805.3428323831], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4111200.0000, 
sim time next is 4111800.0000, 
raw observation next is [21.33333333333333, 81.33333333333334, 1.0, 2.0, 0.7072368183230859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 802957.6626443306, 802957.6626443306, 162239.8345725749], 
processed observation next is [1.0, 0.6086956521739131, 0.6060606060606059, 0.8133333333333335, 1.0, 1.0, 0.6340460229038575, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.29739172690530763, 0.29739172690530763, 0.3957069135916461], 
reward next is 0.6043, 
noisyNet noise sample is [array([-1.1184132], dtype=float32), 0.91101885]. 
=============================================
[2019-03-23 16:18:11,014] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139500, global step 2229727: loss 0.0228
[2019-03-23 16:18:11,015] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139500, global step 2229727: learning rate 0.0000
[2019-03-23 16:18:15,148] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139500, global step 2231908: loss 0.0471
[2019-03-23 16:18:15,151] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139500, global step 2231908: learning rate 0.0000
[2019-03-23 16:18:15,190] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139500, global step 2231925: loss 0.0335
[2019-03-23 16:18:15,192] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139500, global step 2231925: learning rate 0.0000
[2019-03-23 16:18:15,292] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139500, global step 2231982: loss 0.0205
[2019-03-23 16:18:15,295] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139500, global step 2231982: learning rate 0.0000
[2019-03-23 16:18:15,390] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139500, global step 2232031: loss 0.1033
[2019-03-23 16:18:15,392] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139500, global step 2232031: learning rate 0.0000
[2019-03-23 16:18:15,426] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139500, global step 2232053: loss 0.0099
[2019-03-23 16:18:15,428] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139500, global step 2232053: learning rate 0.0000
[2019-03-23 16:18:15,846] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139500, global step 2232276: loss 0.0097
[2019-03-23 16:18:15,849] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139500, global step 2232276: learning rate 0.0000
[2019-03-23 16:18:15,862] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139500, global step 2232283: loss 0.0180
[2019-03-23 16:18:15,864] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139500, global step 2232283: learning rate 0.0000
[2019-03-23 16:18:15,992] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139500, global step 2232352: loss 0.0414
[2019-03-23 16:18:15,998] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139500, global step 2232353: learning rate 0.0000
[2019-03-23 16:18:16,216] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139500, global step 2232466: loss 0.0755
[2019-03-23 16:18:16,217] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139500, global step 2232466: learning rate 0.0000
[2019-03-23 16:18:16,252] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.9460987e-11 1.0000000e+00 1.8842860e-22 1.4675539e-14 4.8381652e-20], sum to 1.0000
[2019-03-23 16:18:16,260] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4618
[2019-03-23 16:18:16,266] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 88.0, 1.0, 2.0, 0.3634802786437301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 406202.8015859347, 406202.801585935, 119976.6021929858], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4229400.0000, 
sim time next is 4230000.0000, 
raw observation next is [19.0, 88.0, 1.0, 2.0, 0.3647468568568258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 407621.5181973057, 407621.5181973054, 120082.22301072], 
processed observation next is [1.0, 1.0, 0.5, 0.88, 1.0, 1.0, 0.20593357107103222, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15097093266566877, 0.15097093266566866, 0.29288347075785365], 
reward next is 0.7071, 
noisyNet noise sample is [array([0.5299592], dtype=float32), 0.6760343]. 
=============================================
[2019-03-23 16:18:16,291] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[71.04009 ]
 [71.04743 ]
 [71.06162 ]
 [71.082054]
 [71.12114 ]], R is [[71.0746994 ]
 [71.07132721]
 [71.06809998]
 [71.06480408]
 [71.06152344]].
[2019-03-23 16:18:16,407] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139500, global step 2232568: loss 0.2046
[2019-03-23 16:18:16,410] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139500, global step 2232569: learning rate 0.0000
[2019-03-23 16:18:16,544] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139500, global step 2232640: loss 0.1039
[2019-03-23 16:18:16,547] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139500, global step 2232640: learning rate 0.0000
[2019-03-23 16:18:16,777] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139500, global step 2232763: loss 0.1076
[2019-03-23 16:18:16,781] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139500, global step 2232764: learning rate 0.0000
[2019-03-23 16:18:16,807] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139500, global step 2232776: loss 0.3520
[2019-03-23 16:18:16,808] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139500, global step 2232776: learning rate 0.0000
[2019-03-23 16:18:17,278] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139500, global step 2233023: loss 0.1243
[2019-03-23 16:18:17,283] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139500, global step 2233024: learning rate 0.0000
[2019-03-23 16:18:20,468] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.8905544e-10 1.0000000e+00 1.5386672e-21 3.7461076e-14 1.1263897e-17], sum to 1.0000
[2019-03-23 16:18:20,469] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9551
[2019-03-23 16:18:20,474] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 85.5, 1.0, 2.0, 0.4049678644384403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 458360.5108026888, 458360.5108026888, 126455.746037945], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4422600.0000, 
sim time next is 4423200.0000, 
raw observation next is [20.33333333333333, 86.33333333333334, 1.0, 2.0, 0.4026250380183539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 455482.4485974388, 455482.4485974388, 126097.2830346519], 
processed observation next is [0.0, 0.17391304347826086, 0.5606060606060604, 0.8633333333333334, 1.0, 1.0, 0.2532812975229424, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1686972031842366, 0.1686972031842366, 0.30755434886500466], 
reward next is 0.6924, 
noisyNet noise sample is [array([-2.3718772], dtype=float32), 0.099667914]. 
=============================================
[2019-03-23 16:18:21,716] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9900175e-10 1.0000000e+00 1.3723261e-19 7.5209792e-15 6.0882463e-19], sum to 1.0000
[2019-03-23 16:18:21,722] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2113
[2019-03-23 16:18:21,726] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 78.0, 1.0, 2.0, 0.3920761827223053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 441921.7606203331, 441921.7606203328, 124193.1507297933], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4312800.0000, 
sim time next is 4313400.0000, 
raw observation next is [21.0, 78.0, 1.0, 2.0, 0.38958136698379, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 438990.6494278092, 438990.6494278092, 123907.3926885854], 
processed observation next is [1.0, 0.9565217391304348, 0.5909090909090909, 0.78, 1.0, 1.0, 0.23697670872973745, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16258912941770712, 0.16258912941770712, 0.30221315289898876], 
reward next is 0.6978, 
noisyNet noise sample is [array([1.1746683], dtype=float32), 2.044303]. 
=============================================
[2019-03-23 16:18:24,923] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140000, global step 2237061: loss 0.0176
[2019-03-23 16:18:24,924] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140000, global step 2237062: learning rate 0.0000
[2019-03-23 16:18:26,357] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140000, global step 2237797: loss 0.0427
[2019-03-23 16:18:26,358] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140000, global step 2237797: learning rate 0.0000
[2019-03-23 16:18:26,700] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1532626e-08 1.0000000e+00 3.8203459e-20 8.4516826e-14 5.2209053e-17], sum to 1.0000
[2019-03-23 16:18:26,708] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7066
[2019-03-23 16:18:26,716] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 78.83333333333333, 1.0, 2.0, 0.4490454020754537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 511970.8956891022, 511970.8956891022, 133929.7934511263], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4438200.0000, 
sim time next is 4438800.0000, 
raw observation next is [23.0, 78.0, 1.0, 2.0, 0.4507269448755032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 513946.6334416406, 513946.6334416409, 134206.9373651471], 
processed observation next is [0.0, 0.391304347826087, 0.6818181818181818, 0.78, 1.0, 1.0, 0.31340868109437897, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1903506049783854, 0.19035060497838552, 0.32733399357352955], 
reward next is 0.6727, 
noisyNet noise sample is [array([1.6357472], dtype=float32), 0.80259746]. 
=============================================
[2019-03-23 16:18:29,163] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.9473503e-11 1.0000000e+00 1.4045255e-21 3.2208930e-15 1.1874992e-20], sum to 1.0000
[2019-03-23 16:18:29,172] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8753
[2019-03-23 16:18:29,176] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 78.0, 1.0, 2.0, 0.4997051965112653, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 570049.753670859, 570049.753670859, 141728.5898342388], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4471200.0000, 
sim time next is 4471800.0000, 
raw observation next is [23.83333333333333, 78.83333333333333, 1.0, 2.0, 0.4986533458163162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 568876.0260466185, 568876.0260466185, 141540.0152789013], 
processed observation next is [0.0, 0.782608695652174, 0.7196969696969695, 0.7883333333333333, 1.0, 1.0, 0.3733166822703952, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21069482446171053, 0.21069482446171053, 0.34521954946073485], 
reward next is 0.6548, 
noisyNet noise sample is [array([-0.28523484], dtype=float32), 0.60953546]. 
=============================================
[2019-03-23 16:18:30,221] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140000, global step 2239834: loss 0.0585
[2019-03-23 16:18:30,227] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140000, global step 2239834: learning rate 0.0000
[2019-03-23 16:18:30,370] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140000, global step 2239912: loss 0.0003
[2019-03-23 16:18:30,372] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140000, global step 2239912: learning rate 0.0000
[2019-03-23 16:18:30,408] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140000, global step 2239930: loss 0.0137
[2019-03-23 16:18:30,410] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140000, global step 2239930: learning rate 0.0000
[2019-03-23 16:18:30,645] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140000, global step 2240057: loss 0.0122
[2019-03-23 16:18:30,647] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140000, global step 2240057: learning rate 0.0000
[2019-03-23 16:18:30,647] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140000, global step 2240057: loss 0.0147
[2019-03-23 16:18:30,650] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140000, global step 2240058: learning rate 0.0000
[2019-03-23 16:18:31,007] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140000, global step 2240249: loss 0.0122
[2019-03-23 16:18:31,010] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140000, global step 2240249: learning rate 0.0000
[2019-03-23 16:18:31,154] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140000, global step 2240325: loss 0.0116
[2019-03-23 16:18:31,159] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140000, global step 2240325: learning rate 0.0000
[2019-03-23 16:18:31,195] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140000, global step 2240347: loss 0.0003
[2019-03-23 16:18:31,197] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140000, global step 2240348: learning rate 0.0000
[2019-03-23 16:18:31,358] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140000, global step 2240433: loss 0.0118
[2019-03-23 16:18:31,360] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140000, global step 2240434: learning rate 0.0000
[2019-03-23 16:18:31,766] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140000, global step 2240652: loss 0.0349
[2019-03-23 16:18:31,771] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140000, global step 2240654: learning rate 0.0000
[2019-03-23 16:18:31,796] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140000, global step 2240665: loss 0.0119
[2019-03-23 16:18:31,799] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140000, global step 2240665: learning rate 0.0000
[2019-03-23 16:18:31,856] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140000, global step 2240697: loss 0.0007
[2019-03-23 16:18:31,858] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140000, global step 2240697: learning rate 0.0000
[2019-03-23 16:18:32,092] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140000, global step 2240821: loss 0.0485
[2019-03-23 16:18:32,093] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140000, global step 2240821: learning rate 0.0000
[2019-03-23 16:18:32,240] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140000, global step 2240896: loss 0.1042
[2019-03-23 16:18:32,241] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140000, global step 2240896: learning rate 0.0000
[2019-03-23 16:18:32,563] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.2373980e-11 1.0000000e+00 1.0770960e-22 2.1238513e-15 2.1634003e-18], sum to 1.0000
[2019-03-23 16:18:32,568] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4140
[2019-03-23 16:18:32,573] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 75.0, 1.0, 2.0, 0.2654499222873655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 288228.2877667096, 288228.2877667098, 90730.96868612032], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4663800.0000, 
sim time next is 4664400.0000, 
raw observation next is [17.33333333333333, 75.66666666666666, 1.0, 2.0, 0.2629561672483062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 285519.7477671632, 285519.7477671629, 89714.63813194231], 
processed observation next is [1.0, 1.0, 0.42424242424242403, 0.7566666666666666, 1.0, 1.0, 0.07869520906038277, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10574805472857897, 0.10574805472857886, 0.21881619056571294], 
reward next is 0.7812, 
noisyNet noise sample is [array([1.7420834], dtype=float32), -0.4225684]. 
=============================================
[2019-03-23 16:18:39,939] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140500, global step 2244959: loss 61.4026
[2019-03-23 16:18:39,943] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140500, global step 2244961: learning rate 0.0000
[2019-03-23 16:18:41,892] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140500, global step 2245928: loss 41.5221
[2019-03-23 16:18:41,894] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140500, global step 2245929: learning rate 0.0000
[2019-03-23 16:18:43,245] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1796895e-07 9.9999976e-01 2.4887936e-19 1.7439018e-12 6.5814158e-16], sum to 1.0000
[2019-03-23 16:18:43,253] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1547
[2019-03-23 16:18:43,259] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.7834177862233779, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 889500.3091360445, 889500.3091360445, 173004.0083197685], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4873200.0000, 
sim time next is 4873800.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.7828257595380779, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 888827.520077587, 888827.520077587, 172917.1501405915], 
processed observation next is [1.0, 0.391304347826087, 0.5, 1.0, 1.0, 1.0, 0.7285321994225974, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3291953778065137, 0.3291953778065137, 0.42174914668436947], 
reward next is 0.5783, 
noisyNet noise sample is [array([-0.9383785], dtype=float32), -1.6404922]. 
=============================================
[2019-03-23 16:18:45,182] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0526625e-08 1.0000000e+00 1.0617826e-20 2.8777474e-13 3.3504861e-17], sum to 1.0000
[2019-03-23 16:18:45,189] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0989
[2019-03-23 16:18:45,195] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 85.5, 1.0, 2.0, 0.4172123549245484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 473741.8688691885, 473741.8688691888, 128654.0691621063], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4912200.0000, 
sim time next is 4912800.0000, 
raw observation next is [21.0, 86.33333333333334, 1.0, 2.0, 0.4204481554206463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 477722.2025554839, 477722.2025554839, 129209.6266244541], 
processed observation next is [1.0, 0.8695652173913043, 0.5909090909090909, 0.8633333333333334, 1.0, 1.0, 0.2755601942758078, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17693414909462366, 0.17693414909462366, 0.3151454307913515], 
reward next is 0.6849, 
noisyNet noise sample is [array([0.07528716], dtype=float32), -0.87756747]. 
=============================================
[2019-03-23 16:18:45,611] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140500, global step 2247888: loss -8.8959
[2019-03-23 16:18:45,615] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140500, global step 2247889: learning rate 0.0000
[2019-03-23 16:18:45,621] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140500, global step 2247890: loss -40.8290
[2019-03-23 16:18:45,623] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140500, global step 2247890: learning rate 0.0000
[2019-03-23 16:18:45,778] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140500, global step 2247976: loss -42.9288
[2019-03-23 16:18:45,780] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140500, global step 2247977: learning rate 0.0000
[2019-03-23 16:18:45,884] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140500, global step 2248036: loss 1.7751
[2019-03-23 16:18:45,889] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140500, global step 2248037: learning rate 0.0000
[2019-03-23 16:18:45,950] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140500, global step 2248064: loss -32.3651
[2019-03-23 16:18:45,952] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140500, global step 2248065: learning rate 0.0000
[2019-03-23 16:18:46,278] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140500, global step 2248238: loss -27.3235
[2019-03-23 16:18:46,281] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140500, global step 2248240: learning rate 0.0000
[2019-03-23 16:18:46,326] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140500, global step 2248266: loss -32.7346
[2019-03-23 16:18:46,328] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140500, global step 2248266: learning rate 0.0000
[2019-03-23 16:18:46,526] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140500, global step 2248372: loss 36.1141
[2019-03-23 16:18:46,527] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140500, global step 2248372: learning rate 0.0000
[2019-03-23 16:18:46,717] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140500, global step 2248465: loss 26.8065
[2019-03-23 16:18:46,718] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140500, global step 2248465: learning rate 0.0000
[2019-03-23 16:18:46,845] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4524663e-10 1.0000000e+00 1.1619965e-21 5.8483443e-16 4.7492425e-19], sum to 1.0000
[2019-03-23 16:18:46,846] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6112
[2019-03-23 16:18:46,849] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 96.0, 1.0, 2.0, 0.5099842005525846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 581674.4547466817, 581674.4547466815, 143154.3160830911], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4814400.0000, 
sim time next is 4815000.0000, 
raw observation next is [21.5, 97.0, 1.0, 2.0, 0.4966455097285857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 566522.3056705081, 566522.3056705083, 141451.3514526153], 
processed observation next is [1.0, 0.7391304347826086, 0.6136363636363636, 0.97, 1.0, 1.0, 0.37080688716073207, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20982307617426224, 0.20982307617426232, 0.34500329622589093], 
reward next is 0.6550, 
noisyNet noise sample is [array([0.688293], dtype=float32), -1.4462439]. 
=============================================
[2019-03-23 16:18:46,849] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140500, global step 2248537: loss -0.7408
[2019-03-23 16:18:46,852] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140500, global step 2248537: learning rate 0.0000
[2019-03-23 16:18:46,864] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[70.99915 ]
 [70.33647 ]
 [69.859985]
 [69.463104]
 [69.73051 ]], R is [[71.04048157]
 [70.98091888]
 [70.88703156]
 [70.6988678 ]
 [70.50157928]].
[2019-03-23 16:18:47,111] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140500, global step 2248683: loss -29.0743
[2019-03-23 16:18:47,112] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140500, global step 2248683: learning rate 0.0000
[2019-03-23 16:18:47,275] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140500, global step 2248774: loss 37.2239
[2019-03-23 16:18:47,278] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140500, global step 2248774: learning rate 0.0000
[2019-03-23 16:18:47,564] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.2568513e-09 1.0000000e+00 4.6285897e-17 2.0621651e-12 1.2082006e-16], sum to 1.0000
[2019-03-23 16:18:47,565] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140500, global step 2248935: loss 47.1494
[2019-03-23 16:18:47,567] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140500, global step 2248935: learning rate 0.0000
[2019-03-23 16:18:47,573] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7353
[2019-03-23 16:18:47,581] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1173194.078600534 W.
[2019-03-23 16:18:47,584] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.0, 99.0, 1.0, 2.0, 0.5191620056792767, 1.0, 2.0, 0.5191620056792767, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846275488033, 1173194.078600534, 1173194.078600534, 238914.2758255119], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4809000.0000, 
sim time next is 4809600.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.3484754609238532, 1.0, 2.0, 0.3484754609238532, 1.0, 1.0, 0.7045375891567996, 6.911199999999999, 6.9112, 77.3421103, 1178439.72691999, 1178439.72691999, 282578.4539256743], 
processed observation next is [1.0, 0.6956521739130435, 0.6363636363636364, 1.0, 1.0, 1.0, 0.18559432615481644, 1.0, 1.0, 0.18559432615481644, 1.0, 0.5, 0.577910841652571, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4364591581185148, 0.4364591581185148, 0.6892157412821325], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4527699], dtype=float32), -0.20810382]. 
=============================================
[2019-03-23 16:18:47,675] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140500, global step 2249002: loss 52.2796
[2019-03-23 16:18:47,676] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140500, global step 2249003: learning rate 0.0000
[2019-03-23 16:18:49,555] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 16:18:49,558] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:18:49,559] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:18:49,559] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:18:49,559] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:18:49,560] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:18:49,561] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:18:49,561] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:18:49,562] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:18:49,563] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:18:49,564] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:18:49,589] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run91
[2019-03-23 16:18:49,622] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run91
[2019-03-23 16:18:49,655] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run91
[2019-03-23 16:18:49,683] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run91
[2019-03-23 16:18:49,684] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run91
[2019-03-23 16:19:06,225] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.052698], dtype=float32), 0.37770543]
[2019-03-23 16:19:06,228] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.11978487666667, 80.22982190666667, 1.0, 2.0, 0.5616098665718615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769694995, 640191.0431514581, 640191.0431514581, 150770.9451156221]
[2019-03-23 16:19:06,228] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:19:06,232] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.1655802e-08 1.0000000e+00 5.9765733e-19 4.5109378e-13 2.2111438e-16], sampled 0.9086856554390028
[2019-03-23 16:19:26,548] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.052698], dtype=float32), 0.37770543]
[2019-03-23 16:19:26,549] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.1, 53.0, 1.0, 2.0, 0.4569871338268348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 520818.636736632, 520818.636736632, 138827.8046127883]
[2019-03-23 16:19:26,551] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:19:26,552] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.2207205e-09 1.0000000e+00 1.4269001e-20 3.6000689e-14 8.8144292e-18], sampled 0.564784660113912
[2019-03-23 16:19:32,950] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.052698], dtype=float32), 0.37770543]
[2019-03-23 16:19:32,950] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 83.0, 1.0, 2.0, 0.4428972757498358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 504603.1152432897, 504603.1152432897, 132773.2755677894]
[2019-03-23 16:19:32,950] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:19:32,954] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.6535273e-09 1.0000000e+00 7.5591577e-20 1.1131162e-13 3.7143133e-17], sampled 0.6921087535079279
[2019-03-23 16:19:38,580] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.052698], dtype=float32), 0.37770543]
[2019-03-23 16:19:38,581] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.73333333333333, 89.33333333333333, 1.0, 2.0, 0.4382572595554526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 498387.1398027299, 498387.1398027299, 135676.9455227544]
[2019-03-23 16:19:38,584] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:19:38,588] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.3730520e-09 1.0000000e+00 1.6610271e-20 3.9841682e-14 1.0051161e-17], sampled 0.144533884912187
[2019-03-23 16:19:50,724] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.052698], dtype=float32), 0.37770543]
[2019-03-23 16:19:50,726] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.0, 70.0, 1.0, 2.0, 0.5225109563582991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 594881.3005703798, 594881.3005703798, 145831.6221109789]
[2019-03-23 16:19:50,727] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:19:50,730] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.2762585e-09 1.0000000e+00 6.2511228e-20 9.7808324e-14 3.1533551e-17], sampled 0.18769585950102707
[2019-03-23 16:20:37,233] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 16:20:37,276] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 16:20:37,277] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 16:20:37,356] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 16:20:37,373] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 16:20:38,388] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 2250000, evaluation results [2250000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 16:20:39,863] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.2044864e-12 1.0000000e+00 4.6172915e-22 3.4359811e-15 4.6315301e-21], sum to 1.0000
[2019-03-23 16:20:39,866] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6284
[2019-03-23 16:20:39,873] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 88.0, 1.0, 2.0, 0.4233411535842916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 480886.4386862759, 480886.4386862762, 129391.5625358769], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4915200.0000, 
sim time next is 4915800.0000, 
raw observation next is [20.5, 88.0, 1.0, 2.0, 0.4184317409592149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 474812.8379445921, 474812.8379445923, 128535.2321533412], 
processed observation next is [1.0, 0.9130434782608695, 0.5681818181818182, 0.88, 1.0, 1.0, 0.27303967619901864, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17585660664614522, 0.1758566066461453, 0.3135005662276615], 
reward next is 0.6865, 
noisyNet noise sample is [array([-0.16006675], dtype=float32), 1.6905373]. 
=============================================
[2019-03-23 16:20:39,910] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.0778958e-10 1.0000000e+00 1.0017609e-21 7.9105347e-15 6.4267917e-19], sum to 1.0000
[2019-03-23 16:20:39,916] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5072
[2019-03-23 16:20:39,920] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3804132868627348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 427246.5410246626, 427246.5410246623, 122373.0752704277], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4921200.0000, 
sim time next is 4921800.0000, 
raw observation next is [18.16666666666667, 99.00000000000001, 1.0, 2.0, 0.3794640580260923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 426238.5240333385, 426238.5240333388, 122320.4020518755], 
processed observation next is [1.0, 1.0, 0.4621212121212123, 0.9900000000000001, 1.0, 1.0, 0.22433007253261533, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1578661200123476, 0.1578661200123477, 0.29834244402896465], 
reward next is 0.7017, 
noisyNet noise sample is [array([-1.2122039], dtype=float32), 2.1549556]. 
=============================================
[2019-03-23 16:20:43,853] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141000, global step 2252890: loss 0.2165
[2019-03-23 16:20:43,857] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141000, global step 2252890: learning rate 0.0000
[2019-03-23 16:20:44,464] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3151531e-10 1.0000000e+00 2.0582251e-22 3.5697488e-15 2.6408938e-18], sum to 1.0000
[2019-03-23 16:20:44,470] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0530
[2019-03-23 16:20:44,478] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 81.16666666666667, 1.0, 2.0, 0.2849549493128204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 309413.7862923166, 309413.7862923169, 97527.44104880404], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5007000.0000, 
sim time next is 5007600.0000, 
raw observation next is [17.0, 82.0, 1.0, 2.0, 0.2806492166611334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 304737.0103567261, 304737.0103567261, 96215.29007976975], 
processed observation next is [1.0, 1.0, 0.4090909090909091, 0.82, 1.0, 1.0, 0.10081152082641674, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11286555939138004, 0.11286555939138004, 0.23467143921895062], 
reward next is 0.7653, 
noisyNet noise sample is [array([0.45464873], dtype=float32), -1.6653696]. 
=============================================
[2019-03-23 16:20:45,438] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.4537945e-11 1.0000000e+00 3.1994498e-23 1.7984565e-16 7.4883490e-21], sum to 1.0000
[2019-03-23 16:20:45,442] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3236
[2019-03-23 16:20:45,448] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 62.66666666666667, 1.0, 2.0, 0.3018582315005937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 327774.1310203323, 327774.1310203323, 104718.231737682], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4987200.0000, 
sim time next is 4987800.0000, 
raw observation next is [20.0, 62.0, 1.0, 2.0, 0.2863627970532033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 310942.9640134359, 310942.9640134356, 101076.0403543813], 
processed observation next is [1.0, 0.7391304347826086, 0.5454545454545454, 0.62, 1.0, 1.0, 0.10795349631650408, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11516406074571699, 0.11516406074571689, 0.24652692769361292], 
reward next is 0.7535, 
noisyNet noise sample is [array([0.49451447], dtype=float32), -0.31198782]. 
=============================================
[2019-03-23 16:20:45,635] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141000, global step 2253807: loss 0.0058
[2019-03-23 16:20:45,636] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141000, global step 2253807: learning rate 0.0000
[2019-03-23 16:20:47,304] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.6804624e-11 1.0000000e+00 5.8181938e-23 6.1702730e-17 2.7414254e-19], sum to 1.0000
[2019-03-23 16:20:47,311] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0261
[2019-03-23 16:20:47,321] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.33333333333333, 100.0, 1.0, 2.0, 0.2369617853710211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 257287.3903744289, 257287.3903744289, 84014.63501221985], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5035200.0000, 
sim time next is 5035800.0000, 
raw observation next is [14.66666666666667, 100.0, 1.0, 2.0, 0.2479346898325014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 269204.8026032164, 269204.8026032161, 88034.74109974889], 
processed observation next is [0.0, 0.2608695652173913, 0.30303030303030315, 1.0, 1.0, 1.0, 0.05991836229062672, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0997054824456357, 0.09970548244563558, 0.21471888073109485], 
reward next is 0.7853, 
noisyNet noise sample is [array([0.89163], dtype=float32), 0.748922]. 
=============================================
[2019-03-23 16:20:49,518] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141000, global step 2255843: loss 0.0015
[2019-03-23 16:20:49,520] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141000, global step 2255843: learning rate 0.0000
[2019-03-23 16:20:49,718] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141000, global step 2255953: loss 0.1145
[2019-03-23 16:20:49,725] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141000, global step 2255954: learning rate 0.0000
[2019-03-23 16:20:49,752] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141000, global step 2255970: loss 0.0771
[2019-03-23 16:20:49,757] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141000, global step 2255972: learning rate 0.0000
[2019-03-23 16:20:49,772] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141000, global step 2255976: loss 0.0361
[2019-03-23 16:20:49,773] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141000, global step 2255976: learning rate 0.0000
[2019-03-23 16:20:49,831] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141000, global step 2256008: loss 0.0013
[2019-03-23 16:20:49,833] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141000, global step 2256009: learning rate 0.0000
[2019-03-23 16:20:50,074] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141000, global step 2256136: loss 0.0016
[2019-03-23 16:20:50,078] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141000, global step 2256136: learning rate 0.0000
[2019-03-23 16:20:50,184] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141000, global step 2256194: loss 0.0284
[2019-03-23 16:20:50,186] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141000, global step 2256197: learning rate 0.0000
[2019-03-23 16:20:50,612] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141000, global step 2256416: loss 0.0454
[2019-03-23 16:20:50,614] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141000, global step 2256416: learning rate 0.0000
[2019-03-23 16:20:50,828] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141000, global step 2256538: loss 0.0097
[2019-03-23 16:20:50,831] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141000, global step 2256540: learning rate 0.0000
[2019-03-23 16:20:50,857] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141000, global step 2256550: loss 0.0224
[2019-03-23 16:20:50,864] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141000, global step 2256550: learning rate 0.0000
[2019-03-23 16:20:51,084] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141000, global step 2256665: loss 0.0261
[2019-03-23 16:20:51,086] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141000, global step 2256665: learning rate 0.0000
[2019-03-23 16:20:51,306] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141000, global step 2256779: loss 0.0137
[2019-03-23 16:20:51,308] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141000, global step 2256780: learning rate 0.0000
[2019-03-23 16:20:51,750] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141000, global step 2257015: loss 0.0222
[2019-03-23 16:20:51,753] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141000, global step 2257016: learning rate 0.0000
[2019-03-23 16:20:51,765] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141000, global step 2257023: loss 0.0180
[2019-03-23 16:20:51,766] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141000, global step 2257023: learning rate 0.0000
[2019-03-23 16:20:51,792] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.9233867e-10 1.0000000e+00 7.2482932e-23 3.9246124e-15 6.8940235e-18], sum to 1.0000
[2019-03-23 16:20:51,793] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6886
[2019-03-23 16:20:51,799] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666666, 69.33333333333334, 1.0, 2.0, 0.5597713945202133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 633381.5715195404, 633381.5715195404, 152333.3672433452], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5145000.0000, 
sim time next is 5145600.0000, 
raw observation next is [27.33333333333334, 68.66666666666667, 1.0, 2.0, 0.5649880582535515, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 639020.9722273998, 639020.9722273998, 153102.536036811], 
processed observation next is [0.0, 0.5652173913043478, 0.878787878787879, 0.6866666666666668, 1.0, 1.0, 0.4562350728169393, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23667443415829623, 0.23667443415829623, 0.3734208196019781], 
reward next is 0.6266, 
noisyNet noise sample is [array([-2.6704087], dtype=float32), 0.40622333]. 
=============================================
[2019-03-23 16:20:53,919] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3928532e-07 9.9999988e-01 9.1171055e-21 6.5256868e-14 9.8280627e-19], sum to 1.0000
[2019-03-23 16:20:53,930] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7315
[2019-03-23 16:20:53,934] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4404041906871755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 501764.9781219977, 501764.9781219977, 132521.1973821438], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5185200.0000, 
sim time next is 5185800.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4395274750113518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 500764.4016974586, 500764.4016974589, 132429.5488483578], 
processed observation next is [1.0, 0.0, 0.6363636363636364, 0.83, 1.0, 1.0, 0.2994093437641897, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18546829692498465, 0.18546829692498476, 0.322998899630141], 
reward next is 0.6770, 
noisyNet noise sample is [array([-0.46975276], dtype=float32), -0.68453246]. 
=============================================
[2019-03-23 16:20:59,475] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141500, global step 2261094: loss -159.5482
[2019-03-23 16:20:59,480] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141500, global step 2261096: learning rate 0.0000
[2019-03-23 16:21:00,870] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141500, global step 2261831: loss 30.6773
[2019-03-23 16:21:00,875] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141500, global step 2261831: learning rate 0.0000
[2019-03-23 16:21:01,669] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4484204e-08 1.0000000e+00 5.6492533e-19 5.1479373e-14 1.3132623e-15], sum to 1.0000
[2019-03-23 16:21:01,680] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4560
[2019-03-23 16:21:01,684] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 54.00000000000001, 1.0, 2.0, 0.42449237708336, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482347.1044834981, 482347.1044834981, 129627.9452054078], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5343600.0000, 
sim time next is 5344200.0000, 
raw observation next is [26.1, 54.0, 1.0, 2.0, 0.4248942851650592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482805.9944416936, 482805.9944416936, 129669.0671666594], 
processed observation next is [1.0, 0.8695652173913043, 0.8227272727272728, 0.54, 1.0, 1.0, 0.281117856456324, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17881703497840504, 0.17881703497840504, 0.31626601747965705], 
reward next is 0.6837, 
noisyNet noise sample is [array([-0.4669041], dtype=float32), -0.28644645]. 
=============================================
[2019-03-23 16:21:03,688] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.1705451e-09 1.0000000e+00 4.6912786e-20 4.1973169e-13 1.5436507e-16], sum to 1.0000
[2019-03-23 16:21:03,700] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6687
[2019-03-23 16:21:03,703] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.73333333333333, 56.66666666666667, 1.0, 2.0, 0.4220159346560499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 479832.641665652, 479832.641665652, 129641.4642792418], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5347200.0000, 
sim time next is 5347800.0000, 
raw observation next is [25.55, 58.0, 1.0, 2.0, 0.4266002193183771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 485204.5014636535, 485204.5014636535, 130234.9462516586], 
processed observation next is [1.0, 0.9130434782608695, 0.7977272727272727, 0.58, 1.0, 1.0, 0.2832502741479713, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17970537091246427, 0.17970537091246427, 0.31764621036989904], 
reward next is 0.6824, 
noisyNet noise sample is [array([0.34664425], dtype=float32), -0.92121917]. 
=============================================
[2019-03-23 16:21:04,545] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141500, global step 2263753: loss 1.5233
[2019-03-23 16:21:04,547] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141500, global step 2263753: learning rate 0.0000
[2019-03-23 16:21:04,984] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141500, global step 2263983: loss -53.0324
[2019-03-23 16:21:04,988] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141500, global step 2263984: learning rate 0.0000
[2019-03-23 16:21:05,114] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141500, global step 2264053: loss -124.0302
[2019-03-23 16:21:05,115] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141500, global step 2264053: learning rate 0.0000
[2019-03-23 16:21:05,117] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141500, global step 2264054: loss -60.9568
[2019-03-23 16:21:05,119] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141500, global step 2264054: learning rate 0.0000
[2019-03-23 16:21:05,221] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141500, global step 2264109: loss -94.7759
[2019-03-23 16:21:05,222] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141500, global step 2264109: learning rate 0.0000
[2019-03-23 16:21:05,271] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141500, global step 2264133: loss -24.7715
[2019-03-23 16:21:05,274] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141500, global step 2264133: learning rate 0.0000
[2019-03-23 16:21:05,350] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141500, global step 2264176: loss -19.9370
[2019-03-23 16:21:05,352] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141500, global step 2264176: learning rate 0.0000
[2019-03-23 16:21:05,804] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141500, global step 2264420: loss 46.2779
[2019-03-23 16:21:05,806] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141500, global step 2264420: learning rate 0.0000
[2019-03-23 16:21:05,846] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141500, global step 2264437: loss 67.9873
[2019-03-23 16:21:05,849] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141500, global step 2264437: learning rate 0.0000
[2019-03-23 16:21:06,281] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141500, global step 2264670: loss -77.8723
[2019-03-23 16:21:06,284] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141500, global step 2264671: learning rate 0.0000
[2019-03-23 16:21:06,475] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141500, global step 2264765: loss -62.1034
[2019-03-23 16:21:06,478] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141500, global step 2264765: learning rate 0.0000
[2019-03-23 16:21:06,528] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141500, global step 2264795: loss -6.7469
[2019-03-23 16:21:06,532] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141500, global step 2264796: learning rate 0.0000
[2019-03-23 16:21:06,964] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141500, global step 2265017: loss -58.1181
[2019-03-23 16:21:06,967] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141500, global step 2265018: learning rate 0.0000
[2019-03-23 16:21:06,980] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141500, global step 2265021: loss -65.2265
[2019-03-23 16:21:06,981] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141500, global step 2265023: learning rate 0.0000
[2019-03-23 16:21:08,738] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4908893e-05 9.9998510e-01 7.2895059e-14 5.0772258e-09 1.3962557e-11], sum to 1.0000
[2019-03-23 16:21:08,741] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0687
[2019-03-23 16:21:08,743] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1284187.509345289 W.
[2019-03-23 16:21:08,748] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.91666666666667, 69.83333333333333, 1.0, 2.0, 0.5680685541827513, 1.0, 2.0, 0.5680685541827513, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1284187.509345289, 1284187.509345289, 251552.3308414801], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5485800.0000, 
sim time next is 5486400.0000, 
raw observation next is [26.1, 69.0, 1.0, 2.0, 0.5700085968068139, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9775877449043994, 6.911199999999999, 6.9112, 77.32846344354104, 1195654.159679456, 1195654.159679456, 273631.5599183686], 
processed observation next is [1.0, 0.5217391304347826, 0.8227272727272728, 0.69, 1.0, 1.0, 0.4625107460085174, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9679824927205707, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.44283487395535404, 0.44283487395535404, 0.6673940485813868], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.07814085], dtype=float32), -0.054914538]. 
=============================================
[2019-03-23 16:21:12,367] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.4160930e-05 9.9995589e-01 2.2786677e-15 1.3682797e-08 9.8731461e-13], sum to 1.0000
[2019-03-23 16:21:12,378] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1740
[2019-03-23 16:21:12,382] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 87.0, 1.0, 2.0, 0.4695902621284575, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 532368.2521421504, 532368.2521421504, 133285.6788150413], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5539800.0000, 
sim time next is 5540400.0000, 
raw observation next is [20.5, 87.0, 1.0, 2.0, 0.4607472966090362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 522317.5275046534, 522317.5275046531, 132368.0312084027], 
processed observation next is [1.0, 0.13043478260869565, 0.5681818181818182, 0.87, 1.0, 1.0, 0.3259341207612952, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1934509361128346, 0.19345093611283448, 0.32284885660586027], 
reward next is 0.6772, 
noisyNet noise sample is [array([-0.28090927], dtype=float32), 0.4908791]. 
=============================================
[2019-03-23 16:21:14,336] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142000, global step 2268901: loss 1.8375
[2019-03-23 16:21:14,337] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142000, global step 2268901: learning rate 0.0000
[2019-03-23 16:21:16,032] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142000, global step 2269787: loss 1.2318
[2019-03-23 16:21:16,034] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142000, global step 2269787: learning rate 0.0000
[2019-03-23 16:21:19,675] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142000, global step 2271710: loss 0.9218
[2019-03-23 16:21:19,677] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142000, global step 2271710: learning rate 0.0000
[2019-03-23 16:21:20,106] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142000, global step 2271936: loss 0.2855
[2019-03-23 16:21:20,111] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142000, global step 2271937: learning rate 0.0000
[2019-03-23 16:21:20,294] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142000, global step 2272031: loss 3.2095
[2019-03-23 16:21:20,297] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142000, global step 2272034: learning rate 0.0000
[2019-03-23 16:21:20,305] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9996889e-01 2.2713062e-05 1.4623686e-08 8.3693385e-06 2.6484455e-09], sum to 1.0000
[2019-03-23 16:21:20,313] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4460
[2019-03-23 16:21:20,318] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [10.73333333333333, 80.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 158841.6535949923, 158841.6535949926, 55285.06153864176], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5710800.0000, 
sim time next is 5711400.0000, 
raw observation next is [10.55, 81.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 156558.5238790925, 156558.5238790925, 54878.62741725323], 
processed observation next is [0.0, 0.08695652173913043, 0.11590909090909095, 0.815, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.057984638473737964, 0.057984638473737964, 0.13385031077378837], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2852012], dtype=float32), 0.49910194]. 
=============================================
[2019-03-23 16:21:20,361] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142000, global step 2272066: loss 0.8218
[2019-03-23 16:21:20,365] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142000, global step 2272066: learning rate 0.0000
[2019-03-23 16:21:20,384] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142000, global step 2272075: loss 0.2662
[2019-03-23 16:21:20,386] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142000, global step 2272076: learning rate 0.0000
[2019-03-23 16:21:20,470] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142000, global step 2272126: loss 0.8184
[2019-03-23 16:21:20,474] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142000, global step 2272126: learning rate 0.0000
[2019-03-23 16:21:20,484] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142000, global step 2272131: loss 0.8139
[2019-03-23 16:21:20,487] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142000, global step 2272133: learning rate 0.0000
[2019-03-23 16:21:20,982] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142000, global step 2272391: loss 0.5634
[2019-03-23 16:21:20,982] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142000, global step 2272391: learning rate 0.0000
[2019-03-23 16:21:21,090] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142000, global step 2272451: loss 0.2066
[2019-03-23 16:21:21,095] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142000, global step 2272453: learning rate 0.0000
[2019-03-23 16:21:21,316] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142000, global step 2272567: loss 0.2239
[2019-03-23 16:21:21,318] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142000, global step 2272567: learning rate 0.0000
[2019-03-23 16:21:21,457] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9999988e-01 3.1046820e-08 5.5335621e-09 8.3961147e-08 7.3636895e-11], sum to 1.0000
[2019-03-23 16:21:21,465] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8681
[2019-03-23 16:21:21,468] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.5, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3642689072955308, 6.911200000000001, 6.9112, 77.32846344354104, 212319.0148919453, 212319.014891945, 60591.36062426464], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5734800.0000, 
sim time next is 5735400.0000, 
raw observation next is [15.78333333333333, 61.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3694029443977189, 6.911199999999998, 6.9112, 77.32846344354104, 215113.5776730375, 215113.5776730381, 60990.82442143514], 
processed observation next is [0.0, 0.391304347826087, 0.3537878787878786, 0.61, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.09914706342531276, -1.7763568394002506e-16, 0.0, 0.5084288129206541, 0.07967169543445833, 0.07967169543445855, 0.14875810834496375], 
reward next is 0.8512, 
noisyNet noise sample is [array([0.5108555], dtype=float32), -0.31130642]. 
=============================================
[2019-03-23 16:21:21,763] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142000, global step 2272804: loss 0.2399
[2019-03-23 16:21:21,765] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142000, global step 2272804: learning rate 0.0000
[2019-03-23 16:21:21,840] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142000, global step 2272848: loss 0.9427
[2019-03-23 16:21:21,845] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142000, global step 2272849: learning rate 0.0000
[2019-03-23 16:21:22,043] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142000, global step 2272958: loss 0.4215
[2019-03-23 16:21:22,044] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142000, global step 2272958: learning rate 0.0000
[2019-03-23 16:21:22,199] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142000, global step 2273046: loss 1.1670
[2019-03-23 16:21:22,200] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142000, global step 2273046: learning rate 0.0000
[2019-03-23 16:21:24,457] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.0196630e-04 9.9969769e-01 2.2138001e-16 3.5840870e-07 1.2631671e-12], sum to 1.0000
[2019-03-23 16:21:24,465] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0956
[2019-03-23 16:21:24,470] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.2, 82.5, 1.0, 2.0, 0.3032737142136486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 72.46276211267944, 329319.1471886617, 329319.147188662, 76369.17988295808], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5796600.0000, 
sim time next is 5797200.0000, 
raw observation next is [13.1, 82.0, 1.0, 2.0, 0.36538597538087, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 396784.1641650766, 396784.1641650769, 85847.45489937464], 
processed observation next is [1.0, 0.08695652173913043, 0.2318181818181818, 0.82, 1.0, 1.0, 0.20673246922608746, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14695709783891728, 0.1469570978389174, 0.20938403633993816], 
reward next is 0.7906, 
noisyNet noise sample is [array([-1.2722331], dtype=float32), 1.5243391]. 
=============================================
[2019-03-23 16:21:25,948] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 16:21:25,950] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:21:25,951] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:21:25,951] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:21:25,952] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:21:25,953] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:21:25,954] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:21:25,954] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:21:25,955] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:21:25,956] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:21:25,957] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:21:25,975] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run92
[2019-03-23 16:21:25,975] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run92
[2019-03-23 16:21:26,039] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run92
[2019-03-23 16:21:26,071] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run92
[2019-03-23 16:21:26,071] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run92
[2019-03-23 16:21:56,275] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04962119], dtype=float32), 0.38143817]
[2019-03-23 16:21:56,278] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.80023352666667, 95.08233906666666, 1.0, 2.0, 0.2938641631214766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 319934.4917668309, 319934.4917668305, 115398.9741007981]
[2019-03-23 16:21:56,280] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:21:56,284] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.2760286e-07 9.9999952e-01 1.1360499e-19 2.5095124e-09 1.1085085e-15], sampled 0.5765003123980919
[2019-03-23 16:22:06,505] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.04962119], dtype=float32), 0.38143817]
[2019-03-23 16:22:06,507] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.8525819, 100.0, 1.0, 2.0, 0.4875156858338328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 556223.4836476569, 556223.4836476565, 144098.5239770858]
[2019-03-23 16:22:06,510] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:22:06,513] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.4308574e-06 9.9999762e-01 1.6247717e-17 2.3989330e-08 5.6617024e-14], sampled 0.37115414272850844
[2019-03-23 16:22:21,960] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04962119], dtype=float32), 0.38143817]
[2019-03-23 16:22:21,962] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.33333333333334, 94.0, 1.0, 2.0, 0.5290484084775643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 591715.1939827312, 591715.193982731, 135513.5087341162]
[2019-03-23 16:22:21,964] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:22:21,967] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.9065272e-07 9.9999952e-01 1.7424689e-19 3.0492902e-09 1.5670448e-15], sampled 0.4930084022509623
[2019-03-23 16:22:51,573] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04962119], dtype=float32), 0.38143817]
[2019-03-23 16:22:51,574] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [29.5, 53.33333333333334, 1.0, 2.0, 0.5344322967754594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 607417.2638036802, 607417.2638036802, 147954.5854526992]
[2019-03-23 16:22:51,576] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:22:51,579] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.8324758e-06 9.9999821e-01 7.1002181e-18 1.6466343e-08 2.9211693e-14], sampled 0.7830019121019789
[2019-03-23 16:22:53,244] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04962119], dtype=float32), 0.38143817]
[2019-03-23 16:22:53,246] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.07367774, 71.45095524, 1.0, 2.0, 0.4908086064534915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 559914.5754338922, 559914.5754338922, 144783.2659298173]
[2019-03-23 16:22:53,248] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:22:53,252] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.0872158e-07 9.9999964e-01 4.5962068e-20 1.6647149e-09 5.4446658e-16], sampled 0.6550147001354887
[2019-03-23 16:23:01,353] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.04962119], dtype=float32), 0.38143817]
[2019-03-23 16:23:01,354] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.01666666666667, 45.33333333333334, 1.0, 2.0, 0.3882310704353593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 438655.7033415031, 438655.7033415031, 128782.7809340021]
[2019-03-23 16:23:01,355] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:23:01,358] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.46252933e-06 9.99998569e-01 3.08227659e-18 1.13231255e-08
 1.44676836e-14], sampled 0.9613314011863422
[2019-03-23 16:23:04,471] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04962119], dtype=float32), 0.38143817]
[2019-03-23 16:23:04,472] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.23333333333333, 56.33333333333334, 1.0, 2.0, 0.298231520409854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 323834.7391068159, 323834.7391068159, 107184.2036219408]
[2019-03-23 16:23:04,474] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:23:04,477] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.8601557e-06 9.9999297e-01 2.0850300e-16 7.7264794e-08 3.9252100e-13], sampled 0.5520703048455988
[2019-03-23 16:23:07,214] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.04962119], dtype=float32), 0.38143817]
[2019-03-23 16:23:07,214] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.24928776, 98.42449313, 1.0, 2.0, 0.3733039598994647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 418524.7883651264, 418524.788365126, 125731.291700197]
[2019-03-23 16:23:07,215] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:23:07,218] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.323269e-06 9.999906e-01 5.027022e-16 1.153391e-07 7.896494e-13], sampled 0.22562135663428196
[2019-03-23 16:23:13,238] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 16:23:13,242] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 16:23:13,248] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 16:23:13,263] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 16:23:13,353] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 16:23:14,366] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 2275000, evaluation results [2275000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 16:23:16,104] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.8706992e-07 9.9999976e-01 7.8674142e-21 2.5892080e-09 1.3182799e-17], sum to 1.0000
[2019-03-23 16:23:16,106] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2903
[2019-03-23 16:23:16,110] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.2, 90.0, 1.0, 2.0, 0.344855891585025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 382433.5273235979, 382433.5273235976, 117199.0718558518], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5976600.0000, 
sim time next is 5977200.0000, 
raw observation next is [18.1, 90.0, 1.0, 2.0, 0.3380333814256901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 374283.3604149817, 374283.3604149817, 116437.5761571157], 
processed observation next is [1.0, 0.17391304347826086, 0.45909090909090916, 0.9, 1.0, 1.0, 0.17254172678211263, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1386234668203636, 0.1386234668203636, 0.2839940881880871], 
reward next is 0.7160, 
noisyNet noise sample is [array([0.12776838], dtype=float32), -0.6617897]. 
=============================================
[2019-03-23 16:23:17,821] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142500, global step 2276836: loss -86.6791
[2019-03-23 16:23:17,823] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142500, global step 2276836: learning rate 0.0000
[2019-03-23 16:23:19,070] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.1645407e-06 9.9999619e-01 4.6108612e-17 6.2059019e-07 1.5212464e-13], sum to 1.0000
[2019-03-23 16:23:19,081] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2628
[2019-03-23 16:23:19,088] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 56.5, 1.0, 2.0, 0.944612904863899, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1075978.965767594, 1075978.965767594, 201390.4858643656], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5916600.0000, 
sim time next is 5917200.0000, 
raw observation next is [26.06666666666667, 55.33333333333333, 1.0, 2.0, 0.9594287337140713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1093056.956902286, 1093056.956902286, 204177.9623131395], 
processed observation next is [1.0, 0.4782608695652174, 0.8212121212121214, 0.5533333333333332, 1.0, 1.0, 0.949285917142589, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.40483590996380964, 0.40483590996380964, 0.49799503003204754], 
reward next is 0.5020, 
noisyNet noise sample is [array([0.28166133], dtype=float32), 0.7222734]. 
=============================================
[2019-03-23 16:23:19,905] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142500, global step 2277937: loss -41.5199
[2019-03-23 16:23:19,908] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142500, global step 2277938: learning rate 0.0000
[2019-03-23 16:23:20,407] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.2972432e-04 9.9976736e-01 1.1235365e-16 2.8903301e-06 1.3996228e-11], sum to 1.0000
[2019-03-23 16:23:20,414] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6349
[2019-03-23 16:23:20,421] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.06666666666667, 53.0, 1.0, 2.0, 0.4033240222431428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 457676.7180965557, 457676.7180965557, 127105.0956390441], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5942400.0000, 
sim time next is 5943000.0000, 
raw observation next is [25.78333333333333, 54.5, 1.0, 2.0, 0.4045453314294736, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 459106.5864627147, 459106.5864627147, 127252.6781745944], 
processed observation next is [1.0, 0.782608695652174, 0.8083333333333332, 0.545, 1.0, 1.0, 0.2556816642868419, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17003947646767212, 0.17003947646767212, 0.3103723857916937], 
reward next is 0.6896, 
noisyNet noise sample is [array([1.0603802], dtype=float32), -0.10706135]. 
=============================================
[2019-03-23 16:23:20,440] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[60.412094]
 [59.988464]
 [60.63157 ]
 [60.94486 ]
 [60.84088 ]], R is [[60.01309967]
 [60.10295486]
 [60.19189072]
 [60.28033066]
 [60.3692627 ]].
[2019-03-23 16:23:22,307] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.8846854e-05 9.9995065e-01 4.5988268e-18 4.7290658e-07 7.9067646e-15], sum to 1.0000
[2019-03-23 16:23:22,314] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7667
[2019-03-23 16:23:22,325] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 44.5, 1.0, 2.0, 0.7655840836858431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 843756.9071680858, 843756.9071680856, 158704.7160967243], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6102600.0000, 
sim time next is 6103200.0000, 
raw observation next is [24.6, 44.0, 1.0, 2.0, 0.7323847390892414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 806689.1620915818, 806689.1620915818, 154421.8460857491], 
processed observation next is [1.0, 0.6521739130434783, 0.7545454545454546, 0.44, 1.0, 1.0, 0.6654809238615517, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.29877376373762293, 0.29877376373762293, 0.37663864898963195], 
reward next is 0.6234, 
noisyNet noise sample is [array([2.4275744], dtype=float32), -1.5003802]. 
=============================================
[2019-03-23 16:23:23,275] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142500, global step 2279706: loss -12.1747
[2019-03-23 16:23:23,277] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142500, global step 2279706: learning rate 0.0000
[2019-03-23 16:23:23,737] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142500, global step 2279956: loss -6.1129
[2019-03-23 16:23:23,738] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142500, global step 2279956: learning rate 0.0000
[2019-03-23 16:23:23,822] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142500, global step 2279992: loss -44.9349
[2019-03-23 16:23:23,826] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142500, global step 2279993: learning rate 0.0000
[2019-03-23 16:23:23,925] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142500, global step 2280051: loss -87.9620
[2019-03-23 16:23:23,935] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142500, global step 2280052: learning rate 0.0000
[2019-03-23 16:23:23,935] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142500, global step 2280055: loss -7.5717
[2019-03-23 16:23:23,938] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142500, global step 2280055: learning rate 0.0000
[2019-03-23 16:23:24,084] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142500, global step 2280134: loss -27.9952
[2019-03-23 16:23:24,087] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142500, global step 2280134: learning rate 0.0000
[2019-03-23 16:23:24,110] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142500, global step 2280142: loss -33.3999
[2019-03-23 16:23:24,111] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142500, global step 2280143: learning rate 0.0000
[2019-03-23 16:23:24,421] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142500, global step 2280306: loss 14.4152
[2019-03-23 16:23:24,425] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142500, global step 2280308: learning rate 0.0000
[2019-03-23 16:23:24,520] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142500, global step 2280358: loss -24.5935
[2019-03-23 16:23:24,524] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142500, global step 2280359: learning rate 0.0000
[2019-03-23 16:23:24,695] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.53456946e-04 9.99843240e-01 1.07387125e-14 3.28862370e-06
 2.21069742e-11], sum to 1.0000
[2019-03-23 16:23:24,704] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4789
[2019-03-23 16:23:24,710] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1182823.752979649 W.
[2019-03-23 16:23:24,713] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.16666666666667, 77.83333333333334, 1.0, 2.0, 0.5189450149444951, 1.0, 2.0, 0.5189450149444951, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1182823.752979649, 1182823.752979648, 234216.323410962], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6022200.0000, 
sim time next is 6022800.0000, 
raw observation next is [22.7, 79.0, 1.0, 2.0, 0.334197781736456, 1.0, 2.0, 0.334197781736456, 1.0, 1.0, 0.6763097834311178, 6.9112, 6.9112, 77.3421103, 1143234.452034981, 1143234.452034981, 269443.9462833612], 
processed observation next is [1.0, 0.7391304347826086, 0.6681818181818181, 0.79, 1.0, 1.0, 0.16774722717056995, 1.0, 1.0, 0.16774722717056995, 1.0, 0.5, 0.5375854049015969, 0.0, 0.0, 0.5085185399722538, 0.4234201674203633, 0.4234201674203633, 0.6571803567886858], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5495769], dtype=float32), 0.71717393]. 
=============================================
[2019-03-23 16:23:24,909] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142500, global step 2280563: loss -24.8470
[2019-03-23 16:23:24,911] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142500, global step 2280563: learning rate 0.0000
[2019-03-23 16:23:25,430] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142500, global step 2280838: loss -93.0451
[2019-03-23 16:23:25,432] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142500, global step 2280840: learning rate 0.0000
[2019-03-23 16:23:25,600] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142500, global step 2280928: loss 30.9848
[2019-03-23 16:23:25,601] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142500, global step 2280928: learning rate 0.0000
[2019-03-23 16:23:25,655] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142500, global step 2280955: loss 11.1120
[2019-03-23 16:23:25,655] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142500, global step 2280955: loss -14.2683
[2019-03-23 16:23:25,662] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142500, global step 2280957: learning rate 0.0000
[2019-03-23 16:23:25,662] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142500, global step 2280957: learning rate 0.0000
[2019-03-23 16:23:26,377] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.5326551e-07 9.9999928e-01 5.9997517e-20 1.1361312e-09 2.1206922e-15], sum to 1.0000
[2019-03-23 16:23:26,387] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6242
[2019-03-23 16:23:26,390] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.9, 79.33333333333334, 1.0, 2.0, 0.2521725103478644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 273807.4774870933, 273807.477487093, 82267.33641407182], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6056400.0000, 
sim time next is 6057000.0000, 
raw observation next is [15.8, 79.0, 1.0, 2.0, 0.2380766579582266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 258498.2138179602, 258498.2138179599, 80062.18840564314], 
processed observation next is [1.0, 0.08695652173913043, 0.35454545454545455, 0.79, 1.0, 1.0, 0.047595822447783244, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09574007919183711, 0.09574007919183701, 0.1952736302576662], 
reward next is 0.8047, 
noisyNet noise sample is [array([-1.8402082], dtype=float32), -0.5709209]. 
=============================================
[2019-03-23 16:23:26,405] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[70.66823 ]
 [70.881165]
 [70.937454]
 [71.29267 ]
 [71.40135 ]], R is [[70.42438507]
 [70.51948547]
 [70.60777283]
 [70.70024109]
 [70.78952789]].
[2019-03-23 16:23:32,633] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143000, global step 2284653: loss 0.6637
[2019-03-23 16:23:32,635] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143000, global step 2284653: learning rate 0.0000
[2019-03-23 16:23:35,089] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143000, global step 2285954: loss 0.5985
[2019-03-23 16:23:35,091] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143000, global step 2285955: learning rate 0.0000
[2019-03-23 16:23:38,657] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143000, global step 2287791: loss 0.8017
[2019-03-23 16:23:38,659] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143000, global step 2287792: learning rate 0.0000
[2019-03-23 16:23:38,721] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143000, global step 2287835: loss 0.9296
[2019-03-23 16:23:38,722] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143000, global step 2287835: learning rate 0.0000
[2019-03-23 16:23:39,012] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143000, global step 2287989: loss 0.0075
[2019-03-23 16:23:39,018] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143000, global step 2287990: learning rate 0.0000
[2019-03-23 16:23:39,142] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143000, global step 2288057: loss 0.2050
[2019-03-23 16:23:39,144] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143000, global step 2288057: learning rate 0.0000
[2019-03-23 16:23:39,213] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143000, global step 2288094: loss 0.4779
[2019-03-23 16:23:39,216] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143000, global step 2288094: learning rate 0.0000
[2019-03-23 16:23:39,245] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143000, global step 2288109: loss 0.6249
[2019-03-23 16:23:39,246] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143000, global step 2288109: learning rate 0.0000
[2019-03-23 16:23:39,367] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143000, global step 2288173: loss 0.8060
[2019-03-23 16:23:39,370] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143000, global step 2288173: learning rate 0.0000
[2019-03-23 16:23:39,594] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143000, global step 2288289: loss 0.4726
[2019-03-23 16:23:39,597] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143000, global step 2288291: learning rate 0.0000
[2019-03-23 16:23:39,985] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143000, global step 2288498: loss 0.6515
[2019-03-23 16:23:39,989] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143000, global step 2288498: learning rate 0.0000
[2019-03-23 16:23:40,270] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143000, global step 2288646: loss 0.2031
[2019-03-23 16:23:40,272] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143000, global step 2288647: learning rate 0.0000
[2019-03-23 16:23:40,623] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143000, global step 2288830: loss 0.1088
[2019-03-23 16:23:40,628] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143000, global step 2288830: learning rate 0.0000
[2019-03-23 16:23:40,693] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143000, global step 2288863: loss 0.0143
[2019-03-23 16:23:40,696] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143000, global step 2288864: learning rate 0.0000
[2019-03-23 16:23:40,928] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143000, global step 2288990: loss 0.1366
[2019-03-23 16:23:40,931] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143000, global step 2288990: learning rate 0.0000
[2019-03-23 16:23:41,079] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143000, global step 2289067: loss 0.0840
[2019-03-23 16:23:41,080] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143000, global step 2289067: learning rate 0.0000
[2019-03-23 16:23:47,911] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143500, global step 2292661: loss 0.0849
[2019-03-23 16:23:47,913] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143500, global step 2292661: learning rate 0.0000
[2019-03-23 16:23:50,405] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143500, global step 2293986: loss 0.1853
[2019-03-23 16:23:50,407] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143500, global step 2293986: learning rate 0.0000
[2019-03-23 16:23:53,726] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143500, global step 2295745: loss 0.0580
[2019-03-23 16:23:53,727] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143500, global step 2295745: learning rate 0.0000
[2019-03-23 16:23:54,149] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143500, global step 2295966: loss 0.1640
[2019-03-23 16:23:54,152] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143500, global step 2295967: learning rate 0.0000
[2019-03-23 16:23:54,171] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143500, global step 2295978: loss 0.1886
[2019-03-23 16:23:54,174] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143500, global step 2295978: learning rate 0.0000
[2019-03-23 16:23:54,191] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143500, global step 2295990: loss 0.2099
[2019-03-23 16:23:54,192] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143500, global step 2295990: learning rate 0.0000
[2019-03-23 16:23:54,211] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143500, global step 2296000: loss 0.2489
[2019-03-23 16:23:54,212] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143500, global step 2296000: learning rate 0.0000
[2019-03-23 16:23:54,540] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143500, global step 2296171: loss 0.2105
[2019-03-23 16:23:54,544] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143500, global step 2296173: learning rate 0.0000
[2019-03-23 16:23:54,597] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143500, global step 2296203: loss 0.2969
[2019-03-23 16:23:54,601] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143500, global step 2296204: learning rate 0.0000
[2019-03-23 16:23:54,836] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143500, global step 2296324: loss 0.0980
[2019-03-23 16:23:54,838] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143500, global step 2296325: learning rate 0.0000
[2019-03-23 16:23:54,995] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143500, global step 2296410: loss 0.1312
[2019-03-23 16:23:55,001] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143500, global step 2296411: learning rate 0.0000
[2019-03-23 16:23:55,286] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143500, global step 2296568: loss 0.2226
[2019-03-23 16:23:55,288] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143500, global step 2296568: learning rate 0.0000
[2019-03-23 16:23:55,548] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3883323e-07 9.9999988e-01 9.5039795e-19 4.2294843e-10 6.4564383e-15], sum to 1.0000
[2019-03-23 16:23:55,556] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8160
[2019-03-23 16:23:55,561] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 81.0, 1.0, 2.0, 0.3673114803274615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 411155.3742943989, 411155.3742943992, 120597.2077071324], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6638400.0000, 
sim time next is 6639000.0000, 
raw observation next is [19.9, 81.0, 1.0, 2.0, 0.3673851417130771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 410847.3826031398, 410847.3826031398, 120424.5747916892], 
processed observation next is [1.0, 0.8695652173913043, 0.5409090909090909, 0.81, 1.0, 1.0, 0.20923142714134638, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15216569726042214, 0.15216569726042214, 0.293718475101681], 
reward next is 0.7063, 
noisyNet noise sample is [array([0.013141], dtype=float32), -1.6107918]. 
=============================================
[2019-03-23 16:23:55,573] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[65.03195]
 [64.9205 ]
 [64.9209 ]
 [64.94904]
 [64.97469]], R is [[65.1157074 ]
 [65.17041779]
 [65.22465515]
 [65.27841949]
 [65.331604  ]].
[2019-03-23 16:23:55,754] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143500, global step 2296813: loss 0.5743
[2019-03-23 16:23:55,756] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143500, global step 2296814: learning rate 0.0000
[2019-03-23 16:23:55,922] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143500, global step 2296904: loss 0.5071
[2019-03-23 16:23:55,923] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143500, global step 2296904: learning rate 0.0000
[2019-03-23 16:23:56,112] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143500, global step 2297007: loss 0.5068
[2019-03-23 16:23:56,115] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143500, global step 2297007: learning rate 0.0000
[2019-03-23 16:23:56,375] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143500, global step 2297153: loss 0.3586
[2019-03-23 16:23:56,377] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143500, global step 2297153: learning rate 0.0000
[2019-03-23 16:23:59,770] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.4556192e-06 9.9999857e-01 1.0517966e-18 1.5408887e-09 3.9568709e-13], sum to 1.0000
[2019-03-23 16:23:59,778] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8568
[2019-03-23 16:23:59,783] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 84.0, 1.0, 2.0, 0.4832333009910278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 540210.0958335458, 540210.0958335458, 130795.8864295273], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6687000.0000, 
sim time next is 6687600.0000, 
raw observation next is [19.2, 85.0, 1.0, 2.0, 0.5633957309684106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 629379.4630743278, 629379.4630743274, 138826.7500405345], 
processed observation next is [1.0, 0.391304347826087, 0.509090909090909, 0.85, 1.0, 1.0, 0.45424466371051314, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23310350484234363, 0.2331035048423435, 0.3386018293671573], 
reward next is 0.6614, 
noisyNet noise sample is [array([0.83065397], dtype=float32), 0.7700586]. 
=============================================
[2019-03-23 16:24:01,859] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 16:24:01,861] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:24:01,862] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:24:01,863] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:24:01,863] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:24:01,864] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:24:01,864] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:24:01,866] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:24:01,864] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:24:01,869] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:24:01,870] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:24:01,890] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run93
[2019-03-23 16:24:01,925] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run93
[2019-03-23 16:24:01,957] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run93
[2019-03-23 16:24:01,957] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run93
[2019-03-23 16:24:02,019] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run93
[2019-03-23 16:24:30,374] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.04962119], dtype=float32), 0.38587266]
[2019-03-23 16:24:30,375] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.7, 48.0, 1.0, 2.0, 0.3698940457342725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 414997.1108229284, 414997.1108229284, 125584.4232300678]
[2019-03-23 16:24:30,377] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:24:30,379] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.1421118e-07 9.9999976e-01 1.5738603e-18 7.8578599e-10 2.7437649e-14], sampled 0.5343352558770983
[2019-03-23 16:25:21,529] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.04962119], dtype=float32), 0.38587266]
[2019-03-23 16:25:21,531] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.42727098666667, 64.40816386333333, 1.0, 2.0, 0.2935649123226176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 58.14075979994296, 318800.3269354503, 318800.3269354501, 80394.10183795475]
[2019-03-23 16:25:21,535] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:25:21,537] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.2431676e-07 9.9999976e-01 1.7757396e-18 8.3628138e-10 3.0110463e-14], sampled 0.9869653140186061
[2019-03-23 16:25:39,003] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04962119], dtype=float32), 0.38587266]
[2019-03-23 16:25:39,005] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.1, 56.33333333333333, 1.0, 2.0, 0.4034756716760187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 448314.4645447732, 448314.4645447729, 122289.6108068574]
[2019-03-23 16:25:39,005] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:25:39,008] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.8699397e-07 9.9999964e-01 7.3106223e-18 1.7260874e-09 8.9059707e-14], sampled 0.9734625423457105
[2019-03-23 16:25:48,380] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 16:25:48,755] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 16:25:48,795] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 16:25:48,805] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 16:25:48,869] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 16:25:49,884] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 2300000, evaluation results [2300000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 16:25:50,556] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.6670948e-06 9.9999535e-01 6.3701411e-17 4.6433385e-08 1.2722223e-12], sum to 1.0000
[2019-03-23 16:25:50,566] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8309
[2019-03-23 16:25:50,571] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.98333333333333, 74.33333333333334, 1.0, 2.0, 0.9293791968609662, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1059180.181370347, 1059180.181370347, 199431.6296474564], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6783000.0000, 
sim time next is 6783600.0000, 
raw observation next is [23.26666666666667, 72.66666666666667, 1.0, 2.0, 0.7284323009419592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 830019.3567735439, 830019.3567735439, 167814.8154139588], 
processed observation next is [1.0, 0.5217391304347826, 0.6939393939393941, 0.7266666666666667, 1.0, 1.0, 0.6605403761774489, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.30741457658279403, 0.30741457658279403, 0.4093044278389239], 
reward next is 0.5907, 
noisyNet noise sample is [array([0.34485197], dtype=float32), 0.72086656]. 
=============================================
[2019-03-23 16:25:51,160] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144000, global step 2300666: loss 0.1003
[2019-03-23 16:25:51,163] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144000, global step 2300669: learning rate 0.0000
[2019-03-23 16:25:53,759] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144000, global step 2302032: loss 0.0012
[2019-03-23 16:25:53,760] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144000, global step 2302032: learning rate 0.0000
[2019-03-23 16:25:56,252] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.3230949e-06 9.9999666e-01 5.1224803e-19 4.9393317e-10 4.8956824e-13], sum to 1.0000
[2019-03-23 16:25:56,261] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4061
[2019-03-23 16:25:56,266] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.1, 67.5, 1.0, 2.0, 0.4349652899279504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 495211.5257905112, 495211.5257905112, 131551.4571799383], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6899400.0000, 
sim time next is 6900000.0000, 
raw observation next is [24.0, 68.0, 1.0, 2.0, 0.4341845711559714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 494286.171616079, 494286.171616079, 131433.960010849], 
processed observation next is [0.0, 0.8695652173913043, 0.7272727272727273, 0.68, 1.0, 1.0, 0.29273071394496425, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18306895245039964, 0.18306895245039964, 0.32057063417280246], 
reward next is 0.6794, 
noisyNet noise sample is [array([0.7414905], dtype=float32), 0.72595817]. 
=============================================
[2019-03-23 16:25:56,281] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[72.046906]
 [72.06638 ]
 [72.06571 ]
 [72.08239 ]
 [72.08046 ]], R is [[72.00444031]
 [71.96353912]
 [71.92273712]
 [71.88197327]
 [71.84104919]].
[2019-03-23 16:25:56,951] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144000, global step 2303697: loss 0.2435
[2019-03-23 16:25:56,952] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144000, global step 2303697: learning rate 0.0000
[2019-03-23 16:25:57,326] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144000, global step 2303896: loss 0.1105
[2019-03-23 16:25:57,328] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144000, global step 2303896: learning rate 0.0000
[2019-03-23 16:25:57,426] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144000, global step 2303946: loss 0.0431
[2019-03-23 16:25:57,431] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144000, global step 2303948: learning rate 0.0000
[2019-03-23 16:25:57,437] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144000, global step 2303952: loss 0.0138
[2019-03-23 16:25:57,438] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144000, global step 2303952: learning rate 0.0000
[2019-03-23 16:25:57,537] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144000, global step 2304007: loss 0.0643
[2019-03-23 16:25:57,537] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144000, global step 2304007: learning rate 0.0000
[2019-03-23 16:25:57,839] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144000, global step 2304168: loss 0.0157
[2019-03-23 16:25:57,841] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144000, global step 2304168: learning rate 0.0000
[2019-03-23 16:25:57,939] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144000, global step 2304216: loss 0.0020
[2019-03-23 16:25:57,942] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144000, global step 2304216: learning rate 0.0000
[2019-03-23 16:25:58,024] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144000, global step 2304257: loss 0.0188
[2019-03-23 16:25:58,026] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144000, global step 2304257: learning rate 0.0000
[2019-03-23 16:25:58,107] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144000, global step 2304303: loss 0.0059
[2019-03-23 16:25:58,108] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144000, global step 2304303: learning rate 0.0000
[2019-03-23 16:25:58,545] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144000, global step 2304536: loss 0.0169
[2019-03-23 16:25:58,551] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144000, global step 2304539: learning rate 0.0000
[2019-03-23 16:25:59,334] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144000, global step 2304954: loss 0.0074
[2019-03-23 16:25:59,336] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144000, global step 2304954: loss 0.0122
[2019-03-23 16:25:59,338] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144000, global step 2304954: learning rate 0.0000
[2019-03-23 16:25:59,340] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144000, global step 2304955: learning rate 0.0000
[2019-03-23 16:25:59,514] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144000, global step 2305046: loss 0.0164
[2019-03-23 16:25:59,517] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144000, global step 2305046: learning rate 0.0000
[2019-03-23 16:25:59,642] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144000, global step 2305115: loss 0.0531
[2019-03-23 16:25:59,644] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144000, global step 2305115: learning rate 0.0000
[2019-03-23 16:26:00,599] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.3688514e-09 1.0000000e+00 1.7119520e-18 8.0063782e-11 1.2706597e-15], sum to 1.0000
[2019-03-23 16:26:00,606] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6266
[2019-03-23 16:26:00,610] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.61666666666667, 60.83333333333334, 1.0, 2.0, 0.5204867728575017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592526.759998291, 592526.759998291, 145620.2429240337], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6973800.0000, 
sim time next is 6974400.0000, 
raw observation next is [27.53333333333333, 60.66666666666667, 1.0, 2.0, 0.5180455309189422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 589992.7771017144, 589992.7771017144, 145130.3223776071], 
processed observation next is [0.0, 0.7391304347826086, 0.8878787878787878, 0.6066666666666667, 1.0, 1.0, 0.39755691364867773, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21851584337100532, 0.21851584337100532, 0.3539763960429442], 
reward next is 0.6460, 
noisyNet noise sample is [array([1.232055], dtype=float32), -0.90948945]. 
=============================================
[2019-03-23 16:26:02,214] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.6276793e-07 9.9999964e-01 1.5404090e-16 1.0686683e-08 1.0445891e-13], sum to 1.0000
[2019-03-23 16:26:02,229] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0664
[2019-03-23 16:26:02,236] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.53333333333333, 62.0, 1.0, 2.0, 0.6398921002079119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 716107.2520122001, 716107.2520121998, 147929.8397574456], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7126800.0000, 
sim time next is 7127400.0000, 
raw observation next is [22.61666666666667, 60.5, 1.0, 2.0, 0.6499444272348781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 726045.340052144, 726045.340052144, 148570.360680264], 
processed observation next is [1.0, 0.4782608695652174, 0.6643939393939395, 0.605, 1.0, 1.0, 0.5624305340435976, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2689056815007941, 0.2689056815007941, 0.3623667333664976], 
reward next is 0.6376, 
noisyNet noise sample is [array([-0.3111705], dtype=float32), -0.21267492]. 
=============================================
[2019-03-23 16:26:06,554] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144500, global step 2308765: loss 0.0148
[2019-03-23 16:26:06,555] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144500, global step 2308766: learning rate 0.0000
[2019-03-23 16:26:08,860] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144500, global step 2309998: loss 0.0192
[2019-03-23 16:26:08,863] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144500, global step 2309999: learning rate 0.0000
[2019-03-23 16:26:09,950] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.0855007e-09 1.0000000e+00 2.1681177e-18 8.9675732e-11 1.3432110e-15], sum to 1.0000
[2019-03-23 16:26:09,958] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0753
[2019-03-23 16:26:09,961] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.46666666666667, 63.0, 1.0, 2.0, 0.2569896857635383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 279039.4396215774, 279039.4396215771, 84900.86334952968], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7159200.0000, 
sim time next is 7159800.0000, 
raw observation next is [18.38333333333333, 63.0, 1.0, 2.0, 0.2558842947702094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 277838.8630821632, 277838.8630821629, 84318.55438317468], 
processed observation next is [1.0, 0.8695652173913043, 0.47196969696969676, 0.63, 1.0, 1.0, 0.06985536846276175, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10290328262302341, 0.1029032826230233, 0.20565501069066994], 
reward next is 0.7943, 
noisyNet noise sample is [array([1.185669], dtype=float32), -0.7470978]. 
=============================================
[2019-03-23 16:26:11,866] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144500, global step 2311592: loss 1.9787
[2019-03-23 16:26:11,868] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144500, global step 2311592: learning rate 0.0000
[2019-03-23 16:26:12,457] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144500, global step 2311903: loss 1.6499
[2019-03-23 16:26:12,460] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144500, global step 2311903: learning rate 0.0000
[2019-03-23 16:26:12,559] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144500, global step 2311957: loss 0.7527
[2019-03-23 16:26:12,560] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144500, global step 2311957: learning rate 0.0000
[2019-03-23 16:26:12,618] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144500, global step 2311986: loss 0.5693
[2019-03-23 16:26:12,621] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144500, global step 2311986: learning rate 0.0000
[2019-03-23 16:26:12,730] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144500, global step 2312046: loss 0.3207
[2019-03-23 16:26:12,731] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144500, global step 2312046: learning rate 0.0000
[2019-03-23 16:26:13,098] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144500, global step 2312238: loss 0.0211
[2019-03-23 16:26:13,099] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144500, global step 2312238: loss 0.0016
[2019-03-23 16:26:13,101] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144500, global step 2312238: learning rate 0.0000
[2019-03-23 16:26:13,102] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144500, global step 2312238: learning rate 0.0000
[2019-03-23 16:26:13,158] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144500, global step 2312275: loss 0.0127
[2019-03-23 16:26:13,160] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144500, global step 2312275: learning rate 0.0000
[2019-03-23 16:26:13,185] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144500, global step 2312285: loss 0.0065
[2019-03-23 16:26:13,186] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144500, global step 2312287: learning rate 0.0000
[2019-03-23 16:26:13,629] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144500, global step 2312520: loss 0.0853
[2019-03-23 16:26:13,632] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144500, global step 2312520: learning rate 0.0000
[2019-03-23 16:26:13,673] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.9622601e-05 9.9991965e-01 8.4723527e-11 6.5891646e-07 1.7378621e-08], sum to 1.0000
[2019-03-23 16:26:13,687] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3587
[2019-03-23 16:26:13,692] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.38333333333333, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 198747.9993375249, 198747.9993375252, 66794.83978422373], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7193400.0000, 
sim time next is 7194000.0000, 
raw observation next is [12.56666666666667, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 197529.7321313653, 197529.7321313653, 66742.89856270271], 
processed observation next is [1.0, 0.2608695652173913, 0.20757575757575772, 0.87, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07315916004865382, 0.07315916004865382, 0.16278755747000662], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7903342], dtype=float32), 0.4571041]. 
=============================================
[2019-03-23 16:26:13,705] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[34.788494]
 [34.700485]
 [34.634907]
 [34.675533]
 [34.741325]], R is [[34.48676682]
 [34.14189911]
 [33.80047989]
 [33.46247482]
 [33.12784958]].
[2019-03-23 16:26:14,212] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144500, global step 2312829: loss 0.0012
[2019-03-23 16:26:14,214] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144500, global step 2312829: learning rate 0.0000
[2019-03-23 16:26:14,561] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144500, global step 2313016: loss 0.2257
[2019-03-23 16:26:14,564] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144500, global step 2313016: learning rate 0.0000
[2019-03-23 16:26:14,639] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144500, global step 2313058: loss 0.5099
[2019-03-23 16:26:14,642] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144500, global step 2313059: learning rate 0.0000
[2019-03-23 16:26:14,681] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144500, global step 2313075: loss 0.3781
[2019-03-23 16:26:14,684] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144500, global step 2313076: learning rate 0.0000
[2019-03-23 16:26:21,851] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145000, global step 2316853: loss 0.0232
[2019-03-23 16:26:21,853] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145000, global step 2316854: learning rate 0.0000
[2019-03-23 16:26:21,960] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.2801852e-06 9.9999666e-01 1.7372292e-13 8.7485317e-09 1.3568980e-11], sum to 1.0000
[2019-03-23 16:26:21,976] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1286
[2019-03-23 16:26:21,983] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1422952.871637182 W.
[2019-03-23 16:26:21,986] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.8, 53.0, 1.0, 2.0, 0.6283728884825044, 1.0, 2.0, 0.6283728884825044, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1422952.871637182, 1422952.871637183, 267647.7048459469], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7398000.0000, 
sim time next is 7398600.0000, 
raw observation next is [28.71666666666667, 53.33333333333334, 1.0, 2.0, 0.7456491229278498, 1.0, 2.0, 0.7456491229278498, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 81.83708179275594, 1685954.554056235, 1685954.554056235, 307327.0781928423], 
processed observation next is [1.0, 0.6521739130434783, 0.9416666666666668, 0.5333333333333334, 1.0, 1.0, 0.6820614036598122, 1.0, 1.0, 0.6820614036598122, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5380726384038447, 0.6244276126134203, 0.6244276126134203, 0.7495782394947373], 
reward next is 0.2504, 
noisyNet noise sample is [array([0.8032115], dtype=float32), 0.6068194]. 
=============================================
[2019-03-23 16:26:24,170] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145000, global step 2318072: loss 0.0076
[2019-03-23 16:26:24,172] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145000, global step 2318072: learning rate 0.0000
[2019-03-23 16:26:26,671] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.4970364e-10 1.0000000e+00 1.1724830e-20 6.7541892e-13 2.9556771e-17], sum to 1.0000
[2019-03-23 16:26:26,678] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8545
[2019-03-23 16:26:26,681] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.53333333333333, 70.33333333333334, 1.0, 2.0, 0.4919517229472158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560895.2235718134, 560895.2235718134, 141357.2086811576], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7471200.0000, 
sim time next is 7471800.0000, 
raw observation next is [25.8, 70.0, 1.0, 2.0, 0.5004509926542936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 570253.7390031024, 570253.7390031024, 142738.4634356862], 
processed observation next is [0.0, 0.4782608695652174, 0.8090909090909091, 0.7, 1.0, 1.0, 0.375563740817867, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21120508851966757, 0.21120508851966757, 0.3481425937455761], 
reward next is 0.6519, 
noisyNet noise sample is [array([-2.2599008], dtype=float32), 1.883919]. 
=============================================
[2019-03-23 16:26:26,909] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145000, global step 2319526: loss 0.0266
[2019-03-23 16:26:26,913] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145000, global step 2319528: learning rate 0.0000
[2019-03-23 16:26:27,474] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145000, global step 2319826: loss 0.0012
[2019-03-23 16:26:27,475] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145000, global step 2319826: learning rate 0.0000
[2019-03-23 16:26:27,584] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145000, global step 2319883: loss 0.0101
[2019-03-23 16:26:27,585] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145000, global step 2319883: learning rate 0.0000
[2019-03-23 16:26:27,833] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145000, global step 2320016: loss 0.0070
[2019-03-23 16:26:27,836] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145000, global step 2320017: learning rate 0.0000
[2019-03-23 16:26:28,070] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145000, global step 2320138: loss 0.0002
[2019-03-23 16:26:28,070] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145000, global step 2320138: learning rate 0.0000
[2019-03-23 16:26:28,115] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145000, global step 2320163: loss 0.0002
[2019-03-23 16:26:28,116] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145000, global step 2320163: learning rate 0.0000
[2019-03-23 16:26:28,188] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145000, global step 2320204: loss 0.0448
[2019-03-23 16:26:28,189] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145000, global step 2320204: learning rate 0.0000
[2019-03-23 16:26:28,309] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145000, global step 2320265: loss 0.0709
[2019-03-23 16:26:28,311] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145000, global step 2320265: learning rate 0.0000
[2019-03-23 16:26:28,637] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145000, global step 2320436: loss 0.0001
[2019-03-23 16:26:28,639] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145000, global step 2320436: learning rate 0.0000
[2019-03-23 16:26:28,671] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145000, global step 2320453: loss 0.0016
[2019-03-23 16:26:28,680] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145000, global step 2320453: learning rate 0.0000
[2019-03-23 16:26:29,249] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145000, global step 2320756: loss 0.0072
[2019-03-23 16:26:29,252] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145000, global step 2320756: learning rate 0.0000
[2019-03-23 16:26:29,624] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145000, global step 2320955: loss 0.0003
[2019-03-23 16:26:29,631] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145000, global step 2320955: learning rate 0.0000
[2019-03-23 16:26:29,866] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145000, global step 2321086: loss 0.0095
[2019-03-23 16:26:29,868] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145000, global step 2321086: learning rate 0.0000
[2019-03-23 16:26:29,983] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145000, global step 2321149: loss 0.0736
[2019-03-23 16:26:29,984] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.4025172e-10 1.0000000e+00 9.7068070e-22 1.9744065e-14 6.1244280e-17], sum to 1.0000
[2019-03-23 16:26:29,986] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145000, global step 2321150: learning rate 0.0000
[2019-03-23 16:26:29,990] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0066
[2019-03-23 16:26:30,004] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 80.0, 1.0, 2.0, 0.4677999811071776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 533790.6841288036, 533790.6841288036, 137183.8281795019], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7551000.0000, 
sim time next is 7551600.0000, 
raw observation next is [23.66666666666666, 78.66666666666667, 1.0, 2.0, 0.4745860985188759, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 541528.4935074683, 541528.493507468, 138289.9830981256], 
processed observation next is [0.0, 0.391304347826087, 0.7121212121212118, 0.7866666666666667, 1.0, 1.0, 0.3432326231485948, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20056610870646974, 0.20056610870646963, 0.33729264170274537], 
reward next is 0.6627, 
noisyNet noise sample is [array([1.5790727], dtype=float32), -0.15549351]. 
=============================================
[2019-03-23 16:26:30,536] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.5538091e-09 1.0000000e+00 5.0178164e-23 2.1152725e-15 4.2107931e-18], sum to 1.0000
[2019-03-23 16:26:30,545] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0088
[2019-03-23 16:26:30,550] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.56666666666667, 82.66666666666667, 1.0, 2.0, 0.4558990839251063, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 520034.6652802475, 520034.6652802475, 135149.133369795], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7549800.0000, 
sim time next is 7550400.0000, 
raw observation next is [22.93333333333333, 81.33333333333334, 1.0, 2.0, 0.4614353591743494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 526471.4313356519, 526471.4313356519, 136121.7221354652], 
processed observation next is [0.0, 0.391304347826087, 0.6787878787878786, 0.8133333333333335, 1.0, 1.0, 0.3267941989679367, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1949894190132044, 0.1949894190132044, 0.33200420033040295], 
reward next is 0.6680, 
noisyNet noise sample is [array([1.1967156], dtype=float32), -0.5286351]. 
=============================================
[2019-03-23 16:26:32,913] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.6314253e-08 1.0000000e+00 4.6083245e-19 6.8088350e-14 6.2719163e-16], sum to 1.0000
[2019-03-23 16:26:32,921] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6311
[2019-03-23 16:26:32,927] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 96.0, 1.0, 2.0, 0.4336045556554503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 493234.9068481887, 493234.9068481887, 130988.760805581], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7609200.0000, 
sim time next is 7609800.0000, 
raw observation next is [20.0, 96.0, 1.0, 2.0, 0.4336867820819115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 493328.7764960498, 493328.7764960501, 130997.2806901163], 
processed observation next is [1.0, 0.043478260869565216, 0.5454545454545454, 0.96, 1.0, 1.0, 0.2921084776023894, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1827143616652036, 0.18271436166520374, 0.31950556265882024], 
reward next is 0.6805, 
noisyNet noise sample is [array([-0.72927356], dtype=float32), -0.45348972]. 
=============================================
[2019-03-23 16:26:34,083] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.8196366e-10 1.0000000e+00 3.9378444e-20 2.0185786e-13 5.4992079e-17], sum to 1.0000
[2019-03-23 16:26:34,093] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6407
[2019-03-23 16:26:34,096] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 93.5, 1.0, 2.0, 0.4230213821287263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 480336.8482734638, 480336.8482734638, 129214.9440404725], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7593000.0000, 
sim time next is 7593600.0000, 
raw observation next is [20.0, 94.0, 1.0, 2.0, 0.4260671260385807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 483981.3286240124, 483981.3286240124, 129656.836226231], 
processed observation next is [0.0, 0.9130434782608695, 0.5454545454545454, 0.94, 1.0, 1.0, 0.2825839075482259, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17925234393481942, 0.17925234393481942, 0.3162361859176366], 
reward next is 0.6838, 
noisyNet noise sample is [array([1.2619032], dtype=float32), -2.3556507]. 
=============================================
[2019-03-23 16:26:35,208] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1368011e-06 9.9999881e-01 1.0879717e-15 4.9637822e-11 7.8249072e-13], sum to 1.0000
[2019-03-23 16:26:35,214] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3792
[2019-03-23 16:26:35,221] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1298225.173809735 W.
[2019-03-23 16:26:35,226] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.6, 65.0, 1.0, 2.0, 0.5738036089181134, 1.0, 2.0, 0.5738036089181134, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1298225.173809735, 1298225.173809735, 252785.8716975841], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7646400.0000, 
sim time next is 7647000.0000, 
raw observation next is [26.78333333333333, 63.66666666666667, 1.0, 2.0, 0.5891530828119051, 1.0, 2.0, 0.5891530828119051, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1333605.051557276, 1333605.051557275, 256776.4602036662], 
processed observation next is [1.0, 0.5217391304347826, 0.8537878787878787, 0.6366666666666667, 1.0, 1.0, 0.4864413535148814, 1.0, 1.0, 0.4864413535148814, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.49392779687306515, 0.4939277968730648, 0.6262840492772347], 
reward next is 0.3737, 
noisyNet noise sample is [array([0.87201625], dtype=float32), -0.65991396]. 
=============================================
[2019-03-23 16:26:35,242] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[50.902035]
 [50.47805 ]
 [49.501266]
 [48.919727]
 [47.728817]], R is [[50.67921448]
 [50.55587387]
 [50.33224487]
 [50.11322403]
 [49.92277908]].
[2019-03-23 16:26:36,984] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145500, global step 2324742: loss 1.9779
[2019-03-23 16:26:36,987] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145500, global step 2324742: learning rate 0.0000
[2019-03-23 16:26:37,518] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 16:26:37,519] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:26:37,519] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:26:37,520] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:26:37,520] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:26:37,521] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:26:37,522] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:26:37,523] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:26:37,526] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:26:37,525] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:26:37,526] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:26:37,547] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run94
[2019-03-23 16:26:37,579] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run94
[2019-03-23 16:26:37,611] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run94
[2019-03-23 16:26:37,612] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run94
[2019-03-23 16:26:37,641] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run94
[2019-03-23 16:27:04,628] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04962119], dtype=float32), 0.39045614]
[2019-03-23 16:27:04,629] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.09228886333333, 81.00776327666667, 1.0, 2.0, 0.2833119997316786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 307610.6960287869, 307610.6960287865, 100235.2241884641]
[2019-03-23 16:27:04,630] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:27:04,634] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.67396202e-09 1.00000000e+00 2.64670024e-20 1.07707226e-13
 8.88854934e-17], sampled 0.6668458349873091
[2019-03-23 16:28:23,499] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 16:28:23,816] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 16:28:23,968] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 16:28:24,054] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 16:28:24,199] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 16:28:25,214] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 2325000, evaluation results [2325000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 16:28:27,309] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145500, global step 2326116: loss 2.0173
[2019-03-23 16:28:27,312] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145500, global step 2326117: learning rate 0.0000
[2019-03-23 16:28:29,981] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145500, global step 2327522: loss 0.2138
[2019-03-23 16:28:29,985] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145500, global step 2327524: learning rate 0.0000
[2019-03-23 16:28:30,568] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145500, global step 2327843: loss 0.9522
[2019-03-23 16:28:30,571] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145500, global step 2327843: learning rate 0.0000
[2019-03-23 16:28:30,831] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145500, global step 2327977: loss 0.4358
[2019-03-23 16:28:30,834] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145500, global step 2327979: learning rate 0.0000
[2019-03-23 16:28:30,963] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145500, global step 2328044: loss 0.2791
[2019-03-23 16:28:30,966] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145500, global step 2328045: learning rate 0.0000
[2019-03-23 16:28:31,015] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145500, global step 2328075: loss 0.1447
[2019-03-23 16:28:31,017] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145500, global step 2328075: learning rate 0.0000
[2019-03-23 16:28:31,126] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145500, global step 2328131: loss 0.1903
[2019-03-23 16:28:31,129] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145500, global step 2328133: learning rate 0.0000
[2019-03-23 16:28:31,345] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145500, global step 2328249: loss 0.2330
[2019-03-23 16:28:31,348] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145500, global step 2328249: learning rate 0.0000
[2019-03-23 16:28:31,382] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145500, global step 2328268: loss 0.1802
[2019-03-23 16:28:31,389] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145500, global step 2328269: learning rate 0.0000
[2019-03-23 16:28:31,644] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145500, global step 2328405: loss 0.0331
[2019-03-23 16:28:31,646] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145500, global step 2328406: learning rate 0.0000
[2019-03-23 16:28:31,656] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145500, global step 2328410: loss 0.0239
[2019-03-23 16:28:31,657] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145500, global step 2328410: learning rate 0.0000
[2019-03-23 16:28:32,409] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145500, global step 2328802: loss 0.1080
[2019-03-23 16:28:32,413] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145500, global step 2328803: learning rate 0.0000
[2019-03-23 16:28:32,652] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:28:32,653] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:28:32,672] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145500, global step 2328939: loss 0.0878
[2019-03-23 16:28:32,674] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145500, global step 2328940: learning rate 0.0000
[2019-03-23 16:28:32,703] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run12
[2019-03-23 16:28:32,823] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145500, global step 2328996: loss 0.1522
[2019-03-23 16:28:32,825] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145500, global step 2328996: learning rate 0.0000
[2019-03-23 16:28:33,110] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145500, global step 2329140: loss 0.0266
[2019-03-23 16:28:33,113] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145500, global step 2329142: learning rate 0.0000
[2019-03-23 16:28:34,493] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.7374078e-11 1.0000000e+00 1.1896977e-21 9.0628324e-15 7.4171160e-18], sum to 1.0000
[2019-03-23 16:28:34,499] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6696
[2019-03-23 16:28:34,503] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.31666666666667, 80.5, 1.0, 2.0, 0.3993059899883393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 448076.2500747524, 448076.2500747521, 123837.2153176789], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7891800.0000, 
sim time next is 7892400.0000, 
raw observation next is [20.13333333333333, 83.0, 1.0, 2.0, 0.5497561305635711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 618344.628416449, 618344.6284164487, 139234.1641121624], 
processed observation next is [1.0, 0.34782608695652173, 0.5515151515151513, 0.83, 1.0, 1.0, 0.43719516320446383, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22901652904312925, 0.22901652904312916, 0.33959552222478634], 
reward next is 0.6604, 
noisyNet noise sample is [array([1.8772453], dtype=float32), 0.8747201]. 
=============================================
[2019-03-23 16:28:35,108] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:28:35,109] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:28:35,156] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run12
[2019-03-23 16:28:36,733] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3157403e-10 1.0000000e+00 5.2154206e-21 1.5963634e-14 3.9991149e-17], sum to 1.0000
[2019-03-23 16:28:36,740] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7872
[2019-03-23 16:28:36,748] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.9, 93.5, 1.0, 2.0, 0.6971573207888463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 791991.4431105884, 791991.4431105884, 161233.011724761], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7901400.0000, 
sim time next is 7902000.0000, 
raw observation next is [20.0, 93.0, 1.0, 2.0, 0.6761024193290729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 768244.6200757561, 768244.6200757561, 158556.602098067], 
processed observation next is [1.0, 0.4782608695652174, 0.5454545454545454, 0.93, 1.0, 1.0, 0.595128024161341, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2845350444725023, 0.2845350444725023, 0.3867234197513829], 
reward next is 0.6133, 
noisyNet noise sample is [array([-1.4170609], dtype=float32), -1.2537073]. 
=============================================
[2019-03-23 16:28:36,764] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[64.675224]
 [64.79691 ]
 [64.94018 ]
 [64.98147 ]
 [64.91411 ]], R is [[64.71976471]
 [64.67932129]
 [64.64915466]
 [64.63401794]
 [64.62189484]].
[2019-03-23 16:28:37,564] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:28:37,564] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:28:37,598] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.4888661e-11 1.0000000e+00 1.8454456e-22 5.5051115e-15 2.9047394e-18], sum to 1.0000
[2019-03-23 16:28:37,604] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8318
[2019-03-23 16:28:37,605] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run12
[2019-03-23 16:28:37,653] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 87.0, 1.0, 2.0, 0.8494694005527201, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 969137.5231281946, 969137.5231281946, 187793.5481564701], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7920000.0000, 
sim time next is 7920600.0000, 
raw observation next is [21.51666666666667, 87.5, 1.0, 2.0, 0.8826518130496328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1006955.876459009, 1006955.876459009, 193130.7599561236], 
processed observation next is [1.0, 0.6956521739130435, 0.6143939393939395, 0.875, 1.0, 1.0, 0.8533147663120411, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3729466209107441, 0.3729466209107441, 0.47105063403932584], 
reward next is 0.5289, 
noisyNet noise sample is [array([0.4268127], dtype=float32), 0.46477205]. 
=============================================
[2019-03-23 16:28:38,170] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:28:38,171] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:28:38,203] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run12
[2019-03-23 16:28:38,309] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:28:38,309] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:28:38,316] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run12
[2019-03-23 16:28:38,368] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:28:38,371] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:28:38,383] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run12
[2019-03-23 16:28:38,412] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:28:38,413] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:28:38,418] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run12
[2019-03-23 16:28:38,510] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:28:38,511] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:28:38,514] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run12
[2019-03-23 16:28:38,779] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:28:38,779] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:28:38,784] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run12
[2019-03-23 16:28:38,831] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:28:38,832] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:28:38,839] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run12
[2019-03-23 16:28:38,897] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:28:38,897] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:28:38,901] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run12
[2019-03-23 16:28:38,950] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:28:38,950] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:28:38,979] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run12
[2019-03-23 16:28:39,149] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:28:39,149] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:28:39,152] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run12
[2019-03-23 16:28:39,281] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:28:39,281] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:28:39,284] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run12
[2019-03-23 16:28:39,393] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:28:39,393] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:28:39,396] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run12
[2019-03-23 16:28:39,637] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:28:39,637] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:28:39,640] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run12
[2019-03-23 16:28:40,537] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.1390030e-11 1.0000000e+00 4.1183266e-23 2.1149880e-17 5.0293990e-20], sum to 1.0000
[2019-03-23 16:28:40,543] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3762
[2019-03-23 16:28:40,547] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.36666666666667, 89.0, 1.0, 2.0, 0.3641677532786219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 397633.168108004, 397633.168108004, 116443.2067967597], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 10200.0000, 
sim time next is 10800.0000, 
raw observation next is [17.3, 88.0, 1.0, 2.0, 0.3407109797267428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 370648.2899704065, 370648.2899704062, 114235.9046958977], 
processed observation next is [1.0, 0.13043478260869565, 0.4227272727272728, 0.88, 1.0, 1.0, 0.17588872465842847, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13727714443348388, 0.1372771444334838, 0.27862415779487243], 
reward next is 0.7214, 
noisyNet noise sample is [array([0.761255], dtype=float32), 0.22259921]. 
=============================================
[2019-03-23 16:28:42,717] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2691256e-09 1.0000000e+00 3.3775193e-20 5.2931086e-13 2.4813671e-15], sum to 1.0000
[2019-03-23 16:28:42,722] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0422
[2019-03-23 16:28:42,729] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 81.33333333333334, 1.0, 2.0, 0.8112725979908038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 921555.8633433699, 921555.8633433699, 177445.6787898057], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 37200.0000, 
sim time next is 37800.0000, 
raw observation next is [21.5, 80.5, 1.0, 2.0, 0.8178356370340304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 929307.1627412746, 929307.1627412746, 178664.4527045301], 
processed observation next is [1.0, 0.43478260869565216, 0.6136363636363636, 0.805, 1.0, 1.0, 0.7722945462925379, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3441878380523239, 0.3441878380523239, 0.43576695781592706], 
reward next is 0.5642, 
noisyNet noise sample is [array([-0.00863232], dtype=float32), -0.23526813]. 
=============================================
[2019-03-23 16:28:44,595] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.5892500e-10 1.0000000e+00 1.0418374e-21 8.9998547e-15 2.1536112e-17], sum to 1.0000
[2019-03-23 16:28:44,604] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0914
[2019-03-23 16:28:44,607] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 75.5, 1.0, 2.0, 0.3747845059400603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 418401.3842179609, 418401.3842179609, 120721.8743888377], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 70200.0000, 
sim time next is 70800.0000, 
raw observation next is [20.33333333333333, 76.33333333333334, 1.0, 2.0, 0.372458056382278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 415522.8144128206, 415522.8144128209, 120406.2365531607], 
processed observation next is [1.0, 0.8260869565217391, 0.5606060606060604, 0.7633333333333334, 1.0, 1.0, 0.2155725704778475, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15389733867141506, 0.15389733867141514, 0.29367374769063587], 
reward next is 0.7063, 
noisyNet noise sample is [array([-0.35062677], dtype=float32), 0.87596923]. 
=============================================
[2019-03-23 16:28:47,838] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.1352903e-13 1.0000000e+00 5.3602546e-24 2.5679479e-16 2.3514941e-19], sum to 1.0000
[2019-03-23 16:28:47,847] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6689
[2019-03-23 16:28:47,853] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 82.5, 1.0, 2.0, 0.2129836173142588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 231246.2848854575, 231246.2848854578, 73023.00076805848], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 171000.0000, 
sim time next is 171600.0000, 
raw observation next is [13.66666666666667, 84.33333333333333, 1.0, 2.0, 0.209948081408352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 227949.6891409298, 227949.6891409295, 72438.21641294802], 
processed observation next is [1.0, 1.0, 0.25757575757575774, 0.8433333333333333, 1.0, 1.0, 0.012435101760439986, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08442581079293697, 0.08442581079293685, 0.1766785766169464], 
reward next is 0.8233, 
noisyNet noise sample is [array([-0.21513464], dtype=float32), -0.028450677]. 
=============================================
[2019-03-23 16:28:49,109] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5944208e-08 1.0000000e+00 1.0443020e-18 2.8545699e-12 6.1927785e-14], sum to 1.0000
[2019-03-23 16:28:49,124] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3225
[2019-03-23 16:28:49,143] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.16666666666667, 93.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 207270.8899343811, 207270.8899343811, 70557.948253454], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 184200.0000, 
sim time next is 184800.0000, 
raw observation next is [13.33333333333333, 92.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 208176.3252267966, 208176.3252267966, 70868.44796679058], 
processed observation next is [0.0, 0.13043478260869565, 0.2424242424242423, 0.92, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07710234267659133, 0.07710234267659133, 0.17284987308973312], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.199309], dtype=float32), -1.5146348]. 
=============================================
[2019-03-23 16:28:49,911] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.8855715e-08 9.9999988e-01 7.3782356e-16 1.3373900e-11 3.0851233e-13], sum to 1.0000
[2019-03-23 16:28:49,915] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0238
[2019-03-23 16:28:49,918] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 88.0, 1.0, 2.0, 0.2029177505652241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 220314.8269528325, 220314.8269528325, 73422.8996055748], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 179400.0000, 
sim time next is 180000.0000, 
raw observation next is [14.0, 88.0, 1.0, 2.0, 0.2021783428299338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 219511.845226851, 219511.8452268513, 73345.06017512913], 
processed observation next is [0.0, 0.08695652173913043, 0.2727272727272727, 0.88, 1.0, 1.0, 0.002722928537417235, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08130068341735222, 0.08130068341735233, 0.17889039067104665], 
reward next is 0.8211, 
noisyNet noise sample is [array([0.6873668], dtype=float32), 1.665989]. 
=============================================
[2019-03-23 16:28:49,954] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[48.57065 ]
 [49.146786]
 [49.975307]
 [50.000893]
 [50.464283]], R is [[48.4346199 ]
 [48.77119446]
 [49.10415649]
 [49.43357849]
 [49.75966644]].
[2019-03-23 16:28:57,749] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2059214e-06 9.9999881e-01 7.2197009e-14 6.5120775e-10 1.4815463e-11], sum to 1.0000
[2019-03-23 16:28:57,755] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4999
[2019-03-23 16:28:57,759] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 46.0, 1.0, 2.0, 0.2395404400446718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 260087.980029516, 260087.9800295162, 76565.07653618154], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 328800.0000, 
sim time next is 329400.0000, 
raw observation next is [19.0, 47.5, 1.0, 2.0, 0.2358558868522007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 256086.316325278, 256086.316325278, 76028.26402769148], 
processed observation next is [0.0, 0.8260869565217391, 0.5, 0.475, 1.0, 1.0, 0.04481985856525088, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09484678382417704, 0.09484678382417704, 0.1854347903114426], 
reward next is 0.8146, 
noisyNet noise sample is [array([0.62775177], dtype=float32), -0.27922374]. 
=============================================
[2019-03-23 16:29:04,680] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9797464e-10 1.0000000e+00 1.0104225e-22 6.5182790e-16 1.4007601e-19], sum to 1.0000
[2019-03-23 16:29:04,686] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4455
[2019-03-23 16:29:04,696] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.3681233474996012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 399757.9849311399, 399757.9849311399, 95971.25747050457], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 471600.0000, 
sim time next is 472200.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.3989033388670831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 433197.9416390546, 433197.9416390546, 99172.37076848646], 
processed observation next is [1.0, 0.4782608695652174, 0.2727272727272727, 1.0, 1.0, 1.0, 0.2486291735838539, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16044368208853876, 0.16044368208853876, 0.2418838311426499], 
reward next is 0.7581, 
noisyNet noise sample is [array([-1.214131], dtype=float32), -0.008690587]. 
=============================================
[2019-03-23 16:29:08,417] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.2944387e-07 9.9999976e-01 5.9016948e-19 1.2637784e-11 2.0617180e-14], sum to 1.0000
[2019-03-23 16:29:08,427] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1242
[2019-03-23 16:29:08,435] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 72.33333333333334, 1.0, 2.0, 0.5072438633807063, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 552683.3196189082, 552683.3196189086, 128065.5569140423], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 562200.0000, 
sim time next is 562800.0000, 
raw observation next is [19.66666666666667, 71.66666666666667, 1.0, 2.0, 0.4219672453892512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 461386.3418357777, 461386.3418357777, 121211.7907193146], 
processed observation next is [1.0, 0.5217391304347826, 0.5303030303030305, 0.7166666666666667, 1.0, 1.0, 0.27745905673656396, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1708838303095473, 0.1708838303095473, 0.29563851394954777], 
reward next is 0.7044, 
noisyNet noise sample is [array([0.48461255], dtype=float32), -0.49640465]. 
=============================================
[2019-03-23 16:29:14,413] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 16:29:14,416] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:29:14,417] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:29:14,418] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:29:14,418] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:29:14,418] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:29:14,420] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:29:14,421] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:29:14,422] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:29:14,421] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:29:14,425] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:29:14,442] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run95
[2019-03-23 16:29:14,477] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run95
[2019-03-23 16:29:14,511] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run95
[2019-03-23 16:29:14,543] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run95
[2019-03-23 16:29:14,543] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run95
[2019-03-23 16:29:24,275] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.04859467], dtype=float32), 0.3954411]
[2019-03-23 16:29:24,276] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.3, 69.0, 1.0, 2.0, 0.3855734729634337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 418681.4620788808, 418681.4620788804, 93627.84638908734]
[2019-03-23 16:29:24,277] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:29:24,280] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.4818276e-10 1.0000000e+00 3.5056358e-22 1.3007281e-15 2.7869253e-18], sampled 0.13265439237878862
[2019-03-23 16:30:00,255] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.04859467], dtype=float32), 0.3954411]
[2019-03-23 16:30:00,257] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.37605253, 53.069923915, 1.0, 2.0, 0.3191962208331586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 351933.2434215168, 351933.2434215165, 118746.9233131766]
[2019-03-23 16:30:00,258] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:30:00,260] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.16066504e-10 1.00000000e+00 3.04608446e-23 2.38438636e-16
 3.73927358e-19], sampled 0.27206662989100006
[2019-03-23 16:30:36,886] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.04859467], dtype=float32), 0.3954411]
[2019-03-23 16:30:36,887] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.41666666666667, 56.83333333333334, 1.0, 2.0, 0.3029776407298894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 328968.8352663708, 328968.8352663704, 115697.8225460754]
[2019-03-23 16:30:36,889] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:30:36,892] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.3926520e-10 1.0000000e+00 4.5659862e-23 3.1575215e-16 5.2209200e-19], sampled 0.8865501523345909
[2019-03-23 16:30:59,288] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.04859467], dtype=float32), 0.3954411]
[2019-03-23 16:30:59,289] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.26666666666667, 80.66666666666667, 1.0, 2.0, 0.258717155793007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 280900.1964755903, 280900.1964755903, 90227.99059664721]
[2019-03-23 16:30:59,290] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:30:59,296] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.5005375e-10 1.0000000e+00 5.3857137e-23 3.5402653e-16 5.9827094e-19], sampled 0.8787651014112383
[2019-03-23 16:31:00,484] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 16:31:00,495] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 16:31:00,591] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 16:31:00,639] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 16:31:00,778] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 16:31:01,793] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 2350000, evaluation results [2350000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 16:31:02,133] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.5718353e-10 1.0000000e+00 8.0250923e-22 1.1237556e-15 3.9131255e-18], sum to 1.0000
[2019-03-23 16:31:02,141] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6018
[2019-03-23 16:31:02,150] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 55.5, 1.0, 2.0, 0.3521409941850666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 392303.5166022091, 392303.5166022094, 118511.1596713064], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 678600.0000, 
sim time next is 679200.0000, 
raw observation next is [23.33333333333333, 56.0, 1.0, 2.0, 0.3492236493022419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 388684.3046509746, 388684.3046509749, 118121.1073178294], 
processed observation next is [1.0, 0.8695652173913043, 0.6969696969696968, 0.56, 1.0, 1.0, 0.18652956162780238, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14395714987073133, 0.14395714987073147, 0.28810026175080344], 
reward next is 0.7119, 
noisyNet noise sample is [array([-0.07161409], dtype=float32), 0.0492674]. 
=============================================
[2019-03-23 16:31:03,496] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.9444824e-10 1.0000000e+00 6.8725642e-20 1.4789483e-14 1.7280806e-17], sum to 1.0000
[2019-03-23 16:31:03,504] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4095
[2019-03-23 16:31:03,508] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 76.0, 1.0, 2.0, 0.4592678000644322, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 523458.3130062427, 523458.3130062427, 134741.1586959582], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 855000.0000, 
sim time next is 855600.0000, 
raw observation next is [22.33333333333334, 78.33333333333333, 1.0, 2.0, 0.4475555883804673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 509522.0268138651, 509522.0268138651, 132804.6642834593], 
processed observation next is [0.0, 0.9130434782608695, 0.6515151515151518, 0.7833333333333333, 1.0, 1.0, 0.30944448547558406, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.188711861782913, 0.188711861782913, 0.3239138153255105], 
reward next is 0.6761, 
noisyNet noise sample is [array([-1.3170772], dtype=float32), -0.13390075]. 
=============================================
[2019-03-23 16:31:05,170] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.9930552e-07 9.9999964e-01 1.0986032e-15 1.3462816e-10 4.4443732e-13], sum to 1.0000
[2019-03-23 16:31:05,179] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6440
[2019-03-23 16:31:05,184] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.83333333333334, 55.5, 1.0, 2.0, 0.2478251859140698, 1.0, 2.0, 0.2478251859140698, 1.0, 2.0, 0.5019798877622239, 6.911199999999998, 6.9112, 77.3421103, 843546.8713618198, 843546.8713618204, 243112.5095338949], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 753000.0000, 
sim time next is 753600.0000, 
raw observation next is [27.66666666666667, 56.0, 1.0, 2.0, 0.4833578648069967, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 551175.2768622135, 551175.2768622137, 140240.4016394959], 
processed observation next is [1.0, 0.7391304347826086, 0.8939393939393941, 0.56, 1.0, 1.0, 0.35419733100874584, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20413899143044945, 0.20413899143044953, 0.3420497600963314], 
reward next is 0.6580, 
noisyNet noise sample is [array([-0.35321894], dtype=float32), -1.1626892]. 
=============================================
[2019-03-23 16:31:07,630] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.2790922e-10 1.0000000e+00 1.7476802e-21 2.7887467e-16 3.2863679e-19], sum to 1.0000
[2019-03-23 16:31:07,637] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0384
[2019-03-23 16:31:07,643] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.00000000000001, 1.0, 2.0, 0.387914568297187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 437119.5945355474, 437119.5945355474, 123763.6091410746], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 792600.0000, 
sim time next is 793200.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.387117208161012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 436214.326137478, 436214.326137478, 123689.4906295523], 
processed observation next is [0.0, 0.17391304347826086, 0.5, 0.94, 1.0, 1.0, 0.233896510201265, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16156086153239926, 0.16156086153239926, 0.3016816844623227], 
reward next is 0.6983, 
noisyNet noise sample is [array([0.97699666], dtype=float32), 0.156239]. 
=============================================
[2019-03-23 16:31:08,133] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1878450e-10 1.0000000e+00 6.3880440e-21 7.0092506e-16 5.3900055e-17], sum to 1.0000
[2019-03-23 16:31:08,141] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3605
[2019-03-23 16:31:08,145] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.4232138994983671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 481346.8756731279, 481346.8756731282, 129896.0416569622], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 802800.0000, 
sim time next is 803400.0000, 
raw observation next is [21.16666666666667, 87.16666666666667, 1.0, 2.0, 0.4290252524480803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 488196.3866127747, 488196.3866127747, 130696.4904549169], 
processed observation next is [0.0, 0.30434782608695654, 0.5984848484848487, 0.8716666666666667, 1.0, 1.0, 0.28628156556010037, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1808134765232499, 0.1808134765232499, 0.3187719279388217], 
reward next is 0.6812, 
noisyNet noise sample is [array([-0.9438965], dtype=float32), 0.98928833]. 
=============================================
[2019-03-23 16:31:11,327] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4661439e-10 1.0000000e+00 6.1392358e-24 2.3418196e-17 1.6017333e-19], sum to 1.0000
[2019-03-23 16:31:11,331] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5399
[2019-03-23 16:31:11,340] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666667, 68.33333333333333, 1.0, 2.0, 0.4838777950619151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 552142.1769867184, 552142.1769867184, 139281.6392157865], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 852600.0000, 
sim time next is 853200.0000, 
raw observation next is [25.0, 69.0, 1.0, 2.0, 0.4818126167244566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 549791.3636714054, 549791.3636714054, 138938.2829829869], 
processed observation next is [0.0, 0.9130434782608695, 0.7727272727272727, 0.69, 1.0, 1.0, 0.3522657709055707, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20362643098940938, 0.20362643098940938, 0.33887386093411437], 
reward next is 0.6611, 
noisyNet noise sample is [array([-0.4418459], dtype=float32), -0.97523457]. 
=============================================
[2019-03-23 16:31:15,409] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.9034040e-11 1.0000000e+00 3.9053162e-23 1.1807711e-16 2.0862736e-20], sum to 1.0000
[2019-03-23 16:31:15,418] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6983
[2019-03-23 16:31:15,423] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.4375236906570158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 497789.0445275598, 497789.0445275598, 131471.3767264673], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 930600.0000, 
sim time next is 931200.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.4357469089393176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 495765.5165771325, 495765.5165771325, 131291.0864896584], 
processed observation next is [0.0, 0.782608695652174, 0.5909090909090909, 0.88, 1.0, 1.0, 0.294683636174147, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18361685799153055, 0.18361685799153055, 0.3202221621698985], 
reward next is 0.6798, 
noisyNet noise sample is [array([-0.74439085], dtype=float32), 0.74631083]. 
=============================================
[2019-03-23 16:31:29,384] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6287732e-08 1.0000000e+00 6.0018849e-20 1.0982396e-14 3.9348190e-16], sum to 1.0000
[2019-03-23 16:31:29,389] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9039
[2019-03-23 16:31:29,402] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4091689747754452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 463831.2561950829, 463831.2561950831, 127317.0055032597], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1226400.0000, 
sim time next is 1227000.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4083008504096193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 462845.2027136751, 462845.2027136751, 127233.9200589653], 
processed observation next is [1.0, 0.17391304347826086, 0.5, 1.0, 1.0, 1.0, 0.26037606301202404, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.171424149153213, 0.171424149153213, 0.3103266342901593], 
reward next is 0.6897, 
noisyNet noise sample is [array([-0.03687302], dtype=float32), 1.2555002]. 
=============================================
[2019-03-23 16:31:29,422] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[67.353424]
 [67.445274]
 [67.51872 ]
 [67.623314]
 [67.67938 ]], R is [[67.28765869]
 [67.30425262]
 [67.32048798]
 [67.33624268]
 [67.35040283]].
[2019-03-23 16:31:32,025] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.2328119e-09 1.0000000e+00 4.6672017e-19 2.9734551e-13 6.6557207e-16], sum to 1.0000
[2019-03-23 16:31:32,032] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3023
[2019-03-23 16:31:32,035] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 74.0, 1.0, 2.0, 0.5110697679400865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 582754.2421343029, 582754.2421343025, 143535.5327908216], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1278600.0000, 
sim time next is 1279200.0000, 
raw observation next is [23.33333333333334, 78.0, 1.0, 2.0, 0.4887367356031715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 557695.0702418404, 557695.0702418402, 139524.2168988134], 
processed observation next is [1.0, 0.8260869565217391, 0.6969696969696972, 0.78, 1.0, 1.0, 0.3609209195039643, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20655372971920016, 0.20655372971920008, 0.34030296804588633], 
reward next is 0.6597, 
noisyNet noise sample is [array([0.98050797], dtype=float32), 0.9901992]. 
=============================================
[2019-03-23 16:31:38,094] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.2148687e-09 1.0000000e+00 2.5229942e-21 7.3630008e-15 1.6642579e-17], sum to 1.0000
[2019-03-23 16:31:38,100] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8535
[2019-03-23 16:31:38,109] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 92.0, 1.0, 2.0, 0.4748436090584265, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 541831.9042790551, 541831.9042790551, 137953.6471923252], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1380000.0000, 
sim time next is 1380600.0000, 
raw observation next is [21.5, 94.0, 1.0, 2.0, 0.4784862203119544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 545994.4591197944, 545994.4591197944, 138532.4130460337], 
processed observation next is [1.0, 1.0, 0.6136363636363636, 0.94, 1.0, 1.0, 0.348107775389943, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20222017004436832, 0.20222017004436832, 0.3378839342586188], 
reward next is 0.6621, 
noisyNet noise sample is [array([-0.1415052], dtype=float32), -0.32086927]. 
=============================================
[2019-03-23 16:31:42,640] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3739858e-09 1.0000000e+00 1.4744654e-20 1.1232033e-14 5.5517736e-18], sum to 1.0000
[2019-03-23 16:31:42,649] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7209
[2019-03-23 16:31:42,653] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4799617985158691, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 547607.5761479785, 547607.5761479785, 139191.7528106458], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1477800.0000, 
sim time next is 1478400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4798588345607402, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 547490.0929183116, 547490.0929183112, 139179.9090240864], 
processed observation next is [0.0, 0.08695652173913043, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3498235432009252, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20277410848826355, 0.20277410848826344, 0.33946319274167414], 
reward next is 0.6605, 
noisyNet noise sample is [array([-0.9573445], dtype=float32), 0.73102885]. 
=============================================
[2019-03-23 16:31:44,129] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.4561836e-09 1.0000000e+00 2.5059983e-20 9.2208396e-15 7.3798374e-17], sum to 1.0000
[2019-03-23 16:31:44,136] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2264
[2019-03-23 16:31:44,144] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 88.66666666666666, 1.0, 2.0, 0.5059301573624307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576521.6865230842, 576521.6865230842, 143366.7844683559], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1521600.0000, 
sim time next is 1522200.0000, 
raw observation next is [23.5, 85.83333333333334, 1.0, 2.0, 0.5106651142878842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 581662.1577227198, 581662.1577227198, 144172.4910806895], 
processed observation next is [0.0, 0.6086956521739131, 0.7045454545454546, 0.8583333333333334, 1.0, 1.0, 0.3883313928598552, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21543042878619253, 0.21543042878619253, 0.3516402221480232], 
reward next is 0.6484, 
noisyNet noise sample is [array([0.5242683], dtype=float32), 1.5881541]. 
=============================================
[2019-03-23 16:31:49,687] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 16:31:49,688] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:31:49,689] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:31:49,690] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:31:49,690] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:31:49,690] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:31:49,691] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:31:49,691] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:31:49,692] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:31:49,693] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:31:49,692] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:31:49,715] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run96
[2019-03-23 16:31:49,749] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run96
[2019-03-23 16:31:49,781] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run96
[2019-03-23 16:31:49,808] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run96
[2019-03-23 16:31:49,840] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run96
[2019-03-23 16:31:53,873] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.04859467], dtype=float32), 0.39695024]
[2019-03-23 16:31:53,873] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.14369781, 70.86114963, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 210900.2091881308, 210900.2091881304, 74845.7417723567]
[2019-03-23 16:31:53,875] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:31:53,878] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.4021573e-09 1.0000000e+00 2.2992912e-20 8.9047464e-15 2.2524507e-16], sampled 0.18658580970624594
[2019-03-23 16:31:56,296] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04859467], dtype=float32), 0.39695024]
[2019-03-23 16:31:56,298] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.10571135833333, 45.69771209, 1.0, 2.0, 0.2461760052902583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 267280.7095162165, 267280.7095162165, 77075.71503072661]
[2019-03-23 16:31:56,299] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:31:56,302] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.3254786e-09 1.0000000e+00 1.5040235e-19 3.4209035e-14 1.0135453e-15], sampled 0.09510099349979018
[2019-03-23 16:32:14,864] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04859467], dtype=float32), 0.39695024]
[2019-03-23 16:32:14,866] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.34311511, 35.0775435, 1.0, 2.0, 0.3261689078639421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 354157.0045351253, 354157.0045351249, 84859.22045652255]
[2019-03-23 16:32:14,867] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:32:14,871] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.2621200e-09 1.0000000e+00 6.5031156e-20 1.8760885e-14 5.1793301e-16], sampled 0.8046782753041609
[2019-03-23 16:32:34,761] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.04859467], dtype=float32), 0.39695024]
[2019-03-23 16:32:34,763] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.06666666666667, 63.83333333333334, 1.0, 2.0, 0.3763443168416239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 423672.1463126314, 423672.1463126318, 126855.5020748111]
[2019-03-23 16:32:34,764] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:32:34,768] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.2014534e-09 1.0000000e+00 1.6434613e-20 7.0008099e-15 1.7215610e-16], sampled 0.7330049594510126
[2019-03-23 16:32:37,448] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.04859467], dtype=float32), 0.39695024]
[2019-03-23 16:32:37,449] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.55, 90.0, 1.0, 2.0, 0.3585079270371055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 399608.5895291276, 399608.5895291276, 123431.9753155335]
[2019-03-23 16:32:37,449] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:32:37,452] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.3206550e-09 1.0000000e+00 6.8676632e-20 1.9512924e-14 5.4108565e-16], sampled 0.98179521181345
[2019-03-23 16:33:05,220] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.04859467], dtype=float32), 0.39695024]
[2019-03-23 16:33:05,221] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.9, 52.66666666666667, 1.0, 2.0, 0.4885895593947344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 556555.4995011999, 556555.4995011996, 141851.3606750683]
[2019-03-23 16:33:05,225] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:33:05,234] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.4787687e-09 1.0000000e+00 2.5799413e-20 9.6736465e-15 2.4701177e-16], sampled 0.43786958253713193
[2019-03-23 16:33:22,630] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.04859467], dtype=float32), 0.39695024]
[2019-03-23 16:33:22,631] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.05, 51.5, 1.0, 2.0, 0.4119140370681642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 466540.6838907488, 466540.6838907488, 131641.5120490785]
[2019-03-23 16:33:22,633] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:33:22,640] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.6262139e-10 1.0000000e+00 3.1565501e-21 2.1459703e-15 4.5921845e-17], sampled 0.1496879764310346
[2019-03-23 16:33:22,918] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04859467], dtype=float32), 0.39695024]
[2019-03-23 16:33:22,919] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.37899652, 68.12214594833333, 1.0, 2.0, 0.3672229793286819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 412926.8115149508, 412926.8115149508, 125822.581764277]
[2019-03-23 16:33:22,921] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:33:22,923] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.9013136e-09 1.0000000e+00 4.4552907e-20 1.4307498e-14 3.8259539e-16], sampled 0.16574487983974373
[2019-03-23 16:33:34,880] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 16:33:35,288] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 16:33:35,309] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 16:33:35,479] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 16:33:35,650] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 16:33:36,667] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 2375000, evaluation results [2375000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 16:33:38,144] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.9083619e-12 1.0000000e+00 3.8375334e-22 2.0984489e-17 1.2744241e-19], sum to 1.0000
[2019-03-23 16:33:38,156] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3046
[2019-03-23 16:33:38,171] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 80.5, 1.0, 2.0, 0.4039317547743673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 456727.6973358463, 456727.6973358465, 126075.8245770605], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1632600.0000, 
sim time next is 1633200.0000, 
raw observation next is [21.0, 79.66666666666667, 1.0, 2.0, 0.3996423207886139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 451446.5844576068, 451446.5844576065, 125426.5806685091], 
processed observation next is [1.0, 0.9130434782608695, 0.5909090909090909, 0.7966666666666667, 1.0, 1.0, 0.24955290098576735, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1672024386880025, 0.1672024386880024, 0.305918489435388], 
reward next is 0.6941, 
noisyNet noise sample is [array([-0.5352892], dtype=float32), 0.6396169]. 
=============================================
[2019-03-23 16:33:40,173] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.2310927e-13 1.0000000e+00 2.5312422e-24 6.8141997e-18 1.9588273e-19], sum to 1.0000
[2019-03-23 16:33:40,180] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0318
[2019-03-23 16:33:40,185] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.5540706203521216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 611819.3862337598, 611819.3862337602, 135132.7563958416], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1677600.0000, 
sim time next is 1678200.0000, 
raw observation next is [18.16666666666667, 86.33333333333334, 1.0, 2.0, 0.6805432088006347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 751495.4301850139, 751495.4301850139, 148930.6120408716], 
processed observation next is [1.0, 0.43478260869565216, 0.4621212121212123, 0.8633333333333334, 1.0, 1.0, 0.6006790110007934, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2783316408092644, 0.2783316408092644, 0.36324539522163807], 
reward next is 0.6368, 
noisyNet noise sample is [array([-2.8468091], dtype=float32), -0.92628115]. 
=============================================
[2019-03-23 16:33:40,852] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.0477001e-14 1.0000000e+00 2.8667564e-29 9.7438370e-21 2.2888913e-23], sum to 1.0000
[2019-03-23 16:33:40,857] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9761
[2019-03-23 16:33:40,864] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 49.0, 1.0, 2.0, 0.2534514697517722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 275196.5572193616, 275196.5572193613, 76373.64643826109], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1706400.0000, 
sim time next is 1707000.0000, 
raw observation next is [17.83333333333333, 49.5, 1.0, 2.0, 0.2524665903395181, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 274126.8778571115, 274126.8778571112, 76106.0220190197], 
processed observation next is [1.0, 0.782608695652174, 0.44696969696969674, 0.495, 1.0, 1.0, 0.06558323792439764, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10152847328041167, 0.10152847328041156, 0.18562444394882854], 
reward next is 0.8144, 
noisyNet noise sample is [array([-1.3136767], dtype=float32), 0.19753161]. 
=============================================
[2019-03-23 16:33:40,882] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[88.003395]
 [88.04455 ]
 [88.00129 ]
 [87.956   ]
 [87.95052 ]], R is [[87.84320831]
 [87.77849579]
 [87.71196747]
 [87.64344025]
 [87.57282257]].
[2019-03-23 16:33:47,958] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3259264e-09 1.0000000e+00 1.5606933e-21 3.0914115e-15 4.4504712e-18], sum to 1.0000
[2019-03-23 16:33:47,965] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9535
[2019-03-23 16:33:47,969] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.0, 100.0, 1.0, 2.0, 0.3005860483793121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 326392.2616203327, 326392.2616203327, 78631.4097779441], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1836000.0000, 
sim time next is 1836600.0000, 
raw observation next is [11.5, 97.00000000000001, 1.0, 2.0, 0.4227401783580459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 459096.3089998421, 459096.3089998421, 91167.46833331221], 
processed observation next is [1.0, 0.2608695652173913, 0.1590909090909091, 0.9700000000000002, 1.0, 1.0, 0.27842522294755734, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17003566999994152, 0.17003566999994152, 0.2223596788617371], 
reward next is 0.7776, 
noisyNet noise sample is [array([0.62624264], dtype=float32), -1.3288635]. 
=============================================
[2019-03-23 16:33:50,320] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3219705e-11 1.0000000e+00 5.8063760e-23 3.5639080e-17 2.6389889e-19], sum to 1.0000
[2019-03-23 16:33:50,325] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6444
[2019-03-23 16:33:50,333] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666666, 44.0, 1.0, 2.0, 0.5996183572594376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 651314.9061896611, 651314.9061896611, 136388.6299519212], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1873200.0000, 
sim time next is 1873800.0000, 
raw observation next is [23.5, 44.0, 1.0, 2.0, 0.5936621861136117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 644840.9269720541, 644840.9269720541, 135786.0455443101], 
processed observation next is [1.0, 0.6956521739130435, 0.7045454545454546, 0.44, 1.0, 1.0, 0.49207773264201454, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23882997295261263, 0.23882997295261263, 0.3311854769373417], 
reward next is 0.6688, 
noisyNet noise sample is [array([-0.4559366], dtype=float32), -0.41237214]. 
=============================================
[2019-03-23 16:33:52,648] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0142248e-10 1.0000000e+00 5.7840291e-22 1.0674995e-15 2.5713677e-17], sum to 1.0000
[2019-03-23 16:33:52,654] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6555
[2019-03-23 16:33:52,658] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333334, 87.0, 1.0, 2.0, 0.3211747654772793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 354297.1214537145, 354297.1214537142, 114645.689879502], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1910400.0000, 
sim time next is 1911000.0000, 
raw observation next is [18.16666666666666, 90.5, 1.0, 2.0, 0.3263422665157338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 361429.7216484712, 361429.7216484712, 115593.9044069666], 
processed observation next is [1.0, 0.08695652173913043, 0.4621212121212119, 0.905, 1.0, 1.0, 0.1579278331446672, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13386285986980415, 0.13386285986980415, 0.28193635221211366], 
reward next is 0.7181, 
noisyNet noise sample is [array([-0.9278716], dtype=float32), 1.0986608]. 
=============================================
[2019-03-23 16:33:52,677] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[66.63107 ]
 [66.645195]
 [66.96064 ]
 [67.17747 ]
 [67.4034  ]], R is [[66.3913269 ]
 [66.44779205]
 [66.5052948 ]
 [66.5619812 ]
 [66.61534119]].
[2019-03-23 16:33:56,733] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.56961721e-09 1.00000000e+00 1.18179165e-20 3.19317902e-14
 3.29218082e-17], sum to 1.0000
[2019-03-23 16:33:56,739] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8399
[2019-03-23 16:33:56,743] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.83333333333333, 68.83333333333334, 1.0, 2.0, 0.2814689360573104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 305627.3649913585, 305627.3649913582, 98014.05265916829], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2019000.0000, 
sim time next is 2019600.0000, 
raw observation next is [19.0, 68.0, 1.0, 2.0, 0.2846998381492299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 309136.6898619929, 309136.6898619926, 99028.53620547839], 
processed observation next is [0.0, 0.391304347826087, 0.5, 0.68, 1.0, 1.0, 0.10587479768653735, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11449507031925663, 0.11449507031925651, 0.24153301513531314], 
reward next is 0.7585, 
noisyNet noise sample is [array([-0.55741817], dtype=float32), -2.3250003]. 
=============================================
[2019-03-23 16:33:57,457] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1967145e-09 1.0000000e+00 2.6653326e-20 7.4817192e-15 6.2432443e-17], sum to 1.0000
[2019-03-23 16:33:57,465] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3318
[2019-03-23 16:33:57,469] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.83333333333334, 60.66666666666666, 1.0, 2.0, 0.2624327261698343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 284951.2250776169, 284951.2250776166, 85679.16002694324], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1991400.0000, 
sim time next is 1992000.0000, 
raw observation next is [18.66666666666667, 61.33333333333334, 1.0, 2.0, 0.2619692075169115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 284447.786215755, 284447.786215755, 85252.73308451926], 
processed observation next is [0.0, 0.043478260869565216, 0.4848484848484851, 0.6133333333333334, 1.0, 1.0, 0.07746150939613936, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10535103193176111, 0.10535103193176111, 0.20793349532809577], 
reward next is 0.7921, 
noisyNet noise sample is [array([0.770791], dtype=float32), 0.04756894]. 
=============================================
[2019-03-23 16:33:57,490] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[63.12089 ]
 [63.355167]
 [63.28103 ]
 [63.25045 ]
 [63.26463 ]], R is [[63.5632782 ]
 [63.71867371]
 [63.87147141]
 [64.01941681]
 [64.16140747]].
[2019-03-23 16:34:02,028] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.2575458e-10 1.0000000e+00 4.0954558e-22 8.8463046e-16 9.2768921e-17], sum to 1.0000
[2019-03-23 16:34:02,040] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2387
[2019-03-23 16:34:02,043] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 59.00000000000001, 1.0, 2.0, 0.3069383376348814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 335259.7022322599, 335259.7022322602, 112355.6355628237], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2107200.0000, 
sim time next is 2107800.0000, 
raw observation next is [22.0, 58.5, 1.0, 2.0, 0.3131024703907797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 343434.1211619705, 343434.1211619708, 113309.4873452034], 
processed observation next is [0.0, 0.391304347826087, 0.6363636363636364, 0.585, 1.0, 1.0, 0.14137808798847462, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12719782265258167, 0.12719782265258178, 0.2763646032809839], 
reward next is 0.7236, 
noisyNet noise sample is [array([0.55641556], dtype=float32), 0.7643268]. 
=============================================
[2019-03-23 16:34:05,504] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.5280926e-11 1.0000000e+00 3.3946935e-23 4.4416032e-17 1.2967726e-18], sum to 1.0000
[2019-03-23 16:34:05,518] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7965
[2019-03-23 16:34:05,521] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 77.0, 1.0, 2.0, 0.5116698336630561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 555729.2181998958, 555729.2181998955, 121069.6865658928], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2194800.0000, 
sim time next is 2195400.0000, 
raw observation next is [17.83333333333333, 77.0, 1.0, 2.0, 0.5289027207276912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 574457.0724814228, 574457.0724814228, 124775.5323340388], 
processed observation next is [1.0, 0.391304347826087, 0.44696969696969674, 0.77, 1.0, 1.0, 0.41112840090961394, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21276187869682325, 0.21276187869682325, 0.3043305666683873], 
reward next is 0.6957, 
noisyNet noise sample is [array([-0.88062304], dtype=float32), 0.3507242]. 
=============================================
[2019-03-23 16:34:07,245] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.3924893e-10 1.0000000e+00 2.9466408e-22 4.6302721e-15 8.9887289e-17], sum to 1.0000
[2019-03-23 16:34:07,253] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8537
[2019-03-23 16:34:07,257] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.83333333333334, 78.0, 1.0, 2.0, 0.5967440506794901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 664160.7128461725, 664160.7128461727, 141487.2125223214], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2209800.0000, 
sim time next is 2210400.0000, 
raw observation next is [20.0, 78.0, 1.0, 2.0, 0.6439272173478632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 718417.107822061, 718417.107822061, 147493.5266120589], 
processed observation next is [1.0, 0.6086956521739131, 0.5454545454545454, 0.78, 1.0, 1.0, 0.5549090216848289, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.26608041030446705, 0.26608041030446705, 0.3597403088098997], 
reward next is 0.6403, 
noisyNet noise sample is [array([-0.9814338], dtype=float32), -0.5153757]. 
=============================================
[2019-03-23 16:34:10,531] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.8554223e-10 1.0000000e+00 9.8750671e-21 2.0644522e-15 2.2537560e-17], sum to 1.0000
[2019-03-23 16:34:10,531] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5403
[2019-03-23 16:34:10,548] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 49.0, 1.0, 2.0, 0.4411310161127315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 479078.6202980049, 479078.6202980049, 101344.7930904988], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2374800.0000, 
sim time next is 2375400.0000, 
raw observation next is [20.0, 49.0, 1.0, 2.0, 0.4408879462532246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 478814.510736125, 478814.5107361247, 101304.6262553089], 
processed observation next is [1.0, 0.4782608695652174, 0.5454545454545454, 0.49, 1.0, 1.0, 0.3011099328165307, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1773387076800463, 0.1773387076800462, 0.24708445428124123], 
reward next is 0.7529, 
noisyNet noise sample is [array([0.53011864], dtype=float32), -0.063055925]. 
=============================================
[2019-03-23 16:34:13,470] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.47514549e-12 1.00000000e+00 1.09387784e-23 1.34878641e-16
 1.78465548e-19], sum to 1.0000
[2019-03-23 16:34:13,477] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1264
[2019-03-23 16:34:13,482] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.33333333333333, 88.0, 1.0, 2.0, 0.2168690635178737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 235465.9168661261, 235465.9168661258, 71497.26714209853], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2344800.0000, 
sim time next is 2345400.0000, 
raw observation next is [12.5, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 208400.0013964919, 208400.0013964917, 68787.08101460492], 
processed observation next is [1.0, 0.13043478260869565, 0.20454545454545456, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0771851857024044, 0.07718518570240433, 0.16777336832830467], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0353788], dtype=float32), -1.1421227]. 
=============================================
[2019-03-23 16:34:15,674] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.4252497e-12 1.0000000e+00 7.0722669e-29 3.6169320e-21 1.2256139e-22], sum to 1.0000
[2019-03-23 16:34:15,686] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7382
[2019-03-23 16:34:15,692] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 49.0, 1.0, 2.0, 0.4600270761299203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 499610.7294136912, 499610.7294136915, 103469.0741318445], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2371200.0000, 
sim time next is 2371800.0000, 
raw observation next is [20.0, 49.0, 1.0, 2.0, 0.4570293561638016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 496353.4045015313, 496353.4045015316, 103112.0627637181], 
processed observation next is [1.0, 0.43478260869565216, 0.5454545454545454, 0.49, 1.0, 1.0, 0.32128669520475195, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1838345942598264, 0.18383459425982654, 0.2514928360090685], 
reward next is 0.7485, 
noisyNet noise sample is [array([1.2391651], dtype=float32), -0.4708398]. 
=============================================
[2019-03-23 16:34:16,659] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.5638544e-13 1.0000000e+00 3.4486601e-26 9.6473889e-19 6.2962799e-21], sum to 1.0000
[2019-03-23 16:34:16,669] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0540
[2019-03-23 16:34:16,676] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 49.5, 1.0, 2.0, 0.2970670769777586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 322569.9086915394, 322569.9086915394, 95148.90058355757], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2395800.0000, 
sim time next is 2396400.0000, 
raw observation next is [21.33333333333334, 50.66666666666666, 1.0, 2.0, 0.2960218531902059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 321434.5786803224, 321434.5786803224, 95334.4898168836], 
processed observation next is [1.0, 0.7391304347826086, 0.6060606060606063, 0.5066666666666666, 1.0, 1.0, 0.12002731648775737, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11904984395567496, 0.11904984395567496, 0.23252314589483802], 
reward next is 0.7675, 
noisyNet noise sample is [array([-0.10855403], dtype=float32), 1.1815675]. 
=============================================
[2019-03-23 16:34:17,278] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.1208435e-11 1.0000000e+00 4.5815168e-22 6.6230491e-16 4.5320357e-19], sum to 1.0000
[2019-03-23 16:34:17,288] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3958
[2019-03-23 16:34:17,295] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 61.33333333333333, 1.0, 2.0, 0.2675385274711357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 290496.7943126038, 290496.7943126041, 90187.53716891052], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2407200.0000, 
sim time next is 2407800.0000, 
raw observation next is [19.16666666666667, 62.66666666666667, 1.0, 2.0, 0.2655557266238332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 288343.2052725681, 288343.2052725678, 90243.23833989809], 
processed observation next is [1.0, 0.8695652173913043, 0.5075757575757578, 0.6266666666666667, 1.0, 1.0, 0.08194465827979149, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10679377973058078, 0.10679377973058067, 0.2201054593656051], 
reward next is 0.7799, 
noisyNet noise sample is [array([1.3435131], dtype=float32), 0.1733463]. 
=============================================
[2019-03-23 16:34:25,162] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 16:34:25,164] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:34:25,165] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:34:25,165] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:34:25,167] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:34:25,166] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:34:25,172] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:34:25,173] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:34:25,169] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:34:25,174] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:34:25,180] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:34:25,199] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run97
[2019-03-23 16:34:25,234] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run97
[2019-03-23 16:34:25,265] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run97
[2019-03-23 16:34:25,295] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run97
[2019-03-23 16:34:25,295] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run97
[2019-03-23 16:34:48,611] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.04531563], dtype=float32), 0.40207803]
[2019-03-23 16:34:48,612] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.66666666666667, 48.0, 1.0, 2.0, 0.4190872592443467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 455086.7533321276, 455086.7533321272, 121858.9431706472]
[2019-03-23 16:34:48,614] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:34:48,617] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.4510231e-11 1.0000000e+00 1.5953394e-23 5.5926522e-17 3.4865433e-19], sampled 0.2569540028141456
[2019-03-23 16:35:09,304] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.04531563], dtype=float32), 0.40207803]
[2019-03-23 16:35:09,306] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.81167017333334, 76.11175564333334, 1.0, 2.0, 0.4839503722728804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 550735.5116040481, 550735.5116040477, 140770.3624986785]
[2019-03-23 16:35:09,308] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:35:09,311] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.3122934e-11 1.0000000e+00 4.2611635e-24 2.1788310e-17 1.1907795e-19], sampled 0.6269580603664644
[2019-03-23 16:35:12,831] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.04531563], dtype=float32), 0.40207803]
[2019-03-23 16:35:12,832] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.25, 87.0, 1.0, 2.0, 0.3639939425162309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 407288.5073707174, 407288.5073707171, 124572.6683446816]
[2019-03-23 16:35:12,833] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:35:12,837] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.9786204e-11 1.0000000e+00 1.0144463e-23 4.0472121e-17 2.4129308e-19], sampled 0.21967200830065237
[2019-03-23 16:35:37,628] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.04531563], dtype=float32), 0.40207803]
[2019-03-23 16:35:37,629] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.66862217833334, 97.34748535666667, 1.0, 2.0, 0.4428465680246871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 503515.5093528454, 503515.5093528454, 136057.83567714]
[2019-03-23 16:35:37,631] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:35:37,635] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.1307483e-12 1.0000000e+00 3.7021610e-25 3.8072270e-18 1.6313811e-20], sampled 0.03823970011030009
[2019-03-23 16:35:43,418] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04531563], dtype=float32), 0.40207803]
[2019-03-23 16:35:43,420] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [7.247731966333333, 77.22185326666668, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 115073.380111979, 115073.3801119786, 57678.62674751318]
[2019-03-23 16:35:43,422] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:35:43,425] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.3530536e-11 1.0000000e+00 3.0945372e-23 8.9703688e-17 5.9746584e-19], sampled 0.12566899783580432
[2019-03-23 16:35:59,966] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04531563], dtype=float32), 0.40207803]
[2019-03-23 16:35:59,970] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [28.3, 56.0, 1.0, 2.0, 0.5080079215323373, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 578906.5867699528, 578906.5867699528, 143597.655143547]
[2019-03-23 16:35:59,971] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:35:59,973] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.6589116e-11 1.0000000e+00 1.8961392e-23 6.3267736e-17 4.0113643e-19], sampled 0.8201635193536652
[2019-03-23 16:36:10,489] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 16:36:10,779] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 16:36:10,810] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 16:36:10,819] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 16:36:10,824] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 16:36:11,841] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 2400000, evaluation results [2400000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 16:36:11,992] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.6407205e-12 1.0000000e+00 7.1768916e-24 1.8896453e-18 5.4339297e-20], sum to 1.0000
[2019-03-23 16:36:11,995] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9800
[2019-03-23 16:36:12,001] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333333, 68.33333333333333, 1.0, 2.0, 0.5707135862730605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 619898.0647317538, 619898.0647317538, 133394.121788375], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2547600.0000, 
sim time next is 2548200.0000, 
raw observation next is [19.66666666666667, 66.16666666666667, 1.0, 2.0, 0.5757698450434169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 625393.6088415553, 625393.6088415553, 134004.3960260388], 
processed observation next is [1.0, 0.4782608695652174, 0.5303030303030305, 0.6616666666666667, 1.0, 1.0, 0.4697123063042711, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23162726253390936, 0.23162726253390936, 0.3268399903074117], 
reward next is 0.6732, 
noisyNet noise sample is [array([0.5174142], dtype=float32), 2.118914]. 
=============================================
[2019-03-23 16:36:13,746] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.2337516e-11 1.0000000e+00 7.1395130e-23 3.8607868e-17 1.9049538e-17], sum to 1.0000
[2019-03-23 16:36:13,755] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2300
[2019-03-23 16:36:13,764] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.9, 94.0, 1.0, 2.0, 0.3148060980130679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 343657.9039482377, 343657.9039482374, 112831.2465945915], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2599200.0000, 
sim time next is 2599800.0000, 
raw observation next is [16.81666666666667, 93.00000000000001, 1.0, 2.0, 0.3129092295128519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 340723.7022249435, 340723.7022249432, 112393.5521589766], 
processed observation next is [0.0, 0.08695652173913043, 0.4007575757575759, 0.9300000000000002, 1.0, 1.0, 0.14113653689106484, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1261939637870161, 0.126193963787016, 0.2741306150218941], 
reward next is 0.7259, 
noisyNet noise sample is [array([0.759551], dtype=float32), -0.83023494]. 
=============================================
[2019-03-23 16:36:13,764] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.3869383e-12 1.0000000e+00 2.3360540e-26 1.5421534e-19 4.2493344e-22], sum to 1.0000
[2019-03-23 16:36:13,769] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0352
[2019-03-23 16:36:13,773] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666666, 55.5, 1.0, 2.0, 0.2924630958101348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 317569.0492787193, 317569.0492787193, 103206.317964352], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2573400.0000, 
sim time next is 2574000.0000, 
raw observation next is [21.0, 56.0, 1.0, 2.0, 0.291503829415967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 316527.0974553599, 316527.0974553599, 101869.3695874504], 
processed observation next is [1.0, 0.8260869565217391, 0.5909090909090909, 0.56, 1.0, 1.0, 0.1143797867699587, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11723225831679995, 0.11723225831679995, 0.24846187704256195], 
reward next is 0.7515, 
noisyNet noise sample is [array([-1.6410513], dtype=float32), 0.69920975]. 
=============================================
[2019-03-23 16:36:13,797] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[84.41887 ]
 [84.45058 ]
 [84.45818 ]
 [84.501465]
 [84.48984 ]], R is [[84.35320282]
 [84.25794983]
 [84.1600647 ]
 [84.05921936]
 [83.95539856]].
[2019-03-23 16:36:15,203] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.1278046e-11 1.0000000e+00 5.6406281e-23 4.5427912e-16 1.7069829e-18], sum to 1.0000
[2019-03-23 16:36:15,210] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2367
[2019-03-23 16:36:15,212] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666666, 51.66666666666667, 1.0, 2.0, 0.3619505568460294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 405613.1590257251, 405613.1590257248, 120367.6604969782], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2630400.0000, 
sim time next is 2631000.0000, 
raw observation next is [24.83333333333334, 49.33333333333334, 1.0, 2.0, 0.3540189374712276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 395463.9552171498, 395463.9552171498, 119129.7574876473], 
processed observation next is [0.0, 0.43478260869565216, 0.7651515151515155, 0.4933333333333334, 1.0, 1.0, 0.19252367183903446, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14646813156190733, 0.14646813156190733, 0.29056038411621293], 
reward next is 0.7094, 
noisyNet noise sample is [array([0.14680961], dtype=float32), -0.4550131]. 
=============================================
[2019-03-23 16:36:15,230] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[68.90161 ]
 [68.82088 ]
 [68.75077 ]
 [68.647064]
 [68.60456 ]], R is [[68.99197388]
 [69.00847626]
 [69.02190399]
 [69.03249359]
 [69.04053497]].
[2019-03-23 16:36:16,021] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4386858e-10 1.0000000e+00 1.1030973e-22 2.7570469e-15 1.0056218e-18], sum to 1.0000
[2019-03-23 16:36:16,026] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6446
[2019-03-23 16:36:16,030] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 63.66666666666667, 1.0, 2.0, 0.4520698171639598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 515553.430843838, 515553.4308438377, 134490.9865649538], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2733600.0000, 
sim time next is 2734200.0000, 
raw observation next is [25.5, 63.0, 1.0, 2.0, 0.453147782187876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516829.2896218686, 516829.2896218686, 134701.3770174593], 
processed observation next is [0.0, 0.6521739130434783, 0.7954545454545454, 0.63, 1.0, 1.0, 0.31643472773484493, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1914182554155069, 0.1914182554155069, 0.3285399439450227], 
reward next is 0.6715, 
noisyNet noise sample is [array([-1.3614022], dtype=float32), 0.076851904]. 
=============================================
[2019-03-23 16:36:16,384] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.8095421e-12 1.0000000e+00 3.7834009e-23 7.2691896e-18 2.2106354e-18], sum to 1.0000
[2019-03-23 16:36:16,391] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4692
[2019-03-23 16:36:16,395] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 73.0, 1.0, 2.0, 0.3822483048432085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 431749.2831178434, 431749.2831178437, 123833.5876164804], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2624400.0000, 
sim time next is 2625000.0000, 
raw observation next is [22.33333333333334, 71.0, 1.0, 2.0, 0.3842191887820897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 434165.8187564478, 434165.8187564478, 124120.9165182527], 
processed observation next is [0.0, 0.391304347826087, 0.6515151515151518, 0.71, 1.0, 1.0, 0.23027398597761212, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16080215509498066, 0.16080215509498066, 0.30273394272744564], 
reward next is 0.6973, 
noisyNet noise sample is [array([0.3991601], dtype=float32), -0.38648137]. 
=============================================
[2019-03-23 16:36:16,423] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[70.51813 ]
 [70.510185]
 [70.50735 ]
 [70.495544]
 [70.5218  ]], R is [[70.52071381]
 [70.51347351]
 [70.50752258]
 [70.50285339]
 [70.49947357]].
[2019-03-23 16:36:16,590] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.9611718e-11 1.0000000e+00 6.1299484e-23 6.2714346e-17 7.2840093e-19], sum to 1.0000
[2019-03-23 16:36:16,605] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2308
[2019-03-23 16:36:16,611] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 91.0, 1.0, 2.0, 0.3327124848498984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 368086.1234223282, 368086.1234223282, 115912.3070787413], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2788200.0000, 
sim time next is 2788800.0000, 
raw observation next is [18.0, 92.0, 1.0, 2.0, 0.3363004282628039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 372735.5079221652, 372735.5079221652, 116456.1069791395], 
processed observation next is [1.0, 0.2608695652173913, 0.45454545454545453, 0.92, 1.0, 1.0, 0.17037553532850483, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13805018811932046, 0.13805018811932046, 0.2840392853149744], 
reward next is 0.7160, 
noisyNet noise sample is [array([-0.5241749], dtype=float32), 2.407684]. 
=============================================
[2019-03-23 16:36:18,377] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2096980e-11 1.0000000e+00 1.7077594e-24 1.4188374e-16 3.7340993e-19], sum to 1.0000
[2019-03-23 16:36:18,383] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4925
[2019-03-23 16:36:18,388] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3240954672385231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 356684.2885806834, 356684.2885806834, 114538.0181005221], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2780400.0000, 
sim time next is 2781000.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3223374843994752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 354738.1147683792, 354738.1147683792, 114405.8885702768], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 0.88, 1.0, 1.0, 0.15292185549934395, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13138448695125154, 0.13138448695125154, 0.2790387526104312], 
reward next is 0.7210, 
noisyNet noise sample is [array([-0.6174775], dtype=float32), 1.2529812]. 
=============================================
[2019-03-23 16:36:18,406] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[71.158104]
 [71.10546 ]
 [71.03909 ]
 [71.04368 ]
 [71.034134]], R is [[71.20109558]
 [71.20972443]
 [71.21735382]
 [71.22576141]
 [71.23413086]].
[2019-03-23 16:36:31,413] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.2671189e-08 1.0000000e+00 4.8229307e-18 3.4945279e-14 3.2168760e-16], sum to 1.0000
[2019-03-23 16:36:31,422] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9684
[2019-03-23 16:36:31,427] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 91.0, 1.0, 2.0, 0.3940419402645693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 433069.2221214545, 433069.2221214548, 119710.9644436762], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3033000.0000, 
sim time next is 3033600.0000, 
raw observation next is [17.33333333333333, 92.0, 1.0, 2.0, 0.3740748820799013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 410596.1727665297, 410596.17276653, 117935.0126010674], 
processed observation next is [1.0, 0.08695652173913043, 0.42424242424242403, 0.92, 1.0, 1.0, 0.21759360259987662, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1520726565801962, 0.1520726565801963, 0.2876463721977254], 
reward next is 0.7124, 
noisyNet noise sample is [array([-2.0796537], dtype=float32), 1.2767019]. 
=============================================
[2019-03-23 16:36:35,979] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.0834155e-09 1.0000000e+00 5.4654511e-18 2.0220544e-13 1.4504528e-15], sum to 1.0000
[2019-03-23 16:36:35,987] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6534
[2019-03-23 16:36:35,992] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.83333333333334, 88.00000000000001, 1.0, 2.0, 0.3711361703607176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 414157.995914966, 414157.995914966, 120344.4370805964], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3024600.0000, 
sim time next is 3025200.0000, 
raw observation next is [18.66666666666667, 88.0, 1.0, 2.0, 0.3671620107911553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 408785.9890284555, 408785.9890284555, 119615.8551349524], 
processed observation next is [1.0, 0.0, 0.4848484848484851, 0.88, 1.0, 1.0, 0.20895251348894409, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15140221815868724, 0.15140221815868724, 0.29174598813403024], 
reward next is 0.7083, 
noisyNet noise sample is [array([1.357286], dtype=float32), 0.7349921]. 
=============================================
[2019-03-23 16:36:38,210] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.9905927e-09 1.0000000e+00 5.6053946e-20 9.7729027e-15 6.4597585e-17], sum to 1.0000
[2019-03-23 16:36:38,214] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7725
[2019-03-23 16:36:38,218] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 69.0, 1.0, 2.0, 0.8901323057897862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1013164.216727191, 1013164.216727191, 191457.5465115983], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3065400.0000, 
sim time next is 3066000.0000, 
raw observation next is [23.66666666666667, 69.0, 1.0, 2.0, 0.8949945782352934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1019421.549671739, 1019421.549671739, 192992.1971213865], 
processed observation next is [1.0, 0.4782608695652174, 0.7121212121212124, 0.69, 1.0, 1.0, 0.8687432227941166, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3775635369154589, 0.3775635369154589, 0.4707126759058207], 
reward next is 0.5293, 
noisyNet noise sample is [array([-1.145309], dtype=float32), 2.2862375]. 
=============================================
[2019-03-23 16:36:38,243] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[57.797592]
 [57.562294]
 [57.35031 ]
 [56.832817]
 [56.516098]], R is [[58.01228333]
 [57.96519089]
 [57.38554001]
 [57.25049973]
 [57.18523026]].
[2019-03-23 16:36:40,619] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3077978e-08 1.0000000e+00 7.9735346e-19 4.4862351e-13 3.5579212e-15], sum to 1.0000
[2019-03-23 16:36:40,628] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4358
[2019-03-23 16:36:40,635] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 88.0, 1.0, 2.0, 0.4734443371313326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 540188.749433736, 540188.749433736, 137470.1613169415], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3117000.0000, 
sim time next is 3117600.0000, 
raw observation next is [22.0, 88.0, 1.0, 2.0, 0.4736089051512268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 540376.5952721691, 540376.5952721691, 137488.1765251067], 
processed observation next is [1.0, 0.08695652173913043, 0.6363636363636364, 0.88, 1.0, 1.0, 0.34201113143903344, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.200139479730433, 0.200139479730433, 0.3353370159148944], 
reward next is 0.6647, 
noisyNet noise sample is [array([-0.84854966], dtype=float32), -0.2215406]. 
=============================================
[2019-03-23 16:36:50,667] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.1600642e-13 1.0000000e+00 1.2113042e-27 1.9753055e-19 9.0558834e-23], sum to 1.0000
[2019-03-23 16:36:50,680] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1674
[2019-03-23 16:36:50,683] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 54.0, 1.0, 2.0, 0.3510772094848385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 392091.2457129736, 392091.2457129739, 118854.2074967756], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3329400.0000, 
sim time next is 3330000.0000, 
raw observation next is [24.0, 54.0, 1.0, 2.0, 0.3522861482202406, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 393445.2881940732, 393445.2881940729, 118953.1999146243], 
processed observation next is [0.0, 0.5652173913043478, 0.7272727272727273, 0.54, 1.0, 1.0, 0.19035768527530075, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.145720477108916, 0.1457204771089159, 0.29012975588932755], 
reward next is 0.7099, 
noisyNet noise sample is [array([-1.7638351], dtype=float32), -0.52310055]. 
=============================================
[2019-03-23 16:36:50,700] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[81.46606 ]
 [81.45642 ]
 [81.42722 ]
 [81.42391 ]
 [81.399895]], R is [[81.35440826]
 [81.25097656]
 [81.14878082]
 [81.04769897]
 [80.94774628]].
[2019-03-23 16:36:52,923] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.3486863e-10 1.0000000e+00 2.0755732e-20 8.6501571e-15 2.5830668e-17], sum to 1.0000
[2019-03-23 16:36:52,931] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1978
[2019-03-23 16:36:52,937] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 69.0, 1.0, 2.0, 0.3437222167664315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 381386.1689758741, 381386.1689758744, 117197.1515876336], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3361200.0000, 
sim time next is 3361800.0000, 
raw observation next is [21.0, 69.0, 1.0, 2.0, 0.3435715403672872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 381218.5991523528, 381218.5991523528, 117185.3303734149], 
processed observation next is [0.0, 0.9130434782608695, 0.5909090909090909, 0.69, 1.0, 1.0, 0.17946442545910898, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14119207376013065, 0.14119207376013065, 0.2858178789595485], 
reward next is 0.7142, 
noisyNet noise sample is [array([-0.7139118], dtype=float32), -0.30988812]. 
=============================================
[2019-03-23 16:36:53,643] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.5900951e-08 1.0000000e+00 2.0794347e-18 7.7748510e-14 5.6387338e-16], sum to 1.0000
[2019-03-23 16:36:53,649] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7577
[2019-03-23 16:36:53,657] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3323424098302538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 365803.80494756, 365803.8049475597, 115158.71441485], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3373200.0000, 
sim time next is 3373800.0000, 
raw observation next is [18.0, 88.00000000000001, 1.0, 2.0, 0.3314507676999837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 364818.2690991445, 364818.2690991448, 115091.3969740186], 
processed observation next is [1.0, 0.043478260869565216, 0.45454545454545453, 0.8800000000000001, 1.0, 1.0, 0.16431345962497962, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1351178774441276, 0.1351178774441277, 0.28071072432687466], 
reward next is 0.7193, 
noisyNet noise sample is [array([0.07902695], dtype=float32), 0.7749794]. 
=============================================
[2019-03-23 16:36:57,964] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.5189987e-09 1.0000000e+00 2.7513483e-18 3.1643796e-14 7.5200861e-16], sum to 1.0000
[2019-03-23 16:36:57,971] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4941
[2019-03-23 16:36:57,974] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5813674073940932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 663348.3164351654, 663348.3164351656, 151524.6832141272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3464400.0000, 
sim time next is 3465000.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5369981285213693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 612704.6668176327, 612704.6668176327, 145939.7668351234], 
processed observation next is [1.0, 0.08695652173913043, 0.5909090909090909, 1.0, 1.0, 1.0, 0.4212476606517116, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22692765437690102, 0.22692765437690102, 0.3559506508173741], 
reward next is 0.6440, 
noisyNet noise sample is [array([1.5712355], dtype=float32), 1.1215667]. 
=============================================
[2019-03-23 16:36:57,987] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[56.13226 ]
 [55.92857 ]
 [57.132206]
 [56.91347 ]
 [56.844746]], R is [[56.25825882]
 [56.32610321]
 [56.34997559]
 [56.44382477]
 [56.53615952]].
[2019-03-23 16:36:59,533] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.8353890e-07 9.9999976e-01 2.2627304e-18 2.0605279e-13 4.0544011e-15], sum to 1.0000
[2019-03-23 16:36:59,541] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5452
[2019-03-23 16:36:59,546] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5266837152223558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 600936.6641990814, 600936.6641990814, 144668.5141418968], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3473400.0000, 
sim time next is 3474000.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5445208268329929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 621299.6719502112, 621299.6719502112, 146837.5148683893], 
processed observation next is [1.0, 0.21739130434782608, 0.5909090909090909, 1.0, 1.0, 1.0, 0.430651033541241, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2301109896111893, 0.2301109896111893, 0.35814028016680316], 
reward next is 0.6419, 
noisyNet noise sample is [array([-1.3397527], dtype=float32), -0.06814368]. 
=============================================
[2019-03-23 16:36:59,563] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[53.503307]
 [53.581417]
 [53.64285 ]
 [53.790752]
 [53.961033]], R is [[53.43555832]
 [53.54835129]
 [53.65850067]
 [53.76399231]
 [53.86445618]].
[2019-03-23 16:36:59,946] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 16:36:59,947] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:36:59,947] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:36:59,951] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:36:59,952] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:36:59,953] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:36:59,954] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:36:59,955] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:36:59,954] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:36:59,957] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:36:59,958] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:36:59,979] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run98
[2019-03-23 16:37:00,011] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run98
[2019-03-23 16:37:00,012] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run98
[2019-03-23 16:37:00,086] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run98
[2019-03-23 16:37:00,087] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run98
[2019-03-23 16:37:06,125] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.04531563], dtype=float32), 0.40365016]
[2019-03-23 16:37:06,126] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.76666666666667, 86.0, 1.0, 2.0, 0.3859693276807644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 428318.3650613559, 428318.3650613556, 124920.6911204222]
[2019-03-23 16:37:06,127] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:37:06,131] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.0721947e-10 1.0000000e+00 1.7371593e-20 8.0776058e-16 2.9687284e-17], sampled 0.34236872296707854
[2019-03-23 16:37:23,647] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04531563], dtype=float32), 0.40365016]
[2019-03-23 16:37:23,649] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.97025288666667, 82.66611929000001, 1.0, 2.0, 0.379961511322464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 427092.6139295941, 427092.6139295938, 126833.180538512]
[2019-03-23 16:37:23,652] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:37:23,654] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.5809405e-10 1.0000000e+00 1.9523139e-20 8.8350740e-16 3.2751952e-17], sampled 0.8268887169944341
[2019-03-23 16:37:25,999] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.04531563], dtype=float32), 0.40365016]
[2019-03-23 16:37:26,001] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.78152728666667, 53.28715742, 1.0, 2.0, 0.320444874241555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 347940.0004085507, 347940.0004085503, 114571.0201739265]
[2019-03-23 16:37:26,002] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:37:26,007] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.7477611e-10 1.0000000e+00 4.3369508e-21 2.7918547e-16 9.2454449e-18], sampled 0.3655970482163896
[2019-03-23 16:37:46,405] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.04531563], dtype=float32), 0.40365016]
[2019-03-23 16:37:46,408] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.649133505, 81.622761265, 1.0, 2.0, 0.2144744350943268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 232854.6920862645, 232854.6920862641, 79016.47692448708]
[2019-03-23 16:37:46,408] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:37:46,411] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.7680798e-10 1.0000000e+00 4.3759708e-21 2.8105977e-16 9.3176379e-18], sampled 0.6665109854878634
[2019-03-23 16:37:54,287] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.04531563], dtype=float32), 0.40365016]
[2019-03-23 16:37:54,289] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.63333333333334, 52.33333333333334, 1.0, 2.0, 0.3990196060734906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 451138.4015552818, 451138.4015552818, 129934.2237803353]
[2019-03-23 16:37:54,290] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:37:54,292] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.1833464e-10 1.0000000e+00 1.8405041e-21 1.4483289e-16 4.4975415e-18], sampled 0.7638016428482539
[2019-03-23 16:37:54,850] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.04531563], dtype=float32), 0.40365016]
[2019-03-23 16:37:54,851] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.7, 84.5, 1.0, 2.0, 0.3604574627063186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 403877.8541462976, 403877.854146298, 124537.0084339857]
[2019-03-23 16:37:54,852] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:37:54,855] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.2122079e-10 1.0000000e+00 5.2947633e-21 3.2538522e-16 1.0932846e-17], sampled 0.09166034057460082
[2019-03-23 16:38:10,072] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04531563], dtype=float32), 0.40365016]
[2019-03-23 16:38:10,077] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.53693995, 68.45795301, 1.0, 2.0, 0.4550265783990922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 519114.4103199371, 519114.4103199368, 140629.3126092966]
[2019-03-23 16:38:10,078] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:38:10,080] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.3334855e-10 1.0000000e+00 3.5648661e-21 2.4019417e-16 7.8407921e-18], sampled 0.6459927117392112
[2019-03-23 16:38:12,581] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04531563], dtype=float32), 0.40365016]
[2019-03-23 16:38:12,583] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.66428435333333, 80.47306912333333, 1.0, 2.0, 0.4430704924271442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 505125.8918771634, 505125.8918771634, 137647.1840310348]
[2019-03-23 16:38:12,583] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:38:12,587] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.1951068e-10 1.0000000e+00 1.3974930e-20 6.8390504e-16 2.4738886e-17], sampled 0.844258136815743
[2019-03-23 16:38:27,966] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.04531563], dtype=float32), 0.40365016]
[2019-03-23 16:38:27,966] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.8, 71.0, 1.0, 2.0, 0.465942199383486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 530946.2743230258, 530946.2743230258, 139663.8948642277]
[2019-03-23 16:38:27,967] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:38:27,969] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.0705159e-10 1.0000000e+00 1.3521374e-20 6.6649693e-16 2.4046357e-17], sampled 0.6939761301101015
[2019-03-23 16:38:32,938] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.04531563], dtype=float32), 0.40365016]
[2019-03-23 16:38:32,939] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.50609811333333, 87.69370469, 1.0, 2.0, 0.2774746195858708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 301271.0753117561, 301271.0753117558, 92565.16626590729]
[2019-03-23 16:38:32,941] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:38:32,943] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.4194213e-10 1.0000000e+00 1.0217020e-21 9.2387161e-17 2.7417511e-18], sampled 0.24173022697934277
[2019-03-23 16:38:40,153] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04531563], dtype=float32), 0.40365016]
[2019-03-23 16:38:40,154] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.20662294, 96.86786500166667, 1.0, 2.0, 0.2652189791152584, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 287961.1931029425, 287961.1931029422, 96808.21446521317]
[2019-03-23 16:38:40,154] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:38:40,156] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.6619118e-10 1.0000000e+00 1.2532393e-21 1.0801236e-16 3.2545688e-18], sampled 0.9829037887891037
[2019-03-23 16:38:43,884] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04531563], dtype=float32), 0.40365016]
[2019-03-23 16:38:43,884] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.03543805666667, 85.20542524000001, 1.0, 2.0, 0.2118198685527284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 229972.0803623242, 229972.0803623238, 81344.74092579904]
[2019-03-23 16:38:43,888] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:38:43,890] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.0709560e-10 1.0000000e+00 1.7019998e-21 1.3654666e-16 4.2088984e-18], sampled 0.0008374785886207103
[2019-03-23 16:38:45,002] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 16:38:45,124] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 16:38:45,133] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 16:38:45,162] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 16:38:45,300] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 16:38:46,317] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 2425000, evaluation results [2425000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 16:38:50,903] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1958250e-06 9.9999881e-01 2.5674298e-13 1.0664210e-09 4.0715625e-11], sum to 1.0000
[2019-03-23 16:38:50,909] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4557
[2019-03-23 16:38:50,919] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1218464.915979889 W.
[2019-03-23 16:38:50,925] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.33333333333334, 92.33333333333334, 1.0, 2.0, 0.3581899979077025, 1.0, 1.0, 0.3581899979077025, 1.0, 1.0, 0.7254271673043936, 6.911199999999999, 6.9112, 77.3421103, 1218464.915979889, 1218464.915979889, 284076.7887288206], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3576000.0000, 
sim time next is 3576600.0000, 
raw observation next is [22.5, 91.5, 1.0, 2.0, 0.5308497314828764, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9639132736928409, 6.931985219375589, 6.9112, 77.32841062792649, 1152116.833870595, 1145366.224359353, 264837.2831866144], 
processed observation next is [1.0, 0.391304347826087, 0.6590909090909091, 0.915, 1.0, 1.0, 0.41356216435359544, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9484475338469155, 0.002078521937558886, 0.0, 0.5084284656619732, 0.4267099384705908, 0.4242097127256863, 0.645944593138084], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5634618], dtype=float32), 0.5163822]. 
=============================================
[2019-03-23 16:38:51,734] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.1324549e-07 9.9999964e-01 1.4102625e-16 3.2415324e-11 7.0661969e-14], sum to 1.0000
[2019-03-23 16:38:51,739] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7723
[2019-03-23 16:38:51,743] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5004555154724121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 570998.2757538031, 570998.2757538031, 141556.0918053549], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3562200.0000, 
sim time next is 3562800.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4981047116198293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 568316.5676854661, 568316.5676854661, 141276.6031572278], 
processed observation next is [1.0, 0.21739130434782608, 0.5909090909090909, 1.0, 1.0, 1.0, 0.37263088952478657, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21048761766128377, 0.21048761766128377, 0.3445770808712873], 
reward next is 0.6554, 
noisyNet noise sample is [array([0.7047419], dtype=float32), 1.0744871]. 
=============================================
[2019-03-23 16:38:56,597] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.0704350e-07 9.9999905e-01 6.2398813e-17 1.3498850e-11 6.6871137e-14], sum to 1.0000
[2019-03-23 16:38:56,602] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5574
[2019-03-23 16:38:56,609] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1181741.148788009 W.
[2019-03-23 16:38:56,613] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.5, 68.0, 1.0, 2.0, 0.9986066014457107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.051443273658832, 6.9112, 77.32815719115946, 1181741.148788009, 1136193.182363939, 222202.9295303677], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3675000.0000, 
sim time next is 3675600.0000, 
raw observation next is [27.0, 66.0, 1.0, 2.0, 0.5930644730270856, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9782766055158084, 6.9112, 6.9112, 77.32837917011473, 1221354.819607823, 1221354.819607823, 277538.6631429404], 
processed observation next is [1.0, 0.5652173913043478, 0.8636363636363636, 0.66, 1.0, 1.0, 0.49133059128385703, 0.0, 1.0, -0.25, 1.0, 0.5, 0.9689665793082979, 0.0, 0.0, 0.5084282588292344, 0.45235363689178626, 0.45235363689178626, 0.676923568641318], 
reward next is 0.3231, 
noisyNet noise sample is [array([-0.9503297], dtype=float32), -0.5062752]. 
=============================================
[2019-03-23 16:39:00,330] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.2693350e-07 9.9999988e-01 8.0507647e-20 6.0827598e-14 3.9935216e-16], sum to 1.0000
[2019-03-23 16:39:00,341] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2676
[2019-03-23 16:39:00,346] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 60.33333333333334, 1.0, 2.0, 0.6758664412013049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 752123.0344608927, 752123.0344608929, 150521.7856912242], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3775200.0000, 
sim time next is 3775800.0000, 
raw observation next is [22.16666666666667, 60.16666666666666, 1.0, 2.0, 0.708938831065829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 787275.4530758444, 787275.4530758444, 153907.6719745887], 
processed observation next is [1.0, 0.6956521739130435, 0.6439393939393941, 0.6016666666666666, 1.0, 1.0, 0.6361735388322861, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2915835011392017, 0.2915835011392017, 0.3753845657916798], 
reward next is 0.6246, 
noisyNet noise sample is [array([-0.9766495], dtype=float32), -0.3032697]. 
=============================================
[2019-03-23 16:39:08,889] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.127789e-11 1.000000e+00 2.762834e-25 7.475175e-18 5.911173e-22], sum to 1.0000
[2019-03-23 16:39:08,895] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2020
[2019-03-23 16:39:08,901] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 46.33333333333334, 1.0, 2.0, 0.3376301024170078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 375921.2889882079, 375921.2889882082, 117274.1372078825], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3932400.0000, 
sim time next is 3933000.0000, 
raw observation next is [25.5, 46.0, 1.0, 2.0, 0.3408959810076022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 379988.0322431006, 379988.0322431009, 117715.8476222141], 
processed observation next is [0.0, 0.5217391304347826, 0.7954545454545454, 0.46, 1.0, 1.0, 0.17611997625950274, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1407363082381854, 0.14073630823818553, 0.28711182346881486], 
reward next is 0.7129, 
noisyNet noise sample is [array([1.3203071], dtype=float32), 0.6575322]. 
=============================================
[2019-03-23 16:39:08,921] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[73.84521 ]
 [73.81206 ]
 [73.80416 ]
 [73.79025 ]
 [73.774864]], R is [[73.82492828]
 [73.80064392]
 [73.77761078]
 [73.75579834]
 [73.73530579]].
[2019-03-23 16:39:10,834] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.7051295e-09 1.0000000e+00 3.0510984e-22 1.8466070e-15 2.8777731e-18], sum to 1.0000
[2019-03-23 16:39:10,843] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1311
[2019-03-23 16:39:10,848] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666666, 81.33333333333334, 1.0, 2.0, 0.2775792879763764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 301402.5603330864, 301402.5603330867, 96906.44135644018], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3984000.0000, 
sim time next is 3984600.0000, 
raw observation next is [17.08333333333334, 81.66666666666667, 1.0, 2.0, 0.2725545903101141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 295944.9573969772, 295944.9573969769, 95765.76454255336], 
processed observation next is [1.0, 0.08695652173913043, 0.4128787878787881, 0.8166666666666668, 1.0, 1.0, 0.0906932378876426, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10960924348036191, 0.10960924348036181, 0.23357503546964234], 
reward next is 0.7664, 
noisyNet noise sample is [array([0.25044167], dtype=float32), 0.79742265]. 
=============================================
[2019-03-23 16:39:14,517] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.5807405e-11 1.0000000e+00 1.5519984e-25 5.9529383e-17 7.3969584e-21], sum to 1.0000
[2019-03-23 16:39:14,526] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0486
[2019-03-23 16:39:14,532] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 100.0, 1.0, 2.0, 0.3436308458151943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 380122.7329654808, 380122.7329654811, 116724.198094788], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4042800.0000, 
sim time next is 4043400.0000, 
raw observation next is [17.0, 100.0, 1.0, 2.0, 0.3428877715256138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 379474.0817325331, 379474.0817325333, 116735.5811562786], 
processed observation next is [1.0, 0.8260869565217391, 0.4090909090909091, 1.0, 1.0, 1.0, 0.1786097144070172, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14054595619723448, 0.14054595619723456, 0.28472092964946], 
reward next is 0.7153, 
noisyNet noise sample is [array([1.2816578], dtype=float32), -1.5296004]. 
=============================================
[2019-03-23 16:39:19,586] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.7178279e-11 1.0000000e+00 6.0610461e-25 1.1055054e-17 3.6893131e-20], sum to 1.0000
[2019-03-23 16:39:19,595] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3554
[2019-03-23 16:39:19,598] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3697203145882876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415037.1744666042, 415037.1744666042, 121361.1408152434], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4154400.0000, 
sim time next is 4155000.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3960415362367474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 444636.6653154541, 444636.6653154541, 123656.6770155783], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 1.0, 1.0, 1.0, 0.24505192029593426, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16468024641313117, 0.16468024641313117, 0.30160165125750804], 
reward next is 0.6984, 
noisyNet noise sample is [array([1.0098683], dtype=float32), 1.5438112]. 
=============================================
[2019-03-23 16:39:19,614] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[71.7615  ]
 [71.82841 ]
 [71.845924]
 [72.18412 ]
 [72.18832 ]], R is [[71.98997498]
 [71.97406769]
 [71.95807648]
 [71.94218445]
 [71.92665863]].
[2019-03-23 16:39:19,841] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.0850443e-09 1.0000000e+00 1.8764049e-20 3.9943336e-14 4.1184063e-15], sum to 1.0000
[2019-03-23 16:39:19,850] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4844
[2019-03-23 16:39:19,855] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3700795610525945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 415452.6153433203, 415452.6153433206, 121397.4806174149], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4156200.0000, 
sim time next is 4156800.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3684948876279565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 413660.0463934981, 413660.0463934984, 121256.8717781028], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 1.0, 1.0, 1.0, 0.21061860953494563, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15320742459018447, 0.1532074245901846, 0.29574846775147023], 
reward next is 0.7043, 
noisyNet noise sample is [array([1.1884713], dtype=float32), -0.43995798]. 
=============================================
[2019-03-23 16:39:30,955] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.3035182e-08 1.0000000e+00 2.3922177e-19 4.3354030e-14 5.8980365e-16], sum to 1.0000
[2019-03-23 16:39:30,962] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4176
[2019-03-23 16:39:30,967] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 86.66666666666666, 1.0, 2.0, 0.4463050372864881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 504969.9791474392, 504969.9791474395, 130298.5686258074], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4347600.0000, 
sim time next is 4348200.0000, 
raw observation next is [20.66666666666666, 84.83333333333333, 1.0, 2.0, 0.4791582422655746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 542667.5998849326, 542667.5998849329, 133917.86198535], 
processed observation next is [1.0, 0.30434782608695654, 0.5757575757575755, 0.8483333333333333, 1.0, 1.0, 0.3489478028319682, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20098799995738245, 0.20098799995738253, 0.32662893167158535], 
reward next is 0.6734, 
noisyNet noise sample is [array([0.37535092], dtype=float32), -1.4987526]. 
=============================================
[2019-03-23 16:39:34,300] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 16:39:34,303] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:39:34,304] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:39:34,304] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:39:34,305] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:39:34,305] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:39:34,306] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:39:34,308] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:39:34,309] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:39:34,311] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:39:34,309] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:39:34,328] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run99
[2019-03-23 16:39:34,358] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run99
[2019-03-23 16:39:34,359] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run99
[2019-03-23 16:39:34,422] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run99
[2019-03-23 16:39:34,455] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run99
[2019-03-23 16:39:43,599] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.04531563], dtype=float32), 0.40761542]
[2019-03-23 16:39:43,600] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.55, 51.0, 1.0, 2.0, 0.2743114173531273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 297835.7432226039, 297835.7432226035, 82621.20952504202]
[2019-03-23 16:39:43,601] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:39:43,604] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.6418436e-10 1.0000000e+00 8.2039982e-23 1.1425189e-16 6.5956828e-19], sampled 0.5741930518788624
[2019-03-23 16:40:21,547] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.04531563], dtype=float32), 0.40761542]
[2019-03-23 16:40:21,550] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.85455069333334, 55.02583255666667, 1.0, 2.0, 0.5109705613010931, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 582986.3766145865, 582986.3766145861, 146872.6991484035]
[2019-03-23 16:40:21,552] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:40:21,556] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.4521616e-10 1.0000000e+00 6.2527110e-23 9.3870329e-17 5.2690588e-19], sampled 0.49382877289182947
[2019-03-23 16:40:37,420] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04531563], dtype=float32), 0.40761542]
[2019-03-23 16:40:37,421] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.7, 71.0, 1.0, 2.0, 0.3191552908765643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 348605.4493683941, 348605.4493683944, 113206.0356322741]
[2019-03-23 16:40:37,422] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:40:37,427] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.2849548e-10 1.0000000e+00 4.7660209e-23 7.7142321e-17 4.2100203e-19], sampled 0.8391469821757462
[2019-03-23 16:40:42,829] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.04531563], dtype=float32), 0.40761542]
[2019-03-23 16:40:42,831] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.73333333333334, 90.33333333333334, 1.0, 2.0, 0.2815168934841632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 305661.1340617251, 305661.1340617251, 97019.48671970262]
[2019-03-23 16:40:42,833] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:40:42,835] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.8294329e-11 1.0000000e+00 1.5909759e-23 3.4890614e-17 1.7004893e-19], sampled 0.43296711806676136
[2019-03-23 16:41:03,063] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04531563], dtype=float32), 0.40761542]
[2019-03-23 16:41:03,064] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.3, 87.5, 1.0, 2.0, 0.62467243387988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 692645.9261513278, 692645.9261513278, 143620.8246885082]
[2019-03-23 16:41:03,065] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:41:03,067] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.9214301e-10 1.0000000e+00 1.9876316e-21 1.1457230e-15 9.1906599e-18], sampled 0.736635428151977
[2019-03-23 16:41:03,135] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04531563], dtype=float32), 0.40761542]
[2019-03-23 16:41:03,136] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.69794104, 77.624933285, 1.0, 2.0, 0.2100081620615748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 228004.7439927451, 228004.7439927451, 77603.59586726673]
[2019-03-23 16:41:03,138] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:41:03,142] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.4354405e-10 1.0000000e+00 6.0886292e-23 9.2096159e-17 5.1539763e-19], sampled 0.1023553844906161
[2019-03-23 16:41:15,737] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.04531563], dtype=float32), 0.40761542]
[2019-03-23 16:41:15,738] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.26266903666667, 95.66180236333334, 1.0, 2.0, 0.4544085162141439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 517604.371944939, 517604.371944939, 138191.28426554]
[2019-03-23 16:41:15,740] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:41:15,742] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.2954182e-10 1.0000000e+00 4.8512421e-23 7.8142217e-17 4.2723561e-19], sampled 0.011523307150665407
[2019-03-23 16:41:19,142] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 16:41:19,268] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 16:41:19,428] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 16:41:19,492] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 16:41:19,509] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 16:41:20,525] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 2450000, evaluation results [2450000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 16:41:24,627] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.6833796e-12 1.0000000e+00 4.0685442e-24 2.5876021e-18 1.2267992e-19], sum to 1.0000
[2019-03-23 16:41:24,635] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5744
[2019-03-23 16:41:24,639] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.411214281627138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 466149.7439746224, 466149.7439746224, 127509.9575241226], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4509600.0000, 
sim time next is 4510200.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4113712844941463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 466327.9541286997, 466327.9541286997, 127524.9551303941], 
processed observation next is [0.0, 0.17391304347826086, 0.5, 1.0, 1.0, 1.0, 0.2642141056176828, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1727140570847036, 0.1727140570847036, 0.3110364759277905], 
reward next is 0.6890, 
noisyNet noise sample is [array([-0.2315012], dtype=float32), -0.15555705]. 
=============================================
[2019-03-23 16:41:30,429] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.9931652e-12 1.0000000e+00 9.9570171e-25 2.5969668e-18 3.9865427e-20], sum to 1.0000
[2019-03-23 16:41:30,435] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3382
[2019-03-23 16:41:30,439] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.66666666666667, 92.0, 1.0, 2.0, 0.2303644764066917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 250122.3495729415, 250122.3495729418, 80436.82254288658], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4602000.0000, 
sim time next is 4602600.0000, 
raw observation next is [15.0, 91.0, 1.0, 2.0, 0.2401541357045192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 260754.496511885, 260754.4965118847, 82787.43788148704], 
processed observation next is [1.0, 0.2608695652173913, 0.3181818181818182, 0.91, 1.0, 1.0, 0.050192669630649, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09657573944884629, 0.09657573944884619, 0.2019205801987489], 
reward next is 0.7981, 
noisyNet noise sample is [array([-0.68792444], dtype=float32), -0.50035465]. 
=============================================
[2019-03-23 16:41:32,648] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.7433870e-10 1.0000000e+00 1.2098521e-23 1.5198040e-18 9.0054294e-20], sum to 1.0000
[2019-03-23 16:41:32,655] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7480
[2019-03-23 16:41:32,660] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 50.0, 1.0, 2.0, 0.3180395820348563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 346514.5859246352, 346514.5859246349, 112820.1994482496], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4644000.0000, 
sim time next is 4644600.0000, 
raw observation next is [22.83333333333334, 50.5, 1.0, 2.0, 0.3183980733292153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 346604.7742359259, 346604.7742359262, 112740.5389013591], 
processed observation next is [1.0, 0.782608695652174, 0.6742424242424245, 0.505, 1.0, 1.0, 0.14799759166151913, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1283721386058985, 0.1283721386058986, 0.27497692414965635], 
reward next is 0.7250, 
noisyNet noise sample is [array([0.2539835], dtype=float32), -1.0381371]. 
=============================================
[2019-03-23 16:41:36,124] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.5666176e-11 1.0000000e+00 8.7503847e-23 1.6793788e-17 3.5887321e-20], sum to 1.0000
[2019-03-23 16:41:36,131] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9372
[2019-03-23 16:41:36,138] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 74.66666666666667, 1.0, 2.0, 0.4170836954112053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 473440.8215607484, 473440.8215607487, 128522.818602985], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4738800.0000, 
sim time next is 4739400.0000, 
raw observation next is [22.0, 75.5, 1.0, 2.0, 0.4109997911643531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 465888.201940909, 465888.201940909, 127476.618261315], 
processed observation next is [1.0, 0.8695652173913043, 0.6363636363636364, 0.755, 1.0, 1.0, 0.26374973895544135, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1725511859040404, 0.1725511859040404, 0.3109185811251585], 
reward next is 0.6891, 
noisyNet noise sample is [array([-0.6641045], dtype=float32), -0.16373615]. 
=============================================
[2019-03-23 16:41:37,442] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.1409159e-09 1.0000000e+00 1.2517910e-22 1.7255322e-16 2.5985411e-19], sum to 1.0000
[2019-03-23 16:41:37,450] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8185
[2019-03-23 16:41:37,457] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 94.0, 1.0, 2.0, 0.372120939750711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 416863.1667457073, 416863.166745707, 121149.3287977327], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4764600.0000, 
sim time next is 4765200.0000, 
raw observation next is [18.33333333333334, 96.0, 1.0, 2.0, 0.3710201836070098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415917.7623458111, 415917.7623458111, 121192.3668193623], 
processed observation next is [1.0, 0.13043478260869565, 0.46969696969696995, 0.96, 1.0, 1.0, 0.2137752295087622, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15404361568363376, 0.15404361568363376, 0.2955911385838105], 
reward next is 0.7044, 
noisyNet noise sample is [array([-0.04214217], dtype=float32), -0.03599136]. 
=============================================
[2019-03-23 16:41:39,801] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.0120897e-10 1.0000000e+00 8.1271933e-21 7.0511131e-16 1.0622340e-17], sum to 1.0000
[2019-03-23 16:41:39,810] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7640
[2019-03-23 16:41:39,818] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 99.00000000000001, 1.0, 2.0, 0.4699630836855989, 1.0, 1.0, 0.4699630836855989, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846011422917, 1063195.114594044, 1063195.114594044, 226505.0353352257], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4810200.0000, 
sim time next is 4810800.0000, 
raw observation next is [22.0, 98.0, 1.0, 2.0, 0.8944958114754176, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846342293232, 1017271.134464485, 1017271.134464485, 202837.5230178668], 
processed observation next is [1.0, 0.6956521739130435, 0.6363636363636364, 0.98, 1.0, 1.0, 0.868119764344272, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288127851533, 0.37676708683869814, 0.37676708683869814, 0.4947256658972361], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6478438], dtype=float32), -0.14361054]. 
=============================================
[2019-03-23 16:41:48,514] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.6912697e-13 1.0000000e+00 1.8161597e-25 1.4558831e-18 5.2072277e-22], sum to 1.0000
[2019-03-23 16:41:48,525] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8706
[2019-03-23 16:41:48,530] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 65.33333333333333, 1.0, 2.0, 0.582910721221126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 633154.9867752973, 633154.9867752973, 134712.8767478144], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4981200.0000, 
sim time next is 4981800.0000, 
raw observation next is [20.0, 64.66666666666667, 1.0, 2.0, 0.6154204094008504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 668491.149784483, 668491.149784483, 138002.6495688542], 
processed observation next is [1.0, 0.6521739130434783, 0.5454545454545454, 0.6466666666666667, 1.0, 1.0, 0.519275511751063, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2475893147349937, 0.2475893147349937, 0.3365918282167175], 
reward next is 0.6634, 
noisyNet noise sample is [array([1.0537689], dtype=float32), 0.9593812]. 
=============================================
[2019-03-23 16:41:49,252] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.728468e-13 1.000000e+00 9.238876e-28 7.008217e-21 1.765341e-23], sum to 1.0000
[2019-03-23 16:41:49,260] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7268
[2019-03-23 16:41:49,264] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 82.0, 1.0, 2.0, 0.2799746326454133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 304004.2986441747, 304004.298644175, 96110.02167971885], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5000400.0000, 
sim time next is 5001000.0000, 
raw observation next is [17.16666666666667, 81.16666666666667, 1.0, 2.0, 0.2809147974511244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 305025.4760707429, 305025.4760707432, 97049.106216607], 
processed observation next is [1.0, 0.9130434782608695, 0.4166666666666669, 0.8116666666666668, 1.0, 1.0, 0.1011434968139055, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11297239854471959, 0.11297239854471972, 0.2367051371136756], 
reward next is 0.7633, 
noisyNet noise sample is [array([-1.6774962], dtype=float32), 0.078952]. 
=============================================
[2019-03-23 16:41:49,281] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[76.796684]
 [76.778984]
 [76.78083 ]
 [76.75627 ]
 [76.690186]], R is [[76.76868439]
 [76.7665863 ]
 [76.76461792]
 [76.76303101]
 [76.76220703]].
[2019-03-23 16:42:00,227] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2443151e-09 1.0000000e+00 1.0679234e-22 3.7101517e-16 4.9175106e-18], sum to 1.0000
[2019-03-23 16:42:00,238] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1316
[2019-03-23 16:42:00,245] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 69.5, 1.0, 2.0, 0.5066502083886762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 577098.3270993975, 577098.3270993975, 143681.6758046829], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5160600.0000, 
sim time next is 5161200.0000, 
raw observation next is [26.0, 71.0, 1.0, 2.0, 0.5157445600459453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 586876.135752602, 586876.135752602, 145219.032494161], 
processed observation next is [0.0, 0.7391304347826086, 0.8181818181818182, 0.71, 1.0, 1.0, 0.39468070005743155, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21736153176022296, 0.21736153176022296, 0.35419276218088047], 
reward next is 0.6458, 
noisyNet noise sample is [array([-0.16047078], dtype=float32), -0.038253333]. 
=============================================
[2019-03-23 16:42:04,787] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.5117945e-10 1.0000000e+00 5.3415834e-22 4.6867625e-16 8.1762130e-18], sum to 1.0000
[2019-03-23 16:42:04,798] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7052
[2019-03-23 16:42:04,802] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.9, 87.0, 1.0, 2.0, 0.3574230102779145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 398082.4284094052, 398082.4284094055, 118889.1704585334], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5289000.0000, 
sim time next is 5289600.0000, 
raw observation next is [19.0, 87.0, 1.0, 2.0, 0.3474498041486415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 387482.4787783488, 387482.4787783491, 118315.6109285052], 
processed observation next is [1.0, 0.21739130434782608, 0.5, 0.87, 1.0, 1.0, 0.18431225518580188, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14351202917716624, 0.14351202917716635, 0.2885746608012322], 
reward next is 0.7114, 
noisyNet noise sample is [array([0.6099698], dtype=float32), 0.3738353]. 
=============================================
[2019-03-23 16:42:05,944] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2555430e-06 9.9999869e-01 1.2753881e-15 4.6676774e-11 2.6171500e-12], sum to 1.0000
[2019-03-23 16:42:05,952] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1393
[2019-03-23 16:42:05,960] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1142203.784413368 W.
[2019-03-23 16:42:05,967] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.51666666666667, 51.5, 1.0, 2.0, 0.5005123229448586, 1.0, 2.0, 0.5005123229448586, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1142203.784413368, 1142203.784413368, 228117.2739049727], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5309400.0000, 
sim time next is 5310000.0000, 
raw observation next is [27.7, 51.0, 1.0, 2.0, 0.3371960305038147, 1.0, 2.0, 0.3371960305038147, 1.0, 1.0, 0.6823766656506495, 6.911199999999999, 6.9112, 77.3421103, 1153502.6169567, 1153502.6169567, 270613.3073768496], 
processed observation next is [1.0, 0.4782608695652174, 0.8954545454545454, 0.51, 1.0, 1.0, 0.17149503812976835, 1.0, 1.0, 0.17149503812976835, 1.0, 0.5, 0.5462523795009279, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.42722319146544446, 0.42722319146544446, 0.6600324570167063], 
reward next is 0.3400, 
noisyNet noise sample is [array([-0.8562531], dtype=float32), -0.15735105]. 
=============================================
[2019-03-23 16:42:05,979] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[42.575558]
 [43.112988]
 [44.224945]
 [44.65075 ]
 [44.861237]], R is [[41.16765594]
 [41.19959641]
 [41.23497391]
 [41.31351089]
 [41.42388916]].
[2019-03-23 16:42:08,451] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 16:42:08,452] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:42:08,453] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:42:08,456] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:42:08,458] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:42:08,458] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:42:08,459] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:42:08,459] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:42:08,462] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:42:08,464] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:42:08,465] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:42:08,488] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run100
[2019-03-23 16:42:08,520] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run100
[2019-03-23 16:42:08,550] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run100
[2019-03-23 16:42:08,551] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run100
[2019-03-23 16:42:08,595] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run100
[2019-03-23 16:42:15,728] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04531563], dtype=float32), 0.41265926]
[2019-03-23 16:42:15,731] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.83333333333333, 95.0, 1.0, 2.0, 0.4346054756971791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 471988.2902840512, 471988.2902840512, 105599.6561897993]
[2019-03-23 16:42:15,732] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:42:15,735] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0338820e-09 1.0000000e+00 1.5887404e-20 2.4665599e-15 2.1133024e-17], sampled 0.4556325796188955
[2019-03-23 16:42:44,267] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.04531563], dtype=float32), 0.41265926]
[2019-03-23 16:42:44,269] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.4, 73.66666666666667, 1.0, 2.0, 0.4976244426577031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 567753.199392164, 567753.199392164, 145313.5380698901]
[2019-03-23 16:42:44,269] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:42:44,272] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.9550038e-10 1.0000000e+00 1.9980160e-21 5.3229874e-16 3.6603131e-18], sampled 0.8161427617649993
[2019-03-23 16:43:24,906] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04531563], dtype=float32), 0.41265926]
[2019-03-23 16:43:24,907] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.4, 93.0, 1.0, 2.0, 0.3945933573752975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 445773.5756164278, 445773.5756164278, 124986.3211270023]
[2019-03-23 16:43:24,909] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:43:24,911] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.1874894e-10 1.0000000e+00 5.2442088e-21 1.0867658e-15 8.2751479e-18], sampled 0.8204303986661506
[2019-03-23 16:43:35,258] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04531563], dtype=float32), 0.41265926]
[2019-03-23 16:43:35,259] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.0, 77.66666666666667, 1.0, 2.0, 0.5415652802959112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 615829.6281766444, 615829.6281766444, 148685.1041301648]
[2019-03-23 16:43:35,262] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:43:35,264] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.9059574e-10 1.0000000e+00 4.7498540e-21 1.0097595e-15 7.6140073e-18], sampled 0.2094347959180537
[2019-03-23 16:43:39,702] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.04531563], dtype=float32), 0.41265926]
[2019-03-23 16:43:39,702] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.24047246, 78.14711736166667, 1.0, 2.0, 0.2883200987772301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 313049.7386790678, 313049.7386790674, 114597.0522902975]
[2019-03-23 16:43:39,703] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:43:39,707] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.8740438e-10 1.0000000e+00 1.0011229e-21 3.1944855e-16 2.0388803e-18], sampled 0.967524378229134
[2019-03-23 16:43:53,114] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 16:43:53,287] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 16:43:53,375] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 16:43:53,493] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 16:43:53,614] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 16:43:54,630] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 2475000, evaluation results [2475000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 16:43:58,237] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.7045527e-11 1.0000000e+00 1.1014778e-23 4.3506464e-17 2.8280255e-20], sum to 1.0000
[2019-03-23 16:43:58,242] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4745
[2019-03-23 16:43:58,247] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.63333333333333, 96.66666666666666, 1.0, 2.0, 0.3861672185318473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 434703.4548024923, 434703.4548024926, 123373.1306133187], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5438400.0000, 
sim time next is 5439000.0000, 
raw observation next is [18.71666666666667, 96.83333333333334, 1.0, 2.0, 0.3892769860731648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 438675.6482906157, 438675.648290616, 123895.6674681098], 
processed observation next is [1.0, 0.9565217391304348, 0.48712121212121223, 0.9683333333333334, 1.0, 1.0, 0.23659623259145598, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16247246232985768, 0.16247246232985776, 0.3021845548002678], 
reward next is 0.6978, 
noisyNet noise sample is [array([0.5009803], dtype=float32), 0.6097453]. 
=============================================
[2019-03-23 16:43:58,260] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[67.24704]
 [67.23346]
 [67.23268]
 [67.19712]
 [67.1457 ]], R is [[67.28598022]
 [67.31221008]
 [67.33958435]
 [67.36774445]
 [67.39627838]].
[2019-03-23 16:43:59,530] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.1158912e-10 1.0000000e+00 1.0826608e-23 2.8742309e-17 2.4958678e-19], sum to 1.0000
[2019-03-23 16:43:59,536] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8448
[2019-03-23 16:43:59,540] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 100.0, 1.0, 2.0, 0.3668682721646479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 407463.6251556794, 407463.6251556797, 119181.3008075339], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5457600.0000, 
sim time next is 5458200.0000, 
raw observation next is [17.2, 98.33333333333334, 1.0, 2.0, 0.367187016179823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 406955.1389708584, 406955.1389708587, 118861.8228177175], 
processed observation next is [1.0, 0.17391304347826086, 0.41818181818181815, 0.9833333333333334, 1.0, 1.0, 0.20898377022477876, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1507241255447624, 0.15072412554476247, 0.2899068849212622], 
reward next is 0.7101, 
noisyNet noise sample is [array([1.1504928], dtype=float32), 0.21508908]. 
=============================================
[2019-03-23 16:44:00,998] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.04815773e-09 1.00000000e+00 1.08184256e-17 3.47859599e-13
 1.23480696e-15], sum to 1.0000
[2019-03-23 16:44:01,003] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7777
[2019-03-23 16:44:01,007] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 95.0, 1.0, 2.0, 0.3269762733194131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 359575.7567413406, 359575.7567413409, 114643.2848225369], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5467800.0000, 
sim time next is 5468400.0000, 
raw observation next is [17.2, 96.0, 1.0, 2.0, 0.3286617055359304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 362117.8286965055, 362117.8286965055, 115027.0222153749], 
processed observation next is [1.0, 0.30434782608695654, 0.41818181818181815, 0.96, 1.0, 1.0, 0.16082713191991296, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1341177143320391, 0.1341177143320391, 0.2805537127204266], 
reward next is 0.7194, 
noisyNet noise sample is [array([-0.17175741], dtype=float32), -0.8394539]. 
=============================================
[2019-03-23 16:44:03,547] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.6763766e-09 1.0000000e+00 1.3901820e-20 6.6605975e-16 2.0067737e-17], sum to 1.0000
[2019-03-23 16:44:03,556] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4413
[2019-03-23 16:44:03,564] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 90.0, 1.0, 2.0, 0.4133549824662253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 469600.0395787795, 469600.0395787798, 128472.2247331474], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5551200.0000, 
sim time next is 5551800.0000, 
raw observation next is [20.5, 90.0, 1.0, 2.0, 0.4282060805361732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 486507.013255471, 486507.013255471, 129943.186070107], 
processed observation next is [1.0, 0.2608695652173913, 0.5681818181818182, 0.9, 1.0, 1.0, 0.2852576006702165, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18018778268721147, 0.18018778268721147, 0.3169346001709927], 
reward next is 0.6831, 
noisyNet noise sample is [array([0.7646507], dtype=float32), 2.1149101]. 
=============================================
[2019-03-23 16:44:10,835] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.3697186e-12 1.0000000e+00 1.9484792e-23 1.8820414e-18 6.7462509e-19], sum to 1.0000
[2019-03-23 16:44:10,839] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0239
[2019-03-23 16:44:10,844] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.2, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 184565.4786423804, 184565.4786423801, 63129.63764594678], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5695200.0000, 
sim time next is 5695800.0000, 
raw observation next is [12.1, 77.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 182174.8174775832, 182174.8174775835, 62696.7142151537], 
processed observation next is [0.0, 0.9565217391304348, 0.18636363636363634, 0.775, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.06747215462132711, 0.06747215462132722, 0.15291881515891145], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.50070995], dtype=float32), 0.04735328]. 
=============================================
[2019-03-23 16:44:15,174] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.2337724e-07 9.9999976e-01 1.6822846e-15 3.6234110e-12 6.6558440e-13], sum to 1.0000
[2019-03-23 16:44:15,184] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1845
[2019-03-23 16:44:15,190] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.15, 59.0, 1.0, 2.0, 0.2182768060342902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 236994.7478249702, 236994.7478249702, 74067.92788682083], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5779800.0000, 
sim time next is 5780400.0000, 
raw observation next is [16.96666666666667, 60.0, 1.0, 2.0, 0.2160776379385588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 234606.4180994516, 234606.4180994513, 73760.75076979672], 
processed observation next is [0.0, 0.9130434782608695, 0.40757575757575765, 0.6, 1.0, 1.0, 0.02009704742319849, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08689126596275985, 0.08689126596275974, 0.1799042701702359], 
reward next is 0.8201, 
noisyNet noise sample is [array([0.41205752], dtype=float32), -0.96374494]. 
=============================================
[2019-03-23 16:44:17,148] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.29763257e-12 1.00000000e+00 1.02841386e-25 9.37102576e-20
 1.50905557e-22], sum to 1.0000
[2019-03-23 16:44:17,155] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8652
[2019-03-23 16:44:17,160] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.36666666666667, 82.0, 1.0, 2.0, 0.3838700670894554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416865.227458022, 416865.227458022, 86758.90298655523], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5802000.0000, 
sim time next is 5802600.0000, 
raw observation next is [12.28333333333333, 82.5, 1.0, 2.0, 0.3840965503795006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 417111.2833867737, 417111.283386774, 86730.03445008938], 
processed observation next is [1.0, 0.13043478260869565, 0.19469696969696954, 0.825, 1.0, 1.0, 0.2301206879743757, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1544856605136199, 0.15448566051362, 0.21153666939046192], 
reward next is 0.7885, 
noisyNet noise sample is [array([-0.16682322], dtype=float32), 2.4380674]. 
=============================================
[2019-03-23 16:44:18,193] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3083441e-12 1.0000000e+00 2.4059104e-25 1.3845147e-19 6.4103311e-21], sum to 1.0000
[2019-03-23 16:44:18,201] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9128
[2019-03-23 16:44:18,211] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.53333333333333, 63.66666666666667, 1.0, 2.0, 0.2488771133298788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 270228.3601099845, 270228.3601099848, 80163.49154785585], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5818800.0000, 
sim time next is 5819400.0000, 
raw observation next is [18.0, 63.0, 1.0, 2.0, 0.2826879396050059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 306951.4131160961, 306951.4131160961, 85126.10038083138], 
processed observation next is [1.0, 0.34782608695652173, 0.45454545454545453, 0.63, 1.0, 1.0, 0.10335992450625733, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11368570856151708, 0.11368570856151708, 0.2076246350751985], 
reward next is 0.7924, 
noisyNet noise sample is [array([-0.32480115], dtype=float32), -0.33847547]. 
=============================================
[2019-03-23 16:44:25,101] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0317863e-12 1.0000000e+00 7.8841643e-25 1.2261208e-19 1.6365545e-20], sum to 1.0000
[2019-03-23 16:44:25,111] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3101
[2019-03-23 16:44:25,119] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.86666666666667, 74.66666666666667, 1.0, 2.0, 0.3623670596627815, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 405554.8100595456, 405554.8100595456, 120156.9756900971], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5964000.0000, 
sim time next is 5964600.0000, 
raw observation next is [20.68333333333334, 76.33333333333333, 1.0, 2.0, 0.3634879502381314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 407050.6037130427, 407050.6037130427, 120361.6338385402], 
processed observation next is [1.0, 0.0, 0.5765151515151519, 0.7633333333333333, 1.0, 1.0, 0.20435993779766423, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15075948285668248, 0.15075948285668248, 0.29356496058180537], 
reward next is 0.7064, 
noisyNet noise sample is [array([2.0322921], dtype=float32), 1.8423004]. 
=============================================
[2019-03-23 16:44:35,573] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.7871425e-14 1.0000000e+00 4.9190990e-28 4.0823399e-21 2.7012343e-24], sum to 1.0000
[2019-03-23 16:44:35,580] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1242
[2019-03-23 16:44:35,590] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.3, 76.5, 1.0, 2.0, 0.5816832752466051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 640557.0406077611, 640557.0406077608, 137375.8803880771], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6166200.0000, 
sim time next is 6166800.0000, 
raw observation next is [19.4, 76.0, 1.0, 2.0, 0.5876781916664858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 647588.889055846, 647588.8890558457, 138146.2834196305], 
processed observation next is [1.0, 0.391304347826087, 0.5181818181818181, 0.76, 1.0, 1.0, 0.48459773958310726, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23984773668735038, 0.23984773668735024, 0.3369421546820256], 
reward next is 0.6631, 
noisyNet noise sample is [array([-1.7044408], dtype=float32), 1.148525]. 
=============================================
[2019-03-23 16:44:37,089] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.8584437e-12 1.0000000e+00 1.7199515e-25 8.5809209e-20 6.8715349e-22], sum to 1.0000
[2019-03-23 16:44:37,097] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2996
[2019-03-23 16:44:37,103] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 84.0, 1.0, 2.0, 0.2868178158310526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 311437.197875049, 311437.1978750487, 103364.2794019646], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6153000.0000, 
sim time next is 6153600.0000, 
raw observation next is [17.2, 84.0, 1.0, 2.0, 0.2807868083412831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 304886.4582011487, 304886.458201149, 102703.7185544112], 
processed observation next is [1.0, 0.21739130434782608, 0.41818181818181815, 0.84, 1.0, 1.0, 0.10098351042660388, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11292091044486989, 0.11292091044487, 0.25049687452295416], 
reward next is 0.7495, 
noisyNet noise sample is [array([0.35824522], dtype=float32), 1.033366]. 
=============================================
[2019-03-23 16:44:40,631] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.8826386e-13 1.0000000e+00 1.0666474e-25 1.3204676e-20 1.6372710e-22], sum to 1.0000
[2019-03-23 16:44:40,634] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9612
[2019-03-23 16:44:40,640] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.4, 55.0, 1.0, 2.0, 0.5448050239259676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 618383.2286838716, 618383.2286838712, 149663.1861793263], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6278400.0000, 
sim time next is 6279000.0000, 
raw observation next is [29.5, 55.0, 1.0, 2.0, 0.5440718470410457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 617406.3722911695, 617406.3722911695, 149633.0384649251], 
processed observation next is [0.0, 0.6956521739130435, 0.9772727272727273, 0.55, 1.0, 1.0, 0.4300898088013071, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2286690267745072, 0.2286690267745072, 0.36495863040225635], 
reward next is 0.6350, 
noisyNet noise sample is [array([-0.46926147], dtype=float32), -0.5679288]. 
=============================================
[2019-03-23 16:44:40,680] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[73.74744 ]
 [73.60641 ]
 [73.48074 ]
 [73.348434]
 [73.1782  ]], R is [[73.7156601 ]
 [73.61347961]
 [73.51019287]
 [73.40566254]
 [73.29956055]].
[2019-03-23 16:44:42,585] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 16:44:42,587] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:44:42,588] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:44:42,588] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:44:42,591] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:44:42,592] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:44:42,593] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:44:42,594] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:44:42,595] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:44:42,596] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:44:42,597] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:44:42,620] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run101
[2019-03-23 16:44:42,621] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run101
[2019-03-23 16:44:42,682] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run101
[2019-03-23 16:44:42,714] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run101
[2019-03-23 16:44:42,741] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/40/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run101
[2019-03-23 16:44:48,849] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05153958], dtype=float32), 0.41409975]
[2019-03-23 16:44:48,851] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.0, 71.33333333333333, 1.0, 2.0, 0.2565219037470286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 278531.3763952542, 278531.3763952539, 89904.25207089241]
[2019-03-23 16:44:48,853] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:44:48,856] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.2411423e-11 1.0000000e+00 2.7109274e-24 1.0043298e-18 6.5969597e-21], sampled 0.6018275345631814
[2019-03-23 16:45:03,680] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05153958], dtype=float32), 0.41409975]
[2019-03-23 16:45:03,683] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.89146526, 87.897831655, 1.0, 2.0, 0.3407172614368313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 379188.375340339, 379188.3753403386, 121761.0645320948]
[2019-03-23 16:45:03,686] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:45:03,688] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.7754595e-12 1.0000000e+00 5.3117663e-25 2.8892884e-19 1.6278431e-21], sampled 0.9411481542951876
[2019-03-23 16:45:22,430] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05153958], dtype=float32), 0.41409975]
[2019-03-23 16:45:22,433] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.7, 40.0, 1.0, 2.0, 0.3789442314636829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 426063.5793342607, 426063.5793342611, 126804.6212391566]
[2019-03-23 16:45:22,436] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:45:22,439] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.0143622e-12 1.0000000e+00 3.9469931e-25 2.2990206e-19 1.2590902e-21], sampled 0.8465911555128552
[2019-03-23 16:45:39,436] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05153958], dtype=float32), 0.41409975]
[2019-03-23 16:45:39,438] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.22839848166667, 49.971232975, 1.0, 2.0, 0.3713339317647046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 416834.7834311895, 416834.7834311899, 125813.6041295396]
[2019-03-23 16:45:39,438] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:45:39,441] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.7550067e-12 1.0000000e+00 5.2883736e-25 2.8760486e-19 1.6191973e-21], sampled 0.07513923025710845
[2019-03-23 16:46:25,622] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05153958], dtype=float32), 0.41409975]
[2019-03-23 16:46:25,623] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.2, 67.83333333333333, 1.0, 2.0, 0.224585829391636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 243834.8500156171, 243834.8500156167, 83039.99829084444]
[2019-03-23 16:46:25,625] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:46:25,627] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.9674822e-12 1.0000000e+00 5.6996719e-25 3.0477992e-19 1.7287297e-21], sampled 0.8688436819729146
[2019-03-23 16:46:29,190] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 16:46:29,243] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 16:46:29,284] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 16:46:29,379] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 16:46:29,380] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 16:46:30,397] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 2500000, evaluation results [2500000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
