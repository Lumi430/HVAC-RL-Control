Using TensorFlow backend.
[2019-03-23 16:46:37,212] A3C_AGENT_MAIN INFO:Namespace(action_repeat_n=1, action_space='part3_v1', activation='relu', agent_num=5, check_args_only=False, clip_norm=5.0, debug_log_prob=0.0005, decay_steps=1000000, dropout_prob=0.0, end_e=0.0, env='Part3-NA-Pit-Train-v1', eval_act_func='part3_pit_det_v1', eval_env_res_max_keep=50, eval_epi_num=1, eval_freq=25000, forecast_dim=0, gamma=0.99, h_decay_bounds=[], h_regu_frac=[0.0], init_e=0.0, isNoisyNet=True, isNoisyNetEval_rmNoise=True, is_greedy_policy=False, is_learning_rate_decay_staircase=False, is_warm_start=False, job_mode='Train', learning_rate=5e-06, learning_rate_decay_rate=1.0, learning_rate_decay_steps=100000, max_interactions=2500000, metric_func='part3_v1', model_dir='None', model_param=[256, 8], model_type='nn', num_threads=16, output='./Part3-NA-Pit-Train-v1-res1', p_loss_frac=1.0, raw_state_prcs_func='cslDx_1', reward_func='part3_v3', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=1.0, rwd_p_para=1.0, save_freq=500000, save_max_to_keep=5, save_scope='all', sharedNet_type='Dense', state_dim=17, test_env=['Part3-NA-Pit-Test-v1', 'Part3-NA-Pit-Test-v2', 'Part3-NA-Pit-Test-v3', 'Part3-NA-Pit-Test-v4'], test_mode='Multiple', train_act_func='part3_pit_sto_v1', train_freq=5, v_loss_frac=0.5, violation_penalty_scl=50.0, weight_initer='glorot_uniform', window_len=21)
[2019-03-23 16:46:37,213] A3C_AGENT_MAIN INFO:Start compiling...
2019-03-23 16:46:37.313356: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[2019-03-23 16:47:09,944] A3C_AGENT_MAIN INFO:Start the learning...
[2019-03-23 16:47:09,944] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['Part3-NA-Pit-Train-v1', 'Part3-NA-Pit-Test-v1', 'Part3-NA-Pit-Test-v2', 'Part3-NA-Pit-Test-v3', 'Part3-NA-Pit-Test-v4'] ...
[2019-03-23 16:47:09,955] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation worker starts!
[2019-03-23 16:47:09,958] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation worker starts!
[2019-03-23 16:47:09,960] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation worker starts!
[2019-03-23 16:47:09,966] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation worker starts!
[2019-03-23 16:47:09,970] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation worker starts!
[2019-03-23 16:47:09,970] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 16:47:09,970] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2019-03-23 16:47:10,060] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:47:10,061] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run1
[2019-03-23 16:47:10,972] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 16:47:10,975] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2019-03-23 16:47:11,135] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:47:11,136] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run1
[2019-03-23 16:47:11,505] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 16:47:11,506] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:47:11,506] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:47:11,507] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:47:11,507] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:47:11,507] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:47:11,507] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:47:11,508] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:47:11,508] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:47:11,509] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:47:11,509] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:47:11,513] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run1
[2019-03-23 16:47:11,525] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run1
[2019-03-23 16:47:11,527] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run1
[2019-03-23 16:47:11,537] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run1
[2019-03-23 16:47:11,537] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run1
[2019-03-23 16:47:11,976] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 16:47:11,977] A3C_AGENT_WORKER-Thread-9 INFO:Local worker starts!
[2019-03-23 16:47:12,106] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:47:12,107] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run1
[2019-03-23 16:47:12,978] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 16:47:12,979] A3C_AGENT_WORKER-Thread-10 INFO:Local worker starts!
[2019-03-23 16:47:13,194] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:47:13,195] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run1
[2019-03-23 16:47:13,980] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 16:47:13,983] A3C_AGENT_WORKER-Thread-11 INFO:Local worker starts!
[2019-03-23 16:47:14,107] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:47:14,132] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run1
[2019-03-23 16:47:14,983] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 16:47:14,989] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2019-03-23 16:47:15,109] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:47:15,117] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run1
[2019-03-23 16:47:15,988] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 16:47:15,993] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2019-03-23 16:47:16,115] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:47:16,119] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run1
[2019-03-23 16:47:16,993] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 16:47:16,997] A3C_AGENT_WORKER-Thread-14 INFO:Local worker starts!
[2019-03-23 16:47:17,095] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:47:17,096] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run1
[2019-03-23 16:47:17,997] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 16:47:18,001] A3C_AGENT_WORKER-Thread-15 INFO:Local worker starts!
[2019-03-23 16:47:18,100] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:47:18,101] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run1
[2019-03-23 16:47:19,002] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 16:47:19,006] A3C_AGENT_WORKER-Thread-16 INFO:Local worker starts!
[2019-03-23 16:47:19,098] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:47:19,099] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run1
[2019-03-23 16:47:20,006] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 16:47:20,013] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2019-03-23 16:47:20,106] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:47:20,107] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run1
[2019-03-23 16:47:21,011] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 16:47:21,016] A3C_AGENT_WORKER-Thread-18 INFO:Local worker starts!
[2019-03-23 16:47:21,106] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:47:21,108] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run1
[2019-03-23 16:47:22,013] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 16:47:22,019] A3C_AGENT_WORKER-Thread-19 INFO:Local worker starts!
[2019-03-23 16:47:22,114] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:47:22,115] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run1
[2019-03-23 16:47:23,017] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 16:47:23,020] A3C_AGENT_WORKER-Thread-20 INFO:Local worker starts!
[2019-03-23 16:47:23,117] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:47:23,118] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run1
[2019-03-23 16:47:24,021] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 16:47:24,030] A3C_AGENT_WORKER-Thread-21 INFO:Local worker starts!
[2019-03-23 16:47:24,126] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:47:24,127] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run1
[2019-03-23 16:47:25,026] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 16:47:25,030] A3C_AGENT_WORKER-Thread-22 INFO:Local worker starts!
[2019-03-23 16:47:25,172] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:47:25,173] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run1
[2019-03-23 16:47:35,834] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 16:47:35,837] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.15, 82.0, 1.0, 2.0, 0.2640970196886683, 1.0, 2.0, 0.2640970196886683, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 602595.2760747855, 602595.2760747859, 183862.6003459549]
[2019-03-23 16:47:35,838] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:47:35,842] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.23064888 0.19290632 0.18629876 0.20127012 0.18887594], sampled 0.31967488213002004
[2019-03-23 16:47:36,622] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 16:47:36,623] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.4, 90.0, 1.0, 2.0, 0.2184281582847688, 1.0, 1.0, 0.2184281582847688, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 497331.6458429993, 497331.645842999, 174447.2462115416]
[2019-03-23 16:47:36,624] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:47:36,627] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.22974154 0.1922927  0.18645845 0.20196044 0.18954687], sampled 0.5059248406447899
[2019-03-23 16:48:03,529] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 16:48:03,530] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.79972494333333, 78.98167060499999, 1.0, 2.0, 0.2693303117307703, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 292426.1535687009, 292426.1535687009, 92365.85760101375]
[2019-03-23 16:48:03,531] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:48:03,535] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.22817892 0.19174346 0.18625192 0.205548   0.18827766], sampled 0.9906323296586902
[2019-03-23 16:48:07,137] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 16:48:07,139] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 100.0, 1.0, 2.0, 0.2568054761857116, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5192488342314251, 6.9112, 6.9112, 77.32846344354104, 585749.7342166515, 585749.7342166515, 180073.5866859853]
[2019-03-23 16:48:07,142] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:48:07,146] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.23251651 0.19237211 0.1867969  0.2011741  0.1871404 ], sampled 0.97178159453707
[2019-03-23 16:48:25,325] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 16:48:25,326] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.58319530333333, 63.81995866666667, 1.0, 2.0, 0.214716974908826, 1.0, 2.0, 0.214716974908826, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 478624.2688832487, 478624.2688832484, 165957.1856971638]
[2019-03-23 16:48:25,328] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:48:25,331] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.22922447 0.19064528 0.18817459 0.1989104  0.19304529], sampled 0.2962398704713882
[2019-03-23 16:48:32,805] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 16:48:32,807] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.76395342, 94.39452134166666, 1.0, 2.0, 0.5846367554605094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338671837417, 639216.4720725807, 639216.4720725807, 140509.1681450802]
[2019-03-23 16:48:32,809] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:48:32,812] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.22887808 0.19290033 0.18774247 0.20278303 0.18769608], sampled 0.8450014926264808
[2019-03-23 16:48:36,714] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 16:48:36,715] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.1, 66.66666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6240645960538214, 6.911200000000001, 6.9112, 95.55338769695034, 360576.3008517534, 360576.300851753, 121606.1017407531]
[2019-03-23 16:48:36,716] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:48:36,720] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.2306103  0.19480596 0.1848058  0.20032811 0.18944986], sampled 0.46606573534818563
[2019-03-23 16:48:46,769] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 16:48:46,770] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [28.73333333333333, 46.0, 1.0, 2.0, 0.7418196438303565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 846096.3166026406, 846096.3166026402, 175439.0874403623]
[2019-03-23 16:48:46,770] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:48:46,773] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.2336024  0.1918162  0.18461351 0.20097482 0.18899316], sampled 0.46844919465618695
[2019-03-23 16:48:49,454] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 16:48:49,454] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.63333333333333, 57.0, 1.0, 2.0, 0.6351875371219166, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9232512244363692, 6.981764985208343, 6.9112, 95.55311190371737, 1272007.929291815, 1243688.572793808, 275411.3089747251]
[2019-03-23 16:48:49,455] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:48:49,457] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.23288132 0.19195817 0.18236521 0.20296824 0.18982708], sampled 0.9405965814760832
[2019-03-23 16:49:02,208] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2373.4958 2015308686.3159 1225.0000
[2019-03-23 16:49:02,256] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 2636.7130 2070785845.9619 784.0000
[2019-03-23 16:49:02,304] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 2405.2222 1993193132.2054 1052.0000
[2019-03-23 16:49:02,372] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 2502.0822 1990364229.6686 995.0000
[2019-03-23 16:49:02,395] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 2386.9121 2002061119.1406 1032.0000
[2019-03-23 16:49:03,413] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 0, evaluation results [0.0, 2636.712973369623, 2070785845.9619217, 784.0, 2502.082216774352, 1990364229.6685717, 995.0, 2405.2222019032033, 1993193132.2053936, 1052.0, 2373.4958111019214, 2015308686.315941, 1225.0, 2386.912106711278, 2002061119.1405976, 1032.0]
[2019-03-23 16:49:08,323] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.22429438 0.19707282 0.18725483 0.20675516 0.18462276], sum to 1.0000
[2019-03-23 16:49:08,332] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2575
[2019-03-23 16:49:08,507] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 1.0, 0.2, 1.0, 1.0, 0.2, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32842600004773, 426479.1051433336, 426479.1051433338, 159357.4527462912], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 25200.0000, 
sim time next is 25800.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3934719850347188, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846321176226, 442628.9836812186, 442628.9836812186, 123863.5198644494], 
processed observation next is [1.0, 0.30434782608695654, 0.45454545454545453, 1.0, 1.0, 1.0, 0.24183998129339848, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288113967261, 0.16393666062267354, 0.16393666062267354, 0.3021061460108522], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.0578727], dtype=float32), 0.5302155]. 
=============================================
[2019-03-23 16:49:13,176] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.22716598 0.1934885  0.18630385 0.2032985  0.18974322], sum to 1.0000
[2019-03-23 16:49:13,183] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4184
[2019-03-23 16:49:13,188] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 64.0, 1.0, 2.0, 0.2357073610225238, 1.0, 2.0, 0.2357073610225238, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344002935, 511984.75351237, 511984.75351237, 142509.7726765449], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 118800.0000, 
sim time next is 119400.0000, 
raw observation next is [18.5, 62.66666666666667, 1.0, 2.0, 0.5027631972615986, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.3284634435193, 546050.20655315, 546050.2065531497, 110116.5176076228], 
processed observation next is [1.0, 0.391304347826087, 0.4772727272727273, 0.6266666666666667, 1.0, 1.0, 0.3784539965769982, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129205111, 0.2022408172419074, 0.20224081724190732, 0.2685768722137141], 
reward next is 0.7314, 
noisyNet noise sample is [array([0.55924034], dtype=float32), -0.27848694]. 
=============================================
[2019-03-23 16:49:14,473] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.23181531 0.19475128 0.18054001 0.20376761 0.18912587], sum to 1.0000
[2019-03-23 16:49:14,479] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0652
[2019-03-23 16:49:14,487] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 783676.4723637488 W.
[2019-03-23 16:49:14,661] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.33333333333334, 41.33333333333333, 1.0, 2.0, 0.3606879290376518, 0.0, 2.0, 0.0, 1.0, 1.0, 0.6733253454387255, 6.9112, 6.9112, 77.32846344354104, 783676.4723637488, 783676.4723637488, 174783.9665672252], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 146400.0000, 
sim time next is 147000.0000, 
raw observation next is [22.16666666666667, 42.16666666666667, 1.0, 2.0, 0.2375833449589002, 1.0, 1.0, 0.2375833449589002, 1.0, 2.0, 0.4435160562255472, 6.9112, 6.9112, 77.3421103, 774298.1160459957, 774298.1160459957, 207556.2927437108], 
processed observation next is [1.0, 0.6956521739130435, 0.6439393939393941, 0.4216666666666667, 1.0, 1.0, 0.04697918119862525, 1.0, 0.5, 0.04697918119862525, 1.0, 1.0, 0.20502293746506745, 0.0, 0.0, 0.5085185399722538, 0.28677708001703545, 0.28677708001703545, 0.5062348603505141], 
reward next is 0.4938, 
noisyNet noise sample is [array([0.92971], dtype=float32), -0.23119283]. 
=============================================
[2019-03-23 16:49:14,662] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.23084156 0.18891208 0.18190008 0.19748285 0.20086344], sum to 1.0000
[2019-03-23 16:49:14,672] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7684
[2019-03-23 16:49:14,846] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.83333333333334, 38.83333333333334, 1.0, 2.0, 0.7397146824240455, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 803615.5805429522, 803615.5805429518, 140689.0019441946], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 144600.0000, 
sim time next is 145200.0000, 
raw observation next is [22.66666666666667, 39.66666666666667, 1.0, 2.0, 0.3707820205120319, 1.0, 1.0, 0.3707820205120319, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 805626.3634317339, 805626.3634317339, 173877.7208022272], 
processed observation next is [1.0, 0.6956521739130435, 0.6666666666666669, 0.3966666666666667, 1.0, 1.0, 0.21347752564003986, 1.0, 0.5, 0.21347752564003986, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.29838013460434587, 0.29838013460434587, 0.42409200195665175], 
reward next is 0.5759, 
noisyNet noise sample is [array([-1.1714448], dtype=float32), -0.045767736]. 
=============================================
[2019-03-23 16:49:14,854] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[0.18198207]
 [0.17672724]
 [0.16247976]
 [0.16650122]
 [0.18396406]], R is [[0.66692764]
 [1.23395598]
 [1.88004971]
 [2.51596308]
 [3.14670038]].
[2019-03-23 16:49:22,294] A3C_AGENT_WORKER-Thread-15 INFO:Local step 500, global step 7908: loss 20.0349
[2019-03-23 16:49:22,381] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 500, global step 7912: learning rate 0.0000
[2019-03-23 16:49:22,390] A3C_AGENT_WORKER-Thread-14 INFO:Local step 500, global step 7921: loss 8.5521
[2019-03-23 16:49:22,392] A3C_AGENT_WORKER-Thread-21 INFO:Local step 500, global step 7922: loss 7.8215
[2019-03-23 16:49:22,394] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 500, global step 7922: learning rate 0.0000
[2019-03-23 16:49:22,392] A3C_AGENT_WORKER-Thread-20 INFO:Local step 500, global step 7922: loss 4.0568
[2019-03-23 16:49:22,399] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 500, global step 7925: learning rate 0.0000
[2019-03-23 16:49:22,400] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 500, global step 7925: learning rate 0.0000
[2019-03-23 16:49:22,425] A3C_AGENT_WORKER-Thread-11 INFO:Local step 500, global step 7939: loss 6.6038
[2019-03-23 16:49:22,427] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 500, global step 7939: learning rate 0.0000
[2019-03-23 16:49:22,441] A3C_AGENT_WORKER-Thread-16 INFO:Local step 500, global step 7947: loss 18.0988
[2019-03-23 16:49:22,444] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 500, global step 7949: learning rate 0.0000
[2019-03-23 16:49:22,480] A3C_AGENT_WORKER-Thread-3 INFO:Local step 500, global step 7968: loss 5.8645
[2019-03-23 16:49:22,481] A3C_AGENT_WORKER-Thread-19 INFO:Local step 500, global step 7968: loss 6.6255
[2019-03-23 16:49:22,481] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 500, global step 7968: learning rate 0.0000
[2019-03-23 16:49:22,482] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 500, global step 7968: learning rate 0.0000
[2019-03-23 16:49:22,484] A3C_AGENT_WORKER-Thread-10 INFO:Local step 500, global step 7968: loss 10.7079
[2019-03-23 16:49:22,487] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 500, global step 7968: learning rate 0.0000
[2019-03-23 16:49:22,508] A3C_AGENT_WORKER-Thread-9 INFO:Local step 500, global step 7982: loss -1.1030
[2019-03-23 16:49:22,508] A3C_AGENT_WORKER-Thread-22 INFO:Local step 500, global step 7982: loss 4.5229
[2019-03-23 16:49:22,511] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 500, global step 7983: learning rate 0.0000
[2019-03-23 16:49:22,516] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 500, global step 7985: learning rate 0.0000
[2019-03-23 16:49:22,598] A3C_AGENT_WORKER-Thread-12 INFO:Local step 500, global step 8027: loss -0.2265
[2019-03-23 16:49:22,601] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 500, global step 8027: learning rate 0.0000
[2019-03-23 16:49:22,624] A3C_AGENT_WORKER-Thread-2 INFO:Local step 500, global step 8041: loss -2.3479
[2019-03-23 16:49:22,625] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 500, global step 8041: learning rate 0.0000
[2019-03-23 16:49:22,687] A3C_AGENT_WORKER-Thread-13 INFO:Local step 500, global step 8072: loss 6.7100
[2019-03-23 16:49:22,692] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 500, global step 8075: learning rate 0.0000
[2019-03-23 16:49:22,758] A3C_AGENT_WORKER-Thread-18 INFO:Local step 500, global step 8112: loss 8.3807
[2019-03-23 16:49:22,760] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 500, global step 8112: learning rate 0.0000
[2019-03-23 16:49:22,784] A3C_AGENT_WORKER-Thread-17 INFO:Local step 500, global step 8125: loss 3.9344
[2019-03-23 16:49:22,786] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 500, global step 8125: learning rate 0.0000
[2019-03-23 16:49:23,784] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.7411362  0.1013885  0.02229764 0.04607966 0.08909791], sum to 1.0000
[2019-03-23 16:49:23,787] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8890
[2019-03-23 16:49:23,790] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.0, 43.0, 1.0, 1.0, 0.2, 1.0, 1.0, 0.2, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 279067.5746047622, 279067.5746047622, 116590.6283257699], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 323400.0000, 
sim time next is 324000.0000, 
raw observation next is [21.0, 43.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 279672.7306362223, 279672.7306362223, 108425.6747324714], 
processed observation next is [0.0, 0.782608695652174, 0.5909090909090909, 0.43, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10358249282823048, 0.10358249282823048, 0.26445286520114974], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.8482103], dtype=float32), 0.12276129]. 
=============================================
[2019-03-23 16:49:23,811] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[4.6656523]
 [4.522534 ]
 [4.121685 ]
 [4.3719816]
 [4.4443283]], R is [[4.68397665]
 [4.63713694]
 [5.3941679 ]
 [6.14491796]
 [6.89232445]].
[2019-03-23 16:49:30,369] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9976832e-01 2.3055536e-05 3.8533152e-10 2.1168560e-08 2.0852941e-04], sum to 1.0000
[2019-03-23 16:49:30,374] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4870
[2019-03-23 16:49:30,380] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 575121.4659194407 W.
[2019-03-23 16:49:30,557] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7557672224574414, 7.328106393510597, 6.9112, 77.3274531032638, 575121.4659194407, 439720.5656303461, 96769.1985829622], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 457200.0000, 
sim time next is 457800.0000, 
raw observation next is [13.0, 100.0, 1.0, 1.0, 0.4513785705036624, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32821292028112, 490213.3164329709, 490213.3164329706, 104066.6017697755], 
processed observation next is [1.0, 0.30434782608695654, 0.22727272727272727, 1.0, 1.0, 0.5, 0.314223213129578, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084271657491214, 0.18156048756776702, 0.18156048756776688, 0.2538209799262817], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.15483], dtype=float32), -1.4715418]. 
=============================================
[2019-03-23 16:49:30,745] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9986172e-01 1.3288933e-04 1.5445094e-08 6.1650255e-08 5.3917679e-06], sum to 1.0000
[2019-03-23 16:49:30,756] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6538
[2019-03-23 16:49:30,928] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [13.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4812321493240848, 6.9112, 6.9112, 77.32846344354104, 279905.5844561808, 279905.5844561808, 77750.13778967917], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 463200.0000, 
sim time next is 463800.0000, 
raw observation next is [13.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5289618126337251, 6.911199999999999, 6.9112, 77.32846344354104, 307676.017759894, 307676.0177598943, 81864.88122421503], 
processed observation next is [1.0, 0.34782608695652173, 0.22727272727272727, 1.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.32708830376246445, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1139540806518126, 0.11395408065181271, 0.19967044201028056], 
reward next is 0.8003, 
noisyNet noise sample is [array([0.9720102], dtype=float32), 1.0175174]. 
=============================================
[2019-03-23 16:49:35,540] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 8.8797525e-10 8.3274661e-17 1.5461157e-14 3.1189656e-10], sum to 1.0000
[2019-03-23 16:49:35,547] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1089
[2019-03-23 16:49:35,553] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 634998.735019295 W.
[2019-03-23 16:49:35,711] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [17.16666666666667, 87.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7739287885129212, 7.479979725588406, 6.9112, 77.32688701205221, 634998.735019295, 450274.4796029481, 127959.5614640706], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 555000.0000, 
sim time next is 555600.0000, 
raw observation next is [17.33333333333334, 86.33333333333334, 1.0, 1.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3295103720970705, 6.9112, 6.9112, 77.3421103, 571886.6885779495, 571886.6885779495, 195662.5030303659], 
processed observation next is [1.0, 0.43478260869565216, 0.42424242424242453, 0.8633333333333334, 1.0, 0.5, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.04215767442438647, 0.0, 0.0, 0.5085185399722538, 0.21180988465849981, 0.21180988465849981, 0.4772256171472339], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.2974562], dtype=float32), -1.5802623]. 
=============================================
[2019-03-23 16:49:36,246] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.9999988e-01 2.0251587e-08 3.4733812e-15 9.3278727e-12 6.1456589e-08], sum to 1.0000
[2019-03-23 16:49:36,252] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5697
[2019-03-23 16:49:36,260] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 561286.9514866258 W.
[2019-03-23 16:49:36,420] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333334, 79.66666666666667, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 1.0, 0.3235753073422217, 6.9112, 6.9112, 77.3421103, 561286.9514866258, 561286.9514866258, 194887.4764475608], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 559200.0000, 
sim time next is 559800.0000, 
raw observation next is [18.5, 78.0, 1.0, 2.0, 0.5110382823036878, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354043, 558782.7776095867, 558782.7776095867, 129029.8645275855], 
processed observation next is [1.0, 0.4782608695652174, 0.4772727272727273, 0.78, 1.0, 1.0, 0.38879785287960966, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206501, 0.20695658429984692, 0.20695658429984692, 0.31470698665264757], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3209691], dtype=float32), 0.046056062]. 
=============================================
[2019-03-23 16:49:37,827] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1000, global step 15785: loss 0.1030
[2019-03-23 16:49:37,829] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1000, global step 15785: learning rate 0.0000
[2019-03-23 16:49:37,983] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1000, global step 15861: loss 0.1249
[2019-03-23 16:49:37,985] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1000, global step 15861: learning rate 0.0000
[2019-03-23 16:49:38,014] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1000, global step 15875: loss 0.0518
[2019-03-23 16:49:38,016] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1000, global step 15877: learning rate 0.0000
[2019-03-23 16:49:38,074] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1000, global step 15905: loss 0.0754
[2019-03-23 16:49:38,077] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1000, global step 15906: learning rate 0.0000
[2019-03-23 16:49:38,090] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1000, global step 15915: loss 0.0444
[2019-03-23 16:49:38,091] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1000, global step 15916: learning rate 0.0000
[2019-03-23 16:49:38,137] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1000, global step 15939: loss 0.0298
[2019-03-23 16:49:38,143] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1000, global step 15939: learning rate 0.0000
[2019-03-23 16:49:38,157] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1000, global step 15950: loss 0.0498
[2019-03-23 16:49:38,160] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1000, global step 15950: learning rate 0.0000
[2019-03-23 16:49:38,209] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1000, global step 15975: loss 0.0007
[2019-03-23 16:49:38,211] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1000, global step 15975: learning rate 0.0000
[2019-03-23 16:49:38,245] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1000, global step 15992: loss 0.0016
[2019-03-23 16:49:38,248] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1000, global step 15993: learning rate 0.0000
[2019-03-23 16:49:38,261] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1000, global step 16000: loss 0.0095
[2019-03-23 16:49:38,264] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1000, global step 16000: learning rate 0.0000
[2019-03-23 16:49:38,295] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1000, global step 16019: loss 0.0007
[2019-03-23 16:49:38,298] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1000, global step 16020: learning rate 0.0000
[2019-03-23 16:49:38,345] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1000, global step 16044: loss 0.0024
[2019-03-23 16:49:38,346] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1000, global step 16044: learning rate 0.0000
[2019-03-23 16:49:38,387] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1000, global step 16064: loss 0.0011
[2019-03-23 16:49:38,390] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1000, global step 16065: learning rate 0.0000
[2019-03-23 16:49:38,466] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1000, global step 16105: loss 0.0214
[2019-03-23 16:49:38,471] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1000, global step 16107: learning rate 0.0000
[2019-03-23 16:49:38,595] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1000, global step 16166: loss 0.0200
[2019-03-23 16:49:38,596] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1000, global step 16166: learning rate 0.0000
[2019-03-23 16:49:38,671] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1000, global step 16205: loss 0.0045
[2019-03-23 16:49:38,673] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1000, global step 16205: learning rate 0.0000
[2019-03-23 16:49:39,915] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 7.0935246e-12 1.8605956e-20 2.5171831e-17 2.1070784e-11], sum to 1.0000
[2019-03-23 16:49:39,923] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6278
[2019-03-23 16:49:39,929] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4438799533322897, 6.911199999999999, 6.9112, 77.32846344354104, 258174.1535656486, 258174.1535656489, 81258.79662806139], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 622800.0000, 
sim time next is 623400.0000, 
raw observation next is [14.16666666666667, 99.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5177576194415172, 6.911199999999999, 6.9112, 77.32846344354104, 301156.9669972641, 301156.9669972644, 87093.27560925046], 
processed observation next is [1.0, 0.21739130434782608, 0.28030303030303044, 0.9900000000000001, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3110823134878818, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11153961740639412, 0.11153961740639423, 0.21242262343719623], 
reward next is 0.7876, 
noisyNet noise sample is [array([-0.2732994], dtype=float32), -1.130886]. 
=============================================
[2019-03-23 16:49:41,472] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 3.7640550e-11 2.9914890e-16 1.6674624e-15 1.1146662e-11], sum to 1.0000
[2019-03-23 16:49:41,476] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6484
[2019-03-23 16:49:41,480] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 929560.7746480919 W.
[2019-03-23 16:49:41,637] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.5, 53.5, 1.0, 2.0, 0.2727667784000494, 1.0, 2.0, 0.2727667784000494, 1.0, 1.0, 0.5425258838082245, 6.911199999999999, 6.9112, 77.3421103, 929560.7746480919, 929560.7746480921, 236144.1836655238], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 657000.0000, 
sim time next is 657600.0000, 
raw observation next is [24.66666666666666, 52.33333333333333, 1.0, 2.0, 0.4256842898998994, 1.0, 2.0, 0.4256842898998994, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 966501.2035378444, 966501.2035378444, 201818.0556857256], 
processed observation next is [1.0, 0.6086956521739131, 0.7575757575757573, 0.5233333333333333, 1.0, 1.0, 0.28210536237487427, 1.0, 1.0, 0.28210536237487427, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.35796340871772014, 0.35796340871772014, 0.4922391602090868], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5119712], dtype=float32), 0.08630663]. 
=============================================
[2019-03-23 16:49:43,418] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.5852243e-11 2.9217743e-19 6.4331722e-18 3.9287396e-11], sum to 1.0000
[2019-03-23 16:49:43,424] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8860
[2019-03-23 16:49:43,579] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.0, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6853175252156101, 6.911199999999999, 6.9112, 77.32846344354104, 395550.0266130154, 395550.0266130157, 123339.375734919], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 689400.0000, 
sim time next is 690000.0000, 
raw observation next is [19.66666666666667, 79.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6780772073525996, 6.9112, 6.9112, 77.32846344354104, 391578.1915700895, 391578.1915700895, 122474.8336776289], 
processed observation next is [1.0, 1.0, 0.5303030303030305, 0.7966666666666665, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5401102962179994, 0.0, 0.0, 0.5084288129206541, 0.14502895984077388, 0.14502895984077388, 0.2987191065308022], 
reward next is 0.7013, 
noisyNet noise sample is [array([-0.34169245], dtype=float32), -0.24235266]. 
=============================================
[2019-03-23 16:49:43,607] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[71.807274]
 [71.73385 ]
 [71.634224]
 [71.56115 ]
 [71.413376]], R is [[71.86650848]
 [71.84701538]
 [71.82575226]
 [71.80311584]
 [71.78022003]].
[2019-03-23 16:49:43,756] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.1066396e-11 5.7258650e-18 4.4183333e-17 8.0352963e-10], sum to 1.0000
[2019-03-23 16:49:43,766] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3685
[2019-03-23 16:49:43,771] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6092142073165427, 6.9112, 6.9112, 77.32846344354104, 353608.555563543, 353608.555563543, 114820.3696338028], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 698400.0000, 
sim time next is 699000.0000, 
raw observation next is [16.83333333333334, 94.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6929598428213662, 6.9112, 6.9112, 77.32846344354104, 402443.0864548155, 402443.0864548155, 122222.1861405306], 
processed observation next is [1.0, 0.08695652173913043, 0.40151515151515177, 0.9400000000000002, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5613712040305232, 0.0, 0.0, 0.5084288129206541, 0.14905299498326502, 0.14905299498326502, 0.2981028930256844], 
reward next is 0.7019, 
noisyNet noise sample is [array([-0.19150718], dtype=float32), -0.16496801]. 
=============================================
[2019-03-23 16:49:43,790] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[68.055855]
 [68.70218 ]
 [68.908005]
 [69.007195]
 [69.60726 ]], R is [[68.33117676]
 [68.36781311]
 [68.40313721]
 [68.43714905]
 [68.46983337]].
[2019-03-23 16:49:46,094] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 7.9516671e-11 7.4739281e-16 2.9027514e-14 2.9263444e-10], sum to 1.0000
[2019-03-23 16:49:46,104] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8943
[2019-03-23 16:49:46,112] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1377788.876877293 W.
[2019-03-23 16:49:46,260] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 55.0, 1.0, 2.0, 0.6067567381961994, 1.0, 1.0, 0.6067567381961994, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1377788.876877293, 1377788.876877292, 260102.2962104497], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 745800.0000, 
sim time next is 746400.0000, 
raw observation next is [28.0, 55.0, 1.0, 2.0, 0.6276290317895168, 1.0, 2.0, 0.6276290317895168, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1424006.287097626, 1424006.287097626, 266470.4838952661], 
processed observation next is [1.0, 0.6521739130434783, 0.9090909090909091, 0.55, 1.0, 1.0, 0.5345362897368959, 1.0, 1.0, 0.5345362897368959, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5274097359620836, 0.5274097359620836, 0.649928009500649], 
reward next is 0.3501, 
noisyNet noise sample is [array([-0.23144789], dtype=float32), 1.5320497]. 
=============================================
[2019-03-23 16:49:53,388] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9997389e-01 2.5060452e-05 2.2112228e-07 3.6291988e-07 5.1251703e-07], sum to 1.0000
[2019-03-23 16:49:53,394] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6901
[2019-03-23 16:49:53,549] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7550331762229091, 7.24047005076191, 6.9112, 77.3274875366937, 540569.7737055583, 433630.945570266, 132274.3372661298], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 880200.0000, 
sim time next is 880800.0000, 
raw observation next is [19.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7632890838927141, 7.310606865158291, 6.9112, 77.32724153898992, 568221.9649133446, 438504.8341487557, 133124.882901864], 
processed observation next is [0.0, 0.17391304347826086, 0.5, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6618415484181631, 0.03994068651582907, 0.0, 0.5084207789904198, 0.21045257959753502, 0.16240919783287247, 0.32469483634600976], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.27132985], dtype=float32), -0.9209129]. 
=============================================
[2019-03-23 16:49:54,320] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1500, global step 23773: loss 1.6692
[2019-03-23 16:49:54,321] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1500, global step 23773: learning rate 0.0000
[2019-03-23 16:49:54,455] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1500, global step 23845: loss -31.1979
[2019-03-23 16:49:54,455] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1500, global step 23845: learning rate 0.0000
[2019-03-23 16:49:54,583] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1500, global step 23912: loss 9.3910
[2019-03-23 16:49:54,586] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1500, global step 23914: loss -4.8922
[2019-03-23 16:49:54,587] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1500, global step 23913: learning rate 0.0000
[2019-03-23 16:49:54,589] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1500, global step 23914: learning rate 0.0000
[2019-03-23 16:49:54,602] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1500, global step 23920: loss -42.2261
[2019-03-23 16:49:54,603] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1500, global step 23920: learning rate 0.0000
[2019-03-23 16:49:54,607] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1500, global step 23920: loss -21.6672
[2019-03-23 16:49:54,610] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1500, global step 23920: learning rate 0.0000
[2019-03-23 16:49:54,623] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1500, global step 23927: loss -61.8285
[2019-03-23 16:49:54,625] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1500, global step 23927: learning rate 0.0000
[2019-03-23 16:49:54,691] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1500, global step 23959: loss -2.1187
[2019-03-23 16:49:54,693] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1500, global step 23959: learning rate 0.0000
[2019-03-23 16:49:54,747] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1500, global step 23990: loss -7.9874
[2019-03-23 16:49:54,751] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1500, global step 23990: learning rate 0.0000
[2019-03-23 16:49:54,762] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1500, global step 23994: loss -5.8243
[2019-03-23 16:49:54,766] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1500, global step 23994: learning rate 0.0000
[2019-03-23 16:49:54,796] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1500, global step 24009: loss -25.8207
[2019-03-23 16:49:54,799] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1500, global step 24009: learning rate 0.0000
[2019-03-23 16:49:54,885] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1500, global step 24055: loss -46.4991
[2019-03-23 16:49:54,886] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1500, global step 24055: learning rate 0.0000
[2019-03-23 16:49:54,949] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1500, global step 24088: loss -26.1995
[2019-03-23 16:49:54,950] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1500, global step 24088: learning rate 0.0000
[2019-03-23 16:49:55,004] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1500, global step 24112: loss -10.5239
[2019-03-23 16:49:55,006] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1500, global step 24112: learning rate 0.0000
[2019-03-23 16:49:55,162] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1500, global step 24189: loss -39.0697
[2019-03-23 16:49:55,165] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1500, global step 24189: loss -12.7689
[2019-03-23 16:49:55,165] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1500, global step 24189: learning rate 0.0000
[2019-03-23 16:49:55,167] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1500, global step 24191: learning rate 0.0000
[2019-03-23 16:49:56,761] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 16:49:56,770] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:49:56,771] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:49:56,771] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:49:56,773] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:49:56,773] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:49:56,774] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:49:56,775] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:49:56,775] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:49:56,776] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:49:56,777] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:49:56,789] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run2
[2019-03-23 16:49:56,790] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run2
[2019-03-23 16:49:56,836] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run2
[2019-03-23 16:49:56,863] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run2
[2019-03-23 16:49:56,863] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run2
[2019-03-23 16:50:18,136] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00257053], dtype=float32), 0.003556985]
[2019-03-23 16:50:18,138] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.0, 83.0, 1.0, 2.0, 0.5173895005407687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588991.8875350053, 588991.8875350053, 145248.3893840361]
[2019-03-23 16:50:18,140] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:50:18,144] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.9999571e-01 3.7470395e-06 1.7858113e-07 2.0686359e-07 2.6203605e-07], sampled 0.6437279799838945
[2019-03-23 16:50:18,147] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 588991.8875350053 W.
[2019-03-23 16:50:24,073] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00257053], dtype=float32), 0.003556985]
[2019-03-23 16:50:24,075] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.45, 85.5, 1.0, 2.0, 0.8307922547792903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 948221.5423494972, 948221.5423494969, 191376.8900504787]
[2019-03-23 16:50:24,076] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:50:24,080] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.9999666e-01 2.8546344e-06 1.2438281e-07 1.4644392e-07 1.8622029e-07], sampled 0.15313634549799493
[2019-03-23 16:50:24,082] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 948221.5423494972 W.
[2019-03-23 16:50:30,998] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00257053], dtype=float32), 0.003556985]
[2019-03-23 16:50:30,999] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.3, 55.5, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7633522803081547, 7.510551956599303, 6.9112, 95.55152325786479, 675190.9741753755, 434661.2060086662, 140213.9453801232]
[2019-03-23 16:50:31,002] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:50:31,006] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.9999583e-01 3.6042698e-06 1.7102607e-07 2.0431420e-07 2.4780655e-07], sampled 0.21083878945624124
[2019-03-23 16:50:31,007] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 675190.9741753755 W.
[2019-03-23 16:50:33,631] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00257053], dtype=float32), 0.003556985]
[2019-03-23 16:50:33,633] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.59601007666667, 41.81464737333334, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.6996712629473788, 7.033382332479681, 6.9112, 95.55292219660298, 451837.644087478, 402803.1526687103, 129830.4232255281]
[2019-03-23 16:50:33,634] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:50:33,636] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.9999738e-01 2.3170921e-06 9.6532148e-08 1.1591129e-07 1.4537119e-07], sampled 0.28687537253230866
[2019-03-23 16:50:46,477] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00257053], dtype=float32), 0.003556985]
[2019-03-23 16:50:46,478] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.23333333333333, 79.0, 1.0, 2.0, 0.5070424551055538, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8830397853212802, 7.033226963058355, 6.9112, 95.55292835895122, 1126754.888399471, 1077782.747031774, 250078.3894429258]
[2019-03-23 16:50:46,480] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:50:46,483] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.9999845e-01 1.3585819e-06 4.7559428e-08 5.6828863e-08 7.3134956e-08], sampled 0.29078949268106047
[2019-03-23 16:50:46,484] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1126754.888399471 W.
[2019-03-23 16:51:08,669] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00257053], dtype=float32), 0.003556985]
[2019-03-23 16:51:08,670] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.13333333333334, 52.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.69539190091295, 7.014599337703224, 6.9112, 95.55289088194347, 443045.620196086, 401549.1765382361, 128499.5231766747]
[2019-03-23 16:51:08,672] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:51:08,675] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.99999523e-01 4.19085978e-07 1.09283045e-08 1.37038452e-08
 1.72653909e-08], sampled 0.09931375547308685
[2019-03-23 16:51:39,033] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6549.5165 1698732195.5514 2958.0000
[2019-03-23 16:51:39,247] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6326.2332 1723321016.9417 3425.0000
[2019-03-23 16:51:39,359] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6479.1493 1678913930.1483 3057.0000
[2019-03-23 16:51:39,371] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6292.7082 1685657231.5103 3227.0000
[2019-03-23 16:51:39,413] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6861.4642 1793018100.3445 2409.0000
[2019-03-23 16:51:40,426] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 25000, evaluation results [25000.0, 6861.4642441583155, 1793018100.344515, 2409.0, 6479.149349332589, 1678913930.1482782, 3057.0, 6292.708181723208, 1685657231.5103364, 3227.0, 6326.233243074557, 1723321016.9417222, 3425.0, 6549.516545157779, 1698732195.5514169, 2958.0]
[2019-03-23 16:51:45,655] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9999988e-01 9.0768580e-08 2.5197604e-11 1.8801435e-10 9.2773081e-11], sum to 1.0000
[2019-03-23 16:51:45,662] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2896
[2019-03-23 16:51:45,667] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [13.0, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.375601218963116, 6.911200000000001, 6.9112, 77.32846344354104, 218452.2356983836, 218452.2356983833, 69034.64648799946], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1045800.0000, 
sim time next is 1046400.0000, 
raw observation next is [13.0, 98.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3662240626496008, 6.911199999999999, 6.9112, 77.32846344354104, 212997.2234048789, 212997.2234048792, 68112.82805278189], 
processed observation next is [1.0, 0.08695652173913043, 0.22727272727272727, 0.98, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.094605803785144, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07888786052032552, 0.07888786052032562, 0.1661288489092241], 
reward next is 0.8339, 
noisyNet noise sample is [array([-0.05407815], dtype=float32), -0.32920957]. 
=============================================
[2019-03-23 16:51:50,817] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.5313532e-14 1.2340334e-17 7.3018459e-18 4.9863284e-17], sum to 1.0000
[2019-03-23 16:51:50,824] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7925
[2019-03-23 16:51:50,830] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6730235167911011, 6.9112, 6.9112, 77.32846344354104, 388736.9538735235, 388736.9538735235, 121927.7510104475], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1139400.0000, 
sim time next is 1140000.0000, 
raw observation next is [18.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6657038810378997, 6.911199999999999, 6.9112, 77.32846344354104, 384502.2080792284, 384502.2080792287, 121231.5375821202], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5224341157684281, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14240822521452903, 0.14240822521452914, 0.2956866770295615], 
reward next is 0.7043, 
noisyNet noise sample is [array([0.08233982], dtype=float32), -0.96670496]. 
=============================================
[2019-03-23 16:51:50,842] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[62.569496]
 [62.437813]
 [62.288868]
 [62.19133 ]
 [62.063976]], R is [[62.77773666]
 [62.85257339]
 [62.92876053]
 [63.00275803]
 [63.08070755]].
[2019-03-23 16:51:53,167] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2000, global step 31779: loss 56.9870
[2019-03-23 16:51:53,169] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2000, global step 31779: learning rate 0.0000
[2019-03-23 16:51:53,278] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2000, global step 31834: loss -59.8058
[2019-03-23 16:51:53,279] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2000, global step 31834: learning rate 0.0000
[2019-03-23 16:51:53,358] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2000, global step 31875: loss 7.8111
[2019-03-23 16:51:53,360] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2000, global step 31875: learning rate 0.0000
[2019-03-23 16:51:53,451] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2000, global step 31923: loss -128.0160
[2019-03-23 16:51:53,453] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2000, global step 31923: learning rate 0.0000
[2019-03-23 16:51:53,478] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2000, global step 31941: loss 64.0961
[2019-03-23 16:51:53,478] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2000, global step 31941: loss 79.0833
[2019-03-23 16:51:53,481] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2000, global step 31943: learning rate 0.0000
[2019-03-23 16:51:53,482] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2000, global step 31943: learning rate 0.0000
[2019-03-23 16:51:53,497] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2000, global step 31948: loss 23.9301
[2019-03-23 16:51:53,499] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2000, global step 31948: learning rate 0.0000
[2019-03-23 16:51:53,531] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2000, global step 31962: loss 20.3448
[2019-03-23 16:51:53,533] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2000, global step 31962: learning rate 0.0000
[2019-03-23 16:51:53,539] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2000, global step 31963: loss 48.5100
[2019-03-23 16:51:53,540] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2000, global step 31963: learning rate 0.0000
[2019-03-23 16:51:53,671] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2000, global step 32036: loss -30.2061
[2019-03-23 16:51:53,672] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2000, global step 32036: learning rate 0.0000
[2019-03-23 16:51:53,727] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2000, global step 32065: loss -24.5729
[2019-03-23 16:51:53,728] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2000, global step 32066: learning rate 0.0000
[2019-03-23 16:51:53,742] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2000, global step 32074: loss -47.1489
[2019-03-23 16:51:53,744] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2000, global step 32074: learning rate 0.0000
[2019-03-23 16:51:53,763] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2000, global step 32085: loss 32.9431
[2019-03-23 16:51:53,764] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2000, global step 32085: learning rate 0.0000
[2019-03-23 16:51:53,804] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2000, global step 32105: loss 63.2890
[2019-03-23 16:51:53,805] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2000, global step 32106: learning rate 0.0000
[2019-03-23 16:51:53,819] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2000, global step 32117: loss 54.6662
[2019-03-23 16:51:53,822] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2000, global step 32117: learning rate 0.0000
[2019-03-23 16:51:53,979] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2000, global step 32200: loss 2.6745
[2019-03-23 16:51:53,985] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2000, global step 32200: learning rate 0.0000
[2019-03-23 16:51:57,144] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9999893e-01 1.0191814e-06 2.1719591e-08 1.5461424e-08 4.6157787e-08], sum to 1.0000
[2019-03-23 16:51:57,152] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7650
[2019-03-23 16:51:57,163] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 556416.7832520033 W.
[2019-03-23 16:51:57,165] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 62.0, 1.0, 2.0, 0.2444804701168305, 1.0, 1.0, 0.2444804701168305, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 556416.7832520033, 556416.783252003, 179409.1309875688], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1273200.0000, 
sim time next is 1273800.0000, 
raw observation next is [27.0, 62.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 1.0, 0.3330074035697294, 6.911199999999999, 6.9112, 77.3421103, 560738.8275420098, 560738.82754201, 212005.9295990345], 
processed observation next is [1.0, 0.7391304347826086, 0.8636363636363636, 0.62, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.047153433671042036, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.20768104723778139, 0.20768104723778147, 0.5170876331683769], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.735393], dtype=float32), -0.21818067]. 
=============================================
[2019-03-23 16:52:07,329] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.7629172e-01 2.0796997e-03 2.0910701e-02 4.5250161e-04 2.6548252e-04], sum to 1.0000
[2019-03-23 16:52:07,338] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1724
[2019-03-23 16:52:07,342] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 548172.7228510617 W.
[2019-03-23 16:52:07,506] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.2403218957812459, 0.0, 1.0, 0.0, 1.0, 2.0, 0.4858526742921293, 6.9112, 6.9112, 77.32846344354104, 548172.7228510617, 548172.7228510617, 176160.0075114464], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1477200.0000, 
sim time next is 1477800.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.240034805284897, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4850981991509531, 6.9112, 6.9112, 77.32846344354104, 547607.4659378562, 547607.4659378562, 175872.899039504], 
processed observation next is [0.0, 0.08695652173913043, 0.5909090909090909, 1.0, 1.0, 1.0, 0.05004350660612125, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2644259987870759, 0.0, 0.0, 0.5084288129206541, 0.2028175799769838, 0.2028175799769838, 0.4289582903402537], 
reward next is 0.5710, 
noisyNet noise sample is [array([-0.99015564], dtype=float32), 2.8465204]. 
=============================================
[2019-03-23 16:52:08,441] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 39738: loss 24.5512
[2019-03-23 16:52:08,443] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2500, global step 39739: learning rate 0.0000
[2019-03-23 16:52:08,581] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2500, global step 39807: loss 28.9218
[2019-03-23 16:52:08,585] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2500, global step 39810: learning rate 0.0000
[2019-03-23 16:52:08,667] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 39848: loss 17.7360
[2019-03-23 16:52:08,669] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2500, global step 39848: learning rate 0.0000
[2019-03-23 16:52:08,759] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2500, global step 39896: loss 19.6388
[2019-03-23 16:52:08,761] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2500, global step 39896: learning rate 0.0000
[2019-03-23 16:52:08,785] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2500, global step 39909: loss 5.7863
[2019-03-23 16:52:08,790] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2500, global step 39910: learning rate 0.0000
[2019-03-23 16:52:08,805] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2500, global step 39916: loss 8.9019
[2019-03-23 16:52:08,806] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2500, global step 39916: learning rate 0.0000
[2019-03-23 16:52:08,807] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2500, global step 39917: loss 28.9792
[2019-03-23 16:52:08,812] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2500, global step 39918: learning rate 0.0000
[2019-03-23 16:52:08,954] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 39989: loss 35.1233
[2019-03-23 16:52:08,956] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2500, global step 39990: learning rate 0.0000
[2019-03-23 16:52:09,005] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2500, global step 40009: loss 28.3813
[2019-03-23 16:52:09,006] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2500, global step 40009: learning rate 0.0000
[2019-03-23 16:52:09,007] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2500, global step 40010: loss 16.4622
[2019-03-23 16:52:09,010] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2500, global step 40011: learning rate 0.0000
[2019-03-23 16:52:09,071] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 40046: loss 50.1037
[2019-03-23 16:52:09,072] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2500, global step 40046: learning rate 0.0000
[2019-03-23 16:52:09,143] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 40081: loss 5.8954
[2019-03-23 16:52:09,147] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2500, global step 40081: learning rate 0.0000
[2019-03-23 16:52:09,226] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2500, global step 40123: loss 30.8634
[2019-03-23 16:52:09,227] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2500, global step 40123: learning rate 0.0000
[2019-03-23 16:52:09,271] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2500, global step 40145: loss -14.3272
[2019-03-23 16:52:09,273] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2500, global step 40145: learning rate 0.0000
[2019-03-23 16:52:09,295] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2500, global step 40155: loss 22.2678
[2019-03-23 16:52:09,297] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2500, global step 40155: learning rate 0.0000
[2019-03-23 16:52:09,410] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2500, global step 40212: loss 8.0278
[2019-03-23 16:52:09,412] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2500, global step 40212: learning rate 0.0000
[2019-03-23 16:52:09,846] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.3718015e-01 9.3202936e-03 3.5278600e-01 2.3575856e-04 4.7785544e-04], sum to 1.0000
[2019-03-23 16:52:09,852] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6819
[2019-03-23 16:52:09,855] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.5171940911991629, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588677.044754659, 588677.044754659, 145290.7311498038], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1525200.0000, 
sim time next is 1525800.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.258621957950223, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5238033827669237, 6.911199999999999, 6.9112, 77.32846344354104, 588453.6895724321, 588453.6895724324, 182240.8100748603], 
processed observation next is [0.0, 0.6521739130434783, 0.7272727272727273, 0.83, 1.0, 1.0, 0.07327744743777877, 0.0, 1.0, -0.25, 1.0, 0.5, 0.3197191182384625, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21794581095275262, 0.21794581095275276, 0.44448978067039097], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2861557], dtype=float32), -0.06448656]. 
=============================================
[2019-03-23 16:52:22,198] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.2044461e-03 1.5784371e-04 9.9459606e-01 2.9048118e-05 1.2652601e-05], sum to 1.0000
[2019-03-23 16:52:22,204] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9913
[2019-03-23 16:52:22,207] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [11.0, 71.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3596650804391304, 6.9112, 6.9112, 77.32846344354104, 418453.3476211993, 418453.3476211993, 117512.7746420495], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1753200.0000, 
sim time next is 1753800.0000, 
raw observation next is [11.16666666666667, 70.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3608229193172092, 6.9112, 6.9112, 77.32846344354104, 419801.0200664458, 419801.0200664458, 117785.4449723327], 
processed observation next is [1.0, 0.30434782608695654, 0.14393939393939406, 0.7033333333333335, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.08688988473887034, 0.0, 0.0, 0.5084288129206541, 0.15548185928386882, 0.15548185928386882, 0.2872815731032505], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.24794747], dtype=float32), -1.0878478]. 
=============================================
[2019-03-23 16:52:24,413] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3000, global step 47759: loss 0.0006
[2019-03-23 16:52:24,414] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3000, global step 47759: learning rate 0.0000
[2019-03-23 16:52:24,481] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3000, global step 47789: loss 1.9332
[2019-03-23 16:52:24,483] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3000, global step 47789: learning rate 0.0000
[2019-03-23 16:52:24,530] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3000, global step 47816: loss 0.1161
[2019-03-23 16:52:24,533] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3000, global step 47816: learning rate 0.0000
[2019-03-23 16:52:24,603] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3000, global step 47850: loss 0.0159
[2019-03-23 16:52:24,604] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3000, global step 47850: learning rate 0.0000
[2019-03-23 16:52:24,616] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3000, global step 47858: loss 1.5830
[2019-03-23 16:52:24,618] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3000, global step 47858: learning rate 0.0000
[2019-03-23 16:52:24,705] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3000, global step 47905: loss -0.0291
[2019-03-23 16:52:24,706] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3000, global step 47905: learning rate 0.0000
[2019-03-23 16:52:24,730] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3000, global step 47918: loss 0.0627
[2019-03-23 16:52:24,733] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3000, global step 47918: learning rate 0.0000
[2019-03-23 16:52:24,795] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3000, global step 47946: loss 0.1118
[2019-03-23 16:52:24,799] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3000, global step 47946: learning rate 0.0000
[2019-03-23 16:52:24,811] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3000, global step 47954: loss 0.0817
[2019-03-23 16:52:24,814] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3000, global step 47954: learning rate 0.0000
[2019-03-23 16:52:24,865] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3000, global step 47981: loss 3.2317
[2019-03-23 16:52:24,869] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3000, global step 47982: learning rate 0.0000
[2019-03-23 16:52:25,056] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3000, global step 48074: loss 0.0137
[2019-03-23 16:52:25,059] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3000, global step 48075: learning rate 0.0000
[2019-03-23 16:52:25,120] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3000, global step 48106: loss 1.8243
[2019-03-23 16:52:25,123] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3000, global step 48106: learning rate 0.0000
[2019-03-23 16:52:25,223] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3000, global step 48157: loss 0.0232
[2019-03-23 16:52:25,226] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3000, global step 48158: learning rate 0.0000
[2019-03-23 16:52:25,264] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3000, global step 48180: loss 1.8743
[2019-03-23 16:52:25,266] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3000, global step 48180: learning rate 0.0000
[2019-03-23 16:52:25,411] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3000, global step 48254: loss 2.4278
[2019-03-23 16:52:25,415] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3000, global step 48254: learning rate 0.0000
[2019-03-23 16:52:25,456] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3000, global step 48278: loss 0.0042
[2019-03-23 16:52:25,458] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3000, global step 48278: learning rate 0.0000
[2019-03-23 16:52:25,625] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.4987855e-02 8.3877128e-03 9.3555737e-01 6.1492855e-04 4.5197748e-04], sum to 1.0000
[2019-03-23 16:52:25,634] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2121
[2019-03-23 16:52:25,794] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.0, 70.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 206426.9932607347, 206426.993260735, 87166.53022586845], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1816800.0000, 
sim time next is 1817400.0000, 
raw observation next is [14.0, 71.16666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 206592.9915732061, 206592.9915732061, 87318.13768813632], 
processed observation next is [1.0, 0.0, 0.2727272727272727, 0.7116666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.07651592280489114, 0.07651592280489114, 0.21297106753203981], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0215107], dtype=float32), 0.90822256]. 
=============================================
[2019-03-23 16:52:29,023] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 16:52:29,023] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:52:29,024] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:52:29,025] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:52:29,025] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:52:29,025] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:52:29,027] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:52:29,027] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:52:29,026] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:52:29,028] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:52:29,028] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:52:29,043] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run3
[2019-03-23 16:52:29,044] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run3
[2019-03-23 16:52:29,099] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run3
[2019-03-23 16:52:29,100] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run3
[2019-03-23 16:52:29,100] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run3
[2019-03-23 16:52:32,532] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00296545], dtype=float32), 0.0042362968]
[2019-03-23 16:52:32,534] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.2, 48.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 258809.2931236214, 258809.293123621, 101446.3214985426]
[2019-03-23 16:52:32,536] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:52:32,539] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.3702860e-01 4.1860431e-03 2.5861344e-01 1.3258419e-04 3.9389732e-05], sampled 0.9676942135445189
[2019-03-23 16:52:45,226] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00296545], dtype=float32), 0.0042362968]
[2019-03-23 16:52:45,227] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.85895023, 81.08199768, 1.0, 1.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 95.55338769695034, 258864.0226341276, 258864.0226341279, 114407.5402775931]
[2019-03-23 16:52:45,230] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:52:45,234] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.3945498e-01 2.7297805e-03 2.5773671e-01 6.2048181e-05 1.6452801e-05], sampled 0.6300979118080514
[2019-03-23 16:52:55,204] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00296545], dtype=float32), 0.0042362968]
[2019-03-23 16:52:55,205] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.46666666666667, 59.0, 1.0, 2.0, 0.5440558621693246, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8977688768055958, 7.018742741961156, 6.9112, 95.55296395732267, 1167640.966315656, 1124481.649780414, 260193.7455612164]
[2019-03-23 16:52:55,206] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:52:55,211] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.5558680e-01 1.0137723e-03 2.4338621e-01 1.0897671e-05 2.3492489e-06], sampled 0.3759956085690572
[2019-03-23 16:52:55,211] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1167640.966315656 W.
[2019-03-23 16:53:29,045] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00296545], dtype=float32), 0.0042362968]
[2019-03-23 16:53:29,046] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.71526577333334, 65.51077541666666, 1.0, 1.0, 0.498534483544151, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 95.55305797796622, 567872.9957106103, 567872.9957106103, 142931.1406633419]
[2019-03-23 16:53:29,046] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:53:29,049] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.1566308e-01 3.2248893e-03 2.8100470e-01 8.4436433e-05 2.2922486e-05], sampled 0.7408176496344675
[2019-03-23 16:53:38,258] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00296545], dtype=float32), 0.0042362968]
[2019-03-23 16:53:38,260] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.66666666666667, 53.33333333333334, 1.0, 2.0, 0.2129756123171528, 0.0, 2.0, 0.0, 1.0, 1.0, 0.4265255883283244, 6.9112, 6.9112, 77.32846203138364, 485206.2913930615, 485206.2913930615, 166750.5878304595]
[2019-03-23 16:53:38,261] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:53:38,264] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.2639012e-01 3.0306387e-03 2.7047783e-01 8.0061262e-05 2.1395170e-05], sampled 0.7921301974172974
[2019-03-23 16:54:11,348] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 4571.5305 1790925877.3630 2503.0000
[2019-03-23 16:54:11,378] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 4321.3051 1827226342.7311 2955.0000
[2019-03-23 16:54:11,427] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 4581.4650 1805905243.4938 2421.0000
[2019-03-23 16:54:11,428] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 4403.6591 1795921949.5594 2605.0000
[2019-03-23 16:54:11,428] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 4865.6937 1893652474.2633 1995.0000
[2019-03-23 16:54:12,443] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 50000, evaluation results [50000.0, 4865.6937450520345, 1893652474.2632594, 1995.0, 4571.530494740559, 1790925877.3630323, 2503.0, 4403.659128261812, 1795921949.5594099, 2605.0, 4321.305078925505, 1827226342.7311335, 2955.0, 4581.464984563301, 1805905243.4938385, 2421.0]
[2019-03-23 16:54:12,594] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.3243612e-01 1.1554149e-03 2.6613042e-01 2.3343859e-04 4.4536435e-05], sum to 1.0000
[2019-03-23 16:54:12,604] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6948
[2019-03-23 16:54:12,787] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 47.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5786718322630724, 6.9112, 6.9112, 77.32846344354104, 336597.2634253992, 336597.2634253992, 107730.0037346133], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1879200.0000, 
sim time next is 1879800.0000, 
raw observation next is [22.83333333333334, 46.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5808534650081089, 6.911200000000001, 6.9112, 77.32846344354104, 337868.7667345246, 337868.7667345243, 106258.7387096688], 
processed observation next is [1.0, 0.782608695652174, 0.6742424242424245, 0.46833333333333343, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4012192357258698, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12513658027204613, 0.12513658027204602, 0.2591676553894361], 
reward next is 0.7408, 
noisyNet noise sample is [array([-1.0259699], dtype=float32), 0.97953206]. 
=============================================
[2019-03-23 16:54:15,107] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9839908e-01 5.8996164e-07 1.6002837e-03 4.3144177e-10 1.3331790e-09], sum to 1.0000
[2019-03-23 16:54:15,119] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1785
[2019-03-23 16:54:15,125] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 612818.5926502382 W.
[2019-03-23 16:54:15,130] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.16666666666667, 99.00000000000001, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7807958945315492, 7.423721224857692, 6.9112, 77.32724781025702, 612818.5926502382, 446364.7984473719, 136770.5649491497], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1926600.0000, 
sim time next is 1927200.0000, 
raw observation next is [19.33333333333334, 98.0, 1.0, 1.0, 0.2365841829430361, 1.0, 1.0, 0.2365841829430361, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32815545132637, 538765.9606962835, 538765.9606962835, 172030.3396876168], 
processed observation next is [1.0, 0.30434782608695654, 0.5151515151515155, 0.98, 1.0, 0.5, 0.04573022867879511, 1.0, 0.5, 0.04573022867879511, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084267878950798, 0.19954294840603093, 0.19954294840603093, 0.41958619436004096], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.06345236], dtype=float32), -0.92173314]. 
=============================================
[2019-03-23 16:54:16,398] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9336630e-01 5.6856543e-06 6.6280207e-03 6.1842771e-09 3.8293166e-08], sum to 1.0000
[2019-03-23 16:54:16,400] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8532
[2019-03-23 16:54:16,405] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1231768.987246803 W.
[2019-03-23 16:54:16,411] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.16666666666667, 61.0, 1.0, 2.0, 0.3598332897750748, 1.0, 2.0, 0.3598332897750748, 1.0, 2.0, 0.7276883063000846, 6.911199999999999, 6.9112, 77.3421103, 1231768.987246803, 1231768.987246803, 278573.1658737173], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1954200.0000, 
sim time next is 1954800.0000, 
raw observation next is [25.0, 61.0, 1.0, 2.0, 0.5373058323841114, 1.0, 2.0, 0.5373058323841114, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1226874.017211278, 1226874.017211278, 235644.2542662659], 
processed observation next is [1.0, 0.6521739130434783, 0.7727272727272727, 0.61, 1.0, 1.0, 0.4216322904801393, 1.0, 1.0, 0.4216322904801393, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4543977841523252, 0.4543977841523252, 0.5747420835762583], 
reward next is 0.4253, 
noisyNet noise sample is [array([-0.46712846], dtype=float32), 1.0363163]. 
=============================================
[2019-03-23 16:54:17,037] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9583554e-01 3.1630113e-06 4.1612028e-03 6.0323359e-08 1.7326565e-08], sum to 1.0000
[2019-03-23 16:54:17,043] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2605
[2019-03-23 16:54:17,049] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 665301.1464291192 W.
[2019-03-23 16:54:17,054] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 55.83333333333333, 1.0, 2.0, 0.2926116359086862, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5831684882495934, 6.911199999999999, 6.9112, 77.32846344354104, 665301.1464291192, 665301.1464291195, 182829.1076119446], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1962600.0000, 
sim time next is 1963200.0000, 
raw observation next is [25.0, 54.66666666666667, 1.0, 2.0, 0.200550954027444, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3969237646831267, 6.911199999999999, 6.9112, 77.32846344354104, 454154.0615721203, 454154.0615721206, 161609.221669896], 
processed observation next is [1.0, 0.7391304347826086, 0.7727272727272727, 0.5466666666666667, 1.0, 1.0, 0.0006886925343049799, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1384625209758953, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16820520798967417, 0.16820520798967428, 0.3941688333412098], 
reward next is 0.6058, 
noisyNet noise sample is [array([1.447367], dtype=float32), -2.385254]. 
=============================================
[2019-03-23 16:54:23,084] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.1390604e-14 1.6408708e-09 2.0614666e-18 3.6715024e-17], sum to 1.0000
[2019-03-23 16:54:23,092] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8863
[2019-03-23 16:54:23,096] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.0, 77.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4360555198414859, 6.9112, 6.9112, 77.32846344354104, 253622.0372372149, 253622.0372372149, 78276.1863280909], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2080200.0000, 
sim time next is 2080800.0000, 
raw observation next is [16.0, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4267712166385659, 6.9112, 6.9112, 77.32846344354104, 248220.6499281845, 248220.6499281845, 76973.97405587544], 
processed observation next is [0.0, 0.08695652173913043, 0.36363636363636365, 0.77, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.18110173805509414, 0.0, 0.0, 0.5084288129206541, 0.09193357404747574, 0.09193357404747574, 0.18774140013628157], 
reward next is 0.8123, 
noisyNet noise sample is [array([-0.26030055], dtype=float32), 0.86806464]. 
=============================================
[2019-03-23 16:54:23,410] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3500, global step 55734: loss 1.2074
[2019-03-23 16:54:23,410] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3500, global step 55734: loss 0.8652
[2019-03-23 16:54:23,411] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3500, global step 55734: learning rate 0.0000
[2019-03-23 16:54:23,412] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3500, global step 55734: learning rate 0.0000
[2019-03-23 16:54:23,536] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3500, global step 55799: loss 1.0308
[2019-03-23 16:54:23,538] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3500, global step 55799: learning rate 0.0000
[2019-03-23 16:54:23,553] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 3.2544947e-14 1.1094933e-10 3.1113059e-18 1.1480800e-17], sum to 1.0000
[2019-03-23 16:54:23,560] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3283
[2019-03-23 16:54:23,561] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3500, global step 55813: loss 0.8908
[2019-03-23 16:54:23,565] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3500, global step 55813: learning rate 0.0000
[2019-03-23 16:54:23,567] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.33333333333333, 80.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4087054250925485, 6.911199999999999, 6.9112, 77.32846344354104, 237710.5729800045, 237710.5729800048, 73763.86508906662], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2083200.0000, 
sim time next is 2083800.0000, 
raw observation next is [15.16666666666667, 81.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4047837095075635, 6.911199999999999, 6.9112, 77.32846344354104, 235429.0792257683, 235429.0792257686, 73042.98087435399], 
processed observation next is [0.0, 0.08695652173913043, 0.3257575757575759, 0.8116666666666668, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.14969101358223358, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08719595526880308, 0.08719595526880318, 0.17815361188866827], 
reward next is 0.8218, 
noisyNet noise sample is [array([-1.8100312], dtype=float32), 0.12700951]. 
=============================================
[2019-03-23 16:54:23,764] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3500, global step 55923: loss 0.7847
[2019-03-23 16:54:23,769] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3500, global step 55926: loss 0.5754
[2019-03-23 16:54:23,770] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3500, global step 55924: learning rate 0.0000
[2019-03-23 16:54:23,771] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3500, global step 55926: learning rate 0.0000
[2019-03-23 16:54:23,774] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3500, global step 55926: loss 0.8081
[2019-03-23 16:54:23,778] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3500, global step 55927: learning rate 0.0000
[2019-03-23 16:54:23,799] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3500, global step 55940: loss 0.5747
[2019-03-23 16:54:23,801] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3500, global step 55940: learning rate 0.0000
[2019-03-23 16:54:23,844] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3500, global step 55962: loss 0.7431
[2019-03-23 16:54:23,846] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3500, global step 55962: learning rate 0.0000
[2019-03-23 16:54:23,867] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3500, global step 55972: loss 0.6704
[2019-03-23 16:54:23,868] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3500, global step 55972: learning rate 0.0000
[2019-03-23 16:54:24,074] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3500, global step 56084: loss 0.2638
[2019-03-23 16:54:24,075] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3500, global step 56084: learning rate 0.0000
[2019-03-23 16:54:24,111] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3500, global step 56104: loss 0.3601
[2019-03-23 16:54:24,112] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3500, global step 56104: learning rate 0.0000
[2019-03-23 16:54:24,169] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3500, global step 56132: loss 0.2677
[2019-03-23 16:54:24,172] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3500, global step 56132: learning rate 0.0000
[2019-03-23 16:54:24,381] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3500, global step 56251: loss 0.0761
[2019-03-23 16:54:24,388] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3500, global step 56251: learning rate 0.0000
[2019-03-23 16:54:24,403] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3500, global step 56264: loss 0.0802
[2019-03-23 16:54:24,406] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3500, global step 56264: learning rate 0.0000
[2019-03-23 16:54:24,428] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3500, global step 56277: loss 0.0486
[2019-03-23 16:54:24,430] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3500, global step 56277: learning rate 0.0000
[2019-03-23 16:54:35,574] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 6.0929115e-13 1.9167008e-09 2.0210282e-21 3.4894359e-16], sum to 1.0000
[2019-03-23 16:54:35,581] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4201
[2019-03-23 16:54:35,585] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.5, 60.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4256422244659005, 6.911199999999999, 6.9112, 77.32846344354104, 247563.8331610163, 247563.8331610166, 69237.50814414963], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2331000.0000, 
sim time next is 2331600.0000, 
raw observation next is [16.33333333333333, 62.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4203921406578416, 6.9112, 6.9112, 77.32846344354104, 244509.4896483058, 244509.4896483058, 69501.73609089394], 
processed observation next is [1.0, 1.0, 0.37878787878787856, 0.6266666666666666, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.17198877236834514, 0.0, 0.0, 0.5084288129206541, 0.09055907024011327, 0.09055907024011327, 0.16951642948998524], 
reward next is 0.8305, 
noisyNet noise sample is [array([-1.1726142], dtype=float32), 2.4328458]. 
=============================================
[2019-03-23 16:54:36,588] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.9859239e-16 4.0284942e-11 2.5460920e-21 1.6973841e-20], sum to 1.0000
[2019-03-23 16:54:36,597] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0353
[2019-03-23 16:54:36,602] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.33333333333334, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4182076445278311, 6.911200000000001, 6.9112, 77.32846344354104, 243238.6201104992, 243238.6201104989, 74295.07096658985], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2359200.0000, 
sim time next is 2359800.0000, 
raw observation next is [16.5, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4168385481921703, 6.9112, 6.9112, 77.32846344354104, 242442.1255389435, 242442.1255389435, 75205.94847209638], 
processed observation next is [1.0, 0.30434782608695654, 0.38636363636363635, 0.72, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.16691221170310047, 0.0, 0.0, 0.5084288129206541, 0.08979337982923834, 0.08979337982923834, 0.18342914261486923], 
reward next is 0.8166, 
noisyNet noise sample is [array([-0.5117979], dtype=float32), -0.43274093]. 
=============================================
[2019-03-23 16:54:38,048] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 4.6764223e-16 2.6291927e-11 3.7423007e-18 6.5995439e-16], sum to 1.0000
[2019-03-23 16:54:38,053] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5594
[2019-03-23 16:54:38,060] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 779994.9262664826 W.
[2019-03-23 16:54:38,064] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 44.0, 1.0, 2.0, 0.7179897052013201, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 779994.9262664826, 779994.9262664829, 145647.4753796151], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2390400.0000, 
sim time next is 2391000.0000, 
raw observation next is [22.83333333333334, 44.33333333333334, 1.0, 2.0, 0.320162990564884, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5976746537428056, 6.9112, 6.9112, 77.32846344354104, 695563.8134817843, 695563.8134817843, 172077.3965634969], 
processed observation next is [1.0, 0.6956521739130435, 0.6742424242424245, 0.4433333333333334, 1.0, 1.0, 0.150203738206105, 0.0, 1.0, -0.25, 1.0, 0.5, 0.4252495053468652, 0.0, 0.0, 0.5084288129206541, 0.25761622721547567, 0.25761622721547567, 0.41970096722804123], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.30102742], dtype=float32), -1.1583894]. 
=============================================
[2019-03-23 16:54:38,079] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[66.05853 ]
 [64.79869 ]
 [63.886303]
 [65.054695]
 [64.56061 ]], R is [[63.70233154]
 [63.06530762]
 [62.43465424]
 [61.81030655]
 [61.19220352]].
[2019-03-23 16:54:38,168] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4000, global step 63624: loss 34.4454
[2019-03-23 16:54:38,172] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4000, global step 63625: learning rate 0.0000
[2019-03-23 16:54:38,499] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4000, global step 63789: loss 24.3018
[2019-03-23 16:54:38,502] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4000, global step 63789: learning rate 0.0000
[2019-03-23 16:54:38,518] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4000, global step 63797: loss 18.1117
[2019-03-23 16:54:38,520] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4000, global step 63798: learning rate 0.0000
[2019-03-23 16:54:38,615] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4000, global step 63844: loss 38.3316
[2019-03-23 16:54:38,616] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4000, global step 63844: learning rate 0.0000
[2019-03-23 16:54:38,686] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4000, global step 63882: loss 25.3723
[2019-03-23 16:54:38,689] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4000, global step 63883: learning rate 0.0000
[2019-03-23 16:54:38,743] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4000, global step 63913: loss 26.4935
[2019-03-23 16:54:38,745] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4000, global step 63913: learning rate 0.0000
[2019-03-23 16:54:38,759] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4000, global step 63918: loss 22.4743
[2019-03-23 16:54:38,761] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4000, global step 63919: learning rate 0.0000
[2019-03-23 16:54:38,823] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4000, global step 63945: loss 25.0689
[2019-03-23 16:54:38,824] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4000, global step 63945: learning rate 0.0000
[2019-03-23 16:54:38,917] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4000, global step 63998: loss 28.8696
[2019-03-23 16:54:38,918] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4000, global step 63998: learning rate 0.0000
[2019-03-23 16:54:38,923] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4000, global step 63998: loss 21.8564
[2019-03-23 16:54:38,926] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4000, global step 63998: learning rate 0.0000
[2019-03-23 16:54:38,961] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4000, global step 64013: loss 17.2228
[2019-03-23 16:54:38,963] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4000, global step 64013: learning rate 0.0000
[2019-03-23 16:54:39,266] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4000, global step 64165: loss 25.9393
[2019-03-23 16:54:39,271] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4000, global step 64166: learning rate 0.0000
[2019-03-23 16:54:39,271] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4000, global step 64166: loss 27.4026
[2019-03-23 16:54:39,278] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4000, global step 64167: learning rate 0.0000
[2019-03-23 16:54:39,418] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4000, global step 64245: loss 42.4942
[2019-03-23 16:54:39,421] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4000, global step 64245: learning rate 0.0000
[2019-03-23 16:54:39,547] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4000, global step 64306: loss 28.0821
[2019-03-23 16:54:39,550] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4000, global step 64306: learning rate 0.0000
[2019-03-23 16:54:39,667] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4000, global step 64365: loss 32.7299
[2019-03-23 16:54:39,668] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4000, global step 64365: learning rate 0.0000
[2019-03-23 16:54:47,580] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 8.4472509e-14 2.9026079e-10 1.7633003e-17 1.3569152e-15], sum to 1.0000
[2019-03-23 16:54:47,590] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3247
[2019-03-23 16:54:47,595] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 53.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5609736049606584, 6.9112, 6.9112, 77.32846344354104, 326288.0229123495, 326288.0229123495, 107511.6665054851], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2570400.0000, 
sim time next is 2571000.0000, 
raw observation next is [21.83333333333334, 53.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.558953481527163, 6.911199999999999, 6.9112, 77.32846344354104, 325122.0539989887, 325122.053998989, 106573.204156798], 
processed observation next is [1.0, 0.782608695652174, 0.628787878787879, 0.535, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.36993354503880427, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.120415575555181, 0.1204155755551811, 0.2599346442848732], 
reward next is 0.7401, 
noisyNet noise sample is [array([1.2145966], dtype=float32), 1.8038578]. 
=============================================
[2019-03-23 16:54:47,614] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[61.8075  ]
 [60.04882 ]
 [59.03438 ]
 [58.022045]
 [56.351383]], R is [[63.60122299]
 [63.70298767]
 [63.8008461 ]
 [63.89453125]
 [63.98449707]].
[2019-03-23 16:54:49,316] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 4.8838331e-14 5.2077709e-08 9.2730217e-20 8.4900233e-14], sum to 1.0000
[2019-03-23 16:54:49,327] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3452
[2019-03-23 16:54:49,333] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.48333333333333, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5411170984743522, 6.9112, 6.9112, 77.32846344354104, 314743.5077149644, 314743.5077149644, 101174.2920005218], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2602200.0000, 
sim time next is 2602800.0000, 
raw observation next is [16.4, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5283707843680197, 6.911200000000001, 6.9112, 77.32846344354104, 307330.4796111929, 307330.4796111926, 98224.11748190907], 
processed observation next is [0.0, 0.13043478260869565, 0.3818181818181818, 0.88, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3262439776685995, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11382610355970108, 0.11382610355970096, 0.2395710182485587], 
reward next is 0.7604, 
noisyNet noise sample is [array([-1.5788448], dtype=float32), -2.1267855]. 
=============================================
[2019-03-23 16:54:54,035] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4500, global step 71601: loss 1.2046
[2019-03-23 16:54:54,040] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4500, global step 71604: learning rate 0.0000
[2019-03-23 16:54:54,315] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4500, global step 71745: loss 1.0090
[2019-03-23 16:54:54,317] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4500, global step 71745: learning rate 0.0000
[2019-03-23 16:54:54,333] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4500, global step 71752: loss 1.1111
[2019-03-23 16:54:54,335] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4500, global step 71754: learning rate 0.0000
[2019-03-23 16:54:54,433] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4500, global step 71798: loss 1.1551
[2019-03-23 16:54:54,436] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4500, global step 71800: learning rate 0.0000
[2019-03-23 16:54:54,561] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4500, global step 71866: loss 0.8660
[2019-03-23 16:54:54,562] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4500, global step 71866: learning rate 0.0000
[2019-03-23 16:54:54,592] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4500, global step 71879: loss 0.9674
[2019-03-23 16:54:54,594] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4500, global step 71881: loss 0.9682
[2019-03-23 16:54:54,596] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4500, global step 71880: learning rate 0.0000
[2019-03-23 16:54:54,596] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4500, global step 71881: learning rate 0.0000
[2019-03-23 16:54:54,640] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4500, global step 71900: loss 0.7798
[2019-03-23 16:54:54,641] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4500, global step 71902: learning rate 0.0000
[2019-03-23 16:54:54,772] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4500, global step 71970: loss 0.7351
[2019-03-23 16:54:54,776] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4500, global step 71972: learning rate 0.0000
[2019-03-23 16:54:54,881] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4500, global step 72026: loss 0.6760
[2019-03-23 16:54:54,882] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4500, global step 72027: learning rate 0.0000
[2019-03-23 16:54:55,032] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4500, global step 72102: loss 0.5288
[2019-03-23 16:54:55,033] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4500, global step 72102: learning rate 0.0000
[2019-03-23 16:54:55,213] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4500, global step 72193: loss 0.3067
[2019-03-23 16:54:55,213] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4500, global step 72193: learning rate 0.0000
[2019-03-23 16:54:55,256] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4500, global step 72213: loss 0.4381
[2019-03-23 16:54:55,258] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4500, global step 72215: learning rate 0.0000
[2019-03-23 16:54:55,289] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4500, global step 72230: loss 0.3283
[2019-03-23 16:54:55,293] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4500, global step 72230: learning rate 0.0000
[2019-03-23 16:54:55,358] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4500, global step 72262: loss 0.3818
[2019-03-23 16:54:55,362] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4500, global step 72263: learning rate 0.0000
[2019-03-23 16:54:55,437] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4500, global step 72302: loss 0.5367
[2019-03-23 16:54:55,442] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4500, global step 72302: learning rate 0.0000
[2019-03-23 16:55:00,058] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9993551e-01 6.9665967e-10 6.4497173e-05 2.7432654e-13 1.1655950e-10], sum to 1.0000
[2019-03-23 16:55:00,066] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7093
[2019-03-23 16:55:00,071] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1172485.319943224 W.
[2019-03-23 16:55:00,077] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 67.0, 1.0, 2.0, 0.3430825022707207, 1.0, 2.0, 0.3430825022707207, 1.0, 2.0, 0.6947063044532026, 6.911199999999999, 6.9112, 77.3421103, 1172485.319943224, 1172485.319943225, 274232.2632355138], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2802600.0000, 
sim time next is 2803200.0000, 
raw observation next is [25.33333333333333, 66.33333333333333, 1.0, 2.0, 0.5830142792197438, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9713155470131513, 6.911199999999999, 6.9112, 77.32846344354104, 1213499.948188875, 1213499.948188875, 269657.9585967383], 
processed observation next is [1.0, 0.43478260869565216, 0.7878787878787876, 0.6633333333333333, 1.0, 1.0, 0.4787678490246797, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9590222100187876, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.44944442525513895, 0.44944442525513895, 0.6577023380408251], 
reward next is 0.3423, 
noisyNet noise sample is [array([-0.4387882], dtype=float32), -0.42240986]. 
=============================================
[2019-03-23 16:55:00,816] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 16:55:00,817] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:55:00,817] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:55:00,817] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:55:00,818] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:55:00,819] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:55:00,818] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:55:00,820] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:55:00,820] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:55:00,822] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:55:00,822] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:55:00,835] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run4
[2019-03-23 16:55:00,835] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run4
[2019-03-23 16:55:00,859] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run4
[2019-03-23 16:55:00,915] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run4
[2019-03-23 16:55:00,916] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run4
[2019-03-23 16:55:03,870] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00426921], dtype=float32), 0.004886428]
[2019-03-23 16:55:03,871] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.16666666666667, 48.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4588060062170753, 6.9112, 6.9112, 95.55338769695034, 266844.0220200919, 266844.0220200919, 73326.70017816576]
[2019-03-23 16:55:03,872] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:55:03,876] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.9999893e-01 3.4867598e-11 1.0599285e-06 6.3469249e-14 7.5236475e-13], sampled 0.10377784497077847
[2019-03-23 16:55:03,990] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00426921], dtype=float32), 0.004886428]
[2019-03-23 16:55:03,992] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.16666666666667, 54.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4330997993124592, 6.911199999999999, 6.9112, 95.55338769695034, 251890.0220876356, 251890.0220876359, 70681.33640607698]
[2019-03-23 16:55:03,992] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:55:03,994] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.9999905e-01 3.0352318e-11 9.7719453e-07 5.3283309e-14 6.3868821e-13], sampled 0.16324964233825046
[2019-03-23 16:55:29,203] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00426921], dtype=float32), 0.004886428]
[2019-03-23 16:55:29,204] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.0, 49.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5721680807540958, 6.9112, 6.9112, 77.32846344354104, 332815.9826459413, 332815.9826459413, 110944.1573275789]
[2019-03-23 16:55:29,205] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:55:29,208] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.9999952e-01 9.8692330e-12 5.3010842e-07 1.3006041e-14 1.7487269e-13], sampled 0.5386294100320688
[2019-03-23 16:55:38,038] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00426921], dtype=float32), 0.004886428]
[2019-03-23 16:55:38,041] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.53910247, 77.46358496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6072282603974872, 6.9112, 6.9112, 95.55338769690745, 352855.4196196273, 352855.4196196273, 118301.3476931903]
[2019-03-23 16:55:38,043] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:55:38,046] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.9999881e-01 3.5244235e-11 1.2025909e-06 6.5015403e-14 7.6284232e-13], sampled 0.3623488281671938
[2019-03-23 16:56:05,481] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00426921], dtype=float32), 0.004886428]
[2019-03-23 16:56:05,482] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.89075413, 52.38789176, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7329372717630198, 7.287673346798553, 6.9112, 95.55221401364513, 570866.7710925136, 419780.7515168535, 134938.1186648397]
[2019-03-23 16:56:05,482] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:56:05,488] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.9999845e-01 5.8495438e-11 1.5690542e-06 1.2212703e-13 1.3476608e-12], sampled 0.5163331891414347
[2019-03-23 16:56:05,489] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 570866.7710925136 W.
[2019-03-23 16:56:17,377] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00426921], dtype=float32), 0.004886428]
[2019-03-23 16:56:17,378] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.50673022666667, 99.22895729166667, 1.0, 2.0, 0.5091672794306882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 580446.0589273527, 580446.0589273527, 147715.6932960391]
[2019-03-23 16:56:17,378] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:56:17,383] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.9997652e-01 4.4816315e-09 2.3431146e-05 2.8891882e-11 2.1139618e-10], sampled 0.2336405978617162
[2019-03-23 16:56:17,384] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 580446.0589273527 W.
[2019-03-23 16:56:22,504] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00426921], dtype=float32), 0.004886428]
[2019-03-23 16:56:22,504] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.61666666666667, 60.33333333333333, 1.0, 2.0, 0.4200399924094158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.5533872213146, 473261.1848194018, 473261.1848194018, 130971.2343946487]
[2019-03-23 16:56:22,506] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:56:22,508] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.9997377e-01 6.3742718e-09 2.6185020e-05 4.7664522e-11 3.3802836e-10], sampled 0.6174240807659572
[2019-03-23 16:56:36,595] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00426921], dtype=float32), 0.004886428]
[2019-03-23 16:56:36,596] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.555859965, 80.39065431, 1.0, 2.0, 0.5758286562656573, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 95.55338129728314, 635572.6099133135, 635572.6099133135, 141604.3104980993]
[2019-03-23 16:56:36,596] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:56:36,600] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.9999940e-01 1.3677058e-11 6.4531622e-07 1.9306483e-14 2.5577679e-13], sampled 0.6034009957148052
[2019-03-23 16:56:36,601] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 635572.6099133135 W.
[2019-03-23 16:56:37,046] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00426921], dtype=float32), 0.004886428]
[2019-03-23 16:56:37,046] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [28.92184154166667, 54.16968699, 1.0, 2.0, 0.9089559794984677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 1033551.296147064, 1033551.296147063, 209750.0507506988]
[2019-03-23 16:56:37,048] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:56:37,050] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.9995005e-01 1.7052402e-08 4.9897633e-05 1.5190098e-10 1.0007698e-09], sampled 0.11562276245591796
[2019-03-23 16:56:37,051] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1033551.296147064 W.
[2019-03-23 16:56:42,436] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6478.3250 1678962781.6099 3057.0000
[2019-03-23 16:56:42,476] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6862.2842 1793014293.7888 2409.0000
[2019-03-23 16:56:42,681] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6552.3462 1698663906.1774 2957.0000
[2019-03-23 16:56:42,686] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6326.2404 1723371998.0222 3425.0000
[2019-03-23 16:56:42,781] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6294.9961 1685630448.6673 3228.0000
[2019-03-23 16:56:43,798] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 75000, evaluation results [75000.0, 6862.284208925443, 1793014293.78876, 2409.0, 6478.324951601497, 1678962781.6098795, 3057.0, 6294.9960618483565, 1685630448.6673346, 3228.0, 6326.240373982409, 1723371998.0221748, 3425.0, 6552.346231042109, 1698663906.17745, 2957.0]
[2019-03-23 16:56:45,682] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9974364e-01 3.3150535e-08 2.5635055e-04 2.3114737e-09 2.9033560e-08], sum to 1.0000
[2019-03-23 16:56:45,686] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7170
[2019-03-23 16:56:45,689] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 666284.7099679968 W.
[2019-03-23 16:56:45,697] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 78.83333333333333, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8051574159675531, 7.559333394556973, 6.9112, 77.32688821968824, 666284.7099679968, 455788.5280481096, 142941.8018330359], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2850600.0000, 
sim time next is 2851200.0000, 
raw observation next is [23.0, 78.0, 1.0, 1.0, 0.2591117282028194, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5216832090284546, 6.911200000000001, 6.9112, 77.32807397315288, 591287.5267761392, 591287.5267761389, 178382.6393847582], 
processed observation next is [1.0, 0.0, 0.6818181818181818, 0.78, 1.0, 0.5, 0.07388966025352425, 0.0, 1.0, -0.25, 1.0, 1.0, 0.316690298612078, 8.881784197001253e-17, 0.0, 0.5084262521822365, 0.21899538028745894, 0.21899538028745885, 0.4350796082555078], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.03449928], dtype=float32), -0.52357334]. 
=============================================
[2019-03-23 16:56:52,469] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5000, global step 79590: loss 9.4343
[2019-03-23 16:56:52,470] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5000, global step 79590: learning rate 0.0000
[2019-03-23 16:56:52,630] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.0764352e-01 1.2115861e-09 7.9235643e-01 2.7432091e-12 1.0082208e-10], sum to 1.0000
[2019-03-23 16:56:52,642] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8465
[2019-03-23 16:56:52,651] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.33333333333334, 67.33333333333334, 1.0, 2.0, 0.77736553014504, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9770467071172925, 6.911200000000001, 6.9112, 77.32846344354104, 1431989.578575816, 1431989.578575816, 304014.7475734284], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2974800.0000, 
sim time next is 2975400.0000, 
raw observation next is [26.5, 66.0, 1.0, 2.0, 0.8124272690132346, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9768545221254584, 6.9112, 6.9112, 77.32846344354104, 1472078.12330175, 1472078.12330175, 309616.8422764376], 
processed observation next is [1.0, 0.43478260869565216, 0.8409090909090909, 0.66, 1.0, 1.0, 0.7655340862665433, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9669350316077979, 0.0, 0.0, 0.5084288129206541, 0.5452141197413889, 0.5452141197413889, 0.7551630299425308], 
reward next is 0.2448, 
noisyNet noise sample is [array([2.242199], dtype=float32), -2.751146]. 
=============================================
[2019-03-23 16:56:52,933] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5000, global step 79766: loss 6.4188
[2019-03-23 16:56:52,937] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5000, global step 79766: learning rate 0.0000
[2019-03-23 16:56:53,188] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5000, global step 79825: loss 44.7754
[2019-03-23 16:56:53,193] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5000, global step 79825: learning rate 0.0000
[2019-03-23 16:56:53,353] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5000, global step 79842: loss 6.6028
[2019-03-23 16:56:53,357] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5000, global step 79842: learning rate 0.0000
[2019-03-23 16:56:53,523] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5000, global step 79869: loss -0.3487
[2019-03-23 16:56:53,524] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5000, global step 79869: loss 5.1256
[2019-03-23 16:56:53,528] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5000, global step 79869: learning rate 0.0000
[2019-03-23 16:56:53,532] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5000, global step 79870: learning rate 0.0000
[2019-03-23 16:56:53,814] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5000, global step 79879: loss 4.0150
[2019-03-23 16:56:53,815] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5000, global step 79879: learning rate 0.0000
[2019-03-23 16:56:53,815] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5000, global step 79879: loss 5.9463
[2019-03-23 16:56:53,959] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5000, global step 79879: learning rate 0.0000
[2019-03-23 16:56:54,352] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5000, global step 80026: loss 5.8462
[2019-03-23 16:56:54,353] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5000, global step 80026: learning rate 0.0000
[2019-03-23 16:56:54,513] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5000, global step 80043: loss 3.6251
[2019-03-23 16:56:54,514] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5000, global step 80043: learning rate 0.0000
[2019-03-23 16:56:54,776] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5000, global step 80115: loss -41.7604
[2019-03-23 16:56:54,777] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5000, global step 80115: learning rate 0.0000
[2019-03-23 16:56:54,970] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5000, global step 80149: loss 4.5911
[2019-03-23 16:56:54,972] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5000, global step 80149: learning rate 0.0000
[2019-03-23 16:56:55,115] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5000, global step 80153: loss 3.2670
[2019-03-23 16:56:55,116] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5000, global step 80153: learning rate 0.0000
[2019-03-23 16:56:55,291] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5000, global step 80174: loss 14.5322
[2019-03-23 16:56:55,293] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5000, global step 80174: learning rate 0.0000
[2019-03-23 16:56:55,455] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5000, global step 80197: loss 6.4532
[2019-03-23 16:56:55,458] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5000, global step 80199: learning rate 0.0000
[2019-03-23 16:56:55,697] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5000, global step 80250: loss 14.4969
[2019-03-23 16:56:55,699] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5000, global step 80250: learning rate 0.0000
[2019-03-23 16:57:00,669] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.2382826e-01 6.8135259e-12 2.7617168e-01 1.6292434e-16 1.5817420e-13], sum to 1.0000
[2019-03-23 16:57:00,679] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9179
[2019-03-23 16:57:00,685] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.262520758722068, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5315810040128587, 6.911200000000001, 6.9112, 77.32846344354104, 597761.1588436305, 597761.1588436302, 182825.2259785331], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3108000.0000, 
sim time next is 3108600.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.2627700966591356, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5320864027702364, 6.9112, 6.9112, 77.32846344354104, 598327.8186483674, 598327.8186483674, 182888.5559881305], 
processed observation next is [1.0, 1.0, 0.6818181818181818, 0.89, 1.0, 1.0, 0.07846262082391947, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3315520039574807, 0.0, 0.0, 0.5084288129206541, 0.22160289579569165, 0.22160289579569165, 0.4460696487515378], 
reward next is 0.5539, 
noisyNet noise sample is [array([-0.28690767], dtype=float32), -0.07492639]. 
=============================================
[2019-03-23 16:57:09,774] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5500, global step 87644: loss 0.3823
[2019-03-23 16:57:09,775] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5500, global step 87645: learning rate 0.0000
[2019-03-23 16:57:09,899] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5500, global step 87708: loss 0.5513
[2019-03-23 16:57:09,902] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5500, global step 87708: learning rate 0.0000
[2019-03-23 16:57:10,092] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5500, global step 87805: loss 0.2739
[2019-03-23 16:57:10,099] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5500, global step 87806: learning rate 0.0000
[2019-03-23 16:57:10,120] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5500, global step 87819: loss 0.4651
[2019-03-23 16:57:10,123] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5500, global step 87819: loss 0.3123
[2019-03-23 16:57:10,124] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5500, global step 87819: learning rate 0.0000
[2019-03-23 16:57:10,126] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5500, global step 87819: learning rate 0.0000
[2019-03-23 16:57:10,143] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5500, global step 87828: loss 0.5271
[2019-03-23 16:57:10,144] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5500, global step 87828: learning rate 0.0000
[2019-03-23 16:57:10,184] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5500, global step 87850: loss 0.2586
[2019-03-23 16:57:10,187] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5500, global step 87852: learning rate 0.0000
[2019-03-23 16:57:10,369] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5500, global step 87945: loss 0.4215
[2019-03-23 16:57:10,371] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5500, global step 87947: learning rate 0.0000
[2019-03-23 16:57:10,523] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5500, global step 88024: loss 0.2359
[2019-03-23 16:57:10,524] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5500, global step 88024: learning rate 0.0000
[2019-03-23 16:57:10,598] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5500, global step 88055: loss 0.1534
[2019-03-23 16:57:10,600] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5500, global step 88056: learning rate 0.0000
[2019-03-23 16:57:10,637] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5500, global step 88078: loss 0.2090
[2019-03-23 16:57:10,638] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5500, global step 88078: learning rate 0.0000
[2019-03-23 16:57:10,738] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5500, global step 88129: loss 0.0704
[2019-03-23 16:57:10,740] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5500, global step 88129: learning rate 0.0000
[2019-03-23 16:57:10,883] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5500, global step 88200: loss 0.1377
[2019-03-23 16:57:10,885] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5500, global step 88200: learning rate 0.0000
[2019-03-23 16:57:10,979] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5500, global step 88247: loss 0.1265
[2019-03-23 16:57:10,981] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5500, global step 88247: learning rate 0.0000
[2019-03-23 16:57:11,061] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5500, global step 88290: loss 0.0659
[2019-03-23 16:57:11,063] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5500, global step 88290: learning rate 0.0000
[2019-03-23 16:57:11,167] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5500, global step 88337: loss 0.0037
[2019-03-23 16:57:11,170] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5500, global step 88338: learning rate 0.0000
[2019-03-23 16:57:11,582] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 5.4113529e-23 1.9691904e-10 1.2735581e-28 4.7553352e-26], sum to 1.0000
[2019-03-23 16:57:11,586] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7161
[2019-03-23 16:57:11,596] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.0, 54.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6739319603513009, 6.911199999999999, 6.9112, 77.32846344354104, 388804.1578161587, 388804.157816159, 122353.697171836], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3327000.0000, 
sim time next is 3327600.0000, 
raw observation next is [24.0, 54.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6757277303293072, 6.9112, 6.9112, 77.32846344354104, 389785.7445667547, 389785.7445667547, 122568.4915583991], 
processed observation next is [0.0, 0.5217391304347826, 0.7272727272727273, 0.54, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5367539004704389, 0.0, 0.0, 0.5084288129206541, 0.14436509058027952, 0.14436509058027952, 0.29894754038633925], 
reward next is 0.7011, 
noisyNet noise sample is [array([0.00542153], dtype=float32), 0.104778014]. 
=============================================
[2019-03-23 16:57:25,865] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6000, global step 95660: loss -146.0748
[2019-03-23 16:57:25,866] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6000, global step 95660: learning rate 0.0000
[2019-03-23 16:57:26,051] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6000, global step 95754: loss -106.5758
[2019-03-23 16:57:26,052] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6000, global step 95754: learning rate 0.0000
[2019-03-23 16:57:26,192] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6000, global step 95823: loss -133.0638
[2019-03-23 16:57:26,193] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6000, global step 95823: learning rate 0.0000
[2019-03-23 16:57:26,263] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6000, global step 95861: loss -117.9852
[2019-03-23 16:57:26,267] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6000, global step 95863: learning rate 0.0000
[2019-03-23 16:57:26,308] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6000, global step 95880: loss -91.3399
[2019-03-23 16:57:26,313] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6000, global step 95881: learning rate 0.0000
[2019-03-23 16:57:26,333] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6000, global step 95890: loss -74.5864
[2019-03-23 16:57:26,335] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6000, global step 95890: learning rate 0.0000
[2019-03-23 16:57:26,382] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6000, global step 95917: loss -172.0753
[2019-03-23 16:57:26,383] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6000, global step 95917: learning rate 0.0000
[2019-03-23 16:57:26,432] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6000, global step 95942: loss -68.4516
[2019-03-23 16:57:26,434] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6000, global step 95942: learning rate 0.0000
[2019-03-23 16:57:26,603] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6000, global step 96030: loss -84.3880
[2019-03-23 16:57:26,605] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6000, global step 96030: learning rate 0.0000
[2019-03-23 16:57:26,628] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6000, global step 96042: loss -180.2901
[2019-03-23 16:57:26,633] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6000, global step 96043: learning rate 0.0000
[2019-03-23 16:57:26,639] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6000, global step 96043: loss -76.7923
[2019-03-23 16:57:26,639] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6000, global step 96043: learning rate 0.0000
[2019-03-23 16:57:26,688] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6000, global step 96066: loss -159.5753
[2019-03-23 16:57:26,690] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6000, global step 96067: learning rate 0.0000
[2019-03-23 16:57:26,893] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6000, global step 96171: loss -146.9813
[2019-03-23 16:57:26,896] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6000, global step 96172: learning rate 0.0000
[2019-03-23 16:57:26,991] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6000, global step 96213: loss -120.1459
[2019-03-23 16:57:26,998] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6000, global step 96215: learning rate 0.0000
[2019-03-23 16:57:27,161] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6000, global step 96298: loss -173.3101
[2019-03-23 16:57:27,163] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6000, global step 96298: learning rate 0.0000
[2019-03-23 16:57:27,309] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6000, global step 96372: loss -144.5845
[2019-03-23 16:57:27,310] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6000, global step 96372: learning rate 0.0000
[2019-03-23 16:57:28,886] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.8824478e-04 3.5908436e-17 9.9901175e-01 2.6632167e-20 8.4523413e-17], sum to 1.0000
[2019-03-23 16:57:28,892] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1462
[2019-03-23 16:57:28,897] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.2532826710237386, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5119074872701116, 6.9112, 6.9112, 77.32846344354104, 577832.0350407499, 577832.0350407499, 178954.8448706841], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3640800.0000, 
sim time next is 3641400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.2518519428480752, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5090002451899146, 6.9112, 6.9112, 77.32846344354104, 574573.4022578319, 574573.4022578319, 178599.7300586183], 
processed observation next is [1.0, 0.13043478260869565, 0.5909090909090909, 1.0, 1.0, 1.0, 0.064814928560094, 0.0, 1.0, -0.25, 1.0, 1.0, 0.29857177884273517, 0.0, 0.0, 0.5084288129206541, 0.212804963799197, 0.212804963799197, 0.43560909770394707], 
reward next is 0.5644, 
noisyNet noise sample is [array([0.39168507], dtype=float32), -0.9179164]. 
=============================================
[2019-03-23 16:57:32,498] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.0997769e-01 3.0000653e-14 7.9002231e-01 1.5622278e-18 2.2738803e-16], sum to 1.0000
[2019-03-23 16:57:32,511] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6548
[2019-03-23 16:57:32,521] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.16666666666667, 88.0, 1.0, 2.0, 0.2623890322293769, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5313472987898162, 6.9112, 6.9112, 77.32846344354104, 597362.9456692531, 597362.9456692531, 182884.6561457539], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3714600.0000, 
sim time next is 3715200.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.2622283829120533, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5309929148842346, 6.911199999999999, 6.9112, 77.32846344354104, 597083.8918890222, 597083.8918890224, 182763.23775147], 
processed observation next is [1.0, 0.0, 0.6818181818181818, 0.89, 1.0, 1.0, 0.07778547864006662, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3299898784060495, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22114218218111933, 0.22114218218111942, 0.4457639945157805], 
reward next is 0.5542, 
noisyNet noise sample is [array([0.4935852], dtype=float32), -1.4305933]. 
=============================================
[2019-03-23 16:57:34,567] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.8709098e-01 2.1486765e-13 1.1290903e-01 8.3158512e-17 1.1476537e-13], sum to 1.0000
[2019-03-23 16:57:34,576] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0509
[2019-03-23 16:57:34,583] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 730653.3107305409 W.
[2019-03-23 16:57:34,588] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 56.0, 1.0, 2.0, 0.3201227559686647, 1.0, 2.0, 0.3201227559686647, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354076, 730653.3107305409, 730653.3107305412, 188149.1329264621], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3760200.0000, 
sim time next is 3760800.0000, 
raw observation next is [26.0, 55.33333333333334, 1.0, 2.0, 0.3235008185542559, 1.0, 2.0, 0.3235008185542559, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 738167.150919104, 738167.150919104, 187995.9293273338], 
processed observation next is [1.0, 0.5217391304347826, 0.8181818181818182, 0.5533333333333335, 1.0, 1.0, 0.15437602319281984, 1.0, 1.0, 0.15437602319281984, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.27339524108114965, 0.27339524108114965, 0.45852665689593614], 
reward next is 0.5415, 
noisyNet noise sample is [array([-1.8090687], dtype=float32), 0.027292266]. 
=============================================
[2019-03-23 16:57:34,589] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 16:57:34,590] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:57:34,591] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:57:34,591] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:57:34,593] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:57:34,594] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:57:34,594] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:57:34,593] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:57:34,596] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:57:34,597] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:57:34,595] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:57:34,609] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run5
[2019-03-23 16:57:34,635] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run5
[2019-03-23 16:57:34,636] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run5
[2019-03-23 16:57:34,666] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run5
[2019-03-23 16:57:34,696] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run5
[2019-03-23 16:57:42,757] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00413099], dtype=float32), 0.004836259]
[2019-03-23 16:57:42,759] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [11.6, 89.0, 1.0, 1.0, 0.2412033024616551, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4502235061018443, 6.911199999999999, 6.9112, 95.55311601852263, 523875.1921969064, 523875.1921969068, 138694.9489975032]
[2019-03-23 16:57:42,760] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:57:42,764] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.4205916e-01 1.3770541e-13 7.5794083e-01 9.1434838e-17 1.7063211e-14], sampled 0.39673364090914254
[2019-03-23 16:57:46,855] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00413099], dtype=float32), 0.004836259]
[2019-03-23 16:57:46,856] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [28.21009675, 80.90092536, 1.0, 2.0, 0.3500587575864804, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7083016906360972, 6.911200000000001, 6.9112, 95.55338769695034, 786711.7196803861, 786711.7196803858, 218090.8022149208]
[2019-03-23 16:57:46,857] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:57:46,861] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.7729838e-01 2.1315227e-14 8.2270163e-01 9.5272363e-18 2.4965731e-15], sampled 0.7009515063663677
[2019-03-23 16:58:02,150] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00413099], dtype=float32), 0.004836259]
[2019-03-23 16:58:02,152] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.0, 90.0, 1.0, 2.0, 0.2093450606276392, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4152364343370211, 6.911200000000001, 6.9112, 95.55338769695034, 474633.6662614967, 474633.6662614964, 168286.850567735]
[2019-03-23 16:58:02,154] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:58:02,156] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.8401569e-01 2.6396829e-15 8.1598437e-01 6.9209597e-19 2.6058947e-16], sampled 0.26789694456488133
[2019-03-23 16:58:03,582] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00413099], dtype=float32), 0.004836259]
[2019-03-23 16:58:03,583] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.0, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 221877.1599239327, 221877.1599239324, 94307.9061219698]
[2019-03-23 16:58:03,587] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:58:03,590] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.4083494e-01 2.2449989e-13 7.5916511e-01 1.7191255e-16 2.9988605e-14], sampled 0.4170381614406744
[2019-03-23 16:58:06,023] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00413099], dtype=float32), 0.004836259]
[2019-03-23 16:58:06,024] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [13.1, 81.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 204790.9927798323, 204790.9927798323, 91577.15109536261]
[2019-03-23 16:58:06,027] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:58:06,030] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.5549001e-01 2.4849206e-13 7.4450994e-01 1.8960872e-16 3.2403466e-14], sampled 0.7574892683615798
[2019-03-23 16:58:06,707] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00413099], dtype=float32), 0.004836259]
[2019-03-23 16:58:06,708] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.1, 50.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5030888333586889, 6.9112, 6.9112, 95.55338769695034, 292720.0476051578, 292720.0476051578, 72793.36809868997]
[2019-03-23 16:58:06,713] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:58:06,716] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.2508143e-01 4.5896077e-14 7.7491856e-01 2.3014970e-17 5.3065068e-15], sampled 0.057287649927087236
[2019-03-23 16:58:09,063] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00413099], dtype=float32), 0.004836259]
[2019-03-23 16:58:09,065] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.802356715, 63.72688094, 1.0, 2.0, 0.2016309159173722, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3764007475199403, 6.911200000000001, 6.9112, 95.55338769695034, 437895.663648629, 437895.6636486287, 154389.8533190961]
[2019-03-23 16:58:09,068] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:58:09,072] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.9934542e-01 1.2847275e-14 8.0065453e-01 5.0427106e-18 1.4445040e-15], sampled 0.3376630119757199
[2019-03-23 16:58:34,925] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00413099], dtype=float32), 0.004836259]
[2019-03-23 16:58:34,927] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.65, 89.5, 1.0, 2.0, 0.2581684292576465, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5224156326638272, 6.911200000000001, 6.9112, 95.55338769695034, 588420.2742649021, 588420.2742649018, 185755.5112242537]
[2019-03-23 16:58:34,930] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:58:34,936] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.0042774e-01 6.7862247e-14 7.9957223e-01 3.9110089e-17 8.4878995e-15], sampled 0.6206470156985319
[2019-03-23 16:59:03,569] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00413099], dtype=float32), 0.004836259]
[2019-03-23 16:59:03,570] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.68941948833334, 59.88447914166667, 1.0, 2.0, 0.3237323006516902, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6538360025699844, 6.911199999999999, 6.9112, 95.55338769695034, 738735.3104869726, 738735.3104869729, 202196.8653127589]
[2019-03-23 16:59:03,571] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:59:03,572] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.9275117e-01 9.3966752e-15 8.0724883e-01 3.2889135e-18 1.0196993e-15], sampled 0.5057925654834476
[2019-03-23 16:59:08,521] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00413099], dtype=float32), 0.004836259]
[2019-03-23 16:59:08,522] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.6, 40.66666666666667, 1.0, 2.0, 0.277323037185064, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5177013555983386, 6.911199999999999, 6.9112, 95.55338769695034, 602363.8326143875, 602363.8326143879, 166335.6929231823]
[2019-03-23 16:59:08,525] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:59:08,528] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.8157947e-01 4.3780378e-14 8.1842059e-01 2.2817572e-17 5.2363657e-15], sampled 0.6704264776877688
[2019-03-23 16:59:16,288] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3482.4670 2022615427.8939 988.0000
[2019-03-23 16:59:16,367] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3258.1894 2029918294.1275 1055.0000
[2019-03-23 16:59:16,400] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3396.7910 2016082337.3607 962.0000
[2019-03-23 16:59:16,430] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 3010.9983 2043791100.0051 1501.0000
[2019-03-23 16:59:16,499] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3661.4981 2100931050.9838 821.0000
[2019-03-23 16:59:17,514] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 100000, evaluation results [100000.0, 3661.49814928538, 2100931050.9838297, 821.0, 3396.790998570966, 2016082337.360726, 962.0, 3482.4669505082393, 2022615427.8939097, 988.0, 3010.998304946757, 2043791100.00509, 1501.0, 3258.1894254226318, 2029918294.1274712, 1055.0]
[2019-03-23 16:59:24,234] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6500, global step 103563: loss 0.0002
[2019-03-23 16:59:24,236] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6500, global step 103563: learning rate 0.0000
[2019-03-23 16:59:24,443] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6500, global step 103674: loss 0.0437
[2019-03-23 16:59:24,448] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6500, global step 103675: learning rate 0.0000
[2019-03-23 16:59:24,596] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6500, global step 103754: loss 0.0077
[2019-03-23 16:59:24,597] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6500, global step 103754: learning rate 0.0000
[2019-03-23 16:59:24,857] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6500, global step 103887: loss 0.0359
[2019-03-23 16:59:24,859] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6500, global step 103887: learning rate 0.0000
[2019-03-23 16:59:24,864] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6500, global step 103888: loss 0.0024
[2019-03-23 16:59:24,866] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6500, global step 103889: learning rate 0.0000
[2019-03-23 16:59:24,926] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6500, global step 103926: loss 0.0161
[2019-03-23 16:59:24,931] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6500, global step 103926: learning rate 0.0000
[2019-03-23 16:59:24,967] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6500, global step 103944: loss 0.1521
[2019-03-23 16:59:24,970] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6500, global step 103944: learning rate 0.0000
[2019-03-23 16:59:25,097] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6500, global step 104017: loss 0.0022
[2019-03-23 16:59:25,103] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6500, global step 104017: learning rate 0.0000
[2019-03-23 16:59:25,110] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6500, global step 104022: loss 0.0148
[2019-03-23 16:59:25,111] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6500, global step 104022: loss 0.0083
[2019-03-23 16:59:25,114] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6500, global step 104022: learning rate 0.0000
[2019-03-23 16:59:25,114] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6500, global step 104022: learning rate 0.0000
[2019-03-23 16:59:25,215] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9999607e-01 6.7044766e-21 3.9160609e-06 1.0922630e-25 1.3910406e-21], sum to 1.0000
[2019-03-23 16:59:25,222] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9614
[2019-03-23 16:59:25,224] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6500, global step 104081: loss 0.0229
[2019-03-23 16:59:25,225] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6500, global step 104081: learning rate 0.0000
[2019-03-23 16:59:25,227] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.5, 80.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5110754317222127, 6.9112, 6.9112, 77.32846344354104, 297269.0427075215, 297269.0427075215, 98192.51127574885], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3902400.0000, 
sim time next is 3903000.0000, 
raw observation next is [17.41666666666667, 80.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5087743261367379, 6.9112, 6.9112, 77.32846344354104, 295930.1883384165, 295930.1883384165, 97590.30203245788], 
processed observation next is [0.0, 0.17391304347826086, 0.42803030303030326, 0.8033333333333335, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.298249037338197, 0.0, 0.0, 0.5084288129206541, 0.10960377345867278, 0.10960377345867278, 0.23802512690843386], 
reward next is 0.7620, 
noisyNet noise sample is [array([-1.4949838], dtype=float32), -1.3197852]. 
=============================================
[2019-03-23 16:59:25,238] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[74.64071 ]
 [74.54681 ]
 [74.52813 ]
 [74.47788 ]
 [74.462395]], R is [[74.68637085]
 [74.70001221]
 [74.71266174]
 [74.72434235]
 [74.73504639]].
[2019-03-23 16:59:25,266] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6500, global step 104096: loss 0.1026
[2019-03-23 16:59:25,270] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6500, global step 104099: learning rate 0.0000
[2019-03-23 16:59:25,293] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6500, global step 104111: loss 0.0352
[2019-03-23 16:59:25,296] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6500, global step 104112: learning rate 0.0000
[2019-03-23 16:59:25,308] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6500, global step 104119: loss 0.1572
[2019-03-23 16:59:25,309] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6500, global step 104119: learning rate 0.0000
[2019-03-23 16:59:25,749] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6500, global step 104354: loss 0.1476
[2019-03-23 16:59:25,755] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6500, global step 104355: learning rate 0.0000
[2019-03-23 16:59:25,774] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6500, global step 104365: loss 0.2254
[2019-03-23 16:59:25,777] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6500, global step 104365: learning rate 0.0000
[2019-03-23 16:59:31,066] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.7125542e-01 4.5572454e-13 2.8744597e-02 3.6842747e-17 4.2517652e-14], sum to 1.0000
[2019-03-23 16:59:31,071] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2437
[2019-03-23 16:59:31,078] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.5, 97.0, 1.0, 2.0, 0.2123179840243478, 0.0, 1.0, 0.0, 1.0, 2.0, 0.4113620844521537, 6.9112, 6.9112, 77.32846344354104, 474064.9244570893, 474064.9244570893, 159538.5945512904], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4019400.0000, 
sim time next is 4020000.0000, 
raw observation next is [17.33333333333333, 98.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7447546256192472, 7.187800256356734, 6.9112, 77.32778203767069, 519804.048455097, 429970.734247604, 129450.9684025049], 
processed observation next is [1.0, 0.5217391304347826, 0.42424242424242403, 0.98, 0.0, 0.5, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6353637508846389, 0.027660025635673425, 0.0, 0.5084243327284668, 0.19252001794633222, 0.15924842009170517, 0.31573406927440223], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.6824483], dtype=float32), -3.8057601]. 
=============================================
[2019-03-23 16:59:31,089] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[46.80532 ]
 [47.545937]
 [46.911087]
 [45.017757]
 [46.108925]], R is [[48.43625259]
 [47.95188904]
 [47.47237015]
 [46.99764633]
 [47.18497849]].
[2019-03-23 16:59:36,929] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9999976e-01 2.5213931e-16 2.1320173e-07 3.0408074e-19 1.0668998e-17], sum to 1.0000
[2019-03-23 16:59:36,940] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2785
[2019-03-23 16:59:36,947] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.0, 94.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7393118400564112, 7.100465431765972, 6.9112, 77.32796807884145, 485371.0417059175, 423901.894388603, 131009.0266383354], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4132800.0000, 
sim time next is 4133400.0000, 
raw observation next is [18.83333333333334, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7478255412967564, 7.179908305663281, 6.9112, 77.32765665737573, 516692.5475663104, 429422.496440786, 131506.9369236427], 
processed observation next is [1.0, 0.8695652173913043, 0.4924242424242427, 0.95, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6397507732810807, 0.026870830566328063, 0.0, 0.508423508362487, 0.19136761020974458, 0.15904536905214295, 0.320748626643031], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.027682], dtype=float32), -0.13463078]. 
=============================================
[2019-03-23 16:59:38,404] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.6315950e-01 3.7701257e-12 3.6840498e-02 1.8183402e-14 2.0595233e-13], sum to 1.0000
[2019-03-23 16:59:38,413] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4442
[2019-03-23 16:59:38,417] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.33333333333334, 98.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6454958579036448, 6.911199999999999, 6.9112, 77.32846344354104, 373148.6528657415, 373148.6528657418, 119105.4661503275], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4170000.0000, 
sim time next is 4170600.0000, 
raw observation next is [17.5, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.646556537406107, 6.911199999999999, 6.9112, 77.32846344354104, 373801.9445771013, 373801.9445771016, 119172.8137051232], 
processed observation next is [1.0, 0.2608695652173913, 0.4318181818181818, 0.97, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.49508076772301, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13844516465818568, 0.1384451646581858, 0.29066539928078833], 
reward next is 0.7093, 
noisyNet noise sample is [array([-1.2032366], dtype=float32), 1.2049733]. 
=============================================
[2019-03-23 16:59:39,406] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7000, global step 111601: loss -76.4731
[2019-03-23 16:59:39,410] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7000, global step 111603: learning rate 0.0000
[2019-03-23 16:59:39,554] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7000, global step 111675: loss -49.5384
[2019-03-23 16:59:39,557] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7000, global step 111675: learning rate 0.0000
[2019-03-23 16:59:39,823] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7000, global step 111808: loss -6.1085
[2019-03-23 16:59:39,824] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7000, global step 111808: learning rate 0.0000
[2019-03-23 16:59:39,981] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7000, global step 111888: loss 34.0717
[2019-03-23 16:59:39,987] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7000, global step 111889: learning rate 0.0000
[2019-03-23 16:59:40,084] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7000, global step 111940: loss 24.3627
[2019-03-23 16:59:40,085] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7000, global step 111940: learning rate 0.0000
[2019-03-23 16:59:40,093] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7000, global step 111943: loss -12.5827
[2019-03-23 16:59:40,094] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7000, global step 111943: learning rate 0.0000
[2019-03-23 16:59:40,107] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7000, global step 111951: loss 25.6269
[2019-03-23 16:59:40,108] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7000, global step 111951: learning rate 0.0000
[2019-03-23 16:59:40,211] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7000, global step 111998: loss -60.1258
[2019-03-23 16:59:40,212] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7000, global step 111998: learning rate 0.0000
[2019-03-23 16:59:40,292] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7000, global step 112039: loss -25.7873
[2019-03-23 16:59:40,294] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7000, global step 112040: learning rate 0.0000
[2019-03-23 16:59:40,323] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7000, global step 112051: loss -5.4584
[2019-03-23 16:59:40,324] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7000, global step 112051: learning rate 0.0000
[2019-03-23 16:59:40,338] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7000, global step 112058: loss 63.0741
[2019-03-23 16:59:40,340] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7000, global step 112058: learning rate 0.0000
[2019-03-23 16:59:40,343] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7000, global step 112059: loss -50.9949
[2019-03-23 16:59:40,345] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7000, global step 112059: learning rate 0.0000
[2019-03-23 16:59:40,447] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7000, global step 112117: loss -68.4512
[2019-03-23 16:59:40,452] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7000, global step 112117: learning rate 0.0000
[2019-03-23 16:59:40,520] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7000, global step 112144: loss -126.6612
[2019-03-23 16:59:40,521] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7000, global step 112144: learning rate 0.0000
[2019-03-23 16:59:40,823] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7000, global step 112296: loss -46.3393
[2019-03-23 16:59:40,826] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7000, global step 112296: learning rate 0.0000
[2019-03-23 16:59:40,927] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7000, global step 112354: loss 43.5718
[2019-03-23 16:59:40,929] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7000, global step 112354: learning rate 0.0000
[2019-03-23 16:59:43,903] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9996829e-01 8.0742928e-14 3.1662348e-05 3.6588748e-16 4.7482846e-16], sum to 1.0000
[2019-03-23 16:59:43,911] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9856
[2019-03-23 16:59:43,918] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 852176.7556387899 W.
[2019-03-23 16:59:43,922] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 69.0, 1.0, 2.0, 0.7524878177082083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 852176.7556387899, 852176.7556387899, 167075.7341596468], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4267200.0000, 
sim time next is 4267800.0000, 
raw observation next is [23.0, 67.0, 1.0, 2.0, 0.7621676066632815, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 863244.3640955159, 863244.3640955162, 168499.5450687865], 
processed observation next is [1.0, 0.391304347826087, 0.6818181818181818, 0.67, 1.0, 1.0, 0.7027095083291018, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3197201348501911, 0.3197201348501912, 0.410974500167772], 
reward next is 0.5890, 
noisyNet noise sample is [array([2.2528646], dtype=float32), -0.458571]. 
=============================================
[2019-03-23 16:59:45,043] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9967408e-01 2.9165543e-14 3.2598453e-04 3.0911893e-18 2.1653237e-15], sum to 1.0000
[2019-03-23 16:59:45,048] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9644
[2019-03-23 16:59:45,052] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.66666666666667, 58.33333333333334, 1.0, 1.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 498240.3136863146, 498240.3136863146, 196079.7861493651], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4303200.0000, 
sim time next is 4303800.0000, 
raw observation next is [24.5, 59.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7511326204243515, 7.167502593716724, 6.9112, 77.32780716612412, 511801.417539213, 428560.2838581748, 133856.8842596915], 
processed observation next is [1.0, 0.8260869565217391, 0.75, 0.59, 0.0, 0.5, -0.25, 0.0, 0.5, -0.25, 1.0, 1.0, 0.6444751720347879, 0.02563025937167236, 0.0, 0.5084244979461522, 0.1895560805700789, 0.15872603105858327, 0.32648020551144263], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8231706], dtype=float32), -0.3462368]. 
=============================================
[2019-03-23 16:59:46,582] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.0399083e-01 1.2344381e-11 4.9600920e-01 5.3090111e-15 2.9676581e-11], sum to 1.0000
[2019-03-23 16:59:46,591] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5274
[2019-03-23 16:59:46,595] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 78.0, 1.0, 1.0, 0.2064240091191295, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4071037753410428, 6.9112, 6.9112, 77.32830599681448, 466459.2496499571, 466459.2496499571, 161871.8954533079], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4315200.0000, 
sim time next is 4315800.0000, 
raw observation next is [21.0, 78.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3843698293256595, 6.911199999999999, 6.9112, 77.32846246892456, 440559.162287778, 440559.1622877783, 159303.6792336399], 
processed observation next is [1.0, 0.9565217391304348, 0.5909090909090909, 0.78, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.12052832760808502, -8.881784197001253e-17, 0.0, 0.5084288065126242, 0.16317006010658444, 0.16317006010658455, 0.3885455591064388], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.739658], dtype=float32), -0.55732477]. 
=============================================
[2019-03-23 16:59:49,809] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.0045435e-01 4.1699803e-11 7.9954571e-01 1.3693200e-13 8.3908630e-11], sum to 1.0000
[2019-03-23 16:59:49,818] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5186
[2019-03-23 16:59:49,986] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.16666666666667, 51.16666666666666, 1.0, 2.0, 0.8702926593583702, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9714069316378456, 6.911199999999999, 6.9112, 77.32846344354104, 1541740.100249746, 1541740.100249746, 313359.5554356783], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4380600.0000, 
sim time next is 4381200.0000, 
raw observation next is [28.0, 51.0, 1.0, 2.0, 0.8591836966788652, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9704504614729687, 6.9112, 6.9112, 77.32846344354104, 1529355.287302185, 1529355.287302185, 310297.5656166706], 
processed observation next is [1.0, 0.7391304347826086, 0.9090909090909091, 0.51, 1.0, 1.0, 0.8239796208485813, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9577863735328125, 0.0, 0.0, 0.5084288129206541, 0.5664278841859944, 0.5664278841859944, 0.7568233307723673], 
reward next is 0.2432, 
noisyNet noise sample is [array([-0.01363127], dtype=float32), 1.4367498]. 
=============================================
[2019-03-23 16:59:50,676] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.09502722e-02 9.58302993e-10 9.59049702e-01 1.10769605e-11
 1.06807715e-10], sum to 1.0000
[2019-03-23 16:59:50,686] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3179
[2019-03-23 16:59:50,689] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.0, 51.33333333333334, 1.0, 2.0, 0.4562213013154335, 1.0, 1.0, 0.4562213013154335, 1.0, 2.0, 0.9233967769429163, 6.911199999999999, 6.9112, 77.3421103, 1548353.313041259, 1548353.313041259, 332414.0915631], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4377000.0000, 
sim time next is 4377600.0000, 
raw observation next is [29.0, 52.0, 1.0, 2.0, 0.7840858471875749, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9768240744396985, 6.911199999999999, 6.9112, 77.32846344354104, 1439838.922024957, 1439838.922024957, 304883.6334611966], 
processed observation next is [1.0, 0.6956521739130435, 0.9545454545454546, 0.52, 1.0, 1.0, 0.7301073089844686, 0.0, 0.5, -0.25, 1.0, 1.0, 0.966891534913855, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5332736748240581, 0.5332736748240581, 0.7436186181980405], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.14667967], dtype=float32), -0.7528461]. 
=============================================
[2019-03-23 16:59:51,322] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1387365e-01 1.0465090e-09 7.8612632e-01 2.9676973e-12 1.4206193e-10], sum to 1.0000
[2019-03-23 16:59:51,329] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0444
[2019-03-23 16:59:51,334] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 542195.3576290696 W.
[2019-03-23 16:59:51,337] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.08333333333333, 87.66666666666667, 1.0, 1.0, 0.2379461400191129, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4766904524027696, 6.9112, 6.9112, 77.328186487751, 542195.3576290696, 542195.3576290696, 171844.1638651108], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4416600.0000, 
sim time next is 4417200.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.2194573828186864, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4391929011448731, 6.911199999999999, 6.9112, 77.3284617291364, 499837.4246097634, 499837.4246097637, 167783.9086236046], 
processed observation next is [0.0, 0.13043478260869565, 0.5909090909090909, 0.88, 1.0, 1.0, 0.02432172852335799, 0.0, 1.0, -0.25, 1.0, 1.0, 0.198847001635533, -8.881784197001253e-17, 0.0, 0.5084288016485728, 0.18512497207769013, 0.18512497207769027, 0.40922904542342586], 
reward next is 0.5908, 
noisyNet noise sample is [array([-0.7076365], dtype=float32), -2.120779]. 
=============================================
[2019-03-23 16:59:52,026] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.0433854e-02 5.1947373e-13 9.5956618e-01 1.0294103e-13 1.3956960e-13], sum to 1.0000
[2019-03-23 16:59:52,033] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7421
[2019-03-23 16:59:52,036] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.83333333333333, 83.83333333333334, 1.0, 2.0, 0.2047747339996306, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4065242256974118, 6.9112, 6.9112, 77.32846344354104, 464536.064994645, 464536.064994645, 163013.5056431603], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4421400.0000, 
sim time next is 4422000.0000, 
raw observation next is [20.66666666666667, 84.66666666666667, 1.0, 2.0, 0.2034570919044103, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4036061516719777, 6.9112, 6.9112, 77.32846344354104, 461352.2175142144, 461352.2175142144, 162614.0539685024], 
processed observation next is [0.0, 0.17391304347826086, 0.575757575757576, 0.8466666666666667, 1.0, 1.0, 0.004321364880512865, 0.0, 1.0, -0.25, 1.0, 1.0, 0.14800878810282533, 0.0, 0.0, 0.5084288129206541, 0.17087119167193127, 0.17087119167193127, 0.39661964382561565], 
reward next is 0.6034, 
noisyNet noise sample is [array([-0.2138295], dtype=float32), -0.29435134]. 
=============================================
[2019-03-23 16:59:52,053] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[29.445757]
 [29.34627 ]
 [29.021282]
 [29.885492]
 [29.106016]], R is [[29.74146843]
 [30.0464592 ]
 [30.34721756]
 [30.64329338]
 [30.93471146]].
[2019-03-23 16:59:55,654] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7500, global step 119614: loss 0.7014
[2019-03-23 16:59:55,656] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7500, global step 119614: learning rate 0.0000
[2019-03-23 16:59:55,858] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7500, global step 119716: loss -200.6766
[2019-03-23 16:59:55,866] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7500, global step 119716: learning rate 0.0000
[2019-03-23 16:59:56,043] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7500, global step 119811: loss -137.6775
[2019-03-23 16:59:56,048] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7500, global step 119811: learning rate 0.0000
[2019-03-23 16:59:56,141] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7500, global step 119854: loss -0.9215
[2019-03-23 16:59:56,143] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7500, global step 119855: learning rate 0.0000
[2019-03-23 16:59:56,259] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7500, global step 119915: loss -3.6705
[2019-03-23 16:59:56,261] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7500, global step 119915: learning rate 0.0000
[2019-03-23 16:59:56,284] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7500, global step 119929: loss 0.1882
[2019-03-23 16:59:56,286] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7500, global step 119929: loss -107.9677
[2019-03-23 16:59:56,287] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7500, global step 119929: learning rate 0.0000
[2019-03-23 16:59:56,288] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7500, global step 119929: loss 0.5823
[2019-03-23 16:59:56,290] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7500, global step 119929: learning rate 0.0000
[2019-03-23 16:59:56,292] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7500, global step 119929: learning rate 0.0000
[2019-03-23 16:59:56,371] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7500, global step 119973: loss 0.0394
[2019-03-23 16:59:56,374] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7500, global step 119973: learning rate 0.0000
[2019-03-23 16:59:56,451] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7500, global step 120012: loss -152.3232
[2019-03-23 16:59:56,453] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7500, global step 120012: learning rate 0.0000
[2019-03-23 16:59:56,546] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7500, global step 120059: loss 0.5168
[2019-03-23 16:59:56,553] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7500, global step 120061: learning rate 0.0000
[2019-03-23 16:59:56,564] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7500, global step 120063: loss 2.2033
[2019-03-23 16:59:56,566] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7500, global step 120064: learning rate 0.0000
[2019-03-23 16:59:56,676] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7500, global step 120120: loss -37.8235
[2019-03-23 16:59:56,678] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7500, global step 120121: learning rate 0.0000
[2019-03-23 16:59:56,724] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7500, global step 120142: loss 3.4776
[2019-03-23 16:59:56,728] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7500, global step 120143: learning rate 0.0000
[2019-03-23 16:59:57,144] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7500, global step 120356: loss 0.7793
[2019-03-23 16:59:57,146] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7500, global step 120357: learning rate 0.0000
[2019-03-23 16:59:57,240] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7500, global step 120402: loss -0.0138
[2019-03-23 16:59:57,244] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7500, global step 120405: learning rate 0.0000
[2019-03-23 17:00:01,082] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.3223885e-04 4.7214146e-11 9.9966776e-01 1.2031761e-11 1.9007596e-11], sum to 1.0000
[2019-03-23 17:00:01,087] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7716
[2019-03-23 17:00:01,093] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.0, 95.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 243589.8426306355, 243589.8426306352, 100497.9318263443], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4596600.0000, 
sim time next is 4597200.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 239878.5620027322, 239878.5620027325, 99362.32087773892], 
processed observation next is [1.0, 0.21739130434782608, 0.2727272727272727, 0.94, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08884391185286378, 0.08884391185286389, 0.24234712409204615], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3324239], dtype=float32), -0.47403005]. 
=============================================
[2019-03-23 17:00:04,056] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.9899739e-03 4.4074355e-10 9.9101007e-01 1.4416639e-11 7.2799745e-11], sum to 1.0000
[2019-03-23 17:00:04,061] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1679
[2019-03-23 17:00:04,067] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 50.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 341668.8490723356, 341668.8490723356, 143665.2321946632], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4642200.0000, 
sim time next is 4642800.0000, 
raw observation next is [23.0, 50.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 343661.6495906154, 343661.6495906151, 143946.8098882196], 
processed observation next is [1.0, 0.7391304347826086, 0.6818181818181818, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12728209244096866, 0.12728209244096855, 0.3510897802151698], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7149464], dtype=float32), 0.34097666]. 
=============================================
[2019-03-23 17:00:04,609] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0323003e-03 1.6865841e-09 9.9896765e-01 1.0384279e-10 3.4053527e-11], sum to 1.0000
[2019-03-23 17:00:04,617] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4567
[2019-03-23 17:00:04,778] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.16666666666667, 62.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 289352.5477228661, 289352.5477228664, 117865.3056344013], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4654200.0000, 
sim time next is 4654800.0000, 
raw observation next is [19.0, 64.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 288506.7671064652, 288506.7671064649, 117971.6935716806], 
processed observation next is [1.0, 0.9130434782608695, 0.5, 0.64, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1068543581875797, 0.10685435818757959, 0.2877358379797088], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.09442689], dtype=float32), 1.3783321]. 
=============================================
[2019-03-23 17:00:06,552] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 17:00:06,553] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:00:06,553] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:00:06,553] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:00:06,554] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:00:06,554] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:00:06,553] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:00:06,556] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:00:06,557] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:00:06,558] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:00:06,558] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:00:06,576] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run6
[2019-03-23 17:00:06,599] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run6
[2019-03-23 17:00:06,600] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run6
[2019-03-23 17:00:06,648] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run6
[2019-03-23 17:00:06,649] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run6
[2019-03-23 17:00:21,059] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00239649], dtype=float32), 0.0026544142]
[2019-03-23 17:00:21,059] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.54158860833333, 96.92786150166667, 1.0, 2.0, 0.2062941779227896, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4050783256077632, 6.9112, 6.9112, 95.55338769695034, 464830.5274926353, 464830.5274926353, 165639.9499123344]
[2019-03-23 17:00:21,062] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:00:21,066] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.9441343e-04 2.5479494e-07 9.9950540e-01 3.4182438e-08 1.5418815e-08], sampled 0.661881570334587
[2019-03-23 17:00:33,386] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00239649], dtype=float32), 0.0026544142]
[2019-03-23 17:00:33,387] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.63860093333334, 72.01470443333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 322242.9898852336, 322242.9898852336, 139432.743005889]
[2019-03-23 17:00:33,388] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:00:33,390] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.45291419e-04 6.96414361e-07 9.99153852e-01 1.08262874e-07
 5.22964143e-08], sampled 0.8846394363434084
[2019-03-23 17:00:48,609] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00239649], dtype=float32), 0.0026544142]
[2019-03-23 17:00:48,610] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3516024285159096, 6.9112, 6.9112, 77.32846344354104, 407365.765136931, 407365.765136931, 150932.7544073352]
[2019-03-23 17:00:48,611] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:00:48,615] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.4608169e-04 4.1904894e-07 9.9935347e-01 5.9657978e-08 2.7386497e-08], sampled 0.21208792255606923
[2019-03-23 17:01:07,776] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00239649], dtype=float32), 0.0026544142]
[2019-03-23 17:01:07,777] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.8, 87.0, 1.0, 2.0, 0.2562295249820778, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5182301381659731, 6.9112, 6.9112, 95.55338769695034, 584261.8300887396, 584261.8300887396, 184875.6263935392]
[2019-03-23 17:01:07,778] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:01:07,780] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.5372892e-04 2.0601452e-07 9.9954599e-01 2.6907143e-08 1.2232893e-08], sampled 0.5336340742246223
[2019-03-23 17:01:25,296] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00239649], dtype=float32), 0.0026544142]
[2019-03-23 17:01:25,297] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.3, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3209650793114936, 6.911200000000001, 6.9112, 95.55338769695034, 370717.3937983669, 370717.3937983665, 153093.2709082449]
[2019-03-23 17:01:25,298] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:01:25,301] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.4287115e-04 2.1732913e-07 9.9955684e-01 2.8872806e-08 1.3049612e-08], sampled 0.5842228397941793
[2019-03-23 17:01:47,992] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3120.0845 2108773030.7579 370.0000
[2019-03-23 17:01:48,211] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2760.5191 2123848024.1685 760.0000
[2019-03-23 17:01:48,325] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3614.0102 2174930823.1582 247.0000
[2019-03-23 17:01:48,336] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3520.9379 2103947114.4575 178.0000
[2019-03-23 17:01:48,546] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3361.8628 2097849947.4172 179.0000
[2019-03-23 17:01:49,558] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 125000, evaluation results [125000.0, 3614.010203073189, 2174930823.1581597, 247.0, 3361.8628397963416, 2097849947.4171565, 179.0, 3520.9379026240454, 2103947114.4574823, 178.0, 2760.5190928132656, 2123848024.1684973, 760.0, 3120.0844811130446, 2108773030.7578847, 370.0]
[2019-03-23 17:01:50,168] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.9162460e-03 5.2142690e-07 9.9708313e-01 8.8801251e-08 3.8661728e-08], sum to 1.0000
[2019-03-23 17:01:50,172] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9667
[2019-03-23 17:01:50,177] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.33333333333333, 73.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 249429.0422820077, 249429.0422820074, 101488.4451813612], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4693200.0000, 
sim time next is 4693800.0000, 
raw observation next is [16.66666666666667, 72.83333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 256595.826460557, 256595.8264605567, 103909.2928646403], 
processed observation next is [1.0, 0.30434782608695654, 0.39393939393939414, 0.7283333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09503549128168778, 0.09503549128168767, 0.2534372996698544], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.23568952], dtype=float32), 0.44214308]. 
=============================================
[2019-03-23 17:01:51,326] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.2444813e-03 1.8260407e-08 9.9675554e-01 1.0350578e-10 5.8607556e-11], sum to 1.0000
[2019-03-23 17:01:51,336] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1559
[2019-03-23 17:01:51,341] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.0, 54.0, 1.0, 2.0, 0.3813661448717717, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7453258314111717, 6.9112, 6.9112, 77.32846344354104, 857038.042241896, 857038.042241896, 201195.8954283948], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4708800.0000, 
sim time next is 4709400.0000, 
raw observation next is [24.33333333333333, 53.5, 1.0, 2.0, 0.3619747710879287, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7097046157875041, 6.911200000000001, 6.9112, 77.32846344354104, 815179.6159759137, 815179.6159759134, 196472.8698567964], 
processed observation next is [1.0, 0.5217391304347826, 0.7424242424242422, 0.535, 1.0, 1.0, 0.20246846385991085, 0.0, 1.0, -0.25, 1.0, 1.0, 0.585292308267863, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.30191837628737545, 0.30191837628737533, 0.4792021216019424], 
reward next is 0.5208, 
noisyNet noise sample is [array([-1.11545], dtype=float32), 0.7935064]. 
=============================================
[2019-03-23 17:01:54,435] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8000, global step 127597: loss 1.5024
[2019-03-23 17:01:54,437] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8000, global step 127597: learning rate 0.0000
[2019-03-23 17:01:54,651] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8000, global step 127713: loss 1.0695
[2019-03-23 17:01:54,652] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8000, global step 127713: learning rate 0.0000
[2019-03-23 17:01:54,827] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8000, global step 127806: loss 0.9492
[2019-03-23 17:01:54,830] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8000, global step 127806: learning rate 0.0000
[2019-03-23 17:01:54,893] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8000, global step 127840: loss 0.9633
[2019-03-23 17:01:54,894] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8000, global step 127840: learning rate 0.0000
[2019-03-23 17:01:54,898] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8000, global step 127842: loss 0.9735
[2019-03-23 17:01:54,902] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8000, global step 127843: learning rate 0.0000
[2019-03-23 17:01:54,952] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8000, global step 127864: loss 0.8073
[2019-03-23 17:01:54,954] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8000, global step 127865: learning rate 0.0000
[2019-03-23 17:01:55,043] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8000, global step 127915: loss 1.0463
[2019-03-23 17:01:55,045] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8000, global step 127916: learning rate 0.0000
[2019-03-23 17:01:55,158] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8000, global step 127979: loss -23.6849
[2019-03-23 17:01:55,159] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8000, global step 127979: learning rate 0.0000
[2019-03-23 17:01:55,192] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8000, global step 127998: loss -30.3214
[2019-03-23 17:01:55,194] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8000, global step 127999: learning rate 0.0000
[2019-03-23 17:01:55,211] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8000, global step 128004: loss 2.2851
[2019-03-23 17:01:55,212] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8000, global step 128004: learning rate 0.0000
[2019-03-23 17:01:55,300] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8000, global step 128052: loss 0.3821
[2019-03-23 17:01:55,304] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8000, global step 128054: learning rate 0.0000
[2019-03-23 17:01:55,366] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8000, global step 128090: loss 0.7796
[2019-03-23 17:01:55,369] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8000, global step 128090: learning rate 0.0000
[2019-03-23 17:01:55,410] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8000, global step 128108: loss 1.1994
[2019-03-23 17:01:55,412] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8000, global step 128110: learning rate 0.0000
[2019-03-23 17:01:55,558] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8000, global step 128190: loss 0.8056
[2019-03-23 17:01:55,561] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8000, global step 128190: learning rate 0.0000
[2019-03-23 17:01:55,973] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8000, global step 128415: loss 1.0845
[2019-03-23 17:01:55,975] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8000, global step 128416: learning rate 0.0000
[2019-03-23 17:01:56,008] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8000, global step 128434: loss -72.5810
[2019-03-23 17:01:56,011] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8000, global step 128434: learning rate 0.0000
[2019-03-23 17:01:56,257] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4259996e-01 2.2393093e-15 8.5740000e-01 5.3138314e-18 1.5918502e-15], sum to 1.0000
[2019-03-23 17:01:56,261] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4515
[2019-03-23 17:01:56,264] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.2453972690225711, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4959382775432629, 6.9112, 6.9112, 77.32846344354104, 559846.9924780863, 559846.9924780863, 177086.9358289382], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4824000.0000, 
sim time next is 4824600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.2447632302932976, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4946561829479229, 6.9112, 6.9112, 77.32846344354104, 558399.9998033037, 558399.9998033037, 176941.546438062], 
processed observation next is [1.0, 0.8695652173913043, 0.5909090909090909, 1.0, 1.0, 1.0, 0.055954037866621995, 0.0, 1.0, -0.25, 1.0, 1.0, 0.27808026135417563, 0.0, 0.0, 0.5084288129206541, 0.20681481474196434, 0.20681481474196434, 0.43156474740990736], 
reward next is 0.5684, 
noisyNet noise sample is [array([-0.22049102], dtype=float32), 1.9989198]. 
=============================================
[2019-03-23 17:02:05,575] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.2814547e-04 5.3849769e-13 9.9937183e-01 1.1883379e-14 5.2886542e-13], sum to 1.0000
[2019-03-23 17:02:05,586] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0118
[2019-03-23 17:02:05,592] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.33333333333333, 80.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 313545.4621648108, 313545.4621648111, 128889.723520064], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5006400.0000, 
sim time next is 5007000.0000, 
raw observation next is [17.16666666666667, 81.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 309413.7862923169, 309413.7862923169, 127105.9820813317], 
processed observation next is [1.0, 0.9565217391304348, 0.4166666666666669, 0.8116666666666668, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.11459769862678404, 0.11459769862678404, 0.3100145904422725], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4673854], dtype=float32), -0.39332485]. 
=============================================
[2019-03-23 17:02:05,620] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[27.599026]
 [27.50678 ]
 [27.791735]
 [27.765228]
 [28.002048]], R is [[27.06664467]
 [26.79597855]
 [26.52801895]
 [26.26273918]
 [26.00011253]].
[2019-03-23 17:02:09,057] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8500, global step 135412: loss 2.3921
[2019-03-23 17:02:09,060] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8500, global step 135414: learning rate 0.0000
[2019-03-23 17:02:09,695] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8500, global step 135729: loss 0.9075
[2019-03-23 17:02:09,697] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8500, global step 135730: learning rate 0.0000
[2019-03-23 17:02:09,722] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8500, global step 135745: loss 0.7061
[2019-03-23 17:02:09,724] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8500, global step 135745: learning rate 0.0000
[2019-03-23 17:02:09,767] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8500, global step 135762: loss 0.6428
[2019-03-23 17:02:09,769] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8500, global step 135763: learning rate 0.0000
[2019-03-23 17:02:09,940] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8500, global step 135848: loss 0.2104
[2019-03-23 17:02:09,941] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8500, global step 135848: learning rate 0.0000
[2019-03-23 17:02:09,945] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8500, global step 135849: loss 0.4247
[2019-03-23 17:02:09,946] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8500, global step 135850: learning rate 0.0000
[2019-03-23 17:02:10,009] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8500, global step 135884: loss 0.3586
[2019-03-23 17:02:10,013] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8500, global step 135886: learning rate 0.0000
[2019-03-23 17:02:10,241] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8500, global step 136000: loss 0.0066
[2019-03-23 17:02:10,242] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8500, global step 136000: learning rate 0.0000
[2019-03-23 17:02:10,300] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8500, global step 136025: loss 0.0184
[2019-03-23 17:02:10,303] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8500, global step 136028: learning rate 0.0000
[2019-03-23 17:02:10,421] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8500, global step 136086: loss -0.0355
[2019-03-23 17:02:10,424] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8500, global step 136087: learning rate 0.0000
[2019-03-23 17:02:10,451] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8500, global step 136099: loss 0.0494
[2019-03-23 17:02:10,453] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8500, global step 136099: learning rate 0.0000
[2019-03-23 17:02:10,473] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8500, global step 136109: loss 0.0050
[2019-03-23 17:02:10,474] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8500, global step 136110: learning rate 0.0000
[2019-03-23 17:02:10,524] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8500, global step 136137: loss 0.0055
[2019-03-23 17:02:10,527] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8500, global step 136138: learning rate 0.0000
[2019-03-23 17:02:10,751] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8500, global step 136250: loss 0.0031
[2019-03-23 17:02:10,756] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8500, global step 136252: learning rate 0.0000
[2019-03-23 17:02:11,042] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8500, global step 136392: loss 0.2743
[2019-03-23 17:02:11,044] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8500, global step 136393: learning rate 0.0000
[2019-03-23 17:02:11,188] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8500, global step 136468: loss -1.4334
[2019-03-23 17:02:11,190] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8500, global step 136469: learning rate 0.0000
[2019-03-23 17:02:12,372] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.9183777e-01 1.3742996e-17 5.0816226e-01 9.0970853e-19 3.1700376e-19], sum to 1.0000
[2019-03-23 17:02:12,380] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3792
[2019-03-23 17:02:12,389] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 604733.109738498 W.
[2019-03-23 17:02:12,400] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.83333333333334, 78.83333333333333, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7847486550587577, 7.40321321382239, 6.9112, 77.32728857186596, 604733.109738498, 444939.7091195544, 139836.2630970664], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5129400.0000, 
sim time next is 5130000.0000, 
raw observation next is [23.0, 78.0, 1.0, 1.0, 0.2436661700706281, 1.0, 1.0, 0.2436661700706281, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32816778769448, 556081.6608332205, 556081.6608332202, 176518.7962012734], 
processed observation next is [0.0, 0.391304347826087, 0.6818181818181818, 0.78, 1.0, 0.5, 0.054582712588285114, 1.0, 0.5, 0.054582712588285114, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084268690057694, 0.20595617067897054, 0.20595617067897046, 0.43053364927139853], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.0849812], dtype=float32), 0.018473629]. 
=============================================
[2019-03-23 17:02:12,418] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[49.791256]
 [49.291252]
 [49.50154 ]
 [50.016033]
 [49.45154 ]], R is [[46.88447189]
 [46.41562653]
 [45.95146942]
 [45.4919548 ]
 [45.0370369 ]].
[2019-03-23 17:02:16,890] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.9873489e-01 1.5414978e-16 1.2651666e-03 2.1683650e-20 9.5464997e-19], sum to 1.0000
[2019-03-23 17:02:16,897] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3291
[2019-03-23 17:02:16,903] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 546584.5033302134 W.
[2019-03-23 17:02:16,907] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.0, 79.66666666666667, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7644973953193183, 7.255725633130131, 6.9112, 77.32760149751417, 546584.5033302134, 434690.8716998783, 136476.9789212108], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5208000.0000, 
sim time next is 5208600.0000, 
raw observation next is [22.0, 78.83333333333333, 1.0, 1.0, 0.2185738438686679, 1.0, 1.0, 0.2185738438686679, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32825640511244, 498343.9134292518, 498343.9134292518, 170533.1212309523], 
processed observation next is [1.0, 0.2608695652173913, 0.6363636363636364, 0.7883333333333333, 1.0, 0.5, 0.023217304835834868, 1.0, 0.5, 0.023217304835834868, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084274516586066, 0.18457181978861179, 0.18457181978861179, 0.4159344420267129], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1150225], dtype=float32), 0.103459775]. 
=============================================
[2019-03-23 17:02:24,662] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.40721410e-04 7.14683785e-17 9.99359310e-01 2.89825330e-18
 1.08110405e-17], sum to 1.0000
[2019-03-23 17:02:24,672] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9546
[2019-03-23 17:02:24,678] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.38333333333333, 80.66666666666666, 1.0, 2.0, 0.2246865269836975, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4512072498911575, 6.9112, 6.9112, 77.32846344354104, 512384.805375669, 512384.805375669, 169891.4553415692], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5363400.0000, 
sim time next is 5364000.0000, 
raw observation next is [22.2, 81.0, 1.0, 2.0, 0.2225402606996613, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4464000066242759, 6.9112, 6.9112, 77.32846344354104, 507307.9998109588, 507307.9998109588, 169097.0869369867], 
processed observation next is [1.0, 0.08695652173913043, 0.6454545454545454, 0.81, 1.0, 1.0, 0.0281753258745766, 0.0, 1.0, -0.25, 1.0, 1.0, 0.20914286660610848, 0.0, 0.0, 0.5084288129206541, 0.1878918517818366, 0.1878918517818366, 0.4124319193585042], 
reward next is 0.5876, 
noisyNet noise sample is [array([2.0025196], dtype=float32), 1.5372134]. 
=============================================
[2019-03-23 17:02:24,700] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[41.427937]
 [41.21635 ]
 [41.23245 ]
 [41.46043 ]
 [40.974945]], R is [[41.52323151]
 [41.69363022]
 [41.86035156]
 [42.02340317]
 [42.18291473]].
[2019-03-23 17:02:25,001] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9000, global step 143385: loss 0.0516
[2019-03-23 17:02:25,003] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9000, global step 143385: learning rate 0.0000
[2019-03-23 17:02:25,146] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.3609706e-02 1.5001864e-15 9.4639033e-01 2.3762361e-19 3.5288962e-16], sum to 1.0000
[2019-03-23 17:02:25,152] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3969
[2019-03-23 17:02:25,160] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.93333333333333, 79.66666666666667, 1.0, 2.0, 0.231204954300115, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4656507677918135, 6.9112, 6.9112, 77.32846344354104, 527594.4086957137, 527594.4086957137, 172303.1961269447], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5361600.0000, 
sim time next is 5362200.0000, 
raw observation next is [22.75, 80.0, 1.0, 2.0, 0.2291484490944753, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4610950361876585, 6.9112, 6.9112, 77.32846344354104, 522824.5514198895, 522824.5514198895, 171522.438131347], 
processed observation next is [1.0, 0.043478260869565216, 0.6704545454545454, 0.8, 1.0, 1.0, 0.0364355613680941, 0.0, 1.0, -0.25, 1.0, 1.0, 0.23013576598236934, 0.0, 0.0, 0.5084288129206541, 0.19363872274810723, 0.19363872274810723, 0.4183474100764561], 
reward next is 0.5817, 
noisyNet noise sample is [array([0.42639813], dtype=float32), 0.6504616]. 
=============================================
[2019-03-23 17:02:25,564] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9000, global step 143666: loss 0.0071
[2019-03-23 17:02:25,569] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9000, global step 143666: learning rate 0.0000
[2019-03-23 17:02:25,658] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9000, global step 143709: loss -4.5683
[2019-03-23 17:02:25,661] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9000, global step 143709: learning rate 0.0000
[2019-03-23 17:02:25,751] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9000, global step 143758: loss 2.3725
[2019-03-23 17:02:25,755] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9000, global step 143759: learning rate 0.0000
[2019-03-23 17:02:25,915] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9000, global step 143843: loss 2.5973
[2019-03-23 17:02:25,919] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9000, global step 143844: learning rate 0.0000
[2019-03-23 17:02:25,952] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9000, global step 143858: loss 0.0071
[2019-03-23 17:02:25,954] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9000, global step 143858: learning rate 0.0000
[2019-03-23 17:02:26,040] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9000, global step 143901: loss 0.3194
[2019-03-23 17:02:26,043] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9000, global step 143903: learning rate 0.0000
[2019-03-23 17:02:26,087] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9000, global step 143925: loss -101.6472
[2019-03-23 17:02:26,088] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9000, global step 143925: learning rate 0.0000
[2019-03-23 17:02:26,336] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9000, global step 144054: loss 0.9893
[2019-03-23 17:02:26,340] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9000, global step 144054: learning rate 0.0000
[2019-03-23 17:02:26,347] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9000, global step 144057: loss 0.5548
[2019-03-23 17:02:26,349] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9000, global step 144057: learning rate 0.0000
[2019-03-23 17:02:26,417] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9000, global step 144089: loss 2.7671
[2019-03-23 17:02:26,420] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9000, global step 144091: learning rate 0.0000
[2019-03-23 17:02:26,560] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9000, global step 144162: loss 0.0917
[2019-03-23 17:02:26,561] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9000, global step 144163: learning rate 0.0000
[2019-03-23 17:02:26,622] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9000, global step 144197: loss 2.6371
[2019-03-23 17:02:26,629] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9000, global step 144201: learning rate 0.0000
[2019-03-23 17:02:26,819] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9000, global step 144292: loss 0.6828
[2019-03-23 17:02:26,821] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9000, global step 144294: learning rate 0.0000
[2019-03-23 17:02:27,120] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9000, global step 144445: loss 0.5209
[2019-03-23 17:02:27,122] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9000, global step 144446: learning rate 0.0000
[2019-03-23 17:02:27,238] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9000, global step 144500: loss 4.5526
[2019-03-23 17:02:27,242] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9000, global step 144503: learning rate 0.0000
[2019-03-23 17:02:28,391] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.6993558e-04 4.8812816e-12 9.9973005e-01 1.9719205e-14 1.2318721e-15], sum to 1.0000
[2019-03-23 17:02:28,402] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0563
[2019-03-23 17:02:28,409] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3804727058785531, 6.9112, 6.9112, 77.32846344354104, 438475.8232771831, 438475.8232771831, 156634.9690143757], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5451000.0000, 
sim time next is 5451600.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3694434428467892, 6.9112, 6.9112, 77.32846344354104, 425748.0414464761, 425748.0414464761, 155259.0932364383], 
processed observation next is [1.0, 0.08695652173913043, 0.44090909090909086, 0.97, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.09920491835255603, 0.0, 0.0, 0.5084288129206541, 0.15768445979499116, 0.15768445979499116, 0.3786807152108251], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.30057257], dtype=float32), -0.95602155]. 
=============================================
[2019-03-23 17:02:28,965] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8473378e-05 6.5724618e-13 9.9998152e-01 3.9850749e-14 7.0981232e-14], sum to 1.0000
[2019-03-23 17:02:28,975] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2689
[2019-03-23 17:02:28,984] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.71666666666667, 96.83333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.382636143953313, 6.911199999999999, 6.9112, 77.32846344354104, 438675.6482906157, 438675.648290616, 158983.9779586305], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5439000.0000, 
sim time next is 5439600.0000, 
raw observation next is [18.8, 97.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3853865577374337, 6.9112, 6.9112, 77.32846344354104, 441579.8267552112, 441579.8267552112, 159565.2880752551], 
processed observation next is [1.0, 1.0, 0.49090909090909096, 0.97, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.12198079676776244, 0.0, 0.0, 0.5084288129206541, 0.16354808398341156, 0.16354808398341156, 0.38918362945184176], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8665678], dtype=float32), 0.45428357]. 
=============================================
[2019-03-23 17:02:36,299] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.6576340e-02 1.1652338e-17 9.5342362e-01 1.6120222e-21 4.6380220e-18], sum to 1.0000
[2019-03-23 17:02:36,311] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5406
[2019-03-23 17:02:36,319] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.6, 58.0, 1.0, 2.0, 0.6530986988006348, 0.0, 2.0, 0.0, 1.0, 2.0, 0.969912277736249, 6.911199999999999, 6.9112, 77.32846344354104, 1293877.646816407, 1293877.646816407, 277892.4319215031], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5587200.0000, 
sim time next is 5587800.0000, 
raw observation next is [26.88333333333333, 57.5, 1.0, 2.0, 0.7569120556781764, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9705539694161431, 6.911199999999999, 6.9112, 77.88841317985447, 1412398.470592041, 1412398.470592041, 294046.8255308677], 
processed observation next is [1.0, 0.6956521739130435, 0.8583333333333332, 0.575, 1.0, 1.0, 0.6961400695977205, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9579342420230617, -8.881784197001253e-17, 0.0, 0.512110440190242, 0.5231105446637189, 0.5231105446637189, 0.7171873793435797], 
reward next is 0.2828, 
noisyNet noise sample is [array([-1.5978185], dtype=float32), 1.2341516]. 
=============================================
[2019-03-23 17:02:36,547] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1067326e-03 2.6527461e-17 9.9889332e-01 1.7999825e-19 5.3078675e-19], sum to 1.0000
[2019-03-23 17:02:36,555] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2188
[2019-03-23 17:02:36,560] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.08333333333334, 92.0, 1.0, 2.0, 0.2094031532564251, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4169095535951515, 6.9112, 6.9112, 77.32846344354104, 475773.4984654625, 475773.4984654625, 164519.7700228724], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5601000.0000, 
sim time next is 5601600.0000, 
raw observation next is [20.0, 93.0, 1.0, 2.0, 0.2104080206274182, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4190875008694293, 6.9112, 6.9112, 77.32846344354104, 478161.3394236055, 478161.3394236055, 164807.1992387174], 
processed observation next is [1.0, 0.8695652173913043, 0.5454545454545454, 0.93, 1.0, 1.0, 0.013010025784272738, 0.0, 1.0, -0.25, 1.0, 1.0, 0.17012500124204188, 0.0, 0.0, 0.5084288129206541, 0.17709679237911313, 0.17709679237911313, 0.4019687786310181], 
reward next is 0.5980, 
noisyNet noise sample is [array([0.69206697], dtype=float32), 0.34058574]. 
=============================================
[2019-03-23 17:02:37,028] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.0068007e-04 3.4980881e-18 9.9939930e-01 4.3235409e-23 1.1287004e-19], sum to 1.0000
[2019-03-23 17:02:37,038] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4332
[2019-03-23 17:02:37,044] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.4, 92.5, 1.0, 2.0, 0.200167694795683, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3955069216877508, 6.9112, 6.9112, 77.32846344354104, 452835.8939845327, 452835.8939845327, 161194.4576988895], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5605800.0000, 
sim time next is 5606400.0000, 
raw observation next is [19.4, 92.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3922677871192424, 6.911199999999999, 6.9112, 77.32846344354104, 449276.5733919076, 449276.5733919079, 160645.1226810952], 
processed observation next is [1.0, 0.9130434782608695, 0.5181818181818181, 0.92, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.13181112445606055, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16639873088589172, 0.16639873088589183, 0.39181737239291514], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.05076298], dtype=float32), 0.4213655]. 
=============================================
[2019-03-23 17:02:37,772] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4416141e-04 7.8384741e-16 9.9985588e-01 4.5985297e-19 2.9136866e-18], sum to 1.0000
[2019-03-23 17:02:37,783] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2181
[2019-03-23 17:02:37,789] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.5, 93.0, 1.0, 2.0, 0.2040373690570616, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4040915388219204, 6.9112, 6.9112, 77.32846344354104, 462232.1956055719, 462232.1956055719, 162350.2914759716], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5604600.0000, 
sim time next is 5605200.0000, 
raw observation next is [19.4, 93.0, 1.0, 2.0, 0.2019554663507924, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3994263095392372, 6.911200000000001, 6.9112, 77.32846344354104, 457148.1786214009, 457148.1786214006, 161700.8010001208], 
processed observation next is [1.0, 0.9130434782608695, 0.5181818181818181, 0.93, 1.0, 1.0, 0.0024443329384904802, 0.0, 1.0, -0.25, 1.0, 1.0, 0.14203758505605316, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16931414023014849, 0.16931414023014837, 0.3943921975612702], 
reward next is 0.6056, 
noisyNet noise sample is [array([1.3183019], dtype=float32), -1.6652242]. 
=============================================
[2019-03-23 17:02:38,156] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 17:02:38,158] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:02:38,159] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:02:38,159] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:02:38,160] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:02:38,161] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:02:38,164] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:02:38,165] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:02:38,167] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:02:38,168] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:02:38,167] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:02:38,178] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run7
[2019-03-23 17:02:38,201] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run7
[2019-03-23 17:02:38,239] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run7
[2019-03-23 17:02:38,239] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run7
[2019-03-23 17:02:38,285] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run7
[2019-03-23 17:02:40,792] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00343612], dtype=float32), 0.002699358]
[2019-03-23 17:02:40,795] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.10307006333333, 59.87415494333334, 1.0, 2.0, 0.2394925258556208, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4593177212007455, 6.911200000000001, 6.9112, 95.55338769695034, 530731.5052509777, 530731.5052509774, 167241.1102097454]
[2019-03-23 17:02:40,795] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:02:40,798] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.3941018e-04 2.4899829e-14 9.9966061e-01 4.7754990e-17 4.6935260e-16], sampled 0.263561336126216
[2019-03-23 17:02:40,988] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00343612], dtype=float32), 0.002699358]
[2019-03-23 17:02:40,990] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.368440165, 40.882460165, 1.0, 2.0, 0.3606435689015858, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6998228092793959, 6.911199999999999, 6.9112, 95.55338769695034, 806287.2013398245, 806287.2013398248, 198107.9302994562]
[2019-03-23 17:02:40,991] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:02:40,994] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5797898e-04 7.1876500e-16 9.9984205e-01 6.6070803e-19 8.9007455e-18], sampled 0.07866007854774892
[2019-03-23 17:02:52,336] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00343612], dtype=float32), 0.002699358]
[2019-03-23 17:02:52,337] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.43333333333333, 69.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3496868600186371, 6.9112, 6.9112, 95.55338769695034, 402532.5884593407, 402532.5884593407, 157797.649486196]
[2019-03-23 17:02:52,341] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:02:52,343] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.7855844e-04 1.0880024e-14 9.9972147e-01 1.7862578e-17 1.8715616e-16], sampled 0.24830857696629827
[2019-03-23 17:03:01,731] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00343612], dtype=float32), 0.002699358]
[2019-03-23 17:03:01,736] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.398800365, 88.63179528500001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 335091.8571829389, 335091.8571829385, 138714.1282345587]
[2019-03-23 17:03:01,737] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:03:01,740] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.8072766e-04 1.7380959e-15 9.9981934e-01 1.9647150e-18 2.3837815e-17], sampled 0.9036855002370758
[2019-03-23 17:03:13,937] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00343612], dtype=float32), 0.002699358]
[2019-03-23 17:03:13,938] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.42382553833333, 62.77809160166666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3885198755738556, 6.9112, 6.9112, 95.55338769695034, 444982.0544661665, 444982.0544661665, 164745.421540679]
[2019-03-23 17:03:13,939] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:03:13,942] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.5990279e-04 8.9418448e-15 9.9974006e-01 1.4037884e-17 1.4888008e-16], sampled 0.8161726909093246
[2019-03-23 17:03:32,234] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00343612], dtype=float32), 0.002699358]
[2019-03-23 17:03:32,234] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.81427824, 68.61518385, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 325827.9184761535, 325827.9184761531, 145219.4422406396]
[2019-03-23 17:03:32,236] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:03:32,238] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.1416741e-04 1.8164445e-14 9.9968588e-01 3.3041663e-17 3.3005780e-16], sampled 0.7901104105029684
[2019-03-23 17:03:33,667] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00343612], dtype=float32), 0.002699358]
[2019-03-23 17:03:33,671] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.0, 75.5, 1.0, 2.0, 0.2048917222526563, 0.0, 2.0, 0.0, 1.0, 2.0, 0.406932096119706, 6.911200000000001, 6.9112, 95.55338769695034, 464870.0451650856, 464870.0451650853, 167784.3820396464]
[2019-03-23 17:03:33,673] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:03:33,676] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.0865595e-04 3.6125900e-15 9.9979132e-01 4.7484535e-18 5.4535889e-17], sampled 0.8239400357900789
[2019-03-23 17:03:44,696] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00343612], dtype=float32), 0.002699358]
[2019-03-23 17:03:44,698] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.1, 87.0, 1.0, 2.0, 0.2151301244073488, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4187534084202705, 6.9112, 6.9112, 95.55338769695034, 481888.1298469046, 481888.1298469046, 165526.8354302557]
[2019-03-23 17:03:44,700] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:03:44,702] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.1452845e-04 3.4154742e-15 9.9978548e-01 4.4049647e-18 5.0655813e-17], sampled 0.3590841799040967
[2019-03-23 17:03:53,447] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00343612], dtype=float32), 0.002699358]
[2019-03-23 17:03:53,448] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.8, 53.5, 1.0, 2.0, 0.2768782617260551, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5588917997894726, 6.9112, 6.9112, 95.55338769695034, 631825.7881694132, 631825.7881694132, 188785.9263881782]
[2019-03-23 17:03:53,449] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:03:53,452] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.7681527e-04 1.2145767e-15 9.9982327e-01 1.2508087e-18 1.5995226e-17], sampled 0.33837501828006467
[2019-03-23 17:04:11,383] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00343612], dtype=float32), 0.002699358]
[2019-03-23 17:04:11,384] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.33333333333333, 45.83333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 341423.0268152473, 341423.0268152473, 135271.8668831726]
[2019-03-23 17:04:11,384] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:04:11,387] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.3748307e-04 5.5881309e-15 9.9976248e-01 7.9230469e-18 8.8113655e-17], sampled 0.930685066557947
[2019-03-23 17:04:11,582] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00343612], dtype=float32), 0.002699358]
[2019-03-23 17:04:11,585] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.37862501833333, 56.24512975666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3172788407129207, 6.9112, 6.9112, 95.55338769695034, 367466.9562680532, 367466.9562680532, 151652.5248480268]
[2019-03-23 17:04:11,585] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:04:11,588] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.5720205e-04 7.3442500e-15 9.9974281e-01 1.0994308e-17 1.1980832e-16], sampled 0.6788046698220733
[2019-03-23 17:04:19,089] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2762.9493 2123905761.7383 759.0000
[2019-03-23 17:04:19,198] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3616.4229 2175215194.4523 245.0000
[2019-03-23 17:04:19,220] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3120.7607 2108857063.4292 368.0000
[2019-03-23 17:04:19,391] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3523.7186 2103912049.5382 178.0000
[2019-03-23 17:04:19,447] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3363.3488 2097963749.6929 179.0000
[2019-03-23 17:04:20,462] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 150000, evaluation results [150000.0, 3616.422933433318, 2175215194.4522634, 245.0, 3363.348758100122, 2097963749.6929233, 179.0, 3523.718646141135, 2103912049.5381584, 178.0, 2762.949331532842, 2123905761.7383084, 759.0, 3120.7606973204843, 2108857063.4291887, 368.0]
[2019-03-23 17:04:23,002] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9500, global step 151356: loss 0.0013
[2019-03-23 17:04:23,008] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9500, global step 151356: learning rate 0.0000
[2019-03-23 17:04:23,426] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9500, global step 151580: loss 0.0018
[2019-03-23 17:04:23,432] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9500, global step 151582: learning rate 0.0000
[2019-03-23 17:04:23,682] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9500, global step 151721: loss 0.0010
[2019-03-23 17:04:23,687] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9500, global step 151721: learning rate 0.0000
[2019-03-23 17:04:23,716] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9500, global step 151740: loss 0.0034
[2019-03-23 17:04:23,719] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9500, global step 151741: learning rate 0.0000
[2019-03-23 17:04:23,753] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9500, global step 151752: loss 0.0073
[2019-03-23 17:04:23,754] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9500, global step 151752: learning rate 0.0000
[2019-03-23 17:04:23,931] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9500, global step 151844: loss 0.0108
[2019-03-23 17:04:23,933] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9500, global step 151845: learning rate 0.0000
[2019-03-23 17:04:24,008] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9500, global step 151891: loss 0.0000
[2019-03-23 17:04:24,012] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9500, global step 151893: learning rate 0.0000
[2019-03-23 17:04:24,204] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9500, global step 151992: loss 0.0009
[2019-03-23 17:04:24,205] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9500, global step 151992: learning rate 0.0000
[2019-03-23 17:04:24,308] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9500, global step 152046: loss 0.0036
[2019-03-23 17:04:24,310] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9500, global step 152046: learning rate 0.0000
[2019-03-23 17:04:24,347] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9500, global step 152065: loss 0.0000
[2019-03-23 17:04:24,351] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9500, global step 152066: learning rate 0.0000
[2019-03-23 17:04:24,439] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9500, global step 152111: loss 0.0065
[2019-03-23 17:04:24,441] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9500, global step 152112: learning rate 0.0000
[2019-03-23 17:04:24,561] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9500, global step 152173: loss 0.0000
[2019-03-23 17:04:24,565] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9500, global step 152175: learning rate 0.0000
[2019-03-23 17:04:24,598] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9500, global step 152195: loss 0.0005
[2019-03-23 17:04:24,600] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9500, global step 152196: learning rate 0.0000
[2019-03-23 17:04:24,826] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9500, global step 152318: loss 0.0147
[2019-03-23 17:04:24,827] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9500, global step 152318: learning rate 0.0000
[2019-03-23 17:04:25,052] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9500, global step 152436: loss 0.0012
[2019-03-23 17:04:25,052] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9500, global step 152436: learning rate 0.0000
[2019-03-23 17:04:25,304] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9500, global step 152575: loss 0.0014
[2019-03-23 17:04:25,310] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9500, global step 152576: learning rate 0.0000
[2019-03-23 17:04:27,050] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5429587e-05 1.0817230e-09 9.9998462e-01 9.0047823e-11 2.3553648e-10], sum to 1.0000
[2019-03-23 17:04:27,056] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2120
[2019-03-23 17:04:27,059] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.6, 42.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 289724.222447913, 289724.2224479127, 110646.139026724], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5756400.0000, 
sim time next is 5757000.0000, 
raw observation next is [21.6, 42.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 291795.2117940459, 291795.2117940456, 111041.2994204129], 
processed observation next is [0.0, 0.6521739130434783, 0.6181818181818183, 0.42, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10807230066446145, 0.10807230066446133, 0.2708324376107632], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5913522], dtype=float32), -0.95441896]. 
=============================================
[2019-03-23 17:04:27,070] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[0.06857851]
 [0.06595734]
 [0.06383482]
 [0.0586578 ]
 [0.05759862]], R is [[0.07089768]
 [0.07018871]
 [0.06948682]
 [0.06879195]
 [0.06810403]].
[2019-03-23 17:04:31,364] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5430529e-05 9.4205710e-10 9.9998462e-01 8.4383212e-12 3.4441089e-12], sum to 1.0000
[2019-03-23 17:04:31,369] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2741
[2019-03-23 17:04:31,374] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.76666666666667, 46.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3095081318601311, 6.9112, 6.9112, 77.32846344354104, 357656.265733831, 357656.265733831, 147089.7461078947], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5856000.0000, 
sim time next is 5856600.0000, 
raw observation next is [24.58333333333333, 47.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3099111914499789, 6.9112, 6.9112, 77.32846344354104, 358081.9919733327, 358081.9919733327, 147175.5963084467], 
processed observation next is [1.0, 0.782608695652174, 0.7537878787878786, 0.47, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.014158844928541327, 0.0, 0.0, 0.5084288129206541, 0.13262295999012322, 0.13262295999012322, 0.3589648690449919], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.137571], dtype=float32), -0.07854119]. 
=============================================
[2019-03-23 17:04:32,295] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1213322e-04 3.0844192e-09 9.9988782e-01 1.5276889e-11 1.5314935e-11], sum to 1.0000
[2019-03-23 17:04:32,301] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4981
[2019-03-23 17:04:32,308] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.18333333333333, 71.83333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3137077557066303, 6.911199999999999, 6.9112, 77.32846344354104, 362727.666904875, 362727.6669048753, 147343.8620779376], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5871000.0000, 
sim time next is 5871600.0000, 
raw observation next is [20.0, 73.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3156944770672099, 6.9112, 6.9112, 77.32846344354104, 365055.2965525914, 365055.2965525914, 147537.7321625425], 
processed observation next is [1.0, 1.0, 0.5454545454545454, 0.73, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.022420681524585557, 0.0, 0.0, 0.5084288129206541, 0.13520566538984866, 0.13520566538984866, 0.3598481272257134], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.49308524], dtype=float32), 0.32007602]. 
=============================================
[2019-03-23 17:04:35,886] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.95201981e-04 1.05794444e-11 9.99204814e-01 3.74724157e-15
 9.18600157e-13], sum to 1.0000
[2019-03-23 17:04:35,894] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0515
[2019-03-23 17:04:35,908] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.2, 47.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.397434052314002, 6.9112, 6.9112, 77.32846335318558, 453639.0405409174, 453639.0405409174, 162663.3468220135], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5937600.0000, 
sim time next is 5938200.0000, 
raw observation next is [27.2, 47.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3769284357467228, 6.9112, 6.9112, 77.32846344298174, 430413.0711510499, 430413.0711510499, 159726.1053029054], 
processed observation next is [1.0, 0.7391304347826086, 0.8727272727272727, 0.47, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.10989776535246117, 0.0, 0.0, 0.5084288129169767, 0.15941224857446293, 0.15941224857446293, 0.3895758665924522], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.49213088], dtype=float32), 2.669817]. 
=============================================
[2019-03-23 17:04:37,873] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10000, global step 159308: loss 3.7724
[2019-03-23 17:04:37,873] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10000, global step 159308: learning rate 0.0000
[2019-03-23 17:04:38,495] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10000, global step 159657: loss 3.9806
[2019-03-23 17:04:38,496] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10000, global step 159657: learning rate 0.0000
[2019-03-23 17:04:38,509] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10000, global step 159661: loss 3.9508
[2019-03-23 17:04:38,513] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10000, global step 159661: learning rate 0.0000
[2019-03-23 17:04:38,610] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10000, global step 159720: loss 4.0049
[2019-03-23 17:04:38,612] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10000, global step 159721: learning rate 0.0000
[2019-03-23 17:04:38,763] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10000, global step 159794: loss 3.9989
[2019-03-23 17:04:38,767] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10000, global step 159795: learning rate 0.0000
[2019-03-23 17:04:38,832] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10000, global step 159818: loss 3.9618
[2019-03-23 17:04:38,834] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10000, global step 159818: learning rate 0.0000
[2019-03-23 17:04:38,863] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10000, global step 159831: loss 4.0817
[2019-03-23 17:04:38,865] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10000, global step 159833: learning rate 0.0000
[2019-03-23 17:04:39,273] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10000, global step 160048: loss 4.0413
[2019-03-23 17:04:39,273] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10000, global step 160048: loss 4.0552
[2019-03-23 17:04:39,275] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10000, global step 160048: learning rate 0.0000
[2019-03-23 17:04:39,275] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10000, global step 160048: learning rate 0.0000
[2019-03-23 17:04:39,403] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.3627126e-05 2.6438697e-11 9.9997640e-01 8.7588720e-13 2.9552541e-12], sum to 1.0000
[2019-03-23 17:04:39,411] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6437
[2019-03-23 17:04:39,416] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10000, global step 160116: loss 4.1108
[2019-03-23 17:04:39,418] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.1, 59.33333333333334, 1.0, 2.0, 0.538613245014726, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9596213257892359, 6.926015931096275, 6.9112, 77.32842692696046, 1163147.469305606, 1158335.560196047, 259141.2968781657], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6010800.0000, 
sim time next is 6011400.0000, 
raw observation next is [26.1, 59.66666666666666, 1.0, 2.0, 0.5115674712500053, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9501919418577511, 6.942743874673891, 6.9112, 77.32837715724426, 1132235.905163465, 1121991.111284775, 254346.626131715], 
processed observation next is [1.0, 0.5652173913043478, 0.8227272727272728, 0.5966666666666666, 1.0, 1.0, 0.3894593390625066, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9288456312253588, 0.0031543874673890747, 0.0, 0.5084282455947629, 0.4193466315420241, 0.4155522634388055, 0.6203576247115], 
reward next is 0.2219, 
noisyNet noise sample is [array([-1.5184095], dtype=float32), -2.5163102]. 
=============================================
[2019-03-23 17:04:39,423] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10000, global step 160118: learning rate 0.0000
[2019-03-23 17:04:39,436] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10000, global step 160129: loss 4.1316
[2019-03-23 17:04:39,436] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10000, global step 160129: learning rate 0.0000
[2019-03-23 17:04:39,477] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10000, global step 160141: loss 4.2237
[2019-03-23 17:04:39,480] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10000, global step 160143: learning rate 0.0000
[2019-03-23 17:04:39,577] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10000, global step 160195: loss 4.1330
[2019-03-23 17:04:39,580] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10000, global step 160196: learning rate 0.0000
[2019-03-23 17:04:39,933] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10000, global step 160366: loss 4.1979
[2019-03-23 17:04:39,936] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10000, global step 160368: learning rate 0.0000
[2019-03-23 17:04:40,122] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10000, global step 160458: loss 4.2265
[2019-03-23 17:04:40,125] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10000, global step 160459: learning rate 0.0000
[2019-03-23 17:04:40,176] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10000, global step 160488: loss 4.2432
[2019-03-23 17:04:40,176] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10000, global step 160488: learning rate 0.0000
[2019-03-23 17:04:44,797] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.8178520e-02 4.7779988e-11 9.5182145e-01 2.7709061e-11 4.6665154e-11], sum to 1.0000
[2019-03-23 17:04:44,805] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5029
[2019-03-23 17:04:44,809] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.3, 45.5, 1.0, 2.0, 0.4108442446319003, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7879609101115984, 6.9112, 6.9112, 77.32846344354104, 910918.9990284728, 910918.9990284728, 204179.5547743513], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6101400.0000, 
sim time next is 6102000.0000, 
raw observation next is [24.4, 45.0, 1.0, 2.0, 0.4173065511154784, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8004032897575105, 6.911199999999999, 6.9112, 77.32846344354104, 925302.7585148967, 925302.7585148971, 206194.315000135], 
processed observation next is [1.0, 0.6521739130434783, 0.7454545454545454, 0.45, 1.0, 1.0, 0.27163318889434795, 0.0, 1.0, -0.25, 1.0, 1.0, 0.7148618425107295, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3427047253758877, 0.3427047253758878, 0.5029129634149634], 
reward next is 0.4971, 
noisyNet noise sample is [array([-1.1880443], dtype=float32), -0.552178]. 
=============================================
[2019-03-23 17:04:44,829] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[18.190533]
 [17.981134]
 [17.763441]
 [17.613638]
 [17.426886]], R is [[18.76625633]
 [19.08059502]
 [19.39146233]
 [19.70031929]
 [20.01632309]].
[2019-03-23 17:04:47,060] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.9654208e-04 5.9135721e-07 9.9960285e-01 3.9296278e-08 4.5130357e-09], sum to 1.0000
[2019-03-23 17:04:47,070] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5024
[2019-03-23 17:04:47,073] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.2, 84.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 315470.7561463673, 315470.7561463676, 134636.2612102206], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6141600.0000, 
sim time next is 6142200.0000, 
raw observation next is [17.28333333333333, 83.0, 1.0, 2.0, 0.2213281574890694, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4131711823410859, 6.9112, 6.9112, 77.99976149914694, 480733.9039777207, 480733.9039777207, 154244.5861870152], 
processed observation next is [1.0, 0.08695652173913043, 0.4219696969696969, 0.83, 1.0, 1.0, 0.026660196861336728, 0.0, 1.0, -0.25, 1.0, 1.0, 0.16167311763012276, 0.0, 0.0, 0.5128425469886645, 0.1780495940658225, 0.1780495940658225, 0.3762063077732078], 
reward next is 0.6238, 
noisyNet noise sample is [array([-1.0579011], dtype=float32), 0.31918076]. 
=============================================
[2019-03-23 17:04:49,737] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.0594257e-03 2.9192166e-09 9.9794060e-01 4.2826305e-11 1.9128803e-10], sum to 1.0000
[2019-03-23 17:04:49,744] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2922
[2019-03-23 17:04:49,752] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.5, 76.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3477290508055066, 6.9112, 6.9112, 77.32846344354104, 400282.8401446967, 400282.8401446967, 152997.3409251583], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6208800.0000, 
sim time next is 6209400.0000, 
raw observation next is [20.5, 76.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3477322393939086, 6.911200000000001, 6.9112, 77.32846344354104, 400286.116823387, 400286.1168233868, 152998.1005751606], 
processed observation next is [1.0, 0.8695652173913043, 0.5681818181818182, 0.76, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.06818891341986949, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14825411734199517, 0.14825411734199512, 0.37316609896380637], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.29718053], dtype=float32), 1.8297974]. 
=============================================
[2019-03-23 17:04:50,698] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.4059585e-04 1.0620833e-09 9.9945945e-01 1.6695305e-10 9.2669199e-11], sum to 1.0000
[2019-03-23 17:04:50,708] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5193
[2019-03-23 17:04:50,713] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.4, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3738113608558821, 6.9112, 6.9112, 77.32846344354104, 428747.0576361442, 428747.0576361442, 157661.2261560604], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6224400.0000, 
sim time next is 6225000.0000, 
raw observation next is [19.3, 90.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3752187844099227, 6.9112, 6.9112, 77.32846344354104, 430429.0025165689, 430429.0025165689, 157783.7805363788], 
processed observation next is [0.0, 0.043478260869565216, 0.5136363636363637, 0.905, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.10745540629988956, 0.0, 0.0, 0.5084288129206541, 0.15941814908021068, 0.15941814908021068, 0.384838489113119], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.41914403], dtype=float32), -1.4792777]. 
=============================================
[2019-03-23 17:04:50,737] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[7.8523335]
 [8.079918 ]
 [7.7297034]
 [7.8688583]
 [7.8337374]], R is [[7.96776104]
 [7.88808346]
 [7.80920267]
 [7.73111057]
 [7.65379953]].
[2019-03-23 17:04:53,914] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10500, global step 167332: loss 1.6094
[2019-03-23 17:04:53,916] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10500, global step 167334: learning rate 0.0000
[2019-03-23 17:04:54,482] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10500, global step 167622: loss 0.3217
[2019-03-23 17:04:54,484] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10500, global step 167622: learning rate 0.0000
[2019-03-23 17:04:54,673] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10500, global step 167717: loss -130.1962
[2019-03-23 17:04:54,676] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10500, global step 167717: learning rate 0.0000
[2019-03-23 17:04:54,697] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10500, global step 167726: loss -22.4952
[2019-03-23 17:04:54,704] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10500, global step 167728: learning rate 0.0000
[2019-03-23 17:04:54,704] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10500, global step 167729: loss -26.9532
[2019-03-23 17:04:54,707] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10500, global step 167729: learning rate 0.0000
[2019-03-23 17:04:54,851] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10500, global step 167802: loss 3.6564
[2019-03-23 17:04:54,852] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10500, global step 167802: learning rate 0.0000
[2019-03-23 17:04:54,941] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10500, global step 167847: loss 0.3769
[2019-03-23 17:04:54,942] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10500, global step 167847: learning rate 0.0000
[2019-03-23 17:04:55,341] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10500, global step 168051: loss 0.1732
[2019-03-23 17:04:55,343] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10500, global step 168051: learning rate 0.0000
[2019-03-23 17:04:55,384] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10500, global step 168069: loss -8.6842
[2019-03-23 17:04:55,385] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10500, global step 168069: learning rate 0.0000
[2019-03-23 17:04:55,426] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10500, global step 168092: loss -313.2737
[2019-03-23 17:04:55,430] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10500, global step 168094: learning rate 0.0000
[2019-03-23 17:04:55,509] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10500, global step 168132: loss 0.2337
[2019-03-23 17:04:55,514] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10500, global step 168133: learning rate 0.0000
[2019-03-23 17:04:55,594] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10500, global step 168179: loss 1.6630
[2019-03-23 17:04:55,596] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10500, global step 168179: learning rate 0.0000
[2019-03-23 17:04:55,631] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10500, global step 168198: loss 3.7417
[2019-03-23 17:04:55,633] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10500, global step 168198: learning rate 0.0000
[2019-03-23 17:04:55,970] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10500, global step 168366: loss -174.1181
[2019-03-23 17:04:55,972] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10500, global step 168366: learning rate 0.0000
[2019-03-23 17:04:56,085] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10500, global step 168427: loss 4.8982
[2019-03-23 17:04:56,086] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10500, global step 168427: learning rate 0.0000
[2019-03-23 17:04:56,262] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10500, global step 168514: loss 1.6716
[2019-03-23 17:04:56,264] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10500, global step 168514: learning rate 0.0000
[2019-03-23 17:05:00,723] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.5162730e-01 1.4383390e-14 3.4837276e-01 6.0385799e-16 1.6701063e-15], sum to 1.0000
[2019-03-23 17:05:00,731] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6399
[2019-03-23 17:05:00,745] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 567627.9747038307 W.
[2019-03-23 17:05:00,750] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.4, 76.0, 1.0, 2.0, 0.2491854770115041, 1.0, 1.0, 0.2491854770115041, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 567627.9747038307, 567627.9747038307, 179665.5860840244], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6397800.0000, 
sim time next is 6398400.0000, 
raw observation next is [24.4, 76.0, 1.0, 2.0, 0.2486977328902133, 1.0, 2.0, 0.2486977328902133, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 566380.787563185, 566380.7875631853, 179733.906960877], 
processed observation next is [1.0, 0.043478260869565216, 0.7454545454545454, 0.76, 1.0, 1.0, 0.06087216611276661, 1.0, 1.0, 0.06087216611276661, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20977066206043887, 0.209770662060439, 0.4383753828314073], 
reward next is 0.5616, 
noisyNet noise sample is [array([0.28727987], dtype=float32), 1.6297212]. 
=============================================
[2019-03-23 17:05:07,541] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.2081269e-05 5.9584795e-11 9.9996793e-01 5.9141485e-12 1.0742281e-11], sum to 1.0000
[2019-03-23 17:05:07,548] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1762
[2019-03-23 17:05:07,558] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.76666666666667, 52.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3668998540077795, 6.9112, 6.9112, 77.32846344354104, 426874.3603314558, 426874.3603314558, 132606.8636172481], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6524400.0000, 
sim time next is 6525000.0000, 
raw observation next is [19.95, 51.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3228651126945512, 6.911200000000001, 6.9112, 77.32846344354104, 375621.7841234512, 375621.7841234509, 126043.2419747272], 
processed observation next is [1.0, 0.5217391304347826, 0.5431818181818181, 0.515, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.03266444670650174, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13911917930498194, 0.13911917930498183, 0.30742254140177366], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.18438588], dtype=float32), -0.29731452]. 
=============================================
[2019-03-23 17:05:07,577] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[13.737523]
 [13.769557]
 [13.678256]
 [13.61712 ]
 [13.58639 ]], R is [[13.53584385]
 [13.40048599]
 [13.92052078]
 [14.44621563]
 [14.96877956]].
[2019-03-23 17:05:09,235] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 17:05:09,236] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:05:09,237] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:05:09,238] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:05:09,238] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:05:09,239] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:05:09,241] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:05:09,241] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:05:09,243] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:05:09,245] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:05:09,245] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:05:09,258] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run8
[2019-03-23 17:05:09,284] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run8
[2019-03-23 17:05:09,309] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run8
[2019-03-23 17:05:09,311] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run8
[2019-03-23 17:05:09,335] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run8
[2019-03-23 17:05:23,513] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00310335], dtype=float32), 0.001385229]
[2019-03-23 17:05:23,513] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.87939698, 97.56994171, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3116085482117269, 6.9112, 6.9112, 95.55338769695034, 360479.7980367824, 360479.7980367824, 151438.9710037777]
[2019-03-23 17:05:23,515] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:05:23,519] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.3466774e-06 8.1302770e-11 9.9999666e-01 2.5523286e-12 1.5208881e-12], sampled 0.42197737181107675
[2019-03-23 17:06:06,808] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00310335], dtype=float32), 0.001385229]
[2019-03-23 17:06:06,810] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [31.08333333333334, 47.33333333333334, 1.0, 2.0, 0.4456966843573765, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8621941703968506, 6.967532724303128, 6.9112, 95.5531231145518, 1010057.548557606, 987449.9240466035, 246061.7477486548]
[2019-03-23 17:06:06,811] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:06:06,814] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.2975565e-07 3.0260665e-14 9.9999952e-01 1.6849746e-16 2.2957804e-16], sampled 0.6898539891887622
[2019-03-23 17:06:08,258] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00310335], dtype=float32), 0.001385229]
[2019-03-23 17:06:08,260] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3433723670557756, 6.911199999999999, 6.9112, 77.32846344354104, 395807.3064579038, 395807.3064579041, 151953.6853173587]
[2019-03-23 17:06:08,261] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:06:08,264] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.1573567e-06 1.1003760e-10 9.9999583e-01 3.6123214e-12 2.2045278e-12], sampled 0.6058526714312091
[2019-03-23 17:06:14,020] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00310335], dtype=float32), 0.001385229]
[2019-03-23 17:06:14,022] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.6, 72.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3120743705207548, 6.9112, 6.9112, 95.55338769695034, 361710.6646929584, 361710.6646929584, 150783.825967837]
[2019-03-23 17:06:14,024] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:06:14,027] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.44942646e-06 1.08014375e-10 9.99996543e-01 3.65401980e-12
 2.12107003e-12], sampled 0.7679812364903056
[2019-03-23 17:06:19,835] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00310335], dtype=float32), 0.001385229]
[2019-03-23 17:06:19,835] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.2, 53.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3748920027344347, 6.9112, 6.9112, 95.55338769695034, 429478.131257091, 429478.131257091, 162831.6690579448]
[2019-03-23 17:06:19,836] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:06:19,839] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.9076480e-06 2.4569603e-11 9.9999714e-01 5.7790984e-13 4.2471051e-13], sampled 0.5987301245361583
[2019-03-23 17:06:20,647] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00310335], dtype=float32), 0.001385229]
[2019-03-23 17:06:20,648] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.12399839, 85.814865215, 1.0, 2.0, 0.2297810848936591, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4522083800776852, 6.911200000000001, 6.9112, 95.55338769695034, 518522.9820845666, 518522.9820845663, 170369.902913188]
[2019-03-23 17:06:20,649] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:06:20,651] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.6310566e-07 1.6687041e-12 9.9999905e-01 2.4219442e-14 1.9091889e-14], sampled 0.004864918553187714
[2019-03-23 17:06:31,279] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00310335], dtype=float32), 0.001385229]
[2019-03-23 17:06:31,280] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.93333333333334, 50.0, 1.0, 2.0, 0.3591418726562966, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7116432347828608, 6.9112, 6.9112, 95.55338769695034, 814020.4486850573, 814020.4486850573, 204360.6045407846]
[2019-03-23 17:06:31,281] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:06:31,285] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.2009657e-06 6.0568694e-13 9.9999881e-01 6.2985734e-15 6.6301983e-15], sampled 0.29092510121367376
[2019-03-23 17:06:50,171] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3615.0043 2175249159.4172 245.0000
[2019-03-23 17:06:50,181] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3362.1743 2098038232.9775 179.0000
[2019-03-23 17:06:50,391] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2760.0075 2124051796.3784 757.0000
[2019-03-23 17:06:50,396] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3118.8146 2109045993.6110 368.0000
[2019-03-23 17:06:50,436] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3519.0325 2104095443.0865 178.0000
[2019-03-23 17:06:51,449] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 175000, evaluation results [175000.0, 3615.004316682312, 2175249159.4172263, 245.0, 3362.17426541809, 2098038232.977526, 179.0, 3519.032511138161, 2104095443.0864863, 178.0, 2760.0074851005825, 2124051796.3784225, 757.0, 3118.8146269445274, 2109045993.6109858, 368.0]
[2019-03-23 17:06:52,090] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11000, global step 175344: loss 2.2528
[2019-03-23 17:06:52,093] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11000, global step 175344: learning rate 0.0000
[2019-03-23 17:06:52,714] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11000, global step 175676: loss 2.1913
[2019-03-23 17:06:52,718] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11000, global step 175677: learning rate 0.0000
[2019-03-23 17:06:52,746] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11000, global step 175694: loss 2.1818
[2019-03-23 17:06:52,749] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11000, global step 175694: learning rate 0.0000
[2019-03-23 17:06:52,803] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11000, global step 175728: loss 2.1467
[2019-03-23 17:06:52,804] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11000, global step 175729: learning rate 0.0000
[2019-03-23 17:06:52,822] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11000, global step 175736: loss 2.1320
[2019-03-23 17:06:52,823] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11000, global step 175736: loss 2.1563
[2019-03-23 17:06:52,825] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11000, global step 175736: learning rate 0.0000
[2019-03-23 17:06:52,829] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11000, global step 175737: learning rate 0.0000
[2019-03-23 17:06:53,121] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11000, global step 175892: loss 2.4228
[2019-03-23 17:06:53,122] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11000, global step 175892: learning rate 0.0000
[2019-03-23 17:06:53,427] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11000, global step 176055: loss 2.9003
[2019-03-23 17:06:53,429] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11000, global step 176055: learning rate 0.0000
[2019-03-23 17:06:53,472] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11000, global step 176077: loss 2.8554
[2019-03-23 17:06:53,474] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11000, global step 176079: learning rate 0.0000
[2019-03-23 17:06:53,478] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11000, global step 176081: loss 2.8492
[2019-03-23 17:06:53,482] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11000, global step 176081: learning rate 0.0000
[2019-03-23 17:06:53,537] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11000, global step 176119: loss 2.9030
[2019-03-23 17:06:53,542] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11000, global step 176121: learning rate 0.0000
[2019-03-23 17:06:53,717] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11000, global step 176212: loss 2.8950
[2019-03-23 17:06:53,723] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11000, global step 176213: learning rate 0.0000
[2019-03-23 17:06:53,752] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11000, global step 176227: loss 2.8775
[2019-03-23 17:06:53,752] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11000, global step 176227: learning rate 0.0000
[2019-03-23 17:06:53,883] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11000, global step 176296: loss 2.7547
[2019-03-23 17:06:53,884] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11000, global step 176296: learning rate 0.0000
[2019-03-23 17:06:54,151] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11000, global step 176441: loss 2.6697
[2019-03-23 17:06:54,155] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11000, global step 176441: learning rate 0.0000
[2019-03-23 17:06:54,300] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11000, global step 176525: loss 2.4976
[2019-03-23 17:06:54,304] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11000, global step 176526: learning rate 0.0000
[2019-03-23 17:06:54,675] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.7805340e-02 7.3455803e-10 9.8219460e-01 2.5449892e-13 4.3917001e-12], sum to 1.0000
[2019-03-23 17:06:54,686] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0886
[2019-03-23 17:06:54,691] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.36666666666667, 59.0, 1.0, 2.0, 0.2862094150602388, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5406732379985608, 6.9112, 6.9112, 77.32846344354104, 627041.2642411974, 627041.2642411974, 168758.4805047371], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6606600.0000, 
sim time next is 6607200.0000, 
raw observation next is [21.63333333333334, 59.0, 1.0, 2.0, 0.2942527353507886, 0.0, 2.0, 0.0, 1.0, 2.0, 0.559131259461562, 6.9112, 6.9112, 77.32846344354104, 647629.1968314908, 647629.1968314908, 171564.9064685512], 
processed observation next is [1.0, 0.4782608695652174, 0.61969696969697, 0.59, 1.0, 1.0, 0.11781591918848575, 0.0, 1.0, -0.25, 1.0, 1.0, 0.37018751351651713, 0.0, 0.0, 0.5084288129206541, 0.23986266549314475, 0.23986266549314475, 0.4184509913867102], 
reward next is 0.5815, 
noisyNet noise sample is [array([1.3850697], dtype=float32), 0.4518646]. 
=============================================
[2019-03-23 17:06:59,611] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4913230e-05 1.6453136e-11 9.9998510e-01 1.5470256e-13 7.2320066e-14], sum to 1.0000
[2019-03-23 17:06:59,619] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1292
[2019-03-23 17:06:59,626] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.2, 96.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3184277917880057, 6.911199999999999, 6.9112, 77.32846344354104, 368194.653806314, 368194.6538063143, 147869.2775210674], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6737400.0000, 
sim time next is 6738000.0000, 
raw observation next is [17.2, 96.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3172591817465164, 6.9112, 6.9112, 77.32846344354104, 366845.3698344065, 366845.3698344065, 147734.5331509935], 
processed observation next is [1.0, 1.0, 0.41818181818181815, 0.96, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.024655973923594882, 0.0, 0.0, 0.5084288129206541, 0.1358686554942246, 0.1358686554942246, 0.3603281296365695], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6443418], dtype=float32), -1.1419505]. 
=============================================
[2019-03-23 17:06:59,641] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[18.813198]
 [18.860296]
 [18.903421]
 [18.937996]
 [18.973698]], R is [[18.60141373]
 [18.41539955]
 [18.23124504]
 [18.04893303]
 [17.86844444]].
[2019-03-23 17:07:03,783] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.6411786e-06 6.9959040e-13 9.9999034e-01 3.1840997e-17 3.7899274e-13], sum to 1.0000
[2019-03-23 17:07:03,791] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6384
[2019-03-23 17:07:03,794] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.0, 61.66666666666667, 1.0, 2.0, 0.2012428501655025, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3989093283411614, 6.911200000000001, 6.9112, 77.32846344354104, 456131.1299416714, 456131.1299416711, 162062.5324845317], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6807000.0000, 
sim time next is 6807600.0000, 
raw observation next is [23.8, 62.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3930390285182364, 6.9112, 6.9112, 77.32846344354104, 449736.1248021297, 449736.1248021297, 161114.4100745177], 
processed observation next is [1.0, 0.8260869565217391, 0.7181818181818183, 0.62, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1329128978831949, 0.0, 0.0, 0.5084288129206541, 0.16656893511189988, 0.16656893511189988, 0.3929619757915066], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0427254], dtype=float32), -1.2984383]. 
=============================================
[2019-03-23 17:07:06,912] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11500, global step 183230: loss 1.9027
[2019-03-23 17:07:06,914] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11500, global step 183231: learning rate 0.0000
[2019-03-23 17:07:07,714] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11500, global step 183666: loss -44.4933
[2019-03-23 17:07:07,716] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11500, global step 183666: learning rate 0.0000
[2019-03-23 17:07:07,720] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11500, global step 183668: loss 0.2654
[2019-03-23 17:07:07,724] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11500, global step 183670: learning rate 0.0000
[2019-03-23 17:07:07,725] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11500, global step 183670: loss 0.2687
[2019-03-23 17:07:07,727] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11500, global step 183670: learning rate 0.0000
[2019-03-23 17:07:07,815] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11500, global step 183722: loss 0.3452
[2019-03-23 17:07:07,818] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11500, global step 183722: learning rate 0.0000
[2019-03-23 17:07:07,877] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11500, global step 183752: loss 1.7833
[2019-03-23 17:07:07,879] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11500, global step 183752: learning rate 0.0000
[2019-03-23 17:07:08,154] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11500, global step 183924: loss -44.3802
[2019-03-23 17:07:08,155] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11500, global step 183924: learning rate 0.0000
[2019-03-23 17:07:08,344] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11500, global step 184045: loss -126.4173
[2019-03-23 17:07:08,345] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11500, global step 184046: learning rate 0.0000
[2019-03-23 17:07:08,515] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11500, global step 184138: loss 3.5574
[2019-03-23 17:07:08,517] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11500, global step 184138: learning rate 0.0000
[2019-03-23 17:07:08,581] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11500, global step 184170: loss 5.8316
[2019-03-23 17:07:08,583] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11500, global step 184170: learning rate 0.0000
[2019-03-23 17:07:08,589] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11500, global step 184170: loss 0.0722
[2019-03-23 17:07:08,592] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11500, global step 184171: learning rate 0.0000
[2019-03-23 17:07:08,658] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11500, global step 184208: loss 0.1848
[2019-03-23 17:07:08,664] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11500, global step 184210: learning rate 0.0000
[2019-03-23 17:07:08,692] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1412630e-02 7.3143630e-11 9.8858738e-01 1.1416371e-12 2.5142343e-12], sum to 1.0000
[2019-03-23 17:07:08,703] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0023
[2019-03-23 17:07:08,708] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.1, 91.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3732095908110428, 6.911199999999999, 6.9112, 77.32846344354104, 428361.126895634, 428361.1268956343, 157311.4080601911], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6917400.0000, 
sim time next is 6918000.0000, 
raw observation next is [19.2, 91.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7293157502168744, 7.027901251602344, 6.9112, 77.32815168479175, 456761.4548242551, 418859.4280642684, 129399.3916992923], 
processed observation next is [0.0, 0.043478260869565216, 0.509090909090909, 0.91, 0.0, 0.5, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.613308214595535, 0.011670125160234423, 0.0, 0.5084267631303989, 0.16917090919416855, 0.15513312150528458, 0.3156082724372983], 
reward next is 0.1009, 
noisyNet noise sample is [array([1.2746501], dtype=float32), 1.3166178]. 
=============================================
[2019-03-23 17:07:08,721] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[32.55075 ]
 [31.88706 ]
 [32.852535]
 [33.11826 ]
 [33.042545]], R is [[33.2621994 ]
 [32.92957687]
 [32.60028076]
 [32.27427673]
 [31.95153427]].
[2019-03-23 17:07:08,723] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11500, global step 184242: loss 1.1284
[2019-03-23 17:07:08,727] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11500, global step 184242: learning rate 0.0000
[2019-03-23 17:07:09,054] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11500, global step 184406: loss 0.4363
[2019-03-23 17:07:09,056] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11500, global step 184406: learning rate 0.0000
[2019-03-23 17:07:09,066] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11500, global step 184412: loss 0.2364
[2019-03-23 17:07:09,067] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11500, global step 184412: learning rate 0.0000
[2019-03-23 17:07:09,171] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11500, global step 184467: loss 0.0519
[2019-03-23 17:07:09,172] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11500, global step 184467: learning rate 0.0000
[2019-03-23 17:07:12,255] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3153096e-02 6.7480244e-13 9.8684686e-01 3.8611293e-16 1.5113740e-12], sum to 1.0000
[2019-03-23 17:07:12,257] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1328
[2019-03-23 17:07:12,267] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 93.66666666666666, 1.0, 2.0, 0.351352987432849, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7074926955709042, 6.9112, 6.9112, 82.03922015041368, 801931.600299938, 801931.600299938, 205747.7839875115], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7006200.0000, 
sim time next is 7006800.0000, 
raw observation next is [20.9, 94.33333333333334, 1.0, 2.0, 0.2981881800267017, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6004208155041207, 6.911199999999999, 6.9112, 77.32846344354066, 680532.0890858687, 680532.0890858689, 188282.2463319089], 
processed observation next is [1.0, 0.08695652173913043, 0.5863636363636363, 0.9433333333333335, 1.0, 1.0, 0.12273522503337714, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4291725935773154, -8.881784197001253e-17, 0.0, 0.5084288129206516, 0.2520489218836551, 0.25204892188365513, 0.4592249910534363], 
reward next is 0.5408, 
noisyNet noise sample is [array([0.47266173], dtype=float32), 1.2232436]. 
=============================================
[2019-03-23 17:07:22,297] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12000, global step 191064: loss 0.0033
[2019-03-23 17:07:22,298] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12000, global step 191064: learning rate 0.0000
[2019-03-23 17:07:23,399] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12000, global step 191599: loss 0.0121
[2019-03-23 17:07:23,400] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12000, global step 191600: learning rate 0.0000
[2019-03-23 17:07:23,492] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12000, global step 191649: loss 0.0063
[2019-03-23 17:07:23,494] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12000, global step 191649: learning rate 0.0000
[2019-03-23 17:07:23,592] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12000, global step 191696: loss 0.0016
[2019-03-23 17:07:23,596] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12000, global step 191696: learning rate 0.0000
[2019-03-23 17:07:23,622] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12000, global step 191711: loss 0.0005
[2019-03-23 17:07:23,625] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12000, global step 191712: learning rate 0.0000
[2019-03-23 17:07:23,677] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12000, global step 191741: loss 0.0038
[2019-03-23 17:07:23,679] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12000, global step 191742: learning rate 0.0000
[2019-03-23 17:07:23,712] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.7240967e-05 8.4858955e-09 9.9997270e-01 9.5340136e-10 2.1503462e-10], sum to 1.0000
[2019-03-23 17:07:23,721] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5354
[2019-03-23 17:07:23,726] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [12.28333333333333, 88.83333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 199971.7109396313, 199971.710939631, 86304.71851513525], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7188600.0000, 
sim time next is 7189200.0000, 
raw observation next is [12.2, 89.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 197834.2120703247, 197834.2120703244, 85809.6575790076], 
processed observation next is [1.0, 0.21739130434782608, 0.1909090909090909, 0.89, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07327193039641655, 0.07327193039641644, 0.20929184775367707], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.26562732], dtype=float32), 0.9637247]. 
=============================================
[2019-03-23 17:07:24,287] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12000, global step 192040: loss 0.0019
[2019-03-23 17:07:24,289] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12000, global step 192040: learning rate 0.0000
[2019-03-23 17:07:24,385] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12000, global step 192092: loss 0.0037
[2019-03-23 17:07:24,387] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12000, global step 192092: learning rate 0.0000
[2019-03-23 17:07:24,393] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12000, global step 192096: loss 0.0009
[2019-03-23 17:07:24,396] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12000, global step 192096: learning rate 0.0000
[2019-03-23 17:07:24,414] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12000, global step 192105: loss 0.0018
[2019-03-23 17:07:24,417] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12000, global step 192105: learning rate 0.0000
[2019-03-23 17:07:24,569] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12000, global step 192182: loss 0.0136
[2019-03-23 17:07:24,573] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12000, global step 192183: learning rate 0.0000
[2019-03-23 17:07:24,613] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12000, global step 192201: loss 0.0065
[2019-03-23 17:07:24,617] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12000, global step 192202: learning rate 0.0000
[2019-03-23 17:07:24,685] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12000, global step 192239: loss 0.0010
[2019-03-23 17:07:24,691] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12000, global step 192239: learning rate 0.0000
[2019-03-23 17:07:25,012] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12000, global step 192404: loss 0.0076
[2019-03-23 17:07:25,014] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12000, global step 192404: learning rate 0.0000
[2019-03-23 17:07:25,115] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12000, global step 192454: loss 0.0034
[2019-03-23 17:07:25,118] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12000, global step 192456: learning rate 0.0000
[2019-03-23 17:07:25,278] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12000, global step 192538: loss 0.0082
[2019-03-23 17:07:25,281] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12000, global step 192538: learning rate 0.0000
[2019-03-23 17:07:26,224] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.5526303e-04 1.4620226e-10 9.9974471e-01 4.1382904e-11 5.6502017e-12], sum to 1.0000
[2019-03-23 17:07:26,237] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5228
[2019-03-23 17:07:26,244] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.46666666666667, 67.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 288953.0645186757, 288953.0645186757, 116871.3982335683], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7252800.0000, 
sim time next is 7253400.0000, 
raw observation next is [18.38333333333333, 67.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 288750.3574082655, 288750.3574082658, 116709.4773107076], 
processed observation next is [1.0, 0.9565217391304348, 0.47196969696969676, 0.675, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10694457681787611, 0.10694457681787622, 0.2846572617334332], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.60999227], dtype=float32), -0.886978]. 
=============================================
[2019-03-23 17:07:30,042] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.0077943e-03 3.0689036e-13 9.9799228e-01 3.4478116e-16 1.3559278e-15], sum to 1.0000
[2019-03-23 17:07:30,052] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9850
[2019-03-23 17:07:30,055] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.08333333333334, 46.16666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3277753840300172, 6.9112, 6.9112, 77.32846344354104, 378107.7282218347, 378107.7282218347, 149823.806691293], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7321800.0000, 
sim time next is 7322400.0000, 
raw observation next is [25.0, 46.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3274652539288802, 6.911199999999999, 6.9112, 77.32846344354104, 377939.7814750216, 377939.7814750219, 149601.7153841373], 
processed observation next is [1.0, 0.782608695652174, 0.7727272727272727, 0.46, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.03923607704125746, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1399776968426006, 0.1399776968426007, 0.3648822326442373], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.41180074], dtype=float32), 0.17101978]. 
=============================================
[2019-03-23 17:07:33,017] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.3700966e-06 3.0320941e-09 9.9999559e-01 2.4554855e-11 1.3008491e-11], sum to 1.0000
[2019-03-23 17:07:33,025] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6935
[2019-03-23 17:07:33,032] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.7, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.330126122662066, 6.911200000000001, 6.9112, 77.32846344354104, 382682.4750505915, 382682.4750505912, 148240.4764265339], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7356600.0000, 
sim time next is 7357200.0000, 
raw observation next is [17.7, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3187083795754643, 6.911199999999999, 6.9112, 77.32846344354104, 369452.0999090101, 369452.0999090103, 146948.8308966595], 
processed observation next is [1.0, 0.13043478260869565, 0.44090909090909086, 0.87, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.02672625653637755, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13683411107741114, 0.13683411107741122, 0.35841178267477924], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2057585], dtype=float32), 0.13498376]. 
=============================================
[2019-03-23 17:07:33,701] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.7781451e-05 2.9416590e-14 9.9998224e-01 1.1511338e-17 4.6848410e-15], sum to 1.0000
[2019-03-23 17:07:33,708] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4589
[2019-03-23 17:07:33,714] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.3, 53.0, 1.0, 2.0, 0.5056392879261444, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9517330843075636, 6.946714587977209, 6.9112, 77.32837575884842, 1124898.57975548, 1113364.181058586, 256882.2413121562], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7390800.0000, 
sim time next is 7391400.0000, 
raw observation next is [28.38333333333334, 52.66666666666667, 1.0, 2.0, 0.5605342932161191, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9716213493862876, 6.912861913710049, 6.9112, 77.32843802545248, 1187454.405545735, 1186914.650142144, 267603.8856026277], 
processed observation next is [1.0, 0.5652173913043478, 0.9265151515151518, 0.5266666666666667, 1.0, 1.0, 0.4506678665201489, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9594590705518397, 0.0001661913710049312, 0.0, 0.5084286457986396, 0.43979792797990186, 0.43959801857116443, 0.6526924039088481], 
reward next is 0.3390, 
noisyNet noise sample is [array([0.34149882], dtype=float32), 0.70457786]. 
=============================================
[2019-03-23 17:07:35,650] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.2187454e-05 1.3410309e-15 9.9997783e-01 5.3698121e-18 4.3517495e-15], sum to 1.0000
[2019-03-23 17:07:35,661] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6729
[2019-03-23 17:07:35,665] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.18333333333333, 64.0, 1.0, 2.0, 0.3835288639387041, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7765749701107378, 6.911199999999999, 6.9112, 77.32846344354104, 873643.2948287601, 873643.2948287604, 219509.1689699499], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7405800.0000, 
sim time next is 7406400.0000, 
raw observation next is [25.16666666666667, 68.0, 1.0, 2.0, 0.2395919899848824, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4840280995032585, 6.9112, 6.9112, 77.32846344354104, 546665.227444737, 546665.227444737, 175562.4205318501], 
processed observation next is [1.0, 0.7391304347826086, 0.7803030303030305, 0.68, 1.0, 1.0, 0.04948998748110299, 0.0, 1.0, -0.25, 1.0, 1.0, 0.262897285004655, 0.0, 0.0, 0.5084288129206541, 0.20246860275731, 0.20246860275731, 0.4282010256874393], 
reward next is 0.5718, 
noisyNet noise sample is [array([0.8340123], dtype=float32), 0.54507685]. 
=============================================
[2019-03-23 17:07:38,251] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12500, global step 199043: loss 0.4153
[2019-03-23 17:07:38,260] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12500, global step 199043: learning rate 0.0000
[2019-03-23 17:07:39,270] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12500, global step 199549: loss 0.2077
[2019-03-23 17:07:39,274] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12500, global step 199549: learning rate 0.0000
[2019-03-23 17:07:39,393] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12500, global step 199612: loss 0.1409
[2019-03-23 17:07:39,396] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12500, global step 199613: learning rate 0.0000
[2019-03-23 17:07:39,539] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12500, global step 199684: loss 0.5184
[2019-03-23 17:07:39,541] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12500, global step 199685: learning rate 0.0000
[2019-03-23 17:07:39,571] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12500, global step 199700: loss 0.1865
[2019-03-23 17:07:39,573] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12500, global step 199700: learning rate 0.0000
[2019-03-23 17:07:39,652] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12500, global step 199743: loss -0.0140
[2019-03-23 17:07:39,653] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12500, global step 199743: learning rate 0.0000
[2019-03-23 17:07:40,168] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 17:07:40,169] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:07:40,171] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:07:40,171] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:07:40,172] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:07:40,172] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:07:40,175] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:07:40,175] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:07:40,178] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:07:40,180] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:07:40,180] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:07:40,196] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run9
[2019-03-23 17:07:40,220] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run9
[2019-03-23 17:07:40,221] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run9
[2019-03-23 17:07:40,267] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run9
[2019-03-23 17:07:40,268] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run9
[2019-03-23 17:07:45,609] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00361002], dtype=float32), 0.0012783051]
[2019-03-23 17:07:45,610] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.80200700666667, 50.66904686333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 250812.032144967, 250812.032144967, 101604.6433255606]
[2019-03-23 17:07:45,611] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:07:45,613] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.75040860e-02 1.13854785e-11 9.52495933e-01 3.76820259e-14
 2.91847189e-12], sampled 0.6372708219906558
[2019-03-23 17:08:12,373] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00361002], dtype=float32), 0.0012783051]
[2019-03-23 17:08:12,374] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.4, 49.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 265167.2565923765, 265167.2565923765, 103227.8233921151]
[2019-03-23 17:08:12,375] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:08:12,379] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.8024271e-02 3.9059464e-11 9.7197568e-01 1.9066930e-13 9.1844041e-12], sampled 0.8961066246575536
[2019-03-23 17:08:16,396] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00361002], dtype=float32), 0.0012783051]
[2019-03-23 17:08:16,396] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.88333333333333, 80.66666666666666, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7782056002510185, 7.609038470714443, 6.9112, 95.55122644051107, 721289.7984857898, 441236.6472024197, 143318.0390425453]
[2019-03-23 17:08:16,399] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:08:16,401] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.63453400e-01 1.07605934e-13 8.36546600e-01 9.67405593e-17
 3.32782237e-14], sampled 0.3874285138240723
[2019-03-23 17:08:31,343] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00361002], dtype=float32), 0.0012783051]
[2019-03-23 17:08:31,346] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.16666666666666, 61.33333333333334, 1.0, 2.0, 0.2545401938054868, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5152275994115582, 6.911199999999999, 6.9112, 77.32846344354104, 579992.2097907502, 579992.2097907505, 180429.604134659]
[2019-03-23 17:08:31,347] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:08:31,353] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.6191548e-01 7.3151771e-14 7.3808450e-01 5.7023846e-17 2.7552364e-14], sampled 0.21411017222401263
[2019-03-23 17:08:31,354] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 579992.2097907502 W.
[2019-03-23 17:09:20,700] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3203.9252 2064888882.2433 501.0000
[2019-03-23 17:09:20,848] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3056.3597 2053992516.4823 507.0000
[2019-03-23 17:09:20,988] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 2878.7995 2069477796.5712 627.0000
[2019-03-23 17:09:21,134] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2545.0855 2081259532.6161 1023.0000
[2019-03-23 17:09:21,154] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3283.7668 2131337000.5672 506.0000
[2019-03-23 17:09:22,169] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 200000, evaluation results [200000.0, 3283.7667797760037, 2131337000.5671635, 506.0, 3056.3596906991415, 2053992516.48226, 507.0, 3203.925170612743, 2064888882.2433257, 501.0, 2545.085455583934, 2081259532.616051, 1023.0, 2878.79950386472, 2069477796.571224, 627.0]
[2019-03-23 17:09:22,180] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.5179344e-02 1.0977691e-13 9.1482067e-01 8.3648094e-18 2.2472009e-14], sum to 1.0000
[2019-03-23 17:09:22,187] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4077
[2019-03-23 17:09:22,198] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.2584498173074336, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5233657858402918, 6.9112, 6.9112, 77.32846344354104, 588403.3335700224, 588403.3335700224, 181899.9094169799], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7482600.0000, 
sim time next is 7483200.0000, 
raw observation next is [28.1, 57.0, 1.0, 2.0, 0.2563367435425305, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5190056347325372, 6.9112, 6.9112, 77.32846344354104, 583808.5151811973, 583808.5151811973, 181170.5383734868], 
processed observation next is [0.0, 0.6086956521739131, 0.9136363636363637, 0.57, 1.0, 1.0, 0.07042092942816311, 0.0, 1.0, -0.25, 1.0, 1.0, 0.31286519247505323, 0.0, 0.0, 0.5084288129206541, 0.21622537599303604, 0.21622537599303604, 0.4418793618865532], 
reward next is 0.5581, 
noisyNet noise sample is [array([2.158321], dtype=float32), 0.75720054]. 
=============================================
[2019-03-23 17:09:22,250] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.80493701e-02 1.25729478e-13 9.61950660e-01 1.01646766e-16
 3.36113854e-15], sum to 1.0000
[2019-03-23 17:09:22,256] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5807
[2019-03-23 17:09:22,261] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.9, 79.0, 1.0, 2.0, 0.2268991531266313, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4564691056524072, 6.9112, 6.9112, 77.32846344354104, 517667.5570437208, 517667.5570437208, 170975.6826164208], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7516800.0000, 
sim time next is 7517400.0000, 
raw observation next is [22.86666666666667, 79.50000000000001, 1.0, 2.0, 0.2274477562714971, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4576673029076756, 6.9112, 6.9112, 77.32846344354104, 518940.9803611533, 518940.9803611533, 171165.9285039094], 
processed observation next is [0.0, 0.0, 0.6757575757575759, 0.7950000000000002, 1.0, 1.0, 0.034309695339371366, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2252390041538223, 0.0, 0.0, 0.5084288129206541, 0.19220036309672345, 0.19220036309672345, 0.41747787439977907], 
reward next is 0.5825, 
noisyNet noise sample is [array([1.4877858], dtype=float32), 0.45195276]. 
=============================================
[2019-03-23 17:09:22,313] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12500, global step 200071: loss 0.7714
[2019-03-23 17:09:22,314] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12500, global step 200071: learning rate 0.0000
[2019-03-23 17:09:22,360] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12500, global step 200097: loss 0.8657
[2019-03-23 17:09:22,362] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12500, global step 200097: learning rate 0.0000
[2019-03-23 17:09:22,384] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12500, global step 200108: loss -0.7440
[2019-03-23 17:09:22,386] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12500, global step 200109: learning rate 0.0000
[2019-03-23 17:09:22,434] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12500, global step 200140: loss 1.5769
[2019-03-23 17:09:22,438] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12500, global step 200140: learning rate 0.0000
[2019-03-23 17:09:22,611] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12500, global step 200230: loss 0.7484
[2019-03-23 17:09:22,614] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12500, global step 200231: learning rate 0.0000
[2019-03-23 17:09:22,614] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12500, global step 200231: loss -42.3563
[2019-03-23 17:09:22,620] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12500, global step 200232: learning rate 0.0000
[2019-03-23 17:09:22,641] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12500, global step 200243: loss -70.4093
[2019-03-23 17:09:22,642] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12500, global step 200243: learning rate 0.0000
[2019-03-23 17:09:22,878] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12500, global step 200372: loss 8.9575
[2019-03-23 17:09:22,881] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12500, global step 200372: learning rate 0.0000
[2019-03-23 17:09:23,066] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12500, global step 200471: loss -28.9791
[2019-03-23 17:09:23,069] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12500, global step 200474: learning rate 0.0000
[2019-03-23 17:09:23,300] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12500, global step 200597: loss 2.7651
[2019-03-23 17:09:23,302] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12500, global step 200597: learning rate 0.0000
[2019-03-23 17:09:23,758] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.7142619e-03 3.9976050e-15 9.9428576e-01 5.5925185e-17 8.5313557e-15], sum to 1.0000
[2019-03-23 17:09:23,764] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2564
[2019-03-23 17:09:23,769] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.16666666666667, 77.0, 1.0, 2.0, 0.2269639958439889, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4565299683895634, 6.911199999999999, 6.9112, 77.32846344354104, 517799.1518913109, 517799.1518913112, 170932.6862091857], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7514400.0000, 
sim time next is 7515000.0000, 
raw observation next is [23.1, 77.5, 1.0, 2.0, 0.2271021731664719, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4568279316275969, 6.9112, 6.9112, 77.32846344354104, 518119.3596316671, 518119.3596316671, 170977.2488461178], 
processed observation next is [0.0, 1.0, 0.6863636363636364, 0.775, 1.0, 1.0, 0.033877716458089874, 0.0, 1.0, -0.25, 1.0, 1.0, 0.22403990232513843, 0.0, 0.0, 0.5084288129206541, 0.19189605912283966, 0.19189605912283966, 0.41701768011248247], 
reward next is 0.5830, 
noisyNet noise sample is [array([0.3725991], dtype=float32), 0.7246034]. 
=============================================
[2019-03-23 17:09:23,797] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[46.271572]
 [46.95299 ]
 [46.83077 ]
 [46.235264]
 [46.78239 ]], R is [[46.13713455]
 [46.25885391]
 [46.37954712]
 [46.49900055]
 [46.61674881]].
[2019-03-23 17:09:26,430] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2775174e-01 2.0598642e-12 8.7224829e-01 1.8521925e-16 2.5226612e-13], sum to 1.0000
[2019-03-23 17:09:26,437] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3597
[2019-03-23 17:09:26,444] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.65, 62.0, 1.0, 2.0, 0.4899129269826822, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558843.8468794656, 558843.8468794656, 140660.7245701365], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7561800.0000, 
sim time next is 7562400.0000, 
raw observation next is [26.83333333333334, 61.33333333333334, 1.0, 2.0, 0.2457968294906248, 0.0, 2.0, 0.0, 1.0, 1.0, 0.4970454181908652, 6.911200000000001, 6.9112, 77.32846344354104, 560587.5949878696, 560587.5949878693, 177571.1533056127], 
processed observation next is [0.0, 0.5217391304347826, 0.8560606060606063, 0.6133333333333334, 1.0, 1.0, 0.057246036863281, 0.0, 1.0, -0.25, 1.0, 0.5, 0.2814934545583789, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20762503518069245, 0.2076250351806923, 0.43310037391612854], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.63363934], dtype=float32), -0.8012755]. 
=============================================
[2019-03-23 17:09:27,036] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.8761020e-01 3.9316619e-13 6.1238980e-01 7.4850852e-17 2.1243724e-14], sum to 1.0000
[2019-03-23 17:09:27,044] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3177
[2019-03-23 17:09:27,051] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 541841.3744448094 W.
[2019-03-23 17:09:27,055] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.28333333333333, 91.0, 1.0, 2.0, 0.2374668243485558, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4779654430937402, 6.9112, 6.9112, 77.32846344354104, 541841.3744448094, 541841.3744448094, 173389.4845333899], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7584600.0000, 
sim time next is 7585200.0000, 
raw observation next is [21.0, 91.0, 1.0, 2.0, 0.232306007732686, 1.0, 1.0, 0.232306007732686, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 530087.2786098759, 530087.2786098759, 173770.0765836311], 
processed observation next is [0.0, 0.8260869565217391, 0.5909090909090909, 0.91, 1.0, 1.0, 0.04038250966585749, 1.0, 0.5, 0.04038250966585749, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19632862170736146, 0.19632862170736146, 0.4238294550820271], 
reward next is 0.5762, 
noisyNet noise sample is [array([0.48207244], dtype=float32), -0.7404607]. 
=============================================
[2019-03-23 17:09:35,462] A3C_AGENT_WORKER-Thread-22 INFO:Local step 13000, global step 207018: loss 0.6462
[2019-03-23 17:09:35,464] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 13000, global step 207019: learning rate 0.0000
[2019-03-23 17:09:35,713] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4373891e-04 1.8310067e-10 9.9985623e-01 9.2887052e-11 1.5712407e-11], sum to 1.0000
[2019-03-23 17:09:35,721] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8838
[2019-03-23 17:09:35,725] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [15.9, 70.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 241690.8254122976, 241690.8254122973, 97134.79974568699], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7780800.0000, 
sim time next is 7781400.0000, 
raw observation next is [15.8, 70.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 240744.2133140436, 240744.2133140434, 96854.98199529611], 
processed observation next is [1.0, 0.043478260869565216, 0.35454545454545455, 0.705, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08916452344964577, 0.0891645234496457, 0.23623166340316124], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6037262], dtype=float32), -0.58987993]. 
=============================================
[2019-03-23 17:09:36,370] A3C_AGENT_WORKER-Thread-3 INFO:Local step 13000, global step 207498: loss 0.0215
[2019-03-23 17:09:36,373] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 13000, global step 207500: learning rate 0.0000
[2019-03-23 17:09:36,454] A3C_AGENT_WORKER-Thread-18 INFO:Local step 13000, global step 207536: loss 0.0062
[2019-03-23 17:09:36,457] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 13000, global step 207537: learning rate 0.0000
[2019-03-23 17:09:36,552] A3C_AGENT_WORKER-Thread-17 INFO:Local step 13000, global step 207593: loss 0.0036
[2019-03-23 17:09:36,559] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 13000, global step 207594: learning rate 0.0000
[2019-03-23 17:09:36,667] A3C_AGENT_WORKER-Thread-19 INFO:Local step 13000, global step 207649: loss 0.0003
[2019-03-23 17:09:36,670] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 13000, global step 207649: learning rate 0.0000
[2019-03-23 17:09:36,727] A3C_AGENT_WORKER-Thread-16 INFO:Local step 13000, global step 207681: loss 0.0013
[2019-03-23 17:09:36,733] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 13000, global step 207681: learning rate 0.0000
[2019-03-23 17:09:37,323] A3C_AGENT_WORKER-Thread-11 INFO:Local step 13000, global step 208001: loss 0.0099
[2019-03-23 17:09:37,324] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 13000, global step 208001: learning rate 0.0000
[2019-03-23 17:09:37,443] A3C_AGENT_WORKER-Thread-2 INFO:Local step 13000, global step 208073: loss 0.0041
[2019-03-23 17:09:37,447] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 13000, global step 208073: learning rate 0.0000
[2019-03-23 17:09:37,566] A3C_AGENT_WORKER-Thread-14 INFO:Local step 13000, global step 208145: loss 0.0247
[2019-03-23 17:09:37,569] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 13000, global step 208147: learning rate 0.0000
[2019-03-23 17:09:37,580] A3C_AGENT_WORKER-Thread-10 INFO:Local step 13000, global step 208153: loss 0.0094
[2019-03-23 17:09:37,582] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 13000, global step 208154: learning rate 0.0000
[2019-03-23 17:09:37,765] A3C_AGENT_WORKER-Thread-13 INFO:Local step 13000, global step 208252: loss 0.0293
[2019-03-23 17:09:37,770] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 13000, global step 208254: learning rate 0.0000
[2019-03-23 17:09:37,782] A3C_AGENT_WORKER-Thread-12 INFO:Local step 13000, global step 208265: loss 0.0471
[2019-03-23 17:09:37,784] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 13000, global step 208265: learning rate 0.0000
[2019-03-23 17:09:37,968] A3C_AGENT_WORKER-Thread-15 INFO:Local step 13000, global step 208371: loss 0.0454
[2019-03-23 17:09:37,971] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 13000, global step 208372: learning rate 0.0000
[2019-03-23 17:09:38,042] A3C_AGENT_WORKER-Thread-20 INFO:Local step 13000, global step 208425: loss 0.1159
[2019-03-23 17:09:38,043] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 13000, global step 208425: learning rate 0.0000
[2019-03-23 17:09:38,328] A3C_AGENT_WORKER-Thread-21 INFO:Local step 13000, global step 208591: loss 0.2599
[2019-03-23 17:09:38,331] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 13000, global step 208591: learning rate 0.0000
[2019-03-23 17:09:38,415] A3C_AGENT_WORKER-Thread-9 INFO:Local step 13000, global step 208631: loss 0.2300
[2019-03-23 17:09:38,417] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 13000, global step 208632: learning rate 0.0000
[2019-03-23 17:09:41,857] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.3431272e-05 6.8215355e-12 9.9996662e-01 3.1549256e-15 5.3811231e-14], sum to 1.0000
[2019-03-23 17:09:41,866] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1921
[2019-03-23 17:09:41,869] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.9, 93.5, 1.0, 2.0, 0.3480983518706309, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6945214449477447, 6.911200000000001, 6.9112, 77.32846344354104, 791991.4431105879, 791991.4431105875, 198546.7413139175], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7901400.0000, 
sim time next is 7902000.0000, 
raw observation next is [20.0, 93.0, 1.0, 2.0, 0.3376001508446972, 0.0, 2.0, 0.0, 1.0, 2.0, 0.673866355518275, 6.911199999999999, 6.9112, 77.32846344354104, 768244.6200757561, 768244.6200757563, 195612.0854219847], 
processed observation next is [1.0, 0.4782608695652174, 0.5454545454545454, 0.93, 1.0, 1.0, 0.17200018855587146, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5340947935975358, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2845350444725023, 0.28453504447250233, 0.47710264737069435], 
reward next is 0.5229, 
noisyNet noise sample is [array([0.3214714], dtype=float32), 0.8614028]. 
=============================================
[2019-03-23 17:09:41,881] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[18.439684]
 [17.9432  ]
 [17.450764]
 [17.154425]
 [16.81328 ]], R is [[19.10770416]
 [19.43236732]
 [19.76477242]
 [20.10990715]
 [20.45466995]].
[2019-03-23 17:09:44,077] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:09:44,078] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:09:44,094] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run2
[2019-03-23 17:09:44,962] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:09:44,963] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:09:44,967] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run2
[2019-03-23 17:09:45,017] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:09:45,017] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:09:45,022] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run2
[2019-03-23 17:09:45,260] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:09:45,261] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:09:45,263] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run2
[2019-03-23 17:09:45,281] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:09:45,282] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:09:45,286] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run2
[2019-03-23 17:09:45,309] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:09:45,310] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:09:45,312] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run2
[2019-03-23 17:09:45,738] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:09:45,738] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:09:45,740] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run2
[2019-03-23 17:09:45,791] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:09:45,792] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:09:45,793] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:09:45,793] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:09:45,794] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run2
[2019-03-23 17:09:45,821] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run2
[2019-03-23 17:09:45,847] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:09:45,848] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:09:45,854] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run2
[2019-03-23 17:09:45,879] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:09:45,880] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:09:45,882] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run2
[2019-03-23 17:09:45,910] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:09:45,910] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:09:45,911] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run2
[2019-03-23 17:09:45,943] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:09:45,944] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:09:45,945] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run2
[2019-03-23 17:09:45,980] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:09:45,981] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:09:45,982] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run2
[2019-03-23 17:09:46,081] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:09:46,081] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:09:46,082] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run2
[2019-03-23 17:09:46,170] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:09:46,171] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:09:46,198] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run2
[2019-03-23 17:09:51,335] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9086851e-04 1.5438923e-08 9.9980921e-01 1.4527543e-10 1.1200351e-10], sum to 1.0000
[2019-03-23 17:09:51,344] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9571
[2019-03-23 17:09:51,351] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [13.66666666666667, 84.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 222858.7115485393, 222858.711548539, 92159.77463550898], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 98400.0000, 
sim time next is 99000.0000, 
raw observation next is [13.5, 85.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 220065.1423394215, 220065.1423394212, 91463.78237062087], 
processed observation next is [1.0, 0.13043478260869565, 0.25, 0.85, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08150560827385982, 0.0815056082738597, 0.22308239602590457], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.825736], dtype=float32), -1.978786]. 
=============================================
[2019-03-23 17:09:51,372] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[2.438555 ]
 [2.4506977]
 [2.3873856]
 [2.251149 ]
 [2.4022949]], R is [[2.36509943]
 [2.34144855]
 [2.31803417]
 [2.29485393]
 [2.27190542]].
[2019-03-23 17:09:53,746] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.6001261e-04 2.6058497e-10 9.9984002e-01 3.8541245e-12 6.2996586e-13], sum to 1.0000
[2019-03-23 17:09:53,756] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8045
[2019-03-23 17:09:53,760] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 44.0, 1.0, 2.0, 0.3307276032929818, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6173959808622335, 6.9112, 6.9112, 77.32846344354104, 718532.724841486, 718532.724841486, 175110.3241537997], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 136800.0000, 
sim time next is 137400.0000, 
raw observation next is [23.0, 43.50000000000001, 1.0, 2.0, 0.3871728364027765, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7227668652814193, 6.9112, 6.9112, 77.32846344354104, 841270.7749014953, 841270.7749014953, 189361.0413212037], 
processed observation next is [1.0, 0.6086956521739131, 0.6818181818181818, 0.43500000000000005, 1.0, 1.0, 0.2339660455034706, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6039526646877419, 0.0, 0.0, 0.5084288129206541, 0.3115817684820353, 0.3115817684820353, 0.4618561983443993], 
reward next is 0.5381, 
noisyNet noise sample is [array([1.6131948], dtype=float32), 1.0378556]. 
=============================================
[2019-03-23 17:09:56,726] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.9679945e-06 6.3325998e-09 9.9999702e-01 8.3194851e-10 5.4904709e-10], sum to 1.0000
[2019-03-23 17:09:56,731] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4120
[2019-03-23 17:09:56,736] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [13.33333333333333, 86.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 221699.8175175679, 221699.8175175677, 91692.85537591846], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 172200.0000, 
sim time next is 172800.0000, 
raw observation next is [13.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 215040.7329289477, 215040.7329289474, 90158.25741675291], 
processed observation next is [0.0, 0.0, 0.22727272727272727, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07964471589961025, 0.07964471589961016, 0.21989818882134857], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.04520487], dtype=float32), -1.3866181]. 
=============================================
[2019-03-23 17:09:58,383] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.7543067e-06 3.1851891e-10 9.9999130e-01 8.9849926e-11 1.0960079e-10], sum to 1.0000
[2019-03-23 17:09:58,393] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8753
[2019-03-23 17:09:58,399] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 43.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 281604.6488869137, 281604.6488869137, 107683.9941832665], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 320400.0000, 
sim time next is 321000.0000, 
raw observation next is [21.0, 43.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 279607.6099690354, 279607.6099690351, 107284.6722237338], 
processed observation next is [0.0, 0.7391304347826086, 0.5909090909090909, 0.43, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1035583740626057, 0.10355837406260558, 0.2616699322530093], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.798746], dtype=float32), -0.50977814]. 
=============================================
[2019-03-23 17:09:58,414] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[3.011813 ]
 [3.0757372]
 [3.1151612]
 [3.1193407]
 [3.1348004]], R is [[2.9524889 ]
 [2.9229641 ]
 [2.89373446]
 [2.86479712]
 [2.83614922]].
[2019-03-23 17:09:59,577] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.8466595e-05 1.2340480e-08 9.9996150e-01 5.1545705e-09 3.3846934e-10], sum to 1.0000
[2019-03-23 17:09:59,583] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7779
[2019-03-23 17:09:59,589] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.73333333333333, 74.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 277531.5424294114, 277531.5424294114, 116718.6211771111], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 227400.0000, 
sim time next is 228000.0000, 
raw observation next is [17.96666666666667, 73.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 279247.3299489321, 279247.3299489318, 118232.3637753115], 
processed observation next is [0.0, 0.6521739130434783, 0.4530303030303031, 0.73, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.103424937018123, 0.1034249370181229, 0.2883716189641744], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8962939], dtype=float32), 1.073168]. 
=============================================
[2019-03-23 17:09:59,605] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[-1.521868 ]
 [-1.5055448]
 [-1.4834642]
 [-1.4424254]
 [-1.4084333]], R is [[-1.52098596]
 [-1.50577617]
 [-1.49071836]
 [-1.47581124]
 [-1.46105313]].
[2019-03-23 17:10:01,892] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.7018963e-06 1.9270201e-09 9.9999833e-01 6.4961918e-11 1.7536442e-10], sum to 1.0000
[2019-03-23 17:10:01,901] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6982
[2019-03-23 17:10:01,906] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [13.66666666666667, 96.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 211689.9595452026, 211689.9595452023, 93210.2441248567], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 276000.0000, 
sim time next is 276600.0000, 
raw observation next is [13.83333333333333, 95.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 213639.255453051, 213639.2554530512, 93857.23611063234], 
processed observation next is [0.0, 0.17391304347826086, 0.265151515151515, 0.95, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07912565016779667, 0.07912565016779674, 0.228920088074713], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6460406], dtype=float32), -0.17864236]. 
=============================================
[2019-03-23 17:10:07,726] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.8165569e-05 1.7464155e-08 9.9992180e-01 1.0521501e-09 3.0541039e-10], sum to 1.0000
[2019-03-23 17:10:07,737] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5796
[2019-03-23 17:10:07,745] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.5, 62.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3672046925427128, 6.911199999999999, 6.9112, 77.32846344354104, 427229.1844763057, 427229.184476306, 133673.6164830343], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 405000.0000, 
sim time next is 405600.0000, 
raw observation next is [18.33333333333334, 62.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3534140597911224, 6.911199999999999, 6.9112, 77.32846344354104, 411177.5048989934, 411177.5048989936, 131213.0411904914], 
processed observation next is [1.0, 0.6956521739130435, 0.46969696969696995, 0.6266666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.07630579970160344, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15228796477740497, 0.15228796477740503, 0.3200318077816864], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6293408], dtype=float32), -2.43005]. 
=============================================
[2019-03-23 17:10:12,359] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.7604679e-05 1.7530686e-08 9.9997234e-01 2.2221919e-10 5.5061570e-11], sum to 1.0000
[2019-03-23 17:10:12,370] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6668
[2019-03-23 17:10:12,376] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3651909932412769, 6.911200000000001, 6.9112, 77.32846344354104, 424885.2955344684, 424885.2955344681, 133041.1059903604], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 473400.0000, 
sim time next is 474000.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3268463230547501, 6.911199999999999, 6.9112, 77.32846344354104, 380255.3416238934, 380255.3416238937, 127576.0392969722], 
processed observation next is [1.0, 0.4782608695652174, 0.2727272727272727, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.03835189007821443, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14083531171255312, 0.14083531171255323, 0.3111610714560298], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0335379], dtype=float32), -0.11558482]. 
=============================================
[2019-03-23 17:10:12,399] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[11.2658825]
 [11.157706 ]
 [11.087941 ]
 [10.856932 ]
 [10.701254 ]], R is [[11.21826267]
 [11.10608006]
 [10.99501896]
 [10.88506889]
 [10.77621841]].
[2019-03-23 17:10:12,665] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 17:10:12,667] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:10:12,668] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:10:12,668] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:10:12,669] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:10:12,669] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:10:12,670] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:10:12,670] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:10:12,670] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:10:12,672] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:10:12,673] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:10:12,686] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run10
[2019-03-23 17:10:12,710] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run10
[2019-03-23 17:10:12,711] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run10
[2019-03-23 17:10:12,759] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run10
[2019-03-23 17:10:12,781] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run10
[2019-03-23 17:10:28,046] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00298651], dtype=float32), 0.0010835732]
[2019-03-23 17:10:28,047] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.7, 71.0, 1.0, 2.0, 0.2486162328252362, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5018963347974746, 6.9112, 6.9112, 95.55338769695034, 567294.1112092152, 567294.1112092152, 181934.5659917585]
[2019-03-23 17:10:28,048] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:10:28,050] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.2192310e-03 2.7113989e-10 9.9678075e-01 4.3501799e-12 2.9100980e-11], sampled 0.3766860064340727
[2019-03-23 17:10:31,636] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00298651], dtype=float32), 0.0010835732]
[2019-03-23 17:10:31,636] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.40588498333333, 90.27137033833334, 1.0, 2.0, 0.3063122430053861, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6191676770817721, 6.911200000000001, 6.9112, 95.55338769695034, 689787.6201700264, 689787.6201700261, 203012.6159874427]
[2019-03-23 17:10:31,638] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:10:31,640] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.7227555e-03 1.2723420e-11 9.9627727e-01 9.6592073e-14 1.2621703e-12], sampled 0.3446527438660588
[2019-03-23 17:10:33,822] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00298651], dtype=float32), 0.0010835732]
[2019-03-23 17:10:33,823] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.7, 79.0, 1.0, 2.0, 0.2315206789126757, 0.0, 2.0, 0.0, 1.0, 2.0, 0.465180183251582, 6.9112, 6.9112, 95.55338769695034, 528003.6323822993, 528003.6323822993, 176175.6397333818]
[2019-03-23 17:10:33,825] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:10:33,828] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.4720275e-03 2.5803190e-10 9.9552792e-01 3.8021157e-12 3.0460922e-11], sampled 0.6035731588761711
[2019-03-23 17:10:59,387] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00298651], dtype=float32), 0.0010835732]
[2019-03-23 17:10:59,389] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.53670581, 78.201097895, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 292884.9746602416, 292884.9746602416, 118682.7197544717]
[2019-03-23 17:10:59,391] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:10:59,394] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.5710805e-04 3.6254173e-09 9.9954295e-01 1.6672547e-10 3.0492861e-10], sampled 0.9780426437522808
[2019-03-23 17:11:13,518] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00298651], dtype=float32), 0.0010835732]
[2019-03-23 17:11:13,519] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.66666666666667, 74.33333333333334, 1.0, 2.0, 0.2999310761238732, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6063270929803294, 6.911200000000001, 6.9112, 95.55338769695034, 675575.3803353761, 675575.3803353758, 201069.1867942588]
[2019-03-23 17:11:13,521] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:11:13,524] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.12769895e-03 1.44502535e-11 9.95872319e-01 1.11627016e-13
 1.51868264e-12], sampled 0.12678760928695465
[2019-03-23 17:11:39,888] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00298651], dtype=float32), 0.0010835732]
[2019-03-23 17:11:39,889] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.68941948833334, 59.88447914166667, 1.0, 2.0, 0.3237322838993867, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6538358263325991, 6.911200000000001, 6.9112, 95.55338769695034, 738735.3103757624, 738735.310375762, 202196.710401014]
[2019-03-23 17:11:39,890] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:11:39,892] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.1182221e-03 4.4304727e-10 9.9688184e-01 8.0368455e-12 4.8581576e-11], sampled 0.22306012068477887
[2019-03-23 17:11:52,710] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3501.0643 2102754984.3677 193.0000
[2019-03-23 17:11:53,189] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3112.6461 2107669905.8693 373.0000
[2019-03-23 17:11:53,189] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2749.7129 2122623608.8217 760.0000
[2019-03-23 17:11:53,477] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3354.0673 2096666174.3955 185.0000
[2019-03-23 17:11:53,518] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3600.1180 2173911407.1689 249.0000
[2019-03-23 17:11:54,531] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 225000, evaluation results [225000.0, 3600.1179862638314, 2173911407.168901, 249.0, 3354.0673183191916, 2096666174.395512, 185.0, 3501.0642654186613, 2102754984.3676555, 193.0, 2749.7128539036335, 2122623608.8216922, 760.0, 3112.646078552185, 2107669905.869319, 373.0]
[2019-03-23 17:11:58,628] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.5876297e-03 1.1020396e-09 9.9741238e-01 8.4481875e-12 1.8383131e-10], sum to 1.0000
[2019-03-23 17:11:58,633] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8986
[2019-03-23 17:11:58,638] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.83333333333333, 83.83333333333334, 1.0, 2.0, 0.2513327132977934, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4742365990607146, 6.911199999999999, 6.9112, 77.32846344354104, 550084.1816158892, 550084.1816158894, 161862.9481418598], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 557400.0000, 
sim time next is 558000.0000, 
raw observation next is [18.0, 83.0, 1.0, 2.0, 0.2476541771937533, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4680004513569925, 6.911200000000001, 6.9112, 77.32846344354104, 542672.5520213319, 542672.5520213315, 161452.5345107291], 
processed observation next is [1.0, 0.4782608695652174, 0.45454545454545453, 0.83, 1.0, 1.0, 0.059567721492191604, 0.0, 1.0, -0.25, 1.0, 1.0, 0.24000064479570357, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20098983408197477, 0.20098983408197463, 0.39378666953836367], 
reward next is 0.6062, 
noisyNet noise sample is [array([-0.39457944], dtype=float32), -0.65951014]. 
=============================================
[2019-03-23 17:11:58,651] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[18.11833 ]
 [17.56845 ]
 [16.932741]
 [16.388182]
 [15.895011]], R is [[19.01809692]
 [19.43312836]
 [19.84620094]
 [20.25811577]
 [20.6701107 ]].
[2019-03-23 17:12:13,039] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.8774021e-01 3.1986813e-11 3.1225982e-01 5.8825930e-14 1.4040670e-10], sum to 1.0000
[2019-03-23 17:12:13,045] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7134
[2019-03-23 17:12:13,049] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.5, 85.5, 1.0, 1.0, 0.2155212159454816, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4274310671004634, 6.911200000000001, 6.9112, 77.3283015704079, 488652.8591497806, 488652.8591497803, 164712.1218107938], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 862200.0000, 
sim time next is 862800.0000, 
raw observation next is [20.66666666666667, 84.66666666666666, 1.0, 2.0, 0.2055865257225209, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4078932674755037, 6.911199999999999, 6.9112, 77.32846244152427, 466223.6363802867, 466223.636380287, 163020.7157648384], 
processed observation next is [0.0, 1.0, 0.575757575757576, 0.8466666666666666, 1.0, 1.0, 0.006983157153151107, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1541332392507196, -8.881784197001253e-17, 0.0, 0.5084288063324695, 0.17267542088158766, 0.17267542088158777, 0.39761150186545946], 
reward next is 0.6024, 
noisyNet noise sample is [array([0.48117706], dtype=float32), -1.7323909]. 
=============================================
[2019-03-23 17:12:14,935] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.4365872e-02 2.6513987e-11 9.8563415e-01 8.0738489e-14 2.7291738e-11], sum to 1.0000
[2019-03-23 17:12:14,944] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2869
[2019-03-23 17:12:14,948] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.66666666666666, 90.0, 1.0, 2.0, 0.2139949980680566, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4276509570147681, 6.911200000000001, 6.9112, 77.32846343184237, 487091.875008461, 487091.8750084607, 166338.344762527], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 888600.0000, 
sim time next is 889200.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.215180908945944, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4303428088537339, 6.911199999999999, 6.9112, 77.32846344346864, 489952.9026869825, 489952.9026869828, 166769.9413059662], 
processed observation next is [0.0, 0.30434782608695654, 0.5909090909090909, 0.88, 1.0, 1.0, 0.01897613618242998, 0.0, 1.0, -0.25, 1.0, 1.0, 0.18620401264819128, -8.881784197001253e-17, 0.0, 0.508428812920178, 0.18146403803221572, 0.18146403803221586, 0.4067559544047956], 
reward next is 0.5932, 
noisyNet noise sample is [array([0.8723935], dtype=float32), 0.32803532]. 
=============================================
[2019-03-23 17:12:31,355] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.6893422e-02 4.4782917e-11 9.8310661e-01 3.8636019e-14 1.0907486e-13], sum to 1.0000
[2019-03-23 17:12:31,364] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0301
[2019-03-23 17:12:31,368] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.7, 85.0, 1.0, 2.0, 0.2608642545883599, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5283439916875915, 6.911199999999999, 6.9112, 77.32846344354104, 593562.970648845, 593562.9706488453, 182790.584525497], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1211400.0000, 
sim time next is 1212000.0000, 
raw observation next is [23.8, 84.33333333333333, 1.0, 2.0, 0.2609033335698043, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5284275981637454, 6.9112, 6.9112, 77.32846344354104, 593629.944739459, 593629.944739459, 182818.2392277211], 
processed observation next is [1.0, 0.0, 0.7181818181818183, 0.8433333333333333, 1.0, 1.0, 0.07612916696225533, 0.0, 1.0, -0.25, 1.0, 1.0, 0.32632514023392206, 0.0, 0.0, 0.5084288129206541, 0.21986294249609592, 0.21986294249609592, 0.4458981444578563], 
reward next is 0.5541, 
noisyNet noise sample is [array([-0.0051739], dtype=float32), -1.2720596]. 
=============================================
[2019-03-23 17:12:31,391] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[33.22855 ]
 [32.97003 ]
 [32.88356 ]
 [33.02166 ]
 [33.765022]], R is [[33.53129959]
 [33.7501564 ]
 [33.96697235]
 [34.18188477]
 [34.3949852 ]].
[2019-03-23 17:12:34,787] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.9679213e-01 1.3857172e-17 8.0320787e-01 6.0762323e-20 1.0407017e-15], sum to 1.0000
[2019-03-23 17:12:34,792] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8179
[2019-03-23 17:12:34,796] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 62.0, 1.0, 2.0, 0.2532380311272979, 0.0, 2.0, 0.0, 1.0, 2.0, 0.512669875887634, 6.9112, 6.9112, 77.32846344354104, 576881.085334214, 576881.085334214, 180280.9707716677], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1272000.0000, 
sim time next is 1272600.0000, 
raw observation next is [27.0, 62.0, 1.0, 2.0, 0.2416870985210472, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4892109847106649, 6.9112, 6.9112, 77.32846344354104, 550688.7426256948, 550688.7426256948, 177422.1523627315], 
processed observation next is [1.0, 0.7391304347826086, 0.8636363636363636, 0.62, 1.0, 1.0, 0.05210887315130898, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2703014067295213, 0.0, 0.0, 0.5084288129206541, 0.20395879356507216, 0.20395879356507216, 0.43273695698227194], 
reward next is 0.5673, 
noisyNet noise sample is [array([0.13296688], dtype=float32), -1.6648546]. 
=============================================
[2019-03-23 17:12:43,376] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 17:12:43,377] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:12:43,377] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:12:43,378] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:12:43,378] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:12:43,378] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:12:43,380] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:12:43,381] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:12:43,381] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:12:43,382] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:12:43,383] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:12:43,396] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run11
[2019-03-23 17:12:43,396] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run11
[2019-03-23 17:12:43,446] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run11
[2019-03-23 17:12:43,448] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run11
[2019-03-23 17:12:43,448] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run11
[2019-03-23 17:12:51,375] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00329298], dtype=float32), 0.0016083984]
[2019-03-23 17:12:51,377] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [13.31666666666667, 83.5, 1.0, 1.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 95.55338769695034, 208973.9795257321, 208973.9795257325, 95415.71651382325]
[2019-03-23 17:12:51,379] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:12:51,383] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.3077118e-01 5.2865498e-12 8.6922890e-01 3.0212042e-14 4.9224492e-12], sampled 0.629109973032841
[2019-03-23 17:12:51,793] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00329298], dtype=float32), 0.0016083984]
[2019-03-23 17:12:51,793] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 246982.9505116151, 246982.9505116151, 101109.6349627395]
[2019-03-23 17:12:51,794] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:12:51,796] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.3349992e-01 3.6276034e-12 8.6650008e-01 1.9057896e-14 3.3861841e-12], sampled 0.4770711877061493
[2019-03-23 17:13:01,976] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00329298], dtype=float32), 0.0016083984]
[2019-03-23 17:13:01,977] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.45379909166667, 94.05034238333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3299357883605094, 6.911200000000001, 6.9112, 95.55338769695034, 381633.5260767414, 381633.5260767411, 153597.2403272274]
[2019-03-23 17:13:01,980] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:13:01,982] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.2035156e-02 5.6474112e-13 9.2796481e-01 2.1967912e-15 4.9473126e-13], sampled 0.39446243804343784
[2019-03-23 17:13:19,566] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00329298], dtype=float32), 0.0016083984]
[2019-03-23 17:13:19,566] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.77975633, 100.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4872309251184667, 6.911199999999999, 6.9112, 95.55338769695034, 283380.0038562344, 283380.0038562348, 87126.32280450827]
[2019-03-23 17:13:19,568] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:13:19,571] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.4311214e-01 1.8103082e-12 8.5688782e-01 8.1525964e-15 1.7041210e-12], sampled 0.39145285338642843
[2019-03-23 17:13:21,429] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00329298], dtype=float32), 0.0016083984]
[2019-03-23 17:13:21,430] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.68674695, 57.767012655, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3596871306534864, 6.9112, 6.9112, 95.55338769695034, 413341.3596895601, 413341.3596895601, 159692.3762285352]
[2019-03-23 17:13:21,431] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:13:21,433] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.8453965e-01 1.5492334e-13 8.1546032e-01 4.1731860e-16 1.4977356e-13], sampled 0.4293700742840898
[2019-03-23 17:13:36,191] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00329298], dtype=float32), 0.0016083984]
[2019-03-23 17:13:36,194] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.08333333333334, 53.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3913150462146211, 6.9112, 6.9112, 95.55338769695034, 448351.5655265186, 448351.5655265186, 164978.7445184114]
[2019-03-23 17:13:36,195] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:13:36,200] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.5611380e-01 1.3714735e-13 8.4388614e-01 3.7142482e-16 1.3378163e-13], sampled 0.46650731052080585
[2019-03-23 17:13:44,649] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00329298], dtype=float32), 0.0016083984]
[2019-03-23 17:13:44,650] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.55, 83.33333333333334, 1.0, 2.0, 0.2585140973281511, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5231922835908446, 6.9112, 6.9112, 95.55338769695034, 589106.2060718242, 589106.2060718242, 185975.3649780259]
[2019-03-23 17:13:44,652] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:13:44,656] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.18342051e-01 1.11630099e-13 7.81657994e-01 2.71692224e-16
 1.05807866e-13], sampled 0.834766786978925
[2019-03-23 17:13:51,726] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00329298], dtype=float32), 0.0016083984]
[2019-03-23 17:13:51,727] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.15512635, 63.85282040666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3218388843811565, 6.911199999999999, 6.9112, 95.55338769695034, 370946.4892979835, 370946.4892979839, 153958.2373816237]
[2019-03-23 17:13:51,729] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:13:51,732] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.4030497e-01 1.0308036e-12 8.5969502e-01 4.2466869e-15 9.2714703e-13], sampled 0.8827804025724507
[2019-03-23 17:14:00,990] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00329298], dtype=float32), 0.0016083984]
[2019-03-23 17:14:00,992] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.573991195, 75.32512166333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3018568161609001, 6.911199999999999, 6.9112, 95.55338769694944, 350532.531169083, 350532.5311690833, 148946.2617136508]
[2019-03-23 17:14:00,992] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:14:00,996] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.2223427e-01 2.7061521e-13 8.7776577e-01 8.6155363e-16 2.5223774e-13], sampled 0.21838480744300182
[2019-03-23 17:14:03,663] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00329298], dtype=float32), 0.0016083984]
[2019-03-23 17:14:03,664] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.83533384666666, 54.95117669, 1.0, 2.0, 0.2130770284378725, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4212782363469987, 6.9112, 6.9112, 95.55338769695034, 482191.2906243115, 482191.2906243115, 168245.9591355052]
[2019-03-23 17:14:03,665] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:14:03,667] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.7804132e-01 1.2902617e-12 8.2195872e-01 5.3807607e-15 1.2461216e-12], sampled 0.13394994624563072
[2019-03-23 17:14:10,781] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00329298], dtype=float32), 0.0016083984]
[2019-03-23 17:14:10,782] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.21666666666667, 85.33333333333334, 1.0, 2.0, 0.2944196502387495, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5963325200679602, 6.911200000000001, 6.9112, 95.55338769695034, 667653.3595762816, 667653.3595762813, 197801.3374369967]
[2019-03-23 17:14:10,784] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:14:10,786] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.0855331e-01 4.7132454e-15 6.9144672e-01 5.8076305e-18 4.6651276e-15], sampled 0.7204739526352997
[2019-03-23 17:14:12,824] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00329298], dtype=float32), 0.0016083984]
[2019-03-23 17:14:12,826] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.21666666666667, 44.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3787597080270633, 6.911200000000001, 6.9112, 95.55338749151888, 433682.980850191, 433682.9808501906, 163541.0711650001]
[2019-03-23 17:14:12,827] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:14:12,828] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.1088721e-01 5.1803082e-14 7.8911275e-01 1.0803965e-16 5.0304453e-14], sampled 0.15660954833383234
[2019-03-23 17:14:23,125] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00329298], dtype=float32), 0.0016083984]
[2019-03-23 17:14:23,125] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.41666666666667, 77.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3430989527032051, 6.9112, 6.9112, 77.3284634408648, 394784.5286467223, 394784.5286467223, 152591.4571442116]
[2019-03-23 17:14:23,126] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:14:23,130] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.0465529e-01 3.1821377e-13 7.9534471e-01 9.8046880e-16 3.0622287e-13], sampled 0.4831751537428719
[2019-03-23 17:14:23,413] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2701.1112 2044211835.9488 1445.0000
[2019-03-23 17:14:23,702] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3404.1758 2095526135.2402 793.0000
[2019-03-23 17:14:23,715] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00329298], dtype=float32), 0.0016083984]
[2019-03-23 17:14:23,715] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.26666666666667, 70.66666666666667, 1.0, 1.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 252841.1551316108, 252841.1551316108, 105792.3530089722]
[2019-03-23 17:14:23,716] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:14:23,717] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.0741817e-02 5.2007001e-12 9.2925823e-01 3.2141424e-14 4.4498710e-12], sampled 0.6629725405343428
[2019-03-23 17:14:23,724] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3026.7332 2026515393.4106 1009.0000
[2019-03-23 17:14:23,738] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3118.5066 2014198676.7262 908.0000
[2019-03-23 17:14:23,779] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3180.2694 2022234325.2011 951.0000
[2019-03-23 17:14:24,792] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 250000, evaluation results [250000.0, 3404.175839025772, 2095526135.2401965, 793.0, 3118.5066215807265, 2014198676.726218, 908.0, 3180.269372790283, 2022234325.2011476, 951.0, 2701.111157002714, 2044211835.9487739, 1445.0, 3026.733206674803, 2026515393.4105656, 1009.0]
[2019-03-23 17:14:34,330] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.5904966e-05 9.3586616e-16 9.9994409e-01 3.4967409e-17 1.3983464e-15], sum to 1.0000
[2019-03-23 17:14:34,338] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0311
[2019-03-23 17:14:34,346] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.16666666666667, 82.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3699503769731937, 6.911200000000001, 6.9112, 77.32846344354104, 424715.6693054311, 424715.6693054308, 156805.6219026161], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1637400.0000, 
sim time next is 1638000.0000, 
raw observation next is [20.0, 83.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.368643948520675, 6.9112, 6.9112, 77.32846344354104, 423346.7199875486, 423346.7199875486, 156519.9584243664], 
processed observation next is [1.0, 1.0, 0.5454545454545454, 0.83, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0980627836009643, 0.0, 0.0, 0.5084288129206541, 0.15679508147686985, 0.15679508147686985, 0.38175599615699124], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.29409048], dtype=float32), 2.055262]. 
=============================================
[2019-03-23 17:14:34,360] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[53.287323]
 [53.50912 ]
 [53.695072]
 [53.922848]
 [54.167835]], R is [[52.55932236]
 [52.03372955]
 [51.5133934 ]
 [50.9982605 ]
 [50.48827744]].
[2019-03-23 17:14:34,652] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.1279631e-01 1.8783424e-17 3.8720372e-01 2.3676780e-20 6.0714647e-17], sum to 1.0000
[2019-03-23 17:14:34,664] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3639
[2019-03-23 17:14:34,671] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1305957.998494588 W.
[2019-03-23 17:14:34,678] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 62.0, 1.0, 2.0, 0.6662282466727009, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9764418062053087, 6.911199999999999, 6.9112, 77.32846344354104, 1305957.998494588, 1305957.998494588, 286298.1789357461], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1609200.0000, 
sim time next is 1609800.0000, 
raw observation next is [27.0, 62.0, 1.0, 2.0, 0.5144025124571605, 1.0, 1.0, 0.5144025124571605, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1166505.734769238, 1166505.734769238, 236384.924866627], 
processed observation next is [1.0, 0.6521739130434783, 0.8636363636363636, 0.62, 1.0, 1.0, 0.3930031405714506, 1.0, 0.5, 0.3930031405714506, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.43203916102564366, 0.43203916102564366, 0.5765485972356756], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.53840667], dtype=float32), 0.2815483]. 
=============================================
[2019-03-23 17:14:34,945] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.6504397e-03 1.8999833e-16 9.9834955e-01 5.2942635e-19 1.7617614e-16], sum to 1.0000
[2019-03-23 17:14:34,949] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0203
[2019-03-23 17:14:34,958] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.4, 63.66666666666667, 1.0, 2.0, 0.3676110252040043, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7438639954867721, 6.911199999999999, 6.9112, 77.32846344353584, 838191.7712019488, 838191.7712019491, 212976.5992725734], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1600800.0000, 
sim time next is 1601400.0000, 
raw observation next is [26.5, 63.33333333333333, 1.0, 2.0, 0.3809652661129786, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7709885176353256, 6.911199999999999, 6.9112, 77.32846344354101, 868535.9291265896, 868535.9291265898, 217797.0004654079], 
processed observation next is [1.0, 0.5217391304347826, 0.8409090909090909, 0.6333333333333333, 1.0, 1.0, 0.22620658264122323, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6728407394790367, -8.881784197001253e-17, 0.0, 0.5084288129206539, 0.3216799737505887, 0.3216799737505888, 0.5312121962570925], 
reward next is 0.4688, 
noisyNet noise sample is [array([1.9864689], dtype=float32), -1.3083755]. 
=============================================
[2019-03-23 17:14:37,039] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.8624517e-06 1.7624954e-11 9.9999809e-01 7.5919696e-13 2.5456021e-13], sum to 1.0000
[2019-03-23 17:14:37,047] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1546
[2019-03-23 17:14:37,055] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 91.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3509774359398877, 6.9112, 6.9112, 77.32846344354104, 403242.8299959054, 403242.8299959054, 154119.4400833763], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1665000.0000, 
sim time next is 1665600.0000, 
raw observation next is [19.0, 92.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3576201070340234, 6.911200000000001, 6.9112, 77.32846344354104, 410616.8022411956, 410616.8022411953, 155185.0426744984], 
processed observation next is [1.0, 0.2608695652173913, 0.5, 0.92, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.08231443862003347, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15208029712636872, 0.1520802971263686, 0.3785001040841424], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.32463327], dtype=float32), -1.1109538]. 
=============================================
[2019-03-23 17:14:42,678] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.4944435e-06 1.2841405e-08 9.9999452e-01 1.0756724e-09 2.2593168e-10], sum to 1.0000
[2019-03-23 17:14:42,685] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0459
[2019-03-23 17:14:42,688] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [15.66666666666667, 53.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3195920293539075, 6.9112, 6.9112, 77.32846344354104, 371812.4179194601, 371812.4179194601, 114744.4846093887], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1763400.0000, 
sim time next is 1764000.0000, 
raw observation next is [16.0, 51.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3268772022337311, 6.9112, 6.9112, 77.32846344354104, 380291.2807292007, 380291.2807292007, 115830.626822309], 
processed observation next is [1.0, 0.43478260869565216, 0.36363636363636365, 0.51, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.03839600319104448, 0.0, 0.0, 0.5084288129206541, 0.14084862249229654, 0.14084862249229654, 0.2825137239568512], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.14707857], dtype=float32), -0.26757345]. 
=============================================
[2019-03-23 17:14:42,704] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[3.905142 ]
 [3.8882551]
 [3.8620749]
 [3.8850727]
 [3.9160914]], R is [[3.91680861]
 [3.87764049]
 [3.83886409]
 [3.8004756 ]
 [3.76247096]].
[2019-03-23 17:14:43,710] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.1909968e-06 1.4421162e-11 9.9999785e-01 1.5956257e-11 5.8892231e-12], sum to 1.0000
[2019-03-23 17:14:43,720] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3815
[2019-03-23 17:14:43,725] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.66666666666667, 40.0, 1.0, 2.0, 0.2193406640955958, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4094609675876054, 6.911199999999999, 6.9112, 77.32846344354104, 476416.8982334274, 476416.8982334277, 129432.708884003], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1783200.0000, 
sim time next is 1783800.0000, 
raw observation next is [19.5, 40.0, 1.0, 2.0, 0.2206174629596483, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4118444713507829, 6.9112, 6.9112, 77.32846344354104, 479191.5243996654, 479191.5243996654, 129257.1187872864], 
processed observation next is [1.0, 0.6521739130434783, 0.5227272727272727, 0.4, 1.0, 1.0, 0.02577182869956035, 0.0, 1.0, -0.25, 1.0, 1.0, 0.15977781621540416, 0.0, 0.0, 0.5084288129206541, 0.17747834237024646, 0.17747834237024646, 0.3152612653348449], 
reward next is 0.6847, 
noisyNet noise sample is [array([-0.9663666], dtype=float32), -1.0528221]. 
=============================================
[2019-03-23 17:14:44,929] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.9082593e-06 3.9903685e-09 9.9999607e-01 5.6714000e-10 2.8371702e-10], sum to 1.0000
[2019-03-23 17:14:44,939] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6182
[2019-03-23 17:14:44,944] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.16666666666667, 51.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 251896.4782471691, 251896.4782471694, 96497.13278414529], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1799400.0000, 
sim time next is 1800000.0000, 
raw observation next is [17.0, 52.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 249884.928550127, 249884.928550127, 95991.7151866349], 
processed observation next is [1.0, 0.8695652173913043, 0.4090909090909091, 0.52, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.09254997353708407, 0.09254997353708407, 0.23412613460154855], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.18687248], dtype=float32), -1.1956817]. 
=============================================
[2019-03-23 17:14:44,968] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[-1.0747178]
 [-1.0525618]
 [-1.0422658]
 [-1.0267793]
 [-0.9938861]], R is [[-1.06243634]
 [-1.05181193]
 [-1.04129386]
 [-1.03088093]
 [-1.02057219]].
[2019-03-23 17:14:58,412] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.3768485e-06 1.2779345e-08 9.9999464e-01 3.2831842e-09 5.5477012e-10], sum to 1.0000
[2019-03-23 17:14:58,420] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7894
[2019-03-23 17:14:58,428] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.73333333333333, 47.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.301579682316945, 6.9112, 6.9112, 77.32846344354104, 349454.782411821, 349454.782411821, 145209.2533609328], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2049600.0000, 
sim time next is 2050200.0000, 
raw observation next is [23.6, 48.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.300220528006331, 6.9112, 6.9112, 77.32846344354104, 347977.78137266, 347977.78137266, 144958.2266619725], 
processed observation next is [0.0, 0.7391304347826086, 0.7090909090909091, 0.48, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0003150400090442699, 0.0, 0.0, 0.5084288129206541, 0.12888065976765187, 0.12888065976765187, 0.35355665039505485], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5225404], dtype=float32), -0.13375553]. 
=============================================
[2019-03-23 17:15:02,648] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.0247131e-06 1.1944189e-09 9.9999094e-01 1.3737655e-10 2.2267211e-11], sum to 1.0000
[2019-03-23 17:15:02,657] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3683
[2019-03-23 17:15:02,661] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 48.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3912707013994757, 6.911199999999999, 6.9112, 77.32846344354104, 446883.246091154, 446883.2460911543, 161583.5314569831], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2129400.0000, 
sim time next is 2130000.0000, 
raw observation next is [27.0, 49.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3981180358688742, 6.9112, 6.9112, 77.32846344354104, 454241.7309905303, 454241.7309905303, 162906.703184014], 
processed observation next is [0.0, 0.6521739130434783, 0.8636363636363636, 0.49, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.14016862266982028, 0.0, 0.0, 0.5084288129206541, 0.16823767814464086, 0.16823767814464086, 0.39733342240003416], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.89032793], dtype=float32), 0.6443168]. 
=============================================
[2019-03-23 17:15:02,684] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[14.441492]
 [14.377468]
 [14.359535]
 [14.32011 ]
 [14.305914]], R is [[14.40745068]
 [14.26337624]
 [14.1207428 ]
 [13.9795351 ]
 [13.8397398 ]].
[2019-03-23 17:15:12,802] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.4180102e-05 1.4614082e-07 9.9996567e-01 2.9038624e-08 7.0797621e-09], sum to 1.0000
[2019-03-23 17:15:12,810] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7591
[2019-03-23 17:15:12,816] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.33333333333333, 73.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 217089.9514279161, 217089.9514279158, 90154.33575277042], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2338800.0000, 
sim time next is 2339400.0000, 
raw observation next is [14.16666666666667, 75.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 215276.7118204354, 215276.7118204354, 89850.93707283103], 
processed observation next is [1.0, 0.043478260869565216, 0.28030303030303044, 0.7533333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.07973211548905014, 0.07973211548905014, 0.21914862700690496], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5832242], dtype=float32), -0.3312354]. 
=============================================
[2019-03-23 17:15:13,842] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 17:15:13,850] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:15:13,851] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:15:13,852] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:15:13,852] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:15:13,852] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:15:13,853] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:15:13,853] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:15:13,855] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:15:13,854] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:15:13,857] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:15:13,872] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run12
[2019-03-23 17:15:13,875] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run12
[2019-03-23 17:15:13,876] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run12
[2019-03-23 17:15:13,900] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run12
[2019-03-23 17:15:13,974] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run12
[2019-03-23 17:15:23,145] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0025581], dtype=float32), 0.00095217064]
[2019-03-23 17:15:23,148] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [11.65, 87.5, 1.0, 2.0, 0.207027247438613, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3864745162632851, 6.911200000000001, 6.9112, 95.55338769695034, 449619.6309965401, 449619.6309965398, 128281.0002378567]
[2019-03-23 17:15:23,149] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:15:23,152] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.7982642e-05 4.8001501e-09 9.9997199e-01 5.0414045e-10 3.3456529e-10], sampled 0.3405199166169772
[2019-03-23 17:16:17,886] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0025581], dtype=float32), 0.00095217064]
[2019-03-23 17:16:17,888] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.7, 55.66666666666667, 1.0, 2.0, 0.2897009874700005, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5563400513529901, 6.911200000000001, 6.9112, 95.55338769695034, 642687.4491382976, 642687.4491382972, 177642.8110898055]
[2019-03-23 17:16:17,889] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:16:17,892] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.1220853e-05 9.1289698e-11 9.9994874e-01 3.4552365e-12 7.5200323e-12], sampled 0.6800251722502908
[2019-03-23 17:16:24,745] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0025581], dtype=float32), 0.00095217064]
[2019-03-23 17:16:24,747] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [28.63333333333334, 50.66666666666667, 1.0, 2.0, 0.2382187457121418, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4813251926290518, 6.9112, 6.9112, 77.32846344354104, 543504.6431941066, 543504.6431941066, 175342.8092275364]
[2019-03-23 17:16:24,749] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:16:24,752] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.5508509e-05 3.1600456e-12 9.9998450e-01 6.7284299e-14 2.0761542e-13], sampled 0.5409522655960176
[2019-03-23 17:16:30,303] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0025581], dtype=float32), 0.00095217064]
[2019-03-23 17:16:30,305] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.08630353333333, 64.13075961333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 188961.2850743984, 188961.285074398, 86866.89046536053]
[2019-03-23 17:16:30,306] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:16:30,310] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.6057307e-05 2.9284164e-08 9.9998391e-01 5.0124145e-09 1.7393127e-09], sampled 0.6681969303819774
[2019-03-23 17:16:41,356] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0025581], dtype=float32), 0.00095217064]
[2019-03-23 17:16:41,357] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.97919555, 61.71648701333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3203000001409865, 6.9112, 6.9112, 95.55338769695034, 369992.1130415701, 369992.1130415701, 152973.7134498653]
[2019-03-23 17:16:41,358] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:16:41,361] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.4191663e-06 1.5351841e-09 9.9999356e-01 1.6950265e-10 7.6976120e-11], sampled 0.02972399943015802
[2019-03-23 17:16:53,373] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3617.1926 2175182065.0636 245.0000
[2019-03-23 17:16:53,648] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2760.8439 2124022880.4588 757.0000
[2019-03-23 17:16:53,740] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3118.8146 2109028294.6974 368.0000
[2019-03-23 17:16:53,798] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3519.0325 2104095443.0865 178.0000
[2019-03-23 17:16:53,838] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3361.3356 2098067941.7008 179.0000
[2019-03-23 17:16:54,852] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 275000, evaluation results [275000.0, 3617.192644862502, 2175182065.063642, 245.0, 3361.3355917968815, 2098067941.7008436, 179.0, 3519.032511138161, 2104095443.0864863, 178.0, 2760.843876387703, 2124022880.4588451, 757.0, 3118.814627156226, 2109028294.6973863, 368.0]
[2019-03-23 17:16:56,281] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.2266207e-03 7.0642025e-12 9.9777335e-01 1.2160893e-13 5.6227570e-12], sum to 1.0000
[2019-03-23 17:16:56,290] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3856
[2019-03-23 17:16:56,297] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.83333333333334, 47.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3661178232647261, 6.9112, 6.9112, 77.32846344354104, 425964.0980225675, 425964.0980225675, 140426.9982103717], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2394600.0000, 
sim time next is 2395200.0000, 
raw observation next is [21.66666666666667, 48.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 335100.4852159508, 335100.4852159508, 128022.1744857071], 
processed observation next is [1.0, 0.7391304347826086, 0.6212121212121214, 0.48333333333333345, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.12411129082072253, 0.12411129082072253, 0.31224920606270024], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.34092805], dtype=float32), -0.007952705]. 
=============================================
[2019-03-23 17:16:59,398] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.2982305e-05 1.0688493e-07 9.9995685e-01 1.1444240e-08 2.3678723e-09], sum to 1.0000
[2019-03-23 17:16:59,407] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5780
[2019-03-23 17:16:59,413] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [15.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 271219.1441083864, 271219.1441083864, 107182.3662078366], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2446800.0000, 
sim time next is 2447400.0000, 
raw observation next is [15.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 268824.5693575392, 268824.5693575389, 106720.4100875251], 
processed observation next is [1.0, 0.30434782608695654, 0.3181818181818182, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09956465531760711, 0.099564655317607, 0.26029368314030515], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.990002], dtype=float32), 1.964051]. 
=============================================
[2019-03-23 17:17:04,335] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.9647775e-06 1.0781549e-10 9.9999607e-01 4.1553417e-11 1.8503257e-12], sum to 1.0000
[2019-03-23 17:17:04,339] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3896
[2019-03-23 17:17:04,343] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 45.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.377825850375138, 6.9112, 6.9112, 77.32846344354104, 432693.1515435783, 432693.1515435783, 158763.6651051031], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2653200.0000, 
sim time next is 2653800.0000, 
raw observation next is [27.0, 45.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3782165428703797, 6.9112, 6.9112, 77.32846344354104, 433127.9157827144, 433127.9157827144, 158826.1599247155], 
processed observation next is [0.0, 0.7391304347826086, 0.8636363636363636, 0.45, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.11173791838625674, 0.0, 0.0, 0.5084288129206541, 0.1604177465861905, 0.1604177465861905, 0.38738087786515973], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2755872], dtype=float32), -0.6161619]. 
=============================================
[2019-03-23 17:17:06,564] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.9625718e-06 6.3056092e-08 9.9999392e-01 1.3939976e-08 5.2175300e-09], sum to 1.0000
[2019-03-23 17:17:06,573] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1746
[2019-03-23 17:17:06,576] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.16666666666667, 63.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 300197.3031286715, 300197.3031286715, 120758.3541125222], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2580600.0000, 
sim time next is 2581200.0000, 
raw observation next is [19.0, 64.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 296185.0181161624, 296185.0181161627, 119332.1313881807], 
processed observation next is [1.0, 0.9130434782608695, 0.5, 0.64, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10969815485783792, 0.10969815485783803, 0.2910539789955627], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.884957], dtype=float32), -1.2115536]. 
=============================================
[2019-03-23 17:17:15,674] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.98947066e-01 1.69473093e-08 7.01052904e-01 7.63706737e-11
 1.34277425e-08], sum to 1.0000
[2019-03-23 17:17:15,682] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1762
[2019-03-23 17:17:15,686] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.0, 92.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3228932819816176, 6.9112, 6.9112, 77.32846344354104, 372735.5079221652, 372735.5079221652, 148998.5885025049], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2788800.0000, 
sim time next is 2789400.0000, 
raw observation next is [18.0, 93.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6536203248117018, 6.9112, 6.9112, 77.32846344354104, 377424.3237058146, 377424.3237058146, 120165.8013827931], 
processed observation next is [1.0, 0.2608695652173913, 0.45454545454545453, 0.93, 0.0, 0.5, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5051718925881455, 0.0, 0.0, 0.5084288129206541, 0.13978678655770913, 0.13978678655770913, 0.29308732044583685], 
reward next is 0.7069, 
noisyNet noise sample is [array([-1.5826099], dtype=float32), -1.9483603]. 
=============================================
[2019-03-23 17:17:20,422] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.3490376e-02 7.7160522e-10 9.5650965e-01 6.7675505e-12 1.3379774e-10], sum to 1.0000
[2019-03-23 17:17:20,434] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8094
[2019-03-23 17:17:20,441] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.16666666666667, 59.83333333333334, 1.0, 2.0, 0.2287405764513003, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4606027844420659, 6.911200000000001, 6.9112, 77.32846344354104, 521955.0939161963, 521955.093916196, 171713.7937680562], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2839800.0000, 
sim time next is 2840400.0000, 
raw observation next is [26.0, 61.0, 1.0, 2.0, 0.2290791843289616, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4614197082767138, 6.9112, 6.9112, 77.32846344354104, 522747.8418451841, 522747.8418451841, 171901.4760645581], 
processed observation next is [1.0, 0.9130434782608695, 0.8181818181818182, 0.61, 1.0, 1.0, 0.036348980411201985, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2305995832524483, 0.0, 0.0, 0.5084288129206541, 0.19361031179451263, 0.19361031179451263, 0.41927189284038563], 
reward next is 0.5807, 
noisyNet noise sample is [array([-1.8821545], dtype=float32), -0.33494526]. 
=============================================
[2019-03-23 17:17:27,187] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.5765449e-03 1.2307722e-15 9.9442345e-01 1.0937598e-18 2.9312240e-16], sum to 1.0000
[2019-03-23 17:17:27,201] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1891
[2019-03-23 17:17:27,204] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 70.66666666666667, 1.0, 2.0, 0.3636149984399392, 1.0, 2.0, 0.3636149984399392, 1.0, 1.0, 0.7349810207275608, 6.911199999999999, 6.9112, 77.3421103, 1228980.091835355, 1228980.091835356, 289274.8298233747], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2973000.0000, 
sim time next is 2973600.0000, 
raw observation next is [26.0, 70.0, 1.0, 2.0, 0.5756207953639754, 0.0, 1.0, 0.0, 1.0, 2.0, 0.97832197818849, 6.9112, 6.9112, 77.32846344354104, 1201500.149553535, 1201500.149553535, 275064.4739268034], 
processed observation next is [1.0, 0.43478260869565216, 0.8181818181818182, 0.7, 1.0, 1.0, 0.46952599420496915, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9690313974121285, 0.0, 0.0, 0.5084288129206541, 0.44500005539019816, 0.44500005539019816, 0.6708889607970814], 
reward next is 0.3291, 
noisyNet noise sample is [array([0.65434617], dtype=float32), -0.2676563]. 
=============================================
[2019-03-23 17:17:30,917] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9405267e-04 3.1761111e-11 9.9980599e-01 2.6544943e-11 2.0320868e-11], sum to 1.0000
[2019-03-23 17:17:30,927] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2050
[2019-03-23 17:17:30,936] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.83333333333334, 95.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3048542187249256, 6.911199999999999, 6.9112, 77.32846344354104, 353395.3866288841, 353395.3866288844, 145414.5487213344], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3048600.0000, 
sim time next is 3049200.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3102179212581842, 6.911199999999999, 6.9112, 77.32846344354104, 359507.2312721538, 359507.2312721541, 146113.6249213527], 
processed observation next is [1.0, 0.30434782608695654, 0.4090909090909091, 0.94, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.014597030368834593, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.133150826397094, 0.1331508263970941, 0.3563746949301285], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.68379676], dtype=float32), -1.8086247]. 
=============================================
[2019-03-23 17:17:33,218] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.3514165e-03 9.8931193e-13 9.9364859e-01 6.1499691e-15 2.0316162e-13], sum to 1.0000
[2019-03-23 17:17:33,230] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1987
[2019-03-23 17:17:33,232] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.0, 88.0, 1.0, 2.0, 0.278192700459622, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5633841507773215, 6.9112, 6.9112, 77.32846344354104, 630357.5680061538, 630357.5680061538, 188811.5186784251], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3099000.0000, 
sim time next is 3099600.0000, 
raw observation next is [24.0, 89.0, 1.0, 2.0, 0.280859568984207, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5686557149872945, 6.9112, 6.9112, 77.32846344354104, 635732.4083037318, 635732.4083037318, 189823.936457062], 
processed observation next is [1.0, 0.9130434782608695, 0.7272727272727273, 0.89, 1.0, 1.0, 0.10107446123025873, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3837938785532779, 0.0, 0.0, 0.5084288129206541, 0.23545644751990066, 0.23545644751990066, 0.4629852108708829], 
reward next is 0.5370, 
noisyNet noise sample is [array([1.1332062], dtype=float32), 0.72970724]. 
=============================================
[2019-03-23 17:17:36,659] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7115927e-01 5.1417464e-13 8.2884079e-01 2.5403982e-16 3.6321018e-12], sum to 1.0000
[2019-03-23 17:17:36,661] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6251
[2019-03-23 17:17:36,671] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 73.0, 1.0, 2.0, 0.4738223164682448, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9304061145380641, 6.94687646436955, 6.9112, 77.3283776370878, 1080888.921011884, 1069301.947951881, 243523.8345886567], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3141000.0000, 
sim time next is 3141600.0000, 
raw observation next is [23.0, 73.0, 1.0, 2.0, 0.5206862010973573, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9490840264095518, 6.937451064260018, 6.9112, 77.32837682671462, 1142016.252176086, 1133490.452981442, 251737.0700414168], 
processed observation next is [1.0, 0.34782608695652173, 0.6818181818181818, 0.73, 1.0, 1.0, 0.4008577513716966, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9272628948707885, 0.0026251064260017997, 0.0, 0.5084282434215553, 0.42296898228743923, 0.4198112788820155, 0.6139928537595531], 
reward next is 0.2548, 
noisyNet noise sample is [array([-0.24134809], dtype=float32), 0.27702886]. 
=============================================
[2019-03-23 17:17:38,339] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6837646e-01 1.1265598e-13 8.3162349e-01 1.3520175e-15 8.5403663e-12], sum to 1.0000
[2019-03-23 17:17:38,350] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3581
[2019-03-23 17:17:38,352] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 92.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.341444373524555, 6.9112, 6.9112, 77.32846344350939, 393978.5762708485, 393978.5762708485, 151342.7536081722], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3212400.0000, 
sim time next is 3213000.0000, 
raw observation next is [18.0, 91.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3362644236892036, 6.911199999999999, 6.9112, 77.32846344354084, 388237.5394829182, 388237.5394829185, 150496.958473866], 
processed observation next is [0.0, 0.17391304347826086, 0.45454545454545453, 0.91, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.05180631955600519, -8.881784197001253e-17, 0.0, 0.5084288129206528, 0.14379168128996972, 0.14379168128996983, 0.3670657523752829], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.404459], dtype=float32), -0.12395385]. 
=============================================
[2019-03-23 17:17:38,371] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[47.51558 ]
 [48.205822]
 [49.014866]
 [49.474632]
 [50.07605 ]], R is [[46.06846619]
 [45.60778046]
 [45.15170288]
 [44.70018768]
 [44.25318527]].
[2019-03-23 17:17:41,647] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.3937013e-07 1.5737710e-09 9.9999952e-01 2.3692598e-10 5.1032067e-11], sum to 1.0000
[2019-03-23 17:17:41,658] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2306
[2019-03-23 17:17:41,661] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.03333333333333, 47.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3032703391168116, 6.9112, 6.9112, 77.32846344354104, 351124.7140655309, 351124.7140655309, 145695.2060755018], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3244800.0000, 
sim time next is 3245400.0000, 
raw observation next is [24.05, 47.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3040202684363017, 6.911200000000001, 6.9112, 77.32846344354104, 351918.947851272, 351918.9478512717, 145854.4371522993], 
processed observation next is [0.0, 0.5652173913043478, 0.7295454545454546, 0.475, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.005743240623288158, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13034035105602668, 0.13034035105602657, 0.3557425296397544], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.31847197], dtype=float32), -0.57437783]. 
=============================================
[2019-03-23 17:17:41,808] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.4508810e-06 1.7795938e-09 9.9999654e-01 2.4463173e-10 2.9868396e-11], sum to 1.0000
[2019-03-23 17:17:41,817] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2062
[2019-03-23 17:17:41,820] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.5, 53.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3318810795090566, 6.9112, 6.9112, 77.32846344354104, 382989.7588146373, 382989.7588146373, 150164.2816659901], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3238200.0000, 
sim time next is 3238800.0000, 
raw observation next is [23.33333333333333, 53.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3260163833965896, 6.9112, 6.9112, 77.32846344354104, 376555.4868163084, 376555.4868163084, 149148.7247927126], 
processed observation next is [0.0, 0.4782608695652174, 0.6969696969696968, 0.5333333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.03716626199512804, 0.0, 0.0, 0.5084288129206541, 0.13946499511715127, 0.13946499511715127, 0.36377737754320144], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.68988895], dtype=float32), 1.3393433]. 
=============================================
[2019-03-23 17:17:44,241] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 17:17:44,242] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:17:44,244] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:17:44,245] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:17:44,245] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:17:44,247] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:17:44,248] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:17:44,253] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:17:44,256] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:17:44,246] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:17:44,258] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:17:44,267] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run13
[2019-03-23 17:17:44,290] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run13
[2019-03-23 17:17:44,327] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run13
[2019-03-23 17:17:44,328] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run13
[2019-03-23 17:17:44,370] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run13
[2019-03-23 17:17:56,934] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00198188], dtype=float32), 0.00074011687]
[2019-03-23 17:17:56,935] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3908342190158844, 6.911200000000001, 6.9112, 77.32846344354104, 448070.8052010424, 448070.8052010422, 160072.5202774954]
[2019-03-23 17:17:56,937] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:17:56,940] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.5960523e-07 3.8573900e-10 9.9999928e-01 9.1302500e-11 1.1291973e-11], sampled 0.031288821235174624
[2019-03-23 17:18:28,212] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00198188], dtype=float32), 0.00074011687]
[2019-03-23 17:18:28,213] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.38333333333334, 70.5, 1.0, 2.0, 0.3514099997054029, 0.0, 2.0, 0.0, 1.0, 2.0, 0.708489634512256, 6.911200000000001, 6.9112, 95.55338769695034, 802061.5075823962, 802061.5075823958, 209669.926362501]
[2019-03-23 17:18:28,214] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:18:28,219] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.6375689e-06 3.0317912e-12 9.9999833e-01 2.7866728e-13 1.2288127e-13], sampled 0.6533049581679655
[2019-03-23 17:18:48,339] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00198188], dtype=float32), 0.00074011687]
[2019-03-23 17:18:48,340] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.4, 59.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3440784789611822, 6.911200000000001, 6.9112, 95.55338769695034, 397079.2642291343, 397079.264229134, 156153.2687837521]
[2019-03-23 17:18:48,341] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:18:48,346] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.7636743e-07 7.1470357e-10 9.9999940e-01 1.9317647e-10 2.3052636e-11], sampled 0.8172479547911142
[2019-03-23 17:19:01,613] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00198188], dtype=float32), 0.00074011687]
[2019-03-23 17:19:01,614] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.21666666666667, 80.16666666666667, 1.0, 2.0, 0.2102896616424564, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4110966794976603, 6.911200000000001, 6.9112, 95.55338769695034, 472440.0785134096, 472440.0785134092, 165482.8944847732]
[2019-03-23 17:19:01,616] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:19:01,618] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.6886696e-07 6.7666639e-10 9.9999928e-01 1.7132709e-10 2.0390845e-11], sampled 0.9713246619072605
[2019-03-23 17:19:04,078] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00198188], dtype=float32), 0.00074011687]
[2019-03-23 17:19:04,080] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.86733374, 48.31093578166666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 95.55338769695034, 318704.3742858219, 318704.3742858223, 118595.5539093385]
[2019-03-23 17:19:04,081] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:19:04,083] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.1168480e-06 2.0441442e-09 9.9999893e-01 5.9992078e-10 7.8438034e-11], sampled 0.30789474312839504
[2019-03-23 17:19:12,641] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00198188], dtype=float32), 0.00074011687]
[2019-03-23 17:19:12,641] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.27262081, 65.397967795, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3258564307050092, 6.911200000000001, 6.9112, 95.55338769695034, 376556.3798156831, 376556.3798156827, 153478.0311415839]
[2019-03-23 17:19:12,643] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:19:12,646] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.1423283e-06 2.6338902e-09 9.9999881e-01 8.1456814e-10 1.0661377e-10], sampled 0.18873015716536024
[2019-03-23 17:19:19,061] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00198188], dtype=float32), 0.00074011687]
[2019-03-23 17:19:19,062] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.63333333333333, 51.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 292792.4907728086, 292792.4907728086, 114812.9697065636]
[2019-03-23 17:19:19,064] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:19:19,066] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.8528970e-06 1.6440953e-08 9.9999619e-01 5.7296821e-09 8.8748592e-10], sampled 0.5734382327570475
[2019-03-23 17:19:24,073] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3362.1743 2098038232.9775 179.0000
[2019-03-23 17:19:24,168] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3615.0043 2175274589.9064 245.0000
[2019-03-23 17:19:24,319] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3519.0325 2104095443.0865 178.0000
[2019-03-23 17:19:24,549] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2760.8185 2124028802.4384 757.0000
[2019-03-23 17:19:24,619] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3118.8146 2109022190.6825 368.0000
[2019-03-23 17:19:25,633] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 300000, evaluation results [300000.0, 3615.0043166823143, 2175274589.906365, 245.0, 3362.17426541809, 2098038232.977526, 179.0, 3519.032511138161, 2104095443.0864863, 178.0, 2760.8185451384174, 2124028802.4384468, 757.0, 3118.8146269445274, 2109022190.6824877, 368.0]
[2019-03-23 17:19:30,768] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9066820e-06 1.6485402e-09 9.9999011e-01 1.9031912e-10 1.7185958e-11], sum to 1.0000
[2019-03-23 17:19:30,782] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7941
[2019-03-23 17:19:30,786] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.5, 91.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3483117971696044, 6.911200000000001, 6.9112, 77.32846344354104, 401206.7365745551, 401206.7365745548, 152830.4593962494], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3395400.0000, 
sim time next is 3396000.0000, 
raw observation next is [19.0, 88.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3526456376178043, 6.9112, 6.9112, 77.32846344354104, 405791.1541639233, 405791.1541639233, 153742.6231115881], 
processed observation next is [1.0, 0.30434782608695654, 0.5, 0.8866666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.07520805373972048, 0.0, 0.0, 0.5084288129206541, 0.15029302006071232, 0.15029302006071232, 0.3749820075892393], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.8155178], dtype=float32), 0.69182694]. 
=============================================
[2019-03-23 17:19:30,798] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[1.6989578 ]
 [1.3208969 ]
 [1.1515348 ]
 [0.98078847]
 [0.71667325]], R is [[1.94215775]
 [1.92273617]
 [1.90350878]
 [1.88447368]
 [1.86562896]].
[2019-03-23 17:19:31,442] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.9704903e-05 1.2384548e-09 9.9991024e-01 2.3261254e-11 1.3624807e-11], sum to 1.0000
[2019-03-23 17:19:31,446] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2235
[2019-03-23 17:19:31,450] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 74.0, 1.0, 2.0, 0.2754958854192711, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5579397362407831, 6.911200000000001, 6.9112, 77.32846344354104, 624346.4566765664, 624346.4566765662, 188043.9422508994], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3437400.0000, 
sim time next is 3438000.0000, 
raw observation next is [26.0, 74.0, 1.0, 2.0, 0.2754237096925107, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5577938842250886, 6.9112, 6.9112, 77.32846344354104, 624184.7722412533, 624184.7722412533, 188023.8653130602], 
processed observation next is [1.0, 0.8260869565217391, 0.8181818181818182, 0.74, 1.0, 1.0, 0.09427963711563833, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3682769774644123, 0.0, 0.0, 0.5084288129206541, 0.23117954527453827, 0.23117954527453827, 0.4585947934464883], 
reward next is 0.5414, 
noisyNet noise sample is [array([0.33412424], dtype=float32), -1.0330923]. 
=============================================
[2019-03-23 17:19:31,471] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[12.11411 ]
 [12.474938]
 [12.889327]
 [13.561368]
 [14.686034]], R is [[12.3310318 ]
 [12.7490778 ]
 [13.1624012 ]
 [13.57045555]
 [13.97437286]].
[2019-03-23 17:19:37,302] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.2072316e-03 9.4895177e-12 9.9279273e-01 1.3748025e-13 2.2266682e-14], sum to 1.0000
[2019-03-23 17:19:37,309] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8597
[2019-03-23 17:19:37,315] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.2473640663301903, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4999156101506336, 6.9112, 6.9112, 77.32846344354104, 564335.4934480658, 564335.4934480658, 177540.5344457729], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3643200.0000, 
sim time next is 3643800.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.2693054685373077, 0.0, 2.0, 0.0, 1.0, 2.0, 0.544294234675813, 6.9112, 6.9112, 77.32846344354104, 614407.5794771836, 614407.5794771836, 182846.0839910961], 
processed observation next is [1.0, 0.17391304347826086, 0.5909090909090909, 1.0, 1.0, 1.0, 0.0866318356716346, 0.0, 1.0, -0.25, 1.0, 1.0, 0.34899176382258995, 0.0, 0.0, 0.5084288129206541, 0.22755836276932728, 0.22755836276932728, 0.44596605851486854], 
reward next is 0.5540, 
noisyNet noise sample is [array([-0.21607415], dtype=float32), -0.87769467]. 
=============================================
[2019-03-23 17:19:39,024] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.7562920e-01 2.5096952e-13 3.2437083e-01 2.3577550e-15 4.2760622e-13], sum to 1.0000
[2019-03-23 17:19:39,029] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5407
[2019-03-23 17:19:39,036] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 588309.6312326894 W.
[2019-03-23 17:19:39,041] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 98.0, 1.0, 2.0, 0.2579909151945231, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5218383507706579, 6.9112, 6.9112, 77.32846344354104, 588309.6312326894, 588309.6312326894, 180629.2646442027], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3559200.0000, 
sim time next is 3559800.0000, 
raw observation next is [21.16666666666666, 99.0, 1.0, 2.0, 0.5097212476171554, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 581499.9572351174, 581499.9572351174, 142859.1522351399], 
processed observation next is [1.0, 0.17391304347826086, 0.5984848484848482, 0.99, 1.0, 1.0, 0.38715155952144426, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21537035453152498, 0.21537035453152498, 0.3484369566710729], 
reward next is 0.6516, 
noisyNet noise sample is [array([-1.9126666], dtype=float32), 0.12811162]. 
=============================================
[2019-03-23 17:19:42,224] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.5175544e-04 5.8892859e-13 9.9904817e-01 6.6783974e-14 1.5812116e-13], sum to 1.0000
[2019-03-23 17:19:42,231] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6701
[2019-03-23 17:19:42,239] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.83333333333333, 78.83333333333333, 1.0, 2.0, 0.2499922534077878, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5054355814193676, 6.911199999999999, 6.9112, 77.32846344354104, 570223.9870153181, 570223.9870153184, 178414.4016898874], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3611400.0000, 
sim time next is 3612000.0000, 
raw observation next is [23.66666666666666, 79.66666666666667, 1.0, 2.0, 0.2485459801817324, 0.0, 2.0, 0.0, 1.0, 2.0, 0.502421498993663, 6.911200000000001, 6.9112, 77.32846344354104, 566975.302820633, 566975.3028206327, 177960.314681448], 
processed observation next is [1.0, 0.8260869565217391, 0.7121212121212118, 0.7966666666666667, 1.0, 1.0, 0.060682475227165494, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2891735699909471, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20999085289653077, 0.20999085289653063, 0.43404954800353174], 
reward next is 0.5660, 
noisyNet noise sample is [array([0.18174481], dtype=float32), 0.94689184]. 
=============================================
[2019-03-23 17:19:42,259] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[33.820896]
 [33.98544 ]
 [33.39073 ]
 [33.05351 ]
 [33.001045]], R is [[33.91432953]
 [34.14002991]
 [34.36219406]
 [34.58038712]
 [34.79492569]].
[2019-03-23 17:19:42,999] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.1490540e-02 4.2052356e-12 9.7850949e-01 2.1570746e-15 3.0668184e-13], sum to 1.0000
[2019-03-23 17:19:43,005] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5357
[2019-03-23 17:19:43,010] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.16666666666666, 99.0, 1.0, 2.0, 0.2494690499486759, 0.0, 1.0, 0.0, 1.0, 2.0, 0.504488814397871, 6.911199999999999, 6.9112, 77.32846344354104, 568955.0760573249, 568955.0760573252, 178443.8065235384], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3624600.0000, 
sim time next is 3625200.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.2488988745568726, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5030549729678786, 6.911199999999999, 6.9112, 77.32846344354104, 567821.5241038396, 567821.5241038399, 177940.9309389822], 
processed observation next is [1.0, 1.0, 0.5909090909090909, 1.0, 1.0, 1.0, 0.06112359319609073, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2900785328112552, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21030426818660727, 0.21030426818660736, 0.43400227058288343], 
reward next is 0.5660, 
noisyNet noise sample is [array([0.52954215], dtype=float32), -0.022265865]. 
=============================================
[2019-03-23 17:19:44,074] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.0709183e-01 1.6043653e-15 1.9290821e-01 2.2819933e-16 1.5879203e-14], sum to 1.0000
[2019-03-23 17:19:44,083] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9503
[2019-03-23 17:19:44,086] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.0, 53.5, 1.0, 2.0, 0.4476272352770083, 1.0, 1.0, 0.4476272352770083, 1.0, 2.0, 0.9049037888201991, 6.911199999999998, 6.9112, 77.3421103, 1513771.801582924, 1513771.801582925, 329620.875542331], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3684600.0000, 
sim time next is 3685200.0000, 
raw observation next is [29.0, 53.0, 1.0, 2.0, 0.9114563571490804, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9781926491254143, 6.911199999999999, 6.9112, 77.32846344354104, 1583351.450022784, 1583351.450022785, 328474.5206351579], 
processed observation next is [1.0, 0.6521739130434783, 0.9545454545454546, 0.53, 1.0, 1.0, 0.8893204464363504, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9688466416077347, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5864264629714016, 0.5864264629714019, 0.8011573674028241], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.02250463], dtype=float32), -1.0970819]. 
=============================================
[2019-03-23 17:19:44,102] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.5654864e-01 9.0981194e-13 6.4345145e-01 4.6220714e-16 2.2003228e-12], sum to 1.0000
[2019-03-23 17:19:44,111] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8220
[2019-03-23 17:19:44,122] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.2834319197482726, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5729045622522467, 6.911199999999999, 6.9112, 77.32846344354104, 646628.4338558252, 646628.4338558256, 186537.6539822848], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3652800.0000, 
sim time next is 3653400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.2877732002695452, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5816955625198407, 6.9112, 6.9112, 77.32846344354104, 656531.1348455681, 656531.1348455681, 187706.5651116818], 
processed observation next is [1.0, 0.2608695652173913, 0.5909090909090909, 1.0, 1.0, 1.0, 0.10971650033693152, 0.0, 1.0, -0.25, 1.0, 1.0, 0.402422232171201, 0.0, 0.0, 0.5084288129206541, 0.24315967957243262, 0.24315967957243262, 0.45782089051629704], 
reward next is 0.5422, 
noisyNet noise sample is [array([1.0257952], dtype=float32), 0.40255702]. 
=============================================
[2019-03-23 17:19:48,308] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.0874478e-01 9.2384962e-14 5.9125525e-01 2.6283271e-16 1.5091157e-14], sum to 1.0000
[2019-03-23 17:19:48,316] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8174
[2019-03-23 17:19:48,322] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.2603029780147063, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5267773769869815, 6.9112, 6.9112, 77.32846344354104, 593302.4208006851, 593302.4208006851, 181611.2759352347], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3728400.0000, 
sim time next is 3729000.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.2615915901420244, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5292431499772864, 6.9112, 6.9112, 77.32846344354104, 596409.1998409996, 596409.1998409996, 181690.6403603654], 
processed observation next is [1.0, 0.13043478260869565, 0.6363636363636364, 0.94, 1.0, 1.0, 0.07698948767753046, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3274902142532663, 0.0, 0.0, 0.5084288129206541, 0.22089229623740725, 0.22089229623740725, 0.4431479033179644], 
reward next is 0.5569, 
noisyNet noise sample is [array([1.513386], dtype=float32), 0.67912537]. 
=============================================
[2019-03-23 17:19:48,342] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[59.35675 ]
 [58.95605 ]
 [60.432167]
 [59.984142]
 [60.146442]], R is [[58.28505325]
 [57.70220184]
 [57.12517929]
 [57.10851669]
 [57.07600021]].
[2019-03-23 17:19:49,596] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.8855968e-01 5.0334730e-14 7.1144027e-01 1.8802167e-16 1.4586800e-13], sum to 1.0000
[2019-03-23 17:19:49,602] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9139
[2019-03-23 17:19:49,607] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.66666666666667, 69.0, 1.0, 2.0, 0.2917892586740186, 1.0, 1.0, 0.2917892586740186, 1.0, 2.0, 0.5881130154054062, 6.911199999999999, 6.9112, 77.3421103, 999320.6044818773, 999320.6044818775, 249745.1389411298], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3750000.0000, 
sim time next is 3750600.0000, 
raw observation next is [23.83333333333333, 69.0, 1.0, 2.0, 0.440148430167301, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8846313936744684, 6.9112, 6.9112, 77.32846344353835, 1004474.033254271, 1004474.033254271, 234106.838984624], 
processed observation next is [1.0, 0.391304347826087, 0.7196969696969695, 0.69, 1.0, 1.0, 0.3001855377091262, 0.0, 0.5, -0.25, 1.0, 1.0, 0.8351877052492407, 0.0, 0.0, 0.5084288129206365, 0.3720274197238041, 0.3720274197238041, 0.5709922902064], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7131224], dtype=float32), -0.95357436]. 
=============================================
[2019-03-23 17:19:52,569] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.391699e-07 9.282589e-09 9.999994e-01 5.489625e-10 5.065956e-11], sum to 1.0000
[2019-03-23 17:19:52,578] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9525
[2019-03-23 17:19:52,582] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 322436.9996481845, 322436.9996481848, 139990.5719400709], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3844200.0000, 
sim time next is 3844800.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 321792.2937640042, 321792.2937640045, 139891.3915203187], 
processed observation next is [0.0, 0.5217391304347826, 0.5, 0.73, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11918233102370526, 0.11918233102370536, 0.3411985159032163], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9048007], dtype=float32), 0.18113436]. 
=============================================
[2019-03-23 17:19:55,079] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.9731250e-06 1.1831434e-09 9.9999702e-01 4.1181357e-11 2.1432847e-11], sum to 1.0000
[2019-03-23 17:19:55,082] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2740
[2019-03-23 17:19:55,087] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.5, 80.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 304499.7885062752, 304499.7885062755, 129072.1321581732], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3981600.0000, 
sim time next is 3982200.0000, 
raw observation next is [17.41666666666667, 80.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.302818486585633, 6.911200000000001, 6.9112, 77.32846344354104, 352291.059178581, 352291.0591785807, 136893.3596023055], 
processed observation next is [1.0, 0.08695652173913043, 0.42803030303030326, 0.8033333333333335, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.004026409408047137, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1304781700661411, 0.130478170066141, 0.33388624293245245], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.51431614], dtype=float32), 0.47532254]. 
=============================================
[2019-03-23 17:19:57,324] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4703749e-06 7.9582591e-10 9.9999857e-01 7.7046902e-10 7.1176054e-10], sum to 1.0000
[2019-03-23 17:19:57,331] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6836
[2019-03-23 17:19:57,340] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 304327.2347440493, 304327.2347440493, 131301.8123674736], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3896400.0000, 
sim time next is 3897000.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 304167.8214426277, 304167.8214426274, 131265.5943103041], 
processed observation next is [0.0, 0.08695652173913043, 0.45454545454545453, 0.77, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1126547486824547, 0.11265474868245459, 0.3201599861226929], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6460806], dtype=float32), -0.71993726]. 
=============================================
[2019-03-23 17:19:57,358] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[0.9404979 ]
 [0.93329656]
 [1.1110077 ]
 [1.0286767 ]
 [1.0980465 ]], R is [[0.95050216]
 [0.94099712]
 [0.93158716]
 [0.92227131]
 [0.91304862]].
[2019-03-23 17:20:04,131] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.5853997e-02 4.9214209e-11 9.6414596e-01 4.3688036e-11 2.0384421e-09], sum to 1.0000
[2019-03-23 17:20:04,139] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0668
[2019-03-23 17:20:04,148] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3129529938196499, 6.9112, 6.9112, 77.32846344354104, 362577.3205038327, 362577.3205038327, 146519.2490890815], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4053600.0000, 
sim time next is 4054200.0000, 
raw observation next is [17.0, 94.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3115439178165288, 6.9112, 6.9112, 77.32846344354104, 360999.111909769, 360999.111909769, 146306.6422050464], 
processed observation next is [1.0, 0.9565217391304348, 0.4090909090909091, 0.9400000000000002, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.01649131116646972, 0.0, 0.0, 0.5084288129206541, 0.13370337478139593, 0.13370337478139593, 0.3568454687927961], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.88961554], dtype=float32), 0.035662513]. 
=============================================
[2019-03-23 17:20:06,830] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.3062503e-05 1.9264204e-09 9.9997699e-01 5.0509197e-10 6.3353413e-11], sum to 1.0000
[2019-03-23 17:20:06,842] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1874
[2019-03-23 17:20:06,848] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [15.86666666666667, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 326331.10404706, 326331.1040470603, 140641.824766971], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4077600.0000, 
sim time next is 4078200.0000, 
raw observation next is [15.83333333333333, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 324627.9633160905, 324627.9633160908, 140330.0911725583], 
processed observation next is [1.0, 0.17391304347826086, 0.3560606060606059, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12023257900595945, 0.12023257900595956, 0.34226851505502026], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0612876], dtype=float32), 2.7810423]. 
=============================================
[2019-03-23 17:20:12,002] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5464749e-06 2.2194131e-09 9.9999845e-01 7.3234835e-10 9.3757968e-10], sum to 1.0000
[2019-03-23 17:20:12,008] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1264
[2019-03-23 17:20:12,018] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.33333333333334, 98.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3232682992669224, 6.9112, 6.9112, 77.32846344354104, 373148.6528657426, 373148.6528657426, 149061.4531077417], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4170000.0000, 
sim time next is 4170600.0000, 
raw observation next is [17.5, 97.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3239346536226313, 6.9112, 6.9112, 77.32846344354104, 373801.9445771019, 373801.9445771019, 149252.7777683068], 
processed observation next is [1.0, 0.2608695652173913, 0.4318181818181818, 0.97, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.034192362318044726, 0.0, 0.0, 0.5084288129206541, 0.1384451646581859, 0.1384451646581859, 0.3640311652885532], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8321125], dtype=float32), 0.1732579]. 
=============================================
[2019-03-23 17:20:13,960] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4344862e-05 5.9583721e-10 9.9998569e-01 2.5132077e-10 5.9651693e-11], sum to 1.0000
[2019-03-23 17:20:13,969] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3216
[2019-03-23 17:20:13,973] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.33333333333334, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3403518632396494, 6.9112, 6.9112, 77.32846344354104, 392455.6150747066, 392455.6150747066, 151465.3937506462], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4234800.0000, 
sim time next is 4235400.0000, 
raw observation next is [18.0, 91.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3333704821721706, 6.9112, 6.9112, 77.32846344354104, 384838.7862815846, 384838.7862815846, 150212.4087679925], 
processed observation next is [1.0, 0.0, 0.45454545454545453, 0.91, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.04767211738881513, 0.0, 0.0, 0.5084288129206541, 0.14253288380799428, 0.14253288380799428, 0.36637172870242074], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.08008689], dtype=float32), 0.85697657]. 
=============================================
[2019-03-23 17:20:14,798] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 17:20:14,799] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:20:14,800] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:20:14,800] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:20:14,800] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:20:14,800] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:20:14,801] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:20:14,802] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:20:14,802] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:20:14,804] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:20:14,804] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:20:14,821] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run14
[2019-03-23 17:20:14,821] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run14
[2019-03-23 17:20:14,869] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run14
[2019-03-23 17:20:14,870] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run14
[2019-03-23 17:20:14,920] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run14
[2019-03-23 17:20:20,870] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00175422], dtype=float32), 0.0010697623]
[2019-03-23 17:20:20,872] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.46666666666667, 78.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 324372.1327108747, 324372.1327108747, 145168.2516503106]
[2019-03-23 17:20:20,872] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:20:20,875] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.1957773e-06 4.2696433e-09 9.9999678e-01 1.6143205e-09 2.7603705e-10], sampled 0.27248976063366004
[2019-03-23 17:20:30,709] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00175422], dtype=float32), 0.0010697623]
[2019-03-23 17:20:30,710] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.33333333333334, 78.0, 1.0, 2.0, 0.2009966938856069, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3970767048310284, 6.9112, 6.9112, 95.55338769695034, 454624.3587368706, 454624.3587368706, 165945.472410735]
[2019-03-23 17:20:30,711] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:20:30,714] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.2347086e-06 9.8765229e-10 9.9999881e-01 3.6606726e-10 5.8008699e-11], sampled 0.7994603775122568
[2019-03-23 17:20:47,608] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00175422], dtype=float32), 0.0010697623]
[2019-03-23 17:20:47,609] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.24991937333333, 85.48807156666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3480681549099868, 6.911199999999999, 6.9112, 74.59208042816964, 404961.4398269986, 404961.4398269989, 122927.9132921127]
[2019-03-23 17:20:47,611] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:20:47,615] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.6191865e-06 3.1660692e-09 9.9999332e-01 1.0403534e-09 2.8329716e-10], sampled 0.1939807524628655
[2019-03-23 17:20:56,369] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00175422], dtype=float32), 0.0010697623]
[2019-03-23 17:20:56,370] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.7, 74.5, 1.0, 2.0, 0.238285301812377, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4799194295079454, 6.9112, 6.9112, 95.55338769695034, 543703.5676492488, 543703.5676492488, 178533.7737721511]
[2019-03-23 17:20:56,373] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:20:56,376] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.2762371e-06 5.1241755e-10 9.9999869e-01 1.7085577e-10 3.2231939e-11], sampled 0.24748707763574562
[2019-03-23 17:20:58,290] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00175422], dtype=float32), 0.0010697623]
[2019-03-23 17:20:58,291] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.26666666666667, 64.33333333333333, 1.0, 2.0, 0.3174492454970252, 0.0, 2.0, 0.0, 1.0, 2.0, 0.639284058124733, 6.9112, 6.9112, 95.55338769695034, 724432.4433416739, 724432.4433416739, 198630.3425382162]
[2019-03-23 17:20:58,292] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:20:58,295] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.4651208e-06 9.2449243e-11 9.9999356e-01 1.8616430e-11 1.0388932e-11], sampled 0.9965440620881961
[2019-03-23 17:21:03,493] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00175422], dtype=float32), 0.0010697623]
[2019-03-23 17:21:03,494] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.58677102166667, 62.66145794000001, 1.0, 2.0, 0.2329994352793082, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4690204895161689, 6.911200000000001, 6.9112, 95.55338769695034, 531595.791606262, 531595.7916062616, 177173.1304681163]
[2019-03-23 17:21:03,496] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:21:03,500] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.2045087e-07 5.7139254e-10 9.9999905e-01 2.1541262e-10 3.4441869e-11], sampled 0.06760710838517059
[2019-03-23 17:21:08,015] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00175422], dtype=float32), 0.0010697623]
[2019-03-23 17:21:08,016] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.370147495, 56.20974896, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3435642542005538, 6.911200000000001, 6.9112, 95.55338769695034, 394614.7686642265, 394614.7686642261, 157847.892011514]
[2019-03-23 17:21:08,017] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:21:08,019] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.6280642e-06 6.6875336e-09 9.9999642e-01 2.7949236e-09 4.5145265e-10], sampled 0.5075623798115804
[2019-03-23 17:21:22,695] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00175422], dtype=float32), 0.0010697623]
[2019-03-23 17:21:22,695] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.85, 43.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 95.55338769695034, 344641.0684527894, 344641.0684527897, 147781.8070569068]
[2019-03-23 17:21:22,698] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:21:22,700] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.735639e-06 1.495824e-08 9.999943e-01 6.678749e-09 1.132385e-09], sampled 0.508658344526253
[2019-03-23 17:21:27,339] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00175422], dtype=float32), 0.0010697623]
[2019-03-23 17:21:27,340] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.531891605, 89.547389635, 1.0, 2.0, 0.2439439938250338, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4553899941930048, 6.9112, 6.9112, 95.55338769695034, 529830.3890873333, 529830.3890873333, 151931.6793678266]
[2019-03-23 17:21:27,341] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:21:27,345] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.9377689e-06 5.6803412e-10 9.9999404e-01 1.4725868e-10 5.4546489e-11], sampled 0.28250009956795574
[2019-03-23 17:21:32,247] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00175422], dtype=float32), 0.0010697623]
[2019-03-23 17:21:32,248] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.06666666666667, 57.33333333333334, 1.0, 2.0, 0.2031338080515607, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4038627825930939, 6.911200000000001, 6.9112, 77.32846344354104, 461183.4290302964, 461183.4290302961, 163067.5152092075]
[2019-03-23 17:21:32,249] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:21:32,252] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.7155994e-06 9.2479233e-09 9.9999630e-01 4.2484714e-09 6.9336670e-10], sampled 0.04597491067680548
[2019-03-23 17:21:54,312] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3615.0043 2175298874.9786 245.0000
[2019-03-23 17:21:54,633] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2760.0075 2124053765.3178 757.0000
[2019-03-23 17:21:54,640] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3360.1270 2098064777.3875 180.0000
[2019-03-23 17:21:54,720] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3119.6425 2108992341.7382 368.0000
[2019-03-23 17:21:54,791] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3519.0325 2104097639.3110 178.0000
[2019-03-23 17:21:55,805] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 325000, evaluation results [325000.0, 3615.004316682305, 2175298874.9786286, 245.0, 3360.127020422623, 2098064777.3875077, 180.0, 3519.032511138161, 2104097639.3109927, 178.0, 2760.0074851005825, 2124053765.3177998, 757.0, 3119.6425342292473, 2108992341.738153, 368.0]
[2019-03-23 17:22:01,780] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.9896087e-05 1.3272795e-10 9.9996006e-01 9.0239682e-12 5.5106600e-11], sum to 1.0000
[2019-03-23 17:22:01,787] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8109
[2019-03-23 17:22:01,792] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 95.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3649120676773456, 6.9112, 6.9112, 77.32846344354104, 420279.2955608135, 420279.2955608135, 154923.920067524], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4330200.0000, 
sim time next is 4330800.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3728888775677515, 6.911199999999999, 6.9112, 77.32846344354104, 429721.0509074084, 429721.0509074087, 155689.2860981078], 
processed observation next is [1.0, 0.13043478260869565, 0.45454545454545453, 0.94, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.10412696795393077, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15915594478052164, 0.15915594478052175, 0.3797299660929459], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1480365], dtype=float32), 0.6402173]. 
=============================================
[2019-03-23 17:22:06,579] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.10486919e-01 5.32318460e-12 7.89513052e-01 3.99152239e-12
 1.02540155e-11], sum to 1.0000
[2019-03-23 17:22:06,592] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8832
[2019-03-23 17:22:06,596] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.5, 80.5, 1.0, 2.0, 0.2226541405952709, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4472627943068487, 6.911199999999999, 6.9112, 77.32846344348239, 507792.5598389583, 507792.5598389586, 169586.5190391939], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4437000.0000, 
sim time next is 4437600.0000, 
raw observation next is [22.66666666666666, 79.66666666666667, 1.0, 2.0, 0.2235648150460146, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4492638000185604, 6.9112, 6.9112, 77.32846344354068, 509923.7892841558, 509923.7892841558, 169900.4847903377], 
processed observation next is [0.0, 0.34782608695652173, 0.6666666666666664, 0.7966666666666667, 1.0, 1.0, 0.029456018807518247, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2132340000265149, 0.0, 0.0, 0.5084288129206518, 0.1888606626978355, 0.1888606626978355, 0.4143914263178968], 
reward next is 0.5856, 
noisyNet noise sample is [array([0.8898931], dtype=float32), 0.78341824]. 
=============================================
[2019-03-23 17:22:20,258] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.8182347e-05 9.0657082e-10 9.9992180e-01 1.8245447e-10 7.1435476e-11], sum to 1.0000
[2019-03-23 17:22:20,263] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5310
[2019-03-23 17:22:20,267] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 60.0, 1.0, 2.0, 0.2589174415839193, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4868842021102401, 6.9112, 6.9112, 77.32846344354104, 565164.3220961037, 565164.3220961037, 162675.9381622156], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4701600.0000, 
sim time next is 4702200.0000, 
raw observation next is [21.16666666666667, 60.0, 1.0, 2.0, 0.2929128753139945, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5535251412742695, 6.9112, 6.9112, 77.32846344354104, 641909.2204126535, 641909.2204126535, 170209.6165479732], 
processed observation next is [1.0, 0.43478260869565216, 0.5984848484848487, 0.6, 1.0, 1.0, 0.11614109414249313, 0.0, 1.0, -0.25, 1.0, 1.0, 0.36217877324895653, 0.0, 0.0, 0.5084288129206541, 0.2377441557083902, 0.2377441557083902, 0.41514540621456875], 
reward next is 0.5849, 
noisyNet noise sample is [array([0.5298788], dtype=float32), 0.2359582]. 
=============================================
[2019-03-23 17:22:20,309] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2881728e-06 6.5132979e-09 9.9999869e-01 1.6814411e-09 1.4629471e-09], sum to 1.0000
[2019-03-23 17:22:20,315] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1063
[2019-03-23 17:22:20,320] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.0, 85.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 229330.3884133237, 229330.388413324, 94319.96199814175], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4685400.0000, 
sim time next is 4686000.0000, 
raw observation next is [14.0, 84.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 223766.3381759089, 223766.3381759089, 93038.9398214398], 
processed observation next is [1.0, 0.21739130434782608, 0.2727272727272727, 0.84, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.08287642154663293, 0.08287642154663293, 0.22692424346692633], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.37060693], dtype=float32), 1.1098534]. 
=============================================
[2019-03-23 17:22:20,338] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[3.061427 ]
 [3.0524838]
 [3.1071827]
 [3.005758 ]
 [3.0877037]], R is [[3.13195872]
 [3.1006391 ]
 [3.06963277]
 [3.03893638]
 [3.00854707]].
[2019-03-23 17:22:27,454] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.8124457e-02 3.2226809e-13 9.7187561e-01 7.3216552e-14 6.6560698e-12], sum to 1.0000
[2019-03-23 17:22:27,456] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9912
[2019-03-23 17:22:27,463] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.0, 99.00000000000001, 1.0, 2.0, 0.2208591457222382, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4431926784392416, 6.9112, 6.9112, 77.32846343192836, 503536.0630183787, 503536.0630183787, 168882.9880477301], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4842600.0000, 
sim time next is 4843200.0000, 
raw observation next is [20.0, 98.0, 1.0, 2.0, 0.219143939513094, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4393005962664659, 6.9112, 6.9112, 77.32846344346916, 499447.2880785092, 499447.2880785092, 168223.53083094], 
processed observation next is [1.0, 0.043478260869565216, 0.5454545454545454, 0.98, 1.0, 1.0, 0.02392992439136748, 0.0, 1.0, -0.25, 1.0, 1.0, 0.19900085180923702, 0.0, 0.0, 0.5084288129201815, 0.18498047706611453, 0.18498047706611453, 0.41030129470960974], 
reward next is 0.5897, 
noisyNet noise sample is [array([-0.05525728], dtype=float32), -0.13283163]. 
=============================================
[2019-03-23 17:22:28,806] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8229445e-02 1.6913254e-13 9.8177058e-01 2.9526957e-15 1.9364344e-13], sum to 1.0000
[2019-03-23 17:22:28,815] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8530
[2019-03-23 17:22:28,819] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.0, 94.0, 1.0, 2.0, 0.2073765089115424, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4136179891974062, 6.9112, 6.9112, 77.32846344354104, 471591.2130769755, 471591.2130769755, 164602.5764128417], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4852800.0000, 
sim time next is 4853400.0000, 
raw observation next is [19.83333333333334, 95.0, 1.0, 2.0, 0.2158594067468043, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4303939985742998, 6.911199999999999, 6.9112, 77.32846344354104, 490811.9547285042, 490811.9547285045, 166081.3559872891], 
processed observation next is [1.0, 0.17391304347826086, 0.5378787878787882, 0.95, 1.0, 1.0, 0.019824258433505347, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1862771408204283, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18178220545500154, 0.18178220545500168, 0.4050764780177783], 
reward next is 0.5949, 
noisyNet noise sample is [array([-0.15724142], dtype=float32), 0.89553297]. 
=============================================
[2019-03-23 17:22:31,047] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.4667767e-02 4.4925345e-11 9.4533223e-01 1.1263955e-11 3.7851933e-11], sum to 1.0000
[2019-03-23 17:22:31,055] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7411
[2019-03-23 17:22:31,058] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 228507.3005647861, 228507.3005647864, 95587.63739816146], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5029200.0000, 
sim time next is 5029800.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 225122.9963132414, 225122.9963132417, 94903.90022813027], 
processed observation next is [0.0, 0.21739130434782608, 0.22727272727272727, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08337888752342273, 0.08337888752342285, 0.2314729273856836], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5746568], dtype=float32), -0.40393284]. 
=============================================
[2019-03-23 17:22:40,553] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.1860135e-04 3.7768870e-14 9.9908137e-01 8.1184471e-16 8.9148991e-14], sum to 1.0000
[2019-03-23 17:22:40,562] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3668
[2019-03-23 17:22:40,567] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 81.33333333333334, 1.0, 2.0, 0.2119202608337129, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4244804328265449, 6.9112, 6.9112, 77.32846344354104, 482831.0635823695, 482831.0635823695, 166598.0560413617], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5206800.0000, 
sim time next is 5207400.0000, 
raw observation next is [22.0, 80.5, 1.0, 2.0, 0.2081073250962763, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4163913465370289, 6.9112, 6.9112, 77.32846344354104, 473932.8353543109, 473932.8353543109, 165578.1965007758], 
processed observation next is [1.0, 0.2608695652173913, 0.6363636363636364, 0.805, 1.0, 1.0, 0.010134156370345364, 0.0, 1.0, -0.25, 1.0, 1.0, 0.16627335219575562, 0.0, 0.0, 0.5084288129206541, 0.1755306797608559, 0.1755306797608559, 0.4038492597579898], 
reward next is 0.5962, 
noisyNet noise sample is [array([-0.7162665], dtype=float32), -0.12993635]. 
=============================================
[2019-03-23 17:22:42,206] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.8552035e-02 1.2700533e-11 9.7144800e-01 1.5791115e-12 2.6606550e-11], sum to 1.0000
[2019-03-23 17:22:42,219] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0973
[2019-03-23 17:22:42,231] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3913845999919204, 6.911200000000001, 6.9112, 77.32846344354104, 447932.3441310672, 447932.3441310669, 160814.3881418226], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5104800.0000, 
sim time next is 5105400.0000, 
raw observation next is [20.16666666666667, 87.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3896234207152732, 6.9112, 6.9112, 77.32846344354104, 445882.5616214953, 445882.5616214953, 160607.3284299716], 
processed observation next is [0.0, 0.08695652173913043, 0.5530303030303032, 0.8716666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.12803345816467607, 0.0, 0.0, 0.5084288129206541, 0.1651416894894427, 0.1651416894894427, 0.39172519129261363], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.3362764], dtype=float32), 0.9371379]. 
=============================================
[2019-03-23 17:22:45,073] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 17:22:45,074] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:22:45,076] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:22:45,078] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:22:45,080] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:22:45,080] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:22:45,080] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:22:45,081] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:22:45,081] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:22:45,083] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:22:45,084] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:22:45,103] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run15
[2019-03-23 17:22:45,104] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run15
[2019-03-23 17:22:45,128] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run15
[2019-03-23 17:22:45,190] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run15
[2019-03-23 17:22:45,191] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run15
[2019-03-23 17:23:00,331] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00168322], dtype=float32), 0.0017001549]
[2019-03-23 17:23:00,332] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.88333333333333, 70.66666666666667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7665823517401484, 7.52505293629282, 6.9112, 95.55147862976135, 681978.4966257027, 435629.3625849044, 141206.5656816422]
[2019-03-23 17:23:00,334] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:23:00,338] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.3591232e-01 3.7398589e-13 7.6408774e-01 2.4671842e-14 1.0990672e-12], sampled 0.9855580200790918
[2019-03-23 17:23:08,126] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00168322], dtype=float32), 0.0017001549]
[2019-03-23 17:23:08,128] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.03333333333333, 81.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 274740.7294838368, 274740.7294838364, 109198.1718163131]
[2019-03-23 17:23:08,130] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:23:08,131] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.24443084e-01 5.02361607e-12 8.75556886e-01 4.21075338e-13
 1.23764991e-11], sampled 0.8933763869714658
[2019-03-23 17:24:06,600] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00168322], dtype=float32), 0.0017001549]
[2019-03-23 17:24:06,605] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.52097148666667, 75.14923591333334, 1.0, 2.0, 0.5048982350132337, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 575710.3101962677, 575710.3101962677, 147018.7426872053]
[2019-03-23 17:24:06,605] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:24:06,607] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.7284306e-01 1.2148608e-12 7.2715700e-01 8.9443298e-14 3.3699339e-12], sampled 0.15800176074694805
[2019-03-23 17:24:06,609] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 575710.3101962677 W.
[2019-03-23 17:24:24,176] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3345.2882 2110851714.0796 723.0000
[2019-03-23 17:24:24,318] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3147.7679 2031437435.5248 858.0000
[2019-03-23 17:24:24,368] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3060.5805 2027975615.0519 844.0000
[2019-03-23 17:24:24,511] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 2863.9773 2041260138.6503 951.0000
[2019-03-23 17:24:24,675] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2663.8421 2058853561.9757 1325.0000
[2019-03-23 17:24:25,690] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 350000, evaluation results [350000.0, 3345.288241804313, 2110851714.0796015, 723.0, 3060.5804972009155, 2027975615.0518665, 844.0, 3147.767888993215, 2031437435.524753, 858.0, 2663.8421222106927, 2058853561.975699, 1325.0, 2863.9772519940993, 2041260138.6502986, 951.0]
[2019-03-23 17:24:26,465] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.4236428e-01 5.2754381e-12 5.7635766e-02 9.0299926e-14 3.8089689e-13], sum to 1.0000
[2019-03-23 17:24:26,474] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1204
[2019-03-23 17:24:26,482] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 576618.2676173281 W.
[2019-03-23 17:24:26,485] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7756799222649929, 7.331902884764319, 6.9112, 77.32743245239587, 576618.2676173281, 439984.397219936, 138573.9222194575], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5205600.0000, 
sim time next is 5206200.0000, 
raw observation next is [22.0, 82.16666666666667, 1.0, 1.0, 0.4745764558835835, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.328210629973, 540759.7172858156, 540759.7172858156, 136169.0451339832], 
processed observation next is [1.0, 0.2608695652173913, 0.6363636363636364, 0.8216666666666668, 1.0, 0.5, 0.34322056985447935, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084271506905184, 0.2002813767725243, 0.2002813767725243, 0.3321196222780078], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0585586], dtype=float32), 1.002104]. 
=============================================
[2019-03-23 17:24:37,325] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8404098e-02 9.2297361e-13 9.8159593e-01 5.5533025e-13 1.4847215e-12], sum to 1.0000
[2019-03-23 17:24:37,331] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3102
[2019-03-23 17:24:37,339] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.4, 93.0, 1.0, 2.0, 0.2003056297388217, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3959935341283995, 6.9112, 6.9112, 77.32846344354104, 453295.7035078321, 453295.7035078321, 161330.6656100338], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5425200.0000, 
sim time next is 5425800.0000, 
raw observation next is [19.3, 93.66666666666666, 1.0, 2.0, 0.2000265969986914, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3953508427200844, 6.9112, 6.9112, 77.32846344354104, 452601.3137815783, 452601.3137815783, 161235.4072817271], 
processed observation next is [1.0, 0.8260869565217391, 0.5136363636363637, 0.9366666666666665, 1.0, 1.0, 3.32462483642465e-05, 0.0, 1.0, -0.25, 1.0, 1.0, 0.13621548960012062, 0.0, 0.0, 0.5084288129206541, 0.1676301162153994, 0.1676301162153994, 0.39325709093104166], 
reward next is 0.6067, 
noisyNet noise sample is [array([-1.1668696], dtype=float32), 1.5125663]. 
=============================================
[2019-03-23 17:24:42,878] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.1333813e-06 8.5770098e-12 9.9999785e-01 4.3760709e-13 9.1505384e-13], sum to 1.0000
[2019-03-23 17:24:42,885] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2784
[2019-03-23 17:24:42,892] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.86666666666667, 71.0, 1.0, 2.0, 0.516763843501221, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9596134931723052, 6.940935083693794, 6.9112, 77.32839049875199, 1135578.476889255, 1125921.13900303, 262900.6144605728], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5491200.0000, 
sim time next is 5491800.0000, 
raw observation next is [26.05, 70.5, 1.0, 2.0, 0.6206501661351633, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9776900704572866, 6.911199999999999, 6.9112, 77.32844557547881, 1253163.333070794, 1253163.333070794, 280972.3266836336], 
processed observation next is [1.0, 0.5652173913043478, 0.8204545454545454, 0.705, 1.0, 1.0, 0.5258127076689542, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9681286720818381, -8.881784197001253e-17, 0.0, 0.5084286954394931, 0.46413456780399776, 0.46413456780399776, 0.6852983577649601], 
reward next is 0.3147, 
noisyNet noise sample is [array([-0.9839931], dtype=float32), 1.5642022]. 
=============================================
[2019-03-23 17:24:43,240] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.9442246e-05 2.7279770e-10 9.9996054e-01 1.7861052e-10 6.2994152e-11], sum to 1.0000
[2019-03-23 17:24:43,251] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8379
[2019-03-23 17:24:43,257] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.347159594908043, 6.911199999999999, 6.9112, 77.32846344354104, 399992.3133341134, 399992.3133341137, 152582.7538720114], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5637600.0000, 
sim time next is 5638200.0000, 
raw observation next is [17.61666666666667, 97.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3430488216122418, 6.911199999999999, 6.9112, 77.32846344354104, 395406.4689061129, 395406.4689061132, 151941.301518646], 
processed observation next is [0.0, 0.2608695652173913, 0.4371212121212123, 0.975, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0614983165889169, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14644684033559738, 0.14644684033559746, 0.37058854028938054], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.34833595], dtype=float32), -0.8131313]. 
=============================================
[2019-03-23 17:24:47,239] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.6597116e-03 2.6937125e-13 9.9834025e-01 2.0457145e-13 9.4478928e-13], sum to 1.0000
[2019-03-23 17:24:47,256] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5786
[2019-03-23 17:24:47,262] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.45, 61.5, 1.0, 2.0, 0.5667008654076338, 0.0, 2.0, 0.0, 1.0, 2.0, 0.976870472045285, 6.911199999999999, 6.9112, 77.32846344353986, 1192373.052038385, 1192373.052038386, 272537.8246259609], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5574600.0000, 
sim time next is 5575200.0000, 
raw observation next is [27.53333333333333, 61.33333333333333, 1.0, 2.0, 0.5921873301415503, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9770639150624216, 6.911199999999999, 6.9112, 77.32846344354104, 1221244.086365035, 1221244.086365035, 276341.0941360547], 
processed observation next is [1.0, 0.5217391304347826, 0.8878787878787878, 0.6133333333333333, 1.0, 1.0, 0.49023416267693787, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9672341643748881, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4523126245796426, 0.4523126245796426, 0.6740026686245236], 
reward next is 0.3260, 
noisyNet noise sample is [array([-1.642484], dtype=float32), 0.35818344]. 
=============================================
[2019-03-23 17:24:47,593] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.32034472e-05 1.11945426e-13 9.99976754e-01 3.54931579e-13
 1.06121106e-13], sum to 1.0000
[2019-03-23 17:24:47,603] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1767
[2019-03-23 17:24:47,609] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.83333333333334, 63.66666666666666, 1.0, 2.0, 0.5783862666717962, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9758052410550224, 6.9112, 6.9112, 77.328463443541, 1206331.847526699, 1206331.847526699, 273232.3013204481], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5571600.0000, 
sim time next is 5572200.0000, 
raw observation next is [27.01666666666667, 62.83333333333334, 1.0, 2.0, 0.5437572868781058, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9684113415642439, 6.923992921540418, 6.9112, 77.32843206048064, 1166885.780943416, 1162730.903373804, 267218.0209208817], 
processed observation next is [1.0, 0.4782608695652174, 0.8643939393939395, 0.6283333333333334, 1.0, 1.0, 0.42969660859763215, 0.0, 1.0, -0.25, 1.0, 1.0, 0.954873345091777, 0.0012792921540418333, 0.0, 0.5084286065793997, 0.4321799188679319, 0.4306410753236311, 0.6517512705387358], 
reward next is 0.2843, 
noisyNet noise sample is [array([-2.0265644], dtype=float32), 0.08795959]. 
=============================================
[2019-03-23 17:24:51,517] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.9446811e-06 1.4112348e-08 9.9999809e-01 3.5333900e-09 4.5717244e-10], sum to 1.0000
[2019-03-23 17:24:51,524] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3358
[2019-03-23 17:24:51,535] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.6, 69.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 215294.4514008224, 215294.4514008227, 89394.93329809695], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5689200.0000, 
sim time next is 5689800.0000, 
raw observation next is [14.4, 69.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 214653.8340687323, 214653.8340687323, 88990.13493526833], 
processed observation next is [0.0, 0.8695652173913043, 0.29090909090909095, 0.69, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.0795014200254564, 0.0795014200254564, 0.21704910959821544], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8800279], dtype=float32), -0.5547432]. 
=============================================
[2019-03-23 17:25:01,828] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.8098733e-04 1.1975334e-09 9.9971896e-01 1.3493332e-09 3.8806652e-10], sum to 1.0000
[2019-03-23 17:25:01,835] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7019
[2019-03-23 17:25:01,838] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.66666666666667, 50.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3094275010668978, 6.911199999999999, 6.9112, 77.32846344354104, 357946.9600855766, 357946.9600855769, 146690.4301877692], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5859600.0000, 
sim time next is 5860200.0000, 
raw observation next is [23.48333333333333, 50.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3076516893055976, 6.911199999999999, 6.9112, 77.32846344354104, 356024.5872206087, 356024.587220609, 146356.9016367789], 
processed observation next is [1.0, 0.8260869565217391, 0.7037878787878786, 0.505, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.010930984722282315, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13186095822985508, 0.1318609582298552, 0.35696805277263144], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.8647182], dtype=float32), -0.5265205]. 
=============================================
[2019-03-23 17:25:14,969] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 17:25:14,972] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:25:14,973] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:25:14,973] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:25:14,975] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:25:14,976] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:25:14,977] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:25:14,974] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:25:14,979] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:25:14,980] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:25:14,981] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:25:14,987] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run16
[2019-03-23 17:25:14,988] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run16
[2019-03-23 17:25:15,012] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run16
[2019-03-23 17:25:15,037] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run16
[2019-03-23 17:25:15,037] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run16
[2019-03-23 17:25:29,291] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00076279], dtype=float32), 0.0012752422]
[2019-03-23 17:25:29,293] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [29.7, 39.5, 1.0, 2.0, 0.2370515641375022, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4744683208978231, 6.9112, 6.9112, 95.55338769695034, 539905.2893500756, 539905.2893500756, 176092.1464533044]
[2019-03-23 17:25:29,295] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:25:29,298] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.4801054e-04 2.2479697e-10 9.9985194e-01 6.2967964e-11 7.3646644e-11], sampled 0.9354886213526181
[2019-03-23 17:25:32,430] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00076279], dtype=float32), 0.0012752422]
[2019-03-23 17:25:32,432] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.71666666666667, 80.66666666666667, 1.0, 2.0, 0.2216632624308171, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4459294991813155, 6.9112, 6.9112, 95.55338769695034, 505664.1311997333, 505664.1311997333, 174578.5278137239]
[2019-03-23 17:25:32,435] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:25:32,436] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.0283934e-04 2.2636022e-10 9.9979717e-01 5.9601324e-11 7.7966127e-11], sampled 0.12332065325245833
[2019-03-23 17:25:34,874] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00076279], dtype=float32), 0.0012752422]
[2019-03-23 17:25:34,876] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 100.0, 1.0, 2.0, 0.2449069994636626, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4949464539136128, 6.9112, 6.9112, 77.32846344354104, 558728.3080988756, 558728.3080988756, 176973.9325948122]
[2019-03-23 17:25:34,877] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:25:34,879] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.9173601e-04 1.9362310e-10 9.9980825e-01 5.1543065e-11 6.8429359e-11], sampled 0.3384639533753052
[2019-03-23 17:25:51,841] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00076279], dtype=float32), 0.0012752422]
[2019-03-23 17:25:51,841] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.85874560666667, 50.55960892666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3802832607818956, 6.911199999999999, 6.9112, 95.55338769695034, 436722.2142338721, 436722.2142338724, 162607.1627104058]
[2019-03-23 17:25:51,842] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:25:51,845] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.3991097e-05 8.8135105e-10 9.9992597e-01 3.0478317e-10 2.0683248e-10], sampled 0.10223121599647655
[2019-03-23 17:26:17,209] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00076279], dtype=float32), 0.0012752422]
[2019-03-23 17:26:17,210] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.0, 82.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 297944.0516042239, 297944.0516042242, 123895.6062850854]
[2019-03-23 17:26:17,211] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:26:17,213] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.1735613e-05 9.3015862e-09 9.9993825e-01 4.1019610e-09 1.6517184e-09], sampled 0.19930236181755345
[2019-03-23 17:26:21,447] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00076279], dtype=float32), 0.0012752422]
[2019-03-23 17:26:21,448] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.88333333333333, 90.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3048320932533275, 6.911200000000001, 6.9112, 95.55338769695034, 354021.1931612164, 354021.1931612161, 149235.4539264445]
[2019-03-23 17:26:21,448] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:26:21,450] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.7351590e-05 1.8113837e-09 9.9995267e-01 6.9977996e-10 3.3717124e-10], sampled 0.9804627066578507
[2019-03-23 17:26:33,366] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00076279], dtype=float32), 0.0012752422]
[2019-03-23 17:26:33,368] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.4, 50.66666666666666, 1.0, 2.0, 0.3369567403455078, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6563662872989905, 6.911200000000001, 6.9112, 95.55338769695034, 755331.4853557824, 755331.4853557821, 192633.0504228243]
[2019-03-23 17:26:33,368] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:26:33,371] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.9804907e-04 1.0066155e-10 9.9970192e-01 2.3971682e-11 4.2036638e-11], sampled 0.5264889103561189
[2019-03-23 17:26:53,771] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2759.9414 2123974200.7649 756.0000
[2019-03-23 17:26:53,869] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3361.4802 2097858120.8947 180.0000
[2019-03-23 17:26:54,126] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3517.3468 2103984092.6813 181.0000
[2019-03-23 17:26:54,212] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3118.1655 2108895014.8406 368.0000
[2019-03-23 17:26:54,236] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3615.8005 2175212918.2849 245.0000
[2019-03-23 17:26:55,250] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 375000, evaluation results [375000.0, 3615.800544827869, 2175212918.2849145, 245.0, 3361.480187522034, 2097858120.8946712, 180.0, 3517.3467935757753, 2103984092.6812804, 181.0, 2759.9414334483563, 2123974200.7649112, 756.0, 3118.1655449252953, 2108895014.840607, 368.0]
[2019-03-23 17:27:02,582] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.7962473e-05 1.4109415e-09 9.9997199e-01 2.2457626e-10 4.1299100e-11], sum to 1.0000
[2019-03-23 17:27:02,592] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1025
[2019-03-23 17:27:02,598] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.46666666666667, 95.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3590904774008946, 6.9112, 6.9112, 77.32846344354104, 412637.40635172, 412637.40635172, 155067.296335735], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6237600.0000, 
sim time next is 6238200.0000, 
raw observation next is [18.38333333333333, 95.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3585782732752134, 6.9112, 6.9112, 77.32846344354104, 412109.5631085448, 412109.5631085448, 154947.2508868106], 
processed observation next is [0.0, 0.17391304347826086, 0.47196969696969676, 0.955, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.08368324753601918, 0.0, 0.0, 0.5084288129206541, 0.15263317152168326, 0.15263317152168326, 0.3779201241141722], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.4300173], dtype=float32), -1.6530998]. 
=============================================
[2019-03-23 17:27:03,226] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.1773246e-03 1.2233571e-10 9.9482262e-01 4.5142518e-11 3.8577203e-10], sum to 1.0000
[2019-03-23 17:27:03,234] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9883
[2019-03-23 17:27:03,237] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.8, 55.0, 1.0, 2.0, 0.2763746276328612, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5595052904151223, 6.9112, 6.9112, 77.32846344354104, 625262.4335843778, 625262.4335843778, 188745.8435112847], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6280800.0000, 
sim time next is 6281400.0000, 
raw observation next is [29.9, 55.0, 1.0, 2.0, 0.2781068200740844, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5628965596226213, 6.911199999999999, 6.9112, 77.32846344354104, 628714.3212805975, 628714.3212805978, 189393.5943681777], 
processed observation next is [0.0, 0.6956521739130435, 0.9954545454545454, 0.55, 1.0, 1.0, 0.09763352509260546, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3755665137466019, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2328571560298509, 0.23285715602985105, 0.4619355960199456], 
reward next is 0.5381, 
noisyNet noise sample is [array([-0.19622366], dtype=float32), -0.822707]. 
=============================================
[2019-03-23 17:27:03,846] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.5681264e-01 2.5800246e-11 4.4318736e-01 9.2202071e-13 1.5938856e-10], sum to 1.0000
[2019-03-23 17:27:03,856] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4943
[2019-03-23 17:27:03,865] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 607896.2220328451 W.
[2019-03-23 17:27:03,870] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.35, 61.16666666666666, 1.0, 2.0, 0.2682198583285373, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5432120348362276, 6.911199999999999, 6.9112, 77.32846344354104, 607896.2220328451, 607896.2220328454, 186115.6468093845], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6268200.0000, 
sim time next is 6268800.0000, 
raw observation next is [27.9, 65.33333333333334, 1.0, 2.0, 0.275007735164381, 1.0, 1.0, 0.275007735164381, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 619893.617557864, 619893.6175578644, 187340.0161752177], 
processed observation next is [0.0, 0.5652173913043478, 0.9045454545454544, 0.6533333333333334, 1.0, 1.0, 0.09375966895547622, 1.0, 0.5, 0.09375966895547622, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22959022872513485, 0.22959022872513496, 0.4569268687200432], 
reward next is 0.5431, 
noisyNet noise sample is [array([0.69449985], dtype=float32), -0.6986927]. 
=============================================
[2019-03-23 17:27:07,217] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.8621342e-01 2.4830439e-14 5.1378667e-01 1.0691010e-15 2.3884860e-13], sum to 1.0000
[2019-03-23 17:27:07,225] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7830
[2019-03-23 17:27:07,228] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.3, 61.0, 1.0, 2.0, 0.2756933605004567, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5583409579023938, 6.911199999999999, 6.9112, 77.32846344354104, 624802.3237914463, 624802.3237914465, 188092.5552561387], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6366600.0000, 
sim time next is 6367200.0000, 
raw observation next is [28.3, 61.0, 1.0, 2.0, 0.2757669454284462, 0.0, 2.0, 0.0, 1.0, 2.0, 0.558489964845545, 6.9112, 6.9112, 77.32846344354104, 624969.0770937268, 624969.0770937268, 188112.145388599], 
processed observation next is [0.0, 0.6956521739130435, 0.9227272727272727, 0.61, 1.0, 1.0, 0.09470868178555775, 0.0, 1.0, -0.25, 1.0, 1.0, 0.36927137835077867, 0.0, 0.0, 0.5084288129206541, 0.23147002855323215, 0.23147002855323215, 0.4588101107039], 
reward next is 0.5412, 
noisyNet noise sample is [array([-0.16776162], dtype=float32), 1.2959098]. 
=============================================
[2019-03-23 17:27:07,339] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.9085380e-02 5.7646840e-14 9.4091469e-01 8.3235942e-14 1.4257175e-13], sum to 1.0000
[2019-03-23 17:27:07,348] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4233
[2019-03-23 17:27:07,354] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.73333333333333, 72.66666666666666, 1.0, 2.0, 0.263222315147132, 0.0, 2.0, 0.0, 1.0, 2.0, 0.533193584020208, 6.911199999999999, 6.9112, 77.32846344354104, 598396.6011306255, 598396.6011306257, 183781.3565399564], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6345600.0000, 
sim time next is 6346200.0000, 
raw observation next is [25.91666666666667, 71.83333333333334, 1.0, 2.0, 0.2642728529402052, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5353313935694486, 6.9112, 6.9112, 77.32846344354104, 600630.2522531241, 600630.2522531241, 184152.3996502549], 
processed observation next is [0.0, 0.43478260869565216, 0.8143939393939396, 0.7183333333333334, 1.0, 1.0, 0.08034106617525648, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3361877050992123, 0.0, 0.0, 0.5084288129206541, 0.22245564898263856, 0.22245564898263856, 0.4491521942689144], 
reward next is 0.5508, 
noisyNet noise sample is [array([1.0905323], dtype=float32), 0.08887228]. 
=============================================
[2019-03-23 17:27:12,373] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.9455903e-01 3.8188094e-12 7.0544088e-01 3.2885139e-14 2.8056862e-12], sum to 1.0000
[2019-03-23 17:27:12,380] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1865
[2019-03-23 17:27:12,384] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.0, 73.66666666666667, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3013349560779866, 6.911199999999999, 6.9112, 77.3421103, 520289.3475772595, 520289.3475772598, 193397.9476058994], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6455400.0000, 
sim time next is 6456000.0000, 
raw observation next is [20.0, 72.33333333333334, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6817988743000608, 6.9112, 6.9112, 77.32846344354104, 393522.5558924028, 393522.5558924028, 122989.7119260735], 
processed observation next is [1.0, 0.7391304347826086, 0.5454545454545454, 0.7233333333333334, 0.0, 0.5, -0.25, 0.0, 0.5, -0.25, 1.0, 1.0, 0.5454269632858012, 0.0, 0.0, 0.5084288129206541, 0.14574909477496398, 0.14574909477496398, 0.29997490713676467], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7803952], dtype=float32), 2.2589912]. 
=============================================
[2019-03-23 17:27:12,408] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[50.77087 ]
 [53.406666]
 [52.711517]
 [53.75608 ]
 [53.264866]], R is [[50.50733948]
 [50.00226593]
 [49.50224304]
 [49.47473907]
 [49.52574539]].
[2019-03-23 17:27:12,699] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.6534165e-01 9.9155675e-12 4.3465841e-01 3.5305715e-12 4.3390058e-10], sum to 1.0000
[2019-03-23 17:27:12,708] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6844
[2019-03-23 17:27:12,712] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.06666666666667, 88.16666666666667, 1.0, 2.0, 0.8220041587011508, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 938346.4317953681, 938346.4317953681, 185825.1459671631], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6425400.0000, 
sim time next is 6426000.0000, 
raw observation next is [21.6, 91.0, 1.0, 2.0, 0.4003140428394508, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8078751946348862, 6.911199999999999, 6.9112, 77.32846344354104, 913902.5402597261, 913902.5402597263, 222022.469930682], 
processed observation next is [1.0, 0.391304347826087, 0.6181818181818183, 0.91, 1.0, 1.0, 0.2503925535493135, 0.0, 1.0, -0.25, 1.0, 0.5, 0.7255359923355519, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3384824223184171, 0.3384824223184172, 0.5415182193431268], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7504962], dtype=float32), -1.0723543]. 
=============================================
[2019-03-23 17:27:12,726] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[54.27182 ]
 [55.33987 ]
 [53.546448]
 [51.223724]
 [54.5432  ]], R is [[54.47206879]
 [54.47411728]
 [54.36720276]
 [53.8235321 ]
 [53.80384064]].
[2019-03-23 17:27:16,569] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.2827877e-06 3.8555253e-10 9.9999070e-01 6.7494593e-11 4.8159376e-10], sum to 1.0000
[2019-03-23 17:27:16,581] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9951
[2019-03-23 17:27:16,586] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [12.9, 89.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 201645.4057058938, 201645.4057058941, 87595.36070171901], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6493200.0000, 
sim time next is 6493800.0000, 
raw observation next is [12.8, 89.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 200153.4940718499, 200153.4940718499, 87225.5227265244], 
processed observation next is [1.0, 0.13043478260869565, 0.21818181818181823, 0.895, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.07413092373031478, 0.07413092373031478, 0.21274517738176685], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1503476], dtype=float32), 0.6881486]. 
=============================================
[2019-03-23 17:27:18,242] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.8928828e-05 3.1230303e-12 9.9991107e-01 2.0066464e-12 1.7992506e-12], sum to 1.0000
[2019-03-23 17:27:18,251] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3071
[2019-03-23 17:27:18,257] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.1, 88.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3638867605147999, 6.9112, 6.9112, 77.32846344354104, 418395.6395305334, 418395.6395305334, 155446.4331851042], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6679800.0000, 
sim time next is 6680400.0000, 
raw observation next is [19.0, 89.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3617981479525976, 6.9112, 6.9112, 77.32846344354104, 416086.551290492, 416086.551290492, 155098.4359994405], 
processed observation next is [1.0, 0.30434782608695654, 0.5, 0.89, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.08828306850371091, 0.0, 0.0, 0.5084288129206541, 0.15410613010758964, 0.15410613010758964, 0.3782888682913183], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5385036], dtype=float32), -1.474367]. 
=============================================
[2019-03-23 17:27:19,054] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.6227145e-06 1.6720325e-08 9.9999833e-01 1.1855598e-09 1.0741348e-09], sum to 1.0000
[2019-03-23 17:27:19,067] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8231
[2019-03-23 17:27:19,071] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.03333333333333, 55.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 288391.3988137332, 288391.3988137335, 109592.5296518998], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6549600.0000, 
sim time next is 6550200.0000, 
raw observation next is [18.85, 56.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 285173.4492736848, 285173.4492736851, 108654.4138157766], 
processed observation next is [1.0, 0.8260869565217391, 0.4931818181818182, 0.56, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10561979602729067, 0.10561979602729078, 0.26501076540433316], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2511443], dtype=float32), 0.83450997]. 
=============================================
[2019-03-23 17:27:22,225] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.1245031e-03 8.2976031e-12 9.9587554e-01 3.4244034e-14 9.0945715e-12], sum to 1.0000
[2019-03-23 17:27:22,230] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8581
[2019-03-23 17:27:22,235] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.2, 66.0, 1.0, 2.0, 0.3854953211909868, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7567013759409915, 6.9112, 6.9112, 77.32846344354104, 868862.4218855026, 868862.4218855026, 203952.4971450072], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6625800.0000, 
sim time next is 6626400.0000, 
raw observation next is [22.2, 66.0, 1.0, 2.0, 0.3934568886606544, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7724362820587711, 6.911200000000001, 6.9112, 77.32846344354104, 886903.5721799568, 886903.5721799565, 206506.7189462053], 
processed observation next is [1.0, 0.6956521739130435, 0.6454545454545454, 0.66, 1.0, 1.0, 0.241821110825818, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6749089743696731, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.32848280451109513, 0.328482804511095, 0.5036749242590374], 
reward next is 0.4963, 
noisyNet noise sample is [array([0.7637774], dtype=float32), 0.80053866]. 
=============================================
[2019-03-23 17:27:22,875] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.9307017e-06 7.9990820e-11 9.9999809e-01 1.7170768e-10 1.8228358e-11], sum to 1.0000
[2019-03-23 17:27:22,881] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1926
[2019-03-23 17:27:22,883] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.8, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3379802691504749, 6.9112, 6.9112, 77.32846344354104, 389632.5390544955, 389632.5390544955, 151267.3169764458], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6650400.0000, 
sim time next is 6651000.0000, 
raw observation next is [18.8, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3378444614192031, 6.9112, 6.9112, 77.32846344354104, 389475.6455335019, 389475.6455335019, 151251.4090651696], 
processed observation next is [1.0, 1.0, 0.49090909090909096, 0.87, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.054063516313147306, 0.0, 0.0, 0.5084288129206541, 0.14425023908648218, 0.14425023908648218, 0.36890587576870637], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4070199], dtype=float32), -0.5790859]. 
=============================================
[2019-03-23 17:27:22,904] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[12.185503]
 [12.282937]
 [12.273482]
 [12.408674]
 [12.453607]], R is [[12.03941727]
 [11.91902351]
 [11.7998333 ]
 [11.68183517]
 [11.56501675]].
[2019-03-23 17:27:24,410] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.1112374e-06 1.2040027e-09 9.9999487e-01 2.1703662e-10 5.0619536e-11], sum to 1.0000
[2019-03-23 17:27:24,411] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7269
[2019-03-23 17:27:24,417] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.46666666666667, 91.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3505406634497166, 6.911199999999999, 6.9112, 77.32846344354104, 403782.3674763283, 403782.3674763286, 153094.584986396], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6668400.0000, 
sim time next is 6669000.0000, 
raw observation next is [18.55, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3495568882433341, 6.9112, 6.9112, 77.32846344354104, 402721.3609399245, 402721.3609399245, 152906.0953199604], 
processed observation next is [1.0, 0.17391304347826086, 0.47954545454545455, 0.9, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.07079555463333442, 0.0, 0.0, 0.5084288129206541, 0.14915605960737943, 0.14915605960737943, 0.37294169590234244], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.89798516], dtype=float32), 2.312657]. 
=============================================
[2019-03-23 17:27:24,426] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[8.620318]
 [8.765705]
 [8.599652]
 [8.749119]
 [8.935964]], R is [[8.41948891]
 [8.33529377]
 [8.25194073]
 [8.1694212 ]
 [8.08772659]].
[2019-03-23 17:27:24,990] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.7900284e-07 3.3739924e-11 9.9999964e-01 3.7554031e-12 5.3299457e-12], sum to 1.0000
[2019-03-23 17:27:24,996] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8337
[2019-03-23 17:27:25,001] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3409864112971658, 6.9112, 6.9112, 77.32846344354104, 392668.9668405033, 392668.9668405033, 152036.4495728357], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6663600.0000, 
sim time next is 6664200.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3677058288716208, 6.911200000000001, 6.9112, 77.32846344354104, 423437.2769897092, 423437.2769897089, 155329.3586719081], 
processed observation next is [1.0, 0.13043478260869565, 0.4681818181818182, 0.93, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.096722612673744, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1568286211072997, 0.1568286211072996, 0.37885209432172706], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.48143977], dtype=float32), 1.3434787]. 
=============================================
[2019-03-23 17:27:26,133] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.5332417e-05 8.7573587e-10 9.9995470e-01 1.4437646e-09 2.3334468e-10], sum to 1.0000
[2019-03-23 17:27:26,142] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3897
[2019-03-23 17:27:26,149] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.3, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3251144556678594, 6.911200000000001, 6.9112, 77.32846344354104, 375081.2150677823, 375081.215067782, 149470.5226375978], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6674400.0000, 
sim time next is 6675000.0000, 
raw observation next is [18.48333333333333, 89.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3347828648629927, 6.9112, 6.9112, 77.32846344354104, 386060.2699580935, 386060.2699580935, 150776.5003369251], 
processed observation next is [1.0, 0.2608695652173913, 0.4765151515151514, 0.895, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.04968980694713243, 0.0, 0.0, 0.5084288129206541, 0.14298528516966424, 0.14298528516966424, 0.3677475617973783], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.15289108], dtype=float32), -0.124433696]. 
=============================================
[2019-03-23 17:27:26,164] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[18.857386]
 [19.078009]
 [19.289843]
 [19.287153]
 [19.554785]], R is [[18.6775341 ]
 [18.4907589 ]
 [18.30585098]
 [18.1227932 ]
 [17.94156456]].
[2019-03-23 17:27:27,718] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0094734e-05 1.6751961e-10 9.9998987e-01 1.2232339e-10 7.3196178e-11], sum to 1.0000
[2019-03-23 17:27:27,726] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6005
[2019-03-23 17:27:27,736] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.2162649852468792, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4205999647461958, 6.911199999999999, 6.9112, 77.32846344354104, 484184.7180908035, 484184.7180908038, 160875.4751825745], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6700200.0000, 
sim time next is 6700800.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.2619889612456676, 0.0, 2.0, 0.0, 1.0, 2.0, 0.509795402949154, 6.9112, 6.9112, 77.32846344354104, 586833.6157485014, 586833.6157485014, 169619.345734856], 
processed observation next is [1.0, 0.5652173913043478, 0.4681818181818182, 0.93, 1.0, 1.0, 0.07748620155708451, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2997077184987915, 0.0, 0.0, 0.5084288129206541, 0.21734578361055606, 0.21734578361055606, 0.4137057213045268], 
reward next is 0.5863, 
noisyNet noise sample is [array([1.2948327], dtype=float32), -1.1524378]. 
=============================================
[2019-03-23 17:27:35,302] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.6887675e-05 2.7544428e-10 9.9994314e-01 2.2096842e-10 1.4787092e-10], sum to 1.0000
[2019-03-23 17:27:35,309] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7910
[2019-03-23 17:27:35,314] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.2, 96.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3173450398945986, 6.9112, 6.9112, 77.32846344354104, 366943.0743788383, 366943.0743788383, 147745.8630305054], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6847800.0000, 
sim time next is 6848400.0000, 
raw observation next is [17.2, 96.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3169277374734328, 6.9112, 6.9112, 77.32846344354104, 366463.1238482465, 366463.1238482465, 147695.9133236848], 
processed observation next is [0.0, 0.2608695652173913, 0.41818181818181815, 0.96, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.02418248210490399, 0.0, 0.0, 0.5084288129206541, 0.13572708290675797, 0.13572708290675797, 0.36023393493581657], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.02200479], dtype=float32), 0.6858717]. 
=============================================
[2019-03-23 17:27:35,453] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.8656827e-04 2.0702587e-11 9.9921346e-01 1.0584153e-12 1.2124773e-12], sum to 1.0000
[2019-03-23 17:27:35,459] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8704
[2019-03-23 17:27:35,464] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.6, 56.0, 1.0, 2.0, 0.2251279604695337, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4526238664972108, 6.9112, 6.9112, 77.32846344354104, 513553.5461255644, 513553.5461255644, 170386.6297666389], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6872400.0000, 
sim time next is 6873000.0000, 
raw observation next is [26.88333333333333, 54.83333333333334, 1.0, 2.0, 0.2238700051387073, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4500864904986082, 6.9112, 6.9112, 77.32846344354104, 510680.1987366643, 510680.1987366643, 170125.2475260537], 
processed observation next is [0.0, 0.5652173913043478, 0.8583333333333332, 0.5483333333333335, 1.0, 1.0, 0.02983750642338412, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2144092721408689, 0.0, 0.0, 0.5084288129206541, 0.1891408143469127, 0.1891408143469127, 0.41493962811232604], 
reward next is 0.5851, 
noisyNet noise sample is [array([-1.0105315], dtype=float32), 0.5432502]. 
=============================================
[2019-03-23 17:27:35,495] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[36.55165 ]
 [36.80748 ]
 [37.05016 ]
 [37.182243]
 [37.225388]], R is [[36.49982071]
 [36.71924591]
 [36.93400192]
 [37.14435959]
 [37.35066605]].
[2019-03-23 17:27:41,341] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.1084596e-05 5.4992791e-14 9.9993896e-01 1.0849598e-15 9.7310560e-14], sum to 1.0000
[2019-03-23 17:27:41,348] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2739
[2019-03-23 17:27:41,353] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.36666666666667, 69.66666666666666, 1.0, 2.0, 0.2496731738470082, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5049858998512945, 6.9112, 6.9112, 77.32846344354104, 569355.1018958566, 569355.1018958566, 178613.330690468], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6982800.0000, 
sim time next is 6983400.0000, 
raw observation next is [25.18333333333334, 70.33333333333334, 1.0, 2.0, 0.2488018400547702, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5031021530604147, 6.9112, 6.9112, 77.32846344354104, 567459.0977865437, 567459.0977865437, 178237.1770514456], 
processed observation next is [0.0, 0.8260869565217391, 0.7810606060606063, 0.7033333333333335, 1.0, 1.0, 0.06100230006846275, 0.0, 1.0, -0.25, 1.0, 1.0, 0.29014593294344965, 0.0, 0.0, 0.5084288129206541, 0.2101700362172384, 0.2101700362172384, 0.43472482207669655], 
reward next is 0.5653, 
noisyNet noise sample is [array([0.7495015], dtype=float32), -1.3237936]. 
=============================================
[2019-03-23 17:27:44,585] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 17:27:44,588] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:27:44,589] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:27:44,589] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:27:44,589] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:27:44,590] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:27:44,591] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:27:44,591] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:27:44,592] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:27:44,592] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:27:44,593] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:27:44,605] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run17
[2019-03-23 17:27:44,629] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run17
[2019-03-23 17:27:44,653] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run17
[2019-03-23 17:27:44,655] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run17
[2019-03-23 17:27:44,655] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run17
[2019-03-23 17:28:11,283] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00028383], dtype=float32), 0.001735498]
[2019-03-23 17:28:11,284] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.69702689666667, 75.19519379666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 307623.3621584811, 307623.3621584808, 128539.6628004181]
[2019-03-23 17:28:11,285] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:28:11,290] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.8545120e-04 2.9669770e-11 9.9941456e-01 9.1128537e-12 5.4362143e-11], sampled 0.4481784699763435
[2019-03-23 17:28:11,885] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00028383], dtype=float32), 0.001735498]
[2019-03-23 17:28:11,887] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.92630292166667, 70.84251151166666, 1.0, 2.0, 0.3357784517408678, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6790628533871592, 6.911199999999999, 6.9112, 95.55338769695034, 757166.1110440248, 757166.1110440252, 211996.4965984519]
[2019-03-23 17:28:11,890] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:28:11,891] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.2335629e-03 6.1966172e-14 9.9876642e-01 1.1897174e-14 2.8890483e-13], sampled 0.8246316586258045
[2019-03-23 17:28:16,990] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00028383], dtype=float32), 0.001735498]
[2019-03-23 17:28:16,991] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.913160045, 45.24398038, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 301697.3794372793, 301697.3794372793, 113738.339652031]
[2019-03-23 17:28:16,992] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:28:16,994] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.5892953e-04 4.7132038e-11 9.9974102e-01 1.6145495e-11 6.2869543e-11], sampled 0.46701884454401266
[2019-03-23 17:28:18,453] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00028383], dtype=float32), 0.001735498]
[2019-03-23 17:28:18,456] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.96666666666667, 65.66666666666666, 1.0, 2.0, 0.2121613634181243, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3960587860353574, 6.9112, 6.9112, 95.55338769695034, 460774.1261958263, 460774.1261958263, 149764.2051723161]
[2019-03-23 17:28:18,457] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:28:18,460] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.0286699e-04 1.8590268e-11 9.9929714e-01 5.4154246e-12 3.8131661e-11], sampled 0.5973690187797382
[2019-03-23 17:28:28,797] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00028383], dtype=float32), 0.001735498]
[2019-03-23 17:28:28,800] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.88333333333334, 78.83333333333334, 1.0, 2.0, 0.2185152305158431, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4359679166005767, 6.911200000000001, 6.9112, 95.55338769695034, 496959.4695899013, 496959.4695899009, 171430.2384239234]
[2019-03-23 17:28:28,801] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:28:28,803] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.7320650e-04 1.7719957e-12 9.9972683e-01 4.9335855e-13 3.9439394e-12], sampled 0.7827896130050792
[2019-03-23 17:28:29,538] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00028383], dtype=float32), 0.001735498]
[2019-03-23 17:28:29,540] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.226731345, 52.97827670333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3263079893716528, 6.911200000000001, 6.9112, 95.55338769695034, 375888.4174168325, 375888.4174168321, 154689.2093076923]
[2019-03-23 17:28:29,542] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:28:29,545] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.8611846e-04 1.1983397e-11 9.9951386e-01 3.5117373e-12 2.3293447e-11], sampled 0.9995436787977576
[2019-03-23 17:28:50,422] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00028383], dtype=float32), 0.001735498]
[2019-03-23 17:28:50,422] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.31991058333333, 87.49758131333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 281441.9504392949, 281441.9504392949, 115238.2259030395]
[2019-03-23 17:28:50,423] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:28:50,425] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.0186500e-04 9.0143873e-12 9.9979812e-01 2.8219276e-12 1.3579514e-11], sampled 0.943073487277207
[2019-03-23 17:28:52,390] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00028383], dtype=float32), 0.001735498]
[2019-03-23 17:28:52,392] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.83333333333334, 75.5, 1.0, 2.0, 0.2486917629439755, 0.0, 2.0, 0.0, 1.0, 2.0, 0.503471940094748, 6.9112, 6.9112, 77.32846344354104, 566506.8998635687, 566506.8998635687, 179216.7652188589]
[2019-03-23 17:28:52,393] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:28:52,396] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.1343393e-03 3.7712658e-13 9.9886572e-01 8.1611320e-14 1.4927884e-12], sampled 0.4341521393308492
[2019-03-23 17:28:57,351] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00028383], dtype=float32), 0.001735498]
[2019-03-23 17:28:57,352] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.66666666666667, 81.33333333333334, 1.0, 2.0, 0.2227339407155318, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4391688887647261, 6.9112, 6.9112, 95.55338769695034, 503212.5539591744, 503212.5539591744, 169438.1495462534]
[2019-03-23 17:28:57,354] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:28:57,356] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.3658227e-04 8.5471663e-13 9.9926347e-01 1.9956997e-13 2.8530060e-12], sampled 0.3076784652154809
[2019-03-23 17:29:10,140] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00028383], dtype=float32), 0.001735498]
[2019-03-23 17:29:10,141] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.78283160666667, 86.67575155333334, 1.0, 2.0, 0.2121160940065268, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4039800661160841, 6.9112, 6.9112, 95.55338769695034, 467547.5010272366, 467547.5010272366, 161421.4620196378]
[2019-03-23 17:29:10,142] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:29:10,145] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.2878128e-04 8.2825012e-13 9.9917126e-01 1.8976951e-13 2.7504557e-12], sampled 0.6260292370238019
[2019-03-23 17:29:10,319] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00028383], dtype=float32), 0.001735498]
[2019-03-23 17:29:10,321] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.88328738, 95.0974234, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3595292460681679, 6.9112, 6.9112, 95.55338769695034, 414102.4583395495, 414102.4583395495, 158804.7292797831]
[2019-03-23 17:29:10,322] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:29:10,325] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.4346817e-04 3.0745222e-12 9.9945658e-01 7.9100143e-13 7.2384282e-12], sampled 0.9285841288395046
[2019-03-23 17:29:10,695] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00028383], dtype=float32), 0.001735498]
[2019-03-23 17:29:10,696] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.26571026666667, 90.27451278666668, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3067955424169415, 6.9112, 6.9112, 95.55338769695034, 356894.579319641, 356894.579319641, 125355.3633938455]
[2019-03-23 17:29:10,697] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:29:10,702] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.6522788e-04 3.7283844e-12 9.9933475e-01 9.6703927e-13 9.5486605e-12], sampled 0.2412574205483855
[2019-03-23 17:29:23,470] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3358.8352 2097568465.4890 185.0000
[2019-03-23 17:29:23,619] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3120.0028 2108855547.9878 369.0000
[2019-03-23 17:29:23,743] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3608.7083 2175086428.7248 249.0000
[2019-03-23 17:29:23,761] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2760.4946 2123788844.7861 759.0000
[2019-03-23 17:29:23,803] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3519.2033 2103828902.0883 180.0000
[2019-03-23 17:29:24,819] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 400000, evaluation results [400000.0, 3608.7083327877476, 2175086428.724804, 249.0, 3358.8351823404614, 2097568465.489023, 185.0, 3519.203267752029, 2103828902.0883107, 180.0, 2760.494598936826, 2123788844.7861302, 759.0, 3120.0027942492266, 2108855547.987826, 369.0]
[2019-03-23 17:29:29,427] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.7448061e-06 1.4584196e-12 9.9999821e-01 9.5683997e-13 6.6966203e-13], sum to 1.0000
[2019-03-23 17:29:29,437] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1153
[2019-03-23 17:29:29,442] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.8, 84.5, 1.0, 2.0, 0.2868080768648572, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5627674262215541, 6.9112, 6.9112, 77.32846344354104, 646120.925078307, 646120.925078307, 176997.4271050753], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7120200.0000, 
sim time next is 7120800.0000, 
raw observation next is [20.0, 84.0, 1.0, 2.0, 0.3010018432195656, 0.0, 2.0, 0.0, 1.0, 2.0, 0.591974951248051, 6.9112, 6.9112, 77.32846344354104, 679130.6170095204, 679130.6170095204, 180993.13274961], 
processed observation next is [1.0, 0.43478260869565216, 0.5454545454545454, 0.84, 1.0, 1.0, 0.12625230402445695, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4171070732115015, 0.0, 0.0, 0.5084288129206541, 0.2515298581516742, 0.2515298581516742, 0.44144666524295123], 
reward next is 0.5586, 
noisyNet noise sample is [array([0.5907974], dtype=float32), 1.7902414]. 
=============================================
[2019-03-23 17:29:37,169] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.2385503e-07 2.2950561e-10 9.9999952e-01 1.3261324e-10 1.4264862e-12], sum to 1.0000
[2019-03-23 17:29:37,177] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2872
[2019-03-23 17:29:37,180] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.8, 43.5, 1.0, 2.0, 0.4352996367423848, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8488847601107252, 6.9112, 6.9112, 77.32846344296178, 976907.5130068412, 976907.5130068412, 217855.3250660947], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7309800.0000, 
sim time next is 7310400.0000, 
raw observation next is [25.7, 43.66666666666667, 1.0, 2.0, 0.4341538148806323, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8459703028110952, 6.9112, 6.9112, 77.32846344353746, 973791.1351363357, 973791.1351363357, 217156.9696260366], 
processed observation next is [1.0, 0.6086956521739131, 0.8045454545454546, 0.4366666666666667, 1.0, 1.0, 0.29269226860079034, 0.0, 1.0, -0.25, 1.0, 1.0, 0.7799575754444217, 0.0, 0.0, 0.5084288129206306, 0.36066338338382803, 0.36066338338382803, 0.5296511454293575], 
reward next is 0.4703, 
noisyNet noise sample is [array([-0.46442765], dtype=float32), -0.44324818]. 
=============================================
[2019-03-23 17:29:41,405] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.8309803e-07 1.3302153e-11 9.9999940e-01 1.6372706e-10 1.2759098e-11], sum to 1.0000
[2019-03-23 17:29:41,417] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9227
[2019-03-23 17:29:41,421] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.6, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3286544820411728, 6.911200000000001, 6.9112, 77.32846344354104, 379730.2022459774, 379730.2022459771, 149328.9312102897], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7341600.0000, 
sim time next is 7342200.0000, 
raw observation next is [19.4, 78.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3270582144741025, 6.9112, 6.9112, 77.32846344354104, 378011.2810551472, 378011.2810551472, 149019.1930207718], 
processed observation next is [1.0, 1.0, 0.5181818181818181, 0.78, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.038654592105860724, 0.0, 0.0, 0.5084288129206541, 0.14000417816857302, 0.14000417816857302, 0.36346144639212635], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.3146356], dtype=float32), -0.11418158]. 
=============================================
[2019-03-23 17:29:43,759] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4559799e-07 4.4079865e-10 9.9999988e-01 2.0327261e-10 2.9162405e-11], sum to 1.0000
[2019-03-23 17:29:43,766] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7492
[2019-03-23 17:29:43,770] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.35, 84.0, 1.0, 2.0, 0.2167548756166132, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4327551855627837, 6.9112, 6.9112, 77.32846344354104, 493163.3772065846, 493163.3772065846, 166602.1252118537], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7410600.0000, 
sim time next is 7411200.0000, 
raw observation next is [21.43333333333334, 84.0, 1.0, 2.0, 0.2178766968179161, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4353634289829192, 6.9112, 6.9112, 77.32846344354104, 495909.0396405181, 495909.0396405181, 167046.6697090794], 
processed observation next is [1.0, 0.782608695652174, 0.6106060606060609, 0.84, 1.0, 1.0, 0.022345871022395117, 0.0, 1.0, -0.25, 1.0, 1.0, 0.193376327118456, 0.0, 0.0, 0.5084288129206541, 0.18367001468167335, 0.18367001468167335, 0.40743090172946195], 
reward next is 0.5926, 
noisyNet noise sample is [array([1.3951174], dtype=float32), -1.1608407]. 
=============================================
[2019-03-23 17:29:47,250] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.4708915e-04 1.1100925e-12 9.9935287e-01 2.4005706e-12 2.1631216e-11], sum to 1.0000
[2019-03-23 17:29:47,260] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4187
[2019-03-23 17:29:47,264] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.9, 60.0, 1.0, 2.0, 0.2299818540866463, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4626831313324821, 6.911199999999999, 6.9112, 77.32846344354104, 524707.3317076287, 524707.3317076289, 171623.2752003299], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7496400.0000, 
sim time next is 7497000.0000, 
raw observation next is [25.8, 59.0, 1.0, 2.0, 0.2252898718850669, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4523597408752455, 6.9112, 6.9112, 77.32846344354104, 513741.3841171229, 513741.3841171229, 169969.2430420941], 
processed observation next is [0.0, 0.782608695652174, 0.8090909090909091, 0.59, 1.0, 1.0, 0.031612339856333625, 0.0, 1.0, -0.25, 1.0, 1.0, 0.21765677267892217, 0.0, 0.0, 0.5084288129206541, 0.19027458671004552, 0.19027458671004552, 0.41455912937096123], 
reward next is 0.5854, 
noisyNet noise sample is [array([0.48779657], dtype=float32), -1.2519305]. 
=============================================
[2019-03-23 17:29:47,279] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[38.338993]
 [38.45938 ]
 [38.62489 ]
 [38.771862]
 [38.92774 ]], R is [[38.34889984]
 [38.54681778]
 [38.73887253]
 [38.92586899]
 [39.10951233]].
[2019-03-23 17:29:48,085] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.1439587e-01 6.5170382e-12 7.8560412e-01 7.6159124e-14 2.4999651e-12], sum to 1.0000
[2019-03-23 17:29:48,094] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3051
[2019-03-23 17:29:48,097] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.7, 61.0, 1.0, 2.0, 0.2617633897096201, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5302187812975737, 6.911200000000001, 6.9112, 77.32846344354104, 595276.6295750616, 595276.6295750614, 183273.0360109072], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7477800.0000, 
sim time next is 7478400.0000, 
raw observation next is [27.7, 61.0, 1.0, 2.0, 0.2615150257273782, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5297151277765908, 6.9112, 6.9112, 77.32846344354104, 594716.2598999979, 594716.2598999979, 183207.6019151688], 
processed observation next is [0.0, 0.5652173913043478, 0.8954545454545454, 0.61, 1.0, 1.0, 0.07689378215922277, 0.0, 1.0, -0.25, 1.0, 1.0, 0.32816446825227263, 0.0, 0.0, 0.5084288129206541, 0.22026528144444366, 0.22026528144444366, 0.44684780954919223], 
reward next is 0.5532, 
noisyNet noise sample is [array([0.81872], dtype=float32), 0.0045615756]. 
=============================================
[2019-03-23 17:29:50,152] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.8102333e-03 4.4872302e-14 9.9718982e-01 1.9737450e-15 2.0664579e-13], sum to 1.0000
[2019-03-23 17:29:50,162] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5021
[2019-03-23 17:29:50,168] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.9, 63.16666666666667, 1.0, 2.0, 0.2171100558479197, 0.0, 2.0, 0.0, 1.0, 2.0, 0.435048440322398, 6.911199999999999, 6.9112, 77.32846344354104, 494736.1836001844, 494736.1836001847, 167706.3642484202], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7503000.0000, 
sim time next is 7503600.0000, 
raw observation next is [24.8, 64.33333333333334, 1.0, 2.0, 0.2185533517720017, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4383032541969992, 6.9112, 6.9112, 77.32846344354104, 498175.8977763392, 498175.8977763392, 168240.5376472857], 
processed observation next is [0.0, 0.8695652173913043, 0.7636363636363637, 0.6433333333333334, 1.0, 1.0, 0.0231916897150021, 0.0, 1.0, -0.25, 1.0, 1.0, 0.19757607742428462, 0.0, 0.0, 0.5084288129206541, 0.18450959176901452, 0.18450959176901452, 0.41034277474947733], 
reward next is 0.5897, 
noisyNet noise sample is [array([0.6471831], dtype=float32), 0.053162873]. 
=============================================
[2019-03-23 17:29:51,392] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.2337547e-04 1.9306526e-15 9.9937660e-01 5.3721604e-16 1.8730495e-14], sum to 1.0000
[2019-03-23 17:29:51,400] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8416
[2019-03-23 17:29:51,409] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.86666666666667, 66.0, 1.0, 2.0, 0.2475610514679229, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5005043834491109, 6.9112, 6.9112, 77.32846344354104, 564684.9325912416, 564684.9325912416, 177829.3770448472], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7558800.0000, 
sim time next is 7559400.0000, 
raw observation next is [25.98333333333333, 65.0, 1.0, 2.0, 0.2466106295116097, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4984811406067797, 6.9112, 6.9112, 77.32846344354104, 562572.8054262019, 562572.8054262019, 177477.9913368689], 
processed observation next is [0.0, 0.4782608695652174, 0.8174242424242423, 0.65, 1.0, 1.0, 0.05826328688951211, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2835444865811139, 0.0, 0.0, 0.5084288129206541, 0.2083602983060007, 0.2083602983060007, 0.43287314960211926], 
reward next is 0.5671, 
noisyNet noise sample is [array([-0.23408389], dtype=float32), 0.88727224]. 
=============================================
[2019-03-23 17:30:06,633] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:30:06,633] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:30:06,676] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run3
[2019-03-23 17:30:08,688] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.0547407e-08 3.8810580e-11 1.0000000e+00 3.2820169e-10 8.8512843e-12], sum to 1.0000
[2019-03-23 17:30:08,700] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6544
[2019-03-23 17:30:08,706] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.9, 69.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3172004731497182, 6.911200000000001, 6.9112, 77.32846344354104, 369029.0327528053, 369029.032752805, 140499.7857158337], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7870200.0000, 
sim time next is 7870800.0000, 
raw observation next is [19.0, 69.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 330683.0092490705, 330683.0092490703, 136181.8023060975], 
processed observation next is [1.0, 0.08695652173913043, 0.5, 0.6933333333333335, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12247518861076685, 0.12247518861076678, 0.3321507373319451], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.05347759], dtype=float32), -0.21817718]. 
=============================================
[2019-03-23 17:30:10,265] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.5920888e-09 2.0307275e-13 1.0000000e+00 3.7412543e-13 2.9121789e-14], sum to 1.0000
[2019-03-23 17:30:10,280] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8434
[2019-03-23 17:30:10,283] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.73333333333333, 89.0, 1.0, 2.0, 0.3995681573665369, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7999496370108753, 6.911199999999999, 6.9112, 77.32846344354104, 910585.0963992003, 910585.0963992006, 216804.286099476], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7904400.0000, 
sim time next is 7905000.0000, 
raw observation next is [20.91666666666667, 88.0, 1.0, 2.0, 0.4099963957047232, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8214254887772537, 6.9112, 6.9112, 77.32846344354104, 934639.1698820478, 934639.1698820478, 220882.652131452], 
processed observation next is [1.0, 0.4782608695652174, 0.5871212121212124, 0.88, 1.0, 1.0, 0.26249549463090394, 0.0, 1.0, -0.25, 1.0, 1.0, 0.7448935553960769, 0.0, 0.0, 0.5084288129206541, 0.34616265551186953, 0.34616265551186953, 0.5387381759303708], 
reward next is 0.4613, 
noisyNet noise sample is [array([1.6991608], dtype=float32), -1.6979295]. 
=============================================
[2019-03-23 17:30:10,303] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[15.69005 ]
 [15.780565]
 [15.883747]
 [15.80747 ]
 [15.694495]], R is [[16.22467232]
 [16.53363419]
 [16.86239433]
 [17.20010185]
 [17.51168251]].
[2019-03-23 17:30:11,952] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:30:11,952] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:30:11,973] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:30:11,973] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:30:11,980] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run3
[2019-03-23 17:30:12,024] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run3
[2019-03-23 17:30:12,279] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:30:12,280] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:30:12,289] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run3
[2019-03-23 17:30:12,386] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:30:12,386] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:30:12,388] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run3
[2019-03-23 17:30:12,631] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:30:12,632] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:30:12,634] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run3
[2019-03-23 17:30:12,864] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:30:12,865] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:30:12,866] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run3
[2019-03-23 17:30:12,899] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:30:12,900] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:30:12,900] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:30:12,903] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:30:12,908] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run3
[2019-03-23 17:30:12,929] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run3
[2019-03-23 17:30:12,972] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:30:12,973] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:30:12,974] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run3
[2019-03-23 17:30:13,169] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:30:13,169] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:30:13,170] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run3
[2019-03-23 17:30:13,204] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:30:13,205] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:30:13,207] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run3
[2019-03-23 17:30:13,237] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:30:13,237] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:30:13,239] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run3
[2019-03-23 17:30:13,272] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:30:13,272] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:30:13,280] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run3
[2019-03-23 17:30:13,413] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:30:13,414] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:30:13,415] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run3
[2019-03-23 17:30:13,469] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:30:13,470] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:30:13,475] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run3
[2019-03-23 17:30:15,551] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 17:30:15,551] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:30:15,552] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:30:15,552] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:30:15,553] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:30:15,554] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:30:15,556] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:30:15,559] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:30:15,560] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:30:15,561] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:30:15,554] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:30:15,580] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run18
[2019-03-23 17:30:15,581] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run18
[2019-03-23 17:30:15,602] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run18
[2019-03-23 17:30:15,627] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run18
[2019-03-23 17:30:15,681] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run18
[2019-03-23 17:30:22,801] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00055704], dtype=float32), 0.002251067]
[2019-03-23 17:30:22,802] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.71666666666667, 61.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 322820.7176747235, 322820.7176747232, 115737.9274552028]
[2019-03-23 17:30:22,802] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:30:22,806] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.3454105e-06 2.1474170e-11 9.9999666e-01 1.5665594e-11 8.4585490e-12], sampled 0.6957718310211859
[2019-03-23 17:30:36,408] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00055704], dtype=float32), 0.002251067]
[2019-03-23 17:30:36,408] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.66086085666667, 97.43135445333333, 1.0, 2.0, 0.2419079971883975, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4876958445391357, 6.9112, 6.9112, 95.55338769695034, 552017.4398750939, 552017.4398750939, 179756.4937747763]
[2019-03-23 17:30:36,410] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:30:36,414] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.5972300e-06 4.7653067e-14 9.9999440e-01 2.1308276e-14 5.4061688e-14], sampled 0.03780312523862206
[2019-03-23 17:30:41,475] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00055704], dtype=float32), 0.002251067]
[2019-03-23 17:30:41,476] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [10.94674746733333, 85.56760140333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 95.55338769695034, 170436.7066487912, 170436.7066487916, 83654.26549035756]
[2019-03-23 17:30:41,478] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:30:41,482] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.46940601e-06 1.34649819e-10 9.99996543e-01 1.15968735e-10
 4.19484135e-11], sampled 0.13738214838197027
[2019-03-23 17:30:42,423] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00055704], dtype=float32), 0.002251067]
[2019-03-23 17:30:42,425] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.75545286, 78.37568316, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 290968.7878765828, 290968.7878765828, 119925.9428109282]
[2019-03-23 17:30:42,425] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:30:42,429] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.4414782e-06 9.5270684e-12 9.9999654e-01 6.3581722e-12 4.2900436e-12], sampled 0.45887133700653215
[2019-03-23 17:30:45,513] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00055704], dtype=float32), 0.002251067]
[2019-03-23 17:30:45,516] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.95960442666667, 57.58853281666667, 1.0, 2.0, 0.2106455179135528, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4190523061998713, 6.9112, 6.9112, 95.55338769695034, 478355.8845117566, 478355.8845117566, 169215.4000910733]
[2019-03-23 17:30:45,517] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:30:45,521] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.9645859e-06 3.0709446e-13 9.9999404e-01 1.5237869e-13 2.7487059e-13], sampled 0.5583794630006614
[2019-03-23 17:30:47,363] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00055704], dtype=float32), 0.002251067]
[2019-03-23 17:30:47,365] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [12.57986897666667, 83.415708775, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 198925.534619212, 198925.534619212, 90199.16649299221]
[2019-03-23 17:30:47,367] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:30:47,370] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.9864376e-06 1.1409080e-11 9.9999797e-01 8.6133071e-12 4.0694609e-12], sampled 0.738226272961218
[2019-03-23 17:31:02,843] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00055704], dtype=float32), 0.002251067]
[2019-03-23 17:31:02,844] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.9, 89.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3591507872302135, 6.911199999999999, 6.9112, 95.55338769695034, 413147.5403593411, 413147.5403593414, 159237.7042510375]
[2019-03-23 17:31:02,845] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:31:02,847] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.1717128e-06 8.1029389e-13 9.9999785e-01 4.7179719e-13 4.3783334e-13], sampled 0.459145064284192
[2019-03-23 17:31:17,769] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00055704], dtype=float32), 0.002251067]
[2019-03-23 17:31:17,770] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.76666666666667, 72.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 257012.0518079792, 257012.0518079788, 108425.6196117219]
[2019-03-23 17:31:17,771] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:31:17,775] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.6815549e-06 1.4249447e-11 9.9999738e-01 1.0453870e-11 5.5307117e-12], sampled 0.08296166650442238
[2019-03-23 17:31:29,607] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00055704], dtype=float32), 0.002251067]
[2019-03-23 17:31:29,607] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.6, 86.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 290318.6274505636, 290318.6274505632, 127777.0409151096]
[2019-03-23 17:31:29,608] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:31:29,611] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.6203788e-06 5.4305701e-12 9.9999738e-01 3.6174085e-12 2.3366127e-12], sampled 0.5274582162379317
[2019-03-23 17:31:51,664] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00055704], dtype=float32), 0.002251067]
[2019-03-23 17:31:51,666] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.36666666666667, 96.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3461537163637823, 6.911200000000001, 6.9112, 77.32846344354104, 399729.4537773718, 399729.4537773716, 151600.3387297005]
[2019-03-23 17:31:51,668] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:31:51,672] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.6311918e-06 1.4209978e-12 9.9999738e-01 8.5305694e-13 7.6397840e-13], sampled 0.7224478853053212
[2019-03-23 17:31:53,853] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3361.3356 2098067941.7008 179.0000
[2019-03-23 17:31:54,119] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2760.8412 2124022225.0073 757.0000
[2019-03-23 17:31:54,141] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3118.8146 2109022190.6825 368.0000
[2019-03-23 17:31:54,158] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3614.4476 2175239891.5742 245.0000
[2019-03-23 17:31:54,284] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3520.6461 2104033317.6637 178.0000
[2019-03-23 17:31:55,299] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 425000, evaluation results [425000.0, 3614.4475597348155, 2175239891.574205, 245.0, 3361.3355917968815, 2098067941.7008436, 179.0, 3520.646132071608, 2104033317.6637259, 178.0, 2760.8411984169843, 2124022225.007341, 757.0, 3118.8146269445274, 2109022190.6824877, 368.0]
[2019-03-23 17:31:56,428] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4123191e-07 2.3965647e-12 9.9999988e-01 1.9743029e-12 9.6261692e-13], sum to 1.0000
[2019-03-23 17:31:56,440] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3165
[2019-03-23 17:31:56,444] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 78.0, 1.0, 2.0, 0.4287891149736127, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8483939699478901, 6.9112, 6.9112, 77.32846344354104, 971353.5013658251, 971353.5013658251, 221527.1265337835], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 48600.0000, 
sim time next is 49200.0000, 
raw observation next is [21.0, 78.0, 1.0, 2.0, 0.4304628399528326, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8519805084228703, 6.911200000000001, 6.9112, 77.32846344354104, 975334.7890800295, 975334.7890800291, 222268.8481765527], 
processed observation next is [1.0, 0.5652173913043478, 0.5909090909090909, 0.78, 1.0, 1.0, 0.2880785499410407, 0.0, 1.0, -0.25, 1.0, 1.0, 0.7885435834612434, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3612351070666776, 0.36123510706667744, 0.542119141894031], 
reward next is 0.4579, 
noisyNet noise sample is [array([0.36039317], dtype=float32), -0.55946827]. 
=============================================
[2019-03-23 17:31:56,743] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.4719817e-07 1.4565087e-12 9.9999940e-01 1.4935489e-11 2.5471610e-12], sum to 1.0000
[2019-03-23 17:31:56,744] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7660
[2019-03-23 17:31:56,752] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 78.0, 1.0, 2.0, 0.3808250741250019, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7533323268553677, 6.9112, 6.9112, 77.32846344354104, 862492.8333294125, 862492.8333294125, 205302.9486434234], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 50400.0000, 
sim time next is 51000.0000, 
raw observation next is [20.83333333333333, 80.66666666666667, 1.0, 2.0, 0.4233997356794023, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8391317859752281, 6.911199999999999, 6.9112, 77.32846344354104, 960068.7970693053, 960068.7970693056, 220358.6941313942], 
processed observation next is [1.0, 0.6086956521739131, 0.5833333333333331, 0.8066666666666668, 1.0, 1.0, 0.27924966959925285, 0.0, 1.0, -0.25, 1.0, 1.0, 0.7701882656788972, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.35558103595159457, 0.3555810359515946, 0.5374602295887664], 
reward next is 0.4625, 
noisyNet noise sample is [array([1.9506195], dtype=float32), 0.1287251]. 
=============================================
[2019-03-23 17:31:56,772] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[15.690964]
 [15.456499]
 [15.008111]
 [14.457443]
 [13.707961]], R is [[16.21990967]
 [16.5569725 ]
 [16.85090065]
 [17.14027214]
 [17.42856026]].
[2019-03-23 17:32:01,149] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.4568649e-07 4.0943117e-12 9.9999964e-01 5.1082884e-12 6.1070458e-13], sum to 1.0000
[2019-03-23 17:32:01,154] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9603
[2019-03-23 17:32:01,158] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 41.0, 1.0, 2.0, 0.3854872468413951, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7196202388425663, 6.911199999999999, 6.9112, 77.32846344354104, 837605.0741915789, 837605.0741915791, 185130.0253944741], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 140400.0000, 
sim time next is 141000.0000, 
raw observation next is [23.0, 40.50000000000001, 1.0, 2.0, 0.3482942341120038, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6501890321738504, 6.9112, 6.9112, 77.32846344354104, 756727.3839278356, 756727.3839278356, 174149.3975537617], 
processed observation next is [1.0, 0.6521739130434783, 0.6818181818181818, 0.4050000000000001, 1.0, 1.0, 0.1853677926400047, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5002700459626435, 0.0, 0.0, 0.5084288129206541, 0.28026940145475393, 0.28026940145475393, 0.42475462817990656], 
reward next is 0.5752, 
noisyNet noise sample is [array([-0.09764901], dtype=float32), -0.043187853]. 
=============================================
[2019-03-23 17:32:01,171] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[18.204746]
 [19.054544]
 [19.155859]
 [19.258114]
 [19.859858]], R is [[17.79606628]
 [18.16656876]
 [18.53244972]
 [18.9052124 ]
 [19.29849243]].
[2019-03-23 17:32:01,493] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.8423151e-07 1.1907829e-09 9.9999976e-01 8.0234408e-10 2.7866050e-11], sum to 1.0000
[2019-03-23 17:32:01,501] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4076
[2019-03-23 17:32:01,505] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [15.33333333333333, 75.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 243015.8335513164, 243015.8335513164, 97606.68662466311], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 168000.0000, 
sim time next is 168600.0000, 
raw observation next is [15.16666666666667, 76.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 241004.3765676401, 241004.3765676398, 97038.89701679433], 
processed observation next is [1.0, 0.9565217391304348, 0.3257575757575759, 0.7616666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08926088021023708, 0.08926088021023695, 0.23668023662632764], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0009416], dtype=float32), 1.1855372]. 
=============================================
[2019-03-23 17:32:09,539] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.4296190e-07 3.6648260e-09 9.9999928e-01 2.4112528e-09 8.6662205e-11], sum to 1.0000
[2019-03-23 17:32:09,548] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7777
[2019-03-23 17:32:09,553] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 47.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 276297.5152451047, 276297.5152451047, 109946.0422054515], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 307200.0000, 
sim time next is 307800.0000, 
raw observation next is [21.0, 46.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 276485.0480412148, 276485.0480412148, 109048.5003337925], 
processed observation next is [0.0, 0.5652173913043478, 0.5909090909090909, 0.46, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.10240186964489438, 0.10240186964489438, 0.26597195203364027], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.31192344], dtype=float32), -0.37044498]. 
=============================================
[2019-03-23 17:32:10,283] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.2382136e-07 1.3919088e-08 9.9999928e-01 7.6373956e-09 2.6690988e-10], sum to 1.0000
[2019-03-23 17:32:10,290] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4659
[2019-03-23 17:32:10,296] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 229890.2757719168, 229890.275771917, 97363.40239287028], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 521400.0000, 
sim time next is 522000.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 229957.7776970225, 229957.7776970228, 97375.24995670297], 
processed observation next is [1.0, 0.043478260869565216, 0.2727272727272727, 0.94, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08516954729519352, 0.08516954729519363, 0.23750060965049505], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.64904153], dtype=float32), -0.20481835]. 
=============================================
[2019-03-23 17:32:10,313] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[0.788572  ]
 [0.6648136 ]
 [0.6511441 ]
 [0.48409384]
 [0.39982218]], R is [[0.70380342]
 [0.69676536]
 [0.6897977 ]
 [0.68289971]
 [0.67607075]].
[2019-03-23 17:32:23,547] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.9482725e-06 5.6939512e-11 9.9999201e-01 1.5312798e-10 3.5473565e-11], sum to 1.0000
[2019-03-23 17:32:23,552] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.8730149e-04 1.9445749e-10 9.9961275e-01 1.2427417e-10 3.7645806e-10], sum to 1.0000
[2019-03-23 17:32:23,553] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8027
[2019-03-23 17:32:23,559] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.66666666666667, 65.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.34578522794313, 6.9112, 6.9112, 77.32846344354104, 398580.7992647154, 398580.7992647154, 152252.2650625579], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 580800.0000, 
sim time next is 581400.0000, 
raw observation next is [21.5, 66.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3394716473657152, 6.9112, 6.9112, 77.32846344354104, 391445.5950382671, 391445.5950382671, 151355.5242230043], 
processed observation next is [1.0, 0.7391304347826086, 0.6136363636363636, 0.665, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.05638806766530748, 0.0, 0.0, 0.5084288129206541, 0.144979850014173, 0.144979850014173, 0.36915981517805924], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.0789921], dtype=float32), 1.0231678]. 
=============================================
[2019-03-23 17:32:23,562] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7720
[2019-03-23 17:32:23,568] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.0, 88.0, 1.0, 2.0, 0.210247925838928, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3924868172632799, 6.911200000000001, 6.9112, 77.32846344354104, 456657.8230064646, 456657.8230064643, 142812.6540295653], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 550200.0000, 
sim time next is 550800.0000, 
raw observation next is [16.0, 88.0, 1.0, 2.0, 0.2140539568599151, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3995918433693494, 6.9112, 6.9112, 77.32846344354104, 464928.463002962, 464928.463002962, 143620.5384606733], 
processed observation next is [1.0, 0.391304347826087, 0.36363636363636365, 0.88, 1.0, 1.0, 0.017567446074893862, 0.0, 1.0, -0.25, 1.0, 1.0, 0.14227406195621342, 0.0, 0.0, 0.5084288129206541, 0.17219572703813407, 0.17219572703813407, 0.35029399624554464], 
reward next is 0.6497, 
noisyNet noise sample is [array([0.96545637], dtype=float32), 1.3324369]. 
=============================================
[2019-03-23 17:32:26,190] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0514584e-04 7.2566803e-10 9.9989486e-01 7.6664830e-10 4.4820156e-10], sum to 1.0000
[2019-03-23 17:32:26,198] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7226
[2019-03-23 17:32:26,204] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.33333333333334, 92.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 309084.6684161572, 309084.6684161575, 134708.6436689026], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 630600.0000, 
sim time next is 631200.0000, 
raw observation next is [16.66666666666667, 90.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 309075.0370585172, 309075.0370585169, 137747.4042115539], 
processed observation next is [1.0, 0.30434782608695654, 0.39393939393939414, 0.9033333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11447223594759898, 0.11447223594759884, 0.3359692785647656], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.07609899], dtype=float32), 0.627438]. 
=============================================
[2019-03-23 17:32:42,010] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.2769451e-03 1.3667658e-12 9.9072307e-01 8.7394583e-14 1.1858241e-11], sum to 1.0000
[2019-03-23 17:32:42,017] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9408
[2019-03-23 17:32:42,020] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.5, 67.16666666666667, 1.0, 2.0, 0.242869589312382, 0.0, 2.0, 0.0, 1.0, 2.0, 0.490774420515346, 6.9112, 6.9112, 77.32846344354104, 554101.0813451242, 554101.0813451242, 176444.8895002403], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 907800.0000, 
sim time next is 908400.0000, 
raw observation next is [25.0, 69.33333333333334, 1.0, 2.0, 0.2411302239132554, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4869853812531714, 6.911200000000001, 6.9112, 77.32846344354104, 550221.4516548136, 550221.4516548134, 175734.8425734369], 
processed observation next is [0.0, 0.5217391304347826, 0.7727272727272727, 0.6933333333333335, 1.0, 1.0, 0.05141277989156923, 0.0, 1.0, -0.25, 1.0, 1.0, 0.26712197321881637, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20378572283511615, 0.20378572283511606, 0.4286215672522851], 
reward next is 0.5714, 
noisyNet noise sample is [array([2.2484555], dtype=float32), 0.62277275]. 
=============================================
[2019-03-23 17:32:42,341] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.3174196e-03 1.2156359e-12 9.9568260e-01 1.9089268e-14 3.1245507e-12], sum to 1.0000
[2019-03-23 17:32:42,347] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8762
[2019-03-23 17:32:42,356] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.83333333333333, 74.66666666666667, 1.0, 2.0, 0.2325149111155399, 0.0, 2.0, 0.0, 1.0, 2.0, 0.468656904700814, 6.911199999999999, 6.9112, 77.32846344354104, 530623.6334780683, 530623.6334780685, 172907.6414957088], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 913800.0000, 
sim time next is 914400.0000, 
raw observation next is [24.0, 74.0, 1.0, 2.0, 0.233506432465318, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4708325420207919, 6.9112, 6.9112, 77.32846344354104, 532894.9632400925, 532894.9632400925, 173283.8058017116], 
processed observation next is [0.0, 0.6086956521739131, 0.7272727272727273, 0.74, 1.0, 1.0, 0.04188304058164748, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2440464886011313, 0.0, 0.0, 0.5084288129206541, 0.19736850490373797, 0.19736850490373797, 0.42264342878466243], 
reward next is 0.5774, 
noisyNet noise sample is [array([-1.4772191], dtype=float32), -0.52819455]. 
=============================================
[2019-03-23 17:32:44,815] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 17:32:44,817] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:32:44,818] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:32:44,819] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:32:44,819] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:32:44,820] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:32:44,821] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:32:44,821] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:32:44,823] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:32:44,823] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:32:44,823] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:32:44,835] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run19
[2019-03-23 17:32:44,861] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run19
[2019-03-23 17:32:44,886] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run19
[2019-03-23 17:32:44,887] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run19
[2019-03-23 17:32:44,934] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run19
[2019-03-23 17:33:07,818] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00081253], dtype=float32), 0.002450229]
[2019-03-23 17:33:07,819] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.61370997, 48.28760098, 1.0, 2.0, 0.2607127023168014, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5227538281080206, 6.911200000000001, 6.9112, 95.55338769695034, 594224.9400868309, 594224.9400868305, 181946.304464834]
[2019-03-23 17:33:07,821] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:33:07,823] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.0890697e-04 1.5010690e-13 9.9979109e-01 4.0429475e-14 6.0605335e-13], sampled 0.38380310723692634
[2019-03-23 17:33:15,397] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00081253], dtype=float32), 0.002450229]
[2019-03-23 17:33:15,399] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.2, 58.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 95.55338769695034, 223387.0524834158, 223387.0524834161, 94376.24726589731]
[2019-03-23 17:33:15,401] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:33:15,404] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.6673996e-04 8.3485996e-11 9.9953330e-01 3.2391308e-11 1.8108233e-10], sampled 0.258209762322963
[2019-03-23 17:33:27,477] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00081253], dtype=float32), 0.002450229]
[2019-03-23 17:33:27,478] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.36607782333333, 65.23674705333333, 1.0, 2.0, 0.2031526903465493, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3957707912057558, 6.9112, 6.9112, 95.55338769695034, 455314.7558753885, 455314.7558753885, 163653.821929793]
[2019-03-23 17:33:27,480] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:33:27,482] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.8268039e-04 6.6496515e-13 9.9951732e-01 1.8170261e-13 2.8794228e-12], sampled 0.4829791786235531
[2019-03-23 17:33:36,933] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00081253], dtype=float32), 0.002450229]
[2019-03-23 17:33:36,934] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.95, 71.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3842604780364307, 6.911200000000001, 6.9112, 95.55338769695034, 440608.0356580829, 440608.0356580825, 163733.5633239087]
[2019-03-23 17:33:36,934] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:33:36,936] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.1217820e-04 5.0742982e-13 9.9958783e-01 1.3697489e-13 2.1581187e-12], sampled 0.7513816643745294
[2019-03-23 17:33:38,258] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00081253], dtype=float32), 0.002450229]
[2019-03-23 17:33:38,260] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.83333333333334, 69.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3353868512279903, 6.9112, 6.9112, 95.55338769695034, 387157.5399907914, 387157.5399907914, 155001.5744421971]
[2019-03-23 17:33:38,261] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:33:38,263] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.0745569e-04 1.9402895e-12 9.9969256e-01 5.9787895e-13 6.0204923e-12], sampled 0.6182994665997383
[2019-03-23 17:33:45,403] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00081253], dtype=float32), 0.002450229]
[2019-03-23 17:33:45,404] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.77437362333334, 94.17037441666668, 1.0, 2.0, 0.2647346054044488, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5356508903633935, 6.911200000000001, 6.9112, 95.55338769695034, 603454.700088314, 603454.7000883135, 187296.0578400031]
[2019-03-23 17:33:45,405] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:33:45,408] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.4938368e-04 6.3160428e-14 9.9975055e-01 1.5712761e-14 3.1207353e-13], sampled 0.6465905925343824
[2019-03-23 17:33:45,923] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00081253], dtype=float32), 0.002450229]
[2019-03-23 17:33:45,924] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.93333333333333, 73.66666666666667, 1.0, 2.0, 0.255687822852748, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5152079334532395, 6.911199999999999, 6.9112, 95.55338769695034, 583459.1376519569, 583459.1376519572, 182690.1905339816]
[2019-03-23 17:33:45,925] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:33:45,928] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.0025226e-04 1.5480081e-13 9.9959975e-01 3.8946680e-14 7.7551436e-13], sampled 0.471245772304383
[2019-03-23 17:33:50,354] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00081253], dtype=float32), 0.002450229]
[2019-03-23 17:33:50,355] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.91666666666666, 70.66666666666667, 1.0, 2.0, 0.373407371898604, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7549043298251729, 6.911199999999999, 6.9112, 95.55338769695034, 851865.8028648021, 851865.8028648024, 219089.9706706017]
[2019-03-23 17:33:50,356] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:33:50,361] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.2953284e-04 1.0624591e-13 9.9987042e-01 2.9481429e-14 3.8386788e-13], sampled 0.056124065058172135
[2019-03-23 17:33:56,854] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00081253], dtype=float32), 0.002450229]
[2019-03-23 17:33:56,855] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.03333333333333, 51.66666666666667, 1.0, 2.0, 0.33669307860769, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6795182703428296, 6.9112, 6.9112, 95.55338768961946, 768423.213610345, 768423.213610345, 205669.6652129336]
[2019-03-23 17:33:56,856] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:33:56,859] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.3507584e-05 2.7149279e-13 9.9991643e-01 8.7135533e-14 7.6297735e-13], sampled 0.5035340577334676
[2019-03-23 17:34:02,658] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00081253], dtype=float32), 0.002450229]
[2019-03-23 17:34:02,659] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.90479588666667, 71.43849173666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 261735.5462561358, 261735.5462561355, 109599.1890475457]
[2019-03-23 17:34:02,661] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:34:02,664] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.4520859e-04 7.6612145e-12 9.9965477e-01 2.5606409e-12 2.0129403e-11], sampled 0.4069056125251359
[2019-03-23 17:34:22,212] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00081253], dtype=float32), 0.002450229]
[2019-03-23 17:34:22,213] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.8, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 321934.0721400485, 321934.0721400482, 144319.4587813049]
[2019-03-23 17:34:22,216] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:34:22,219] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.3087994e-04 3.1698769e-12 9.9966908e-01 9.9785891e-13 9.7561091e-12], sampled 0.9545388721539216
[2019-03-23 17:34:22,956] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2759.2281 2123936393.7589 759.0000
[2019-03-23 17:34:23,081] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3363.8422 2097904768.5387 180.0000
[2019-03-23 17:34:23,214] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3614.8540 2175171910.5612 246.0000
[2019-03-23 17:34:23,361] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3520.6334 2104036640.7343 178.0000
[2019-03-23 17:34:23,370] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3124.2040 2108850295.2852 368.0000
[2019-03-23 17:34:24,386] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 450000, evaluation results [450000.0, 3614.853996040168, 2175171910.561168, 246.0, 3363.842215933002, 2097904768.5386524, 180.0, 3520.6334249918555, 2104036640.7343316, 178.0, 2759.22809300758, 2123936393.7588594, 759.0, 3124.2040307498364, 2108850295.285167, 368.0]
[2019-03-23 17:34:29,473] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.4869989e-05 1.5820496e-11 9.9997509e-01 1.7365930e-12 4.3283259e-12], sum to 1.0000
[2019-03-23 17:34:29,478] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8231
[2019-03-23 17:34:29,482] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [13.0, 94.0, 1.0, 2.0, 0.219608995484323, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4099618835053874, 6.9112, 6.9112, 77.32846344354104, 477000.0109187847, 477000.0109187847, 130881.1798348274], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1057200.0000, 
sim time next is 1057800.0000, 
raw observation next is [13.0, 94.0, 1.0, 2.0, 0.2161641106823758, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4035310382717906, 6.911199999999999, 6.9112, 77.32846344354104, 469513.9625071776, 469513.9625071779, 130080.5426011748], 
processed observation next is [1.0, 0.21739130434782608, 0.22727272727272727, 0.94, 1.0, 1.0, 0.02020513835296972, 0.0, 1.0, -0.25, 1.0, 1.0, 0.14790148324541516, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17389406018784356, 0.17389406018784367, 0.31726961610042637], 
reward next is 0.6827, 
noisyNet noise sample is [array([1.4689803], dtype=float32), -0.4678797]. 
=============================================
[2019-03-23 17:34:31,879] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0921250e-07 8.4689457e-11 9.9999988e-01 5.4678678e-11 1.3251967e-11], sum to 1.0000
[2019-03-23 17:34:31,892] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8697
[2019-03-23 17:34:31,899] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.16666666666667, 99.00000000000001, 1.0, 2.0, 0.21148074949517, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4204639081879811, 6.911200000000001, 6.9112, 77.32846344354104, 480146.9147506352, 480146.9147506349, 164561.1504560802], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1318200.0000, 
sim time next is 1318800.0000, 
raw observation next is [19.33333333333334, 98.0, 1.0, 2.0, 0.2080842218353932, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4140146849845132, 6.911200000000001, 6.9112, 77.32846344354104, 472615.6318123002, 472615.6318123, 164123.5571831574], 
processed observation next is [1.0, 0.2608695652173913, 0.5151515151515155, 0.98, 1.0, 1.0, 0.010105277294241502, 0.0, 1.0, -0.25, 1.0, 1.0, 0.16287812140644747, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1750428265971482, 0.17504282659714815, 0.4003013589833107], 
reward next is 0.5997, 
noisyNet noise sample is [array([0.3211436], dtype=float32), 0.8136149]. 
=============================================
[2019-03-23 17:34:37,082] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.6036987e-03 1.5762547e-13 9.9039626e-01 1.5752989e-13 3.3152395e-14], sum to 1.0000
[2019-03-23 17:34:37,090] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0233
[2019-03-23 17:34:37,096] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.66666666666667, 77.0, 1.0, 2.0, 0.2553636089651298, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5170488847268946, 6.911199999999999, 6.9112, 77.32846344354104, 581558.1853650042, 581558.1853650045, 180968.7585487646], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1196400.0000, 
sim time next is 1197000.0000, 
raw observation next is [24.5, 78.5, 1.0, 2.0, 0.2569355848517137, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5202840861510007, 6.911200000000001, 6.9112, 77.32846344354104, 585000.0986681286, 585000.0986681284, 181486.9316400152], 
processed observation next is [1.0, 0.8695652173913043, 0.75, 0.785, 1.0, 1.0, 0.0711694810646421, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3146915516442868, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.216666703210418, 0.21666670321041792, 0.44265105278052486], 
reward next is 0.5573, 
noisyNet noise sample is [array([0.06387079], dtype=float32), 0.20984451]. 
=============================================
[2019-03-23 17:34:37,114] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[59.960545]
 [59.59566 ]
 [59.250156]
 [58.818233]
 [58.402798]], R is [[60.34648514]
 [60.30163193]
 [60.25794983]
 [60.21477127]
 [60.17074966]].
[2019-03-23 17:34:37,692] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.3848952e-03 3.9123977e-15 9.9361503e-01 4.3875798e-16 5.6648666e-14], sum to 1.0000
[2019-03-23 17:34:37,698] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3157
[2019-03-23 17:34:37,706] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.33333333333333, 77.33333333333333, 1.0, 2.0, 0.2481786325595714, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5021246761119245, 6.9112, 6.9112, 77.32846344354104, 565791.5215038195, 565791.5215038195, 178515.8671602158], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1426200.0000, 
sim time next is 1426800.0000, 
raw observation next is [24.66666666666666, 76.66666666666667, 1.0, 2.0, 0.2517850033524225, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5097111335897473, 6.9112, 6.9112, 77.32846344354104, 573602.641338275, 573602.641338275, 179897.7580416806], 
processed observation next is [0.0, 0.5217391304347826, 0.7575757575757573, 0.7666666666666667, 1.0, 1.0, 0.0647312541905281, 0.0, 1.0, -0.25, 1.0, 1.0, 0.299587333699639, 0.0, 0.0, 0.5084288129206541, 0.21244542271787964, 0.21244542271787964, 0.43877501961385507], 
reward next is 0.5612, 
noisyNet noise sample is [array([-0.6485848], dtype=float32), 2.3968997]. 
=============================================
[2019-03-23 17:34:40,691] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3688037e-05 1.6535384e-12 9.9998629e-01 1.1063622e-12 1.5468283e-11], sum to 1.0000
[2019-03-23 17:34:40,697] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5093
[2019-03-23 17:34:40,703] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 98.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3675207151783412, 6.911199999999999, 6.9112, 77.32846344354104, 422557.2128306634, 422557.2128306637, 155921.0604246493], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1290000.0000, 
sim time next is 1290600.0000, 
raw observation next is [18.0, 97.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3646227690710276, 6.9112, 6.9112, 77.32846344354104, 419469.2839158342, 419469.2839158342, 155330.0483382213], 
processed observation next is [1.0, 0.9565217391304348, 0.45454545454545453, 0.97, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.09231824153003942, 0.0, 0.0, 0.5084288129206541, 0.15535899404290157, 0.15535899404290157, 0.3788537764346861], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.68442535], dtype=float32), -1.2279419]. 
=============================================
[2019-03-23 17:34:51,015] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.92967277e-04 1.30853826e-14 9.99707043e-01 1.28509035e-14
 1.00493486e-13], sum to 1.0000
[2019-03-23 17:34:51,022] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3239
[2019-03-23 17:34:51,027] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.33333333333334, 84.66666666666667, 1.0, 2.0, 0.3083637606180756, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5915018187810679, 6.9112, 6.9112, 77.32846344354104, 683617.8652383463, 683617.8652383463, 176680.6508943402], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1678800.0000, 
sim time next is 1679400.0000, 
raw observation next is [18.5, 83.0, 1.0, 2.0, 0.3221500951293618, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6174725069017596, 6.9112, 6.9112, 77.32846344354104, 713791.1280329049, 713791.1280329049, 179758.2576205159], 
processed observation next is [1.0, 0.43478260869565216, 0.4772727272727273, 0.83, 1.0, 1.0, 0.15268761891170227, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4535321527167995, 0.0, 0.0, 0.5084288129206541, 0.26436708445663143, 0.26436708445663143, 0.4384347746841852], 
reward next is 0.5616, 
noisyNet noise sample is [array([1.4438418], dtype=float32), -0.8540709]. 
=============================================
[2019-03-23 17:34:54,408] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7135542e-05 3.7367343e-16 9.9998283e-01 3.5258239e-16 2.0121071e-15], sum to 1.0000
[2019-03-23 17:34:54,418] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7675
[2019-03-23 17:34:54,423] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.2591172214201796, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5248212336735765, 6.9112, 6.9112, 77.32846344354104, 589505.0209710058, 589505.0209710058, 182424.1794016198], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1523400.0000, 
sim time next is 1524000.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.2591080949534696, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5248038538900734, 6.9112, 6.9112, 77.32846344354104, 589478.1734107889, 589478.1734107889, 182426.7740328016], 
processed observation next is [0.0, 0.6521739130434783, 0.7272727272727273, 0.83, 1.0, 1.0, 0.07388511869183698, 0.0, 1.0, -0.25, 1.0, 1.0, 0.32114836270010494, 0.0, 0.0, 0.5084288129206541, 0.2183252494114033, 0.2183252494114033, 0.44494335129951607], 
reward next is 0.5551, 
noisyNet noise sample is [array([-0.29072335], dtype=float32), -0.114668205]. 
=============================================
[2019-03-23 17:34:54,449] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[50.957695]
 [50.52411 ]
 [50.14862 ]
 [49.879433]
 [49.669907]], R is [[51.35242081]
 [51.39395905]
 [51.43584061]
 [51.47948074]
 [51.52481842]].
[2019-03-23 17:34:54,540] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0388963e-05 8.0902624e-15 9.9998963e-01 4.1474354e-15 1.3295559e-14], sum to 1.0000
[2019-03-23 17:34:54,548] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7106
[2019-03-23 17:34:54,552] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.16666666666666, 93.0, 1.0, 2.0, 0.2291008950009416, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4613221282614456, 6.911200000000001, 6.9112, 77.32846344354104, 522776.7457266388, 522776.7457266385, 171783.4247772017], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1547400.0000, 
sim time next is 1548000.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.2279955072675737, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4589523743336194, 6.911199999999999, 6.9112, 77.32846344354104, 520228.1700588639, 520228.1700588642, 171431.020190265], 
processed observation next is [0.0, 0.9565217391304348, 0.5909090909090909, 0.94, 1.0, 1.0, 0.03499438408446711, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2270748204765992, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19267710002180144, 0.19267710002180158, 0.41812443948845124], 
reward next is 0.5819, 
noisyNet noise sample is [array([-1.1903193], dtype=float32), 0.49417675]. 
=============================================
[2019-03-23 17:34:54,569] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[55.69242 ]
 [55.655167]
 [55.549294]
 [55.421333]
 [55.30851 ]], R is [[55.7578125 ]
 [55.78125   ]
 [55.80382538]
 [55.82581329]
 [55.84705734]].
[2019-03-23 17:34:55,361] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.3475035e-04 9.7102563e-14 9.9936527e-01 1.7977686e-15 1.1753675e-12], sum to 1.0000
[2019-03-23 17:34:55,368] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5950
[2019-03-23 17:34:55,373] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.5, 91.0, 1.0, 2.0, 0.208812796637199, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4171852143682567, 6.911200000000001, 6.9112, 77.32846344354104, 475234.463349767, 475234.4633497667, 165304.0773644148], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1560600.0000, 
sim time next is 1561200.0000, 
raw observation next is [20.33333333333333, 92.0, 1.0, 2.0, 0.2080764670562341, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4155170863576685, 6.9112, 6.9112, 77.32846344354104, 473455.3239697435, 473455.3239697435, 165043.4736253795], 
processed observation next is [1.0, 0.043478260869565216, 0.5606060606060604, 0.92, 1.0, 1.0, 0.010095583820292596, 0.0, 1.0, -0.25, 1.0, 1.0, 0.16502440908238358, 0.0, 0.0, 0.5084288129206541, 0.1753538236924976, 0.1753538236924976, 0.40254505762287685], 
reward next is 0.5975, 
noisyNet noise sample is [array([1.0155973], dtype=float32), 0.7160366]. 
=============================================
[2019-03-23 17:35:03,260] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.9656503e-07 4.8182702e-09 9.9999940e-01 3.4002174e-09 3.3838213e-10], sum to 1.0000
[2019-03-23 17:35:03,269] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5008
[2019-03-23 17:35:03,277] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [15.5, 57.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 244755.5628411933, 244755.5628411935, 94123.59872673206], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1711800.0000, 
sim time next is 1712400.0000, 
raw observation next is [15.0, 59.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 237663.2802231181, 237663.2802231181, 92542.84554314101], 
processed observation next is [1.0, 0.8260869565217391, 0.3181818181818182, 0.5933333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.08802343711967338, 0.08802343711967338, 0.22571425742229514], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.31092966], dtype=float32), 2.2934074]. 
=============================================
[2019-03-23 17:35:06,046] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.9992794e-06 8.7238944e-10 9.9999797e-01 3.4558387e-10 1.6547963e-10], sum to 1.0000
[2019-03-23 17:35:06,052] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8137
[2019-03-23 17:35:06,058] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [8.666666666666668, 83.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3223679556391857, 6.9112, 6.9112, 77.32846344354104, 375043.1677610654, 375043.1677610654, 111609.2832470521], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1748400.0000, 
sim time next is 1749000.0000, 
raw observation next is [8.833333333333332, 82.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3257218148378673, 6.9112, 6.9112, 77.32846344354104, 378946.5709675069, 378946.5709675069, 112099.1669094238], 
processed observation next is [1.0, 0.21739130434782608, 0.037878787878787824, 0.82, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.03674544976838184, 0.0, 0.0, 0.5084288129206541, 0.14035058183981738, 0.14035058183981738, 0.2734126022181068], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0611684], dtype=float32), -0.5352964]. 
=============================================
[2019-03-23 17:35:06,070] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[10.289819]
 [ 9.931818]
 [ 9.816456]
 [ 9.4871  ]
 [ 9.399444]], R is [[10.3854475 ]
 [10.28159332]
 [10.17877769]
 [10.07699013]
 [ 9.97622013]].
[2019-03-23 17:35:10,444] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1575422e-06 5.0309752e-09 9.9999881e-01 3.4589508e-08 8.0961926e-10], sum to 1.0000
[2019-03-23 17:35:10,450] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2396
[2019-03-23 17:35:10,455] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.0, 69.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 205984.647386619, 205984.6473866187, 86971.09125502587], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1816200.0000, 
sim time next is 1816800.0000, 
raw observation next is [14.0, 70.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 206426.9932607347, 206426.993260735, 87166.53022586845], 
processed observation next is [1.0, 0.0, 0.2727272727272727, 0.7033333333333335, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07645444194842026, 0.07645444194842037, 0.21260129323382548], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.01626441], dtype=float32), -0.5264864]. 
=============================================
[2019-03-23 17:35:14,090] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 17:35:14,091] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:35:14,092] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:35:14,092] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:35:14,097] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:35:14,100] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:35:14,100] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:35:14,101] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:35:14,105] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:35:14,106] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:35:14,107] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:35:14,123] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run20
[2019-03-23 17:35:14,123] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run20
[2019-03-23 17:35:14,181] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run20
[2019-03-23 17:35:14,203] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run20
[2019-03-23 17:35:14,203] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run20
[2019-03-23 17:36:21,860] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00208905], dtype=float32), 0.0022469442]
[2019-03-23 17:36:21,863] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 80.5, 1.0, 2.0, 0.2081073250962763, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4163913465370289, 6.9112, 6.9112, 77.32846344354104, 473932.8353543109, 473932.8353543109, 165578.1965007758]
[2019-03-23 17:36:21,865] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:36:21,868] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.3655665e-07 1.7820935e-12 9.9999988e-01 1.2628959e-12 3.2431067e-13], sampled 0.0021796825464724945
[2019-03-23 17:36:31,321] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00208905], dtype=float32), 0.0022469442]
[2019-03-23 17:36:31,322] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.5, 49.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3050130211545168, 6.911200000000001, 6.9112, 95.55338769695034, 353195.4018326405, 353195.4018326401, 150339.7421651075]
[2019-03-23 17:36:31,323] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:36:31,326] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.0399785e-08 5.1517162e-11 9.9999988e-01 5.5546949e-11 3.6075162e-12], sampled 0.8235792409084067
[2019-03-23 17:36:38,415] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00208905], dtype=float32), 0.0022469442]
[2019-03-23 17:36:38,416] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [29.98333333333333, 53.0, 1.0, 2.0, 0.3807757635193295, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7710026591941569, 6.911200000000001, 6.9112, 95.55338769695034, 862173.8614361386, 862173.8614361383, 226548.7169596223]
[2019-03-23 17:36:38,417] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:36:38,420] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.1414801e-08 7.6430984e-13 1.0000000e+00 6.9715018e-13 7.9060734e-14], sampled 0.770288270994024
[2019-03-23 17:36:52,249] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3361.3422 2098071489.5709 179.0000
[2019-03-23 17:36:52,353] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2760.0075 2124051796.3784 757.0000
[2019-03-23 17:36:52,386] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3614.1741 2175305489.0345 245.0000
[2019-03-23 17:36:52,391] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3119.6236 2108995491.2113 368.0000
[2019-03-23 17:36:52,525] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3519.7619 2104085987.4531 178.0000
[2019-03-23 17:36:53,540] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 475000, evaluation results [475000.0, 3614.1740929847015, 2175305489.034501, 245.0, 3361.342177577007, 2098071489.5708618, 179.0, 3519.7618759670804, 2104085987.4531295, 178.0, 2760.0074851005825, 2124051796.3784225, 757.0, 3119.623607254903, 2108995491.2112706, 368.0]
[2019-03-23 17:36:55,528] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.2669128e-06 3.0883162e-15 9.9999774e-01 6.5497887e-14 4.9089418e-15], sum to 1.0000
[2019-03-23 17:36:55,536] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0489
[2019-03-23 17:36:55,541] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.2125159538701694, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4223517563177643, 6.9112, 6.9112, 77.32846344354104, 482393.6736496651, 482393.6736496651, 164653.1180666946], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1925400.0000, 
sim time next is 1926000.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.2062120996427421, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4098182658813402, 6.911199999999999, 6.9112, 77.32846344354104, 468074.2903677356, 468074.2903677359, 163515.8444039042], 
processed observation next is [1.0, 0.30434782608695654, 0.5, 1.0, 1.0, 1.0, 0.007765124553427601, 0.0, 1.0, -0.25, 1.0, 1.0, 0.15688323697334314, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17336084828434653, 0.17336084828434664, 0.39881913269244923], 
reward next is 0.6012, 
noisyNet noise sample is [array([0.6695897], dtype=float32), -0.6152785]. 
=============================================
[2019-03-23 17:36:55,560] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[36.32768 ]
 [36.16081 ]
 [36.05228 ]
 [36.05788 ]
 [35.934208]], R is [[36.58571625]
 [36.81826782]
 [37.05140305]
 [36.68088913]
 [36.31407928]].
[2019-03-23 17:36:55,930] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.3819357e-09 7.6101939e-13 1.0000000e+00 2.2815671e-13 7.5515427e-14], sum to 1.0000
[2019-03-23 17:36:55,938] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2847
[2019-03-23 17:36:55,941] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.0, 74.0, 1.0, 2.0, 0.6038424157840038, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9702589954820725, 6.911199999999999, 6.9112, 77.32846344354103, 1237524.342478817, 1237524.342478817, 271565.3874579826], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1944000.0000, 
sim time next is 1944600.0000, 
raw observation next is [24.33333333333333, 71.83333333333334, 1.0, 2.0, 0.6516841344101306, 0.0, 2.0, 0.0, 1.0, 2.0, 0.970335566069582, 6.9112, 6.9112, 77.32846344354104, 1292186.078166971, 1292186.078166971, 278140.5360277524], 
processed observation next is [1.0, 0.5217391304347826, 0.7424242424242422, 0.7183333333333334, 1.0, 1.0, 0.5646051680126632, 0.0, 1.0, -0.25, 1.0, 1.0, 0.95762223724226, 0.0, 0.0, 0.5084288129206541, 0.4785874363581374, 0.4785874363581374, 0.678391551287201], 
reward next is 0.3216, 
noisyNet noise sample is [array([-1.7166415], dtype=float32), 2.0470116]. 
=============================================
[2019-03-23 17:37:00,384] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.7841464e-08 3.5206599e-10 9.9999988e-01 2.0324558e-09 1.4837282e-11], sum to 1.0000
[2019-03-23 17:37:00,393] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8112
[2019-03-23 17:37:00,397] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 51.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 319936.3134832993, 319936.313483299, 135618.1352282397], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2028000.0000, 
sim time next is 2028600.0000, 
raw observation next is [22.0, 51.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 320199.1022586655, 320199.1022586655, 137419.7160584216], 
processed observation next is [0.0, 0.4782608695652174, 0.6363636363636364, 0.515, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.11859226009580204, 0.11859226009580204, 0.33517003916688193], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.2883656], dtype=float32), -0.9623207]. 
=============================================
[2019-03-23 17:37:04,171] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.5777032e-07 3.0185403e-09 9.9999964e-01 6.5426140e-09 1.3691370e-10], sum to 1.0000
[2019-03-23 17:37:04,178] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5528
[2019-03-23 17:37:04,183] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 52.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 272430.5257931644, 272430.5257931647, 101880.0787847141], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2318400.0000, 
sim time next is 2319000.0000, 
raw observation next is [17.83333333333333, 52.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 268419.5272733378, 268419.5272733375, 100950.170125248], 
processed observation next is [1.0, 0.8695652173913043, 0.44696969696969674, 0.525, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09941463973086587, 0.09941463973086573, 0.24621992713475122], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5029815], dtype=float32), 1.214304]. 
=============================================
[2019-03-23 17:37:04,210] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[0.96305406]
 [0.9851726 ]
 [1.011075  ]
 [1.0084939 ]
 [0.99975586]], R is [[0.94969338]
 [0.94019645]
 [0.93079448]
 [0.92148656]
 [0.91227168]].
[2019-03-23 17:37:04,509] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0210507e-07 7.8272855e-10 9.9999988e-01 1.4264099e-09 1.8737095e-11], sum to 1.0000
[2019-03-23 17:37:04,517] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1129
[2019-03-23 17:37:04,526] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.33333333333333, 59.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 326538.5627032336, 326538.5627032336, 141080.2735683909], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2106600.0000, 
sim time next is 2107200.0000, 
raw observation next is [21.66666666666667, 59.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 335259.7022322605, 335259.7022322602, 142889.5970250784], 
processed observation next is [0.0, 0.391304347826087, 0.6212121212121214, 0.5900000000000001, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1241702600860224, 0.12417026008602229, 0.3485112122562888], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.6484268], dtype=float32), -0.8185376]. 
=============================================
[2019-03-23 17:37:07,679] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.9460340e-07 9.6003407e-11 9.9999964e-01 3.9385072e-11 2.3720748e-12], sum to 1.0000
[2019-03-23 17:37:07,686] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9968
[2019-03-23 17:37:07,694] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 53.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 325511.871185477, 325511.871185477, 140394.5697322932], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2154600.0000, 
sim time next is 2155200.0000, 
raw observation next is [22.0, 53.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 323532.5523681076, 323532.5523681079, 140087.8206885638], 
processed observation next is [0.0, 0.9565217391304348, 0.6363636363636364, 0.53, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11982687124744726, 0.11982687124744737, 0.3416776114355215], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3418175], dtype=float32), -1.1577721]. 
=============================================
[2019-03-23 17:37:08,665] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.55438124e-07 4.08701295e-10 9.99999762e-01 2.54258253e-10
 1.06148805e-10], sum to 1.0000
[2019-03-23 17:37:08,669] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5132
[2019-03-23 17:37:08,674] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.0, 82.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 270200.5004147231, 270200.5004147234, 108973.0167121566], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2188800.0000, 
sim time next is 2189400.0000, 
raw observation next is [16.16666666666667, 81.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 285162.0826557829, 285162.0826557832, 112224.0611473536], 
processed observation next is [1.0, 0.34782608695652173, 0.37121212121212144, 0.8116666666666668, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10561558616880849, 0.1056155861688086, 0.2737172223106185], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1676732], dtype=float32), -0.9409694]. 
=============================================
[2019-03-23 17:37:13,452] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.1691556e-07 3.3347224e-11 9.9999964e-01 9.0822974e-11 2.8364214e-11], sum to 1.0000
[2019-03-23 17:37:13,458] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9280
[2019-03-23 17:37:13,461] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 56.0, 1.0, 2.0, 0.2121759155861498, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3960859517450299, 6.9112, 6.9112, 77.32846344354104, 460847.3953198079, 460847.3953198079, 130659.6449251621], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2286000.0000, 
sim time next is 2286600.0000, 
raw observation next is [18.0, 55.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3722918428080718, 6.9112, 6.9112, 77.32846344354104, 433150.5336043517, 433150.5336043517, 127928.4523584664], 
processed observation next is [1.0, 0.4782608695652174, 0.45454545454545453, 0.5533333333333335, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.10327406115438834, 0.0, 0.0, 0.5084288129206541, 0.1604261235571673, 0.1604261235571673, 0.3120206155084546], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.23058377], dtype=float32), 1.2748957]. 
=============================================
[2019-03-23 17:37:15,154] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.8178778e-07 3.9906189e-09 9.9999976e-01 7.2366668e-10 2.7029229e-10], sum to 1.0000
[2019-03-23 17:37:15,162] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0504
[2019-03-23 17:37:15,167] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.0, 55.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 253851.8372110259, 253851.8372110256, 97380.26198760513], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2325600.0000, 
sim time next is 2326200.0000, 
raw observation next is [17.0, 54.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 253575.1663700046, 253575.1663700049, 97200.72673305446], 
processed observation next is [1.0, 0.9565217391304348, 0.4090909090909091, 0.545, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09391672828518688, 0.093916728285187, 0.23707494325135234], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.18269005], dtype=float32), -0.43539715]. 
=============================================
[2019-03-23 17:37:24,314] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.1202336e-07 3.4595668e-12 9.9999964e-01 3.8813215e-12 1.3480944e-12], sum to 1.0000
[2019-03-23 17:37:24,322] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9663
[2019-03-23 17:37:24,326] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.16666666666667, 65.66666666666667, 1.0, 2.0, 0.2268187398995329, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4281061036918385, 6.911199999999999, 6.9112, 77.32846344354104, 496517.8356629406, 496517.8356629409, 157719.2531574189], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2481000.0000, 
sim time next is 2481600.0000, 
raw observation next is [19.33333333333334, 71.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 344598.7391654306, 344598.7391654309, 143813.5447935738], 
processed observation next is [1.0, 0.7391304347826086, 0.5151515151515155, 0.7133333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12762916265386318, 0.1276291626538633, 0.35076474339896047], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.7197347], dtype=float32), -0.5915675]. 
=============================================
[2019-03-23 17:37:28,081] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.6938956e-06 2.0938602e-09 9.9999833e-01 7.2746720e-10 5.6970756e-10], sum to 1.0000
[2019-03-23 17:37:28,095] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1598
[2019-03-23 17:37:28,099] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.33333333333334, 52.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 332888.8255321025, 332888.8255321022, 141744.877412143], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2569200.0000, 
sim time next is 2569800.0000, 
raw observation next is [22.16666666666667, 52.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 329256.987072128, 329256.9870721277, 141052.7510797002], 
processed observation next is [1.0, 0.7391304347826086, 0.6439393939393941, 0.525, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12194703224893629, 0.12194703224893619, 0.3440311001943907], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.23804545], dtype=float32), 0.116775654]. 
=============================================
[2019-03-23 17:37:32,262] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4656457e-06 2.3015988e-10 9.9999857e-01 6.7077033e-10 3.0004527e-11], sum to 1.0000
[2019-03-23 17:37:32,272] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8490
[2019-03-23 17:37:32,276] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 42.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3490065975261922, 6.911199999999999, 6.9112, 77.32846344354104, 400914.4232849595, 400914.4232849598, 153933.4419903742], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2639400.0000, 
sim time next is 2640000.0000, 
raw observation next is [27.0, 42.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3494816125870545, 6.9112, 6.9112, 77.32846344354104, 401450.3368464043, 401450.3368464043, 154001.3995114428], 
processed observation next is [0.0, 0.5652173913043478, 0.8636363636363636, 0.42, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.07068801798150647, 0.0, 0.0, 0.5084288129206541, 0.14868530994311271, 0.14868530994311271, 0.37561316954010443], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5480382], dtype=float32), -0.10505072]. 
=============================================
[2019-03-23 17:37:32,295] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[5.4503994]
 [5.454051 ]
 [5.440847 ]
 [5.4873905]
 [5.5640244]], R is [[5.41968107]
 [5.36548424]
 [5.31182957]
 [5.25871134]
 [5.20612431]].
[2019-03-23 17:37:33,116] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3352683e-07 2.1294306e-09 9.9999988e-01 1.4036715e-09 3.9381474e-11], sum to 1.0000
[2019-03-23 17:37:33,128] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4118
[2019-03-23 17:37:33,132] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.66666666666666, 43.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3231304295845168, 6.9112, 6.9112, 77.32846344354104, 372687.9675948397, 372687.9675948397, 149341.6327922792], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2634000.0000, 
sim time next is 2634600.0000, 
raw observation next is [25.83333333333334, 42.83333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3226980276740776, 6.911199999999999, 6.9112, 77.32846344354104, 372220.5069471597, 372220.5069471599, 149260.6480421744], 
processed observation next is [0.0, 0.4782608695652174, 0.8106060606060609, 0.4283333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.03242575382011091, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13785944701746655, 0.13785944701746664, 0.36405036107847416], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.07461636], dtype=float32), -1.1172054]. 
=============================================
[2019-03-23 17:37:35,248] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4099156e-07 2.1691345e-11 9.9999988e-01 3.4173345e-11 7.6791065e-12], sum to 1.0000
[2019-03-23 17:37:35,254] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4326
[2019-03-23 17:37:35,258] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.58333333333334, 74.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3454802325933343, 6.9112, 6.9112, 77.32846344354104, 397972.4253273155, 397972.4253273155, 152459.5994700042], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2677800.0000, 
sim time next is 2678400.0000, 
raw observation next is [20.3, 75.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3404676676018901, 6.9112, 6.9112, 77.32846344354104, 392480.0790681368, 392480.0790681368, 151584.0557294228], 
processed observation next is [0.0, 0.0, 0.5590909090909091, 0.75, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.057810953716985906, 0.0, 0.0, 0.5084288129206541, 0.14536299224745808, 0.14536299224745808, 0.3697172090961532], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.31858712], dtype=float32), -1.0882274]. 
=============================================
[2019-03-23 17:37:40,957] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.1026198e-09 3.4087681e-11 1.0000000e+00 8.8558102e-12 1.0317686e-12], sum to 1.0000
[2019-03-23 17:37:40,964] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5235
[2019-03-23 17:37:40,971] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.4682876629708073, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9368333825995626, 6.931458798421048, 6.9112, 77.32840524524639, 1065422.362497407, 1058842.724086252, 252643.8480961767], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2812200.0000, 
sim time next is 2812800.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.5478994411737939, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9701126798228048, 6.921523283553464, 6.9112, 77.32842420531983, 1171449.206540952, 1168096.416891732, 268257.6083798853], 
processed observation next is [1.0, 0.5652173913043478, 0.9090909090909091, 0.58, 1.0, 1.0, 0.43487430146724226, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9573038283182925, 0.0010323283553463902, 0.0, 0.5084285549323101, 0.4338700764966489, 0.43262830255249335, 0.6542868497070373], 
reward next is 0.2941, 
noisyNet noise sample is [array([0.5978641], dtype=float32), -0.39594418]. 
=============================================
[2019-03-23 17:37:43,346] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 17:37:43,347] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:37:43,347] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:37:43,347] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:37:43,348] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:37:43,347] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:37:43,349] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:37:43,348] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:37:43,349] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:37:43,350] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:37:43,351] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:37:43,359] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run21
[2019-03-23 17:37:43,383] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run21
[2019-03-23 17:37:43,386] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run21
[2019-03-23 17:37:43,430] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run21
[2019-03-23 17:37:43,434] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run21
[2019-03-23 17:37:49,120] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00205832], dtype=float32), 0.0027321696]
[2019-03-23 17:37:49,124] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.4, 66.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 244350.7069048976, 244350.7069048973, 102128.9697941831]
[2019-03-23 17:37:49,125] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:37:49,129] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.1925695e-04 1.2284175e-11 9.9978071e-01 3.6892859e-12 2.9627245e-11], sampled 0.3873181165404699
[2019-03-23 17:37:56,366] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00205832], dtype=float32), 0.0027321696]
[2019-03-23 17:37:56,367] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.32111071, 57.83387182, 1.0, 2.0, 0.2542684612373861, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5141611638218763, 6.911199999999999, 6.9112, 95.55338769695034, 579865.2148387715, 579865.2148387718, 184258.8529274177]
[2019-03-23 17:37:56,368] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:37:56,373] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.1584265e-04 2.5829489e-14 9.9988413e-01 5.7070895e-15 1.4030137e-13], sampled 0.40727753459723826
[2019-03-23 17:38:13,576] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00205832], dtype=float32), 0.0027321696]
[2019-03-23 17:38:13,576] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.17332261, 62.17745756666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3233248704186211, 6.9112, 6.9112, 95.55338769695034, 373095.713096967, 373095.713096967, 153709.8817834312]
[2019-03-23 17:38:13,578] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:38:13,580] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.9057224e-04 1.2000033e-12 9.9970943e-01 3.0647761e-13 4.8728270e-12], sampled 0.8161232919983424
[2019-03-23 17:38:18,166] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00205832], dtype=float32), 0.0027321696]
[2019-03-23 17:38:18,167] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.13333333333333, 68.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 245894.616840455, 245894.616840455, 102336.6636836742]
[2019-03-23 17:38:18,168] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:38:18,170] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.4079433e-04 1.3577239e-11 9.9965918e-01 3.9089248e-12 3.8950537e-11], sampled 0.4028312886488049
[2019-03-23 17:38:40,499] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00205832], dtype=float32), 0.0027321696]
[2019-03-23 17:38:40,500] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.80486326833334, 65.40222593166666, 1.0, 2.0, 0.3692600176275566, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7479308769317584, 6.9112, 6.9112, 95.55338769695034, 840020.6660680516, 840020.6660680516, 220308.1589727989]
[2019-03-23 17:38:40,500] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:38:40,502] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.5907668e-04 2.6447935e-14 9.9984086e-01 5.8499373e-15 1.6185634e-13], sampled 0.846641991751104
[2019-03-23 17:38:56,823] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00205832], dtype=float32), 0.0027321696]
[2019-03-23 17:38:56,824] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.43333333333333, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 95.55338769695034, 271869.000624728, 271869.0006247284, 116033.332734741]
[2019-03-23 17:38:56,825] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:38:56,826] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.9555401e-04 3.4934217e-12 9.9980444e-01 9.7101374e-13 1.0125436e-11], sampled 0.9157402903019709
[2019-03-23 17:39:10,067] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00205832], dtype=float32), 0.0027321696]
[2019-03-23 17:39:10,068] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.76666666666667, 92.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 307171.1953880457, 307171.1953880457, 129138.7009767989]
[2019-03-23 17:39:10,068] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:39:10,073] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.9916738e-04 2.0998578e-12 9.9980086e-01 5.3132130e-13 6.5711152e-12], sampled 0.9139895316372826
[2019-03-23 17:39:15,640] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00205832], dtype=float32), 0.0027321696]
[2019-03-23 17:39:15,640] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.26666666666667, 84.0, 1.0, 2.0, 0.215193070857615, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4292651764971122, 6.911199999999999, 6.9112, 77.32846344354104, 489407.0311822022, 489407.0311822025, 166077.6739092772]
[2019-03-23 17:39:15,642] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:39:15,643] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.7237658e-04 2.5225111e-12 9.9972767e-01 6.5968005e-13 8.7500866e-12], sampled 0.16284676040414414
[2019-03-23 17:39:21,249] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2761.3454 2123955148.1168 756.0000
[2019-03-23 17:39:21,335] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3364.1793 2097904421.7824 179.0000
[2019-03-23 17:39:21,491] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3122.1732 2108770368.1796 369.0000
[2019-03-23 17:39:21,509] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3615.6431 2175142120.7252 245.0000
[2019-03-23 17:39:21,528] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3521.4377 2103886894.3213 179.0000
[2019-03-23 17:39:22,540] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 500000, evaluation results [500000.0, 3615.6430807769266, 2175142120.7252445, 245.0, 3364.179279371237, 2097904421.782424, 179.0, 3521.4376541497377, 2103886894.3212695, 179.0, 2761.345417019991, 2123955148.1167808, 756.0, 3122.1732411403477, 2108770368.1796167, 369.0]
[2019-03-23 17:39:30,540] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.5158700e-07 4.5045586e-12 9.9999964e-01 6.9381011e-12 2.6550309e-13], sum to 1.0000
[2019-03-23 17:39:30,547] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3921
[2019-03-23 17:39:30,551] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.0, 62.33333333333334, 1.0, 2.0, 0.8947422436963608, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9808422782170761, 6.911200000000001, 6.9112, 77.32846344354104, 1560909.136896877, 1560909.136896876, 328173.4934432808], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2994000.0000, 
sim time next is 2994600.0000, 
raw observation next is [28.0, 64.16666666666666, 1.0, 2.0, 0.9284867240855355, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9827122157136453, 6.911199999999999, 6.9112, 77.32846344354104, 1596191.652936871, 1596191.652936871, 336339.5036667695], 
processed observation next is [1.0, 0.6521739130434783, 0.9090909090909091, 0.6416666666666666, 1.0, 1.0, 0.9106084051069193, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9753031653052078, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5911820936803226, 0.5911820936803226, 0.8203402528457793], 
reward next is 0.1797, 
noisyNet noise sample is [array([-1.0601352], dtype=float32), 0.19942479]. 
=============================================
[2019-03-23 17:39:31,153] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.0075993e-04 5.6187298e-13 9.9939919e-01 3.8011627e-13 9.1473096e-13], sum to 1.0000
[2019-03-23 17:39:31,161] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2536
[2019-03-23 17:39:31,165] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 67.0, 1.0, 2.0, 0.2380534979822009, 0.0, 2.0, 0.0, 1.0, 2.0, 0.479863932567164, 6.911200000000001, 6.9112, 77.32846344354104, 543272.8678377873, 543272.867837787, 174139.0756695957], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3007800.0000, 
sim time next is 3008400.0000, 
raw observation next is [24.66666666666667, 67.66666666666667, 1.0, 2.0, 0.2348941465589684, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4728718515735272, 6.9112, 6.9112, 77.32846344354104, 535983.7639225541, 535983.7639225541, 172908.7056712484], 
processed observation next is [1.0, 0.8260869565217391, 0.7575757575757578, 0.6766666666666667, 1.0, 1.0, 0.04361768319871048, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2469597879621817, 0.0, 0.0, 0.5084288129206541, 0.1985125051565015, 0.1985125051565015, 0.42172855041767904], 
reward next is 0.5783, 
noisyNet noise sample is [array([-0.58844215], dtype=float32), -0.6303478]. 
=============================================
[2019-03-23 17:39:32,332] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1966400e-03 1.0034187e-11 9.9880338e-01 7.4475209e-12 1.6246449e-11], sum to 1.0000
[2019-03-23 17:39:32,342] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5830
[2019-03-23 17:39:32,345] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.16666666666667, 93.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3455805480845373, 6.9112, 6.9112, 77.32846344354104, 400227.5362198022, 400227.5362198022, 150388.4503348955], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3034200.0000, 
sim time next is 3034800.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3382913234514985, 6.9112, 6.9112, 77.32846344354104, 391912.3233933543, 391912.3233933543, 149412.1491246237], 
processed observation next is [1.0, 0.13043478260869565, 0.4090909090909091, 0.94, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.05470189064499785, 0.0, 0.0, 0.5084288129206541, 0.145152712367909, 0.145152712367909, 0.3644198759137164], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8953789], dtype=float32), -1.1987281]. 
=============================================
[2019-03-23 17:39:34,061] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.4552159e-08 4.0669841e-13 1.0000000e+00 9.4549438e-12 3.3251104e-13], sum to 1.0000
[2019-03-23 17:39:34,068] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6717
[2019-03-23 17:39:34,073] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 78.0, 1.0, 2.0, 0.3943183809627167, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7793140531795295, 6.9112, 6.9112, 77.32846344354104, 892593.7429847486, 892593.7429847486, 209290.5079098414], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3060000.0000, 
sim time next is 3060600.0000, 
raw observation next is [21.33333333333333, 76.5, 1.0, 2.0, 0.4128140199212869, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8175633940996763, 6.911200000000001, 6.9112, 77.32846344354104, 935652.4311121792, 935652.4311121788, 216346.3119609741], 
processed observation next is [1.0, 0.43478260869565216, 0.6060606060606059, 0.765, 1.0, 1.0, 0.2660175249016086, 0.0, 1.0, -0.25, 1.0, 1.0, 0.7393762772852518, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3465379374489553, 0.3465379374489551, 0.5276739316121319], 
reward next is 0.4723, 
noisyNet noise sample is [array([0.952328], dtype=float32), -0.42891708]. 
=============================================
[2019-03-23 17:39:37,933] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7625272e-04 4.1531101e-12 9.9982375e-01 1.0840892e-13 7.2473603e-12], sum to 1.0000
[2019-03-23 17:39:37,941] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3660
[2019-03-23 17:39:37,946] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.2137180476717493, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4261984951273137, 6.9112, 6.9112, 77.32846344354104, 485981.9467256087, 485981.9467256087, 165725.7954453196], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3132000.0000, 
sim time next is 3132600.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.2557069135654033, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5099733721714255, 6.911200000000001, 6.9112, 77.32846344354104, 581541.6032088427, 581541.6032088425, 174309.2171037396], 
processed observation next is [1.0, 0.2608695652173913, 0.6363636363636364, 0.78, 1.0, 1.0, 0.06963364195675413, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2999619602448936, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21538577896623803, 0.21538577896623795, 0.42514443196034046], 
reward next is 0.5749, 
noisyNet noise sample is [array([0.848527], dtype=float32), -0.17728502]. 
=============================================
[2019-03-23 17:39:43,624] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.0933335e-08 2.0065245e-10 1.0000000e+00 1.1059950e-09 8.9839698e-12], sum to 1.0000
[2019-03-23 17:39:43,631] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0313
[2019-03-23 17:39:43,644] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.16666666666667, 53.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3201741242837221, 6.911200000000001, 6.9112, 77.32846344354104, 370133.5441822193, 370133.544182219, 148148.6826094433], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3239400.0000, 
sim time next is 3240000.0000, 
raw observation next is [23.0, 53.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3143288183151943, 6.9112, 6.9112, 77.32846344354104, 363694.4494922904, 363694.4494922904, 147161.3291936737], 
processed observation next is [0.0, 0.5217391304347826, 0.6818181818181818, 0.53, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.020469740450277624, 0.0, 0.0, 0.5084288129206541, 0.13470164796010756, 0.13470164796010756, 0.3589300712040822], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.2248983], dtype=float32), 0.50195396]. 
=============================================
[2019-03-23 17:39:43,669] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[0.6907362 ]
 [0.7399515 ]
 [0.7739166 ]
 [0.8036072 ]
 [0.83533466]], R is [[0.62056023]
 [0.61435461]
 [0.60821104]
 [0.60212892]
 [0.59610766]].
[2019-03-23 17:39:45,658] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3110616e-06 3.3661131e-08 9.9999857e-01 4.0978545e-08 1.3043325e-09], sum to 1.0000
[2019-03-23 17:39:45,666] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8608
[2019-03-23 17:39:45,669] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.0, 82.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 267024.1642873026, 267024.1642873026, 108332.9042434939], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3292800.0000, 
sim time next is 3293400.0000, 
raw observation next is [16.0, 82.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 266979.4408262464, 266979.4408262461, 108317.8334231822], 
processed observation next is [0.0, 0.08695652173913043, 0.36363636363636365, 0.82, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09888127438009126, 0.09888127438009114, 0.2641898376175175], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.04385442], dtype=float32), 0.017645353]. 
=============================================
[2019-03-23 17:39:57,123] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.19321085e-04 3.43109520e-13 9.99880672e-01 1.67143538e-14
 1.14108267e-12], sum to 1.0000
[2019-03-23 17:39:57,132] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3608
[2019-03-23 17:39:57,141] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.66666666666667, 96.0, 1.0, 2.0, 0.2544837413918316, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5146975856005092, 6.9112, 6.9112, 77.32846344354104, 580346.5387782705, 580346.5387782705, 179721.1910132186], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3483600.0000, 
sim time next is 3484200.0000, 
raw observation next is [21.83333333333334, 95.0, 1.0, 2.0, 0.2531910068745251, 0.0, 2.0, 0.0, 1.0, 2.0, 0.512153427044754, 6.9112, 6.9112, 77.32846344354104, 577336.5339282686, 577336.5339282686, 179518.6009444576], 
processed observation next is [1.0, 0.30434782608695654, 0.628787878787879, 0.95, 1.0, 1.0, 0.06648875859315638, 0.0, 1.0, -0.25, 1.0, 1.0, 0.30307632434964854, 0.0, 0.0, 0.5084288129206541, 0.21382834589935873, 0.21382834589935873, 0.43785024620599416], 
reward next is 0.5621, 
noisyNet noise sample is [array([-0.11285251], dtype=float32), 0.37408522]. 
=============================================
[2019-03-23 17:39:59,131] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.1708219e-05 1.1260463e-14 9.9996829e-01 2.0372174e-15 5.2065872e-14], sum to 1.0000
[2019-03-23 17:39:59,141] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0703
[2019-03-23 17:39:59,149] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.2602192202997598, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5269205221798198, 6.9112, 6.9112, 77.32846344354104, 592517.5530709184, 592517.5530709184, 182255.8586952837], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3546000.0000, 
sim time next is 3546600.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.2598871247883741, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5262476575192631, 6.9112, 6.9112, 77.32846344354104, 591762.0347431514, 591762.0347431514, 182173.0542543191], 
processed observation next is [1.0, 0.043478260869565216, 0.6818181818181818, 0.89, 1.0, 1.0, 0.07485890598546763, 0.0, 1.0, -0.25, 1.0, 1.0, 0.32321093931323297, 0.0, 0.0, 0.5084288129206541, 0.21917112397894495, 0.21917112397894495, 0.44432452257151], 
reward next is 0.5557, 
noisyNet noise sample is [array([0.28376916], dtype=float32), -0.505506]. 
=============================================
[2019-03-23 17:39:59,830] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.71999660e-04 1.11057546e-13 9.99627948e-01 6.13066835e-13
 3.56147707e-12], sum to 1.0000
[2019-03-23 17:39:59,831] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0430
[2019-03-23 17:39:59,840] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.66666666666667, 90.66666666666667, 1.0, 2.0, 0.3398086190879264, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6880936964530712, 6.911200000000001, 6.9112, 77.32846344354104, 773852.8805099652, 773852.8805099649, 204792.9637329242], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3550800.0000, 
sim time next is 3551400.0000, 
raw observation next is [22.5, 91.5, 1.0, 2.0, 0.3140664820055807, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6358579826390283, 6.911200000000001, 6.9112, 77.32846344354104, 715460.6308036775, 715460.6308036771, 196611.3898689658], 
processed observation next is [1.0, 0.08695652173913043, 0.6590909090909091, 0.915, 1.0, 1.0, 0.14258310250697584, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4797971180557547, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2649854188161768, 0.2649854188161767, 0.4795399752901605], 
reward next is 0.5205, 
noisyNet noise sample is [array([-0.68158895], dtype=float32), 0.050417874]. 
=============================================
[2019-03-23 17:40:12,424] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 17:40:12,426] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:40:12,427] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:40:12,428] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:40:12,429] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:40:12,429] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:40:12,431] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:40:12,433] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:40:12,434] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:40:12,432] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:40:12,437] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:40:12,450] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run22
[2019-03-23 17:40:12,450] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run22
[2019-03-23 17:40:12,498] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run22
[2019-03-23 17:40:12,498] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run22
[2019-03-23 17:40:12,522] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run22
[2019-03-23 17:40:31,809] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00327471], dtype=float32), 0.0025953085]
[2019-03-23 17:40:31,812] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.8, 68.0, 1.0, 2.0, 0.3281997949377727, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6642227850874377, 6.911200000000001, 6.9112, 95.55338769695034, 748009.5583411906, 748009.5583411902, 205314.9989331228]
[2019-03-23 17:40:31,813] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:40:31,816] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.5130217e-06 1.4697877e-13 9.9999654e-01 5.3987820e-14 1.7417346e-13], sampled 0.5479294020755079
[2019-03-23 17:40:38,232] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00327471], dtype=float32), 0.0025953085]
[2019-03-23 17:40:38,233] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.73333333333333, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3456570147135363, 6.9112, 6.9112, 95.55338769695034, 397892.0265388371, 397892.0265388371, 157300.3200457431]
[2019-03-23 17:40:38,233] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:40:38,237] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.6276035e-07 7.4479020e-11 9.9999964e-01 5.5637911e-11 1.0060011e-11], sampled 0.20100548466439594
[2019-03-23 17:40:39,437] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00327471], dtype=float32), 0.0025953085]
[2019-03-23 17:40:39,440] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 100.0, 1.0, 2.0, 0.2060420849076304, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4094355628111139, 6.911199999999999, 6.9112, 77.32846344354104, 467660.4437566291, 467660.4437566294, 163460.1283505582]
[2019-03-23 17:40:39,442] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:40:39,444] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.2134842e-07 1.9356806e-11 9.9999940e-01 1.2087747e-11 4.2378115e-12], sampled 0.10260595542839324
[2019-03-23 17:40:43,814] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00327471], dtype=float32), 0.0025953085]
[2019-03-23 17:40:43,815] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.77371476666667, 77.568876995, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3558615325272594, 6.911200000000001, 6.9112, 95.55338769695034, 408916.5467132233, 408916.546713223, 159233.5227875968]
[2019-03-23 17:40:43,816] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:40:43,819] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.0029914e-07 3.1714350e-11 9.9999964e-01 2.0631372e-11 5.0331891e-12], sampled 0.5028991502241723
[2019-03-23 17:40:48,489] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00327471], dtype=float32), 0.0025953085]
[2019-03-23 17:40:48,490] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.73333333333333, 92.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 335378.1779925025, 335378.1779925025, 142206.1781614579]
[2019-03-23 17:40:48,494] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:40:48,498] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.403648e-07 8.669814e-10 9.999994e-01 7.287929e-10 8.294388e-11], sampled 0.12918845888291108
[2019-03-23 17:40:50,561] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00327471], dtype=float32), 0.0025953085]
[2019-03-23 17:40:50,565] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.026169615, 69.75104757, 1.0, 2.0, 0.2128586421737311, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4267400344426789, 6.9112, 6.9112, 95.55338769695034, 485085.2887140549, 485085.2887140549, 171700.4250886295]
[2019-03-23 17:40:50,565] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:40:50,567] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.1204606e-07 2.2094116e-11 9.9999964e-01 1.4158181e-11 3.8798929e-12], sampled 0.19462623212328634
[2019-03-23 17:41:13,935] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00327471], dtype=float32), 0.0025953085]
[2019-03-23 17:41:13,935] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.23333333333333, 70.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 291694.1408309677, 291694.1408309677, 124701.7927228606]
[2019-03-23 17:41:13,936] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:41:13,938] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.2906245e-07 5.7148875e-10 9.9999952e-01 4.8194354e-10 6.0298148e-11], sampled 0.6256599302606636
[2019-03-23 17:41:17,456] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00327471], dtype=float32), 0.0025953085]
[2019-03-23 17:41:17,458] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.482221125, 85.78493899, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3001229558478485, 6.911200000000001, 6.9112, 95.55338769695034, 348375.9624266575, 348375.9624266571, 148910.8838201054]
[2019-03-23 17:41:17,463] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:41:17,465] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.12910821e-07 1.09473146e-10 9.99999046e-01 7.12633910e-11
 1.97340616e-11], sampled 0.6142900287006487
[2019-03-23 17:41:25,693] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00327471], dtype=float32), 0.0025953085]
[2019-03-23 17:41:25,694] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.31666666666667, 61.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 322587.5662882514, 322587.5662882514, 142387.6571107541]
[2019-03-23 17:41:25,695] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:41:25,697] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.8370487e-07 4.5750201e-10 9.9999964e-01 3.8346434e-10 4.2835509e-11], sampled 0.39832433444978943
[2019-03-23 17:41:49,743] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2760.8185 2124029145.1415 757.0000
[2019-03-23 17:41:49,961] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3519.0325 2104095443.0865 178.0000
[2019-03-23 17:41:50,145] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3616.5303 2175217741.8813 245.0000
[2019-03-23 17:41:50,193] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3119.6236 2108993115.8876 368.0000
[2019-03-23 17:41:50,352] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3362.1704 2098038620.9528 179.0000
[2019-03-23 17:41:51,367] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 525000, evaluation results [525000.0, 3616.5302681563753, 2175217741.881281, 245.0, 3362.17043381659, 2098038620.9527724, 179.0, 3519.032511138161, 2104095443.0864863, 178.0, 2760.8185448033496, 2124029145.1415398, 757.0, 3119.6236072246406, 2108993115.887552, 368.0]
[2019-03-23 17:41:51,402] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.4294219e-06 1.2476519e-13 9.9999452e-01 7.0548758e-14 1.4396036e-13], sum to 1.0000
[2019-03-23 17:41:51,406] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4622
[2019-03-23 17:41:51,412] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 69.0, 1.0, 2.0, 0.4840628197344578, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9333305518457642, 6.960628247538112, 6.9112, 77.32833514013366, 1099187.614567811, 1083134.357385542, 242662.2869481004], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3770400.0000, 
sim time next is 3771000.0000, 
raw observation next is [23.0, 67.0, 1.0, 2.0, 0.4636551066499203, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9178359730299924, 6.919966403792405, 6.9112, 77.32840976194811, 1053893.637209135, 1051046.490537824, 236783.1926773943], 
processed observation next is [1.0, 0.6521739130434783, 0.6818181818181818, 0.67, 1.0, 1.0, 0.32956888331240036, 0.0, 1.0, -0.25, 1.0, 1.0, 0.882622818614275, 0.0008766403792405342, 0.0, 0.5084284599682307, 0.3903309767441241, 0.3892764779769719, 0.5775199821399861], 
reward next is 0.3786, 
noisyNet noise sample is [array([0.8021528], dtype=float32), -1.7392573]. 
=============================================
[2019-03-23 17:41:51,450] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[41.307034]
 [41.659924]
 [42.187008]
 [42.622845]
 [42.974762]], R is [[40.96755981]
 [40.71888351]
 [40.65809631]
 [40.54889679]
 [40.35285187]].
[2019-03-23 17:41:52,321] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.4313961e-08 1.5597922e-09 1.0000000e+00 8.7091817e-10 3.1499203e-11], sum to 1.0000
[2019-03-23 17:41:52,325] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5627
[2019-03-23 17:41:52,331] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.5, 84.83333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3278257722816227, 6.9112, 6.9112, 77.32846344354104, 378956.8321703812, 378956.8321703812, 149049.7163011938], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3786600.0000, 
sim time next is 3787200.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3253261798625737, 6.911200000000001, 6.9112, 77.32846344354104, 376289.4215244648, 376289.4215244645, 148539.000008254], 
processed observation next is [1.0, 0.8695652173913043, 0.45454545454545453, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.03618025694653384, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13936645241646844, 0.13936645241646833, 0.3622902439225707], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.25471234], dtype=float32), -0.4363848]. 
=============================================
[2019-03-23 17:41:52,857] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.8708922e-07 4.9978395e-09 9.9999964e-01 7.0678592e-09 6.7352193e-11], sum to 1.0000
[2019-03-23 17:41:52,863] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9788
[2019-03-23 17:41:52,867] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3276334846126824, 6.9112, 6.9112, 77.32846344354104, 379023.5013814045, 379023.5013814045, 148738.5556777383], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3789000.0000, 
sim time next is 3789600.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3255020848390554, 6.9112, 6.9112, 77.32846344354104, 376559.293360077, 376559.293360077, 148492.5480434922], 
processed observation next is [1.0, 0.8695652173913043, 0.45454545454545453, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.03643154977007917, 0.0, 0.0, 0.5084288129206541, 0.13946640494817666, 0.13946640494817666, 0.36217694644754195], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.02052094], dtype=float32), 0.7414282]. 
=============================================
[2019-03-23 17:41:54,692] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.3509653e-07 1.8540014e-09 9.9999928e-01 4.4167217e-09 3.7145292e-10], sum to 1.0000
[2019-03-23 17:41:54,699] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6310
[2019-03-23 17:41:54,713] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 321620.9117323952, 321620.9117323955, 139739.0179094021], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3822600.0000, 
sim time next is 3823200.0000, 
raw observation next is [17.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 321917.1719117411, 321917.1719117414, 139784.3837882024], 
processed observation next is [0.0, 0.2608695652173913, 0.4090909090909091, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11922858218953374, 0.11922858218953385, 0.34093752143464], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.10713617], dtype=float32), -1.1775928]. 
=============================================
[2019-03-23 17:41:55,003] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.9352897e-07 1.3961626e-09 9.9999940e-01 1.2161815e-08 1.9022436e-10], sum to 1.0000
[2019-03-23 17:41:55,009] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4999
[2019-03-23 17:41:55,015] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 59.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3374096568718503, 6.9112, 6.9112, 77.32846344354104, 388504.1827492064, 388504.1827492064, 151649.0703669388], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3858000.0000, 
sim time next is 3858600.0000, 
raw observation next is [23.0, 60.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3403186375350336, 6.9112, 6.9112, 77.32846344354104, 391643.0641936334, 391643.0641936334, 152198.95423319], 
processed observation next is [0.0, 0.6521739130434783, 0.6818181818181818, 0.6033333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0575980536214766, 0.0, 0.0, 0.5084288129206541, 0.14505298673838274, 0.14505298673838274, 0.37121696154436584], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6017515], dtype=float32), -1.0446646]. 
=============================================
[2019-03-23 17:42:00,117] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.53118401e-07 1.83347226e-09 9.99999762e-01 6.07748241e-10
 1.09737885e-10], sum to 1.0000
[2019-03-23 17:42:00,125] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8950
[2019-03-23 17:42:00,128] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3613410931767748, 6.9112, 6.9112, 77.32846344354104, 415054.7147312658, 415054.7147312658, 155504.8160366794], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4152000.0000, 
sim time next is 4152600.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3618261398848239, 6.911199999999999, 6.9112, 77.32846344354104, 415611.9021334493, 415611.9021334496, 155566.1238305374], 
processed observation next is [1.0, 0.043478260869565216, 0.45454545454545453, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.08832305697831992, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15393033412349974, 0.15393033412349985, 0.3794295703183839], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.96999556], dtype=float32), -1.3153335]. 
=============================================
[2019-03-23 17:42:04,833] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.7330890e-03 1.9510786e-14 9.9826694e-01 1.0650938e-13 1.6290939e-13], sum to 1.0000
[2019-03-23 17:42:04,839] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9453
[2019-03-23 17:42:04,843] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.300378170913027, 0.0, 2.0, 0.0, 1.0, 2.0, 0.590012036243978, 6.911199999999999, 6.9112, 77.32846344354104, 677176.4869474422, 677176.4869474425, 180504.5138807601], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4026000.0000, 
sim time next is 4026600.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3104251537548722, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6098223424845582, 6.9112, 6.9112, 77.32846344354104, 699899.3297363858, 699899.3297363858, 183033.4886250276], 
processed observation next is [1.0, 0.6086956521739131, 0.45454545454545453, 1.0, 1.0, 1.0, 0.1380314421935902, 0.0, 1.0, -0.25, 1.0, 1.0, 0.44260334640651183, 0.0, 0.0, 0.5084288129206541, 0.2592219739764392, 0.2592219739764392, 0.44642314298787217], 
reward next is 0.5536, 
noisyNet noise sample is [array([-0.21726896], dtype=float32), 1.6552641]. 
=============================================
[2019-03-23 17:42:07,416] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.6930744e-05 1.1366947e-11 9.9990308e-01 1.5943421e-12 1.0392927e-11], sum to 1.0000
[2019-03-23 17:42:07,424] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6896
[2019-03-23 17:42:07,427] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.83333333333333, 94.0, 1.0, 2.0, 0.3120375411831459, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6141460349119474, 6.911200000000001, 6.9112, 77.32846344354104, 704390.4895225094, 704390.4895225092, 183971.0862201722], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4092600.0000, 
sim time next is 4093200.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.3132596588808451, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6180712867616796, 6.911200000000001, 6.9112, 77.32846344354104, 708244.1286991709, 708244.1286991707, 184997.7639123295], 
processed observation next is [1.0, 0.391304347826087, 0.5, 0.94, 1.0, 1.0, 0.14157457360105638, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4543875525166851, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2623126402589522, 0.2623126402589521, 0.4512140583227549], 
reward next is 0.5488, 
noisyNet noise sample is [array([1.268233], dtype=float32), -0.7347843]. 
=============================================
[2019-03-23 17:42:07,531] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4664191e-06 5.6900689e-09 9.9999750e-01 2.3419306e-09 1.4143205e-10], sum to 1.0000
[2019-03-23 17:42:07,538] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9080
[2019-03-23 17:42:07,544] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 330918.5320789242, 330918.5320789239, 141608.2042156871], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4064400.0000, 
sim time next is 4065000.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 330734.7363008813, 330734.7363008813, 141579.5244111236], 
processed observation next is [1.0, 0.043478260869565216, 0.36363636363636365, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.1224943467781042, 0.1224943467781042, 0.3453159131978624], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.17078964], dtype=float32), 1.9339819]. 
=============================================
[2019-03-23 17:42:07,557] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[ 9.25941 ]
 [10.040053]
 [ 8.726369]
 [ 8.955007]
 [ 8.290842]], R is [[9.75217819]
 [9.65465641]
 [9.55811024]
 [9.46252918]
 [9.36790371]].
[2019-03-23 17:42:09,212] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.0140406e-05 1.0810172e-11 9.9992990e-01 1.6570578e-11 1.0268836e-10], sum to 1.0000
[2019-03-23 17:42:09,218] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2252
[2019-03-23 17:42:09,225] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.66666666666667, 96.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3764866981021715, 6.9112, 6.9112, 77.32846344354104, 431861.8548611071, 431861.8548611071, 157967.8373148996], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4324800.0000, 
sim time next is 4325400.0000, 
raw observation next is [18.5, 97.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.375065881258746, 6.9112, 6.9112, 77.32846344354104, 430358.7715125659, 430358.7715125659, 157670.1295042128], 
processed observation next is [1.0, 0.043478260869565216, 0.4772727272727273, 0.97, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.10723697322678004, 0.0, 0.0, 0.5084288129206541, 0.15939213759724663, 0.15939213759724663, 0.3845612914736897], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.14567482], dtype=float32), 0.51720804]. 
=============================================
[2019-03-23 17:42:10,862] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.3169790e-08 5.5534166e-10 1.0000000e+00 6.3076017e-10 1.3990730e-11], sum to 1.0000
[2019-03-23 17:42:10,871] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7477
[2019-03-23 17:42:10,877] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.66666666666667, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3582402719724549, 6.911200000000001, 6.9112, 77.32846344354104, 412103.2570936999, 412103.2570936996, 154552.3626304679], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4159200.0000, 
sim time next is 4159800.0000, 
raw observation next is [17.5, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3486262388130884, 6.9112, 6.9112, 77.32846344354104, 401428.1944279697, 401428.1944279697, 153001.0908256728], 
processed observation next is [1.0, 0.13043478260869565, 0.4318181818181818, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.06946605544726918, 0.0, 0.0, 0.5084288129206541, 0.14867710904739617, 0.14867710904739617, 0.37317339225773855], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.24164207], dtype=float32), -0.15501982]. 
=============================================
[2019-03-23 17:42:12,202] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.3926713e-07 6.3391870e-10 9.9999964e-01 9.3864587e-09 7.4273185e-11], sum to 1.0000
[2019-03-23 17:42:12,209] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8190
[2019-03-23 17:42:12,213] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3596081321675689, 6.911199999999999, 6.9112, 77.32846344354104, 413067.1521608254, 413067.1521608257, 155283.2583687766], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4158000.0000, 
sim time next is 4158600.0000, 
raw observation next is [17.83333333333333, 100.0, 1.0, 2.0, 0.2010917168921328, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3930384109606611, 6.911199999999999, 6.9112, 77.32846344354104, 451747.9092222716, 451747.9092222719, 159244.2157254566], 
processed observation next is [1.0, 0.13043478260869565, 0.44696969696969674, 1.0, 1.0, 1.0, 0.0013646461151659711, 0.0, 1.0, -0.25, 1.0, 1.0, 0.13291201565808733, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16731404045269319, 0.1673140404526933, 0.38840052615965026], 
reward next is 0.6116, 
noisyNet noise sample is [array([0.43996948], dtype=float32), 1.2039185]. 
=============================================
[2019-03-23 17:42:19,316] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.6070051e-07 3.4792686e-11 9.9999964e-01 2.6915924e-11 1.2662079e-11], sum to 1.0000
[2019-03-23 17:42:19,328] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0578
[2019-03-23 17:42:19,332] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.08333333333334, 49.33333333333334, 1.0, 2.0, 0.6941819022445432, 0.0, 2.0, 0.0, 1.0, 2.0, 0.963899590785476, 6.911199999999999, 6.9112, 78.26345941519878, 1340031.40382526, 1340031.40382526, 277210.172176568], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4288200.0000, 
sim time next is 4288800.0000, 
raw observation next is [27.06666666666667, 49.66666666666667, 1.0, 2.0, 0.6365654731203533, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9641675400933881, 6.911200000000001, 6.9112, 77.32846344343594, 1274362.9931308, 1274362.9931308, 269352.505074122], 
processed observation next is [1.0, 0.6521739130434783, 0.8666666666666668, 0.4966666666666667, 1.0, 1.0, 0.5457068414004416, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9488107715619832, 8.881784197001253e-17, 0.0, 0.5084288129199631, 0.4719862937521482, 0.4719862937521482, 0.656957329449078], 
reward next is 0.3430, 
noisyNet noise sample is [array([-0.0259038], dtype=float32), -2.6162925]. 
=============================================
[2019-03-23 17:42:19,810] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.6618789e-07 7.2148863e-11 9.9999964e-01 2.3250025e-11 3.1100803e-12], sum to 1.0000
[2019-03-23 17:42:19,821] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4887
[2019-03-23 17:42:19,827] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 94.00000000000001, 1.0, 2.0, 0.2207807863390635, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4277316634484032, 6.9112, 6.9112, 77.32846344354104, 492947.9920616227, 492947.9920616227, 160960.308499249], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4331400.0000, 
sim time next is 4332000.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.2037602330946246, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3947668512810827, 6.9112, 6.9112, 77.32846344354104, 454935.9687244, 454935.9687244, 158140.32314528], 
processed observation next is [1.0, 0.13043478260869565, 0.45454545454545453, 0.94, 1.0, 1.0, 0.004700291368280735, 0.0, 1.0, -0.25, 1.0, 1.0, 0.13538121611583243, 0.0, 0.0, 0.5084288129206541, 0.16849480323125926, 0.16849480323125926, 0.38570810523239024], 
reward next is 0.6143, 
noisyNet noise sample is [array([0.4330655], dtype=float32), -1.2050278]. 
=============================================
[2019-03-23 17:42:19,842] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[14.998165]
 [14.043745]
 [12.989801]
 [12.694122]
 [13.582816]], R is [[16.10350227]
 [16.54988098]
 [16.38438225]
 [16.22053909]
 [16.05833435]].
[2019-03-23 17:42:22,849] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.63021193e-07 1.49460271e-11 9.99999046e-01 1.13520365e-13
 8.77666375e-13], sum to 1.0000
[2019-03-23 17:42:22,857] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4603
[2019-03-23 17:42:22,860] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.5, 67.16666666666667, 1.0, 2.0, 0.5562493458356779, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9694358318558131, 6.91538773895746, 6.9112, 77.32842729872247, 1182786.872676126, 1181426.781352551, 266089.8556090759], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4355400.0000, 
sim time next is 4356000.0000, 
raw observation next is [26.0, 65.0, 1.0, 2.0, 0.5723489266526941, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9726258344834262, 6.911200000000001, 6.9112, 77.32846076712832, 1200926.839079806, 1200926.839079805, 269434.0103418983], 
processed observation next is [1.0, 0.43478260869565216, 0.8181818181818182, 0.65, 1.0, 1.0, 0.4654361583158676, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9608940492620375, 8.881784197001253e-17, 0.0, 0.5084287953234424, 0.44478771817770596, 0.4447877181777055, 0.6571561227851178], 
reward next is 0.3428, 
noisyNet noise sample is [array([1.3499482], dtype=float32), 0.18940006]. 
=============================================
[2019-03-23 17:42:22,877] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[27.190228]
 [27.384321]
 [27.838104]
 [28.548595]
 [29.592918]], R is [[26.88559532]
 [26.94680023]
 [26.84412575]
 [26.99804497]
 [27.13738441]].
[2019-03-23 17:42:23,495] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5015652e-05 2.2347919e-11 9.9998498e-01 1.1008190e-11 4.7315212e-12], sum to 1.0000
[2019-03-23 17:42:23,505] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3044
[2019-03-23 17:42:23,510] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 65.0, 1.0, 2.0, 0.2440574858444729, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4933087436799934, 6.9112, 6.9112, 77.32846344354104, 556751.18094839, 556751.18094839, 176880.037697398], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4392000.0000, 
sim time next is 4392600.0000, 
raw observation next is [25.71666666666667, 66.16666666666667, 1.0, 2.0, 0.2444287828478776, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4939636459050986, 6.9112, 6.9112, 77.32846344354104, 557643.9623406285, 557643.9623406285, 176844.9032053505], 
processed observation next is [1.0, 0.8695652173913043, 0.8053030303030304, 0.6616666666666667, 1.0, 1.0, 0.055535978559847, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2770909227215695, 0.0, 0.0, 0.5084288129206541, 0.20653480086689943, 0.20653480086689943, 0.431329032208172], 
reward next is 0.5687, 
noisyNet noise sample is [array([-0.34874597], dtype=float32), 1.5842009]. 
=============================================
[2019-03-23 17:42:34,524] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.1526240e-07 5.2486806e-09 9.9999952e-01 7.6141262e-09 2.3111470e-10], sum to 1.0000
[2019-03-23 17:42:34,532] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7127
[2019-03-23 17:42:34,541] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.66666666666667, 78.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 310694.6136397364, 310694.6136397364, 130489.878881047], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4573200.0000, 
sim time next is 4573800.0000, 
raw observation next is [17.5, 79.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 307682.824689093, 307682.824689093, 128821.8729566778], 
processed observation next is [0.0, 0.9565217391304348, 0.4318181818181818, 0.795, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.11395660173670111, 0.11395660173670111, 0.31419969013823856], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5651672], dtype=float32), 1.5679278]. 
=============================================
[2019-03-23 17:42:36,283] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.3559738e-05 1.0462623e-12 9.9997640e-01 2.7894527e-12 8.8534104e-11], sum to 1.0000
[2019-03-23 17:42:36,291] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3221
[2019-03-23 17:42:36,294] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.33333333333334, 58.66666666666666, 1.0, 2.0, 0.2674423903470624, 0.0, 2.0, 0.0, 1.0, 2.0, 0.499256352564536, 6.911200000000001, 6.9112, 77.32846344354104, 580958.2498231614, 580958.249823161, 160283.2563553504], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4617600.0000, 
sim time next is 4618200.0000, 
raw observation next is [20.66666666666666, 57.33333333333334, 1.0, 2.0, 0.2730906205460508, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5098003609542769, 6.9112, 6.9112, 77.32846344354104, 593235.2432798689, 593235.2432798689, 162984.5347636836], 
processed observation next is [1.0, 0.43478260869565216, 0.5757575757575755, 0.5733333333333335, 1.0, 1.0, 0.09136327568256351, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2997148013632528, 0.0, 0.0, 0.5084288129206541, 0.2197167567703218, 0.2197167567703218, 0.3975232555211795], 
reward next is 0.6025, 
noisyNet noise sample is [array([-0.04153789], dtype=float32), -0.68588686]. 
=============================================
[2019-03-23 17:42:40,351] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.7373710e-06 1.8670121e-11 9.9999726e-01 3.4287102e-12 1.1200117e-12], sum to 1.0000
[2019-03-23 17:42:40,366] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1573
[2019-03-23 17:42:40,373] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.0, 54.0, 1.0, 2.0, 0.3813661448717717, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7453258314111717, 6.9112, 6.9112, 77.32846344354104, 857038.042241896, 857038.042241896, 201195.8954283948], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4708800.0000, 
sim time next is 4709400.0000, 
raw observation next is [24.33333333333333, 53.5, 1.0, 2.0, 0.3619747710879287, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7097046157875041, 6.911200000000001, 6.9112, 77.32846344354104, 815179.6159759137, 815179.6159759134, 196472.8698567964], 
processed observation next is [1.0, 0.5217391304347826, 0.7424242424242422, 0.535, 1.0, 1.0, 0.20246846385991085, 0.0, 1.0, -0.25, 1.0, 1.0, 0.585292308267863, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.30191837628737545, 0.30191837628737533, 0.4792021216019424], 
reward next is 0.5208, 
noisyNet noise sample is [array([-1.4279861], dtype=float32), -0.2196306]. 
=============================================
[2019-03-23 17:42:41,224] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 17:42:41,225] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:42:41,225] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:42:41,225] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:42:41,226] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:42:41,226] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:42:41,227] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:42:41,227] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:42:41,229] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:42:41,229] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:42:41,231] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:42:41,246] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run23
[2019-03-23 17:42:41,270] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run23
[2019-03-23 17:42:41,294] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run23
[2019-03-23 17:42:41,296] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run23
[2019-03-23 17:42:41,347] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run23
[2019-03-23 17:42:48,422] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00377542], dtype=float32), 0.0028293964]
[2019-03-23 17:42:48,422] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [14.76666666666667, 71.5, 1.0, 2.0, 0.2029263535182625, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3788190457214935, 6.911200000000001, 6.9112, 95.55338769695034, 440710.0859049698, 440710.0859049694, 130240.5921123492]
[2019-03-23 17:42:48,423] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:42:48,425] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.8394229e-06 1.0423769e-10 9.9999714e-01 7.0740656e-11 2.8008037e-11], sampled 0.27197316610456745
[2019-03-23 17:43:18,597] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00377542], dtype=float32), 0.0028293964]
[2019-03-23 17:43:18,600] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.73333333333333, 72.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.386121721948902, 6.9112, 6.9112, 95.55338769695034, 442648.8606622123, 442648.8606622123, 164063.4434669365]
[2019-03-23 17:43:18,601] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:43:18,603] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.1280634e-07 4.8710539e-11 9.9999905e-01 3.4929639e-11 9.4480673e-12], sampled 0.5435664353046893
[2019-03-23 17:43:28,108] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00377542], dtype=float32), 0.0028293964]
[2019-03-23 17:43:28,109] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.7, 64.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 278745.5173019752, 278745.5173019748, 117823.5114676154]
[2019-03-23 17:43:28,110] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:43:28,113] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.4623360e-07 1.2060996e-09 9.9999917e-01 1.0700807e-09 1.2292375e-10], sampled 0.25728211458086936
[2019-03-23 17:43:29,245] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00377542], dtype=float32), 0.0028293964]
[2019-03-23 17:43:29,246] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 94.0, 1.0, 2.0, 0.3758329998422571, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7605688205785313, 6.9112, 6.9112, 77.32846344354104, 856869.605544607, 856869.605544607, 215932.0764485778]
[2019-03-23 17:43:29,247] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:43:29,250] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.8083855e-06 4.7327225e-13 9.9999714e-01 2.3109970e-13 3.6154605e-13], sampled 0.9210290029159636
[2019-03-23 17:43:34,712] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00377542], dtype=float32), 0.0028293964]
[2019-03-23 17:43:34,714] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.8, 55.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3911893560861799, 6.9112, 6.9112, 95.55338769695034, 447999.8181839533, 447999.8181839533, 165140.9257805594]
[2019-03-23 17:43:34,714] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:43:34,717] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.6801995e-07 4.9153414e-11 9.9999964e-01 3.9033131e-11 6.2892968e-12], sampled 0.1991395360835415
[2019-03-23 17:43:37,494] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00377542], dtype=float32), 0.0028293964]
[2019-03-23 17:43:37,495] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [28.96666666666667, 53.0, 1.0, 2.0, 0.2625031505663881, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5315314897076783, 6.911200000000001, 6.9112, 95.55338769695034, 597688.8462444047, 597688.8462444043, 187523.985397569]
[2019-03-23 17:43:37,496] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:43:37,498] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.0077738e-07 2.4024259e-12 9.9999928e-01 1.5053451e-12 7.3619360e-13], sampled 0.5663380026982976
[2019-03-23 17:43:42,350] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00377542], dtype=float32), 0.0028293964]
[2019-03-23 17:43:42,350] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.0, 73.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 294615.6330454065, 294615.6330454062, 121749.5140547578]
[2019-03-23 17:43:42,352] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:43:42,356] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.2839933e-07 1.0830788e-09 9.9999940e-01 9.9252706e-10 9.6441105e-11], sampled 0.9816057996930254
[2019-03-23 17:43:55,673] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00377542], dtype=float32), 0.0028293964]
[2019-03-23 17:43:55,674] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.23333333333333, 87.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3149215766916021, 6.911200000000001, 6.9112, 95.55338769695034, 364005.79966548, 364005.7996654796, 152124.7398804075]
[2019-03-23 17:43:55,676] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:43:55,680] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.2270261e-07 1.2337872e-10 9.9999905e-01 9.3852627e-11 1.9389317e-11], sampled 0.9846655123424963
[2019-03-23 17:43:55,765] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00377542], dtype=float32), 0.0028293964]
[2019-03-23 17:43:55,767] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.73333333333333, 75.66666666666667, 1.0, 2.0, 0.2130304959935554, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4160673286291612, 6.9112, 6.9112, 95.55338769695034, 478297.0196864051, 478297.0196864051, 165783.0981643367]
[2019-03-23 17:43:55,767] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:43:55,773] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.13999613e-06 1.44290725e-11 9.99998808e-01 9.27738181e-12
 3.77950882e-12], sampled 0.3348100928045381
[2019-03-23 17:44:01,828] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00377542], dtype=float32), 0.0028293964]
[2019-03-23 17:44:01,829] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.83333333333334, 67.33333333333334, 1.0, 2.0, 0.2309815364890929, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4564210782570093, 6.911200000000001, 6.9112, 95.55338769695034, 522550.0165617912, 522550.0165617909, 171502.7341108781]
[2019-03-23 17:44:01,829] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:44:01,831] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.7171495e-06 9.3837473e-12 9.9999833e-01 5.6654716e-12 3.2423797e-12], sampled 0.9272350653607325
[2019-03-23 17:44:17,978] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3118.8146 2109022190.6825 368.0000
[2019-03-23 17:44:18,139] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2760.0075 2124051796.3784 757.0000
[2019-03-23 17:44:18,599] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3614.8988 2175275000.0721 245.0000
[2019-03-23 17:44:18,681] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3519.7500 2104086892.6632 178.0000
[2019-03-23 17:44:18,725] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3362.1468 2098045794.0882 179.0000
[2019-03-23 17:44:19,739] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 550000, evaluation results [550000.0, 3614.898849097424, 2175275000.072144, 245.0, 3362.1468120720647, 2098045794.0881922, 179.0, 3519.749992870858, 2104086892.6631973, 178.0, 2760.0074851005825, 2124051796.3784225, 757.0, 3118.8146269445274, 2109022190.6824877, 368.0]
[2019-03-23 17:44:29,535] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.1781023e-05 2.6270013e-13 9.9996817e-01 1.5011171e-13 6.0887710e-12], sum to 1.0000
[2019-03-23 17:44:29,542] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5820
[2019-03-23 17:44:29,545] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.83333333333334, 73.83333333333334, 1.0, 2.0, 0.4394519762856096, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8808295009041898, 6.911200000000001, 6.9112, 77.32846344354104, 1002021.787179741, 1002021.787179741, 232097.3846927704], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4896600.0000, 
sim time next is 4897200.0000, 
raw observation next is [22.66666666666667, 74.66666666666667, 1.0, 2.0, 0.4108632255827624, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8231255667815606, 6.9112, 6.9112, 77.32846344354104, 936601.2616805686, 936601.2616805686, 221169.5126781734], 
processed observation next is [1.0, 0.6956521739130435, 0.6666666666666669, 0.7466666666666667, 1.0, 1.0, 0.26357903197845295, 0.0, 1.0, -0.25, 1.0, 1.0, 0.7473222382593724, 0.0, 0.0, 0.5084288129206541, 0.3468893561779884, 0.3468893561779884, 0.5394378358004229], 
reward next is 0.4606, 
noisyNet noise sample is [array([1.0688555], dtype=float32), 0.2012717]. 
=============================================
[2019-03-23 17:44:31,255] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.7375847e-06 5.0291677e-11 9.9999523e-01 4.1616654e-12 2.1526383e-11], sum to 1.0000
[2019-03-23 17:44:31,260] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0402
[2019-03-23 17:44:31,264] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3662091354748007, 6.911200000000001, 6.9112, 77.32846344354104, 420634.8369124052, 420634.8369124049, 156132.8253888616], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4929600.0000, 
sim time next is 4930200.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.365134652352389, 6.9112, 6.9112, 77.32846344354104, 419403.20342704, 419403.20342704, 155993.8372650989], 
processed observation next is [1.0, 0.043478260869565216, 0.45454545454545453, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.09304950336055576, 0.0, 0.0, 0.5084288129206541, 0.1553345197877926, 0.1553345197877926, 0.3804727738173144], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.27405187], dtype=float32), 0.44153154]. 
=============================================
[2019-03-23 17:44:43,657] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.7786717e-05 5.1166995e-15 9.9992216e-01 5.4045412e-14 4.7997522e-14], sum to 1.0000
[2019-03-23 17:44:43,672] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4283
[2019-03-23 17:44:43,678] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 83.0, 1.0, 2.0, 0.2386824669273895, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4820471503899647, 6.911199999999999, 6.9112, 77.32846344354104, 544631.5657569236, 544631.5657569239, 175197.2018615576], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5175000.0000, 
sim time next is 5175600.0000, 
raw observation next is [23.0, 83.0, 1.0, 2.0, 0.2389825532547875, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4826538030538352, 6.9112, 6.9112, 77.32846344354104, 545316.5398360774, 545316.5398360774, 175264.2400099273], 
processed observation next is [0.0, 0.9130434782608695, 0.6818181818181818, 0.83, 1.0, 1.0, 0.048728191568484375, 0.0, 1.0, -0.25, 1.0, 1.0, 0.26093400436262176, 0.0, 0.0, 0.5084288129206541, 0.2019690888281768, 0.2019690888281768, 0.4274737561217739], 
reward next is 0.5725, 
noisyNet noise sample is [array([1.0287603], dtype=float32), -0.87052286]. 
=============================================
[2019-03-23 17:44:45,129] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8618014e-04 2.7694798e-13 9.9981385e-01 5.9829088e-15 2.1191328e-13], sum to 1.0000
[2019-03-23 17:44:45,134] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3598
[2019-03-23 17:44:45,139] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.6, 83.66666666666667, 1.0, 2.0, 0.234220125557354, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4723278934851179, 6.911199999999999, 6.9112, 77.32846344354104, 534525.2261612942, 534525.2261612944, 173490.073828344], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5179200.0000, 
sim time next is 5179800.0000, 
raw observation next is [22.5, 83.83333333333333, 1.0, 2.0, 0.2326407239558106, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4689290827201787, 6.9112, 6.9112, 77.32846344354104, 530912.0444681387, 530912.0444681387, 172951.2636919135], 
processed observation next is [0.0, 0.9565217391304348, 0.6590909090909091, 0.8383333333333333, 1.0, 1.0, 0.040800904944763225, 0.0, 1.0, -0.25, 1.0, 1.0, 0.24132726102882673, 0.0, 0.0, 0.5084288129206541, 0.19663409054375508, 0.19663409054375508, 0.4218323504680817], 
reward next is 0.5782, 
noisyNet noise sample is [array([1.5204947], dtype=float32), -1.830885]. 
=============================================
[2019-03-23 17:44:45,757] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.4040881e-05 1.1075873e-13 9.9997592e-01 3.5202210e-13 1.8545495e-12], sum to 1.0000
[2019-03-23 17:44:45,765] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4736
[2019-03-23 17:44:45,769] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.66666666666667, 84.66666666666667, 1.0, 2.0, 0.2554949742658446, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5125816373104944, 6.9112, 6.9112, 77.32846344354104, 582506.7669803014, 582506.7669803014, 176171.5914819057], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5192400.0000, 
sim time next is 5193000.0000, 
raw observation next is [21.5, 85.5, 1.0, 2.0, 0.2273089092039021, 0.0, 2.0, 0.0, 1.0, 2.0, 0.455627989275724, 6.911200000000001, 6.9112, 77.32846344354104, 518049.1965510637, 518049.1965510634, 169818.9275586043], 
processed observation next is [1.0, 0.08695652173913043, 0.6136363636363636, 0.855, 1.0, 1.0, 0.0341361365048776, 0.0, 1.0, -0.25, 1.0, 1.0, 0.22232569896532003, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19187007279669024, 0.19187007279669013, 0.4141925062404983], 
reward next is 0.5858, 
noisyNet noise sample is [array([0.13609174], dtype=float32), 0.40509278]. 
=============================================
[2019-03-23 17:44:45,784] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[55.467487]
 [55.960743]
 [55.014248]
 [55.74687 ]
 [54.821903]], R is [[55.99195862]
 [56.00235367]
 [55.97478485]
 [56.00429535]
 [56.03340912]].
[2019-03-23 17:44:48,372] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.2857088e-05 2.1957862e-14 9.9990714e-01 2.7453586e-14 5.8393554e-15], sum to 1.0000
[2019-03-23 17:44:48,377] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4758
[2019-03-23 17:44:48,381] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.249409347134152, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5045800094594849, 6.9112, 6.9112, 77.32846344354104, 568635.3628136634, 568635.3628136634, 178747.0072162131], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5259000.0000, 
sim time next is 5259600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.2498096544131257, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5053903863362932, 6.9112, 6.9112, 77.32846344354104, 569548.0433155935, 569548.0433155935, 178841.5183634444], 
processed observation next is [1.0, 0.9130434782608695, 0.6363636363636364, 0.94, 1.0, 1.0, 0.0622620680164071, 0.0, 1.0, -0.25, 1.0, 1.0, 0.293414837623276, 0.0, 0.0, 0.5084288129206541, 0.2109437197465161, 0.2109437197465161, 0.4361988252766936], 
reward next is 0.5638, 
noisyNet noise sample is [array([1.5953039], dtype=float32), -0.5606293]. 
=============================================
[2019-03-23 17:44:56,332] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.4418139e-05 1.7746245e-11 9.9995553e-01 4.3485228e-12 6.1795304e-12], sum to 1.0000
[2019-03-23 17:44:56,338] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0432
[2019-03-23 17:44:56,344] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.4, 71.0, 1.0, 2.0, 0.5221533012269526, 0.0, 2.0, 0.0, 1.0, 2.0, 0.955792499143018, 6.936277698549043, 6.9112, 77.32840192392811, 1144184.819444893, 1136040.102363438, 258107.0790580525], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5410800.0000, 
sim time next is 5411400.0000, 
raw observation next is [23.66666666666666, 74.16666666666667, 1.0, 2.0, 0.5072129806092492, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9489760038973468, 6.945440604608311, 6.9112, 77.3283641382666, 1127252.557515445, 1116131.923761289, 253884.7773408564], 
processed observation next is [1.0, 0.6521739130434783, 0.7121212121212118, 0.7416666666666667, 1.0, 1.0, 0.3840162257615615, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9271085769962099, 0.003424060460831058, 0.0, 0.5084281599959669, 0.41750094722794256, 0.4133821939856626, 0.6192311642459912], 
reward next is 0.2096, 
noisyNet noise sample is [array([1.3249849], dtype=float32), 0.13990687]. 
=============================================
[2019-03-23 17:44:58,716] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0150657e-08 8.6313866e-11 1.0000000e+00 1.8218044e-10 4.5963320e-12], sum to 1.0000
[2019-03-23 17:44:58,728] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3280
[2019-03-23 17:44:58,732] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.8, 93.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3663347432332751, 6.9112, 6.9112, 77.32846344354104, 420732.5042392994, 420732.5042392994, 156191.0743640676], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5445600.0000, 
sim time next is 5446200.0000, 
raw observation next is [18.8, 93.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3656677105451069, 6.9112, 6.9112, 77.32846344354104, 419967.6652951904, 419967.6652951904, 156104.9986788093], 
processed observation next is [1.0, 0.0, 0.49090909090909096, 0.93, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.09381101506443842, 0.0, 0.0, 0.5084288129206541, 0.1555435797389594, 0.1555435797389594, 0.380743899216608], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.19165446], dtype=float32), 1.7434994]. 
=============================================
[2019-03-23 17:45:05,096] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.4436695e-06 3.6873148e-15 9.9999356e-01 1.7149569e-15 5.0823595e-15], sum to 1.0000
[2019-03-23 17:45:05,105] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8801
[2019-03-23 17:45:05,109] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.5, 90.0, 1.0, 2.0, 0.2075715191831302, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4140944082109681, 6.9112, 6.9112, 77.32846344354104, 472083.086276988, 472083.086276988, 164691.8694732045], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5554200.0000, 
sim time next is 5554800.0000, 
raw observation next is [20.5, 90.0, 1.0, 2.0, 0.2084705990577414, 0.0, 2.0, 0.0, 1.0, 2.0, 0.415883088294055, 6.911200000000001, 6.9112, 77.32846344354104, 474126.1646926983, 474126.164692698, 164852.1821724604], 
processed observation next is [1.0, 0.30434782608695654, 0.5681818181818182, 0.9, 1.0, 1.0, 0.010588248822176738, 0.0, 1.0, -0.25, 1.0, 1.0, 0.16554726899150718, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17560228321951787, 0.17560228321951776, 0.4020784931035619], 
reward next is 0.5979, 
noisyNet noise sample is [array([-1.0964375], dtype=float32), -0.4702892]. 
=============================================
[2019-03-23 17:45:07,300] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1311339e-07 2.7337163e-13 9.9999988e-01 2.1074046e-14 3.2721903e-14], sum to 1.0000
[2019-03-23 17:45:07,305] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5702
[2019-03-23 17:45:07,309] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.45, 56.5, 1.0, 2.0, 0.8115869461397975, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9725176793158234, 6.911200000000001, 6.9112, 77.32846344354104, 1474176.201791707, 1474176.201791707, 304769.499576182], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5589000.0000, 
sim time next is 5589600.0000, 
raw observation next is [27.73333333333333, 56.0, 1.0, 2.0, 0.8288971720207294, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9734362980093417, 6.911199999999999, 6.9112, 77.32846344354104, 1493453.721365167, 1493453.721365168, 308683.7379266549], 
processed observation next is [1.0, 0.6956521739130435, 0.8969696969696969, 0.56, 1.0, 1.0, 0.7861214650259118, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9620518542990598, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5531310079130248, 0.5531310079130252, 0.7528871656747681], 
reward next is 0.2471, 
noisyNet noise sample is [array([0.04273298], dtype=float32), -1.0578585]. 
=============================================
[2019-03-23 17:45:09,780] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 17:45:09,782] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:45:09,784] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:45:09,785] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:45:09,785] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:45:09,785] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:45:09,787] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:45:09,788] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:45:09,790] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:45:09,789] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:45:09,791] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:45:09,807] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run24
[2019-03-23 17:45:09,808] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run24
[2019-03-23 17:45:09,855] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run24
[2019-03-23 17:45:09,878] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run24
[2019-03-23 17:45:09,912] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run24
[2019-03-23 17:45:48,139] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00491553], dtype=float32), 0.002690199]
[2019-03-23 17:45:48,141] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.87165608333333, 72.264350445, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3578450796245364, 6.911199999999999, 6.9112, 95.55338769695034, 412135.3451511833, 412135.3451511836, 158619.6090454859]
[2019-03-23 17:45:48,143] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:45:48,147] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.4902876e-09 4.8262332e-11 1.0000000e+00 6.2914382e-11 1.4616415e-12], sampled 0.983961161552895
[2019-03-23 17:45:54,733] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00491553], dtype=float32), 0.002690199]
[2019-03-23 17:45:54,734] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.8, 60.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3523344031418437, 6.9112, 6.9112, 95.55338769695034, 405568.7476375022, 405568.7476375022, 158137.2287648655]
[2019-03-23 17:45:54,735] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:45:54,739] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.8424622e-08 2.4292751e-10 1.0000000e+00 3.2325270e-10 7.0506166e-12], sampled 0.13809164501530014
[2019-03-23 17:45:55,078] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00491553], dtype=float32), 0.002690199]
[2019-03-23 17:45:55,079] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.5, 62.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3152956713096057, 6.911199999999999, 6.9112, 77.32846344354104, 364803.6458380651, 364803.6458380654, 147279.9745632521]
[2019-03-23 17:45:55,079] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:45:55,080] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.7481816e-08 2.3505999e-09 9.9999988e-01 3.3005496e-09 9.4813497e-11], sampled 0.07396670951955975
[2019-03-23 17:46:07,754] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00491553], dtype=float32), 0.002690199]
[2019-03-23 17:46:07,755] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.02860431166667, 78.33287252666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3402299800952089, 6.9112, 6.9112, 95.55338769695034, 393440.4987308418, 393440.4987308418, 154906.5165685839]
[2019-03-23 17:46:07,755] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:46:07,758] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.0719982e-09 4.0011106e-11 1.0000000e+00 5.2587892e-11 1.2768813e-12], sampled 0.2493026306721614
[2019-03-23 17:46:36,101] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00491553], dtype=float32), 0.002690199]
[2019-03-23 17:46:36,102] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [29.14531480666667, 60.92119301333334, 1.0, 2.0, 0.2824369268090889, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5711121729832519, 6.9112, 6.9112, 95.55338769695034, 636591.3222184747, 636591.3222184747, 195940.9043158646]
[2019-03-23 17:46:36,103] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:46:36,107] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.6763366e-08 4.3106790e-12 1.0000000e+00 4.4738553e-12 3.2427050e-13], sampled 0.7309044067909803
[2019-03-23 17:46:39,182] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00491553], dtype=float32), 0.002690199]
[2019-03-23 17:46:39,183] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [14.5, 88.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 95.55338769695034, 261711.6685810806, 261711.6685810809, 107711.2004877353]
[2019-03-23 17:46:39,185] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:46:39,189] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.815163e-08 2.216290e-09 9.999999e-01 3.038087e-09 8.920965e-11], sampled 0.660875328448057
[2019-03-23 17:46:39,613] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00491553], dtype=float32), 0.002690199]
[2019-03-23 17:46:39,615] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.65, 51.5, 1.0, 2.0, 0.2146428748205561, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4006912244797723, 6.911200000000001, 6.9112, 95.55338769695034, 466165.5875991893, 466165.5875991889, 154944.3012167895]
[2019-03-23 17:46:39,616] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:46:39,620] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.7963931e-08 1.3374164e-10 1.0000000e+00 1.7590572e-10 4.7111863e-12], sampled 0.7057312526103646
[2019-03-23 17:46:46,627] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3361.3356 2098067941.7008 179.0000
[2019-03-23 17:46:46,886] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2760.8400 2123992992.7798 757.0000
[2019-03-23 17:46:46,985] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3118.8146 2109022190.6825 368.0000
[2019-03-23 17:46:47,000] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3519.0325 2104095443.0865 178.0000
[2019-03-23 17:46:47,220] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3614.1741 2175305489.0345 245.0000
[2019-03-23 17:46:48,239] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 575000, evaluation results [575000.0, 3614.1740929847015, 2175305489.034501, 245.0, 3361.3355917968815, 2098067941.7008436, 179.0, 3519.032511138161, 2104095443.0864863, 178.0, 2760.840012042761, 2123992992.7798212, 757.0, 3118.8146269445274, 2109022190.6824877, 368.0]
[2019-03-23 17:46:49,008] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.1573379e-08 6.3777348e-09 1.0000000e+00 4.9450164e-09 9.2343751e-11], sum to 1.0000
[2019-03-23 17:46:49,015] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7107
[2019-03-23 17:46:49,022] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [15.5, 91.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 283250.4940246784, 283250.4940246787, 115870.3436262445], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5657400.0000, 
sim time next is 5658000.0000, 
raw observation next is [15.5, 91.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 281304.9863206642, 281304.9863206645, 114973.5517985358], 
processed observation next is [0.0, 0.4782608695652174, 0.3409090909090909, 0.91, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10418703197061636, 0.10418703197061649, 0.2804232970695995], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.1431556], dtype=float32), 0.1757406]. 
=============================================
[2019-03-23 17:46:49,049] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[-0.73490053]
 [-0.7316871 ]
 [-0.7186695 ]
 [-0.7208403 ]
 [-0.69134396]], R is [[-0.7253629 ]
 [-0.71810925]
 [-0.71092814]
 [-0.70381886]
 [-0.69678068]].
[2019-03-23 17:46:50,133] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.4121393e-07 4.1932122e-08 9.9999952e-01 2.2095076e-08 9.7671460e-10], sum to 1.0000
[2019-03-23 17:46:50,142] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0139
[2019-03-23 17:46:50,146] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [13.0, 73.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 194913.877056291, 194913.8770562907, 84311.49025644781], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5693400.0000, 
sim time next is 5694000.0000, 
raw observation next is [12.73333333333333, 74.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 191544.6736235821, 191544.6736235824, 83583.40215004474], 
processed observation next is [0.0, 0.9130434782608695, 0.21515151515151504, 0.7433333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07094247171243781, 0.07094247171243794, 0.20386195646352376], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3316783], dtype=float32), 0.319318]. 
=============================================
[2019-03-23 17:46:50,161] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[-0.8502652 ]
 [-0.83594126]
 [-0.81592697]
 [-0.8068692 ]
 [-0.7699844 ]], R is [[-0.85105026]
 [-0.84253979]
 [-0.83411437]
 [-0.82577324]
 [-0.81751549]].
[2019-03-23 17:46:51,462] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.9017009e-07 4.9976383e-09 9.9999940e-01 8.7813392e-09 1.1293257e-09], sum to 1.0000
[2019-03-23 17:46:51,467] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1144
[2019-03-23 17:46:51,476] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [13.53333333333333, 70.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 202385.9286927118, 202385.928692712, 85914.1215600484], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5692200.0000, 
sim time next is 5692800.0000, 
raw observation next is [13.26666666666667, 71.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 198435.6148300453, 198435.614830045, 85072.02069198109], 
processed observation next is [0.0, 0.9130434782608695, 0.23939393939393952, 0.7166666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07349467215927603, 0.07349467215927592, 0.20749273339507582], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.4336116], dtype=float32), 0.25762174]. 
=============================================
[2019-03-23 17:47:07,518] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.0083432e-06 4.5539717e-13 9.9999797e-01 1.8027770e-12 1.4014144e-12], sum to 1.0000
[2019-03-23 17:47:07,527] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3450
[2019-03-23 17:47:07,536] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.26666666666667, 56.66666666666667, 1.0, 2.0, 0.2966350622009453, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5959946833526509, 6.9112, 6.9112, 77.32846344353965, 676671.3927353646, 676671.3927353646, 186874.0896838191], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6007200.0000, 
sim time next is 6007800.0000, 
raw observation next is [26.18333333333334, 57.33333333333334, 1.0, 2.0, 0.2711357912728032, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5447022306494013, 6.9112, 6.9112, 77.32846344354103, 618447.8604563581, 618447.8604563581, 180357.5830341651], 
processed observation next is [1.0, 0.5217391304347826, 0.8265151515151519, 0.5733333333333335, 1.0, 1.0, 0.08891973909100397, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3495746152134304, 0.0, 0.0, 0.508428812920654, 0.22905476313198447, 0.22905476313198447, 0.4398965439857685], 
reward next is 0.5601, 
noisyNet noise sample is [array([0.79457825], dtype=float32), 0.46104506]. 
=============================================
[2019-03-23 17:47:15,834] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.2647097e-06 8.6658203e-10 9.9999070e-01 3.4192607e-10 3.1985323e-10], sum to 1.0000
[2019-03-23 17:47:15,845] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1320
[2019-03-23 17:47:15,852] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.28333333333333, 83.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 327327.1453744636, 327327.1453744639, 136151.1633979655], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6151800.0000, 
sim time next is 6152400.0000, 
raw observation next is [17.2, 84.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 326324.5756914483, 326324.5756914483, 136667.2615959755], 
processed observation next is [1.0, 0.21739130434782608, 0.41818181818181815, 0.84, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.12086095395979567, 0.12086095395979567, 0.333334784380428], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.46894655], dtype=float32), -0.018953819]. 
=============================================
[2019-03-23 17:47:16,202] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2518697e-05 3.8901656e-13 9.9998748e-01 9.4035641e-13 5.5474765e-12], sum to 1.0000
[2019-03-23 17:47:16,208] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6595
[2019-03-23 17:47:16,212] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.8, 76.0, 1.0, 2.0, 0.3970714656839602, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7803366724334657, 6.9112, 6.9112, 77.32846344354104, 895659.4382223731, 895659.4382223731, 208038.5498937852], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6175800.0000, 
sim time next is 6176400.0000, 
raw observation next is [21.06666666666667, 74.33333333333333, 1.0, 2.0, 0.3767906220624625, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7406474737647775, 6.9112, 6.9112, 77.32846344354104, 849996.7865096417, 849996.7865096417, 201751.043181137], 
processed observation next is [1.0, 0.4782608695652174, 0.5939393939393941, 0.7433333333333333, 1.0, 1.0, 0.2209882775780781, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6294963910925393, 0.0, 0.0, 0.5084288129206541, 0.3148136246332006, 0.3148136246332006, 0.49207571507594394], 
reward next is 0.5079, 
noisyNet noise sample is [array([-0.27903754], dtype=float32), -1.4676206]. 
=============================================
[2019-03-23 17:47:18,963] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.35333084e-07 3.27808669e-10 9.99999642e-01 2.48095128e-10
 1.38233765e-11], sum to 1.0000
[2019-03-23 17:47:18,975] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7781
[2019-03-23 17:47:18,980] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.5, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.39137716647645, 6.9112, 6.9112, 77.32846344354104, 447249.2489343956, 447249.2489343956, 161390.9660838761], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6249600.0000, 
sim time next is 6250200.0000, 
raw observation next is [20.68333333333334, 86.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3960661246762193, 6.9112, 6.9112, 77.32846344354104, 452346.6798077599, 452346.6798077599, 162249.5621362322], 
processed observation next is [0.0, 0.34782608695652173, 0.5765151515151519, 0.8616666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.13723732096602761, 0.0, 0.0, 0.5084288129206541, 0.16753580733620738, 0.16753580733620738, 0.3957306393566639], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.341773], dtype=float32), -0.823857]. 
=============================================
[2019-03-23 17:47:19,019] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.7688528e-07 2.5327421e-10 9.9999964e-01 1.9401732e-10 1.1649357e-11], sum to 1.0000
[2019-03-23 17:47:19,026] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8738
[2019-03-23 17:47:19,034] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.86666666666667, 85.33333333333334, 1.0, 2.0, 0.2005127219086005, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3988953994381362, 6.911199999999999, 6.9112, 77.32846344354104, 455377.8197177103, 455377.8197177106, 162754.565174841], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6250800.0000, 
sim time next is 6251400.0000, 
raw observation next is [21.05, 84.5, 1.0, 2.0, 0.2017191050978413, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4016472689068221, 6.911200000000001, 6.9112, 77.32846344354104, 458328.0306693189, 458328.0306693186, 163173.0468354139], 
processed observation next is [0.0, 0.34782608695652173, 0.5931818181818183, 0.845, 1.0, 1.0, 0.0021488813723016115, 0.0, 1.0, -0.25, 1.0, 1.0, 0.14521038415260304, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16975112247011812, 0.169751122470118, 0.3979830410619851], 
reward next is 0.6020, 
noisyNet noise sample is [array([1.341773], dtype=float32), -0.823857]. 
=============================================
[2019-03-23 17:47:20,124] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.9435985e-08 2.2605703e-10 9.9999988e-01 2.3575897e-10 1.1792884e-11], sum to 1.0000
[2019-03-23 17:47:20,131] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4829
[2019-03-23 17:47:20,134] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.01666666666667, 82.83333333333334, 1.0, 2.0, 0.2332586472224231, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4709562973125961, 6.911199999999999, 6.9112, 77.32846344354104, 532279.6420087339, 532279.6420087342, 173860.3383595007], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6259800.0000, 
sim time next is 6260400.0000, 
raw observation next is [23.3, 82.0, 1.0, 2.0, 0.2364683489703065, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4778049910193118, 6.9112, 6.9112, 77.32846344354104, 539502.4698922548, 539502.4698922548, 174977.36544006], 
processed observation next is [0.0, 0.4782608695652174, 0.6954545454545454, 0.82, 1.0, 1.0, 0.04558543621288311, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2540071300275883, 0.0, 0.0, 0.5084288129206541, 0.199815729589724, 0.199815729589724, 0.42677406204892687], 
reward next is 0.5732, 
noisyNet noise sample is [array([1.3690143], dtype=float32), -1.0272498]. 
=============================================
[2019-03-23 17:47:28,053] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.1183870e-03 2.8299925e-11 9.9788159e-01 7.3924910e-13 5.7862731e-10], sum to 1.0000
[2019-03-23 17:47:28,063] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2760
[2019-03-23 17:47:28,067] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 76.83333333333333, 1.0, 2.0, 0.2685005600987853, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5438778364594299, 6.911199999999999, 6.9112, 77.32846344354104, 610491.0974598625, 610491.0974598628, 185057.6280043008], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6385800.0000, 
sim time next is 6386400.0000, 
raw observation next is [25.0, 76.0, 1.0, 2.0, 0.2655243890401351, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5377954909652263, 6.911199999999999, 6.9112, 77.32846344354104, 604106.6554694508, 604106.655469451, 184008.9606990448], 
processed observation next is [0.0, 0.9565217391304348, 0.7727272727272727, 0.76, 1.0, 1.0, 0.08190548630016885, 0.0, 1.0, -0.25, 1.0, 1.0, 0.33970784423603756, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22374320572942621, 0.2237432057294263, 0.44880234316840195], 
reward next is 0.5512, 
noisyNet noise sample is [array([0.34572396], dtype=float32), 0.8304631]. 
=============================================
[2019-03-23 17:47:32,296] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.1922908e-05 5.4136341e-11 9.9998808e-01 1.1492222e-11 6.7768109e-12], sum to 1.0000
[2019-03-23 17:47:32,302] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8656
[2019-03-23 17:47:32,307] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.86666666666667, 83.0, 1.0, 2.0, 0.318758455891874, 0.0, 2.0, 0.0, 1.0, 2.0, 0.615359807763288, 6.9112, 6.9112, 77.32846344354104, 710035.8226194377, 710035.8226194377, 180622.79131319], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6452400.0000, 
sim time next is 6453000.0000, 
raw observation next is [19.15, 81.0, 1.0, 2.0, 0.317252254805143, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6123681710632006, 6.9112, 6.9112, 77.32846344354104, 706607.4375969777, 706607.4375969777, 180223.7445985097], 
processed observation next is [1.0, 0.6956521739130435, 0.5068181818181817, 0.81, 1.0, 1.0, 0.14656531850642876, 0.0, 1.0, -0.25, 1.0, 1.0, 0.44624024437600096, 0.0, 0.0, 0.5084288129206541, 0.261706458369251, 0.261706458369251, 0.4395701087768529], 
reward next is 0.5604, 
noisyNet noise sample is [array([-0.24313286], dtype=float32), -1.5520887]. 
=============================================
[2019-03-23 17:47:32,323] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[37.70934 ]
 [38.08363 ]
 [37.292126]
 [37.364223]
 [37.62868 ]], R is [[37.59007263]
 [37.77362823]
 [37.91893005]
 [38.10145187]
 [38.2848587 ]].
[2019-03-23 17:47:33,866] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.5077296e-04 1.1420254e-09 9.9954921e-01 3.3002251e-10 1.3826991e-10], sum to 1.0000
[2019-03-23 17:47:33,875] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4243
[2019-03-23 17:47:33,882] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.76666666666667, 51.0, 1.0, 2.0, 0.2515990287097796, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4696802672882792, 6.911199999999999, 6.9112, 77.32846344354104, 546522.7729052689, 546522.7729052693, 142821.4918235185], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6529200.0000, 
sim time next is 6529800.0000, 
raw observation next is [19.58333333333334, 51.5, 1.0, 2.0, 0.2499022898781884, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4665128276044819, 6.911199999999999, 6.9112, 77.32846344354104, 542835.0631269406, 542835.063126941, 142029.8049865789], 
processed observation next is [1.0, 0.5652173913043478, 0.5265151515151518, 0.515, 1.0, 1.0, 0.0623778623477355, 0.0, 1.0, -0.25, 1.0, 1.0, 0.23787546800640272, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20105002338034839, 0.2010500233803485, 0.346414158503851], 
reward next is 0.6536, 
noisyNet noise sample is [array([-0.4862372], dtype=float32), -0.8703346]. 
=============================================
[2019-03-23 17:47:38,364] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 17:47:38,366] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:47:38,367] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:47:38,368] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:47:38,368] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:47:38,368] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:47:38,369] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:47:38,370] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:47:38,371] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:47:38,372] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:47:38,372] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:47:38,391] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run25
[2019-03-23 17:47:38,417] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run25
[2019-03-23 17:47:38,418] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run25
[2019-03-23 17:47:38,455] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run25
[2019-03-23 17:47:38,457] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run25
[2019-03-23 17:47:41,477] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00474201], dtype=float32), 0.0028469628]
[2019-03-23 17:47:41,478] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.66666666666667, 73.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 247328.1433703965, 247328.1433703962, 98810.61578828344]
[2019-03-23 17:47:41,481] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:47:41,484] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.8016376e-06 7.3265851e-09 9.9999416e-01 6.1282148e-09 1.6925764e-09], sampled 0.8637811369348096
[2019-03-23 17:47:55,025] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00474201], dtype=float32), 0.0028469628]
[2019-03-23 17:47:55,026] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.33423911, 86.81381112333334, 1.0, 2.0, 0.383970158310659, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7769173214244227, 6.911199999999999, 6.9112, 95.55338769695034, 862977.9632727816, 862977.9632727819, 230356.8576201538]
[2019-03-23 17:47:55,027] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:47:55,029] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.5962678e-05 1.2697057e-12 9.9997401e-01 5.3585511e-13 4.1264991e-12], sampled 0.025924643324431118
[2019-03-23 17:48:16,181] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00474201], dtype=float32), 0.0028469628]
[2019-03-23 17:48:16,184] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.26666666666667, 47.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3848299413803546, 6.911199999999999, 6.9112, 95.55338769695034, 441015.7967400964, 441015.7967400967, 164023.2272575856]
[2019-03-23 17:48:16,185] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:48:16,187] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.94601344e-05 2.46405292e-11 9.99980569e-01 1.20438624e-11
 3.56727738e-11], sampled 0.8369883345200132
[2019-03-23 17:48:22,097] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00474201], dtype=float32), 0.0028469628]
[2019-03-23 17:48:22,099] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.268605245, 73.71435867, 1.0, 2.0, 0.2996016098439266, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5971814820613619, 6.911200000000001, 6.9112, 95.55338769695034, 681160.7387190594, 681160.738719059, 189562.4073118512]
[2019-03-23 17:48:22,101] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:48:22,104] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.1280885e-05 3.8209939e-12 9.9997866e-01 1.7523173e-12 9.1552555e-12], sampled 0.7604343508921985
[2019-03-23 17:48:24,933] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00474201], dtype=float32), 0.0028469628]
[2019-03-23 17:48:24,935] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.0, 65.0, 1.0, 2.0, 0.5379152444357723, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9588494587098391, 6.926454649565718, 6.9112, 77.32840519883892, 1162336.460909593, 1157382.066473899, 258487.3319572259]
[2019-03-23 17:48:24,936] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:48:24,939] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.5255646e-05 4.5742403e-12 9.9998474e-01 2.2374687e-12 9.0397811e-12], sampled 0.2775728276550128
[2019-03-23 17:48:37,348] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00474201], dtype=float32), 0.0028469628]
[2019-03-23 17:48:37,349] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.76004748666666, 98.48830058666667, 1.0, 2.0, 0.3712434669701781, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7511663959088983, 6.911200000000001, 6.9112, 95.55338769695034, 834354.6853468285, 834354.6853468282, 225633.555120871]
[2019-03-23 17:48:37,350] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:48:37,352] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.0929830e-05 1.0136664e-12 9.9996912e-01 4.1501560e-13 3.7398348e-12], sampled 0.03772803399744307
[2019-03-23 17:49:06,224] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00474201], dtype=float32), 0.0028469628]
[2019-03-23 17:49:06,225] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.36666666666667, 81.33333333333333, 1.0, 2.0, 0.3242073119607302, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6383674559190973, 6.911199999999999, 6.9112, 77.32846344354104, 732079.0936361721, 732079.0936361725, 187264.3716987826]
[2019-03-23 17:49:06,225] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:49:06,229] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.0116126e-05 4.5823722e-12 9.9992990e-01 1.9529187e-12 1.7242740e-11], sampled 0.47716960027002686
[2019-03-23 17:49:10,712] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00474201], dtype=float32), 0.0028469628]
[2019-03-23 17:49:10,716] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.7, 55.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3599173199947354, 6.9112, 6.9112, 95.55338769695034, 412650.2834252582, 412650.2834252582, 160580.8240690513]
[2019-03-23 17:49:10,716] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:49:10,719] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.1326379e-05 1.0086188e-10 9.9998868e-01 5.7140157e-11 8.2705551e-11], sampled 0.4314704310200712
[2019-03-23 17:49:15,266] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3519.8601 2104065516.4220 178.0000
[2019-03-23 17:49:15,284] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2761.6783 2123992446.4095 757.0000
[2019-03-23 17:49:15,415] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3362.1691 2098038300.6081 179.0000
[2019-03-23 17:49:15,550] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3118.8146 2109022190.6825 368.0000
[2019-03-23 17:49:15,581] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3614.9699 2175277350.2672 245.0000
[2019-03-23 17:49:16,593] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 600000, evaluation results [600000.0, 3614.9699174274924, 2175277350.267185, 245.0, 3362.1690930919945, 2098038300.608117, 179.0, 3519.8600815450736, 2104065516.4220078, 178.0, 2761.678302548772, 2123992446.409528, 757.0, 3118.8146269445274, 2109022190.6824877, 368.0]
[2019-03-23 17:49:18,950] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.34135814e-06 1.11872164e-10 9.99997616e-01 2.65345024e-10
 9.90886678e-11], sum to 1.0000
[2019-03-23 17:49:18,962] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8371
[2019-03-23 17:49:18,967] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.68333333333334, 76.83333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3611554866068676, 6.9112, 6.9112, 77.32846344354104, 415088.5302391734, 415088.5302391734, 155255.718125413], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6634200.0000, 
sim time next is 6634800.0000, 
raw observation next is [20.5, 78.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.358983269154946, 6.9112, 6.9112, 77.32846344354104, 412644.4206890118, 412644.4206890118, 154934.3974354636], 
processed observation next is [1.0, 0.8260869565217391, 0.5681818181818182, 0.78, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0842618130784943, 0.0, 0.0, 0.5084288129206541, 0.15283126692185622, 0.15283126692185622, 0.377888774232838], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.45196098], dtype=float32), 1.3247145]. 
=============================================
[2019-03-23 17:49:24,258] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.3582386e-06 9.6336727e-10 9.9999559e-01 3.7625707e-09 4.6847276e-10], sum to 1.0000
[2019-03-23 17:49:24,267] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7611
[2019-03-23 17:49:24,278] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.61666666666667, 99.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.35465754521441, 6.9112, 6.9112, 77.32846344354104, 408297.7944089075, 408297.7944089075, 153812.2556759725], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6732600.0000, 
sim time next is 6733200.0000, 
raw observation next is [17.53333333333333, 98.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3520067913499324, 6.911200000000001, 6.9112, 77.32846344354104, 405565.9464399148, 405565.9464399145, 153184.5240637973], 
processed observation next is [1.0, 0.9565217391304348, 0.43333333333333324, 0.9866666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.07429541621418917, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15020960979256104, 0.15020960979256093, 0.3736207903995056], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3090965], dtype=float32), -0.8996858]. 
=============================================
[2019-03-23 17:49:27,971] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.79842197e-07 1.05264419e-08 9.99999762e-01 1.02508935e-08
 1.47290202e-09], sum to 1.0000
[2019-03-23 17:49:27,978] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5293
[2019-03-23 17:49:27,982] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.8, 62.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3930390285182364, 6.9112, 6.9112, 77.32846344354104, 449736.1248021297, 449736.1248021297, 161114.4100745177], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6807600.0000, 
sim time next is 6808200.0000, 
raw observation next is [23.61666666666667, 63.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3918091912315362, 6.911199999999999, 6.9112, 77.32846344354104, 448294.4218018862, 448294.4218018865, 160978.3368816282], 
processed observation next is [1.0, 0.8260869565217391, 0.7098484848484851, 0.635, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.13115598747362314, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16603497103773562, 0.16603497103773576, 0.3926300899551907], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.38031152], dtype=float32), 1.0378834]. 
=============================================
[2019-03-23 17:49:30,187] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.0416959e-08 5.6409449e-10 9.9999988e-01 1.0368579e-09 4.6292654e-11], sum to 1.0000
[2019-03-23 17:49:30,193] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9673
[2019-03-23 17:49:30,197] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.8, 84.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3818481279960017, 6.9112, 6.9112, 77.32846344354104, 438651.0729394994, 438651.0729394994, 158097.6609637639], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7064400.0000, 
sim time next is 7065000.0000, 
raw observation next is [19.7, 84.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3754367159678499, 6.9112, 6.9112, 77.32846344354104, 431515.5422025489, 431515.5422025489, 157060.1367522746], 
processed observation next is [1.0, 0.782608695652174, 0.5318181818181817, 0.84, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.10776673709692844, 0.0, 0.0, 0.5084288129206541, 0.15982057118612922, 0.15982057118612922, 0.38307350427384046], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.35615203], dtype=float32), -0.93254775]. 
=============================================
[2019-03-23 17:49:30,211] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[ 6.7141256]
 [ 7.6893473]
 [ 9.326151 ]
 [12.058053 ]
 [14.251636 ]], R is [[6.04991817]
 [5.98941898]
 [5.9295249 ]
 [5.87022972]
 [6.41908884]].
[2019-03-23 17:49:30,236] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.2973839e-07 6.9979702e-09 9.9999940e-01 5.2355724e-09 3.5248171e-10], sum to 1.0000
[2019-03-23 17:49:30,244] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4460
[2019-03-23 17:49:30,250] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.0, 81.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3562299613767091, 6.9112, 6.9112, 77.32846344354104, 409677.4458205416, 409677.4458205416, 154407.0471191024], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6829200.0000, 
sim time next is 6829800.0000, 
raw observation next is [19.8, 82.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3557033763805738, 6.911200000000001, 6.9112, 77.32846344354104, 409110.9687901165, 409110.9687901163, 154305.3119705714], 
processed observation next is [0.0, 0.043478260869565216, 0.5363636363636364, 0.825, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.07957625197224832, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15152258103337649, 0.1515225810333764, 0.3763544194404181], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.38508913], dtype=float32), -0.62942064]. 
=============================================
[2019-03-23 17:49:37,100] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.5166032e-04 1.2114078e-10 9.9934834e-01 9.5706387e-11 1.0195901e-10], sum to 1.0000
[2019-03-23 17:49:37,107] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1334
[2019-03-23 17:49:37,112] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.8, 57.66666666666667, 1.0, 2.0, 0.2496193748228413, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5051972388572218, 6.911199999999999, 6.9112, 77.32846344354104, 568881.3639257022, 568881.3639257024, 179125.6136924627], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6959400.0000, 
sim time next is 6960000.0000, 
raw observation next is [27.9, 57.33333333333334, 1.0, 2.0, 0.250121591693616, 0.0, 2.0, 0.0, 1.0, 2.0, 0.506251377499699, 6.911199999999999, 6.9112, 77.32846344354104, 569970.1345363617, 569970.1345363619, 179315.1463568844], 
processed observation next is [0.0, 0.5652173913043478, 0.9045454545454544, 0.5733333333333335, 1.0, 1.0, 0.06265198961701995, 0.0, 1.0, -0.25, 1.0, 1.0, 0.29464482499956995, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2111000498282821, 0.21110004982828218, 0.43735401550459607], 
reward next is 0.5626, 
noisyNet noise sample is [array([-0.20367578], dtype=float32), 0.24436168]. 
=============================================
[2019-03-23 17:49:37,132] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[54.298298]
 [54.387783]
 [54.389214]
 [54.47843 ]
 [54.532772]], R is [[54.28729248]
 [54.30752563]
 [54.32786942]
 [54.34802628]
 [54.3680954 ]].
[2019-03-23 17:49:37,443] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.6333352e-04 4.4018357e-12 9.9983668e-01 2.3724495e-11 2.1659829e-10], sum to 1.0000
[2019-03-23 17:49:37,455] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8591
[2019-03-23 17:49:37,461] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.2, 84.0, 1.0, 2.0, 0.2280018027108549, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4586708244661925, 6.9112, 6.9112, 77.32846344354104, 520180.7423364588, 520180.7423364588, 171189.5002195349], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7000800.0000, 
sim time next is 7001400.0000, 
raw observation next is [22.2, 84.0, 1.0, 2.0, 0.2278470792371067, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4583588766449728, 6.9112, 6.9112, 77.32846344354104, 519827.3944477831, 519827.3944477831, 171156.9939427636], 
processed observation next is [1.0, 0.0, 0.6454545454545454, 0.84, 1.0, 1.0, 0.034808849046383365, 0.0, 1.0, -0.25, 1.0, 1.0, 0.22622696663567549, 0.0, 0.0, 0.5084288129206541, 0.19252866461029006, 0.19252866461029006, 0.4174560827872283], 
reward next is 0.5825, 
noisyNet noise sample is [array([-0.26970115], dtype=float32), 1.468028]. 
=============================================
[2019-03-23 17:49:38,336] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.3113232e-06 1.2277721e-12 9.9999571e-01 2.0916322e-12 7.9238768e-12], sum to 1.0000
[2019-03-23 17:49:38,345] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5863
[2019-03-23 17:49:38,353] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.2, 84.0, 1.0, 2.0, 0.2276994476393461, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4580612035109809, 6.911200000000001, 6.9112, 77.32846344354104, 519490.2371871269, 519490.2371871266, 171125.977801154], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7002000.0000, 
sim time next is 7002600.0000, 
raw observation next is [22.01666666666667, 85.5, 1.0, 2.0, 0.2281982369757816, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4591060566645849, 6.911199999999999, 6.9112, 77.32846344354104, 520638.3664606047, 520638.3664606049, 171262.6467150251], 
processed observation next is [1.0, 0.043478260869565216, 0.6371212121212122, 0.855, 1.0, 1.0, 0.03524779621972698, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2272943666636928, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19282902461503879, 0.19282902461503884, 0.417713772475671], 
reward next is 0.5823, 
noisyNet noise sample is [array([0.7516685], dtype=float32), -0.84640306]. 
=============================================
[2019-03-23 17:49:41,653] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2730023e-06 1.3157060e-10 9.9999869e-01 1.2941267e-11 2.0148248e-10], sum to 1.0000
[2019-03-23 17:49:41,662] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3720
[2019-03-23 17:49:41,674] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.3, 92.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.351449742561204, 6.911199999999999, 6.9112, 77.32846344354104, 404800.6971060543, 404800.6971060546, 153232.9987598576], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7078200.0000, 
sim time next is 7078800.0000, 
raw observation next is [18.3, 92.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.348862553598918, 6.9112, 6.9112, 77.32846344354104, 401944.9161051234, 401944.9161051234, 152799.1449802041], 
processed observation next is [1.0, 0.9565217391304348, 0.4681818181818182, 0.92, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.06980364799845429, 0.0, 0.0, 0.5084288129206541, 0.148868487446342, 0.148868487446342, 0.3726808414151319], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.7659996], dtype=float32), 2.2948234]. 
=============================================
[2019-03-23 17:49:42,189] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.18036473e-06 8.24510338e-12 9.99998808e-01 2.21488539e-12
 1.18627625e-11], sum to 1.0000
[2019-03-23 17:49:42,190] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6856
[2019-03-23 17:49:42,196] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.58333333333334, 92.0, 1.0, 2.0, 0.3954658746037614, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7851060488713587, 6.9112, 6.9112, 77.32846344354104, 897533.2819415214, 897533.2819415214, 211499.4246388417], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7038600.0000, 
sim time next is 7039200.0000, 
raw observation next is [19.76666666666667, 91.0, 1.0, 2.0, 0.3721771207700992, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7394957290354557, 6.911200000000001, 6.9112, 77.32846344354104, 845024.2655108388, 845024.2655108385, 204297.3012851548], 
processed observation next is [1.0, 0.4782608695652174, 0.534848484848485, 0.91, 1.0, 1.0, 0.21522140096262396, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6278510414792224, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.31297195018919954, 0.31297195018919943, 0.4982861006954995], 
reward next is 0.5017, 
noisyNet noise sample is [array([0.5592648], dtype=float32), 0.31644794]. 
=============================================
[2019-03-23 17:49:50,488] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7983743e-05 3.4883058e-10 9.9998200e-01 7.0619871e-11 9.3844044e-11], sum to 1.0000
[2019-03-23 17:49:50,495] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6469
[2019-03-23 17:49:50,500] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.93333333333333, 46.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3469826121100352, 6.911199999999999, 6.9112, 77.32846344354104, 403691.7687120804, 403691.7687120807, 148119.4021635309], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7216800.0000, 
sim time next is 7217400.0000, 
raw observation next is [23.11666666666667, 46.16666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3506254437249993, 6.911199999999999, 6.9112, 77.32846344354104, 407804.0218908465, 407804.0218908468, 149459.8974734864], 
processed observation next is [1.0, 0.5217391304347826, 0.6871212121212124, 0.46166666666666656, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.07232206246428476, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15103852662623943, 0.15103852662623954, 0.36453633530118634], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7367069], dtype=float32), -0.2561431]. 
=============================================
[2019-03-23 17:49:51,363] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.5538721e-07 1.2278344e-10 9.9999964e-01 4.4709385e-11 6.7998614e-11], sum to 1.0000
[2019-03-23 17:49:51,372] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1546
[2019-03-23 17:49:51,376] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.9, 43.33333333333334, 1.0, 2.0, 0.3900416690556491, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7356214881706593, 6.911199999999999, 6.9112, 77.32846344354104, 853624.2656079452, 853624.2656079455, 193341.8439462981], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7225800.0000, 
sim time next is 7226400.0000, 
raw observation next is [24.0, 43.66666666666667, 1.0, 2.0, 0.3925988706019224, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7428886432040436, 6.9112, 6.9112, 77.32846344354104, 861457.7595928897, 861457.7595928897, 194928.7671980093], 
processed observation next is [1.0, 0.6521739130434783, 0.7272727272727273, 0.4366666666666667, 1.0, 1.0, 0.24074858825240297, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6326980617200623, 0.0, 0.0, 0.5084288129206541, 0.31905842947884805, 0.31905842947884805, 0.47543601755612025], 
reward next is 0.5246, 
noisyNet noise sample is [array([1.4373817], dtype=float32), -1.3536224]. 
=============================================
[2019-03-23 17:49:54,905] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.3174745e-06 8.8001530e-11 9.9999666e-01 1.1197751e-10 6.1511997e-11], sum to 1.0000
[2019-03-23 17:49:54,915] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0977
[2019-03-23 17:49:54,923] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.55, 44.5, 1.0, 2.0, 0.4620755357612053, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9001789738528777, 6.9112, 6.9112, 77.32846344354104, 1036321.652059497, 1036321.652059497, 226896.8353733032], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7306200.0000, 
sim time next is 7306800.0000, 
raw observation next is [25.73333333333333, 44.0, 1.0, 2.0, 0.4727145921701269, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9134028813249248, 6.927691561737229, 6.9112, 77.32841972230268, 1061643.122246327, 1056287.003333178, 230338.2037555782], 
processed observation next is [1.0, 0.5652173913043478, 0.8060606060606059, 0.44, 1.0, 1.0, 0.3408932402126586, 0.0, 1.0, -0.25, 1.0, 1.0, 0.8762898304641784, 0.0016491561737229433, 0.0, 0.5084285254568106, 0.39320115638752856, 0.39121740864191784, 0.5618004969648249], 
reward next is 0.3557, 
noisyNet noise sample is [array([1.4809763], dtype=float32), -0.47263205]. 
=============================================
[2019-03-23 17:49:56,774] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.3800800e-07 1.4106652e-10 9.9999976e-01 9.7156762e-11 6.6913260e-11], sum to 1.0000
[2019-03-23 17:49:56,779] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2063
[2019-03-23 17:49:56,785] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.7, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 346512.9395251893, 346512.9395251896, 144647.6098452072], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7363800.0000, 
sim time next is 7364400.0000, 
raw observation next is [17.7, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3014466310750359, 6.911200000000001, 6.9112, 77.32846344354104, 349480.3518388549, 349480.3518388546, 145005.9591856742], 
processed observation next is [1.0, 0.21739130434782608, 0.44090909090909086, 0.87, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.002066615821479854, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12943716734772404, 0.12943716734772392, 0.35367307118457125], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5839307], dtype=float32), -0.16275239]. 
=============================================
[2019-03-23 17:50:00,122] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.9844995e-06 1.5895789e-10 9.9999607e-01 4.7965361e-11 3.9169099e-11], sum to 1.0000
[2019-03-23 17:50:00,133] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8497
[2019-03-23 17:50:00,142] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.25, 94.5, 1.0, 2.0, 0.2164116357170494, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4330222361985633, 6.9112, 6.9112, 77.32846344354104, 492861.4401126051, 492861.4401126051, 167147.2110462745], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7626600.0000, 
sim time next is 7627200.0000, 
raw observation next is [20.33333333333334, 94.0, 1.0, 2.0, 0.2145213536725534, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4293335220057592, 6.911199999999999, 6.9112, 77.32846344354104, 488598.2984791538, 488598.2984791541, 166849.4459003064], 
processed observation next is [1.0, 0.2608695652173913, 0.5606060606060609, 0.94, 1.0, 1.0, 0.018151692090691736, 0.0, 1.0, -0.25, 1.0, 1.0, 0.18476217429394173, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18096233277005697, 0.18096233277005708, 0.4069498680495278], 
reward next is 0.5931, 
noisyNet noise sample is [array([-0.18012075], dtype=float32), 1.904105]. 
=============================================
[2019-03-23 17:50:04,820] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.6507480e-05 3.0462736e-13 9.9992347e-01 5.4733582e-14 2.7503800e-12], sum to 1.0000
[2019-03-23 17:50:04,821] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8555
[2019-03-23 17:50:04,833] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.7, 57.0, 1.0, 2.0, 0.2487625950973048, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5031869818949686, 6.9112, 6.9112, 77.32846344354104, 567240.5696829824, 567240.5696829824, 178464.849764066], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7491600.0000, 
sim time next is 7492200.0000, 
raw observation next is [27.43333333333333, 57.83333333333333, 1.0, 2.0, 0.2473213755161475, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5001361499374088, 6.911200000000001, 6.9112, 77.32846344354104, 564061.0296538483, 564061.0296538479, 177932.7733444726], 
processed observation next is [0.0, 0.7391304347826086, 0.8833333333333332, 0.5783333333333333, 1.0, 1.0, 0.059151719395184356, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2859087856248698, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20891149246438825, 0.20891149246438812, 0.4339823740109088], 
reward next is 0.5660, 
noisyNet noise sample is [array([-1.5799582], dtype=float32), -0.9913907]. 
=============================================
[2019-03-23 17:50:05,175] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.5186173e-06 7.0722765e-14 9.9999750e-01 1.7535989e-14 1.2338405e-12], sum to 1.0000
[2019-03-23 17:50:05,182] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9596
[2019-03-23 17:50:05,187] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.9, 59.0, 1.0, 2.0, 0.2601808421485241, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5269361405665363, 6.911200000000001, 6.9112, 77.32846344354104, 592113.7406778845, 592113.7406778842, 182532.0924687277], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7482000.0000, 
sim time next is 7482600.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.2584498261836399, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5233658103342298, 6.9112, 6.9112, 77.32846344354104, 588403.3335700224, 588403.3335700224, 181899.9303766899], 
processed observation next is [0.0, 0.6086956521739131, 0.9090909090909091, 0.58, 1.0, 1.0, 0.07306228272954983, 0.0, 1.0, -0.25, 1.0, 1.0, 0.31909401476318544, 0.0, 0.0, 0.5084288129206541, 0.21792716058148975, 0.21792716058148975, 0.44365836677241444], 
reward next is 0.5563, 
noisyNet noise sample is [array([-0.13526164], dtype=float32), -0.04063374]. 
=============================================
[2019-03-23 17:50:06,902] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 17:50:06,904] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:50:06,904] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:50:06,905] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:50:06,906] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:50:06,907] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:50:06,908] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:50:06,905] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:50:06,910] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:50:06,914] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:50:06,915] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:50:06,931] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run26
[2019-03-23 17:50:06,931] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run26
[2019-03-23 17:50:06,975] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run26
[2019-03-23 17:50:07,003] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run26
[2019-03-23 17:50:07,026] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run26
[2019-03-23 17:50:08,052] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00512796], dtype=float32), 0.003168609]
[2019-03-23 17:50:08,053] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.9, 65.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 238058.7168340608, 238058.7168340608, 99412.85236924577]
[2019-03-23 17:50:08,053] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:50:08,054] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.0187966e-04 1.1313545e-11 9.9959809e-01 5.2772973e-12 8.7243941e-11], sampled 0.6541280310759053
[2019-03-23 17:50:19,848] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00512796], dtype=float32), 0.003168609]
[2019-03-23 17:50:19,849] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.56666666666667, 44.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3622580202842245, 6.911200000000001, 6.9112, 95.55338769695034, 416048.8965854615, 416048.8965854611, 160243.4866879014]
[2019-03-23 17:50:19,850] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:50:19,854] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.3726569e-04 4.4931729e-13 9.9966276e-01 1.9263439e-13 5.4414312e-12], sampled 0.5379058096460525
[2019-03-23 17:50:34,906] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00512796], dtype=float32), 0.003168609]
[2019-03-23 17:50:34,907] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.16666666666667, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3605385380351697, 6.911200000000001, 6.9112, 95.55338769695034, 414766.8278061654, 414766.827806165, 159392.190627447]
[2019-03-23 17:50:34,909] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:50:34,912] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.82091089e-04 2.39641775e-13 9.99717891e-01 1.01067016e-13
 3.05474786e-12], sampled 0.33491971374544616
[2019-03-23 17:50:36,894] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00512796], dtype=float32), 0.003168609]
[2019-03-23 17:50:36,894] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.3, 35.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 334977.7824499079, 334977.7824499079, 124796.9726774332]
[2019-03-23 17:50:36,895] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:50:36,897] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.3810720e-04 1.0031402e-11 9.9966192e-01 4.6338901e-12 7.4619352e-11], sampled 0.8101415596083292
[2019-03-23 17:50:56,015] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00512796], dtype=float32), 0.003168609]
[2019-03-23 17:50:56,016] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.1, 79.0, 1.0, 2.0, 0.2235568794204352, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4502921837120165, 6.911200000000001, 6.9112, 95.55338769695034, 510087.9776771581, 510087.9776771577, 175430.9370753745]
[2019-03-23 17:50:56,017] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:50:56,020] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.3892023e-04 9.6476097e-14 9.9976104e-01 4.0085499e-14 1.3725527e-12], sampled 0.37792556461743065
[2019-03-23 17:51:05,350] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00512796], dtype=float32), 0.003168609]
[2019-03-23 17:51:05,352] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 100.0, 1.0, 2.0, 0.2395374693948117, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4839886036121211, 6.9112, 6.9112, 77.32846344354104, 546515.4656093498, 546515.4656093498, 175634.9150345197]
[2019-03-23 17:51:05,352] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:51:05,354] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.4650604e-04 8.8336470e-14 9.9975353e-01 3.6828755e-14 1.2650725e-12], sampled 0.6081031286805649
[2019-03-23 17:51:32,932] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00512796], dtype=float32), 0.003168609]
[2019-03-23 17:51:32,932] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.0, 48.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3725518113581156, 6.9112, 6.9112, 95.55338769695034, 427083.715466059, 427083.715466059, 162271.2330388594]
[2019-03-23 17:51:32,933] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:51:32,936] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.0017301e-04 6.7323322e-13 9.9969983e-01 2.9252160e-13 7.4139644e-12], sampled 0.6267767004247907
[2019-03-23 17:51:43,799] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3119.9758 2108818154.8577 371.0000
[2019-03-23 17:51:44,102] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3616.4026 2175182114.0039 245.0000
[2019-03-23 17:51:44,228] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3363.9780 2097868743.7698 181.0000
[2019-03-23 17:51:44,235] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2763.1010 2123929566.1554 757.0000
[2019-03-23 17:51:44,312] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3519.2264 2104008862.9278 180.0000
[2019-03-23 17:51:45,330] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 625000, evaluation results [625000.0, 3616.402616428714, 2175182114.0038753, 245.0, 3363.9779732888833, 2097868743.7697678, 181.0, 3519.2264410977314, 2104008862.9278386, 180.0, 2763.101039727622, 2123929566.1554155, 757.0, 3119.9757912816076, 2108818154.8577166, 371.0]
[2019-03-23 17:51:46,868] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.1754860e-04 1.2411689e-09 9.9908245e-01 2.1065920e-10 2.7631817e-09], sum to 1.0000
[2019-03-23 17:51:46,875] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1858
[2019-03-23 17:51:46,881] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [15.7, 71.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 239994.3053299002, 239994.3053298999, 96614.2084529449], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7782000.0000, 
sim time next is 7782600.0000, 
raw observation next is [15.6, 71.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 238572.265013991, 238572.2650139913, 96251.61006077987], 
processed observation next is [1.0, 0.043478260869565216, 0.34545454545454546, 0.715, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08836009815333, 0.08836009815333011, 0.2347600245384875], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.01282465], dtype=float32), -0.75472766]. 
=============================================
[2019-03-23 17:51:55,452] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1374050e-05 4.4247420e-10 9.9998868e-01 2.7756589e-10 1.5767036e-10], sum to 1.0000
[2019-03-23 17:51:55,454] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7393
[2019-03-23 17:51:55,461] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.75, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.376472584241332, 6.9112, 6.9112, 77.32846344354104, 432858.0893566288, 432858.0893566288, 157055.118890797], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7705800.0000, 
sim time next is 7706400.0000, 
raw observation next is [17.56666666666667, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3655902088354885, 6.911199999999999, 6.9112, 77.32846344354104, 420773.9822312013, 420773.9822312016, 155274.6073883806], 
processed observation next is [1.0, 0.17391304347826086, 0.434848484848485, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.09370029833641214, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15584221564118567, 0.15584221564118578, 0.37871855460580633], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8472585], dtype=float32), 0.29538944]. 
=============================================
[2019-03-23 17:51:56,779] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:51:56,780] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:51:56,806] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run4
[2019-03-23 17:51:59,361] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.0340002e-07 4.8413572e-08 9.9999917e-01 2.5115526e-08 1.3374262e-09], sum to 1.0000
[2019-03-23 17:51:59,366] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3374
[2019-03-23 17:51:59,371] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [13.3, 96.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 221358.3664326669, 221358.3664326669, 93868.07535629986], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7797600.0000, 
sim time next is 7798200.0000, 
raw observation next is [13.48333333333333, 95.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 224207.6222087217, 224207.6222087217, 94860.13501526382], 
processed observation next is [1.0, 0.2608695652173913, 0.24924242424242413, 0.955, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.08303986007730434, 0.08303986007730434, 0.2313661829640581], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5152004], dtype=float32), -0.9557228]. 
=============================================
[2019-03-23 17:52:00,043] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.7447265e-07 3.6809329e-09 9.9999964e-01 8.3764347e-09 2.1939131e-10], sum to 1.0000
[2019-03-23 17:52:00,052] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1545
[2019-03-23 17:52:00,058] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [13.66666666666667, 89.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 217179.1990082877, 217179.1990082877, 92207.31108753751], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7792800.0000, 
sim time next is 7793400.0000, 
raw observation next is [13.48333333333333, 91.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 213388.7508109855, 213388.7508109858, 91515.97880174023], 
processed observation next is [1.0, 0.17391304347826086, 0.24924242424242413, 0.91, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07903287067073538, 0.07903287067073549, 0.22320970439448837], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.033149], dtype=float32), 0.75457263]. 
=============================================
[2019-03-23 17:52:05,342] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.0393444e-04 3.6474109e-12 9.9979609e-01 4.7831604e-12 5.9973929e-11], sum to 1.0000
[2019-03-23 17:52:05,350] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7329
[2019-03-23 17:52:05,354] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.6, 93.0, 1.0, 2.0, 0.2971011869668644, 0.0, 2.0, 0.0, 1.0, 2.0, 0.595933229216953, 6.9112, 6.9112, 77.32846344354104, 677385.3875181315, 677385.3875181315, 186303.1155519671], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7909800.0000, 
sim time next is 7910400.0000, 
raw observation next is [20.7, 93.0, 1.0, 2.0, 0.3783033418921443, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7598198817834037, 6.9112, 6.9112, 77.32846344354104, 863051.7402242526, 863051.7402242526, 211233.3248750209], 
processed observation next is [1.0, 0.5652173913043478, 0.5772727272727273, 0.93, 1.0, 1.0, 0.22287917736518037, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6568855454048624, 0.0, 0.0, 0.5084288129206541, 0.3196487926756491, 0.3196487926756491, 0.51520323140249], 
reward next is 0.4848, 
noisyNet noise sample is [array([-0.16260535], dtype=float32), 2.1089826]. 
=============================================
[2019-03-23 17:52:07,003] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:52:07,004] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:52:07,025] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run4
[2019-03-23 17:52:07,409] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:52:07,409] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:52:07,411] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run4
[2019-03-23 17:52:07,647] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:52:07,647] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:52:07,650] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run4
[2019-03-23 17:52:07,867] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:52:07,867] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:52:07,869] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run4
[2019-03-23 17:52:08,189] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:52:08,189] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:52:08,193] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run4
[2019-03-23 17:52:08,210] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:52:08,212] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:52:08,218] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run4
[2019-03-23 17:52:08,257] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:52:08,257] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:52:08,258] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:52:08,258] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:52:08,266] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run4
[2019-03-23 17:52:08,286] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run4
[2019-03-23 17:52:08,409] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:52:08,410] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:52:08,411] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run4
[2019-03-23 17:52:08,493] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:52:08,493] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:52:08,494] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run4
[2019-03-23 17:52:08,573] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:52:08,573] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:52:08,574] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run4
[2019-03-23 17:52:08,610] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:52:08,610] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:52:08,612] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run4
[2019-03-23 17:52:08,622] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:52:08,622] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:52:08,623] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run4
[2019-03-23 17:52:08,654] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:52:08,654] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:52:08,734] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run4
[2019-03-23 17:52:08,769] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:52:08,769] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:52:08,770] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run4
[2019-03-23 17:52:09,436] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.8408278e-05 5.9486645e-08 9.9997151e-01 9.5087316e-08 4.7103068e-08], sum to 1.0000
[2019-03-23 17:52:09,436] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2009
[2019-03-23 17:52:09,472] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.5, 91.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3437610605642595, 6.911199999999999, 6.9112, 77.32846344354104, 397822.9397833479, 397822.9397833482, 150472.3960157922], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 9000.0000, 
sim time next is 9600.0000, 
raw observation next is [17.43333333333333, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3431555203349931, 6.9112, 6.9112, 77.32846344354104, 397494.8465193326, 397494.8465193326, 150028.914185938], 
processed observation next is [1.0, 0.08695652173913043, 0.42878787878787866, 0.9, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.061650743335704423, 0.0, 0.0, 0.5084288129206541, 0.14722031352567874, 0.14722031352567874, 0.3659241809413122], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.71450615], dtype=float32), 0.47355345]. 
=============================================
[2019-03-23 17:52:15,223] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.4406086e-06 4.5807496e-09 9.9999762e-01 1.6766778e-08 1.3466365e-09], sum to 1.0000
[2019-03-23 17:52:15,230] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5576
[2019-03-23 17:52:15,236] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.0, 80.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 230381.8895516044, 230381.8895516047, 93426.76698465353], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 110400.0000, 
sim time next is 111000.0000, 
raw observation next is [14.0, 81.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 227628.253974695, 227628.253974695, 93085.16189901698], 
processed observation next is [1.0, 0.2608695652173913, 0.2727272727272727, 0.8116666666666668, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.08430676073136852, 0.08430676073136852, 0.22703698024150484], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0496868], dtype=float32), 0.73306185]. 
=============================================
[2019-03-23 17:52:15,252] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[7.2435827]
 [7.230733 ]
 [7.156308 ]
 [7.172491 ]
 [6.9810915]], R is [[7.11232996]
 [7.04120684]
 [6.97079468]
 [6.90108681]
 [6.83207607]].
[2019-03-23 17:52:29,615] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.6946445e-06 3.0516976e-09 9.9999332e-01 1.5703552e-09 1.7071031e-09], sum to 1.0000
[2019-03-23 17:52:29,623] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8354
[2019-03-23 17:52:29,630] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.0, 54.83333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3476086239039367, 6.9112, 6.9112, 77.32846344354104, 404420.3957349999, 404420.3957349999, 133114.7706191906], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 389400.0000, 
sim time next is 390000.0000, 
raw observation next is [20.0, 53.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 343160.0945775724, 343160.0945775727, 124178.9102408826], 
processed observation next is [1.0, 0.5217391304347826, 0.5454545454545454, 0.5366666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12709633132502682, 0.12709633132502693, 0.30287539083142095], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.92782706], dtype=float32), -0.8544154]. 
=============================================
[2019-03-23 17:52:29,646] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[18.945616]
 [18.561604]
 [18.630836]
 [18.328747]
 [17.909756]], R is [[17.95165062]
 [17.77213478]
 [17.59441376]
 [17.41847038]
 [17.24428558]].
[2019-03-23 17:52:36,494] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 17:52:36,495] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:52:36,497] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:52:36,498] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:52:36,500] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:52:36,501] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:52:36,501] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:52:36,498] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:52:36,503] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:52:36,505] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:52:36,502] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:52:36,526] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run27
[2019-03-23 17:52:36,526] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run27
[2019-03-23 17:52:36,549] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run27
[2019-03-23 17:52:36,601] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run27
[2019-03-23 17:52:36,601] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run27
[2019-03-23 17:52:44,240] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0056681], dtype=float32), 0.0032802247]
[2019-03-23 17:52:44,242] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.58333333333333, 67.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 95.55338769695034, 250121.587891035, 250121.5878910354, 101682.3661329698]
[2019-03-23 17:52:44,245] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:52:44,247] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0024095e-06 1.1827271e-07 9.9999881e-01 1.4168626e-07 5.0980131e-09], sampled 0.8066638522658214
[2019-03-23 17:52:45,429] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0056681], dtype=float32), 0.0032802247]
[2019-03-23 17:52:45,430] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.7, 60.16666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3270342883010687, 6.911200000000001, 6.9112, 95.55338769695034, 380445.720348365, 380445.7203483646, 127327.4363506966]
[2019-03-23 17:52:45,433] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:52:45,435] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.8227056e-07 3.6305561e-08 9.9999928e-01 3.8323059e-08 1.4892604e-09], sampled 0.5500342321507147
[2019-03-23 17:52:57,037] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0056681], dtype=float32), 0.0032802247]
[2019-03-23 17:52:57,038] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.435748115, 96.14703168, 1.0, 2.0, 0.2532029167831211, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5120173896950283, 6.911199999999999, 6.9112, 95.55338769695034, 577426.4097699807, 577426.409769981, 184018.3268538757]
[2019-03-23 17:52:57,040] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:52:57,047] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.1614289e-07 9.2746137e-11 9.9999928e-01 5.9615535e-11 2.2115780e-11], sampled 0.9987661485888542
[2019-03-23 17:53:27,146] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0056681], dtype=float32), 0.0032802247]
[2019-03-23 17:53:27,147] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.31576964333333, 67.23454492333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3150752221490807, 6.911199999999999, 6.9112, 95.55338769695034, 363745.0347372557, 363745.0347372561, 152579.4810899361]
[2019-03-23 17:53:27,148] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:53:27,150] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.6977886e-07 3.6515988e-09 9.9999988e-01 3.5561136e-09 1.5307926e-10], sampled 0.924749650976336
[2019-03-23 17:53:38,191] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0056681], dtype=float32), 0.0032802247]
[2019-03-23 17:53:38,192] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.56666666666667, 72.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.378112674936498, 6.9112, 6.9112, 95.55338769695034, 434056.8553817121, 434056.8553817121, 162476.8896422414]
[2019-03-23 17:53:38,194] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:53:38,197] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.21528574e-07 1.34503555e-08 9.99999642e-01 1.36581555e-08
 5.26810651e-10], sampled 0.7035040882269159
[2019-03-23 17:53:42,171] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0056681], dtype=float32), 0.0032802247]
[2019-03-23 17:53:42,173] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.96666666666667, 49.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3676448899731204, 6.9112, 6.9112, 95.55338769695034, 421133.1028622977, 421133.1028622977, 161915.0529201445]
[2019-03-23 17:53:42,174] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:53:42,177] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.392893e-07 5.666580e-09 9.999999e-01 6.006682e-09 1.870511e-10], sampled 0.7849981936758147
[2019-03-23 17:53:49,365] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0056681], dtype=float32), 0.0032802247]
[2019-03-23 17:53:49,367] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.5, 45.0, 1.0, 2.0, 0.3185430713666454, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6190975475053345, 6.9112, 6.9112, 77.32846344354104, 712999.961651657, 712999.961651657, 182234.3777381497]
[2019-03-23 17:53:49,368] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:53:49,371] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.3080656e-06 2.1883902e-10 9.9999869e-01 1.4331351e-10 6.0260276e-11], sampled 0.01431429706890519
[2019-03-23 17:53:51,593] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0056681], dtype=float32), 0.0032802247]
[2019-03-23 17:53:51,595] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.66666666666666, 74.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 343970.8669627435, 343970.8669627435, 143306.9862467468]
[2019-03-23 17:53:51,597] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:53:51,600] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.6698253e-07 2.6482606e-08 9.9999964e-01 2.9701910e-08 9.2600216e-10], sampled 0.6491697353966062
[2019-03-23 17:54:13,797] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3362.9579 2098021811.5714 179.0000
[2019-03-23 17:54:13,848] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3119.6529 2108994337.2869 368.0000
[2019-03-23 17:54:13,914] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3615.0043 2175244598.0285 245.0000
[2019-03-23 17:54:13,921] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3520.6533 2104073408.4994 178.0000
[2019-03-23 17:54:14,143] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2762.4669 2123977005.3311 757.0000
[2019-03-23 17:54:15,160] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 650000, evaluation results [650000.0, 3615.004316682353, 2175244598.028495, 245.0, 3362.9579322313657, 2098021811.5713768, 179.0, 3520.6532598806293, 2104073408.4993699, 178.0, 2762.466874839552, 2123977005.3310986, 757.0, 3119.6529270702254, 2108994337.28692, 368.0]
[2019-03-23 17:54:16,631] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.0875155e-07 7.2946392e-08 9.9999928e-01 1.1438971e-07 3.3575087e-09], sum to 1.0000
[2019-03-23 17:54:16,642] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4384
[2019-03-23 17:54:16,645] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [13.33333333333333, 98.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 225255.369638282, 225255.3696382817, 95412.62488750718], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 535200.0000, 
sim time next is 535800.0000, 
raw observation next is [13.16666666666667, 99.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 223426.0668872437, 223426.0668872437, 94803.87622952776], 
processed observation next is [1.0, 0.17391304347826086, 0.23484848484848497, 0.99, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.0827503951434236, 0.0827503951434236, 0.23122896641348234], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.85936904], dtype=float32), 0.5441559]. 
=============================================
[2019-03-23 17:54:19,052] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.3178695e-04 4.0504714e-11 9.9976820e-01 4.6408429e-11 1.1185311e-10], sum to 1.0000
[2019-03-23 17:54:19,060] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4121
[2019-03-23 17:54:19,065] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.83333333333334, 64.83333333333334, 1.0, 2.0, 0.2135401268490881, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4143032785656682, 6.9112, 6.9112, 77.32846344354104, 477267.9044353467, 477267.9044353467, 159984.4594159752], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 580200.0000, 
sim time next is 580800.0000, 
raw observation next is [21.66666666666667, 65.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.34578522794313, 6.9112, 6.9112, 77.32846344354104, 398580.7992647154, 398580.7992647154, 152252.2650625579], 
processed observation next is [1.0, 0.7391304347826086, 0.6212121212121214, 0.6566666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.06540746849018572, 0.0, 0.0, 0.5084288129206541, 0.14762251824619088, 0.14762251824619088, 0.3713469879574583], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.05269202], dtype=float32), 1.0812126]. 
=============================================
[2019-03-23 17:54:22,510] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.1674959e-06 1.2685970e-10 9.9999785e-01 2.5316796e-10 7.6579881e-11], sum to 1.0000
[2019-03-23 17:54:22,519] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0273
[2019-03-23 17:54:22,521] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 57.0, 1.0, 2.0, 0.3264800398267563, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6337248860844582, 6.911200000000001, 6.9112, 77.32846344354104, 730126.9279405825, 730126.9279405823, 183909.6355070526], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 644400.0000, 
sim time next is 645000.0000, 
raw observation next is [23.16666666666667, 57.0, 1.0, 2.0, 0.3485875097653103, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6779156929895472, 6.911199999999999, 6.9112, 77.32846344354104, 780648.6324414206, 780648.6324414209, 190247.3435026909], 
processed observation next is [1.0, 0.4782608695652174, 0.6893939393939396, 0.57, 1.0, 1.0, 0.18573438720663782, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5398795614136389, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.28912912312645206, 0.28912912312645217, 0.46401791098217293], 
reward next is 0.5360, 
noisyNet noise sample is [array([0.9303415], dtype=float32), 1.3995287]. 
=============================================
[2019-03-23 17:54:22,535] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[28.893978]
 [29.251541]
 [29.580288]
 [29.958424]
 [30.510159]], R is [[28.92124748]
 [29.18347549]
 [29.45702553]
 [29.71790123]
 [29.96016121]].
[2019-03-23 17:54:24,162] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.9731453e-06 6.7984689e-09 9.9999785e-01 1.2430398e-07 9.5346164e-10], sum to 1.0000
[2019-03-23 17:54:24,168] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5963
[2019-03-23 17:54:24,177] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.0, 54.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3463757554520046, 6.9112, 6.9112, 77.32846344354104, 398743.653440301, 398743.653440301, 152814.3948080401], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 674400.0000, 
sim time next is 675000.0000, 
raw observation next is [24.0, 54.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3495522676068971, 6.9112, 6.9112, 77.32846344354104, 402399.7669560779, 402399.7669560779, 153203.6488520282], 
processed observation next is [1.0, 0.8260869565217391, 0.7272727272727273, 0.54, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.07078895372413875, 0.0, 0.0, 0.5084288129206541, 0.1490369507244733, 0.1490369507244733, 0.37366743622445897], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3730383], dtype=float32), -0.057992823]. 
=============================================
[2019-03-23 17:54:24,199] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[5.9480276]
 [5.2455096]
 [5.008812 ]
 [4.8468285]
 [4.946027 ]], R is [[6.2358222 ]
 [6.17346382]
 [6.11172915]
 [6.05061197]
 [5.99010611]].
[2019-03-23 17:54:25,509] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.5509927e-06 1.4329633e-09 9.9999642e-01 6.6252565e-10 6.0971513e-11], sum to 1.0000
[2019-03-23 17:54:25,516] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4999
[2019-03-23 17:54:25,520] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.33333333333334, 61.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3430103858627126, 6.911199999999999, 6.9112, 77.32846344354104, 395466.7260295106, 395466.7260295108, 151836.7342215727], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 682800.0000, 
sim time next is 683400.0000, 
raw observation next is [22.16666666666667, 62.83333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3445398269137597, 6.911199999999999, 6.9112, 77.32846344354104, 397180.3383538571, 397180.3383538574, 152068.4529038813], 
processed observation next is [1.0, 0.9130434782608695, 0.6439393939393941, 0.6283333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.06362832416251384, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14710382901994706, 0.14710382901994717, 0.37089866561922263], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4590243], dtype=float32), -1.6701943]. 
=============================================
[2019-03-23 17:54:25,718] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.22286564e-07 6.70535516e-10 9.99999404e-01 1.08289089e-09
 1.13888614e-10], sum to 1.0000
[2019-03-23 17:54:25,726] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6999
[2019-03-23 17:54:25,733] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [15.83333333333333, 95.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 324937.5423608015, 324937.5423608018, 133498.1531869395], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 702600.0000, 
sim time next is 703200.0000, 
raw observation next is [15.66666666666667, 96.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 313606.0300153634, 313606.0300153637, 130329.0445440307], 
processed observation next is [1.0, 0.13043478260869565, 0.3484848484848486, 0.96, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11615038148717163, 0.11615038148717174, 0.31787571840007484], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.6281015], dtype=float32), -0.1952698]. 
=============================================
[2019-03-23 17:54:26,020] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.2315222e-08 4.2412954e-10 1.0000000e+00 1.4081332e-10 4.5936852e-12], sum to 1.0000
[2019-03-23 17:54:26,030] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0904
[2019-03-23 17:54:26,035] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.33333333333334, 69.0, 1.0, 2.0, 0.3782933886761611, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7560078416752136, 6.9112, 6.9112, 77.32846344354104, 861406.9707307076, 861406.9707307076, 208734.8724691977], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 724800.0000, 
sim time next is 725400.0000, 
raw observation next is [23.5, 69.0, 1.0, 2.0, 0.3742018117013031, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7487618229043341, 6.911199999999999, 6.9112, 77.32846344354104, 852538.7797764505, 852538.7797764508, 207976.3679323524], 
processed observation next is [1.0, 0.391304347826087, 0.7045454545454546, 0.69, 1.0, 1.0, 0.2177522646266289, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6410883184347631, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3157551036209076, 0.3157551036209077, 0.5072594339813473], 
reward next is 0.4927, 
noisyNet noise sample is [array([1.9848609], dtype=float32), -0.015849484]. 
=============================================
[2019-03-23 17:54:37,508] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7501081e-04 2.2410436e-13 9.9982506e-01 4.9653929e-14 1.6589720e-10], sum to 1.0000
[2019-03-23 17:54:37,515] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4163
[2019-03-23 17:54:37,518] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.5, 71.5, 1.0, 2.0, 0.2388230876912113, 0.0, 2.0, 0.0, 1.0, 2.0, 0.481990653438703, 6.9112, 6.9112, 77.32846344354104, 545015.3885296047, 545015.3885296047, 174863.6203088506], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 909000.0000, 
sim time next is 909600.0000, 
raw observation next is [24.0, 73.66666666666667, 1.0, 2.0, 0.2360517465151393, 0.0, 2.0, 0.0, 1.0, 2.0, 0.475997608620859, 6.9112, 6.9112, 77.32846344354104, 538707.417727383, 538707.417727383, 173862.4111405138], 
processed observation next is [0.0, 0.5217391304347826, 0.7272727272727273, 0.7366666666666667, 1.0, 1.0, 0.04506468314392411, 0.0, 1.0, -0.25, 1.0, 1.0, 0.25142515517265573, 0.0, 0.0, 0.5084288129206541, 0.19952126582495666, 0.19952126582495666, 0.42405466131832636], 
reward next is 0.5759, 
noisyNet noise sample is [array([-1.3915414], dtype=float32), 1.8343645]. 
=============================================
[2019-03-23 17:54:40,978] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2882322e-04 2.4229377e-10 9.9987113e-01 5.0446418e-12 3.6427866e-10], sum to 1.0000
[2019-03-23 17:54:40,987] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0662
[2019-03-23 17:54:40,990] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.2508289895614941, 0.0, 2.0, 0.0, 1.0, 2.0, 0.491845035485731, 6.911200000000001, 6.9112, 77.32846344354104, 564774.1228476963, 564774.122847696, 168994.2161861478], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 981000.0000, 
sim time next is 981600.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.2512669059848348, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4928968881805524, 6.9112, 6.9112, 77.32846344354104, 565907.0695655649, 565907.0695655649, 169170.5285289299], 
processed observation next is [1.0, 0.34782608695652173, 0.45454545454545453, 1.0, 1.0, 1.0, 0.0640836324810435, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2755669831150749, 0.0, 0.0, 0.5084288129206541, 0.20959521095020922, 0.20959521095020922, 0.4126110451925119], 
reward next is 0.5874, 
noisyNet noise sample is [array([-0.7773498], dtype=float32), -1.0266958]. 
=============================================
[2019-03-23 17:54:42,506] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0729686e-04 1.2646071e-08 9.9989271e-01 2.6698862e-08 4.7426925e-09], sum to 1.0000
[2019-03-23 17:54:42,512] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4965
[2019-03-23 17:54:42,516] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 240615.3513711593, 240615.3513711596, 97905.1273084851], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1023000.0000, 
sim time next is 1023600.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 238367.7047767392, 238367.7047767395, 97477.24876199574], 
processed observation next is [1.0, 0.8695652173913043, 0.22727272727272727, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.088284335102496, 0.08828433510249611, 0.23774938722437985], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.473639], dtype=float32), 1.1349927]. 
=============================================
[2019-03-23 17:54:46,941] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.5279145e-04 6.8367423e-10 9.9974722e-01 8.4173245e-11 3.4474149e-10], sum to 1.0000
[2019-03-23 17:54:46,949] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6796
[2019-03-23 17:54:46,954] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 94.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3360699461480846, 6.9112, 6.9112, 77.32846344354104, 387424.695148423, 387424.695148423, 151044.7755550253], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1138200.0000, 
sim time next is 1138800.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3327813669238159, 6.911200000000001, 6.9112, 77.32846344354104, 383620.9320705518, 383620.9320705515, 150666.0335854444], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 0.94, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.04683052417687985, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14208182669279695, 0.14208182669279684, 0.3674781306962059], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.07428065], dtype=float32), 1.9124072]. 
=============================================
[2019-03-23 17:54:54,585] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.4945408e-05 1.5222752e-11 9.9997509e-01 2.3594544e-12 7.0542075e-12], sum to 1.0000
[2019-03-23 17:54:54,594] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5171
[2019-03-23 17:54:54,598] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.0, 60.0, 1.0, 2.0, 0.7368963276470194, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9785800936782129, 6.9112, 6.9112, 77.32846344354104, 1384515.262073901, 1384515.262073901, 299040.7689901392], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1261800.0000, 
sim time next is 1262400.0000, 
raw observation next is [28.0, 60.66666666666666, 1.0, 2.0, 0.8313397522090508, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9793542729034047, 6.9112, 6.9112, 77.32846344354104, 1490939.925578447, 1490939.925578447, 315389.5744553435], 
processed observation next is [1.0, 0.6086956521739131, 0.9090909090909091, 0.6066666666666666, 1.0, 1.0, 0.7891746902613134, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9705061041477212, 0.0, 0.0, 0.5084288129206541, 0.5521999724364619, 0.5521999724364619, 0.7692428645252279], 
reward next is 0.2308, 
noisyNet noise sample is [array([0.65030116], dtype=float32), 0.20450453]. 
=============================================
[2019-03-23 17:54:56,295] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1486499e-05 1.4723075e-12 9.9998856e-01 1.4092528e-11 8.5387019e-12], sum to 1.0000
[2019-03-23 17:54:56,302] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0929
[2019-03-23 17:54:56,312] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.16666666666666, 61.33333333333334, 1.0, 2.0, 0.7040573991666709, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9757816176783463, 6.911199999999999, 6.9112, 77.32846344354104, 1349519.811921085, 1349519.811921085, 291260.6620012106], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1270200.0000, 
sim time next is 1270800.0000, 
raw observation next is [27.0, 62.0, 1.0, 2.0, 0.7365227848458712, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9756070504436235, 6.911199999999999, 6.9112, 77.32846344354104, 1386640.697527892, 1386640.697527893, 296057.6639431181], 
processed observation next is [1.0, 0.7391304347826086, 0.8636363636363636, 0.62, 1.0, 1.0, 0.6706534810573389, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9651529292051766, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.513570628714034, 0.5135706287140344, 0.7220918632758979], 
reward next is 0.2779, 
noisyNet noise sample is [array([-1.2308995], dtype=float32), -0.94298196]. 
=============================================
[2019-03-23 17:54:58,240] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.6614214e-05 2.4571270e-11 9.9997342e-01 6.3303904e-11 1.1140951e-10], sum to 1.0000
[2019-03-23 17:54:58,248] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7214
[2019-03-23 17:54:58,257] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3450837403238399, 6.9112, 6.9112, 77.32846344354104, 397779.0933291152, 397779.0933291152, 152161.0596327151], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1297800.0000, 
sim time next is 1298400.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.34690252124621, 6.9112, 6.9112, 77.32846344354104, 399873.7245708639, 399873.7245708639, 152382.8636953691], 
processed observation next is [1.0, 0.0, 0.45454545454545453, 0.94, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.06700360178030004, 0.0, 0.0, 0.5084288129206541, 0.14810137947069033, 0.14810137947069033, 0.37166552120821733], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.2034774], dtype=float32), -0.9121854]. 
=============================================
[2019-03-23 17:55:03,611] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.5021724e-04 1.1847706e-13 9.9914980e-01 6.6552872e-13 1.6181830e-12], sum to 1.0000
[2019-03-23 17:55:03,620] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8778
[2019-03-23 17:55:03,627] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.2312794080898743, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4656306663546241, 6.911199999999999, 6.9112, 77.32846344354104, 527737.4690593651, 527737.4690593653, 172173.3489988618], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1450800.0000, 
sim time next is 1451400.0000, 
raw observation next is [21.0, 94.00000000000001, 1.0, 2.0, 0.2303217642116457, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4636077524874616, 6.9112, 6.9112, 77.32846344354104, 525533.8270011899, 525533.8270011899, 171892.6872839929], 
processed observation next is [0.0, 0.8260869565217391, 0.5909090909090909, 0.9400000000000002, 1.0, 1.0, 0.03790220526455713, 0.0, 1.0, -0.25, 1.0, 1.0, 0.23372536069637376, 0.0, 0.0, 0.5084288129206541, 0.19464215814858887, 0.19464215814858887, 0.4192504567902266], 
reward next is 0.5807, 
noisyNet noise sample is [array([0.5573646], dtype=float32), -1.120845]. 
=============================================
[2019-03-23 17:55:05,252] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.1980391e-04 1.3102112e-13 9.9918014e-01 8.4838803e-12 4.2966113e-11], sum to 1.0000
[2019-03-23 17:55:05,261] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9693
[2019-03-23 17:55:05,273] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.33333333333333, 100.0, 1.0, 2.0, 0.2314762992041845, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4661776282859463, 6.911200000000001, 6.9112, 77.32846344354104, 528211.103992179, 528211.1039921787, 172343.3432188726], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1467600.0000, 
sim time next is 1468200.0000, 
raw observation next is [20.16666666666667, 100.0, 1.0, 2.0, 0.2282045426686925, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4590388381053451, 6.9112, 6.9112, 77.32846344354104, 520634.1256041912, 520634.1256041912, 171198.9240490719], 
processed observation next is [0.0, 1.0, 0.5530303030303032, 1.0, 1.0, 1.0, 0.03525567833586561, 0.0, 1.0, -0.25, 1.0, 1.0, 0.22719834015049306, 0.0, 0.0, 0.5084288129206541, 0.19282745392747822, 0.19282745392747822, 0.4175583513391998], 
reward next is 0.5824, 
noisyNet noise sample is [array([-1.3239925], dtype=float32), 1.2245744]. 
=============================================
[2019-03-23 17:55:05,341] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 17:55:05,343] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:55:05,343] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:55:05,343] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:55:05,344] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:55:05,345] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:55:05,346] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:55:05,346] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:55:05,346] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:55:05,347] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:55:05,348] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:55:05,362] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run28
[2019-03-23 17:55:05,363] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run28
[2019-03-23 17:55:05,409] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run28
[2019-03-23 17:55:05,412] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run28
[2019-03-23 17:55:05,457] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run28
[2019-03-23 17:55:13,308] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00586911], dtype=float32), 0.0035988907]
[2019-03-23 17:55:13,310] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [11.13433384, 83.87997529, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 198230.3206850292, 198230.3206850288, 88787.33230109219]
[2019-03-23 17:55:13,311] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:55:13,315] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.6609152e-04 4.1107791e-11 9.9963391e-01 3.0229055e-11 2.3022695e-10], sampled 0.8312076142899718
[2019-03-23 17:55:20,611] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00586911], dtype=float32), 0.0035988907]
[2019-03-23 17:55:20,612] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [28.63333333333333, 61.0, 1.0, 2.0, 0.3369070229974561, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6818251698755567, 6.911200000000001, 6.9112, 95.55338769695034, 761313.7930760497, 761313.7930760493, 211861.9786505403]
[2019-03-23 17:55:20,613] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:55:20,616] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.6590954e-04 6.6472831e-13 9.9963403e-01 5.3249972e-13 8.6259853e-12], sampled 0.8251023003364182
[2019-03-23 17:56:13,915] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00586911], dtype=float32), 0.0035988907]
[2019-03-23 17:56:13,916] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.74674490166667, 87.06336565166667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 248124.355041161, 248124.355041161, 105506.6728508052]
[2019-03-23 17:56:13,916] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:56:13,920] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.7073862e-04 2.0247177e-11 9.9962926e-01 1.4845849e-11 1.3885344e-10], sampled 0.8645556331489577
[2019-03-23 17:56:15,741] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00586911], dtype=float32), 0.0035988907]
[2019-03-23 17:56:15,742] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.60822622, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3473419325550881, 6.911200000000001, 6.9112, 95.55338769695034, 399915.5792341493, 399915.5792341489, 157430.1338697975]
[2019-03-23 17:56:15,743] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:56:15,747] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.7269536e-04 3.1082084e-12 9.9952734e-01 2.3647039e-12 3.4540589e-11], sampled 0.6303255761691259
[2019-03-23 17:56:24,117] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00586911], dtype=float32), 0.0035988907]
[2019-03-23 17:56:24,118] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.63601750833334, 80.11920094833333, 1.0, 2.0, 0.3317257399550238, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6712070398056172, 6.9112, 6.9112, 95.55338769695034, 745485.0647462433, 745485.0647462433, 211915.3626462795]
[2019-03-23 17:56:24,119] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:56:24,121] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.5343160e-04 3.2057102e-13 9.9954659e-01 2.5625121e-13 5.0804248e-12], sampled 0.3070031064321467
[2019-03-23 17:56:42,250] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2760.8527 2123780808.1099 761.0000
[2019-03-23 17:56:42,294] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3617.7435 2175065762.7452 247.0000
[2019-03-23 17:56:42,685] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3520.2908 2103693759.4494 184.0000
[2019-03-23 17:56:42,722] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3121.4870 2108797588.9690 369.0000
[2019-03-23 17:56:42,723] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3362.2651 2097843964.9003 182.0000
[2019-03-23 17:56:43,737] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 675000, evaluation results [675000.0, 3617.7435118123517, 2175065762.7452216, 247.0, 3362.2650908770697, 2097843964.900295, 182.0, 3520.290777816812, 2103693759.449432, 184.0, 2760.852691137536, 2123780808.1098585, 761.0, 3121.4869623012187, 2108797588.9690323, 369.0]
[2019-03-23 17:56:52,306] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1206300e-04 1.4497124e-11 9.9988794e-01 6.3385241e-11 6.2717560e-11], sum to 1.0000
[2019-03-23 17:56:52,312] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7729
[2019-03-23 17:56:52,316] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 65.0, 1.0, 2.0, 0.4789766120793599, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9418961162133935, 6.958447441097625, 6.9112, 77.3283459987861, 1092496.665643441, 1077151.686457873, 252228.6092766646], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1598400.0000, 
sim time next is 1599000.0000, 
raw observation next is [26.1, 64.66666666666667, 1.0, 2.0, 0.6453706990003716, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9731007618331419, 6.911199999999999, 6.9112, 81.25878223720332, 1284034.259070364, 1284034.259070364, 281491.268985019], 
processed observation next is [1.0, 0.5217391304347826, 0.8227272727272728, 0.6466666666666667, 1.0, 1.0, 0.5567133737504645, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9615725169044885, -8.881784197001253e-17, 0.0, 0.5342703624572027, 0.4755682441001348, 0.4755682441001348, 0.6865640706951683], 
reward next is 0.3134, 
noisyNet noise sample is [array([1.1218399], dtype=float32), 0.40858376]. 
=============================================
[2019-03-23 17:56:52,340] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[40.571045]
 [40.56993 ]
 [40.66319 ]
 [40.720493]
 [40.633007]], R is [[40.48818588]
 [40.23187637]
 [40.23022079]
 [40.23884201]
 [40.26039886]].
[2019-03-23 17:56:58,599] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.3832359e-06 5.2965834e-07 9.9998939e-01 7.1839651e-07 3.3521534e-08], sum to 1.0000
[2019-03-23 17:56:58,608] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8333
[2019-03-23 17:56:58,613] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.33333333333333, 51.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 266216.809253199, 266216.809253199, 99279.01195485725], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1708800.0000, 
sim time next is 1709400.0000, 
raw observation next is [17.16666666666667, 51.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 262715.3910325018, 262715.3910325021, 98492.05775357591], 
processed observation next is [1.0, 0.782608695652174, 0.4166666666666669, 0.515, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09730199667870437, 0.09730199667870448, 0.2402245311062827], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.3739358], dtype=float32), -0.023567688]. 
=============================================
[2019-03-23 17:57:00,996] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.2218594e-06 8.2905043e-09 9.9999166e-01 5.3399265e-08 5.4235603e-09], sum to 1.0000
[2019-03-23 17:57:01,005] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3867
[2019-03-23 17:57:01,011] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [10.66666666666667, 72.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3518519990002278, 6.9112, 6.9112, 77.32846344354104, 409359.3694310055, 409359.3694310055, 116314.927105327], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1752600.0000, 
sim time next is 1753200.0000, 
raw observation next is [11.0, 71.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3596650804391304, 6.9112, 6.9112, 77.32846344354104, 418453.3476211993, 418453.3476211993, 117512.7746420495], 
processed observation next is [1.0, 0.30434782608695654, 0.13636363636363635, 0.71, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.08523582919875777, 0.0, 0.0, 0.5084288129206541, 0.15498272134118493, 0.15498272134118493, 0.2866165235171939], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4184682], dtype=float32), -1.3801324]. 
=============================================
[2019-03-23 17:57:08,252] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.8291084e-05 2.8419325e-07 9.9998081e-01 7.0253702e-07 2.9147770e-08], sum to 1.0000
[2019-03-23 17:57:08,261] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3120
[2019-03-23 17:57:08,265] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.66666666666667, 59.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 292055.1100591012, 292055.1100591009, 117824.8594863849], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1892400.0000, 
sim time next is 1893000.0000, 
raw observation next is [19.33333333333333, 61.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 287850.8998445239, 287850.8998445239, 117443.175716799], 
processed observation next is [1.0, 0.9130434782608695, 0.5151515151515149, 0.615, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.10661144438686071, 0.10661144438686071, 0.2864467700409732], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.44989124], dtype=float32), 0.58619565]. 
=============================================
[2019-03-23 17:57:08,283] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[4.9379487]
 [4.9204407]
 [4.962139 ]
 [4.9943643]
 [4.994675 ]], R is [[4.88493538]
 [4.83608627]
 [4.78772545]
 [4.73984814]
 [4.69244957]].
[2019-03-23 17:57:14,335] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.6036187e-07 7.6641314e-08 9.9999905e-01 2.7681301e-08 2.0115318e-09], sum to 1.0000
[2019-03-23 17:57:14,344] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9635
[2019-03-23 17:57:14,349] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.83333333333333, 48.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3040137326068993, 6.9112, 6.9112, 77.32846344354104, 352039.5404440322, 352039.5404440322, 145720.8388564834], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2040600.0000, 
sim time next is 2041200.0000, 
raw observation next is [24.0, 47.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3039783956479141, 6.911199999999999, 6.9112, 77.32846344354104, 352048.4303451878, 352048.4303451881, 145665.2039086684], 
processed observation next is [0.0, 0.6521739130434783, 0.7272727272727273, 0.47, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.00568342235416305, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13038830753525474, 0.13038830753525485, 0.35528098514309364], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.41887426], dtype=float32), 0.23192622]. 
=============================================
[2019-03-23 17:57:14,930] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.2118518e-06 2.1415653e-07 9.9999535e-01 2.4645317e-07 9.5421289e-09], sum to 1.0000
[2019-03-23 17:57:14,938] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2378
[2019-03-23 17:57:14,943] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 64.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 288689.9488156607, 288689.9488156604, 117848.4889468809], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2066400.0000, 
sim time next is 2067000.0000, 
raw observation next is [19.0, 63.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 287639.6406881928, 287639.6406881931, 116731.2711466657], 
processed observation next is [0.0, 0.9565217391304348, 0.5, 0.6333333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10653320025488622, 0.10653320025488633, 0.284710417430892], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.6467857], dtype=float32), 1.0775459]. 
=============================================
[2019-03-23 17:57:14,961] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[0.899426  ]
 [0.89475596]
 [0.87182975]
 [0.8395707 ]
 [0.8322134 ]], R is [[0.92282093]
 [0.9135927 ]
 [0.90445679]
 [0.89541221]
 [0.8864581 ]].
[2019-03-23 17:57:20,285] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.5069238e-07 1.2542296e-08 9.9999928e-01 6.8707626e-09 4.9487847e-10], sum to 1.0000
[2019-03-23 17:57:20,294] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4477
[2019-03-23 17:57:20,301] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 51.0, 1.0, 2.0, 0.2065453990682689, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4129707138428987, 6.9112, 6.9112, 77.32846344354104, 470230.8706402871, 470230.8706402871, 165095.6285629649], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2131200.0000, 
sim time next is 2131800.0000, 
raw observation next is [26.83333333333333, 51.5, 1.0, 2.0, 0.2080054083622671, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4159177841454842, 6.9112, 6.9112, 77.32846344354104, 473570.1898276295, 473570.1898276295, 165380.659359567], 
processed observation next is [0.0, 0.6956521739130435, 0.8560606060606059, 0.515, 1.0, 1.0, 0.010006760452833871, 0.0, 1.0, -0.25, 1.0, 1.0, 0.16559683449354887, 0.0, 0.0, 0.5084288129206541, 0.17539636660282573, 0.17539636660282573, 0.40336746185260247], 
reward next is 0.5966, 
noisyNet noise sample is [array([-0.94872385], dtype=float32), -0.38054198]. 
=============================================
[2019-03-23 17:57:20,912] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.7441396e-05 3.4917107e-08 9.9997246e-01 3.5266694e-08 9.6331787e-09], sum to 1.0000
[2019-03-23 17:57:20,921] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9517
[2019-03-23 17:57:20,930] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 75.0, 1.0, 2.0, 0.306713095456816, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5725661557348188, 6.9112, 6.9112, 77.32846344354104, 666323.4749055696, 666323.4749055696, 168936.7816340443], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2467800.0000, 
sim time next is 2468400.0000, 
raw observation next is [18.0, 74.33333333333333, 1.0, 2.0, 0.3048763524389971, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5691373589068939, 6.9112, 6.9112, 77.32846344354104, 662330.4957136337, 662330.4957136337, 167713.7585019969], 
processed observation next is [1.0, 0.5652173913043478, 0.45454545454545453, 0.7433333333333333, 1.0, 1.0, 0.13109544054874633, 0.0, 1.0, -0.25, 1.0, 1.0, 0.38448194129556273, 0.0, 0.0, 0.5084288129206541, 0.24530759100504954, 0.24530759100504954, 0.40905794756584607], 
reward next is 0.5909, 
noisyNet noise sample is [array([0.0708952], dtype=float32), 0.42138547]. 
=============================================
[2019-03-23 17:57:21,347] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.4562884e-06 1.9142754e-09 9.9999452e-01 5.1512000e-10 6.9500722e-10], sum to 1.0000
[2019-03-23 17:57:21,358] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0289
[2019-03-23 17:57:21,361] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 54.0, 1.0, 2.0, 0.2059091840971155, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4104968437541637, 6.9112, 6.9112, 77.32846344354104, 468144.2228325692, 468144.2228325692, 164218.4647352657], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2137200.0000, 
sim time next is 2137800.0000, 
raw observation next is [26.0, 54.0, 1.0, 2.0, 0.2062969214962048, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4112695257629756, 6.9112, 6.9112, 77.32846344354104, 469026.0159926661, 469026.0159926661, 164287.8965879369], 
processed observation next is [0.0, 0.7391304347826086, 0.8181818181818182, 0.54, 1.0, 1.0, 0.007871151870255978, 0.0, 1.0, -0.25, 1.0, 1.0, 0.15895646537567945, 0.0, 0.0, 0.5084288129206541, 0.173713339256543, 0.173713339256543, 0.4007021867998461], 
reward next is 0.5993, 
noisyNet noise sample is [array([0.3236282], dtype=float32), -0.679393]. 
=============================================
[2019-03-23 17:57:22,883] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.5097791e-06 4.1409219e-08 9.9999738e-01 2.5585939e-08 2.5842977e-09], sum to 1.0000
[2019-03-23 17:57:22,896] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3450
[2019-03-23 17:57:22,901] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.83333333333333, 88.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3088569771048409, 6.9112, 6.9112, 77.32846344354104, 357540.3306613929, 357540.3306613929, 146366.6508218316], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2160600.0000, 
sim time next is 2161200.0000, 
raw observation next is [17.66666666666667, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3065480425235957, 6.911200000000001, 6.9112, 77.32846344354104, 355148.867794698, 355148.8677946978, 145818.8685896009], 
processed observation next is [1.0, 0.0, 0.4393939393939396, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.00935434646227957, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13153661770174, 0.13153661770173994, 0.35565577704780704], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6464177], dtype=float32), -0.17717463]. 
=============================================
[2019-03-23 17:57:28,619] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1082434e-06 2.0980840e-08 9.9999893e-01 1.7058573e-08 4.5479784e-09], sum to 1.0000
[2019-03-23 17:57:28,628] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1122
[2019-03-23 17:57:28,637] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 56.0, 1.0, 2.0, 0.2121759155861498, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3960859517450299, 6.9112, 6.9112, 77.32846344354104, 460847.3953198079, 460847.3953198079, 130659.6449251621], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2286000.0000, 
sim time next is 2286600.0000, 
raw observation next is [18.0, 55.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3722918428080718, 6.9112, 6.9112, 77.32846344354104, 433150.5336043517, 433150.5336043517, 127928.4523584664], 
processed observation next is [1.0, 0.4782608695652174, 0.45454545454545453, 0.5533333333333335, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.10327406115438834, 0.0, 0.0, 0.5084288129206541, 0.1604261235571673, 0.1604261235571673, 0.3120206155084546], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.16322449], dtype=float32), 1.2249311]. 
=============================================
[2019-03-23 17:57:30,038] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.7075636e-06 1.6549502e-07 9.9999404e-01 9.9346970e-08 6.0729781e-09], sum to 1.0000
[2019-03-23 17:57:30,046] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8368
[2019-03-23 17:57:30,054] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.0, 55.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 254385.5043881015, 254385.5043881012, 97478.07283417601], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2325000.0000, 
sim time next is 2325600.0000, 
raw observation next is [17.0, 55.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 253851.8372110259, 253851.8372110256, 97380.26198760513], 
processed observation next is [1.0, 0.9565217391304348, 0.4090909090909091, 0.55, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09401919896704664, 0.09401919896704651, 0.23751283411611007], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7314491], dtype=float32), -2.0490186]. 
=============================================
[2019-03-23 17:57:33,932] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 17:57:33,933] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:57:33,935] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:57:33,936] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:57:33,939] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:57:33,941] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:57:33,941] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:57:33,947] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:57:33,949] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:57:33,950] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:57:33,951] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:57:33,952] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run29
[2019-03-23 17:57:33,987] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run29
[2019-03-23 17:57:34,014] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run29
[2019-03-23 17:57:34,035] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run29
[2019-03-23 17:57:34,071] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run29
[2019-03-23 17:57:49,942] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00620896], dtype=float32), 0.0035587396]
[2019-03-23 17:57:49,945] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.5, 57.5, 1.0, 2.0, 0.2740605431452524, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5521414770987869, 6.911200000000001, 6.9112, 95.55338769695034, 625396.9692421284, 625396.9692421281, 187092.4514425195]
[2019-03-23 17:57:49,946] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:57:49,948] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.6319829e-05 2.2537186e-10 9.9998367e-01 1.6557576e-10 1.8616467e-10], sampled 0.6800210084548051
[2019-03-23 17:57:58,670] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00620896], dtype=float32), 0.0035587396]
[2019-03-23 17:57:58,672] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.4, 74.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 273601.9486641804, 273601.94866418, 117703.0234335201]
[2019-03-23 17:57:58,675] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:57:58,678] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.9223905e-05 1.3562503e-09 9.9996078e-01 1.0565995e-09 1.1374208e-09], sampled 0.5822491364381606
[2019-03-23 17:58:05,385] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00620896], dtype=float32), 0.0035587396]
[2019-03-23 17:58:05,387] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.37238999666667, 77.54705155666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 223043.2395439674, 223043.239543967, 94923.56227241053]
[2019-03-23 17:58:05,387] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:58:05,390] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.4008819e-05 2.3982591e-09 9.9994600e-01 1.8777819e-09 2.0360515e-09], sampled 0.8739529576982727
[2019-03-23 17:58:20,140] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00620896], dtype=float32), 0.0035587396]
[2019-03-23 17:58:20,141] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [29.51443577333333, 67.70358809333334, 1.0, 2.0, 0.5735076483807648, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9152839816240921, 7.009855518676366, 6.9112, 95.55299554111633, 1192727.959403951, 1153135.271991956, 273808.8377706406]
[2019-03-23 17:58:20,141] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:58:20,142] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.1421179e-05 7.8944226e-11 9.9998856e-01 5.8775568e-11 6.8580475e-11], sampled 0.08265176113100414
[2019-03-23 17:58:45,213] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00620896], dtype=float32), 0.0035587396]
[2019-03-23 17:58:45,214] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.46666666666667, 78.66666666666667, 1.0, 2.0, 0.2009784680481441, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3751827702837711, 6.9112, 6.9112, 77.32846344354104, 436515.5520282196, 436515.5520282196, 124158.2165137047]
[2019-03-23 17:58:45,214] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:58:45,216] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.2340788e-04 9.2398295e-10 9.9987662e-01 6.2926692e-10 1.4170447e-09], sampled 0.13561091039273576
[2019-03-23 17:58:47,030] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00620896], dtype=float32), 0.0035587396]
[2019-03-23 17:58:47,031] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.1, 42.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.338827770564965, 6.911200000000001, 6.9112, 95.55338769695034, 394169.8206403728, 394169.8206403724, 142588.8181468883]
[2019-03-23 17:58:47,034] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:58:47,036] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.2198097e-05 4.1704991e-09 9.9997783e-01 3.5367909e-09 2.0451152e-09], sampled 0.29801905438386744
[2019-03-23 17:58:49,545] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00620896], dtype=float32), 0.0035587396]
[2019-03-23 17:58:49,545] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.8, 93.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3448767311909933, 6.911200000000001, 6.9112, 95.55338769695034, 398145.6717429777, 398145.6717429773, 156110.5857742866]
[2019-03-23 17:58:49,546] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:58:49,548] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.6682049e-05 1.6903996e-10 9.9995327e-01 1.1319514e-10 2.4238903e-10], sampled 0.4298523803444988
[2019-03-23 17:58:55,000] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00620896], dtype=float32), 0.0035587396]
[2019-03-23 17:58:55,000] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.93623891, 97.45968725666665, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3021929493635013, 6.9112, 6.9112, 95.55338769695034, 351424.4735035092, 351424.4735035092, 148652.5314341336]
[2019-03-23 17:58:55,001] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:58:55,002] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.8836345e-05 1.5762897e-09 9.9998116e-01 1.2785407e-09 8.7389357e-10], sampled 0.0664806148752699
[2019-03-23 17:58:56,053] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00620896], dtype=float32), 0.0035587396]
[2019-03-23 17:58:56,055] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.06501557, 51.9338777, 1.0, 2.0, 0.2176113171567595, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4328047255431851, 6.911200000000001, 6.9112, 95.55338769695034, 494117.5619494559, 494117.5619494555, 170458.6346781629]
[2019-03-23 17:58:56,058] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:58:56,059] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.0637097e-05 5.3528060e-10 9.9997938e-01 4.0006487e-10 3.9680165e-10], sampled 0.44531220001966054
[2019-03-23 17:59:09,823] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3614.1741 2175327363.0663 245.0000
[2019-03-23 17:59:09,923] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3118.8146 2109043552.0607 368.0000
[2019-03-23 17:59:09,967] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3519.8705 2104069816.8657 178.0000
[2019-03-23 17:59:10,075] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2759.5712 2124013801.9203 757.0000
[2019-03-23 17:59:10,099] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3362.1704 2098038620.9528 179.0000
[2019-03-23 17:59:11,115] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 700000, evaluation results [700000.0, 3614.1740929847015, 2175327363.066292, 245.0, 3362.17043381659, 2098038620.9527724, 179.0, 3519.870480882709, 2104069816.865651, 178.0, 2759.571247146694, 2124013801.920311, 757.0, 3118.8146269445274, 2109043552.0607457, 368.0]
[2019-03-23 17:59:15,368] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.04203579e-03 1.03032685e-08 9.90957975e-01 8.10592216e-09
 1.19846906e-08], sum to 1.0000
[2019-03-23 17:59:15,377] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6385
[2019-03-23 17:59:15,382] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.16666666666667, 83.00000000000001, 1.0, 2.0, 0.2612711291732083, 0.0, 2.0, 0.0, 1.0, 2.0, 0.487735959928263, 6.9112, 6.9112, 77.32846344354104, 567544.7507091012, 567544.7507091012, 149938.0122763474], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2455800.0000, 
sim time next is 2456400.0000, 
raw observation next is [16.33333333333334, 84.0, 1.0, 2.0, 0.2531881815213483, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4726468674422109, 6.9112, 6.9112, 77.32846344354104, 549976.679484333, 549976.679484333, 150779.3064147556], 
processed observation next is [1.0, 0.43478260869565216, 0.37878787878787906, 0.84, 1.0, 1.0, 0.06648522690168537, 0.0, 1.0, -0.25, 1.0, 1.0, 0.24663838206030134, 0.0, 0.0, 0.5084288129206541, 0.2036950664756789, 0.2036950664756789, 0.36775440588964786], 
reward next is 0.6322, 
noisyNet noise sample is [array([0.45910582], dtype=float32), -0.77972794]. 
=============================================
[2019-03-23 17:59:20,660] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.1277824e-05 2.4439759e-09 9.9993873e-01 3.2977112e-09 1.0776783e-09], sum to 1.0000
[2019-03-23 17:59:20,668] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7267
[2019-03-23 17:59:20,672] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.66666666666667, 61.33333333333334, 1.0, 2.0, 0.2354429461496302, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4414909006154541, 6.9112, 6.9112, 77.32846344354104, 512738.6928882706, 512738.6928882706, 158151.5180460884], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2551200.0000, 
sim time next is 2551800.0000, 
raw observation next is [20.83333333333333, 60.66666666666666, 1.0, 2.0, 0.2367118894334343, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4444546012095943, 6.911199999999999, 6.9112, 77.32846344354104, 516045.8670383243, 516045.8670383246, 158559.7080176113], 
processed observation next is [1.0, 0.5217391304347826, 0.5833333333333331, 0.6066666666666666, 1.0, 1.0, 0.04588986179179286, 0.0, 1.0, -0.25, 1.0, 1.0, 0.20636371601370615, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19112809890308308, 0.1911280989030832, 0.3867309951649056], 
reward next is 0.6133, 
noisyNet noise sample is [array([1.5148633], dtype=float32), 0.6325946]. 
=============================================
[2019-03-23 17:59:20,935] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.3714576e-05 3.8089187e-08 9.9996614e-01 2.7286976e-08 7.4377375e-09], sum to 1.0000
[2019-03-23 17:59:20,944] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5262
[2019-03-23 17:59:20,949] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.86666666666667, 64.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 287796.2004096826, 287796.2004096824, 116470.2770654228], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2582400.0000, 
sim time next is 2583000.0000, 
raw observation next is [18.8, 64.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 283917.8200031202, 283917.8200031199, 115148.4420819279], 
processed observation next is [1.0, 0.9130434782608695, 0.49090909090909096, 0.64, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10515474814930378, 0.10515474814930366, 0.2808498587364095], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0145698], dtype=float32), -1.0091323]. 
=============================================
[2019-03-23 17:59:20,967] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[13.880018]
 [13.784937]
 [13.696661]
 [13.714348]
 [13.622562]], R is [[13.7550621 ]
 [13.61751175]
 [13.48133659]
 [13.34652328]
 [13.21305847]].
[2019-03-23 17:59:29,581] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.3816302e-04 2.7703057e-10 9.9906188e-01 7.8281814e-10 2.0876545e-09], sum to 1.0000
[2019-03-23 17:59:29,589] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9359
[2019-03-23 17:59:29,595] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 65.66666666666667, 1.0, 2.0, 0.2286024215344648, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4601107627953127, 6.9112, 6.9112, 77.32846344354104, 521601.6351900882, 521601.6351900882, 171503.8485037786], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2731800.0000, 
sim time next is 2732400.0000, 
raw observation next is [25.0, 65.0, 1.0, 2.0, 0.2261792729893863, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4548918382829054, 6.9112, 6.9112, 77.32846344354104, 515993.2660426903, 515993.2660426903, 170723.5131421046], 
processed observation next is [0.0, 0.6521739130434783, 0.7727272727272727, 0.65, 1.0, 1.0, 0.03272409123673287, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2212740546898649, 0.0, 0.0, 0.5084288129206541, 0.19110861705284826, 0.19110861705284826, 0.41639881254171857], 
reward next is 0.5836, 
noisyNet noise sample is [array([1.2207195], dtype=float32), -0.41293854]. 
=============================================
[2019-03-23 17:59:29,837] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.5677464e-04 3.5052843e-11 9.9954331e-01 1.3799403e-10 1.2363862e-09], sum to 1.0000
[2019-03-23 17:59:29,843] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3119
[2019-03-23 17:59:29,850] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.33333333333334, 53.0, 1.0, 2.0, 0.2090234763054521, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4173419775709106, 6.9112, 6.9112, 77.32846344354104, 475576.226399452, 475576.226399452, 165174.8672033952], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2742000.0000, 
sim time next is 2742600.0000, 
raw observation next is [26.16666666666667, 53.5, 1.0, 2.0, 0.2084286293653613, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4159038405546686, 6.9112, 6.9112, 77.32846344354104, 474087.7343450539, 474087.7343450539, 164909.2060837469], 
processed observation next is [0.0, 0.7391304347826086, 0.825757575757576, 0.535, 1.0, 1.0, 0.010535786706701612, 0.0, 1.0, -0.25, 1.0, 1.0, 0.16557691507809805, 0.0, 0.0, 0.5084288129206541, 0.17558804975742737, 0.17558804975742737, 0.4022175758140168], 
reward next is 0.5978, 
noisyNet noise sample is [array([0.11862418], dtype=float32), 1.6549524]. 
=============================================
[2019-03-23 17:59:31,800] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.44611867e-02 5.81672444e-09 9.85538840e-01 1.01888666e-08
 1.00553645e-08], sum to 1.0000
[2019-03-23 17:59:31,807] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5055
[2019-03-23 17:59:31,816] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.30598761976215, 6.911199999999999, 6.9112, 77.32846344354104, 354002.7727720167, 354002.772772017, 146270.9649216407], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2785200.0000, 
sim time next is 2785800.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3058075622711462, 6.9112, 6.9112, 77.32846344354104, 353794.7631565211, 353794.7631565211, 146250.6471038394], 
processed observation next is [1.0, 0.21739130434782608, 0.45454545454545453, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.008296517530208864, 0.0, 0.0, 0.5084288129206541, 0.13103509746537817, 0.13103509746537817, 0.35670889537521805], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0394509], dtype=float32), -0.22944322]. 
=============================================
[2019-03-23 17:59:43,517] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1606893e-06 6.7062363e-11 9.9999785e-01 1.2806604e-10 2.7577948e-10], sum to 1.0000
[2019-03-23 17:59:43,526] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3546
[2019-03-23 17:59:43,530] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.4794376793074351, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9447603748872391, 6.956801665399748, 6.9112, 77.32833626100044, 1090845.761510128, 1076035.297662536, 255180.458752725], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2983200.0000, 
sim time next is 2983800.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.4727268968547202, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9399338458299241, 6.941629621488723, 6.9112, 77.32836003497707, 1075625.633656665, 1065742.728206591, 253584.7468174702], 
processed observation next is [1.0, 0.5217391304347826, 0.9090909090909091, 0.58, 1.0, 1.0, 0.3409086210684002, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9141912083284632, 0.0030429621488723413, 0.0, 0.5084281330171478, 0.39837986431728334, 0.3947195289654041, 0.6184993824816346], 
reward next is 0.2294, 
noisyNet noise sample is [array([-0.15013795], dtype=float32), -0.29580072]. 
=============================================
[2019-03-23 17:59:50,787] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3562846e-04 9.3448464e-11 9.9986434e-01 4.7048386e-11 4.0221459e-10], sum to 1.0000
[2019-03-23 17:59:50,798] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2777
[2019-03-23 17:59:50,803] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.66666666666667, 88.66666666666667, 1.0, 2.0, 0.2554782997729566, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5169207906784871, 6.911200000000001, 6.9112, 77.32846344354104, 582413.0656062365, 582413.0656062362, 180283.925846897], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3111600.0000, 
sim time next is 3112200.0000, 
raw observation next is [22.5, 88.5, 1.0, 2.0, 0.2521005339009814, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5097701707656178, 6.9112, 6.9112, 77.32846344354104, 574988.667590254, 574988.667590254, 179005.0156159053], 
processed observation next is [1.0, 0.0, 0.6590909090909091, 0.885, 1.0, 1.0, 0.06512566737622676, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2996716725223112, 0.0, 0.0, 0.5084288129206541, 0.21295876577416814, 0.21295876577416814, 0.43659759906318363], 
reward next is 0.5634, 
noisyNet noise sample is [array([-1.5704244], dtype=float32), -1.2913142]. 
=============================================
[2019-03-23 17:59:52,074] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2267347e-03 2.2265223e-11 9.9877328e-01 5.2520776e-11 1.2091927e-09], sum to 1.0000
[2019-03-23 17:59:52,074] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6852
[2019-03-23 17:59:52,080] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 73.83333333333334, 1.0, 2.0, 0.2186170055678795, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4373971918720349, 6.9112, 6.9112, 77.32846344354104, 497868.6301986277, 497868.6301986277, 167546.3399606734], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3175800.0000, 
sim time next is 3176400.0000, 
raw observation next is [23.0, 74.66666666666667, 1.0, 2.0, 0.2220597983686063, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4447626306930602, 6.9112, 6.9112, 77.32846344354104, 505932.4886812943, 505932.4886812943, 168533.7683802875], 
processed observation next is [1.0, 0.782608695652174, 0.6818181818181818, 0.7466666666666667, 1.0, 1.0, 0.027574747960757845, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2068037581329432, 0.0, 0.0, 0.5084288129206541, 0.1873824032152942, 0.1873824032152942, 0.41105797165923785], 
reward next is 0.5889, 
noisyNet noise sample is [array([0.19662489], dtype=float32), 0.04399797]. 
=============================================
[2019-03-23 17:59:52,389] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3577483e-04 1.4501828e-09 9.9986422e-01 7.1638517e-10 9.1670410e-10], sum to 1.0000
[2019-03-23 17:59:52,398] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5185
[2019-03-23 17:59:52,407] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.5, 76.5, 1.0, 2.0, 0.5722275479310084, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9698634514254606, 6.911199999999999, 6.9112, 77.32846344354104, 1201455.182883198, 1201455.182883198, 266727.0895357347], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3151800.0000, 
sim time next is 3152400.0000, 
raw observation next is [22.66666666666667, 80.33333333333333, 1.0, 2.0, 0.5845078355659165, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9683899375645968, 6.9112, 6.9112, 77.32846344354104, 1215603.895689443, 1215603.895689443, 266931.9748256], 
processed observation next is [1.0, 0.4782608695652174, 0.6666666666666669, 0.8033333333333332, 1.0, 1.0, 0.48063479445739554, 0.0, 1.0, -0.25, 1.0, 1.0, 0.954842767949424, 0.0, 0.0, 0.5084288129206541, 0.4502236650701641, 0.4502236650701641, 0.6510535971356097], 
reward next is 0.3489, 
noisyNet noise sample is [array([0.71012765], dtype=float32), -1.3208659]. 
=============================================
[2019-03-23 17:59:53,538] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.5022287e-05 1.3296653e-10 9.9996495e-01 1.0693886e-10 1.1926053e-09], sum to 1.0000
[2019-03-23 17:59:53,545] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1015
[2019-03-23 17:59:53,552] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.16666666666667, 73.16666666666667, 1.0, 2.0, 0.2172345194608323, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4351718351404263, 6.9112, 6.9112, 77.32846344354104, 494965.5667680186, 494965.5667680186, 167643.1184457879], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3174600.0000, 
sim time next is 3175200.0000, 
raw observation next is [23.0, 73.0, 1.0, 2.0, 0.2161574131938442, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4322765350973764, 6.911200000000001, 6.9112, 77.32846344354104, 492168.0877247069, 492168.0877247066, 166942.8677097378], 
processed observation next is [1.0, 0.782608695652174, 0.6818181818181818, 0.73, 1.0, 1.0, 0.02019676649230525, 0.0, 1.0, -0.25, 1.0, 1.0, 0.18896647871053773, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18228447693507663, 0.18228447693507652, 0.4071777261213117], 
reward next is 0.5928, 
noisyNet noise sample is [array([0.32786724], dtype=float32), -0.27309322]. 
=============================================
[2019-03-23 17:59:55,896] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.8383266e-07 6.4655794e-08 9.9999964e-01 7.3859233e-08 1.4777052e-09], sum to 1.0000
[2019-03-23 17:59:55,907] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8020
[2019-03-23 17:59:55,910] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.66666666666666, 55.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3475088688152417, 6.911199999999999, 6.9112, 77.32846344354104, 400119.0536907823, 400119.0536907826, 152886.0679386548], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3235800.0000, 
sim time next is 3236400.0000, 
raw observation next is [24.0, 54.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3472821767271222, 6.9112, 6.9112, 77.32846344354104, 399808.4108409886, 399808.4108409886, 152905.1084623839], 
processed observation next is [0.0, 0.4782608695652174, 0.7272727272727273, 0.54, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.06754596675303172, 0.0, 0.0, 0.5084288129206541, 0.14807718920036617, 0.14807718920036617, 0.37293928893264366], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.46108657], dtype=float32), 1.0782814]. 
=============================================
[2019-03-23 17:59:57,443] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4957241e-06 3.7245542e-07 9.9999785e-01 2.1184502e-07 3.6788768e-09], sum to 1.0000
[2019-03-23 17:59:57,445] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5151
[2019-03-23 17:59:57,449] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.1, 48.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3077059234006345, 6.9112, 6.9112, 77.32846344354104, 355955.6694184687, 355955.6694184687, 146498.1150209961], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3247200.0000, 
sim time next is 3247800.0000, 
raw observation next is [24.08333333333334, 48.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3114783180495843, 6.9112, 6.9112, 77.32846344354104, 360239.6463580909, 360239.6463580909, 147001.4024913977], 
processed observation next is [0.0, 0.6086956521739131, 0.7310606060606063, 0.4833333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.016397597213691894, 0.0, 0.0, 0.5084288129206541, 0.13342209124373738, 0.13342209124373738, 0.3585400060765797], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.5666013], dtype=float32), 0.80309665]. 
=============================================
[2019-03-23 18:00:01,091] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 18:00:01,092] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:00:01,092] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:00:01,094] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:00:01,095] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:00:01,095] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:00:01,096] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:00:01,099] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:00:01,102] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:00:01,103] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:00:01,103] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:00:01,121] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run30
[2019-03-23 18:00:01,122] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run30
[2019-03-23 18:00:01,122] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run30
[2019-03-23 18:00:01,192] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run30
[2019-03-23 18:00:01,218] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run30
[2019-03-23 18:00:16,914] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00652011], dtype=float32), 0.0037345188]
[2019-03-23 18:00:16,915] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.40078821666667, 67.94580277666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3634779779551387, 6.911200000000001, 6.9112, 95.55338769695034, 422544.9931975113, 422544.993197511, 155650.6213899893]
[2019-03-23 18:00:16,915] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:00:16,919] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.6888217e-07 1.5938603e-08 9.9999940e-01 2.3191459e-08 8.7256041e-10], sampled 0.6817117779431928
[2019-03-23 18:00:22,041] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00652011], dtype=float32), 0.0037345188]
[2019-03-23 18:00:22,042] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.1, 82.0, 1.0, 2.0, 0.2279137758975313, 0.0, 2.0, 0.0, 1.0, 2.0, 0.457233919979031, 6.911200000000001, 6.9112, 95.55338769695034, 519532.2903005512, 519532.2903005509, 174910.2655356832]
[2019-03-23 18:00:22,044] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:00:22,046] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.81436990e-07 8.88010498e-10 9.99999642e-01 1.21179788e-09
 1.00665996e-10], sampled 0.09412378301196644
[2019-03-23 18:00:37,603] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00652011], dtype=float32), 0.0037345188]
[2019-03-23 18:00:37,604] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.33073814333333, 94.01632385666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 247932.0386814742, 247932.0386814742, 106752.5092506096]
[2019-03-23 18:00:37,605] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:00:37,609] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.3332487e-06 1.3955875e-07 9.9999833e-01 2.0624540e-07 6.9610211e-09], sampled 0.01593522704789896
[2019-03-23 18:01:00,257] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00652011], dtype=float32), 0.0037345188]
[2019-03-23 18:01:00,258] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.06666666666667, 59.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3846935008868453, 6.911200000000001, 6.9112, 95.55338769695034, 442578.800784916, 442578.8007849157, 162480.1266624837]
[2019-03-23 18:01:00,260] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:01:00,264] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.5986819e-07 4.6378226e-09 9.9999928e-01 6.1949161e-09 3.9693826e-10], sampled 0.8099620991563459
[2019-03-23 18:01:00,271] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00652011], dtype=float32), 0.0037345188]
[2019-03-23 18:01:00,272] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.2, 70.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 257252.6235023234, 257252.623502323, 109321.9387958932]
[2019-03-23 18:01:00,275] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:01:00,278] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.1431398e-06 1.2057802e-07 9.9999845e-01 1.7906612e-07 5.8675513e-09], sampled 0.5717676177167811
[2019-03-23 18:01:00,779] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00652011], dtype=float32), 0.0037345188]
[2019-03-23 18:01:00,780] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.49104664166667, 86.31763368166668, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 220644.2559479054, 220644.255947905, 98887.07180585148]
[2019-03-23 18:01:00,781] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:01:00,783] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.3205177e-07 5.8409828e-08 9.9999917e-01 8.5828646e-08 2.5891422e-09], sampled 0.16261862535817273
[2019-03-23 18:01:04,249] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00652011], dtype=float32), 0.0037345188]
[2019-03-23 18:01:04,253] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [12.8, 89.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 199998.23046006, 199998.2304600596, 91542.99399009402]
[2019-03-23 18:01:04,253] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:01:04,257] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.0168613e-07 6.2965803e-08 9.9999917e-01 9.1314988e-08 2.6927751e-09], sampled 0.8307362164534525
[2019-03-23 18:01:11,993] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00652011], dtype=float32), 0.0037345188]
[2019-03-23 18:01:11,994] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.68333333333334, 44.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 271901.9530143797, 271901.9530143794, 105435.9024802894]
[2019-03-23 18:01:11,995] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:01:11,997] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.5127854e-06 3.1125185e-07 9.9999678e-01 4.5623349e-07 1.7859401e-08], sampled 0.6357191271834206
[2019-03-23 18:01:23,075] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00652011], dtype=float32), 0.0037345188]
[2019-03-23 18:01:23,077] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.96188949166667, 91.47510051333335, 1.0, 2.0, 0.2382860751795165, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4775322267925939, 6.9112, 6.9112, 95.55338769695034, 542981.4564409625, 542981.4564409625, 176745.9104754939]
[2019-03-23 18:01:23,078] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:01:23,081] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.7912507e-07 1.2659747e-09 9.9999940e-01 1.7164219e-09 1.5917079e-10], sampled 0.7083734892945951
[2019-03-23 18:01:29,271] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00652011], dtype=float32), 0.0037345188]
[2019-03-23 18:01:29,275] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.28333333333333, 75.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 342085.30646672, 342085.30646672, 145198.097279757]
[2019-03-23 18:01:29,276] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:01:29,281] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.0247309e-07 2.7370975e-08 9.9999940e-01 4.1179785e-08 1.1894842e-09], sampled 0.35797158789228256
[2019-03-23 18:01:38,049] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3614.1741 2175328192.4682 245.0000
[2019-03-23 18:01:38,104] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2760.8201 2124051587.7039 757.0000
[2019-03-23 18:01:38,556] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3119.6511 2108992648.7084 368.0000
[2019-03-23 18:01:38,573] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3520.6977 2104039715.8352 178.0000
[2019-03-23 18:01:38,736] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3363.0106 2098009196.3145 179.0000
[2019-03-23 18:01:39,751] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 725000, evaluation results [725000.0, 3614.1740929846937, 2175328192.4681787, 245.0, 3363.010561098141, 2098009196.3145123, 179.0, 3520.697732357001, 2104039715.8352482, 178.0, 2760.8200524271624, 2124051587.7038968, 757.0, 3119.6510902387913, 2108992648.7083936, 368.0]
[2019-03-23 18:01:44,724] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.4696290e-04 2.3701778e-11 9.9945301e-01 1.5147194e-11 1.2406148e-11], sum to 1.0000
[2019-03-23 18:01:44,734] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4669
[2019-03-23 18:01:44,742] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.66666666666666, 62.5, 1.0, 2.0, 0.3609301037238738, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7302971246940818, 6.911199999999999, 6.9112, 77.32846344354104, 823002.3294409362, 823002.3294409364, 210635.0701329787], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3415800.0000, 
sim time next is 3416400.0000, 
raw observation next is [27.0, 62.0, 1.0, 2.0, 0.3129915317987128, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6336070423983456, 6.911199999999999, 6.9112, 77.32846344354104, 713161.2296071318, 713161.2296071321, 196136.8514053714], 
processed observation next is [1.0, 0.5652173913043478, 0.8636363636363636, 0.62, 1.0, 1.0, 0.141239414748391, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4765814891404938, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.26413378874338217, 0.2641337887433823, 0.47838256440334487], 
reward next is 0.5216, 
noisyNet noise sample is [array([-0.35767075], dtype=float32), -0.72084993]. 
=============================================
[2019-03-23 18:01:44,817] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2729476e-03 7.2764315e-11 9.9872702e-01 1.3756342e-11 6.1065966e-09], sum to 1.0000
[2019-03-23 18:01:44,826] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6428
[2019-03-23 18:01:44,831] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.3891919408453153, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7780454664436155, 6.9112, 6.9112, 77.32846344354104, 886376.0112022109, 886376.0112022109, 212517.6745031775], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3405000.0000, 
sim time next is 3405600.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.3462190344311102, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6919117844251337, 6.911199999999999, 6.9112, 77.32846344354104, 788313.4257211876, 788313.4257211878, 198657.1991312415], 
processed observation next is [1.0, 0.43478260869565216, 0.6363636363636364, 0.78, 1.0, 1.0, 0.18277379303888772, 0.0, 1.0, -0.25, 1.0, 1.0, 0.559873977750191, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2919679354522917, 0.29196793545229177, 0.4845297539786378], 
reward next is 0.5155, 
noisyNet noise sample is [array([-0.616854], dtype=float32), 0.9340965]. 
=============================================
[2019-03-23 18:01:51,494] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.4582675e-04 2.2614367e-12 9.9915421e-01 1.4711015e-12 7.2366980e-11], sum to 1.0000
[2019-03-23 18:01:51,501] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2912
[2019-03-23 18:01:51,508] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.33333333333334, 71.33333333333333, 1.0, 2.0, 0.2736802889013188, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5543330242483826, 6.9112, 6.9112, 77.32846344354104, 620733.1625800604, 620733.1625800604, 187316.5508628539], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3526800.0000, 
sim time next is 3527400.0000, 
raw observation next is [26.16666666666667, 72.66666666666667, 1.0, 2.0, 0.2755602110060992, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5581117053535188, 6.9112, 6.9112, 77.32846344354104, 624771.5419407645, 624771.5419407645, 187926.8431517948], 
processed observation next is [1.0, 0.8260869565217391, 0.825757575757576, 0.7266666666666667, 1.0, 1.0, 0.09445026375762396, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3687310076478841, 0.0, 0.0, 0.5084288129206541, 0.23139686738546833, 0.23139686738546833, 0.45835815402876784], 
reward next is 0.5416, 
noisyNet noise sample is [array([0.24980712], dtype=float32), 1.2388136]. 
=============================================
[2019-03-23 18:01:52,916] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.02163156e-04 1.19503825e-11 9.99697924e-01 1.08987264e-11
 6.65974886e-10], sum to 1.0000
[2019-03-23 18:01:52,923] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1761
[2019-03-23 18:01:52,929] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.3083901545514183, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6240139007144895, 6.911199999999999, 6.9112, 77.32846344354104, 703083.6946060893, 703083.6946060896, 194293.5786967058], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3553800.0000, 
sim time next is 3554400.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.2892498847463161, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5852788895565122, 6.9112, 6.9112, 77.32846344354104, 659423.6456932412, 659423.6456932412, 188939.5735108601], 
processed observation next is [1.0, 0.13043478260869565, 0.6363636363636364, 0.94, 1.0, 1.0, 0.11156235593289508, 0.0, 1.0, -0.25, 1.0, 1.0, 0.40754127079501745, 0.0, 0.0, 0.5084288129206541, 0.24423097988638562, 0.24423097988638562, 0.4608282280752685], 
reward next is 0.5392, 
noisyNet noise sample is [array([1.1559337], dtype=float32), -0.2630308]. 
=============================================
[2019-03-23 18:01:54,357] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5253994e-04 5.7670341e-10 9.9984741e-01 2.5495808e-10 3.9129788e-09], sum to 1.0000
[2019-03-23 18:01:54,366] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7104
[2019-03-23 18:01:54,380] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 2 has been changed to 3 for the demand 1811045.412067672 W.
[2019-03-23 18:01:54,388] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.83333333333334, 70.0, 1.0, 2.0, 0.5857274512655107, 1.0, 2.0, 0.5366521625743627, 1.0, 2.0, 0.9865530188920543, 6.9112, 6.9112, 77.61789310144609, 1811045.412067672, 1811045.412067672, 371907.1966486314], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3597000.0000, 
sim time next is 3597600.0000, 
raw observation next is [27.66666666666667, 70.0, 1.0, 2.0, 0.7899537452613071, 1.0, 2.0, 0.7899537452613071, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1777200.71837531, 1777200.71837531, 321475.7528580602], 
processed observation next is [1.0, 0.6521739130434783, 0.8939393939393941, 0.7, 1.0, 1.0, 0.7374421815766338, 1.0, 1.0, 0.7374421815766338, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.6582224882871519, 0.6582224882871519, 0.7840872020928297], 
reward next is 0.2159, 
noisyNet noise sample is [array([0.3570819], dtype=float32), 0.21460237]. 
=============================================
[2019-03-23 18:02:00,311] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.7612588e-04 4.1705116e-12 9.9962389e-01 4.9664253e-12 6.2706978e-11], sum to 1.0000
[2019-03-23 18:02:00,322] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4878
[2019-03-23 18:02:00,327] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3596534263004726, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7279006195521476, 6.911200000000001, 6.9112, 77.32846337003363, 819847.3253754817, 819847.3253754814, 210519.0173126017], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3724200.0000, 
sim time next is 3724800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3308691393044109, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6695864009829088, 6.9112, 6.9112, 77.32846344308604, 754262.112534159, 754262.112534159, 201141.3798743749], 
processed observation next is [1.0, 0.08695652173913043, 0.6363636363636364, 0.94, 1.0, 1.0, 0.16358642413051364, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5279805728327269, 0.0, 0.0, 0.5084288129176625, 0.27935633797561443, 0.27935633797561443, 0.49058873140091436], 
reward next is 0.5094, 
noisyNet noise sample is [array([1.4743077], dtype=float32), -0.49323437]. 
=============================================
[2019-03-23 18:02:01,582] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3861133e-03 3.8287107e-09 9.9861383e-01 2.0836029e-10 2.0339364e-09], sum to 1.0000
[2019-03-23 18:02:01,588] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0059
[2019-03-23 18:02:01,594] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.2559182225151257, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5177780044168562, 6.9112, 6.9112, 77.32846344354104, 583452.7854301023, 583452.7854301023, 180336.0159324667], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3718800.0000, 
sim time next is 3719400.0000, 
raw observation next is [22.0, 94.00000000000001, 1.0, 2.0, 0.2548101425915275, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5155112900235791, 6.911200000000001, 6.9112, 77.32846344354104, 580951.0936993841, 580951.0936993839, 180031.1172069644], 
processed observation next is [1.0, 0.043478260869565216, 0.6363636363636364, 0.9400000000000002, 1.0, 1.0, 0.06851267823940937, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3078732714622559, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21516707174051264, 0.21516707174051256, 0.4391002858706449], 
reward next is 0.5609, 
noisyNet noise sample is [array([0.912358], dtype=float32), -1.6881757]. 
=============================================
[2019-03-23 18:02:15,523] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.7352663e-06 2.8569028e-07 9.9999321e-01 8.3595978e-07 3.9152539e-08], sum to 1.0000
[2019-03-23 18:02:15,536] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2739
[2019-03-23 18:02:15,544] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.16666666666666, 76.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 318066.8492314044, 318066.8492314044, 135656.1391262552], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3973800.0000, 
sim time next is 3974400.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 314448.6469200488, 314448.6469200488, 133327.0864708779], 
processed observation next is [1.0, 0.0, 0.45454545454545453, 0.77, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.11646246182224029, 0.11646246182224029, 0.325188015782629], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.2716783], dtype=float32), -1.3030891]. 
=============================================
[2019-03-23 18:02:16,154] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0232435e-05 1.1640086e-08 9.9998975e-01 7.9309022e-09 1.5880633e-09], sum to 1.0000
[2019-03-23 18:02:16,163] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9470
[2019-03-23 18:02:16,166] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.83333333333334, 73.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 327083.5444634098, 327083.5444634095, 140665.0062734258], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3971400.0000, 
sim time next is 3972000.0000, 
raw observation next is [18.66666666666667, 74.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 324152.661573103, 324152.6615731027, 140146.5451494361], 
processed observation next is [0.0, 1.0, 0.4848484848484851, 0.7433333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12005654132337147, 0.12005654132337137, 0.34182084182789296], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.8086741], dtype=float32), -0.559042]. 
=============================================
[2019-03-23 18:02:16,181] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[19.443806]
 [19.265146]
 [19.32746 ]
 [19.298918]
 [19.227537]], R is [[19.39307594]
 [19.19914627]
 [19.00715446]
 [18.81708336]
 [18.62891197]].
[2019-03-23 18:02:25,137] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.4274090e-05 8.2941798e-10 9.9997568e-01 1.1911427e-09 3.7862505e-10], sum to 1.0000
[2019-03-23 18:02:25,145] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3195
[2019-03-23 18:02:25,150] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3613264044767902, 6.9112, 6.9112, 77.32846344354104, 415037.1744666042, 415037.1744666042, 155503.5664951204], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4154400.0000, 
sim time next is 4155000.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3871093045688603, 6.9112, 6.9112, 77.32846344354104, 444636.6653154541, 444636.6653154541, 158836.2518038761], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.12444186366980042, 0.0, 0.0, 0.5084288129206541, 0.16468024641313117, 0.16468024641313117, 0.3874054922045759], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.39596286], dtype=float32), 0.23489268]. 
=============================================
[2019-03-23 18:02:25,164] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[28.915535]
 [27.145128]
 [27.275606]
 [26.016497]
 [25.917315]], R is [[27.85263443]
 [27.57410812]
 [27.29836655]
 [27.025383  ]
 [26.75512886]].
[2019-03-23 18:02:26,598] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.7819939e-06 1.0748483e-07 9.9999380e-01 2.4056700e-07 1.1062588e-08], sum to 1.0000
[2019-03-23 18:02:26,608] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8556
[2019-03-23 18:02:26,611] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3541858768126235, 6.9112, 6.9112, 77.32846344354104, 407621.5181973063, 407621.5181973063, 153878.7365778508], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4230000.0000, 
sim time next is 4230600.0000, 
raw observation next is [19.0, 88.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3552608160382799, 6.9112, 6.9112, 77.32846344354104, 408856.89922977, 408856.89922977, 154013.3772108321], 
processed observation next is [1.0, 1.0, 0.5, 0.8800000000000001, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.07894402291182848, 0.0, 0.0, 0.5084288129206541, 0.1514284811962111, 0.1514284811962111, 0.37564238344105394], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.04842421], dtype=float32), -0.38792524]. 
=============================================
[2019-03-23 18:02:27,078] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.8362782e-06 1.3483775e-08 9.9999213e-01 2.1841663e-08 1.2102896e-09], sum to 1.0000
[2019-03-23 18:02:27,087] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0297
[2019-03-23 18:02:27,092] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.66666666666667, 73.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3841934644425581, 6.9112, 6.9112, 77.32846344354104, 440349.0003440228, 440349.0003440228, 159287.2385653072], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4542000.0000, 
sim time next is 4542600.0000, 
raw observation next is [21.33333333333333, 73.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3720435563617754, 6.911200000000001, 6.9112, 77.32846344354104, 427145.436545102, 427145.4365451017, 157050.3327236449], 
processed observation next is [0.0, 0.5652173913043478, 0.6060606060606059, 0.73, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.10291936623110771, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15820201353522295, 0.15820201353522284, 0.38304959200889005], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.397412], dtype=float32), -1.3151786]. 
=============================================
[2019-03-23 18:02:29,947] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 18:02:29,948] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:02:29,949] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:02:29,950] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:02:29,950] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:02:29,952] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:02:29,953] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:02:29,954] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:02:29,955] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:02:29,955] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:02:29,959] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:02:29,977] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run31
[2019-03-23 18:02:29,978] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run31
[2019-03-23 18:02:29,999] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run31
[2019-03-23 18:02:30,000] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run31
[2019-03-23 18:02:30,085] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run31
[2019-03-23 18:02:51,523] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00687371], dtype=float32), 0.0037845823]
[2019-03-23 18:02:51,524] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [29.73333333333333, 48.0, 1.0, 2.0, 0.2516241201695659, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5090782195317095, 6.911199999999999, 6.9112, 95.55338769695034, 573605.1909249387, 573605.190924939, 184016.8079101486]
[2019-03-23 18:02:51,526] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:02:51,528] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.4162290e-06 1.2122725e-09 9.9999261e-01 1.2722839e-09 5.6592891e-10], sampled 0.753387853427906
[2019-03-23 18:03:17,655] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00687371], dtype=float32), 0.0037845823]
[2019-03-23 18:03:17,656] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [30.468434635, 54.305900725, 1.0, 2.0, 0.4662724483390002, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8762371304467983, 7.002919535933191, 6.9112, 95.55310008230086, 1049796.52435827, 1012987.363172859, 252985.6311529563]
[2019-03-23 18:03:17,657] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:03:17,661] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.6922931e-05 9.8633969e-11 9.9995303e-01 9.4003631e-11 2.0835776e-10], sampled 0.048956495261199384
[2019-03-23 18:03:36,150] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00687371], dtype=float32), 0.0037845823]
[2019-03-23 18:03:36,152] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.86286264666667, 45.26843823, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3197224863583913, 6.911200000000002, 6.9112, 95.55338769695034, 369986.7840587085, 369986.7840587078, 152245.7127452297]
[2019-03-23 18:03:36,153] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:03:36,155] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.3195919e-06 3.0997873e-07 9.9999702e-01 4.2370121e-07 1.5493423e-08], sampled 0.4203643088861473
[2019-03-23 18:03:40,907] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00687371], dtype=float32), 0.0037845823]
[2019-03-23 18:03:40,908] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.99483300333333, 40.98265717666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 318083.8389375067, 318083.8389375063, 127663.8873404411]
[2019-03-23 18:03:40,909] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:03:40,911] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.0600547e-06 9.2117580e-07 9.9999285e-01 1.2242717e-06 5.3591869e-08], sampled 0.2975423886212555
[2019-03-23 18:04:03,634] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00687371], dtype=float32), 0.0037845823]
[2019-03-23 18:04:03,636] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.04729886000001, 87.27268055, 1.0, 2.0, 0.2209623523694325, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4420573230914015, 6.9112, 6.9112, 95.55338769695034, 503147.5061410712, 503147.5061410712, 172660.9348782243]
[2019-03-23 18:04:03,636] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:04:03,639] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.5297423e-06 6.3935821e-09 9.9999452e-01 6.8447266e-09 1.5312961e-09], sampled 0.10586627484793776
[2019-03-23 18:04:07,205] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3519.8688 2104065818.8031 178.0000
[2019-03-23 18:04:07,364] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2760.0075 2124051796.3784 757.0000
[2019-03-23 18:04:07,394] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3361.3422 2098042853.2058 179.0000
[2019-03-23 18:04:07,519] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3614.9699 2175275484.4146 245.0000
[2019-03-23 18:04:07,532] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3118.8146 2109022190.6825 368.0000
[2019-03-23 18:04:08,547] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 750000, evaluation results [750000.0, 3614.969905402749, 2175275484.414616, 245.0, 3361.342177577007, 2098042853.205797, 179.0, 3519.8687787924955, 2104065818.8031247, 178.0, 2760.0074851005825, 2124051796.3784225, 757.0, 3118.8146269445274, 2109022190.6824877, 368.0]
[2019-03-23 18:04:22,883] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.9485994e-03 1.4744089e-12 9.9705136e-01 3.6777057e-12 2.7974059e-10], sum to 1.0000
[2019-03-23 18:04:22,899] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7982
[2019-03-23 18:04:22,904] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.2049816020924519, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4073356720161883, 6.911199999999999, 6.9112, 77.32846344354104, 465256.8926341315, 465256.8926341318, 163277.0450225257], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4513800.0000, 
sim time next is 4514400.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.2055589133466086, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4084863745036569, 6.911199999999999, 6.9112, 77.32846344354104, 466570.0296988621, 466570.0296988623, 163380.9040850695], 
processed observation next is [0.0, 0.2608695652173913, 0.5, 1.0, 1.0, 1.0, 0.006948641683260752, 0.0, 1.0, -0.25, 1.0, 1.0, 0.15498053500522413, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17280371470328226, 0.17280371470328232, 0.39849000996358414], 
reward next is 0.6015, 
noisyNet noise sample is [array([1.3482774], dtype=float32), -0.30877095]. 
=============================================
[2019-03-23 18:04:23,039] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.0952844e-04 1.8569345e-12 9.9959046e-01 5.6366296e-12 6.6954414e-11], sum to 1.0000
[2019-03-23 18:04:23,048] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3096
[2019-03-23 18:04:23,057] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.5, 97.0, 1.0, 2.0, 0.2443811302441143, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4941459817120222, 6.911199999999999, 6.9112, 77.32846344354104, 557382.3420014143, 557382.3420014146, 177195.7529361007], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4523400.0000, 
sim time next is 4524000.0000, 
raw observation next is [21.66666666666667, 96.0, 1.0, 2.0, 0.2455932063508169, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4966836608477024, 6.9112, 6.9112, 77.32846344354104, 560085.9023888943, 560085.9023888943, 177595.0769615683], 
processed observation next is [0.0, 0.34782608695652173, 0.6212121212121214, 0.96, 1.0, 1.0, 0.056991507938521126, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2809766583538606, 0.0, 0.0, 0.5084288129206541, 0.20743922310699792, 0.20743922310699792, 0.43315872429650804], 
reward next is 0.5668, 
noisyNet noise sample is [array([0.97929347], dtype=float32), -0.37627468]. 
=============================================
[2019-03-23 18:04:23,078] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[54.720863]
 [54.727554]
 [54.726284]
 [54.828194]
 [54.778015]], R is [[54.67580414]
 [54.69686127]
 [54.71874619]
 [54.741539  ]
 [54.76574326]].
[2019-03-23 18:04:26,982] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.7394638e-05 2.0055961e-09 9.9995255e-01 5.9075694e-10 1.1931661e-09], sum to 1.0000
[2019-03-23 18:04:26,992] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6324
[2019-03-23 18:04:26,997] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.33333333333333, 98.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 263175.7834134179, 263175.7834134179, 107792.3681816923], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4592400.0000, 
sim time next is 4593000.0000, 
raw observation next is [14.16666666666667, 99.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 261230.4386375511, 261230.4386375511, 106949.4430021153], 
processed observation next is [1.0, 0.13043478260869565, 0.28030303030303044, 0.99, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.09675201431020411, 0.09675201431020411, 0.26085230000515924], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.67432517], dtype=float32), -0.2904441]. 
=============================================
[2019-03-23 18:04:27,019] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[33.59345 ]
 [33.454067]
 [33.36392 ]
 [31.864388]
 [33.108017]], R is [[33.29452515]
 [32.96157837]
 [32.63196182]
 [32.30564117]
 [31.98258591]].
[2019-03-23 18:04:32,821] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.3664055e-06 3.4655323e-09 9.9999666e-01 9.9950626e-09 4.4206883e-09], sum to 1.0000
[2019-03-23 18:04:32,824] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5293
[2019-03-23 18:04:32,831] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.5, 66.66666666666667, 1.0, 2.0, 0.2074763683950452, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3873129266973142, 6.9112, 6.9112, 77.32846344354104, 450635.2192058202, 450635.2192058202, 140837.452100517], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4698600.0000, 
sim time next is 4699200.0000, 
raw observation next is [19.0, 65.33333333333334, 1.0, 2.0, 0.2261738471935743, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4222170234450004, 6.9112, 6.9112, 77.32846344354104, 491266.3507310716, 491266.3507310716, 147681.4136909027], 
processed observation next is [1.0, 0.391304347826087, 0.5, 0.6533333333333334, 1.0, 1.0, 0.03271730899196787, 0.0, 1.0, -0.25, 1.0, 1.0, 0.174595747778572, 0.0, 0.0, 0.5084288129206541, 0.18195050027076726, 0.18195050027076726, 0.36019856997781147], 
reward next is 0.6398, 
noisyNet noise sample is [array([0.40987644], dtype=float32), -0.4236275]. 
=============================================
[2019-03-23 18:04:34,434] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.0142713e-06 1.9943013e-08 9.9999595e-01 7.5731670e-09 2.0397566e-09], sum to 1.0000
[2019-03-23 18:04:34,442] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3437
[2019-03-23 18:04:34,449] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 78.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3802945336930042, 6.911200000000001, 6.9112, 77.32846344354104, 435995.870744765, 435995.8707447647, 158671.7650232795], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4742400.0000, 
sim time next is 4743000.0000, 
raw observation next is [21.0, 78.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3806605755997903, 6.9112, 6.9112, 77.32846344354104, 436419.1785596129, 436419.1785596129, 158716.6061857441], 
processed observation next is [1.0, 0.9130434782608695, 0.5909090909090909, 0.78, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.11522939371398613, 0.0, 0.0, 0.5084288129206541, 0.16163673279985663, 0.16163673279985663, 0.38711367362376614], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7526725], dtype=float32), 0.28823754]. 
=============================================
[2019-03-23 18:04:34,467] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[16.508389]
 [16.758669]
 [17.160559]
 [17.73742 ]
 [18.230354]], R is [[16.23295212]
 [16.0706234 ]
 [15.90991688]
 [15.75081825]
 [15.59331036]].
[2019-03-23 18:04:34,837] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.1185358e-07 1.3483267e-10 9.9999940e-01 1.1767674e-10 3.3423115e-11], sum to 1.0000
[2019-03-23 18:04:34,849] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9287
[2019-03-23 18:04:34,855] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.3281885843695503, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6538236795147804, 6.9112, 6.9112, 77.32846344354104, 746110.7504468913, 746110.7504468913, 192187.751265646], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4785000.0000, 
sim time next is 4785600.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.3210024473125226, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6392927482872459, 6.9112, 6.9112, 77.32846344354104, 729636.9596770906, 729636.9596770906, 190067.7905020569], 
processed observation next is [1.0, 0.391304347826087, 0.5, 1.0, 1.0, 1.0, 0.1512530591406532, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4847039261246371, 0.0, 0.0, 0.5084288129206541, 0.27023591099151506, 0.27023591099151506, 0.4635799768342851], 
reward next is 0.5364, 
noisyNet noise sample is [array([-1.6997356], dtype=float32), -1.9022027]. 
=============================================
[2019-03-23 18:04:35,051] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.5622621e-06 1.3707750e-10 9.9999750e-01 2.9659922e-10 2.3531996e-10], sum to 1.0000
[2019-03-23 18:04:35,058] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8104
[2019-03-23 18:04:35,065] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.33333333333334, 98.0, 1.0, 2.0, 0.4099773577957834, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8184364666690965, 6.9112, 6.9112, 77.32846344354104, 933159.2014310188, 933159.2014310188, 219007.1684729379], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4789200.0000, 
sim time next is 4789800.0000, 
raw observation next is [19.5, 97.0, 1.0, 2.0, 0.3960035730079398, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7908836159791216, 6.911200000000001, 6.9112, 77.32846344354104, 901505.0780312374, 901505.078031237, 214360.1430530331], 
processed observation next is [1.0, 0.43478260869565216, 0.5227272727272727, 0.97, 1.0, 1.0, 0.24500446625992475, 0.0, 1.0, -0.25, 1.0, 1.0, 0.7012623085416023, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.333890769641199, 0.3338907696411989, 0.5228296172025197], 
reward next is 0.4772, 
noisyNet noise sample is [array([-0.2610391], dtype=float32), -0.009129995]. 
=============================================
[2019-03-23 18:04:37,695] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.3713874e-05 1.7806943e-09 9.9996626e-01 1.1212932e-09 2.7549700e-09], sum to 1.0000
[2019-03-23 18:04:37,700] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7094
[2019-03-23 18:04:37,706] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.5, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3923559149866228, 6.9112, 6.9112, 77.32846344354104, 449525.6763099156, 449525.6763099156, 160528.4864618033], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4775400.0000, 
sim time next is 4776000.0000, 
raw observation next is [18.66666666666667, 100.0, 1.0, 2.0, 0.2056498512709766, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4066495042515151, 6.9112, 6.9112, 77.32846344354104, 465457.7632660883, 465457.7632660883, 162292.4000573556], 
processed observation next is [1.0, 0.2608695652173913, 0.4848484848484851, 1.0, 1.0, 1.0, 0.007062314088720732, 0.0, 1.0, -0.25, 1.0, 1.0, 0.15235643464502158, 0.0, 0.0, 0.5084288129206541, 0.1723917641726253, 0.1723917641726253, 0.39583512209111127], 
reward next is 0.6042, 
noisyNet noise sample is [array([-0.40835905], dtype=float32), 0.9085218]. 
=============================================
[2019-03-23 18:04:37,725] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[40.86095 ]
 [40.782692]
 [40.64858 ]
 [40.403862]
 [40.223488]], R is [[41.14073563]
 [40.72932816]
 [40.32203674]
 [40.52601242]
 [40.12075424]].
[2019-03-23 18:04:39,567] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.5021359e-07 1.7759871e-13 9.9999928e-01 1.8475166e-13 2.4971809e-11], sum to 1.0000
[2019-03-23 18:04:39,574] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5371
[2019-03-23 18:04:39,579] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.2226817793949782, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4471621499699279, 6.9112, 6.9112, 77.32846344354104, 507804.2246033997, 507804.2246033997, 169474.4974732175], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4840800.0000, 
sim time next is 4841400.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.2222847274076641, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4463628999295801, 6.911199999999999, 6.9112, 77.32846344354104, 506897.6585365623, 506897.6585365626, 169393.7033255969], 
processed observation next is [1.0, 0.0, 0.5454545454545454, 1.0, 1.0, 1.0, 0.027855909259580126, 0.0, 1.0, -0.25, 1.0, 1.0, 0.20908985704225733, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18773987353206012, 0.1877398735320602, 0.4131553739648705], 
reward next is 0.5868, 
noisyNet noise sample is [array([-0.7787261], dtype=float32), -0.2843224]. 
=============================================
[2019-03-23 18:04:54,165] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.0286641e-05 1.2006489e-11 9.9997973e-01 2.5354198e-12 9.0962286e-11], sum to 1.0000
[2019-03-23 18:04:54,175] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1878
[2019-03-23 18:04:54,180] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.88333333333333, 96.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3480579432883533, 6.911200000000001, 6.9112, 77.32846344354104, 400842.0074255842, 400842.007425584, 152867.4246964491], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5449800.0000, 
sim time next is 5450400.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3439577790822885, 6.9112, 6.9112, 77.32846344354104, 396354.9853073673, 396354.9853073673, 152145.3869657301], 
processed observation next is [1.0, 0.08695652173913043, 0.44090909090909086, 0.97, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.06279682726041212, 0.0, 0.0, 0.5084288129206541, 0.14679814270643232, 0.14679814270643232, 0.3710863096725125], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9874235], dtype=float32), 0.29898465]. 
=============================================
[2019-03-23 18:04:58,489] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 18:04:58,490] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:04:58,491] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:04:58,491] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:04:58,491] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:04:58,492] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:04:58,492] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:04:58,494] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:04:58,495] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:04:58,497] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:04:58,499] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:04:58,514] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run32
[2019-03-23 18:04:58,539] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run32
[2019-03-23 18:04:58,561] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run32
[2019-03-23 18:04:58,583] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run32
[2019-03-23 18:04:58,585] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run32
[2019-03-23 18:05:06,819] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00702162], dtype=float32), 0.0040725293]
[2019-03-23 18:05:06,820] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [12.96026621166667, 91.48346159500001, 1.0, 2.0, 0.2530261317915823, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4723443560979469, 6.911200000000001, 6.9112, 95.55338769695034, 549565.220521391, 549565.2205213907, 141698.6965691322]
[2019-03-23 18:05:06,821] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:05:06,824] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.78385744e-04 1.29196905e-11 9.99821603e-01 1.14272333e-11
 1.72635531e-10], sampled 0.5309149852299152
[2019-03-23 18:05:45,934] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00702162], dtype=float32), 0.0040725293]
[2019-03-23 18:05:45,936] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.36832850333334, 81.23536844, 1.0, 2.0, 0.3465995968507782, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7013024959461184, 6.911200000000001, 6.9112, 95.55338769695034, 778932.6622274913, 778932.6622274909, 216886.7248527403]
[2019-03-23 18:05:45,937] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:05:45,938] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.2925137e-05 2.6526695e-12 9.9993706e-01 2.3543569e-12 3.1941460e-11], sampled 0.5587735651343229
[2019-03-23 18:06:04,090] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00702162], dtype=float32), 0.0040725293]
[2019-03-23 18:06:04,093] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.93333333333334, 47.33333333333334, 1.0, 2.0, 0.2160882740174663, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4328321335864531, 6.911199999999999, 6.9112, 77.32846344354104, 492333.4743460142, 492333.4743460145, 167392.777775602]
[2019-03-23 18:06:04,094] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:06:04,096] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.6304983e-04 3.7149589e-11 9.9983692e-01 3.2971521e-11 3.4708836e-10], sampled 0.769317703384542
[2019-03-23 18:06:13,957] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00702162], dtype=float32), 0.0040725293]
[2019-03-23 18:06:13,959] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.13242700333333, 56.87400495666667, 1.0, 2.0, 0.2176883672912633, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4331567438927421, 6.9112, 6.9112, 95.55338769695034, 494412.2571941782, 494412.2571941782, 170586.491173977]
[2019-03-23 18:06:13,960] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:06:13,963] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.7836703e-04 1.5321048e-11 9.9982160e-01 1.3594631e-11 1.9350348e-10], sampled 0.03815844949500202
[2019-03-23 18:06:35,634] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3613.8351 2175250847.6005 246.0000
[2019-03-23 18:06:35,639] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2760.3877 2123967686.8182 758.0000
[2019-03-23 18:06:35,652] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3521.4983 2103906336.5524 179.0000
[2019-03-23 18:06:35,876] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3362.6989 2098017824.4728 180.0000
[2019-03-23 18:06:35,900] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3120.4064 2108967595.9764 368.0000
[2019-03-23 18:06:36,914] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 775000, evaluation results [775000.0, 3613.8351151011707, 2175250847.6005406, 246.0, 3362.698933566721, 2098017824.4728172, 180.0, 3521.4983184731605, 2103906336.5524151, 179.0, 2760.387654772255, 2123967686.8181546, 758.0, 3120.406353429114, 2108967595.9764102, 368.0]
[2019-03-23 18:06:37,599] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.8071163e-05 8.8732288e-13 9.9998188e-01 7.3087407e-13 3.1196153e-11], sum to 1.0000
[2019-03-23 18:06:37,607] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6363
[2019-03-23 18:06:37,611] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3451977224523426, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6985780832239947, 6.911200000000001, 6.9112, 77.32846344296293, 786959.7085734189, 786959.7085734186, 205651.6560956117], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5229600.0000, 
sim time next is 5230200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3641773608801133, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7370330612785433, 6.9112, 6.9112, 77.32846344353746, 830202.4419387103, 830202.4419387103, 212004.6849086068], 
processed observation next is [1.0, 0.5217391304347826, 0.6363636363636364, 0.94, 1.0, 1.0, 0.20522170110014162, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6243329446836333, 0.0, 0.0, 0.5084288129206306, 0.307482385903226, 0.307482385903226, 0.5170845973380654], 
reward next is 0.4829, 
noisyNet noise sample is [array([-0.41084865], dtype=float32), -0.32992113]. 
=============================================
[2019-03-23 18:06:47,363] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.78418440e-06 1.06993615e-10 9.99996185e-01 2.20158919e-10
 1.01852651e-10], sum to 1.0000
[2019-03-23 18:06:47,369] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0692
[2019-03-23 18:06:47,373] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.5, 77.0, 1.0, 2.0, 0.6111381434607209, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9801585642673141, 6.911199999999999, 6.9112, 77.32844082119522, 1240264.849013793, 1240264.849013794, 281823.7950693808], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5392800.0000, 
sim time next is 5393400.0000, 
raw observation next is [25.86666666666667, 75.33333333333334, 1.0, 2.0, 0.8189377496379431, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9813155805496768, 6.9112, 6.9112, 77.8059881609958, 1474369.641158768, 1474369.641158768, 315357.4366678557], 
processed observation next is [1.0, 0.43478260869565216, 0.8121212121212124, 0.7533333333333334, 1.0, 1.0, 0.7736721870474289, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9733079722138241, 0.0, 0.0, 0.5115685019099879, 0.546062830058803, 0.546062830058803, 0.7691644796776969], 
reward next is 0.2308, 
noisyNet noise sample is [array([-0.82275784], dtype=float32), -0.0805172]. 
=============================================
[2019-03-23 18:06:49,676] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.9179148e-07 6.8000027e-08 9.9999964e-01 9.1347779e-08 1.9872792e-09], sum to 1.0000
[2019-03-23 18:06:49,683] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9942
[2019-03-23 18:06:49,686] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.4, 93.0, 1.0, 2.0, 0.2020721439172331, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3995071666555404, 6.9112, 6.9112, 77.32846344354104, 457309.8799162891, 457309.8799162891, 161641.4239324841], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5422200.0000, 
sim time next is 5422800.0000, 
raw observation next is [19.4, 93.0, 1.0, 2.0, 0.2015346528175344, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3984374343858429, 6.9112, 6.9112, 77.32846344354104, 456088.0511426257, 456088.0511426257, 161546.2651331232], 
processed observation next is [1.0, 0.782608695652174, 0.5181818181818181, 0.93, 1.0, 1.0, 0.0019183160219179984, 0.0, 1.0, -0.25, 1.0, 1.0, 0.14062490626548987, 0.0, 0.0, 0.5084288129206541, 0.1689215004231947, 0.1689215004231947, 0.3940152808124956], 
reward next is 0.6060, 
noisyNet noise sample is [array([-0.80594766], dtype=float32), -0.79152536]. 
=============================================
[2019-03-23 18:06:53,448] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1834453e-06 1.7406212e-11 9.9999881e-01 2.0966687e-11 7.2654098e-11], sum to 1.0000
[2019-03-23 18:06:53,454] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4316
[2019-03-23 18:06:53,458] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.96666666666667, 65.0, 1.0, 2.0, 0.2681039847791131, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5430934765749741, 6.911199999999999, 6.9112, 77.32846344354104, 609311.1815209399, 609311.1815209403, 185146.4429830702], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5505600.0000, 
sim time next is 5506200.0000, 
raw observation next is [27.15, 63.0, 1.0, 2.0, 0.2514887524476924, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5093529132632477, 6.911199999999999, 6.9112, 77.32846344354104, 572228.8106245256, 572228.810624526, 180497.8235453168], 
processed observation next is [1.0, 0.7391304347826086, 0.8704545454545454, 0.63, 1.0, 1.0, 0.06436094055961551, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2990755903760682, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2119365965276021, 0.21193659652760222, 0.4402385940129678], 
reward next is 0.5598, 
noisyNet noise sample is [array([-0.33177868], dtype=float32), -0.2828827]. 
=============================================
[2019-03-23 18:06:57,890] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.2549769e-07 1.7753628e-11 9.9999964e-01 2.0512197e-12 3.5808754e-12], sum to 1.0000
[2019-03-23 18:06:57,900] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6279
[2019-03-23 18:06:57,906] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.7, 61.0, 1.0, 2.0, 0.6187504626061696, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9776653965836964, 6.911199999999999, 6.9112, 77.32846344354104, 1251022.060670905, 1251022.060670905, 280685.9372484608], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5576400.0000, 
sim time next is 5577000.0000, 
raw observation next is [27.88333333333333, 60.0, 1.0, 2.0, 0.5287438930784714, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9644396099308169, 6.933794078113415, 6.9112, 77.32840801663426, 1148774.282835826, 1141436.193653148, 265752.8333452025], 
processed observation next is [1.0, 0.5652173913043478, 0.9037878787878786, 0.6, 1.0, 1.0, 0.41092986634808915, 0.0, 1.0, -0.25, 1.0, 1.0, 0.94919944275831, 0.002259407811341507, 0.0, 0.5084284484929238, 0.4254719566058615, 0.4227541457974622, 0.6481776423053719], 
reward next is 0.2389, 
noisyNet noise sample is [array([0.77042925], dtype=float32), -0.24266064]. 
=============================================
[2019-03-23 18:06:57,921] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[32.587566]
 [32.483643]
 [32.36945 ]
 [32.34982 ]
 [32.314484]], R is [[32.70595932]
 [32.69429779]
 [32.68535614]
 [32.68449783]
 [32.69293594]].
[2019-03-23 18:07:05,083] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.9546435e-06 2.5180129e-06 9.9998832e-01 1.0971770e-06 9.7322534e-08], sum to 1.0000
[2019-03-23 18:07:05,092] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4008
[2019-03-23 18:07:05,097] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [10.91666666666667, 78.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 160513.346716107, 160513.3467161072, 77132.83123882857], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5710200.0000, 
sim time next is 5710800.0000, 
raw observation next is [10.73333333333333, 80.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 158841.6535949926, 158841.6535949926, 76870.87743211004], 
processed observation next is [0.0, 0.08695652173913043, 0.12424242424242413, 0.8, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.05883024207221948, 0.05883024207221948, 0.18748994495636595], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.03787674], dtype=float32), 1.3700991]. 
=============================================
[2019-03-23 18:07:06,088] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.3307615e-06 7.6574275e-07 9.9999416e-01 1.7898623e-06 4.4134424e-08], sum to 1.0000
[2019-03-23 18:07:06,095] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9942
[2019-03-23 18:07:06,098] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [10.55, 81.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 156558.5238790925, 156558.5238790928, 76513.70808563163], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5711400.0000, 
sim time next is 5712000.0000, 
raw observation next is [10.36666666666667, 83.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 153886.5682095555, 153886.5682095558, 76089.70659581873], 
processed observation next is [0.0, 0.08695652173913043, 0.10757575757575775, 0.83, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.05699502526279833, 0.05699502526279844, 0.1855846502337042], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.06445532], dtype=float32), -0.48491248]. 
=============================================
[2019-03-23 18:07:06,113] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[0.38934353]
 [0.37645105]
 [0.45727614]
 [0.7569238 ]
 [0.65981376]], R is [[0.43332443]
 [0.4289912 ]
 [0.4247013 ]
 [0.42045429]
 [0.41624975]].
[2019-03-23 18:07:21,902] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.1925909e-05 1.2384412e-06 9.9997592e-01 7.3127768e-07 1.0344064e-07], sum to 1.0000
[2019-03-23 18:07:21,912] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6462
[2019-03-23 18:07:21,919] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.03333333333333, 76.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.309458376768846, 6.911200000000001, 6.9112, 77.32846344354104, 358576.7171273884, 358576.7171273881, 146081.5985672681], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6038400.0000, 
sim time next is 6039000.0000, 
raw observation next is [18.85, 75.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3022131206315797, 6.911199999999999, 6.9112, 77.32846344354104, 350674.2721224062, 350674.2721224065, 144766.1594770857], 
processed observation next is [1.0, 0.9130434782608695, 0.4931818181818182, 0.755, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0031616009022567004, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12987936004533565, 0.12987936004533573, 0.3530881938465505], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2574611], dtype=float32), 0.731564]. 
=============================================
[2019-03-23 18:07:21,943] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[4.8512936]
 [5.1668024]
 [5.3849306]
 [5.621375 ]
 [5.761533 ]], R is [[4.46519709]
 [4.4205451 ]
 [4.37633991]
 [4.33257675]
 [4.28925085]].
[2019-03-23 18:07:26,922] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 18:07:26,924] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:07:26,924] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:07:26,925] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:07:26,927] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:07:26,926] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:07:26,927] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:07:26,929] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:07:26,927] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:07:26,931] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:07:26,930] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:07:26,948] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run33
[2019-03-23 18:07:26,949] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run33
[2019-03-23 18:07:26,998] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run33
[2019-03-23 18:07:26,998] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run33
[2019-03-23 18:07:27,045] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run33
[2019-03-23 18:07:30,362] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00759684], dtype=float32), 0.004015007]
[2019-03-23 18:07:30,364] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.888778275, 86.02983806333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 233761.0107138027, 233761.0107138023, 102807.6500248212]
[2019-03-23 18:07:30,365] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:07:30,369] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.2607335e-05 1.5852197e-07 9.9997699e-01 1.3995640e-07 4.3737714e-08], sampled 0.0730134077007063
[2019-03-23 18:08:04,837] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00759684], dtype=float32), 0.004015007]
[2019-03-23 18:08:04,838] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.0, 82.16666666666667, 1.0, 2.0, 0.2430008903874825, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4905754622669447, 6.911200000000001, 6.9112, 77.32846344354104, 554532.7982444533, 554532.798244453, 175950.2759689712]
[2019-03-23 18:08:04,840] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:08:04,843] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.6983760e-05 1.4504901e-09 9.9997306e-01 1.2613836e-09 1.7910136e-09], sampled 0.1743084026972127
[2019-03-23 18:09:03,926] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2760.0075 2124051796.3784 757.0000
[2019-03-23 18:09:03,959] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3119.5914 2109009555.1329 368.0000
[2019-03-23 18:09:04,100] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3362.3994 2097977528.5617 180.0000
[2019-03-23 18:09:04,128] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3614.1741 2175305489.0345 245.0000
[2019-03-23 18:09:04,302] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3520.6461 2104033317.6637 178.0000
[2019-03-23 18:09:05,316] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 800000, evaluation results [800000.0, 3614.1740929847015, 2175305489.034501, 245.0, 3362.3993797550243, 2097977528.5617077, 180.0, 3520.646132071608, 2104033317.6637259, 178.0, 2760.0074851005825, 2124051796.3784225, 757.0, 3119.591358754909, 2109009555.132935, 368.0]
[2019-03-23 18:09:08,254] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.0034304e-04 1.7176038e-09 9.9949968e-01 3.0199616e-09 1.4967355e-09], sum to 1.0000
[2019-03-23 18:09:08,262] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2460
[2019-03-23 18:09:08,271] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.9, 62.66666666666667, 1.0, 2.0, 0.3986055981339132, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7841286410629218, 6.9112, 6.9112, 77.32846344354104, 899697.1726048042, 899697.1726048042, 208902.5330091868], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6190800.0000, 
sim time next is 6191400.0000, 
raw observation next is [22.8, 63.33333333333334, 1.0, 2.0, 0.409887735419249, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8067516355511082, 6.9112, 6.9112, 77.32846344354104, 925500.6933133536, 925500.6933133536, 212820.2860392871], 
processed observation next is [1.0, 0.6521739130434783, 0.6727272727272727, 0.6333333333333334, 1.0, 1.0, 0.26235966927406124, 0.0, 1.0, -0.25, 1.0, 1.0, 0.7239309079301546, 0.0, 0.0, 0.5084288129206541, 0.3427780345605013, 0.3427780345605013, 0.5190738683885051], 
reward next is 0.4809, 
noisyNet noise sample is [array([-0.26226863], dtype=float32), -1.0142466]. 
=============================================
[2019-03-23 18:09:13,396] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.3637083e-03 2.5981724e-11 9.9663627e-01 2.2565554e-12 6.2358910e-11], sum to 1.0000
[2019-03-23 18:09:13,403] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8537
[2019-03-23 18:09:13,408] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.65, 78.16666666666667, 1.0, 2.0, 0.3016641037146145, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6103809432977788, 6.911199999999999, 6.9112, 77.32846344354104, 677979.8042680218, 677979.8042680221, 197710.3393276469], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6271800.0000, 
sim time next is 6272400.0000, 
raw observation next is [27.2, 74.33333333333334, 1.0, 2.0, 0.3025259045905042, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6121191451879795, 6.911199999999999, 6.9112, 77.32846344354104, 679918.0273925448, 679918.027392545, 197963.0556341231], 
processed observation next is [0.0, 0.6086956521739131, 0.8727272727272727, 0.7433333333333334, 1.0, 1.0, 0.12815738073813024, 0.0, 1.0, -0.25, 1.0, 1.0, 0.44588449312568507, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.25182149162686845, 0.2518214916268685, 0.48283672105883685], 
reward next is 0.5172, 
noisyNet noise sample is [array([-0.69095504], dtype=float32), 0.119423464]. 
=============================================
[2019-03-23 18:09:17,761] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.47340625e-05 6.91480250e-12 9.99985218e-01 9.02823606e-13
 8.83496609e-11], sum to 1.0000
[2019-03-23 18:09:17,769] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4645
[2019-03-23 18:09:17,774] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.3, 61.0, 1.0, 2.0, 0.2760067879330861, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5589750216798757, 6.911200000000001, 6.9112, 77.32846344354104, 625508.7500763036, 625508.7500763033, 188177.8365135033], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6365400.0000, 
sim time next is 6366000.0000, 
raw observation next is [28.3, 61.0, 1.0, 2.0, 0.2757009973221438, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5583562898123595, 6.911199999999999, 6.9112, 77.32846344354104, 624818.803120832, 624818.8031208322, 188094.9765601837], 
processed observation next is [0.0, 0.6956521739130435, 0.9227272727272727, 0.61, 1.0, 1.0, 0.09462624665267975, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3690804140176565, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23141437152623406, 0.23141437152623415, 0.45876823551264323], 
reward next is 0.5412, 
noisyNet noise sample is [array([0.9579568], dtype=float32), 1.1219558]. 
=============================================
[2019-03-23 18:09:17,806] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[50.682095]
 [50.741116]
 [50.66145 ]
 [50.713097]
 [50.725765]], R is [[50.71120453]
 [50.74512482]
 [50.7783699 ]
 [50.81073761]
 [50.84215546]].
[2019-03-23 18:09:25,226] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.6470508e-05 3.5238031e-08 9.9994338e-01 9.0699423e-08 4.2133959e-08], sum to 1.0000
[2019-03-23 18:09:25,232] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8918
[2019-03-23 18:09:25,238] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.13333333333333, 50.0, 1.0, 2.0, 0.2409135454177351, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4497328109151424, 6.911200000000001, 6.9112, 77.32846344354104, 523299.299347006, 523299.2993470057, 141482.2733538788], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6528000.0000, 
sim time next is 6528600.0000, 
raw observation next is [19.95, 50.5, 1.0, 2.0, 0.2485438407221573, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4639769006338013, 6.911200000000001, 6.9112, 77.32846344354104, 539882.6158048923, 539882.6158048919, 142566.6910006282], 
processed observation next is [1.0, 0.5652173913043478, 0.5431818181818181, 0.505, 1.0, 1.0, 0.060679800902696604, 0.0, 1.0, -0.25, 1.0, 1.0, 0.23425271519114477, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1999565243721823, 0.1999565243721822, 0.34772363658689803], 
reward next is 0.6523, 
noisyNet noise sample is [array([0.17361858], dtype=float32), 1.046517]. 
=============================================
[2019-03-23 18:09:27,448] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.9503181e-03 3.5114176e-08 9.9804926e-01 6.9577575e-09 5.0157928e-07], sum to 1.0000
[2019-03-23 18:09:27,456] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0416
[2019-03-23 18:09:27,461] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.5, 51.00000000000001, 1.0, 2.0, 0.2257848772375581, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4214909017511067, 6.9112, 6.9112, 77.32846344354104, 490421.0530130503, 490421.0530130503, 141256.1820853013], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6535200.0000, 
sim time next is 6535800.0000, 
raw observation next is [20.5, 51.0, 1.0, 2.0, 0.2293635050977907, 0.0, 2.0, 0.0, 1.0, 2.0, 0.428171415974626, 6.9112, 6.9112, 77.32846344354104, 498198.074049669, 498198.074049669, 141971.5861616005], 
processed observation next is [1.0, 0.6521739130434783, 0.5681818181818182, 0.51, 1.0, 1.0, 0.036704381372238346, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1831020228208943, 0.0, 0.0, 0.5084288129206541, 0.18451780520358113, 0.18451780520358113, 0.34627216136975736], 
reward next is 0.6537, 
noisyNet noise sample is [array([-0.17201899], dtype=float32), 1.0264999]. 
=============================================
[2019-03-23 18:09:29,519] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.0501126e-04 3.8754724e-10 9.9959499e-01 2.5455520e-09 2.8939668e-09], sum to 1.0000
[2019-03-23 18:09:29,527] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4713
[2019-03-23 18:09:29,531] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.4, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3774471693130999, 6.9112, 6.9112, 77.32846344354104, 432911.0818076715, 432911.0818076715, 158139.6440519892], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6921600.0000, 
sim time next is 6922200.0000, 
raw observation next is [19.4, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3771812568500411, 6.9112, 6.9112, 77.32846344354104, 432606.1271756359, 432606.1271756359, 158104.9385238838], 
processed observation next is [0.0, 0.08695652173913043, 0.5181818181818181, 0.9, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.11025893835720162, 0.0, 0.0, 0.5084288129206541, 0.16022449154653182, 0.16022449154653182, 0.38562180127776535], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.05723856], dtype=float32), 0.18609074]. 
=============================================
[2019-03-23 18:09:34,795] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.9687424e-05 1.9138412e-08 9.9995029e-01 1.4996232e-08 7.7159248e-09], sum to 1.0000
[2019-03-23 18:09:34,805] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7646
[2019-03-23 18:09:34,810] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.2619889612456676, 0.0, 2.0, 0.0, 1.0, 2.0, 0.509795402949154, 6.9112, 6.9112, 77.32846344354104, 586833.6157485014, 586833.6157485014, 169619.345734856], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6700800.0000, 
sim time next is 6701400.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.2997648425969663, 0.0, 2.0, 0.0, 1.0, 2.0, 0.583989181461166, 6.9112, 6.9112, 77.32846344354104, 672059.046949921, 672059.046949921, 178263.4051966247], 
processed observation next is [1.0, 0.5652173913043478, 0.4681818181818182, 0.93, 1.0, 1.0, 0.12470605324620784, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4056988306588086, 0.0, 0.0, 0.5084288129206541, 0.24891075812960034, 0.24891075812960034, 0.43478879316249924], 
reward next is 0.5652, 
noisyNet noise sample is [array([-0.13386127], dtype=float32), 1.7342299]. 
=============================================
[2019-03-23 18:09:40,028] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.5919104e-06 2.2880098e-08 9.9999440e-01 3.4561247e-09 7.7300938e-10], sum to 1.0000
[2019-03-23 18:09:40,035] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2667
[2019-03-23 18:09:40,041] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.65, 76.0, 1.0, 2.0, 0.3942797607987577, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7906296870995847, 6.911200000000001, 6.9112, 77.32846344354104, 899066.3824358608, 899066.3824358606, 215810.8768527349], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6780600.0000, 
sim time next is 6781200.0000, 
raw observation next is [22.66666666666667, 76.0, 1.0, 2.0, 0.359719673325597, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7212598231041455, 6.9112, 6.9112, 77.32846344354104, 820165.9227591858, 820165.9227591858, 204294.8383975599], 
processed observation next is [1.0, 0.4782608695652174, 0.6666666666666669, 0.76, 1.0, 1.0, 0.19964959165699625, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6017997472916364, 0.0, 0.0, 0.5084288129206541, 0.3037651565774762, 0.3037651565774762, 0.49828009365258513], 
reward next is 0.5017, 
noisyNet noise sample is [array([-1.6308491], dtype=float32), 2.18282]. 
=============================================
[2019-03-23 18:09:42,630] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6888289e-05 9.7170005e-07 9.9998152e-01 4.7473227e-07 8.7680320e-08], sum to 1.0000
[2019-03-23 18:09:42,642] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6659
[2019-03-23 18:09:42,648] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.55, 78.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3626202592055592, 6.9112, 6.9112, 77.32846344354104, 416701.1173497428, 416701.1173497428, 155505.1799624365], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6827400.0000, 
sim time next is 6828000.0000, 
raw observation next is [20.36666666666667, 79.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3602704928477964, 6.9112, 6.9112, 77.32846344354104, 414105.2598385714, 414105.2598385714, 155113.2399621854], 
processed observation next is [0.0, 0.0, 0.5621212121212124, 0.79, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.08610070406828058, 0.0, 0.0, 0.5084288129206541, 0.15337231845873014, 0.15337231845873014, 0.3783249755175254], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.4469496], dtype=float32), -1.6162198]. 
=============================================
[2019-03-23 18:09:42,674] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[ 7.8380136]
 [ 8.618627 ]
 [ 9.037811 ]
 [ 9.9823   ]
 [11.604365 ]], R is [[7.22504854]
 [7.15279818]
 [7.08127022]
 [7.01045752]
 [6.94035292]].
[2019-03-23 18:09:43,936] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.4154908e-06 1.2545312e-08 9.9999559e-01 1.6188087e-08 4.1106940e-09], sum to 1.0000
[2019-03-23 18:09:43,942] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7812
[2019-03-23 18:09:43,946] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.2, 96.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3161341864158039, 6.911200000000001, 6.9112, 77.32846344354104, 365547.2832640692, 365547.2832640689, 147604.1880507822], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6850200.0000, 
sim time next is 6850800.0000, 
raw observation next is [17.2, 96.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3159771674124938, 6.911199999999999, 6.9112, 77.32846344354104, 365366.0112101986, 365366.0112101989, 147586.1072181328], 
processed observation next is [0.0, 0.30434782608695654, 0.41818181818181815, 0.96, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.02282452487499119, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13532074489266613, 0.13532074489266627, 0.35996611516617755], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2207268], dtype=float32), -0.65398896]. 
=============================================
[2019-03-23 18:09:44,728] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.3284111e-05 4.2068551e-10 9.9991667e-01 1.0774479e-11 2.7208438e-09], sum to 1.0000
[2019-03-23 18:09:44,737] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1031
[2019-03-23 18:09:44,740] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.61666666666667, 49.83333333333334, 1.0, 2.0, 0.2184355704020841, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4381615987391847, 6.9112, 6.9112, 77.32846344354104, 497944.2475956774, 497944.2475956774, 168285.1669851181], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6887400.0000, 
sim time next is 6888000.0000, 
raw observation next is [27.53333333333333, 50.66666666666667, 1.0, 2.0, 0.2194216895450098, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4404334850065471, 6.911200000000001, 6.9112, 77.32846344354104, 500302.7274022779, 500302.7274022776, 168691.7672345628], 
processed observation next is [0.0, 0.7391304347826086, 0.8878787878787878, 0.5066666666666667, 1.0, 1.0, 0.024277111931262224, 0.0, 1.0, -0.25, 1.0, 1.0, 0.20061926429506732, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1852973064452881, 0.185297306445288, 0.41144333471844585], 
reward next is 0.5886, 
noisyNet noise sample is [array([0.7106782], dtype=float32), 1.0754275]. 
=============================================
[2019-03-23 18:09:44,757] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[41.65488 ]
 [41.986584]
 [42.3652  ]
 [42.791092]
 [43.098373]], R is [[41.72532654]
 [41.89762497]
 [42.06852722]
 [42.23666763]
 [42.40213013]].
[2019-03-23 18:09:48,165] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.1433398e-05 9.4142409e-09 9.9991858e-01 5.3382682e-10 3.1862065e-08], sum to 1.0000
[2019-03-23 18:09:48,172] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9292
[2019-03-23 18:09:48,178] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.88333333333333, 72.33333333333333, 1.0, 2.0, 0.211279346426369, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4215128779993777, 6.9112, 6.9112, 77.32846344354104, 480531.8328744086, 480531.8328744086, 165383.1075753519], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6904200.0000, 
sim time next is 6904800.0000, 
raw observation next is [22.7, 73.0, 1.0, 2.0, 0.2105057505752584, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4196139307348751, 6.9112, 6.9112, 77.32846344354104, 478573.6217466707, 478573.6217466707, 165023.6253944922], 
processed observation next is [0.0, 0.9565217391304348, 0.6681818181818181, 0.73, 1.0, 1.0, 0.013132188219072971, 0.0, 1.0, -0.25, 1.0, 1.0, 0.17087704390696443, 0.0, 0.0, 0.5084288129206541, 0.17724948953580397, 0.17724948953580397, 0.40249664730363954], 
reward next is 0.5975, 
noisyNet noise sample is [array([-1.4017261], dtype=float32), 2.2098858]. 
=============================================
[2019-03-23 18:09:50,756] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.5449239e-05 3.3527073e-11 9.9998450e-01 8.1390602e-13 1.0532316e-10], sum to 1.0000
[2019-03-23 18:09:50,765] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8241
[2019-03-23 18:09:50,772] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.3, 56.0, 1.0, 2.0, 0.2553720550415695, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5170247867112947, 6.9112, 6.9112, 77.32846344354104, 581672.9160126221, 581672.9160126221, 180871.7805181055], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6963000.0000, 
sim time next is 6963600.0000, 
raw observation next is [28.3, 56.0, 1.0, 2.0, 0.254346750089325, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5149488164280805, 6.911199999999999, 6.9112, 77.32846344354104, 579336.4532610293, 579336.4532610296, 180624.566386431], 
processed observation next is [0.0, 0.6086956521739131, 0.9227272727272727, 0.56, 1.0, 1.0, 0.06793343761165624, 0.0, 1.0, -0.25, 1.0, 1.0, 0.30706973775440083, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2145690567633442, 0.21456905676334428, 0.4405477228937341], 
reward next is 0.5595, 
noisyNet noise sample is [array([0.87671596], dtype=float32), -1.6657165]. 
=============================================
[2019-03-23 18:09:53,202] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.0919516e-05 4.5583264e-12 9.9992907e-01 5.5894759e-12 1.8386041e-11], sum to 1.0000
[2019-03-23 18:09:53,210] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5697
[2019-03-23 18:09:53,215] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.8, 97.0, 1.0, 2.0, 0.3599282281651172, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7123366119822698, 6.911199999999999, 6.9112, 77.32846344354104, 815357.3696205277, 815357.369620528, 199036.6055869], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7031400.0000, 
sim time next is 7032000.0000, 
raw observation next is [18.8, 97.0, 1.0, 2.0, 0.3135533830787799, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6204591732625497, 6.911200000000001, 6.9112, 77.32846344354104, 710160.8230077735, 710160.8230077733, 185952.7637181896], 
processed observation next is [1.0, 0.391304347826087, 0.49090909090909096, 0.97, 1.0, 1.0, 0.14194172884847484, 0.0, 1.0, -0.25, 1.0, 1.0, 0.45779881894649965, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.26302252703991613, 0.263022527039916, 0.4535433261419259], 
reward next is 0.5465, 
noisyNet noise sample is [array([0.3130281], dtype=float32), -1.333713]. 
=============================================
[2019-03-23 18:09:53,234] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[49.39638 ]
 [50.18619 ]
 [50.717754]
 [51.21611 ]
 [51.51392 ]], R is [[48.97436142]
 [48.99916458]
 [49.0561676 ]
 [49.11672592]
 [49.17711639]].
[2019-03-23 18:09:55,385] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 18:09:55,385] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:09:55,386] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:09:55,386] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:09:55,388] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:09:55,386] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:09:55,390] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:09:55,389] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:09:55,391] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:09:55,394] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:09:55,391] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:09:55,409] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run34
[2019-03-23 18:09:55,410] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run34
[2019-03-23 18:09:55,459] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run34
[2019-03-23 18:09:55,460] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run34
[2019-03-23 18:09:55,460] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run34
[2019-03-23 18:10:02,173] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00839652], dtype=float32), 0.0041196207]
[2019-03-23 18:10:02,175] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.0, 100.0, 1.0, 2.0, 0.2628818272549116, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4907427803814842, 6.9112, 6.9112, 77.32846344354104, 571045.6359215654, 571045.6359215654, 142276.3990657622]
[2019-03-23 18:10:02,176] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:10:02,178] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.9486622e-05 2.3689053e-10 9.9996054e-01 2.2116875e-10 7.1861106e-10], sampled 0.8654560485752625
[2019-03-23 18:10:11,123] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00839652], dtype=float32), 0.0041196207]
[2019-03-23 18:10:11,124] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.73229308, 76.09236431, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3542613819999512, 6.911200000000001, 6.9112, 95.55338769695034, 411383.6009966907, 411383.6009966904, 154886.891920494]
[2019-03-23 18:10:11,125] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:10:11,129] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.0353535e-05 1.8633950e-09 9.9997962e-01 1.7872717e-09 2.1449182e-09], sampled 0.3146550376260425
[2019-03-23 18:10:35,213] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00839652], dtype=float32), 0.0041196207]
[2019-03-23 18:10:35,214] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3258116137815565, 6.9112, 6.9112, 77.32846344354104, 376899.7785625287, 376899.7785625287, 148545.6945103079]
[2019-03-23 18:10:35,214] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:10:35,217] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.5053275e-05 8.4854328e-09 9.9998498e-01 8.4972553e-09 5.3164730e-09], sampled 0.9217265537258317
[2019-03-23 18:11:08,410] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00839652], dtype=float32), 0.0041196207]
[2019-03-23 18:11:08,411] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.80516475333334, 64.06661474, 1.0, 2.0, 0.3021213432664158, 0.0, 2.0, 0.0, 1.0, 2.0, 0.611672080652222, 6.911200000000001, 6.9112, 95.55338769695034, 688140.7115596393, 688140.7115596388, 197995.8028752444]
[2019-03-23 18:11:08,412] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:11:08,415] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.6661131e-05 2.7259106e-10 9.9997330e-01 2.5517602e-10 6.3841088e-10], sampled 0.08611413069834328
[2019-03-23 18:11:11,601] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00839652], dtype=float32), 0.0041196207]
[2019-03-23 18:11:11,601] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.6, 84.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 95.55338769695034, 255721.261943954, 255721.2619439543, 109505.6873719267]
[2019-03-23 18:11:11,602] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:11:11,605] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.4126160e-06 7.2927508e-09 9.9999654e-01 7.8454834e-09 2.0965578e-09], sampled 0.35265719450899413
[2019-03-23 18:11:18,547] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00839652], dtype=float32), 0.0041196207]
[2019-03-23 18:11:18,547] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.88333333333333, 54.83333333333334, 1.0, 2.0, 0.2238700051387073, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4500864904986082, 6.9112, 6.9112, 77.32846344354104, 510680.1987366643, 510680.1987366643, 170125.2475260537]
[2019-03-23 18:11:18,550] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:11:18,553] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.4553969e-05 2.5222149e-10 9.9997544e-01 2.3194996e-10 5.7627797e-10], sampled 0.6364922870729524
[2019-03-23 18:11:32,272] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3118.8146 2109024566.0080 368.0000
[2019-03-23 18:11:32,380] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2760.8452 2124023301.3954 757.0000
[2019-03-23 18:11:32,680] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3363.0086 2098031640.7795 179.0000
[2019-03-23 18:11:32,735] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3520.4818 2104057336.0669 178.0000
[2019-03-23 18:11:32,740] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3615.7351 2175240536.8163 245.0000
[2019-03-23 18:11:33,756] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 825000, evaluation results [825000.0, 3615.7350615220453, 2175240536.81633, 245.0, 3363.0086404681497, 2098031640.7794623, 179.0, 3520.4818436487803, 2104057336.06692, 178.0, 2760.8452000539987, 2124023301.395385, 757.0, 3118.8146269445274, 2109024566.0080473, 368.0]
[2019-03-23 18:11:33,954] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.5022240e-05 1.4189737e-07 9.9996471e-01 8.4741863e-08 5.7401696e-08], sum to 1.0000
[2019-03-23 18:11:33,963] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7359
[2019-03-23 18:11:33,967] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.9, 92.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3286252971022485, 6.9112, 6.9112, 77.32846344354104, 379445.940390485, 379445.940390485, 149573.0076995583], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7083600.0000, 
sim time next is 7084200.0000, 
raw observation next is [17.8, 92.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3270325724216078, 6.911199999999999, 6.9112, 77.32846344354104, 377692.8606089979, 377692.8606089982, 149302.6781479573], 
processed observation next is [1.0, 1.0, 0.4454545454545455, 0.925, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.038617960602296914, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13988624466999922, 0.13988624466999935, 0.3641528735316032], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5833737], dtype=float32), 1.2461622]. 
=============================================
[2019-03-23 18:11:34,317] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.7970422e-05 6.6453815e-10 9.9997199e-01 3.4899478e-10 4.3825992e-09], sum to 1.0000
[2019-03-23 18:11:34,326] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5930
[2019-03-23 18:11:34,333] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3375547485848838, 6.911200000000001, 6.9112, 77.32846344354104, 389041.2695877263, 389041.269587726, 151313.1843188352], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7104600.0000, 
sim time next is 7105200.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3356626211754178, 6.9112, 6.9112, 77.32846344354104, 386873.3244472365, 386873.3244472365, 151074.9042361461], 
processed observation next is [1.0, 0.21739130434782608, 0.44090909090909086, 0.97, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.050946601679168285, 0.0, 0.0, 0.5084288129206541, 0.14328641646193943, 0.14328641646193943, 0.3684753761857222], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.00894711], dtype=float32), -1.3365109]. 
=============================================
[2019-03-23 18:11:34,502] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6587706e-05 9.2409094e-09 9.9998343e-01 1.7454242e-08 2.1070425e-08], sum to 1.0000
[2019-03-23 18:11:34,513] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3687
[2019-03-23 18:11:34,520] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.8, 91.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3647384098402188, 6.9112, 6.9112, 77.32846344354104, 419326.3984941545, 419326.3984941545, 155598.4527007972], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7072200.0000, 
sim time next is 7072800.0000, 
raw observation next is [18.8, 92.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.371082122678803, 6.9112, 6.9112, 77.32846344354104, 426480.7519735183, 426480.7519735183, 156529.8480041753], 
processed observation next is [1.0, 0.8695652173913043, 0.49090909090909096, 0.92, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.10154588954114713, 0.0, 0.0, 0.5084288129206541, 0.15795583406426603, 0.15795583406426603, 0.38178011708335435], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.47310916], dtype=float32), -0.33513552]. 
=============================================
[2019-03-23 18:11:38,743] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.5777926e-04 1.2544899e-06 9.9983966e-01 8.0489741e-07 4.5550453e-07], sum to 1.0000
[2019-03-23 18:11:38,748] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1437267e-05 1.8676735e-10 9.9998856e-01 3.5955952e-10 2.7189420e-10], sum to 1.0000
[2019-03-23 18:11:38,751] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3684
[2019-03-23 18:11:38,756] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [15.25, 77.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 234390.6672317697, 234390.6672317697, 96431.96888087665], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7173000.0000, 
sim time next is 7173600.0000, 
raw observation next is [15.16666666666667, 77.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 232877.9829876809, 232877.9829876812, 95841.55964480764], 
processed observation next is [1.0, 0.0, 0.3257575757575759, 0.7733333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0862511048102522, 0.08625110481025229, 0.23375990157270157], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.168087], dtype=float32), 1.1774561]. 
=============================================
[2019-03-23 18:11:38,760] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9836
[2019-03-23 18:11:38,767] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 61.0, 1.0, 2.0, 0.2343423981370814, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4722510898459039, 6.911199999999999, 6.9112, 77.32846344354104, 534789.8601679677, 534789.860167968, 173216.4393369962], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7495800.0000, 
sim time next is 7496400.0000, 
raw observation next is [25.9, 60.0, 1.0, 2.0, 0.2299818540866463, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4626831313324821, 6.911199999999999, 6.9112, 77.32846344354104, 524707.3317076287, 524707.3317076289, 171623.2752003299], 
processed observation next is [0.0, 0.782608695652174, 0.8136363636363636, 0.6, 1.0, 1.0, 0.037477317608307845, 0.0, 1.0, -0.25, 1.0, 1.0, 0.23240447333211736, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1943360487806032, 0.1943360487806033, 0.4185933541471461], 
reward next is 0.5814, 
noisyNet noise sample is [array([0.6808091], dtype=float32), 2.3516498]. 
=============================================
[2019-03-23 18:11:43,641] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.36761992e-05 6.58642563e-08 9.99986053e-01 1.19023646e-07
 3.60136205e-08], sum to 1.0000
[2019-03-23 18:11:43,647] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6679
[2019-03-23 18:11:43,651] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.0, 43.0, 1.0, 2.0, 0.3803055441214656, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7185522780556374, 6.911199999999999, 6.9112, 77.32846344354104, 833481.2581030322, 833481.2581030326, 191147.2638898401], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7224000.0000, 
sim time next is 7224600.0000, 
raw observation next is [23.9, 43.0, 1.0, 2.0, 0.3754046920297999, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7078360820660786, 6.911199999999999, 6.9112, 77.32846344354104, 821398.3811933488, 821398.3811933491, 189313.7571059148], 
processed observation next is [1.0, 0.6086956521739131, 0.7227272727272727, 0.43, 1.0, 1.0, 0.2192558650372499, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5826229743801123, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3042216226642033, 0.3042216226642034, 0.4617408709900361], 
reward next is 0.5383, 
noisyNet noise sample is [array([1.5831087], dtype=float32), -1.1877205]. 
=============================================
[2019-03-23 18:11:44,143] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7204034e-04 2.3024953e-07 9.9982762e-01 1.6589313e-07 3.6949807e-08], sum to 1.0000
[2019-03-23 18:11:44,148] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8495
[2019-03-23 18:11:44,152] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.8, 89.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 259352.9278429465, 259352.9278429468, 104616.0854980567], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7262400.0000, 
sim time next is 7263000.0000, 
raw observation next is [14.7, 89.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 255897.4877348997, 255897.4877348994, 103282.2154234592], 
processed observation next is [1.0, 0.043478260869565216, 0.3045454545454545, 0.89, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09477684730922212, 0.09477684730922199, 0.25190784249624193], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5248061], dtype=float32), -0.5381648]. 
=============================================
[2019-03-23 18:11:44,176] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[18.20965 ]
 [17.897802]
 [16.81374 ]
 [17.185987]
 [16.673954]], R is [[18.22189903]
 [18.03968048]
 [17.85928345]
 [17.68069077]
 [17.50388336]].
[2019-03-23 18:11:45,002] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.7471178e-05 1.4427849e-08 9.9995255e-01 2.1847299e-08 3.1180061e-08], sum to 1.0000
[2019-03-23 18:11:45,010] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6384
[2019-03-23 18:11:45,015] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.2, 58.0, 1.0, 2.0, 0.3034293912167892, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5812971412831731, 6.911200000000001, 6.9112, 77.32846344354104, 672027.3859486998, 672027.3859486995, 175274.2473591622], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7295400.0000, 
sim time next is 7296000.0000, 
raw observation next is [22.56666666666667, 57.0, 1.0, 2.0, 0.3123001159622132, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6005737543035857, 6.911199999999999, 6.9112, 77.32846344354104, 693664.7661393736, 693664.7661393739, 178170.6366847933], 
processed observation next is [1.0, 0.43478260869565216, 0.6621212121212122, 0.57, 1.0, 1.0, 0.14037514495276646, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4293910775765511, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.25691287634791615, 0.25691287634791626, 0.4345625284994959], 
reward next is 0.5654, 
noisyNet noise sample is [array([-0.25493598], dtype=float32), 1.2398756]. 
=============================================
[2019-03-23 18:11:45,032] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[20.959488]
 [21.242931]
 [21.749435]
 [22.061298]
 [22.38715 ]], R is [[20.92632675]
 [21.28956604]
 [21.65711212]
 [22.02682877]
 [22.39937592]].
[2019-03-23 18:11:48,925] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.8084079e-06 3.9660357e-08 9.9999404e-01 9.4904458e-08 2.7457364e-08], sum to 1.0000
[2019-03-23 18:11:48,936] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3180
[2019-03-23 18:11:48,940] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.8, 81.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3190780070353361, 6.911199999999999, 6.9112, 77.32846344354104, 369213.2149635557, 369213.214963556, 147673.5580212613], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7344600.0000, 
sim time next is 7345200.0000, 
raw observation next is [18.8, 81.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3172581508643834, 6.9112, 6.9112, 77.32846344354104, 367114.6813504467, 367114.6813504467, 147460.3962967666], 
processed observation next is [1.0, 0.0, 0.49090909090909096, 0.81, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.024654501234833467, 0.0, 0.0, 0.5084288129206541, 0.13596840050016545, 0.13596840050016545, 0.35965950316284534], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.3054715], dtype=float32), -0.12366734]. 
=============================================
[2019-03-23 18:11:50,321] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.4518833e-06 1.6519211e-08 9.9999750e-01 7.5486630e-09 4.1111097e-09], sum to 1.0000
[2019-03-23 18:11:50,328] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2465
[2019-03-23 18:11:50,335] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.53333333333333, 96.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3425406332173051, 6.911200000000001, 6.9112, 77.32846344354104, 395138.3647459169, 395138.3647459166, 151575.1688419238], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7712400.0000, 
sim time next is 7713000.0000, 
raw observation next is [17.45, 96.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3498925574202844, 6.9112, 6.9112, 77.32846344354104, 403838.5856111746, 403838.5856111746, 152249.7502725197], 
processed observation next is [1.0, 0.2608695652173913, 0.4295454545454545, 0.965, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.07127508202897775, 0.0, 0.0, 0.5084288129206541, 0.14956984652265726, 0.14956984652265726, 0.3713408543232188], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9485492], dtype=float32), -0.7897401]. 
=============================================
[2019-03-23 18:11:50,351] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[13.930348]
 [13.801984]
 [13.467628]
 [13.366202]
 [13.261594]], R is [[13.96486092]
 [13.82521248]
 [13.68696022]
 [13.55009079]
 [13.41458988]].
[2019-03-23 18:12:03,909] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:12:03,910] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:12:03,939] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run5
[2019-03-23 18:12:06,964] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3787611e-04 1.2704296e-10 9.9986207e-01 1.0429361e-10 9.9945190e-09], sum to 1.0000
[2019-03-23 18:12:06,965] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4556
[2019-03-23 18:12:06,973] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.38333333333333, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3553010426688106, 6.911200000000001, 6.9112, 77.32846344354104, 409345.3056704167, 409345.3056704164, 153603.8075641027], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7707000.0000, 
sim time next is 7707600.0000, 
raw observation next is [17.2, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3471691240247261, 6.9112, 6.9112, 77.32846344354104, 400376.7053243449, 400376.7053243449, 152228.0128422079], 
processed observation next is [1.0, 0.21739130434782608, 0.41818181818181815, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.06738446289246589, 0.0, 0.0, 0.5084288129206541, 0.14828766863864626, 0.14828766863864626, 0.3712878362005071], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.8588071], dtype=float32), 1.259552]. 
=============================================
[2019-03-23 18:12:15,404] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.6681140e-04 2.4784686e-08 9.9983287e-01 8.2561826e-08 1.6916951e-07], sum to 1.0000
[2019-03-23 18:12:15,410] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3874
[2019-03-23 18:12:15,418] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.1, 69.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 312588.838879297, 312588.8388792973, 133685.4780977022], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7871400.0000, 
sim time next is 7872000.0000, 
raw observation next is [19.2, 68.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 309126.512494081, 309126.512494081, 134008.5154571383], 
processed observation next is [1.0, 0.08695652173913043, 0.509090909090909, 0.6866666666666665, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.1144913009237337, 0.1144913009237337, 0.3268500377003373], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5621912], dtype=float32), 1.5208565]. 
=============================================
[2019-03-23 18:12:15,444] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[26.119453]
 [25.539257]
 [26.407215]
 [27.519878]
 [26.375397]], R is [[25.27550697]
 [25.02275276]
 [24.77252579]
 [24.52480125]
 [24.27955437]].
[2019-03-23 18:12:15,692] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.07233626e-04 1.27108308e-07 9.99691963e-01 5.47876766e-07
 1.04458564e-07], sum to 1.0000
[2019-03-23 18:12:15,697] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2036
[2019-03-23 18:12:15,702] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.6, 67.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 321563.2660156086, 321563.2660156086, 139680.8405989501], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7856400.0000, 
sim time next is 7857000.0000, 
raw observation next is [19.4, 69.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 326417.5707948231, 326417.5707948233, 140506.9380993974], 
processed observation next is [1.0, 0.9565217391304348, 0.5181818181818181, 0.695, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12089539659067523, 0.12089539659067529, 0.3426998490229205], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6871172], dtype=float32), 0.658635]. 
=============================================
[2019-03-23 18:12:15,725] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[26.350794]
 [26.189596]
 [26.270174]
 [26.382858]
 [26.184748]], R is [[26.40793037]
 [26.14385223]
 [25.88241386]
 [25.62359047]
 [25.36735535]].
[2019-03-23 18:12:15,818] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.1087231e-05 1.2336048e-07 9.9995840e-01 2.3476598e-07 1.1863710e-07], sum to 1.0000
[2019-03-23 18:12:15,826] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3203
[2019-03-23 18:12:15,836] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.8, 65.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 318555.3427410363, 318555.3427410366, 137729.4953304116], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7855800.0000, 
sim time next is 7856400.0000, 
raw observation next is [19.6, 67.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 321563.2660156086, 321563.2660156086, 139680.8405989501], 
processed observation next is [1.0, 0.9565217391304348, 0.5272727272727273, 0.6733333333333335, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.1190975059317069, 0.1190975059317069, 0.34068497707061], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.63161767], dtype=float32), 0.13386634]. 
=============================================
[2019-03-23 18:12:19,402] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.9196536e-06 6.9244033e-09 9.9999404e-01 1.3649484e-08 7.9166398e-09], sum to 1.0000
[2019-03-23 18:12:19,408] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3070
[2019-03-23 18:12:19,416] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 208665.7852702028, 208665.7852702031, 91661.44668403681], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 270000.0000, 
sim time next is 270600.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 207891.3357247718, 207891.3357247715, 91514.13138317772], 
processed observation next is [0.0, 0.13043478260869565, 0.22727272727272727, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07699679100917474, 0.07699679100917463, 0.22320519849555542], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.8051193], dtype=float32), -0.28161865]. 
=============================================
[2019-03-23 18:12:19,469] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:12:19,470] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:12:19,496] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run5
[2019-03-23 18:12:20,204] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:12:20,204] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:12:20,207] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run5
[2019-03-23 18:12:20,281] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:12:20,281] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:12:20,290] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run5
[2019-03-23 18:12:20,535] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:12:20,536] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:12:20,537] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run5
[2019-03-23 18:12:20,873] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:12:20,874] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:12:20,878] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run5
[2019-03-23 18:12:20,933] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:12:20,933] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:12:20,935] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run5
[2019-03-23 18:12:20,999] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:12:20,999] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:12:21,000] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run5
[2019-03-23 18:12:21,077] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:12:21,077] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:12:21,078] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run5
[2019-03-23 18:12:21,121] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:12:21,122] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:12:21,124] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run5
[2019-03-23 18:12:21,168] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:12:21,169] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:12:21,170] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run5
[2019-03-23 18:12:21,202] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:12:21,202] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:12:21,204] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run5
[2019-03-23 18:12:21,257] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:12:21,257] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:12:21,259] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run5
[2019-03-23 18:12:21,397] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:12:21,397] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:12:21,398] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run5
[2019-03-23 18:12:21,427] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:12:21,427] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:12:21,432] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run5
[2019-03-23 18:12:21,481] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:12:21,481] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:12:21,483] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run5
[2019-03-23 18:12:24,976] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 18:12:24,977] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:12:24,978] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:12:24,980] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:12:24,980] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:12:24,981] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:12:24,982] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:12:24,983] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:12:24,981] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:12:24,985] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:12:24,987] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:12:25,004] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run35
[2019-03-23 18:12:25,029] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run35
[2019-03-23 18:12:25,056] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run35
[2019-03-23 18:12:25,057] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run35
[2019-03-23 18:12:25,057] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run35
[2019-03-23 18:12:55,020] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0084745], dtype=float32), 0.0046491004]
[2019-03-23 18:12:55,022] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.49858198, 57.9963993, 1.0, 2.0, 0.2154388682916891, 0.0, 2.0, 0.0, 1.0, 2.0, 0.42566254416003, 6.911200000000001, 6.9112, 95.55338769695034, 487341.6189900023, 487341.6189900019, 168532.2466649332]
[2019-03-23 18:12:55,022] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:12:55,024] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.9902327e-04 7.0152506e-09 9.9960095e-01 1.3775650e-08 5.6711006e-08], sampled 0.08753899858633252
[2019-03-23 18:12:59,741] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0084745], dtype=float32), 0.0046491004]
[2019-03-23 18:12:59,744] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.61222498333333, 55.21347053666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 339171.7122474986, 339171.7122474983, 148158.0419484987]
[2019-03-23 18:12:59,747] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:12:59,749] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.3571734e-05 2.2408750e-07 9.9995565e-01 3.6058833e-07 1.3891197e-07], sampled 0.24628824000765537
[2019-03-23 18:13:22,867] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0084745], dtype=float32), 0.0046491004]
[2019-03-23 18:13:22,868] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.83333333333333, 63.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3113478841852635, 6.9112, 6.9112, 95.55338769695034, 360968.3079084876, 360968.3079084876, 150599.3385603956]
[2019-03-23 18:13:22,869] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:13:22,874] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.6830591e-05 1.8131594e-07 9.9992251e-01 3.0426679e-07 1.7446050e-07], sampled 0.8695068944519844
[2019-03-23 18:13:46,480] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0084745], dtype=float32), 0.0046491004]
[2019-03-23 18:13:46,482] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.73333333333333, 76.66666666666667, 1.0, 2.0, 0.3058363157483815, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5990271318981449, 6.911199999999999, 6.9112, 77.32846344354104, 688198.5523748689, 688198.5523748692, 181090.1794509072]
[2019-03-23 18:13:46,483] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:13:46,486] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.3593011e-04 5.1300346e-09 9.9976403e-01 1.0663175e-08 3.5438486e-08], sampled 0.6573670491209543
[2019-03-23 18:14:01,675] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2759.3139 2123934821.4836 758.0000
[2019-03-23 18:14:01,820] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3119.7390 2108985547.2829 369.0000
[2019-03-23 18:14:02,092] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3362.7113 2097945203.7472 180.0000
[2019-03-23 18:14:02,127] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3616.7907 2175120235.0657 246.0000
[2019-03-23 18:14:02,235] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3519.2854 2104028191.2956 178.0000
[2019-03-23 18:14:03,250] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 850000, evaluation results [850000.0, 3616.7907308651284, 2175120235.065727, 246.0, 3362.711274792115, 2097945203.7472212, 180.0, 3519.285402714164, 2104028191.295584, 178.0, 2759.313919940242, 2123934821.4835887, 758.0, 3119.7389789572458, 2108985547.2828763, 369.0]
[2019-03-23 18:14:16,151] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.1508433e-05 7.8583507e-06 9.9994385e-01 2.6094594e-05 7.4362458e-07], sum to 1.0000
[2019-03-23 18:14:16,162] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0574
[2019-03-23 18:14:16,167] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.16666666666667, 62.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 252605.2354567029, 252605.2354567032, 110504.5457484619], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 299400.0000, 
sim time next is 300000.0000, 
raw observation next is [19.33333333333334, 61.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 253502.5589337488, 253502.5589337485, 110373.0189408028], 
processed observation next is [0.0, 0.4782608695652174, 0.5151515151515155, 0.6133333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09388983664212919, 0.09388983664212908, 0.2692024852214702], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7238301], dtype=float32), 0.9791764]. 
=============================================
[2019-03-23 18:14:16,182] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[0.87829447]
 [0.8944421 ]
 [0.91820455]
 [0.9544705 ]
 [0.97716236]], R is [[0.83783787]
 [0.82945949]
 [0.82116491]
 [0.81295329]
 [0.80482376]].
[2019-03-23 18:14:16,341] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.3688531e-05 2.7069806e-05 9.9991620e-01 2.1696589e-05 1.2875827e-06], sum to 1.0000
[2019-03-23 18:14:16,351] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4964
[2019-03-23 18:14:16,356] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 236908.8728668569, 236908.8728668572, 101664.6503755313], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 282600.0000, 
sim time next is 283200.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 237632.0896996653, 237632.0896996653, 101811.5628184353], 
processed observation next is [0.0, 0.2608695652173913, 0.2727272727272727, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.08801188507395011, 0.08801188507395011, 0.2483208849230129], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.07908918], dtype=float32), -1.2570351]. 
=============================================
[2019-03-23 18:14:20,875] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.4106246e-04 2.9411783e-06 9.9915135e-01 3.0205897e-06 1.6144863e-06], sum to 1.0000
[2019-03-23 18:14:20,883] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2157
[2019-03-23 18:14:20,886] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [12.0, 76.0, 1.0, 2.0, 0.2018396800170586, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3767904643588473, 6.9112, 6.9112, 77.32846344354104, 438386.9062427719, 438386.9062427719, 121428.1334565831], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 366000.0000, 
sim time next is 366600.0000, 
raw observation next is [12.0, 76.0, 1.0, 2.0, 0.2022870600996516, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3776256249628022, 6.9112, 6.9112, 77.32846344354104, 439359.0351512149, 439359.0351512149, 121505.4000959376], 
processed observation next is [1.0, 0.21739130434782608, 0.18181818181818182, 0.76, 1.0, 1.0, 0.0028588251245645, 0.0, 1.0, -0.25, 1.0, 1.0, 0.11089374994686034, 0.0, 0.0, 0.5084288129206541, 0.16272556857452405, 0.16272556857452405, 0.2963546343803356], 
reward next is 0.7036, 
noisyNet noise sample is [array([1.6123996], dtype=float32), 0.23570798]. 
=============================================
[2019-03-23 18:14:22,893] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.8843765e-04 3.7332011e-06 9.9980050e-01 5.7981088e-06 1.5544083e-06], sum to 1.0000
[2019-03-23 18:14:22,900] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2708
[2019-03-23 18:14:22,906] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [13.0, 99.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 210779.9438469571, 210779.9438469574, 91886.30764631186], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 434400.0000, 
sim time next is 435000.0000, 
raw observation next is [13.0, 99.16666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 209156.2872562572, 209156.2872562575, 91529.78403119324], 
processed observation next is [1.0, 0.0, 0.22727272727272727, 0.9916666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07746529157639155, 0.07746529157639166, 0.22324337568583716], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0142967], dtype=float32), -1.2146401]. 
=============================================
[2019-03-23 18:14:22,926] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[11.076535]
 [11.597995]
 [10.929576]
 [10.984307]
 [10.498519]], R is [[11.32157135]
 [11.2083559 ]
 [11.09627247]
 [10.9853096 ]
 [10.87545681]].
[2019-03-23 18:14:25,956] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.2284394e-04 4.5568580e-08 9.9977654e-01 1.0879127e-07 4.3068260e-07], sum to 1.0000
[2019-03-23 18:14:25,963] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1138
[2019-03-23 18:14:25,969] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 325021.5680474165, 325021.5680474168, 118934.6453443238], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 477600.0000, 
sim time next is 478200.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 320048.0392167295, 320048.0392167295, 117914.4400221893], 
processed observation next is [1.0, 0.5217391304347826, 0.2727272727272727, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.11853631082101093, 0.11853631082101093, 0.2875961951760715], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.8909491], dtype=float32), -0.7730274]. 
=============================================
[2019-03-23 18:14:31,014] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.6917098e-04 3.7943883e-07 9.9982661e-01 1.9454660e-06 1.8940812e-06], sum to 1.0000
[2019-03-23 18:14:31,021] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5715
[2019-03-23 18:14:31,025] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.33333333333333, 75.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3377642957006834, 6.9112, 6.9112, 77.32846344354104, 389414.0716138023, 389414.0716138023, 151212.2203318696], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 585600.0000, 
sim time next is 586200.0000, 
raw observation next is [20.16666666666667, 76.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3372668635371932, 6.911200000000001, 6.9112, 77.32846344354104, 388767.1178285255, 388767.1178285253, 151223.485531052], 
processed observation next is [1.0, 0.782608695652174, 0.5530303030303032, 0.765, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0532383764817046, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1439878214179724, 0.14398782141797234, 0.3688377695879317], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9104952], dtype=float32), -1.7303731]. 
=============================================
[2019-03-23 18:14:33,586] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0277652e-02 1.8165299e-07 9.8972124e-01 4.5060077e-07 5.2655656e-07], sum to 1.0000
[2019-03-23 18:14:33,600] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1010
[2019-03-23 18:14:33,604] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 80.5, 1.0, 2.0, 0.2394019884855669, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4579288199849433, 6.9112, 6.9112, 77.32846344354104, 529524.962711226, 529524.962711226, 162008.8136887289], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 635400.0000, 
sim time next is 636000.0000, 
raw observation next is [19.33333333333333, 79.66666666666667, 1.0, 2.0, 0.2567693393859309, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4939223143890309, 6.911199999999999, 6.9112, 77.32846344354104, 570368.729332178, 570368.7293321784, 166266.8090671405], 
processed observation next is [1.0, 0.34782608695652173, 0.5151515151515149, 0.7966666666666667, 1.0, 1.0, 0.07096167423241359, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2770318776986156, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2112476775304363, 0.21124767753043644, 0.40552880260278173], 
reward next is 0.5945, 
noisyNet noise sample is [array([-0.5668701], dtype=float32), -0.32702464]. 
=============================================
[2019-03-23 18:14:33,624] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[35.780792]
 [33.04382 ]
 [31.787657]
 [31.714296]
 [31.683065]], R is [[38.22309875]
 [38.4457283 ]
 [38.06127167]
 [37.68066025]
 [37.3038559 ]].
[2019-03-23 18:14:36,345] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.8685693e-04 2.6016655e-08 9.9961299e-01 6.9649282e-08 8.6018673e-08], sum to 1.0000
[2019-03-23 18:14:36,352] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7072
[2019-03-23 18:14:36,357] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.66666666666667, 48.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3680349082154308, 6.9112, 6.9112, 77.32846344248352, 422257.7590542451, 422257.7590542451, 156792.4864685692], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 667200.0000, 
sim time next is 667800.0000, 
raw observation next is [25.5, 49.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3486560957445183, 6.9112, 6.9112, 77.3284634435345, 400359.9517067528, 400359.9517067528, 154029.1665836922], 
processed observation next is [1.0, 0.7391304347826086, 0.7954545454545454, 0.49, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0695087082064547, 0.0, 0.0, 0.5084288129206112, 0.14828146359509364, 0.14828146359509364, 0.3756808941065663], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.16909187], dtype=float32), -1.7114139]. 
=============================================
[2019-03-23 18:14:43,374] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.2030533e-05 1.7812747e-08 9.9995792e-01 2.2432363e-09 5.0288604e-09], sum to 1.0000
[2019-03-23 18:14:43,382] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1171
[2019-03-23 18:14:43,390] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.66666666666667, 92.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3903957821480558, 6.9112, 6.9112, 77.32846344354104, 446675.0952701232, 446675.0952701232, 160789.9770618979], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 800400.0000, 
sim time next is 801000.0000, 
raw observation next is [20.0, 91.0, 1.0, 2.0, 0.2006392654940168, 0.0, 2.0, 0.0, 1.0, 2.0, 0.398223819482646, 6.9112, 6.9112, 77.32846344354104, 455092.6761234325, 455092.6761234325, 162244.6280192505], 
processed observation next is [0.0, 0.2608695652173913, 0.5454545454545454, 0.91, 1.0, 1.0, 0.0007990818675209996, 0.0, 1.0, -0.25, 1.0, 1.0, 0.14031974211806575, 0.0, 0.0, 0.5084288129206541, 0.1685528430086787, 0.1685528430086787, 0.3957186049250012], 
reward next is 0.6043, 
noisyNet noise sample is [array([0.3619685], dtype=float32), 0.316629]. 
=============================================
[2019-03-23 18:14:43,410] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[37.975555]
 [37.331955]
 [36.89742 ]
 [36.742493]
 [36.6409  ]], R is [[38.84382629]
 [38.45538712]
 [38.07083511]
 [37.69012833]
 [37.31322861]].
[2019-03-23 18:14:46,207] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.31173176e-04 1.10314491e-09 9.99868751e-01 2.03977324e-09
 1.12881695e-08], sum to 1.0000
[2019-03-23 18:14:46,215] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5781
[2019-03-23 18:14:46,224] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.66666666666666, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3926942285203982, 6.911199999999999, 6.9112, 77.32846344354104, 449757.1277672657, 449757.127767266, 160709.3055314451], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 870000.0000, 
sim time next is 870600.0000, 
raw observation next is [19.83333333333334, 89.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3937695195941309, 6.911199999999999, 6.9112, 77.32846344354104, 450875.9167420417, 450875.916742042, 160951.3767263379], 
processed observation next is [0.0, 0.043478260869565216, 0.5378787878787882, 0.89, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1339564565630442, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16699108027483026, 0.16699108027483037, 0.392564333478873], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7974296], dtype=float32), 0.03874681]. 
=============================================
[2019-03-23 18:14:46,347] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.7592616e-05 2.1025882e-10 9.9992239e-01 3.2106802e-09 1.0975128e-08], sum to 1.0000
[2019-03-23 18:14:46,356] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3978
[2019-03-23 18:14:46,360] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.5, 85.5, 1.0, 2.0, 0.2059491096531161, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4083124166407866, 6.9112, 6.9112, 77.32846344354104, 466851.8336241831, 466851.8336241831, 162918.8670743814], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 858600.0000, 
sim time next is 859200.0000, 
raw observation next is [20.33333333333333, 86.33333333333334, 1.0, 2.0, 0.2046511081239547, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4054156303469906, 6.9112, 6.9112, 77.32846344354104, 463695.3907161072, 463695.3907161072, 162515.4602740307], 
processed observation next is [0.0, 0.9565217391304348, 0.5606060606060604, 0.8633333333333334, 1.0, 1.0, 0.0058138851549433684, 0.0, 1.0, -0.25, 1.0, 1.0, 0.15059375763855798, 0.0, 0.0, 0.5084288129206541, 0.17173903359855822, 0.17173903359855822, 0.39637917140007484], 
reward next is 0.6036, 
noisyNet noise sample is [array([0.17794798], dtype=float32), 1.1547337]. 
=============================================
[2019-03-23 18:14:48,903] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.1276251e-04 1.5317127e-12 9.9958724e-01 2.2019463e-12 5.9949504e-11], sum to 1.0000
[2019-03-23 18:14:48,911] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4202
[2019-03-23 18:14:48,918] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 69.33333333333334, 1.0, 2.0, 0.2411302239132554, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4869853812531714, 6.911200000000001, 6.9112, 77.32846344354104, 550221.4516548136, 550221.4516548134, 175734.8425734369], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 908400.0000, 
sim time next is 909000.0000, 
raw observation next is [24.5, 71.5, 1.0, 2.0, 0.2388230876912113, 0.0, 2.0, 0.0, 1.0, 2.0, 0.481990653438703, 6.9112, 6.9112, 77.32846344354104, 545015.3885296047, 545015.3885296047, 174863.6203088506], 
processed observation next is [0.0, 0.5217391304347826, 0.75, 0.715, 1.0, 1.0, 0.04852885961401411, 0.0, 1.0, -0.25, 1.0, 1.0, 0.25998664776957575, 0.0, 0.0, 0.5084288129206541, 0.201857551307261, 0.201857551307261, 0.42649663489963563], 
reward next is 0.5735, 
noisyNet noise sample is [array([0.5429329], dtype=float32), -1.1642344]. 
=============================================
[2019-03-23 18:14:48,929] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[59.45508 ]
 [59.492928]
 [59.58466 ]
 [59.60604 ]
 [59.68156 ]], R is [[59.52736282]
 [59.50346756]
 [59.47807693]
 [59.4516716 ]
 [59.42530441]].
[2019-03-23 18:14:49,350] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8146905e-07 5.1304219e-13 9.9999976e-01 8.6957546e-13 1.3624156e-11], sum to 1.0000
[2019-03-23 18:14:49,359] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4113
[2019-03-23 18:14:49,365] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.66666666666667, 74.66666666666667, 1.0, 2.0, 0.2325083173941954, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4683794744170221, 6.911199999999999, 6.9112, 77.32846344354104, 530583.9271236982, 530583.9271236985, 172668.8251718526], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 915000.0000, 
sim time next is 915600.0000, 
raw observation next is [23.33333333333333, 75.33333333333334, 1.0, 2.0, 0.2305170376382355, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4636858156510933, 6.9112, 6.9112, 77.32846344354104, 525911.6730815585, 525911.6730815585, 171675.2640416998], 
processed observation next is [0.0, 0.6086956521739131, 0.6969696969696968, 0.7533333333333334, 1.0, 1.0, 0.03814629704779436, 0.0, 1.0, -0.25, 1.0, 1.0, 0.23383687950156187, 0.0, 0.0, 0.5084288129206541, 0.19478210114131797, 0.19478210114131797, 0.4187201561992678], 
reward next is 0.5813, 
noisyNet noise sample is [array([-0.6305025], dtype=float32), 0.032428365]. 
=============================================
[2019-03-23 18:14:49,910] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.2700251e-03 6.5481404e-10 9.9672997e-01 6.2409183e-10 3.6826249e-09], sum to 1.0000
[2019-03-23 18:14:49,921] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7507
[2019-03-23 18:14:49,924] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [15.33333333333333, 100.0, 1.0, 2.0, 0.285622761688317, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5333444774863741, 6.9112, 6.9112, 77.32846344354104, 620476.2133511713, 620476.2133511713, 166454.5926049652], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 999600.0000, 
sim time next is 1000200.0000, 
raw observation next is [15.16666666666667, 100.0, 1.0, 2.0, 0.2827936895569096, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5279244612357977, 6.911200000000001, 6.9112, 77.32846344354104, 614326.5585863458, 614326.5585863455, 163587.9613703292], 
processed observation next is [1.0, 0.5652173913043478, 0.3257575757575759, 1.0, 1.0, 1.0, 0.10349211194613697, 0.0, 1.0, -0.25, 1.0, 1.0, 0.32560637319399677, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2275283550319799, 0.22752835503197982, 0.3989950277325102], 
reward next is 0.6010, 
noisyNet noise sample is [array([-0.21488026], dtype=float32), 0.7253019]. 
=============================================
[2019-03-23 18:14:52,503] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.3414284e-04 1.9406410e-09 9.9926585e-01 9.7661674e-09 2.7110888e-08], sum to 1.0000
[2019-03-23 18:14:52,514] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7380
[2019-03-23 18:14:52,518] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.33333333333333, 100.0, 1.0, 2.0, 0.2955739082683006, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5634982572653491, 6.911199999999999, 6.9112, 77.32846344354104, 652196.5479537948, 652196.5479537951, 172511.5065481328], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 988800.0000, 
sim time next is 989400.0000, 
raw observation next is [16.16666666666667, 100.0, 1.0, 2.0, 0.2903871066111543, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5513801734888529, 6.9112, 6.9112, 77.32846344354104, 638751.0766516706, 638751.0766516706, 170598.8547497249], 
processed observation next is [1.0, 0.43478260869565216, 0.37121212121212144, 1.0, 1.0, 1.0, 0.11298388326394286, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3591145335555042, 0.0, 0.0, 0.5084288129206541, 0.23657447283395208, 0.23657447283395208, 0.4160947676822559], 
reward next is 0.5839, 
noisyNet noise sample is [array([0.7223884], dtype=float32), -1.0990937]. 
=============================================
[2019-03-23 18:14:53,231] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 18:14:53,232] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:14:53,233] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:14:53,233] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:14:53,233] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:14:53,236] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:14:53,238] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:14:53,236] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:14:53,238] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:14:53,240] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:14:53,240] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:14:53,253] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run36
[2019-03-23 18:14:53,254] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run36
[2019-03-23 18:14:53,302] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run36
[2019-03-23 18:14:53,303] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run36
[2019-03-23 18:14:53,303] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run36
[2019-03-23 18:15:19,051] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00870175], dtype=float32), 0.0047660405]
[2019-03-23 18:15:19,052] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.81005401666667, 54.02127600666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000002, 6.9112, 95.55338769695034, 338074.9449455568, 338074.9449455561, 146812.4508116469]
[2019-03-23 18:15:19,052] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:15:19,055] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.3661582e-04 1.5054420e-08 9.9986327e-01 2.2271111e-08 7.6166508e-08], sampled 0.05841560866618245
[2019-03-23 18:15:20,133] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00870175], dtype=float32), 0.0047660405]
[2019-03-23 18:15:20,135] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.3, 86.66666666666666, 1.0, 2.0, 0.3019584760455726, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6114542121852976, 6.911200000000001, 6.9112, 95.55338769695034, 687487.8056644184, 687487.805664418, 198217.1268856329]
[2019-03-23 18:15:20,136] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:15:20,140] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.4171407e-05 2.2126192e-11 9.9993587e-01 4.2076238e-11 8.1395313e-10], sampled 0.21311373710713766
[2019-03-23 18:15:52,754] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00870175], dtype=float32), 0.0047660405]
[2019-03-23 18:15:52,755] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.41749914, 68.039960325, 1.0, 2.0, 0.2378085209490726, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4801978091536404, 6.911200000000001, 6.9112, 95.55338769695034, 542598.7136025052, 542598.7136025048, 179611.1001179161]
[2019-03-23 18:15:52,756] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:15:52,760] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.1792527e-04 6.2527754e-11 9.9988210e-01 1.1721853e-10 2.1952846e-09], sampled 0.051482399723166816
[2019-03-23 18:16:24,718] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00870175], dtype=float32), 0.0047660405]
[2019-03-23 18:16:24,720] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.55928347, 61.35907589, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.375289546772429, 6.911200000000001, 6.9112, 95.55338769695034, 431783.1386390838, 431783.1386390834, 161235.5485426444]
[2019-03-23 18:16:24,722] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:16:24,730] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0026439e-04 1.5431267e-10 9.9989974e-01 2.7333319e-10 3.6544869e-09], sampled 0.5273554576603878
[2019-03-23 18:16:29,787] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00870175], dtype=float32), 0.0047660405]
[2019-03-23 18:16:29,790] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.072824445, 72.415489295, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3084258593848283, 6.9112, 6.9112, 95.55338769695034, 356757.7661328359, 356757.7661328359, 151119.9018617735]
[2019-03-23 18:16:29,794] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:16:29,797] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.3523419e-04 9.5727453e-09 9.9986470e-01 1.4359241e-08 5.8692539e-08], sampled 0.4020453466210907
[2019-03-23 18:16:30,471] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3119.6484 2108991956.8470 368.0000
[2019-03-23 18:16:30,747] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2762.5226 2123968922.8295 757.0000
[2019-03-23 18:16:30,785] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3520.5382 2103916332.8558 179.0000
[2019-03-23 18:16:30,825] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3615.6971 2175258031.8538 245.0000
[2019-03-23 18:16:30,931] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3363.0027 2097978287.5787 179.0000
[2019-03-23 18:16:31,947] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 875000, evaluation results [875000.0, 3615.6971334805353, 2175258031.8537707, 245.0, 3363.002718287279, 2097978287.5786793, 179.0, 3520.538212319965, 2103916332.8557794, 179.0, 2762.5226348826823, 2123968922.8294897, 757.0, 3119.6483972694346, 2108991956.8469684, 368.0]
[2019-03-23 18:16:37,938] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.7012107e-06 5.5708704e-13 9.9999428e-01 8.3667006e-12 1.1461297e-11], sum to 1.0000
[2019-03-23 18:16:37,944] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3019
[2019-03-23 18:16:37,954] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 88.66666666666666, 1.0, 2.0, 0.2531183287673433, 0.0, 2.0, 0.0, 1.0, 2.0, 0.512468599095784, 6.911200000000001, 6.9112, 77.32846344354104, 576521.6865230842, 576521.686523084, 180346.2451676627], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1521600.0000, 
sim time next is 1522200.0000, 
raw observation next is [23.5, 85.83333333333334, 1.0, 2.0, 0.2555076419762871, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5174200385397841, 6.911200000000001, 6.9112, 77.32846344354104, 581662.1577227198, 581662.1577227196, 181219.8620541827], 
processed observation next is [0.0, 0.6086956521739131, 0.7045454545454546, 0.8583333333333334, 1.0, 1.0, 0.06938455247035888, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3106000550568345, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21543042878619253, 0.21543042878619245, 0.4419996635467871], 
reward next is 0.5580, 
noisyNet noise sample is [array([1.058746], dtype=float32), -0.23245111]. 
=============================================
[2019-03-23 18:16:39,551] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.4131483e-06 5.7643711e-06 9.9998057e-01 7.7067571e-06 5.5506484e-07], sum to 1.0000
[2019-03-23 18:16:39,560] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4920
[2019-03-23 18:16:39,566] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 78.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3053032376029828, 6.911200000000001, 6.9112, 77.32846344354104, 353604.194290664, 353604.1942906638, 145788.8032492348], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1114200.0000, 
sim time next is 1114800.0000, 
raw observation next is [19.0, 78.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3054733222972881, 6.911200000000001, 6.9112, 77.32846344354104, 353801.4466445792, 353801.4466445789, 145807.2666880585], 
processed observation next is [1.0, 0.9130434782608695, 0.5, 0.78, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.007819031853268694, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1310375728313256, 0.1310375728313255, 0.35562747972697195], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1560345], dtype=float32), 1.3481257]. 
=============================================
[2019-03-23 18:16:42,456] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.8565144e-06 2.3519968e-09 9.9999511e-01 1.8859576e-09 4.7581477e-09], sum to 1.0000
[2019-03-23 18:16:42,463] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0928
[2019-03-23 18:16:42,470] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 66.0, 1.0, 2.0, 0.6445615338435466, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9788210636260919, 6.9112, 6.9112, 77.32846344353644, 1279403.439417978, 1279403.439417978, 285368.3106723871], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1173600.0000, 
sim time next is 1174200.0000, 
raw observation next is [27.0, 65.33333333333333, 1.0, 2.0, 0.7476078736670994, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9786138702202497, 6.911200000000001, 6.9112, 77.32846344354101, 1396651.962012828, 1396651.962012828, 300769.4922149776], 
processed observation next is [1.0, 0.6086956521739131, 0.8636363636363636, 0.6533333333333333, 1.0, 1.0, 0.6845098420838741, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9694483860289284, 8.881784197001253e-17, 0.0, 0.5084288129206539, 0.5172785044491955, 0.5172785044491955, 0.733584127353604], 
reward next is 0.2664, 
noisyNet noise sample is [array([1.5648437], dtype=float32), 0.7299042]. 
=============================================
[2019-03-23 18:16:47,052] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0376289e-05 1.8114852e-09 9.9998963e-01 7.8175078e-10 1.2992539e-08], sum to 1.0000
[2019-03-23 18:16:47,062] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7076
[2019-03-23 18:16:47,068] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.0, 58.66666666666666, 1.0, 2.0, 0.4782353226198653, 1.0, 2.0, 0.4782353226198653, 1.0, 2.0, 0.9666890886278253, 6.9112, 6.9112, 77.3421103, 1613633.692940503, 1613633.692940503, 347674.3054059556], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1266600.0000, 
sim time next is 1267200.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.8056049069717522, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9785243649332535, 6.911199999999999, 6.9112, 77.32846344354104, 1462647.614185868, 1462647.614185868, 310171.9545535786], 
processed observation next is [1.0, 0.6956521739130435, 0.9090909090909091, 0.58, 1.0, 1.0, 0.7570061337146902, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9693205213332193, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5417213385873585, 0.5417213385873585, 0.7565169623258013], 
reward next is 0.2435, 
noisyNet noise sample is [array([0.5468594], dtype=float32), 0.46121436]. 
=============================================
[2019-03-23 18:16:52,612] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.7676327e-05 3.2229767e-11 9.9995232e-01 2.5818285e-11 1.3627423e-09], sum to 1.0000
[2019-03-23 18:16:52,621] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6510
[2019-03-23 18:16:52,623] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.16666666666667, 86.33333333333334, 1.0, 2.0, 0.2339143779848989, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4714058885928118, 6.9112, 6.9112, 77.32846344354104, 533813.967694544, 533813.967694544, 173140.9986958851], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1363800.0000, 
sim time next is 1364400.0000, 
raw observation next is [22.0, 88.0, 1.0, 2.0, 0.2354614603648576, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4746746037958298, 6.9112, 6.9112, 77.32846344354104, 537355.9250059064, 537355.9250059064, 173610.7820073714], 
processed observation next is [1.0, 0.8260869565217391, 0.6363636363636364, 0.88, 1.0, 1.0, 0.044326825456071986, 0.0, 1.0, -0.25, 1.0, 1.0, 0.24953514827975692, 0.0, 0.0, 0.5084288129206541, 0.1990207129651505, 0.1990207129651505, 0.42344093172529607], 
reward next is 0.5766, 
noisyNet noise sample is [array([-0.04259598], dtype=float32), 1.8763123]. 
=============================================
[2019-03-23 18:16:54,829] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.1117469e-04 9.0780100e-12 9.9918884e-01 3.5827612e-11 7.6579143e-10], sum to 1.0000
[2019-03-23 18:16:54,836] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3241
[2019-03-23 18:16:54,841] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.5, 70.5, 1.0, 2.0, 0.2728839186066381, 0.0, 2.0, 0.0, 1.0, 2.0, 0.552677976317501, 6.9112, 6.9112, 77.32846344354104, 618606.2687791884, 618606.2687791884, 187266.5033261727], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1434600.0000, 
sim time next is 1435200.0000, 
raw observation next is [26.33333333333334, 70.66666666666666, 1.0, 2.0, 0.2701312024168246, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5471702123649491, 6.9112, 6.9112, 77.32846344354104, 612925.105788076, 612925.105788076, 186259.3288247087], 
processed observation next is [0.0, 0.6086956521739131, 0.8333333333333336, 0.7066666666666666, 1.0, 1.0, 0.08766400302103072, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3531003033784988, 0.0, 0.0, 0.5084288129206541, 0.22700929844002812, 0.22700929844002812, 0.45429104591392366], 
reward next is 0.5457, 
noisyNet noise sample is [array([0.43354088], dtype=float32), -1.234886]. 
=============================================
[2019-03-23 18:17:00,234] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0276682e-04 2.0436196e-10 9.9989724e-01 1.2519500e-09 6.0705609e-09], sum to 1.0000
[2019-03-23 18:17:00,246] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1011
[2019-03-23 18:17:00,249] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.66666666666666, 67.33333333333334, 1.0, 2.0, 0.3038687519522992, 0.0, 2.0, 0.0, 1.0, 2.0, 0.614841783200132, 6.9112, 6.9112, 77.32846344354104, 682938.1578666389, 682938.1578666389, 198367.2569450251], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1514400.0000, 
sim time next is 1515000.0000, 
raw observation next is [28.83333333333334, 66.66666666666666, 1.0, 2.0, 0.3049379317579632, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6170051396296844, 6.9112, 6.9112, 77.32846344354104, 685342.8098240594, 685342.8098240594, 198687.0555474595], 
processed observation next is [0.0, 0.5217391304347826, 0.9469696969696972, 0.6666666666666665, 1.0, 1.0, 0.13117241469745397, 0.0, 1.0, -0.25, 1.0, 1.0, 0.45286448518526345, 0.0, 0.0, 0.5084288129206541, 0.2538306703052072, 0.2538306703052072, 0.48460257450599875], 
reward next is 0.5154, 
noisyNet noise sample is [array([-2.238195], dtype=float32), -0.85911894]. 
=============================================
[2019-03-23 18:17:00,264] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[51.73958 ]
 [51.77425 ]
 [51.731285]
 [51.655666]
 [51.63116 ]], R is [[51.68153   ]
 [51.68089294]
 [51.68095398]
 [51.68148804]
 [51.68214035]].
[2019-03-23 18:17:01,470] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.2597571e-03 7.6184636e-10 9.9373996e-01 1.3404193e-09 4.0189906e-07], sum to 1.0000
[2019-03-23 18:17:01,478] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1421
[2019-03-23 18:17:01,484] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.16666666666667, 83.0, 1.0, 2.0, 0.2446559585234079, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4945804935753019, 6.9112, 6.9112, 77.32846344354104, 558084.0526273035, 558084.0526273035, 177095.8038741022], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1540200.0000, 
sim time next is 1540800.0000, 
raw observation next is [23.0, 83.0, 1.0, 2.0, 0.2410450652073177, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4869414554068463, 6.9112, 6.9112, 77.32846344354104, 549989.8476188192, 549989.8476188192, 175861.2354044439], 
processed observation next is [0.0, 0.8695652173913043, 0.6818181818181818, 0.83, 1.0, 1.0, 0.0513063315091471, 0.0, 1.0, -0.25, 1.0, 1.0, 0.26705922200978044, 0.0, 0.0, 0.5084288129206541, 0.20369994356252563, 0.20369994356252563, 0.42892984244986315], 
reward next is 0.5711, 
noisyNet noise sample is [array([-1.4325814], dtype=float32), -0.38348648]. 
=============================================
[2019-03-23 18:17:02,493] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1656157e-05 9.0207170e-10 9.9997830e-01 1.4646315e-09 1.4664800e-08], sum to 1.0000
[2019-03-23 18:17:02,500] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7928
[2019-03-23 18:17:02,505] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.66666666666667, 90.0, 1.0, 2.0, 0.2092420078626002, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4181315065968392, 6.911200000000001, 6.9112, 77.32846344354104, 476257.2186614546, 476257.2186614543, 165440.0804141223], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1557600.0000, 
sim time next is 1558200.0000, 
raw observation next is [20.83333333333333, 89.0, 1.0, 2.0, 0.2095324914579609, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4188937813325268, 6.9112, 6.9112, 77.32846344354104, 477010.2564747385, 477010.2564747385, 165611.3758870904], 
processed observation next is [1.0, 0.0, 0.5833333333333331, 0.89, 1.0, 1.0, 0.01191561432245112, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1698482590464669, 0.0, 0.0, 0.5084288129206541, 0.17667046536101425, 0.17667046536101425, 0.4039301850904644], 
reward next is 0.5961, 
noisyNet noise sample is [array([-0.35260987], dtype=float32), 0.10946379]. 
=============================================
[2019-03-23 18:17:08,235] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.9674368e-04 1.8124961e-08 9.9980325e-01 7.8868281e-09 2.7191255e-08], sum to 1.0000
[2019-03-23 18:17:08,249] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1556
[2019-03-23 18:17:08,254] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.91666666666667, 67.16666666666666, 1.0, 2.0, 0.2220533582766695, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4176146600556365, 6.911199999999999, 6.9112, 77.32846344354104, 484705.3270421228, 484705.3270421231, 156428.703077266], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1687800.0000, 
sim time next is 1688400.0000, 
raw observation next is [20.1, 66.0, 1.0, 2.0, 0.2235883478814071, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4206452798053212, 6.9112, 6.9112, 77.32846344354104, 488190.2820966902, 488190.2820966902, 156720.8947291248], 
processed observation next is [1.0, 0.5652173913043478, 0.55, 0.66, 1.0, 1.0, 0.02948543485175887, 0.0, 1.0, -0.25, 1.0, 1.0, 0.17235039972188743, 0.0, 0.0, 0.5084288129206541, 0.18081121559136673, 0.18081121559136673, 0.3822460847051824], 
reward next is 0.6178, 
noisyNet noise sample is [array([2.282515], dtype=float32), 1.2826893]. 
=============================================
[2019-03-23 18:17:22,051] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 18:17:22,053] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:17:22,054] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:17:22,054] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:17:22,055] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:17:22,055] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:17:22,056] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:17:22,058] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:17:22,058] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:17:22,059] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:17:22,060] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:17:22,079] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run37
[2019-03-23 18:17:22,105] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run37
[2019-03-23 18:17:22,106] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run37
[2019-03-23 18:17:22,106] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run37
[2019-03-23 18:17:22,106] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run37
[2019-03-23 18:17:56,452] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00876491], dtype=float32), 0.005166044]
[2019-03-23 18:17:56,453] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [27.750439, 45.266080335, 1.0, 2.0, 0.2016734706914242, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4021436190478873, 6.911200000000001, 6.9112, 95.55338769695034, 458519.3762367172, 458519.3762367169, 168161.7128191477]
[2019-03-23 18:17:56,454] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:17:56,457] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.2968077e-04 2.6040419e-09 9.9987030e-01 5.3154374e-09 2.6640784e-08], sampled 0.8935548704585696
[2019-03-23 18:18:02,006] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00876491], dtype=float32), 0.005166044]
[2019-03-23 18:18:02,008] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.1, 72.0, 1.0, 2.0, 0.3211799640722455, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6473489612142136, 6.9112, 6.9112, 95.55338769695034, 733012.447862924, 733012.447862924, 200175.9812759552]
[2019-03-23 18:18:02,010] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:18:02,012] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.4760431e-05 3.2405556e-10 9.9991524e-01 7.9161927e-10 5.7690119e-09], sampled 0.22915934100365465
[2019-03-23 18:18:22,192] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00876491], dtype=float32), 0.005166044]
[2019-03-23 18:18:22,192] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.5, 64.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 310042.0052219194, 310042.0052219197, 127923.445050741]
[2019-03-23 18:18:22,193] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:18:22,197] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.2172582e-04 5.1837549e-08 9.9977797e-01 9.4283749e-08 2.2696817e-07], sampled 0.3688775919002446
[2019-03-23 18:18:26,550] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00876491], dtype=float32), 0.005166044]
[2019-03-23 18:18:26,551] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.35, 49.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3773389645405848, 6.9112, 6.9112, 95.55338769695034, 433455.4446783407, 433455.4446783407, 162119.528058819]
[2019-03-23 18:18:26,552] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:18:26,554] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.9000906e-04 8.0655393e-09 9.9980992e-01 1.5825691e-08 6.5660011e-08], sampled 0.4640516983153826
[2019-03-23 18:18:47,365] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00876491], dtype=float32), 0.005166044]
[2019-03-23 18:18:47,366] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.2, 78.0, 1.0, 2.0, 0.518656618355687, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9479580906123298, 6.938772571894358, 6.9112, 77.32837764282812, 1139574.30777998, 1130619.31032145, 250977.9819735353]
[2019-03-23 18:18:47,367] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:18:47,370] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0083316e-04 1.8814510e-09 9.9989915e-01 4.2029256e-09 1.8721876e-08], sampled 0.8979986626950285
[2019-03-23 18:18:59,187] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2760.5002 2123966748.0823 758.0000
[2019-03-23 18:18:59,389] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3615.4978 2175140141.0870 245.0000
[2019-03-23 18:18:59,473] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3363.0138 2098010331.3474 179.0000
[2019-03-23 18:18:59,719] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3520.0775 2104007821.3646 179.0000
[2019-03-23 18:18:59,735] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3121.9238 2108873613.6356 368.0000
[2019-03-23 18:19:00,750] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 900000, evaluation results [900000.0, 3615.497761851025, 2175140141.086996, 245.0, 3363.013844454273, 2098010331.347409, 179.0, 3520.07747731918, 2104007821.364624, 179.0, 2760.5002265441562, 2123966748.0822995, 758.0, 3121.9238102794, 2108873613.6356437, 368.0]
[2019-03-23 18:19:01,033] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8777256e-04 2.5300142e-09 9.9981230e-01 5.9140576e-10 3.2721836e-09], sum to 1.0000
[2019-03-23 18:19:01,040] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6139
[2019-03-23 18:19:01,048] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.2062120996427421, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4098182658813402, 6.911199999999999, 6.9112, 77.32846344354104, 468074.2903677356, 468074.2903677359, 163515.8444039042], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1926000.0000, 
sim time next is 1926600.0000, 
raw observation next is [19.16666666666667, 99.00000000000001, 1.0, 2.0, 0.2215230351788111, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4405249501958623, 6.9112, 6.9112, 77.32846344354104, 503016.7546871224, 503016.7546871224, 166484.190300108], 
processed observation next is [1.0, 0.30434782608695654, 0.5075757575757578, 0.9900000000000001, 1.0, 1.0, 0.026903793973513876, 0.0, 1.0, -0.25, 1.0, 1.0, 0.20074992885123188, 0.0, 0.0, 0.5084288129206541, 0.18630250173597127, 0.18630250173597127, 0.4060590007319707], 
reward next is 0.5939, 
noisyNet noise sample is [array([-0.5238073], dtype=float32), 0.903648]. 
=============================================
[2019-03-23 18:19:08,867] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.5005280e-05 7.9182082e-06 9.9994469e-01 1.1299126e-05 1.1021052e-06], sum to 1.0000
[2019-03-23 18:19:08,872] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8084
[2019-03-23 18:19:08,878] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.66666666666667, 54.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 311711.7480839394, 311711.7480839391, 123227.4699030134], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2060400.0000, 
sim time next is 2061000.0000, 
raw observation next is [20.5, 54.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 309284.0800290594, 309284.0800290597, 121981.0286697054], 
processed observation next is [0.0, 0.8695652173913043, 0.5681818181818182, 0.545, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11454965927002199, 0.11454965927002211, 0.2975147040724522], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1412222], dtype=float32), 1.1875948]. 
=============================================
[2019-03-23 18:19:08,909] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[3.318491 ]
 [3.259524 ]
 [3.2618742]
 [3.3017504]
 [3.336091 ]], R is [[3.29548597]
 [3.26253104]
 [3.22990584]
 [3.1976068 ]
 [3.16563082]].
[2019-03-23 18:19:13,569] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0859896e-05 7.0970735e-08 9.9998891e-01 9.0286541e-08 1.2075638e-07], sum to 1.0000
[2019-03-23 18:19:13,576] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7886
[2019-03-23 18:19:13,582] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 69.0, 1.0, 2.0, 0.2034367912094927, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4040387836694263, 6.911200000000001, 6.9112, 77.32846344354104, 461607.2144405321, 461607.2144405318, 162876.2442551822], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2147400.0000, 
sim time next is 2148000.0000, 
raw observation next is [23.0, 69.0, 1.0, 2.0, 0.2038448384307461, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4048540004197702, 6.911199999999999, 6.9112, 77.32846344354104, 462536.5523329652, 462536.5523329655, 162950.258640539], 
processed observation next is [0.0, 0.8695652173913043, 0.6818181818181818, 0.69, 1.0, 1.0, 0.0048060480384326185, 0.0, 1.0, -0.25, 1.0, 1.0, 0.14979142917110033, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1713098341973945, 0.17130983419739462, 0.3974396552208268], 
reward next is 0.6026, 
noisyNet noise sample is [array([-1.2405576], dtype=float32), 0.25336713]. 
=============================================
[2019-03-23 18:19:13,600] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[17.204681]
 [17.025494]
 [16.767374]
 [16.594276]
 [16.495209]], R is [[17.85102463]
 [18.2752552 ]
 [18.69546127]
 [19.11162186]
 [19.52377319]].
[2019-03-23 18:19:14,459] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.1747643e-05 2.1404563e-05 9.9986076e-01 4.2502950e-05 3.6022127e-06], sum to 1.0000
[2019-03-23 18:19:14,467] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4340
[2019-03-23 18:19:14,471] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.16666666666667, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 339391.1640324417, 339391.164032442, 142786.7123513384], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2163000.0000, 
sim time next is 2163600.0000, 
raw observation next is [17.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 333158.7355356919, 333158.7355356916, 141573.4741097608], 
processed observation next is [1.0, 0.043478260869565216, 0.4090909090909091, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12339212427247848, 0.12339212427247838, 0.34530115636527026], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5548993], dtype=float32), -0.22315043]. 
=============================================
[2019-03-23 18:19:21,749] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.3343086e-05 1.2729475e-06 9.9989927e-01 5.2494743e-06 8.7094304e-07], sum to 1.0000
[2019-03-23 18:19:21,760] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6917
[2019-03-23 18:19:21,763] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.0, 51.0, 1.0, 2.0, 0.2565142935545048, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4788559899367404, 6.9112, 6.9112, 77.32846344354104, 557205.8184282902, 557205.8184282902, 145084.0127420404], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2302200.0000, 
sim time next is 2302800.0000, 
raw observation next is [20.0, 50.33333333333333, 1.0, 2.0, 0.2614420025689445, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4880549431238396, 6.911199999999999, 6.9112, 77.32846344354104, 567916.1463327453, 567916.1463327456, 145604.6622381987], 
processed observation next is [1.0, 0.6521739130434783, 0.5454545454545454, 0.5033333333333333, 1.0, 1.0, 0.07680250321118062, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2686499187483424, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21033931345657234, 0.21033931345657242, 0.355133322532192], 
reward next is 0.6449, 
noisyNet noise sample is [array([0.8776005], dtype=float32), 0.258587]. 
=============================================
[2019-03-23 18:19:29,148] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7901571e-04 8.7217921e-07 9.9981838e-01 4.5911068e-07 1.3127568e-06], sum to 1.0000
[2019-03-23 18:19:29,154] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3126
[2019-03-23 18:19:29,161] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 60.0, 1.0, 2.0, 0.3771499670702094, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7144753720495601, 6.9112, 6.9112, 77.32846344354104, 828274.0822120826, 828274.0822120826, 190972.0645821796], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2480400.0000, 
sim time next is 2481000.0000, 
raw observation next is [20.16666666666667, 65.66666666666667, 1.0, 2.0, 0.2268187398995329, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4281061036918385, 6.911199999999999, 6.9112, 77.32846344354104, 496517.8356629406, 496517.8356629409, 157719.2531574189], 
processed observation next is [1.0, 0.7391304347826086, 0.5530303030303032, 0.6566666666666667, 1.0, 1.0, 0.033523424874416126, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1830087195597693, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18389549468997798, 0.18389549468997812, 0.3846811052619973], 
reward next is 0.6153, 
noisyNet noise sample is [array([-0.02405405], dtype=float32), -1.0671706]. 
=============================================
[2019-03-23 18:19:29,182] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[22.022186]
 [22.276958]
 [22.53537 ]
 [22.928204]
 [23.301865]], R is [[21.51098824]
 [21.83009338]
 [22.14532661]
 [22.45002556]
 [22.7487011 ]].
[2019-03-23 18:19:29,949] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0747686e-05 1.9633131e-08 9.9998915e-01 2.6262313e-08 1.3445668e-07], sum to 1.0000
[2019-03-23 18:19:29,957] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5912
[2019-03-23 18:19:29,963] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [15.0, 94.0, 1.0, 2.0, 0.2454099805169307, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4581266701842521, 6.911199999999999, 6.9112, 77.32846344354104, 533071.5664496769, 533071.5664496771, 146702.0491079715], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2451600.0000, 
sim time next is 2452200.0000, 
raw observation next is [15.16666666666667, 92.00000000000001, 1.0, 2.0, 0.2370216905311762, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4424675704540009, 6.9112, 6.9112, 77.32846344354104, 514841.1471711223, 514841.1471711223, 144739.011468097], 
processed observation next is [1.0, 0.391304347826087, 0.3257575757575759, 0.9200000000000002, 1.0, 1.0, 0.04627711316397023, 0.0, 1.0, -0.25, 1.0, 1.0, 0.20352510064857277, 0.0, 0.0, 0.5084288129206541, 0.19068190635967494, 0.19068190635967494, 0.35302197919048045], 
reward next is 0.6470, 
noisyNet noise sample is [array([-0.44688988], dtype=float32), -0.56035364]. 
=============================================
[2019-03-23 18:19:31,043] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3897405e-04 3.0845987e-07 9.9985921e-01 4.0909447e-07 1.0237858e-06], sum to 1.0000
[2019-03-23 18:19:31,048] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4640
[2019-03-23 18:19:31,052] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [13.5, 97.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 247615.3975675348, 247615.3975675345, 100016.9910727658], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2493000.0000, 
sim time next is 2493600.0000, 
raw observation next is [13.33333333333333, 98.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 245422.0001441115, 245422.0001441113, 99335.14872425389], 
processed observation next is [1.0, 0.8695652173913043, 0.2424242424242423, 0.98, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09089703709041166, 0.0908970370904116, 0.2422808505469607], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2445694], dtype=float32), -0.23160087]. 
=============================================
[2019-03-23 18:19:37,591] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.13337075e-04 5.06406991e-07 9.99885440e-01 2.98649127e-07
 3.05589708e-07], sum to 1.0000
[2019-03-23 18:19:37,597] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3162
[2019-03-23 18:19:37,602] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.33333333333334, 42.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3273119422407407, 6.9112, 6.9112, 77.32846344354104, 377139.4371374561, 377139.4371374561, 150190.822005865], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2636400.0000, 
sim time next is 2637000.0000, 
raw observation next is [26.5, 42.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3307803045226531, 6.9112, 6.9112, 77.32846344354104, 380868.661886282, 380868.661886282, 150857.4033625135], 
processed observation next is [0.0, 0.5217391304347826, 0.8409090909090909, 0.42, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.04397186360379018, 0.0, 0.0, 0.5084288129206541, 0.14106246736528963, 0.14106246736528963, 0.3679448862500329], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7300011], dtype=float32), -0.5022196]. 
=============================================
[2019-03-23 18:19:37,617] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[20.822914]
 [20.93333 ]
 [21.336548]
 [21.885277]
 [22.565468]], R is [[20.41846848]
 [20.2142849 ]
 [20.01214218]
 [19.81202126]
 [19.61390114]].
[2019-03-23 18:19:39,383] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.3302055e-06 1.1516628e-05 9.9996257e-01 1.7770981e-05 1.7322562e-06], sum to 1.0000
[2019-03-23 18:19:39,389] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6923
[2019-03-23 18:19:39,395] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.66666666666667, 49.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3680700944374066, 6.9112, 6.9112, 77.32846344354104, 422320.3423818607, 422320.3423818607, 156777.3235345911], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2661000.0000, 
sim time next is 2661600.0000, 
raw observation next is [25.33333333333334, 50.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3644950229902878, 6.9112, 6.9112, 77.32846344354104, 418454.5129125963, 418454.5129125963, 156106.3263054318], 
processed observation next is [0.0, 0.8260869565217391, 0.7878787878787882, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.09213574712898259, 0.0, 0.0, 0.5084288129206541, 0.15498315293059123, 0.15498315293059123, 0.3807471373303215], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.4609983], dtype=float32), -1.479433]. 
=============================================
[2019-03-23 18:19:43,216] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.4585118e-04 9.5267190e-09 9.9955410e-01 8.5384899e-09 3.2456967e-08], sum to 1.0000
[2019-03-23 18:19:43,224] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0846
[2019-03-23 18:19:43,226] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 67.0, 1.0, 2.0, 0.2248209316955065, 0.0, 2.0, 0.0, 1.0, 2.0, 0.452859747752255, 6.9112, 6.9112, 77.32846344354104, 513027.8258410466, 513027.8258410466, 171035.1884183232], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2719800.0000, 
sim time next is 2720400.0000, 
raw observation next is [25.33333333333333, 66.33333333333333, 1.0, 2.0, 0.2282510825486954, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4603463655341466, 6.911200000000001, 6.9112, 77.32846344354104, 520895.4171675468, 520895.4171675465, 172277.1532923767], 
processed observation next is [0.0, 0.4782608695652174, 0.7878787878787876, 0.6633333333333333, 1.0, 1.0, 0.03531385318586922, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2290662364773523, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1929242285805729, 0.1929242285805728, 0.42018817876189435], 
reward next is 0.5798, 
noisyNet noise sample is [array([0.19646423], dtype=float32), 0.80341536]. 
=============================================
[2019-03-23 18:19:43,891] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.6114811e-05 2.9185857e-10 9.9992383e-01 4.6405935e-10 2.4659186e-09], sum to 1.0000
[2019-03-23 18:19:43,898] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0102
[2019-03-23 18:19:43,905] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.33333333333334, 67.83333333333333, 1.0, 2.0, 0.2409690870365633, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4868156040090862, 6.9112, 6.9112, 77.32846344354104, 549807.207085289, 549807.207085289, 175876.4585046668], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2728200.0000, 
sim time next is 2728800.0000, 
raw observation next is [25.0, 69.0, 1.0, 2.0, 0.2388314273515693, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4822018544716375, 6.9112, 6.9112, 77.32846344354104, 545004.6338019347, 545004.6338019347, 175069.5929408703], 
processed observation next is [0.0, 0.6086956521739131, 0.7727272727272727, 0.69, 1.0, 1.0, 0.048539284189461594, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2602883635309107, 0.0, 0.0, 0.5084288129206541, 0.2018535680747906, 0.2018535680747906, 0.4269990071728544], 
reward next is 0.5730, 
noisyNet noise sample is [array([-0.05476088], dtype=float32), -0.6721141]. 
=============================================
[2019-03-23 18:19:50,869] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 18:19:50,869] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:19:50,870] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:19:50,870] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:19:50,871] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:19:50,872] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:19:50,872] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:19:50,873] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:19:50,874] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:19:50,874] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:19:50,877] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:19:50,892] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run38
[2019-03-23 18:19:50,916] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run38
[2019-03-23 18:19:50,918] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run38
[2019-03-23 18:19:50,943] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run38
[2019-03-23 18:19:50,967] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run38
[2019-03-23 18:20:07,774] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00886836], dtype=float32), 0.005515578]
[2019-03-23 18:20:07,776] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [28.0, 60.0, 1.0, 2.0, 0.3371421026630793, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6829489190644784, 6.9112, 6.9112, 95.55338769695018, 766001.8567810551, 766001.8567810551, 210089.3681503979]
[2019-03-23 18:20:07,777] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:20:07,780] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.8392149e-05 1.3747370e-12 9.9998164e-01 3.9044996e-12 1.7092196e-10], sampled 0.9054921714269583
[2019-03-23 18:20:16,225] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00886836], dtype=float32), 0.005515578]
[2019-03-23 18:20:16,226] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.34140849333333, 50.29565176, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 348798.8288723352, 348798.8288723349, 123664.6417910195]
[2019-03-23 18:20:16,227] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:20:16,229] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.91301726e-05 1.04180005e-10 9.99950886e-01 2.41879489e-10
 3.80683973e-09], sampled 0.5304326619128072
[2019-03-23 18:20:28,226] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00886836], dtype=float32), 0.005515578]
[2019-03-23 18:20:28,227] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.1, 66.0, 1.0, 2.0, 0.2756252375316891, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5553511649238179, 6.9112, 6.9112, 95.55338769695034, 628975.5365058562, 628975.5365058562, 187536.538917431]
[2019-03-23 18:20:28,228] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:20:28,230] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.4392713e-05 5.7679539e-13 9.9998558e-01 1.6590341e-12 8.9194249e-11], sampled 0.3166825253632929
[2019-03-23 18:20:34,601] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00886836], dtype=float32), 0.005515578]
[2019-03-23 18:20:34,603] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.8, 59.66666666666667, 1.0, 2.0, 0.2676573281032942, 0.0, 2.0, 0.0, 1.0, 2.0, 0.54209171984369, 6.911200000000001, 6.9112, 95.55338769695034, 609006.811539236, 609006.8115392356, 189202.8139548661]
[2019-03-23 18:20:34,604] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:20:34,608] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.3541572e-05 5.0465372e-13 9.9997652e-01 1.6332797e-12 1.1134613e-10], sampled 0.33106070750039684
[2019-03-23 18:20:48,558] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00886836], dtype=float32), 0.005515578]
[2019-03-23 18:20:48,560] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.26666666666667, 71.83333333333334, 1.0, 2.0, 0.2148124692399432, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4296599764528705, 6.9112, 6.9112, 95.55338769695034, 489092.8981654029, 489092.8981654029, 171401.9668861283]
[2019-03-23 18:20:48,561] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:20:48,562] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.66047212e-05 6.78642526e-13 9.99983430e-01 1.96082777e-12
 1.07825644e-10], sampled 0.7981469531848074
[2019-03-23 18:21:14,756] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00886836], dtype=float32), 0.005515578]
[2019-03-23 18:21:14,757] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [28.0, 62.33333333333333, 1.0, 2.0, 0.361728306269592, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7324835315589426, 6.911200000000001, 6.9112, 95.55338769695034, 819261.6722790775, 819261.6722790771, 219612.8960904365]
[2019-03-23 18:21:14,759] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:21:14,762] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.7569151e-05 1.0249170e-12 9.9998248e-01 2.9666350e-12 1.3833089e-10], sampled 0.6715286715333494
[2019-03-23 18:21:26,840] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3119.6511 2108992648.7084 368.0000
[2019-03-23 18:21:26,922] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3362.1743 2098038232.9775 179.0000
[2019-03-23 18:21:26,976] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3519.8705 2104067451.3644 178.0000
[2019-03-23 18:21:27,106] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3614.1741 2175305489.0345 245.0000
[2019-03-23 18:21:27,381] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2760.0075 2124051796.3784 757.0000
[2019-03-23 18:21:28,400] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 925000, evaluation results [925000.0, 3614.1740929847015, 2175305489.034501, 245.0, 3362.17426541809, 2098038232.977526, 179.0, 3519.870480882709, 2104067451.364433, 178.0, 2760.0074851005825, 2124051796.3784225, 757.0, 3119.6510902387913, 2108992648.7083936, 368.0]
[2019-03-23 18:21:31,380] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.1281650e-03 1.2029043e-10 9.9787188e-01 2.8080842e-09 5.8049704e-08], sum to 1.0000
[2019-03-23 18:21:31,389] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0381
[2019-03-23 18:21:31,394] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.33333333333333, 81.66666666666667, 1.0, 2.0, 0.2629315334676871, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5325946545706611, 6.911199999999999, 6.9112, 77.32846344353989, 597846.4986794002, 597846.4986794004, 183629.4138625912], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2914800.0000, 
sim time next is 2915400.0000, 
raw observation next is [24.66666666666667, 79.83333333333333, 1.0, 2.0, 0.2669137377201067, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5406788220836272, 6.911200000000001, 6.9112, 77.32846344354104, 606677.4370725028, 606677.4370725024, 184794.249130505], 
processed observation next is [1.0, 0.7391304347826086, 0.7575757575757578, 0.7983333333333333, 1.0, 1.0, 0.08364217215013334, 0.0, 1.0, -0.25, 1.0, 1.0, 0.343826888690896, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22469534706388994, 0.2246953470638898, 0.45071768080610974], 
reward next is 0.5493, 
noisyNet noise sample is [array([-0.27683812], dtype=float32), 0.03455376]. 
=============================================
[2019-03-23 18:21:34,026] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.5169338e-04 5.8313310e-09 9.9984694e-01 1.7136980e-08 1.3535474e-06], sum to 1.0000
[2019-03-23 18:21:34,034] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8234
[2019-03-23 18:21:34,037] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.2791578679321905, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5648063059197387, 6.911199999999999, 6.9112, 77.32846344354104, 636459.9543307901, 636459.9543307903, 186172.0690144549], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2956200.0000, 
sim time next is 2956800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.271934500565255, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5501965806886682, 6.9112, 6.9112, 77.32846344354104, 619975.2814002162, 619975.2814002162, 184317.7798489245], 
processed observation next is [1.0, 0.21739130434782608, 0.6363636363636364, 0.94, 1.0, 1.0, 0.08991812570656871, 0.0, 1.0, -0.25, 1.0, 1.0, 0.35742368669809743, 0.0, 0.0, 0.5084288129206541, 0.22962047459267265, 0.22962047459267265, 0.4495555606071329], 
reward next is 0.5504, 
noisyNet noise sample is [array([1.1929148], dtype=float32), 1.2000598]. 
=============================================
[2019-03-23 18:21:34,574] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.0131835e-04 2.5285662e-09 9.9979872e-01 1.2323184e-08 5.6915567e-08], sum to 1.0000
[2019-03-23 18:21:34,582] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8831
[2019-03-23 18:21:34,586] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.16666666666667, 93.16666666666667, 1.0, 2.0, 0.2768394078373441, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5601832091435462, 6.911200000000001, 6.9112, 77.32846344354104, 631092.9688285132, 631092.9688285129, 185679.4324107832], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2959800.0000, 
sim time next is 2960400.0000, 
raw observation next is [22.33333333333334, 92.33333333333334, 1.0, 2.0, 0.2748029851099444, 0.0, 2.0, 0.0, 1.0, 2.0, 0.556171063700498, 6.9112, 6.9112, 77.32846344354104, 626303.7593730375, 626303.7593730375, 185342.0856788351], 
processed observation next is [1.0, 0.2608695652173913, 0.6515151515151518, 0.9233333333333335, 1.0, 1.0, 0.09350373138743047, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3659586624292828, 0.0, 0.0, 0.5084288129206541, 0.23196435532334722, 0.23196435532334722, 0.45205386750935395], 
reward next is 0.5479, 
noisyNet noise sample is [array([0.1919084], dtype=float32), 0.8845345]. 
=============================================
[2019-03-23 18:21:35,066] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.0612139e-05 1.6619776e-08 9.9997854e-01 6.2734586e-08 7.1860597e-07], sum to 1.0000
[2019-03-23 18:21:35,073] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5426
[2019-03-23 18:21:35,079] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.9216875922508518, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9771127889312362, 6.9112, 6.9112, 77.32846344255778, 1596212.26734892, 1596212.26734892, 329178.786576597], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2988000.0000, 
sim time next is 2988600.0000, 
raw observation next is [28.0, 57.5, 1.0, 2.0, 0.686070568928821, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9763851469217812, 6.9112, 6.9112, 77.32846344353496, 1328593.86039933, 1328593.86039933, 289159.0752898035], 
processed observation next is [1.0, 0.6086956521739131, 0.9090909090909091, 0.575, 1.0, 1.0, 0.6075882111610262, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9662644956025447, 0.0, 0.0, 0.5084288129206141, 0.49207180014790003, 0.49207180014790003, 0.7052660372922036], 
reward next is 0.2947, 
noisyNet noise sample is [array([0.25727507], dtype=float32), -0.25358853]. 
=============================================
[2019-03-23 18:21:38,499] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.6891141e-05 2.0542538e-07 9.9992168e-01 6.5207701e-07 6.5228721e-07], sum to 1.0000
[2019-03-23 18:21:38,507] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5608
[2019-03-23 18:21:38,510] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.2372596334657601, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4794745419921578, 6.9112, 6.9112, 77.32846344354104, 541279.4947560871, 541279.4947560871, 175237.7385108234], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3477000.0000, 
sim time next is 3477600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.2376066283897671, 0.0, 2.0, 0.0, 1.0, 2.0, 0.480176142184389, 6.9112, 6.9112, 77.32846344354104, 542071.4042292545, 542071.4042292545, 175314.853785874], 
processed observation next is [1.0, 0.2608695652173913, 0.5909090909090909, 1.0, 1.0, 1.0, 0.047008285487208853, 0.0, 1.0, -0.25, 1.0, 1.0, 0.25739448883484145, 0.0, 0.0, 0.5084288129206541, 0.20076718675157573, 0.20076718675157573, 0.42759720435579024], 
reward next is 0.5724, 
noisyNet noise sample is [array([-0.08700071], dtype=float32), 0.6904026]. 
=============================================
[2019-03-23 18:21:38,845] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9521457e-03 6.6966273e-08 9.9804556e-01 1.0354742e-07 2.1661151e-06], sum to 1.0000
[2019-03-23 18:21:38,850] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2077
[2019-03-23 18:21:38,855] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 74.0, 1.0, 2.0, 0.6699049076064636, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9751107925714155, 6.9112, 6.9112, 77.32846344334472, 1311040.418566331, 1311040.418566331, 285552.7851053127], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3076200.0000, 
sim time next is 3076800.0000, 
raw observation next is [25.33333333333333, 74.0, 1.0, 2.0, 0.6144542380403516, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9768302615660567, 6.911199999999999, 6.9112, 77.32846344353983, 1246744.071962421, 1246744.071962421, 279334.8863390364], 
processed observation next is [1.0, 0.6086956521739131, 0.7878787878787876, 0.74, 1.0, 1.0, 0.5180677975504394, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9669003736657953, -8.881784197001253e-17, 0.0, 0.5084288129206461, 0.4617570636897856, 0.4617570636897856, 0.681304600826918], 
reward next is 0.3187, 
noisyNet noise sample is [array([-0.4136365], dtype=float32), 0.68832743]. 
=============================================
[2019-03-23 18:21:40,888] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.5859392e-03 1.1458080e-08 9.9141395e-01 2.7179309e-10 1.0459963e-07], sum to 1.0000
[2019-03-23 18:21:40,895] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2679
[2019-03-23 18:21:40,901] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.0, 88.0, 1.0, 2.0, 0.2781927004596404, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5633841507773516, 6.9112, 6.9112, 77.32846344354104, 630357.5680061538, 630357.5680061538, 188811.5186784493], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3099000.0000, 
sim time next is 3099600.0000, 
raw observation next is [24.0, 89.0, 1.0, 2.0, 0.2808595689842137, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5686557149873048, 6.9112, 6.9112, 77.32846344354104, 635732.4083037318, 635732.4083037318, 189823.9364570701], 
processed observation next is [1.0, 0.9130434782608695, 0.7272727272727273, 0.89, 1.0, 1.0, 0.10107446123026713, 0.0, 1.0, -0.25, 1.0, 1.0, 0.38379387855329267, 0.0, 0.0, 0.5084288129206541, 0.23545644751990066, 0.23545644751990066, 0.46298521087090266], 
reward next is 0.5370, 
noisyNet noise sample is [array([0.27354255], dtype=float32), 0.8633388]. 
=============================================
[2019-03-23 18:21:45,805] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2168805e-03 7.6788538e-08 9.9877745e-01 3.6182527e-07 5.2523283e-06], sum to 1.0000
[2019-03-23 18:21:45,815] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8136
[2019-03-23 18:21:45,818] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.2211257656885414, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4423919636611577, 6.9112, 6.9112, 77.32846344354104, 503573.1896423055, 503573.1896423055, 168017.1339969151], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3186000.0000, 
sim time next is 3186600.0000, 
raw observation next is [21.0, 88.00000000000001, 1.0, 2.0, 0.2207051471740079, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4414875712937803, 6.9112, 6.9112, 77.32846344354104, 502584.6499824583, 502584.6499824583, 167894.1351680256], 
processed observation next is [1.0, 0.9130434782608695, 0.5909090909090909, 0.8800000000000001, 1.0, 1.0, 0.025881433967509873, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2021251018482576, 0.0, 0.0, 0.5084288129206541, 0.18614246295646603, 0.18614246295646603, 0.40949789065372094], 
reward next is 0.5905, 
noisyNet noise sample is [array([1.0573362], dtype=float32), -1.8259413]. 
=============================================
[2019-03-23 18:21:46,040] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.8030587e-06 1.9882904e-07 9.9999523e-01 8.0422774e-07 4.8427509e-08], sum to 1.0000
[2019-03-23 18:21:46,048] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3225
[2019-03-23 18:21:46,053] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3821812419014669, 6.911200000000001, 6.9112, 77.32846344354104, 438172.9190402292, 438172.9190402289, 158907.3915036487], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3207600.0000, 
sim time next is 3208200.0000, 
raw observation next is [18.83333333333334, 94.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3781591931275181, 6.911199999999999, 6.9112, 77.32846344354104, 433855.7167689805, 433855.7167689808, 158118.6517135729], 
processed observation next is [0.0, 0.13043478260869565, 0.4924242424242427, 0.9400000000000002, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.11165599018216875, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1606873025070298, 0.16068730250702992, 0.3856552480818851], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7270417], dtype=float32), 2.1557498]. 
=============================================
[2019-03-23 18:21:47,672] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.07759202e-04 5.97118124e-05 9.99582469e-01 2.37207860e-04
 1.28211095e-05], sum to 1.0000
[2019-03-23 18:21:47,681] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1511
[2019-03-23 18:21:47,684] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.05, 49.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3163382852985427, 6.9112, 6.9112, 77.32846344354104, 365696.833678356, 365696.833678356, 147714.6034037324], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3249000.0000, 
sim time next is 3249600.0000, 
raw observation next is [24.03333333333333, 49.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3180089252673782, 6.9112, 6.9112, 77.32846344354104, 367547.8639483955, 367547.8639483955, 147985.1928345171], 
processed observation next is [0.0, 0.6086956521739131, 0.7287878787878787, 0.4933333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.02572703609625455, 0.0, 0.0, 0.5084288129206541, 0.13612883849940574, 0.13612883849940574, 0.3609394947183344], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.170552], dtype=float32), -1.0206442]. 
=============================================
[2019-03-23 18:21:51,302] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.05858581e-05 4.65174962e-05 9.99746501e-01 1.16820236e-04
 9.51625316e-06], sum to 1.0000
[2019-03-23 18:21:51,310] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5849
[2019-03-23 18:21:51,313] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.0, 82.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 273506.4006284022, 273506.4006284019, 109634.6682374275], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3290400.0000, 
sim time next is 3291000.0000, 
raw observation next is [16.0, 82.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 270679.732103062, 270679.732103062, 109066.4362443932], 
processed observation next is [0.0, 0.08695652173913043, 0.36363636363636365, 0.8200000000000002, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.10025175263076369, 0.10025175263076369, 0.2660156981570566], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.3057323], dtype=float32), 0.61915123]. 
=============================================
[2019-03-23 18:21:51,333] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[-0.8186618 ]
 [-0.78374434]
 [-0.7743832 ]
 [-0.7267402 ]
 [-0.77385086]], R is [[-0.94074112]
 [-0.93133372]
 [-0.92202038]
 [-0.91280019]
 [-0.90367222]].
[2019-03-23 18:22:00,308] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.2317274e-04 6.4053818e-11 9.9987674e-01 2.3880681e-10 7.0729818e-08], sum to 1.0000
[2019-03-23 18:22:00,315] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5051
[2019-03-23 18:22:00,321] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.2513879656638625, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5085918120082427, 6.911199999999999, 6.9112, 77.32846344354104, 573140.0239018808, 573140.0239018812, 179225.6113300999], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3456600.0000, 
sim time next is 3457200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.2512606228358441, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5083317643927154, 6.911200000000001, 6.9112, 77.32846344354104, 572852.019945291, 572852.0199452908, 179191.755720782], 
processed observation next is [1.0, 0.0, 0.6363636363636364, 0.94, 1.0, 1.0, 0.06407577854480512, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2976168062753078, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21216741479455223, 0.21216741479455214, 0.43705306273361466], 
reward next is 0.5629, 
noisyNet noise sample is [array([-0.47912115], dtype=float32), 0.6266183]. 
=============================================
[2019-03-23 18:22:03,344] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.4588747e-04 4.6173659e-07 9.9975103e-01 6.9761052e-07 1.9250149e-06], sum to 1.0000
[2019-03-23 18:22:03,351] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2157
[2019-03-23 18:22:03,358] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 2 has been changed to 3 for the demand 1749772.794397405 W.
[2019-03-23 18:22:03,364] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 62.0, 1.0, 2.0, 0.5494647918880824, 1.0, 2.0, 0.5185208328856484, 1.0, 1.0, 0.9865530188920543, 6.911199999999999, 6.9112, 77.3421103, 1749772.794397405, 1749772.794397405, 364762.4708970584], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3513600.0000, 
sim time next is 3514200.0000, 
raw observation next is [28.93333333333333, 61.66666666666667, 1.0, 2.0, 0.75101958994842, 1.0, 2.0, 0.75101958994842, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1689477.741440119, 1689477.741440119, 308293.5636406709], 
processed observation next is [1.0, 0.6956521739130435, 0.9515151515151513, 0.6166666666666667, 1.0, 1.0, 0.688774487435525, 1.0, 1.0, 0.688774487435525, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.6257324968296737, 0.6257324968296737, 0.7519355210748071], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.03947637], dtype=float32), -2.0321126]. 
=============================================
[2019-03-23 18:22:05,050] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.5937886e-05 9.6221581e-12 9.9996412e-01 3.5212258e-10 3.6751409e-09], sum to 1.0000
[2019-03-23 18:22:05,058] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3118
[2019-03-23 18:22:05,061] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.83333333333334, 95.0, 1.0, 2.0, 0.296483406650536, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5998350459094443, 6.911199999999999, 6.9112, 77.32846344354104, 676015.285812264, 676015.2858122643, 190792.726931254], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3557400.0000, 
sim time next is 3558000.0000, 
raw observation next is [21.66666666666667, 96.0, 1.0, 2.0, 0.2695695978423077, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5452931235528388, 6.9112, 6.9112, 77.32846344354104, 614698.9583404833, 614698.9583404833, 183534.9249812522], 
processed observation next is [1.0, 0.17391304347826086, 0.6212121212121214, 0.96, 1.0, 1.0, 0.08696199730288463, 0.0, 1.0, -0.25, 1.0, 1.0, 0.35041874793262684, 0.0, 0.0, 0.5084288129206541, 0.22766628086684565, 0.22766628086684565, 0.44764615849085904], 
reward next is 0.5524, 
noisyNet noise sample is [array([-2.001705], dtype=float32), 0.16697283]. 
=============================================
[2019-03-23 18:22:05,078] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[50.013813]
 [49.77748 ]
 [49.8585  ]
 [49.313263]
 [49.256615]], R is [[50.15979004]
 [50.19284439]
 [50.24036407]
 [50.2859993 ]
 [50.3296814 ]].
[2019-03-23 18:22:11,118] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.6206787e-03 2.4956114e-07 9.9234080e-01 2.3975319e-06 3.5988149e-05], sum to 1.0000
[2019-03-23 18:22:11,124] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4931
[2019-03-23 18:22:11,133] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.5, 78.0, 1.0, 2.0, 0.5595002192679474, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9742021744012856, 6.914357147586765, 6.9112, 77.32845554349933, 1184691.690650693, 1183666.313794102, 270484.908017304], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3670200.0000, 
sim time next is 3670800.0000, 
raw observation next is [24.33333333333334, 78.0, 1.0, 2.0, 0.5078547344431821, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9549612839810141, 6.945913167784269, 6.9112, 77.32837638843532, 1126379.497411176, 1115105.383214138, 259733.0934486008], 
processed observation next is [1.0, 0.4782608695652174, 0.7424242424242427, 0.78, 1.0, 1.0, 0.38481841805397754, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9356589771157345, 0.003471316778426914, 0.0, 0.5084282405399021, 0.41717759163376894, 0.41300199378301405, 0.6334953498746361], 
reward next is 0.1929, 
noisyNet noise sample is [array([0.6153797], dtype=float32), -0.28818583]. 
=============================================
[2019-03-23 18:22:14,064] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.1028019e-04 5.9103403e-11 9.9968958e-01 4.6797695e-09 1.5629408e-07], sum to 1.0000
[2019-03-23 18:22:14,072] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6806
[2019-03-23 18:22:14,079] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.2660304520087329, 0.0, 2.0, 0.0, 1.0, 2.0, 0.53881830177786, 6.911199999999999, 6.9112, 77.32846344354104, 605270.2555259702, 605270.2555259705, 184127.7535021542], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3708600.0000, 
sim time next is 3709200.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.2674446656592109, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5416846808153676, 6.911199999999999, 6.9112, 77.32846344354104, 608479.130761882, 608479.1307618824, 184494.6422710914], 
processed observation next is [1.0, 0.9565217391304348, 0.7272727272727273, 0.83, 1.0, 1.0, 0.08430583207401358, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3452638297362394, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22536264102291928, 0.22536264102291942, 0.4499869323685156], 
reward next is 0.5500, 
noisyNet noise sample is [array([0.6622228], dtype=float32), -0.8266977]. 
=============================================
[2019-03-23 18:22:15,063] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.9817435e-04 2.0504642e-08 9.9939859e-01 2.8718182e-07 2.8471704e-06], sum to 1.0000
[2019-03-23 18:22:15,069] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1734
[2019-03-23 18:22:15,081] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.33333333333333, 78.0, 1.0, 2.0, 0.2442447785123824, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4886909370381277, 6.911199999999999, 6.9112, 77.32846344354104, 556274.6391539354, 556274.6391539356, 172786.9611389284], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3739200.0000, 
sim time next is 3739800.0000, 
raw observation next is [22.66666666666667, 75.5, 1.0, 2.0, 0.2451938043630018, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4904859858477197, 6.911199999999999, 6.9112, 77.32846344354104, 558387.7113814827, 558387.711381483, 172925.4577598219], 
processed observation next is [1.0, 0.2608695652173913, 0.6666666666666669, 0.755, 1.0, 1.0, 0.05649225545375225, 0.0, 1.0, -0.25, 1.0, 1.0, 0.27212283692531386, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2068102634746232, 0.20681026347462333, 0.4217694091702973], 
reward next is 0.5782, 
noisyNet noise sample is [array([-0.00221082], dtype=float32), 0.3832708]. 
=============================================
[2019-03-23 18:22:18,583] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 18:22:18,585] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:22:18,586] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:22:18,586] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:22:18,587] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:22:18,587] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:22:18,588] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:22:18,588] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:22:18,589] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:22:18,593] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:22:18,594] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:22:18,609] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run39
[2019-03-23 18:22:18,632] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run39
[2019-03-23 18:22:18,633] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run39
[2019-03-23 18:22:18,655] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run39
[2019-03-23 18:22:18,706] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run39
[2019-03-23 18:22:39,849] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00940583], dtype=float32), 0.005426947]
[2019-03-23 18:22:39,850] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.5, 84.0, 1.0, 2.0, 0.2988789705890734, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6040374787344466, 6.9112, 6.9112, 77.32846344354104, 671715.9862289042, 671715.9862289042, 196584.1053748223]
[2019-03-23 18:22:39,853] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:22:39,855] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.7309690e-04 1.4979925e-08 9.9972624e-01 1.6594387e-07 3.2805414e-07], sampled 0.9551304757031169
[2019-03-23 18:22:57,339] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00940583], dtype=float32), 0.005426947]
[2019-03-23 18:22:57,343] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.61666666666667, 70.66666666666667, 1.0, 2.0, 0.4362366048891443, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8508716004921814, 6.954526790173384, 6.9112, 95.55320769614302, 995451.7559547158, 978063.6980776886, 238076.5908734002]
[2019-03-23 18:22:57,343] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:22:57,347] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.9836756e-04 3.6975352e-09 9.9900144e-01 5.3401159e-08 2.7833508e-07], sampled 0.4737184775164377
[2019-03-23 18:23:27,083] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00940583], dtype=float32), 0.005426947]
[2019-03-23 18:23:27,083] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.66811241333333, 44.74994124166667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 304629.6389852855, 304629.6389852851, 129333.966926359]
[2019-03-23 18:23:27,086] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:23:27,088] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.4952575e-04 1.3154614e-04 9.9931419e-01 3.7223296e-04 3.2491716e-05], sampled 0.05629303525462537
[2019-03-23 18:23:33,572] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00940583], dtype=float32), 0.005426947]
[2019-03-23 18:23:33,574] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.2, 79.0, 1.0, 2.0, 0.2122262753177362, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4244820617748635, 6.9112, 6.9112, 95.55338769695034, 483199.716455002, 483199.716455002, 170904.9705116183]
[2019-03-23 18:23:33,579] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:23:33,583] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.1891418e-06 1.9287022e-06 9.9998152e-01 9.0748063e-06 4.1109152e-07], sampled 0.37100542292422856
[2019-03-23 18:23:55,704] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3362.4909 2097888082.8367 179.0000
[2019-03-23 18:23:55,842] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3119.2507 2108925600.9407 368.0000
[2019-03-23 18:23:56,092] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3519.8494 2104073705.4323 178.0000
[2019-03-23 18:23:56,131] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2760.7019 2123814270.7588 757.0000
[2019-03-23 18:23:56,190] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3614.2490 2175202402.6237 245.0000
[2019-03-23 18:23:57,204] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 950000, evaluation results [950000.0, 3614.248973168282, 2175202402.62372, 245.0, 3362.49092788643, 2097888082.8366778, 179.0, 3519.8494203192986, 2104073705.4322646, 178.0, 2760.7018793212874, 2123814270.7588298, 757.0, 3119.250668267257, 2108925600.940732, 368.0]
[2019-03-23 18:24:00,710] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3134770e-04 1.3253375e-04 9.9912256e-01 5.9809780e-04 1.5479205e-05], sum to 1.0000
[2019-03-23 18:24:00,719] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3311
[2019-03-23 18:24:00,724] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 57.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3007040410415281, 6.911200000000001, 6.9112, 77.32846344354104, 348491.7363997346, 348491.7363997343, 145059.6723516256], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3867000.0000, 
sim time next is 3867600.0000, 
raw observation next is [22.0, 57.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 345618.838383784, 345618.838383784, 144646.0855776471], 
processed observation next is [0.0, 0.782608695652174, 0.6363636363636364, 0.5700000000000001, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.12800697717917925, 0.12800697717917925, 0.3527953306771881], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0016922], dtype=float32), -1.1773071]. 
=============================================
[2019-03-23 18:24:03,696] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.3640043e-06 9.6719186e-06 9.9995410e-01 2.6713915e-05 1.1765169e-06], sum to 1.0000
[2019-03-23 18:24:03,699] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6293
[2019-03-23 18:24:03,703] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.0, 73.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 343198.380668094, 343198.3806680943, 144960.8688568508], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3916800.0000, 
sim time next is 3917400.0000, 
raw observation next is [20.33333333333334, 72.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.304848006024024, 6.911199999999999, 6.9112, 77.32846344354104, 352271.2083186514, 352271.2083186517, 146566.8183526173], 
processed observation next is [0.0, 0.34782608695652173, 0.5606060606060609, 0.7233333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0069257228914628875, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13047081789579681, 0.13047081789579693, 0.3574800447624812], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.22731341], dtype=float32), 0.115087785]. 
=============================================
[2019-03-23 18:24:13,889] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.9754849e-04 1.6645591e-07 9.9950075e-01 4.1207898e-07 1.0383660e-06], sum to 1.0000
[2019-03-23 18:24:13,896] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7421
[2019-03-23 18:24:13,900] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.83333333333333, 95.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.334190937564681, 6.9112, 6.9112, 77.32846344354104, 385393.9177845401, 385393.9177845401, 150690.4941547703], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4089000.0000, 
sim time next is 4089600.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3447144555476013, 6.911199999999999, 6.9112, 77.32846344354104, 397403.689210005, 397403.6892100053, 152068.5153265684], 
processed observation next is [1.0, 0.34782608695652173, 0.45454545454545453, 0.94, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.06387779363943041, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1471865515592611, 0.14718655155926122, 0.370898817869679], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.22386883], dtype=float32), 0.69955033]. 
=============================================
[2019-03-23 18:24:20,778] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.70265828e-03 1.84300109e-06 9.90272105e-01 1.01724345e-05
 1.32363930e-05], sum to 1.0000
[2019-03-23 18:24:20,785] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6323
[2019-03-23 18:24:20,788] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.33333333333334, 93.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3184539561774738, 6.9112, 6.9112, 77.32846344354104, 368459.9452427315, 368459.9452427315, 147634.2802537358], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4236600.0000, 
sim time next is 4237200.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3108487771477065, 6.9112, 6.9112, 77.32846344354104, 360074.726781866, 360074.726781866, 146352.5395942637], 
processed observation next is [1.0, 0.043478260869565216, 0.4090909090909091, 0.94, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.01549825306815213, 0.0, 0.0, 0.5084288129206541, 0.13336100991920963, 0.13336100991920963, 0.35695741364454564], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7472519], dtype=float32), -0.78867924]. 
=============================================
[2019-03-23 18:24:26,776] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3164515e-03 9.5327732e-07 9.9867284e-01 4.4917456e-06 5.2238802e-06], sum to 1.0000
[2019-03-23 18:24:26,786] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5127
[2019-03-23 18:24:26,792] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.2043218516027471, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4060158300522726, 6.9112, 6.9112, 77.32846344354104, 463753.2567464196, 463753.2567464196, 163155.9387398841], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4777800.0000, 
sim time next is 4778400.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.215383609483961, 0.0, 2.0, 0.0, 1.0, 2.0, 0.428057381861995, 6.9112, 6.9112, 77.32846344354104, 488910.2927334014, 488910.2927334014, 165183.652565562], 
processed observation next is [1.0, 0.30434782608695654, 0.5, 1.0, 1.0, 1.0, 0.019229511854951253, 0.0, 1.0, -0.25, 1.0, 1.0, 0.18293911694570716, 0.0, 0.0, 0.5084288129206541, 0.18107788619755608, 0.18107788619755608, 0.40288695747698045], 
reward next is 0.5971, 
noisyNet noise sample is [array([-0.49590415], dtype=float32), -1.0924952]. 
=============================================
[2019-03-23 18:24:33,284] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.0533876e-02 1.1815124e-10 9.4946545e-01 2.2099909e-08 6.9717953e-07], sum to 1.0000
[2019-03-23 18:24:33,293] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3756
[2019-03-23 18:24:33,298] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.0, 94.0, 1.0, 2.0, 0.2158494098187801, 0.0, 2.0, 0.0, 1.0, 2.0, 0.430783508463935, 6.9112, 6.9112, 77.32846344354104, 491014.4479761011, 491014.4479761011, 166328.8639607215], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4500000.0000, 
sim time next is 4500600.0000, 
raw observation next is [20.0, 94.00000000000001, 1.0, 2.0, 0.2139505349100333, 0.0, 2.0, 0.0, 1.0, 2.0, 0.426796282085855, 6.911199999999999, 6.9112, 77.32846344354104, 486585.0945567675, 486585.0945567678, 165850.9532787019], 
processed observation next is [0.0, 0.08695652173913043, 0.5454545454545454, 0.9400000000000002, 1.0, 1.0, 0.017438168637541607, 0.0, 1.0, -0.25, 1.0, 1.0, 0.18113754583693575, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18021670168769166, 0.18021670168769177, 0.40451452019195583], 
reward next is 0.5955, 
noisyNet noise sample is [array([-0.69980454], dtype=float32), -0.8796608]. 
=============================================
[2019-03-23 18:24:37,831] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.2483795e-05 6.5877262e-05 9.9963558e-01 1.7001681e-04 3.5970163e-05], sum to 1.0000
[2019-03-23 18:24:37,838] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2627
[2019-03-23 18:24:37,842] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.4, 69.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.314676794730049, 6.9112, 6.9112, 77.32846344354104, 364083.2896237489, 364083.2896237489, 147214.5636102961], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4564800.0000, 
sim time next is 4565400.0000, 
raw observation next is [20.16666666666667, 69.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3102646348025231, 6.9112, 6.9112, 77.32846344354104, 359215.3535285083, 359215.3535285083, 146476.4733777015], 
processed observation next is [0.0, 0.8695652173913043, 0.5530303030303032, 0.6966666666666668, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.014663764003604427, 0.0, 0.0, 0.5084288129206541, 0.13304272352907714, 0.13304272352907714, 0.3572596911651256], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4056686], dtype=float32), -0.41018173]. 
=============================================
[2019-03-23 18:24:41,239] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.8176683e-03 1.2503838e-07 9.9717605e-01 1.5049241e-06 4.6260416e-06], sum to 1.0000
[2019-03-23 18:24:41,243] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.0432653e-03 9.2853639e-08 9.9695325e-01 1.1105032e-07 3.2412893e-06], sum to 1.0000
[2019-03-23 18:24:41,246] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2451
[2019-03-23 18:24:41,251] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.33333333333334, 56.0, 1.0, 2.0, 0.3300591712132074, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6418255022122302, 6.9112, 6.9112, 77.32846344354104, 739077.2087375271, 739077.2087375271, 185298.8328827229], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4707600.0000, 
sim time next is 4708200.0000, 
raw observation next is [23.66666666666666, 55.0, 1.0, 2.0, 0.3273107863781836, 0.0, 2.0, 0.0, 1.0, 2.0, 0.637797536164804, 6.9112, 6.9112, 77.32846344354104, 733978.0266050177, 733978.0266050177, 185140.1919921304], 
processed observation next is [1.0, 0.4782608695652174, 0.7121212121212118, 0.55, 1.0, 1.0, 0.1591384829727295, 0.0, 1.0, -0.25, 1.0, 1.0, 0.48256790880686284, 0.0, 0.0, 0.5084288129206541, 0.271843713557414, 0.271843713557414, 0.4515614438832449], 
reward next is 0.5484, 
noisyNet noise sample is [array([0.55041283], dtype=float32), -0.23039517]. 
=============================================
[2019-03-23 18:24:41,262] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6963
[2019-03-23 18:24:41,268] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 47.0, 1.0, 2.0, 0.3460233455941244, 0.0, 2.0, 0.0, 1.0, 2.0, 0.651294412476396, 6.9112, 6.9112, 77.32846344354104, 756010.3821761305, 756010.3821761305, 181420.289098058], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4633200.0000, 
sim time next is 4633800.0000, 
raw observation next is [23.16666666666667, 47.00000000000001, 1.0, 2.0, 0.3341796647405706, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6297395227555816, 6.9112, 6.9112, 77.32846344354104, 730793.0205138329, 730793.0205138329, 178836.2570859114], 
processed observation next is [1.0, 0.6521739130434783, 0.6893939393939396, 0.4700000000000001, 1.0, 1.0, 0.1677245809257132, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4710564610794024, 0.0, 0.0, 0.5084288129206541, 0.27066408167178996, 0.27066408167178996, 0.43618599289246685], 
reward next is 0.5638, 
noisyNet noise sample is [array([2.735515], dtype=float32), 1.972757]. 
=============================================
[2019-03-23 18:24:47,211] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 18:24:47,214] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:24:47,215] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:24:47,215] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:24:47,216] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:24:47,216] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:24:47,217] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:24:47,217] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:24:47,218] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:24:47,219] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:24:47,219] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:24:47,241] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run40
[2019-03-23 18:24:47,264] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run40
[2019-03-23 18:24:47,265] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run40
[2019-03-23 18:24:47,266] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run40
[2019-03-23 18:24:47,336] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run40
[2019-03-23 18:24:49,200] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0093743], dtype=float32), 0.005734236]
[2019-03-23 18:24:49,201] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.214726135, 74.338236025, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3730592336652647, 6.9112, 6.9112, 95.55338769695034, 429664.367427645, 429664.367427645, 160537.6474831721]
[2019-03-23 18:24:49,201] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:24:49,206] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.5348374e-04 2.4506139e-10 9.9914634e-01 4.2524291e-09 8.1640096e-08], sampled 0.08782359008964535
[2019-03-23 18:24:57,714] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0093743], dtype=float32), 0.005734236]
[2019-03-23 18:24:57,716] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.13333333333333, 70.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 269105.6394071156, 269105.6394071156, 105140.053926288]
[2019-03-23 18:24:57,718] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:24:57,723] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.1142916e-03 5.0539743e-08 9.9888366e-01 4.1101237e-07 1.6020842e-06], sampled 0.2142772417130654
[2019-03-23 18:25:10,748] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0093743], dtype=float32), 0.005734236]
[2019-03-23 18:25:10,749] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.26666666666667, 73.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 263154.510603787, 263154.510603787, 113575.2564370699]
[2019-03-23 18:25:10,752] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:25:10,753] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.5717521e-04 2.3724548e-08 9.9914157e-01 2.1327936e-07 9.0108108e-07], sampled 0.5490804432258225
[2019-03-23 18:25:45,300] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0093743], dtype=float32), 0.005734236]
[2019-03-23 18:25:45,300] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.21666666666667, 85.33333333333334, 1.0, 2.0, 0.2613789365501104, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5091913465076386, 6.9112, 6.9112, 95.55338769695034, 585867.541642144, 585867.541642144, 174550.8887902438]
[2019-03-23 18:25:45,302] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:25:45,304] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.5716166e-04 5.8905443e-11 9.9954283e-01 1.1712563e-09 2.5038123e-08], sampled 0.3797320029010637
[2019-03-23 18:25:53,387] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0093743], dtype=float32), 0.005734236]
[2019-03-23 18:25:53,389] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.25926654, 75.35069927, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3037119882460619, 6.911199999999999, 6.9112, 95.55338769695034, 353173.882136117, 353173.8821361173, 147038.2338801648]
[2019-03-23 18:25:53,391] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:25:53,395] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.1414659e-03 3.6847698e-09 9.9885821e-01 4.3814950e-08 3.9038886e-07], sampled 0.28152951753828137
[2019-03-23 18:25:56,005] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0093743], dtype=float32), 0.005734236]
[2019-03-23 18:25:56,006] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.87836326, 50.34400461333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3055895131858685, 6.9112, 6.9112, 95.55338769695034, 353516.9036782262, 353516.9036782262, 150760.0128643403]
[2019-03-23 18:25:56,006] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:25:56,008] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.9146168e-04 3.2038077e-08 9.9910706e-01 2.7383308e-07 1.0627741e-06], sampled 0.2698761081863754
[2019-03-23 18:26:18,645] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0093743], dtype=float32), 0.005734236]
[2019-03-23 18:26:18,646] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.2, 57.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 265103.1950571932, 265103.1950571929, 107566.6740989007]
[2019-03-23 18:26:18,647] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:26:18,650] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.3124484e-03 3.0181053e-07 9.9868053e-01 1.9450958e-06 4.7157969e-06], sampled 0.9973505622646319
[2019-03-23 18:26:24,126] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3126.1697 2108558051.8145 369.0000
[2019-03-23 18:26:24,438] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2766.0703 2123624508.6570 761.0000
[2019-03-23 18:26:24,572] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3360.3307 2097666685.0068 182.0000
[2019-03-23 18:26:24,738] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3521.4583 2103743239.4551 183.0000
[2019-03-23 18:26:24,922] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3616.9123 2174995866.8943 246.0000
[2019-03-23 18:26:25,939] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 975000, evaluation results [975000.0, 3616.9123399839846, 2174995866.8942776, 246.0, 3360.3307084287794, 2097666685.0068498, 182.0, 3521.4583007822675, 2103743239.4551215, 183.0, 2766.0702859975063, 2123624508.656967, 761.0, 3126.1697424775434, 2108558051.8145244, 369.0]
[2019-03-23 18:26:26,338] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0959618e-02 3.2542968e-10 9.8903990e-01 1.5023383e-07 3.1427373e-07], sum to 1.0000
[2019-03-23 18:26:26,344] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1952
[2019-03-23 18:26:26,353] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.83333333333333, 78.83333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3858767300809315, 6.9112, 6.9112, 77.32846344354104, 442481.3142488432, 442481.3142488432, 159331.8166208316], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4745400.0000, 
sim time next is 4746000.0000, 
raw observation next is [20.66666666666667, 79.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3837228147963243, 6.9112, 6.9112, 77.32846344354104, 440132.1416077534, 440132.1416077534, 158941.0565679608], 
processed observation next is [1.0, 0.9565217391304348, 0.575757575757576, 0.7966666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.11960402113760618, 0.0, 0.0, 0.5084288129206541, 0.16301190429916793, 0.16301190429916793, 0.3876611135803922], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3857497], dtype=float32), 0.36546466]. 
=============================================
[2019-03-23 18:26:26,367] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[48.11384 ]
 [47.90969 ]
 [48.111763]
 [48.375008]
 [48.903336]], R is [[47.31279373]
 [46.83966446]
 [46.37126923]
 [45.90755844]
 [45.44848251]].
[2019-03-23 18:26:33,262] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3373525e-02 4.2988585e-08 9.8661929e-01 1.0422157e-06 6.0666075e-06], sum to 1.0000
[2019-03-23 18:26:33,271] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5301
[2019-03-23 18:26:33,279] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.3994523233883052, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7964048253198452, 6.911199999999999, 6.9112, 77.32846344354104, 908620.9661537859, 908620.9661537862, 214731.4703003225], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4881600.0000, 
sim time next is 4882200.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.3652141737768628, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7276956673769697, 6.9112, 6.9112, 77.32846344354104, 830420.0758636708, 830420.0758636708, 203245.9822207248], 
processed observation next is [1.0, 0.5217391304347826, 0.5909090909090909, 0.83, 1.0, 1.0, 0.2065177172210785, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6109938105385282, 0.0, 0.0, 0.5084288129206541, 0.3075629910606188, 0.3075629910606188, 0.49572190785542636], 
reward next is 0.5043, 
noisyNet noise sample is [array([1.3520972], dtype=float32), 0.8589811]. 
=============================================
[2019-03-23 18:26:34,316] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4821767e-03 2.5594102e-07 9.9850106e-01 2.3449056e-06 1.4191120e-05], sum to 1.0000
[2019-03-23 18:26:34,323] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7287
[2019-03-23 18:26:34,332] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.33333333333334, 92.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3899299481957074, 6.911200000000001, 6.9112, 77.32846344354104, 446730.3512306605, 446730.3512306602, 160217.6105507395], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4918800.0000, 
sim time next is 4919400.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.384987916291595, 6.9112, 6.9112, 77.32846344354104, 441312.3786047756, 441312.3786047756, 159346.1846870006], 
processed observation next is [1.0, 0.9565217391304348, 0.5, 0.94, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.12141130898799289, 0.0, 0.0, 0.5084288129206541, 0.16344902911287984, 0.16344902911287984, 0.3886492309439039], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.311962], dtype=float32), 0.9447106]. 
=============================================
[2019-03-23 18:26:36,520] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3722039e-03 5.5949486e-06 9.9854821e-01 1.9869194e-05 5.4086919e-05], sum to 1.0000
[2019-03-23 18:26:36,530] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7043
[2019-03-23 18:26:36,537] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3644493040406723, 6.9112, 6.9112, 77.32846344354104, 418617.5189899665, 418617.5189899665, 155905.3799356908], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4930800.0000, 
sim time next is 4931400.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3639750982338927, 6.911199999999999, 6.9112, 77.32846344354104, 418073.8163294232, 418073.8163294235, 155844.2880745837], 
processed observation next is [1.0, 0.043478260869565216, 0.45454545454545453, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.09139299747698956, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1548421541960827, 0.15484215419608277, 0.38010801969410657], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.40104857], dtype=float32), 1.8412234]. 
=============================================
[2019-03-23 18:26:37,386] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.474387e-04 7.741937e-08 9.995503e-01 1.986571e-06 2.922150e-07], sum to 1.0000
[2019-03-23 18:26:37,394] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7723
[2019-03-23 18:26:37,402] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.83333333333333, 84.83333333333333, 1.0, 2.0, 0.2623015438120707, 0.0, 2.0, 0.0, 1.0, 2.0, 0.497003742130582, 6.9112, 6.9112, 77.32846344354104, 575990.1168668864, 575990.1168668864, 164590.5241534662], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4960200.0000, 
sim time next is 4960800.0000, 
raw observation next is [18.0, 83.0, 1.0, 2.0, 0.2755162554725439, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5215326509306212, 6.9112, 6.9112, 77.32846344354104, 604564.1593963457, 604564.1593963457, 166978.6475327563], 
processed observation next is [1.0, 0.43478260869565216, 0.45454545454545453, 0.83, 1.0, 1.0, 0.09439531934067984, 0.0, 1.0, -0.25, 1.0, 1.0, 0.31647521561517317, 0.0, 0.0, 0.5084288129206541, 0.2239126516282762, 0.2239126516282762, 0.4072649939823324], 
reward next is 0.5927, 
noisyNet noise sample is [array([-2.0783803], dtype=float32), 1.2948489]. 
=============================================
[2019-03-23 18:26:38,832] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1673436e-03 2.1755053e-09 9.9782985e-01 6.2873923e-08 2.6540515e-06], sum to 1.0000
[2019-03-23 18:26:38,838] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1171
[2019-03-23 18:26:38,841] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.2908607280157949, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5476447501591608, 6.911199999999999, 6.9112, 77.32846344354104, 635574.1086484538, 635574.1086484542, 169097.2185769043], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4974000.0000, 
sim time next is 4974600.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.2853051329960388, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5370413344481468, 6.9112, 6.9112, 77.32846344354104, 623294.7188734232, 623294.7188734232, 167917.4636122009], 
processed observation next is [1.0, 0.5652173913043478, 0.5, 0.73, 1.0, 1.0, 0.10663141624504852, 0.0, 1.0, -0.25, 1.0, 1.0, 0.33863047778306693, 0.0, 0.0, 0.5084288129206541, 0.2308498958790456, 0.2308498958790456, 0.40955478929805095], 
reward next is 0.5904, 
noisyNet noise sample is [array([2.6537027], dtype=float32), -1.3132217]. 
=============================================
[2019-03-23 18:26:40,211] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0460364e-03 2.1522895e-10 9.9895394e-01 2.6845800e-08 3.7250523e-08], sum to 1.0000
[2019-03-23 18:26:40,221] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5852
[2019-03-23 18:26:40,228] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.5, 70.5, 1.0, 2.0, 0.2930729450325463, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5532392902785387, 6.911199999999999, 6.9112, 77.32846344354104, 641722.9194488196, 641722.9194488198, 170040.7589557458], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4977000.0000, 
sim time next is 4977600.0000, 
raw observation next is [19.66666666666666, 69.66666666666666, 1.0, 2.0, 0.2947254449589736, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5571940668834906, 6.9112, 6.9112, 77.32846344354104, 646106.1351975348, 646106.1351975348, 170674.1128509316], 
processed observation next is [1.0, 0.6086956521739131, 0.53030303030303, 0.6966666666666665, 1.0, 1.0, 0.11840680619871702, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3674200955478438, 0.0, 0.0, 0.5084288129206541, 0.23929856859167956, 0.23929856859167956, 0.4162783240266624], 
reward next is 0.5837, 
noisyNet noise sample is [array([1.607466], dtype=float32), -1.2872854]. 
=============================================
[2019-03-23 18:26:43,311] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.3457133e-04 5.1918261e-07 9.9975592e-01 5.4869806e-06 3.5241812e-06], sum to 1.0000
[2019-03-23 18:26:43,319] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8247
[2019-03-23 18:26:43,326] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [13.66666666666667, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 236447.3403581084, 236447.3403581087, 99693.27565110858], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5034000.0000, 
sim time next is 5034600.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 246658.714126013, 246658.714126013, 103527.1352683012], 
processed observation next is [0.0, 0.2608695652173913, 0.2727272727272727, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.09135507930593073, 0.09135507930593073, 0.2525052079714663], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.14428997], dtype=float32), -0.85801184]. 
=============================================
[2019-03-23 18:26:46,927] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.0382961e-05 9.4868742e-13 9.9991965e-01 2.1586920e-11 2.1997135e-09], sum to 1.0000
[2019-03-23 18:26:46,936] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0806
[2019-03-23 18:26:46,942] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.2167178220867377, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4348317757518842, 6.911199999999999, 6.9112, 77.32846344354104, 494070.6094298982, 494070.6094298985, 168034.7543220761], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5125200.0000, 
sim time next is 5125800.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.2172599419923281, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4359220917762426, 6.911199999999999, 6.9112, 77.32846344354104, 495308.1266007953, 495308.1266007955, 168141.9602028786], 
processed observation next is [0.0, 0.30434782608695654, 0.6363636363636364, 0.83, 1.0, 1.0, 0.021574927490410102, 0.0, 1.0, -0.25, 1.0, 1.0, 0.19417441682320372, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18344745429659085, 0.18344745429659093, 0.41010234195824047], 
reward next is 0.5899, 
noisyNet noise sample is [array([-1.6957588], dtype=float32), 0.67536736]. 
=============================================
[2019-03-23 18:26:55,644] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0565680e-04 6.8469581e-07 9.9988747e-01 3.8678400e-06 2.3414889e-06], sum to 1.0000
[2019-03-23 18:26:55,652] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2688
[2019-03-23 18:26:55,657] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [9.7, 86.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 143851.6003749139, 143851.6003749142, 74414.44602130703], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5715000.0000, 
sim time next is 5715600.0000, 
raw observation next is [9.600000000000001, 86.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 142239.955990045, 142239.955990045, 74174.48388502873], 
processed observation next is [0.0, 0.13043478260869565, 0.0727272727272728, 0.86, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.052681465181498154, 0.052681465181498154, 0.18091337532933838], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.13313402], dtype=float32), 0.51138693]. 
=============================================
[2019-03-23 18:26:56,814] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.8447370e-04 2.9825744e-05 9.9974602e-01 3.3177676e-05 6.4915480e-06], sum to 1.0000
[2019-03-23 18:26:56,824] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7938
[2019-03-23 18:26:56,830] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.06666666666667, 60.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 215425.827475927, 215425.827475927, 89853.8788832587], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5736000.0000, 
sim time next is 5736600.0000, 
raw observation next is [16.35, 59.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 219044.1890451909, 219044.1890451906, 90738.91013325675], 
processed observation next is [0.0, 0.391304347826087, 0.37954545454545463, 0.59, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08112747742414478, 0.08112747742414467, 0.22131441495916282], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.21525492], dtype=float32), 0.6714137]. 
=============================================
[2019-03-23 18:27:01,349] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.1191141e-05 2.0056805e-09 9.9990880e-01 4.4148480e-09 2.4261297e-08], sum to 1.0000
[2019-03-23 18:27:01,357] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6149
[2019-03-23 18:27:01,373] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.7, 91.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3892916513937905, 6.9112, 6.9112, 77.32846344308753, 445273.8432515771, 445273.8432515771, 160759.6269196325], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5419800.0000, 
sim time next is 5420400.0000, 
raw observation next is [19.6, 92.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3917652439005226, 6.911199999999999, 6.9112, 77.32846344353824, 448233.483776564, 448233.4837765642, 160981.4548769476], 
processed observation next is [1.0, 0.7391304347826086, 0.5272727272727273, 0.92, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.13109320557217516, -8.881784197001253e-17, 0.0, 0.5084288129206357, 0.16601240139872742, 0.16601240139872747, 0.3926376948218234], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.41174957], dtype=float32), 0.92256516]. 
=============================================
[2019-03-23 18:27:03,291] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.8530294e-05 1.6185826e-05 9.9992108e-01 3.0456427e-05 3.8453068e-06], sum to 1.0000
[2019-03-23 18:27:03,301] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1796
[2019-03-23 18:27:03,305] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.2, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3022114946460978, 6.9112, 6.9112, 77.32846344354104, 350629.1845485391, 350629.1845485391, 144812.192232317], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5463000.0000, 
sim time next is 5463600.0000, 
raw observation next is [17.2, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.30308483176533, 6.911200000000001, 6.9112, 77.32846344354104, 351644.2493624324, 351644.2493624321, 144904.8147685222], 
processed observation next is [1.0, 0.21739130434782608, 0.41818181818181815, 0.9, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.004406902521900046, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13023861087497496, 0.13023861087497485, 0.35342637748420047], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1857164], dtype=float32), -0.7963408]. 
=============================================
[2019-03-23 18:27:06,395] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.0953574e-03 8.5412788e-09 9.9590069e-01 2.0114001e-06 1.8876661e-06], sum to 1.0000
[2019-03-23 18:27:06,404] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8990
[2019-03-23 18:27:06,409] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.8, 70.5, 1.0, 2.0, 0.573360826594232, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9765290262322992, 6.911199999999999, 6.9112, 77.32846344354104, 1200170.48964797, 1200170.48964797, 273171.3082543275], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5488200.0000, 
sim time next is 5488800.0000, 
raw observation next is [25.7, 71.0, 1.0, 2.0, 0.4258466736140096, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8625907954887625, 6.911200000000001, 6.9112, 77.32846344354104, 968696.9126422846, 968696.9126422844, 236703.2196921297], 
processed observation next is [1.0, 0.5217391304347826, 0.8045454545454546, 0.71, 1.0, 1.0, 0.2823083420175119, 0.0, 1.0, -0.25, 1.0, 1.0, 0.803701136412518, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3587766343119573, 0.35877663431195717, 0.5773249260783652], 
reward next is 0.4227, 
noisyNet noise sample is [array([0.5526557], dtype=float32), -0.4472189]. 
=============================================
[2019-03-23 18:27:08,993] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.5957387e-04 1.5135464e-08 9.9953890e-01 1.2705110e-06 2.9089537e-07], sum to 1.0000
[2019-03-23 18:27:09,000] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2294
[2019-03-23 18:27:09,006] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.5, 87.0, 1.0, 2.0, 0.2300861811433425, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4573021373858159, 6.911200000000001, 6.9112, 77.32846344354104, 522317.5275046534, 522317.5275046531, 168005.8606712283], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5540400.0000, 
sim time next is 5541000.0000, 
raw observation next is [20.41666666666667, 88.0, 1.0, 2.0, 0.224084425118168, 0.0, 2.0, 0.0, 1.0, 2.0, 0.445491960295127, 6.9112, 6.9112, 77.32846344354104, 508758.6911371691, 508758.6911371691, 166903.6615853614], 
processed observation next is [1.0, 0.13043478260869565, 0.5643939393939396, 0.88, 1.0, 1.0, 0.030105531397709995, 0.0, 1.0, -0.25, 1.0, 1.0, 0.20784565756446716, 0.0, 0.0, 0.5084288129206541, 0.18842914486561818, 0.18842914486561818, 0.40708210142771073], 
reward next is 0.5929, 
noisyNet noise sample is [array([-0.38518697], dtype=float32), -0.97082025]. 
=============================================
[2019-03-23 18:27:09,022] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[38.191936]
 [38.491367]
 [38.670277]
 [38.28183 ]
 [38.821407]], R is [[37.47204208]
 [37.68754959]
 [37.8986969 ]
 [38.10482025]
 [38.30081558]].
[2019-03-23 18:27:09,698] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.4468460e-03 3.6156802e-08 9.9553728e-01 8.6727431e-07 1.4964841e-05], sum to 1.0000
[2019-03-23 18:27:09,708] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6221
[2019-03-23 18:27:09,714] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.5, 90.0, 1.0, 2.0, 0.2121798737500775, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4233122880801073, 6.9112, 6.9112, 77.32846344354104, 482582.5407914596, 482582.5407914596, 165551.4001879253], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5552400.0000, 
sim time next is 5553000.0000, 
raw observation next is [20.5, 90.0, 1.0, 2.0, 0.2148046916970792, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4285567803609591, 6.9112, 6.9112, 77.32846344354104, 488559.7107567757, 488559.7107567757, 166045.3207427954], 
processed observation next is [1.0, 0.2608695652173913, 0.5681818181818182, 0.9, 1.0, 1.0, 0.018505864621348976, 0.0, 1.0, -0.25, 1.0, 1.0, 0.18365254337279877, 0.0, 0.0, 0.5084288129206541, 0.18094804102102804, 0.18094804102102804, 0.4049885871775497], 
reward next is 0.5950, 
noisyNet noise sample is [array([2.5483518], dtype=float32), 0.48326728]. 
=============================================
[2019-03-23 18:27:09,735] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[44.204323]
 [44.18827 ]
 [44.156822]
 [44.17499 ]
 [44.25179 ]], R is [[44.33076859]
 [44.48367691]
 [44.63429642]
 [44.78680801]
 [44.93794632]].
[2019-03-23 18:27:11,024] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.3049962e-04 1.8991826e-06 9.9934655e-01 1.2209727e-05 8.9692094e-06], sum to 1.0000
[2019-03-23 18:27:11,032] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6867
[2019-03-23 18:27:11,037] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.36666666666667, 61.66666666666667, 1.0, 2.0, 0.6534925718451525, 0.0, 2.0, 0.0, 1.0, 2.0, 0.976929115569606, 6.9112, 6.9112, 77.32846344335043, 1291101.440259993, 1291101.440259993, 284917.8117866411], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5574000.0000, 
sim time next is 5574600.0000, 
raw observation next is [27.45, 61.5, 1.0, 2.0, 0.5666986188704788, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9768665057022462, 6.911199999999999, 6.9112, 77.32846344353986, 1192373.053139318, 1192373.053139318, 272534.0115831323], 
processed observation next is [1.0, 0.5217391304347826, 0.884090909090909, 0.615, 1.0, 1.0, 0.45837327358809843, 0.0, 1.0, -0.25, 1.0, 1.0, 0.966952151003209, -8.881784197001253e-17, 0.0, 0.5084288129206463, 0.4416196493108585, 0.4416196493108585, 0.6647171014222739], 
reward next is 0.3353, 
noisyNet noise sample is [array([0.45252898], dtype=float32), 0.41661668]. 
=============================================
[2019-03-23 18:27:14,641] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.6983532e-04 5.4748193e-04 9.9776173e-01 1.3519226e-03 6.8936250e-05], sum to 1.0000
[2019-03-23 18:27:14,650] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9868
[2019-03-23 18:27:14,658] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [15.5, 78.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 229711.7850357791, 229711.7850357794, 96684.34921419073], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5673000.0000, 
sim time next is 5673600.0000, 
raw observation next is [15.5, 78.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 229985.1835727772, 229985.1835727772, 96534.70975885211], 
processed observation next is [0.0, 0.6956521739130435, 0.3409090909090909, 0.78, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.0851796976195471, 0.0851796976195471, 0.23545051160695638], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.8746113], dtype=float32), 0.90705395]. 
=============================================
[2019-03-23 18:27:14,923] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.9571660e-05 4.0107730e-06 9.9986887e-01 8.6288659e-05 1.1519575e-06], sum to 1.0000
[2019-03-23 18:27:14,928] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7115
[2019-03-23 18:27:14,931] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.6, 96.0, 1.0, 2.0, 0.2082554468047778, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4147331190996405, 6.9112, 6.9112, 77.32846344354104, 473228.1984275312, 473228.1984275312, 164376.3864593989], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5625600.0000, 
sim time next is 5626200.0000, 
raw observation next is [19.5, 96.0, 1.0, 2.0, 0.2064605568092629, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4106717097631594, 6.9112, 6.9112, 77.32846344354104, 468858.3902145593, 468858.3902145593, 163767.1215705379], 
processed observation next is [0.0, 0.08695652173913043, 0.5227272727272727, 0.96, 1.0, 1.0, 0.008075696011578606, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1581024425187992, 0.0, 0.0, 0.5084288129206541, 0.17365125563502196, 0.17365125563502196, 0.3994320038305803], 
reward next is 0.6006, 
noisyNet noise sample is [array([1.1503125], dtype=float32), 2.6706262]. 
=============================================
[2019-03-23 18:27:16,128] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 18:27:16,129] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:27:16,130] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:27:16,131] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:27:16,132] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:27:16,133] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:27:16,135] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:27:16,135] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:27:16,135] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:27:16,136] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:27:16,137] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:27:16,160] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run41
[2019-03-23 18:27:16,160] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run41
[2019-03-23 18:27:16,181] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run41
[2019-03-23 18:27:16,183] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run41
[2019-03-23 18:27:16,254] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run41
[2019-03-23 18:27:31,996] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00978425], dtype=float32), 0.0056816763]
[2019-03-23 18:27:31,998] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.38347262, 97.90852338, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3116333746004514, 6.9112, 6.9112, 81.84244075642364, 362542.4367673178, 362542.4367673178, 122573.2280014285]
[2019-03-23 18:27:32,001] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:27:32,003] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.61217057e-05 3.12326192e-05 9.99790967e-01 1.14110466e-04
 7.66780067e-06], sampled 0.8087773392227284
[2019-03-23 18:27:35,669] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00978425], dtype=float32), 0.0056816763]
[2019-03-23 18:27:35,670] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 86.66666666666667, 1.0, 2.0, 0.5453268981889152, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9626251312337742, 6.921869958023215, 6.9112, 77.32843710624306, 1170808.793183298, 1167343.410236015, 261021.9172947718]
[2019-03-23 18:27:35,670] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:27:35,673] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.0733146e-04 7.5831650e-07 9.9927360e-01 1.0437791e-05 7.8493922e-06], sampled 0.9622822665794055
[2019-03-23 18:27:39,916] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00978425], dtype=float32), 0.0056816763]
[2019-03-23 18:27:39,918] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [9.110880116, 72.84999794, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.351576432371026, 6.9112, 6.9112, 95.55338769695034, 409005.8179410551, 409005.8179410551, 119756.7686365983]
[2019-03-23 18:27:39,919] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:27:39,922] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.7713415e-05 4.5378012e-05 9.9969268e-01 1.6201979e-04 1.2332664e-05], sampled 0.03655495359034522
[2019-03-23 18:27:42,444] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00978425], dtype=float32), 0.0056816763]
[2019-03-23 18:27:42,444] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.96666666666667, 87.0, 1.0, 2.0, 0.2844217868157858, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5756471394495649, 6.911200000000001, 6.9112, 95.55338769695034, 648145.4406358994, 648145.4406358991, 192683.2160401437]
[2019-03-23 18:27:42,447] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:27:42,452] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.2580112e-04 2.5632320e-07 9.9956697e-01 3.7306424e-06 3.3169504e-06], sampled 0.402867604115158
[2019-03-23 18:27:53,972] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00978425], dtype=float32), 0.0056816763]
[2019-03-23 18:27:53,973] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.11666666666667, 77.33333333333334, 1.0, 2.0, 0.2295468171388352, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4617980048056416, 6.9112, 6.9112, 95.55338769695034, 523658.1809227856, 523658.1809227856, 176215.9556164492]
[2019-03-23 18:27:53,975] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:27:53,978] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.17315445e-04 8.15130898e-06 9.99819577e-01 4.76761379e-05
 7.38288963e-06], sampled 0.39322816395768934
[2019-03-23 18:27:56,472] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00978425], dtype=float32), 0.0056816763]
[2019-03-23 18:27:56,474] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.0, 91.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3362641650550412, 6.9112, 6.9112, 77.32846344354104, 388237.5368471611, 388237.5368471611, 150496.6393234008]
[2019-03-23 18:27:56,476] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:27:56,479] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.2699838e-05 1.8278530e-05 9.9987400e-01 7.0955110e-05 4.0312789e-06], sampled 0.7745239172902545
[2019-03-23 18:28:02,658] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00978425], dtype=float32), 0.0056816763]
[2019-03-23 18:28:02,659] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.959597555, 87.75024214999999, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 95.55338769695034, 276957.528748208, 276957.5287482083, 119403.120390519]
[2019-03-23 18:28:02,660] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:28:02,662] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.5026966e-04 1.9545112e-04 9.9891436e-01 5.8294390e-04 5.6931018e-05], sampled 0.5340695462814268
[2019-03-23 18:28:06,480] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00978425], dtype=float32), 0.0056816763]
[2019-03-23 18:28:06,482] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.66191923333334, 94.65793394, 1.0, 2.0, 0.2171608222855914, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4324753087704158, 6.911199999999999, 6.9112, 95.55338769695034, 493431.1420724611, 493431.1420724615, 170699.031886806]
[2019-03-23 18:28:06,484] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:28:06,486] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.5235308e-05 6.5904846e-06 9.9987435e-01 3.8894377e-05 4.8798970e-06], sampled 0.797124743423514
[2019-03-23 18:28:06,986] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00978425], dtype=float32), 0.0056816763]
[2019-03-23 18:28:06,987] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3700492974639603, 6.9112, 6.9112, 77.32846344354104, 425043.9682034132, 425043.9682034132, 156624.590833438]
[2019-03-23 18:28:06,989] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:28:06,991] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.8464644e-05 3.1531647e-05 9.9976760e-01 1.2378042e-04 8.7575090e-06], sampled 0.05848483709874286
[2019-03-23 18:28:25,181] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00978425], dtype=float32), 0.0056816763]
[2019-03-23 18:28:25,183] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.1, 66.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3171353304037574, 6.9112, 6.9112, 95.55338769695034, 366417.9912790933, 366417.9912790933, 152525.6360987198]
[2019-03-23 18:28:25,184] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:28:25,185] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0821290e-04 7.4542004e-05 9.9954778e-01 2.5037676e-04 1.9075427e-05], sampled 0.023956803124591586
[2019-03-23 18:28:28,615] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00978425], dtype=float32), 0.0056816763]
[2019-03-23 18:28:28,617] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.32449013666667, 81.43406832000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3167165964539089, 6.911199999999999, 6.9112, 85.40281283076101, 368452.6825651032, 368452.6825651035, 118796.345527696]
[2019-03-23 18:28:28,618] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:28:28,624] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.4597618e-05 3.8438047e-05 9.9975127e-01 1.3645274e-04 9.3156086e-06], sampled 0.00496032899988974
[2019-03-23 18:28:38,072] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00978425], dtype=float32), 0.0056816763]
[2019-03-23 18:28:38,072] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.75, 92.0, 1.0, 2.0, 0.2345487672294833, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4734862128630741, 6.911200000000001, 6.9112, 95.55338769695034, 535182.4533523789, 535182.4533523786, 178751.2722663892]
[2019-03-23 18:28:38,073] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:28:38,076] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.8893900e-05 8.4367485e-07 9.9993110e-01 7.5071957e-06 1.6204127e-06], sampled 0.9121117119158384
[2019-03-23 18:28:53,910] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3519.0325 2104099291.0044 178.0000
[2019-03-23 18:28:53,977] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2758.5501 2123979520.8924 757.0000
[2019-03-23 18:28:54,139] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3118.6004 2108982029.1344 369.0000
[2019-03-23 18:28:54,382] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3362.1913 2097939387.3781 180.0000
[2019-03-23 18:28:54,430] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3616.8244 2175158727.9054 245.0000
[2019-03-23 18:28:55,446] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1000000, evaluation results [1000000.0, 3616.8243578414103, 2175158727.9053903, 245.0, 3362.191266271479, 2097939387.378055, 180.0, 3519.032511138161, 2104099291.004396, 178.0, 2758.5500555702447, 2123979520.8923967, 757.0, 3118.6004070848808, 2108982029.134425, 369.0]
[2019-03-23 18:28:56,387] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.6881733e-04 6.3177891e-04 9.9799830e-01 1.0216198e-03 7.9306214e-05], sum to 1.0000
[2019-03-23 18:28:56,394] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4791
[2019-03-23 18:28:56,399] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.33333333333333, 58.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 236690.4174478241, 236690.4174478244, 95801.39833124772], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5777400.0000, 
sim time next is 5778000.0000, 
raw observation next is [17.7, 56.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 240283.499876091, 240283.4998760913, 96539.03317477967], 
processed observation next is [0.0, 0.9130434782608695, 0.44090909090909086, 0.56, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08899388884299667, 0.08899388884299678, 0.23546105652385285], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8215117], dtype=float32), 1.4204375]. 
=============================================
[2019-03-23 18:28:56,417] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[-2.3077087]
 [-2.3492422]
 [-2.3979182]
 [-2.4288325]
 [-2.6512873]], R is [[-2.25043535]
 [-2.22793102]
 [-2.20565176]
 [-2.18359518]
 [-2.16175914]].
[2019-03-23 18:28:59,062] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1520897e-04 1.8459043e-04 9.9927264e-01 2.9452943e-04 3.3040116e-05], sum to 1.0000
[2019-03-23 18:28:59,069] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3416
[2019-03-23 18:28:59,078] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.98333333333333, 49.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 237364.9494536862, 237364.9494536865, 94448.82157246447], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5742600.0000, 
sim time next is 5743200.0000, 
raw observation next is [18.26666666666667, 48.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 240258.0642548333, 240258.0642548336, 95237.42351965365], 
processed observation next is [0.0, 0.4782608695652174, 0.4666666666666668, 0.48333333333333345, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08898446824253085, 0.08898446824253096, 0.23228639882842353], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5311867], dtype=float32), 1.3782822]. 
=============================================
[2019-03-23 18:29:04,486] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.9843369e-03 3.6835244e-09 9.9501485e-01 6.2973406e-08 6.6027826e-07], sum to 1.0000
[2019-03-23 18:29:04,495] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1261
[2019-03-23 18:29:04,501] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.5, 45.0, 1.0, 2.0, 0.3185430713666454, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6190975475053345, 6.9112, 6.9112, 77.32846344354104, 712999.961651657, 712999.961651657, 182234.3777381497], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5842800.0000, 
sim time next is 5843400.0000, 
raw observation next is [25.6, 44.16666666666666, 1.0, 2.0, 0.2970873189119118, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5767011002446429, 6.9112, 6.9112, 77.32846344354104, 664373.8071816183, 664373.8071816183, 176778.9401395466], 
processed observation next is [1.0, 0.6521739130434783, 0.8, 0.4416666666666666, 1.0, 1.0, 0.12135914863988975, 0.0, 1.0, -0.25, 1.0, 1.0, 0.39528728606377567, 0.0, 0.0, 0.5084288129206541, 0.246064373030229, 0.246064373030229, 0.431168146681821], 
reward next is 0.5688, 
noisyNet noise sample is [array([1.6630584], dtype=float32), -0.80346024]. 
=============================================
[2019-03-23 18:29:05,338] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.9245328e-05 1.9806878e-10 9.9992037e-01 5.3524140e-08 3.2436566e-07], sum to 1.0000
[2019-03-23 18:29:05,346] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9085
[2019-03-23 18:29:05,354] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.6, 55.0, 1.0, 2.0, 0.2732362172690738, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5533292286377329, 6.9112, 6.9112, 77.32846344354104, 619019.5126799339, 619019.5126799339, 187541.206894305], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6279600.0000, 
sim time next is 6280200.0000, 
raw observation next is [29.7, 55.0, 1.0, 2.0, 0.2747230531251478, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5562593722727747, 6.911200000000001, 6.9112, 77.32846344354104, 621967.788411779, 621967.7884117786, 188120.7572445473], 
processed observation next is [0.0, 0.6956521739130435, 0.9863636363636363, 0.55, 1.0, 1.0, 0.0934038164064347, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3660848175325353, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23035844015251072, 0.2303584401525106, 0.45883111523060316], 
reward next is 0.5412, 
noisyNet noise sample is [array([0.8345779], dtype=float32), 1.015506]. 
=============================================
[2019-03-23 18:29:12,198] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.4531205e-04 6.3229352e-05 9.9929380e-01 3.0957398e-04 8.8049877e-05], sum to 1.0000
[2019-03-23 18:29:12,210] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9002
[2019-03-23 18:29:12,213] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.41666666666667, 69.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.348863087995913, 6.9112, 6.9112, 77.32846344354104, 401591.757164519, 401591.757164519, 153132.9782811381], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5962200.0000, 
sim time next is 5962800.0000, 
raw observation next is [21.23333333333333, 71.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3501848036588974, 6.9112, 6.9112, 77.32846344354104, 402998.1866805669, 402998.1866805669, 153402.8717792121], 
processed observation next is [1.0, 0.0, 0.6015151515151514, 0.7133333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.07169257665556777, 0.0, 0.0, 0.5084288129206541, 0.14925858765946923, 0.14925858765946923, 0.37415334580295634], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.03579396], dtype=float32), 0.40865153]. 
=============================================
[2019-03-23 18:29:14,835] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.14337694e-04 3.51460658e-05 9.99615550e-01 2.14184562e-04
 2.07515895e-05], sum to 1.0000
[2019-03-23 18:29:14,840] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7970
[2019-03-23 18:29:14,844] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [13.8, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 216430.5110841017, 216430.511084102, 91882.94026984565], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6062400.0000, 
sim time next is 6063000.0000, 
raw observation next is [13.9, 86.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 234050.2462237542, 234050.246223754, 95198.01533159411], 
processed observation next is [1.0, 0.17391304347826086, 0.2681818181818182, 0.8633333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08668527637916822, 0.08668527637916815, 0.23219028129657102], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5749382], dtype=float32), -0.8008439]. 
=============================================
[2019-03-23 18:29:14,860] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[3.2387633]
 [3.2447789]
 [3.3234816]
 [3.3706393]
 [3.4565258]], R is [[3.33270931]
 [3.29938221]
 [3.26638842]
 [3.23372459]
 [3.20138741]].
[2019-03-23 18:29:19,591] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.5451356e-03 4.9781832e-08 9.9745017e-01 1.1038712e-06 3.4212858e-06], sum to 1.0000
[2019-03-23 18:29:19,604] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3178
[2019-03-23 18:29:19,607] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.2, 84.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 326324.5756914483, 326324.5756914483, 136667.2615959755], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6152400.0000, 
sim time next is 6153000.0000, 
raw observation next is [17.2, 84.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 311437.197875049, 311437.1978750487, 133975.5432933221], 
processed observation next is [1.0, 0.21739130434782608, 0.41818181818181815, 0.84, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11534711032409223, 0.1153471103240921, 0.3267696177885905], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0753148], dtype=float32), -1.1255811]. 
=============================================
[2019-03-23 18:29:19,626] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[37.128643]
 [36.959305]
 [37.118877]
 [36.882046]
 [36.577015]], R is [[36.71405411]
 [36.34691238]
 [35.98344421]
 [35.62361145]
 [35.26737595]].
[2019-03-23 18:29:20,959] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4009052e-03 7.9246500e-05 9.9820113e-01 2.6405577e-04 5.4642784e-05], sum to 1.0000
[2019-03-23 18:29:20,964] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1977
[2019-03-23 18:29:20,970] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.1, 64.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 291791.4740767277, 291791.4740767277, 119372.0987332016], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6125400.0000, 
sim time next is 6126000.0000, 
raw observation next is [19.0, 64.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 291315.5116114583, 291315.5116114583, 118761.6841307298], 
processed observation next is [1.0, 0.9130434782608695, 0.5, 0.6433333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.10789463393016975, 0.10789463393016975, 0.2896626442212922], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.12012755], dtype=float32), -0.19102086]. 
=============================================
[2019-03-23 18:29:20,999] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[8.452383 ]
 [8.393405 ]
 [8.382122 ]
 [8.3607025]
 [8.343563 ]], R is [[8.47975159]
 [8.39495373]
 [8.31100464]
 [8.22789478]
 [8.14561558]].
[2019-03-23 18:29:26,560] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.1899669e-03 6.6934005e-09 9.9880838e-01 6.9999419e-07 9.1461601e-07], sum to 1.0000
[2019-03-23 18:29:26,567] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0246
[2019-03-23 18:29:26,571] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.6, 69.0, 1.0, 2.0, 0.2628477759603536, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5324455445025729, 6.9112, 6.9112, 77.32846344354104, 596813.1077822414, 596813.1077822414, 184156.1954148339], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6264000.0000, 
sim time next is 6264600.0000, 
raw observation next is [26.96666666666667, 67.0, 1.0, 2.0, 0.2647595794816977, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5363066414013468, 6.9112, 6.9112, 77.32846344354104, 600942.8945879784, 600942.8945879784, 184762.299779967], 
processed observation next is [0.0, 0.5217391304347826, 0.8621212121212122, 0.67, 1.0, 1.0, 0.08094947435212212, 0.0, 1.0, -0.25, 1.0, 1.0, 0.33758091628763826, 0.0, 0.0, 0.5084288129206541, 0.222571442439992, 0.222571442439992, 0.45063975556089514], 
reward next is 0.5494, 
noisyNet noise sample is [array([-0.6236444], dtype=float32), 0.53989893]. 
=============================================
[2019-03-23 18:29:35,937] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.8316611e-03 3.5473215e-09 9.9716610e-01 8.1557090e-07 1.3854540e-06], sum to 1.0000
[2019-03-23 18:29:35,951] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3401
[2019-03-23 18:29:35,960] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.0, 93.0, 1.0, 2.0, 0.4140393830103911, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8279053230445675, 6.911199999999999, 6.9112, 77.32846344354098, 943112.9795796066, 943112.9795796068, 221289.5300741151], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6429600.0000, 
sim time next is 6430200.0000, 
raw observation next is [20.0, 93.0, 1.0, 2.0, 0.3883162768474044, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7758944606462798, 6.9112, 6.9112, 77.32846344354104, 884177.38691855, 884177.38691855, 211976.3071103447], 
processed observation next is [1.0, 0.43478260869565216, 0.5454545454545454, 0.93, 1.0, 1.0, 0.23539534605925547, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6798492294946854, 0.0, 0.0, 0.5084288129206541, 0.32747310626612963, 0.32747310626612963, 0.5170153831959626], 
reward next is 0.4830, 
noisyNet noise sample is [array([0.64660925], dtype=float32), 1.1407727]. 
=============================================
[2019-03-23 18:29:40,781] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.8855603e-05 2.6778256e-08 9.9993038e-01 4.1939543e-08 5.9951572e-07], sum to 1.0000
[2019-03-23 18:29:40,789] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2668
[2019-03-23 18:29:40,796] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [12.7, 89.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 212489.4237423865, 212489.4237423868, 89262.4565949124], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6495000.0000, 
sim time next is 6495600.0000, 
raw observation next is [12.7, 88.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 208932.0521535791, 208932.0521535791, 88584.18066032822], 
processed observation next is [1.0, 0.17391304347826086, 0.2136363636363636, 0.8866666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.07738224153836264, 0.07738224153836264, 0.21605897722031273], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.6679689], dtype=float32), 0.016363164]. 
=============================================
[2019-03-23 18:29:43,864] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.4651557e-03 8.8771365e-08 9.9752730e-01 5.8111624e-08 7.4685295e-06], sum to 1.0000
[2019-03-23 18:29:43,873] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1132
[2019-03-23 18:29:43,881] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.15, 82.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 257561.1079397596, 257561.1079397599, 99078.47136647375], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6574200.0000, 
sim time next is 6574800.0000, 
raw observation next is [13.9, 83.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 234161.426956285, 234161.4269562847, 94808.4932778539], 
processed observation next is [1.0, 0.08695652173913043, 0.2681818181818182, 0.8366666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0867264544282537, 0.0867264544282536, 0.23124022750696072], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6189262], dtype=float32), -0.70906997]. 
=============================================
[2019-03-23 18:29:45,481] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 18:29:45,484] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:29:45,484] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:29:45,484] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:29:45,485] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:29:45,487] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:29:45,487] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:29:45,488] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:29:45,489] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:29:45,492] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:29:45,494] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:29:45,509] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run42
[2019-03-23 18:29:45,510] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run42
[2019-03-23 18:29:45,558] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run42
[2019-03-23 18:29:45,559] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run42
[2019-03-23 18:29:45,581] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run42
[2019-03-23 18:30:04,293] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00988824], dtype=float32), 0.005838258]
[2019-03-23 18:30:04,293] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.53333333333333, 90.83333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3153892779042994, 6.911200000000001, 6.9112, 95.55338769695034, 365047.6183001129, 365047.6183001125, 151672.8383240477]
[2019-03-23 18:30:04,295] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:30:04,298] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.9607810e-04 4.5894527e-08 9.9970180e-01 6.2130869e-07 1.3726196e-06], sampled 0.1058169122050222
[2019-03-23 18:30:43,001] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00988824], dtype=float32), 0.005838258]
[2019-03-23 18:30:43,002] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.76666666666667, 71.66666666666666, 1.0, 2.0, 0.2450942397875226, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4951928988699656, 6.9112, 6.9112, 95.55338769695034, 559148.0934432495, 559148.0934432495, 181571.6414594798]
[2019-03-23 18:30:43,003] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:30:43,006] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.8227500e-04 2.5465166e-08 9.9911529e-01 4.2673366e-07 1.9091692e-06], sampled 0.7368631084348167
[2019-03-23 18:30:45,968] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00988824], dtype=float32), 0.005838258]
[2019-03-23 18:30:45,969] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.4, 79.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 255884.3274185018, 255884.3274185018, 110857.688213747]
[2019-03-23 18:30:45,970] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:30:45,973] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.7517544e-04 3.1008787e-07 9.9961770e-01 3.0674469e-06 3.8493490e-06], sampled 0.8061192975498014
[2019-03-23 18:31:07,013] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00988824], dtype=float32), 0.005838258]
[2019-03-23 18:31:07,014] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.56445127, 59.32801603, 1.0, 2.0, 0.376347490864296, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7592487119136213, 6.911200000000001, 6.9112, 95.55338769695034, 859015.4070746042, 859015.4070746038, 218419.9255605729]
[2019-03-23 18:31:07,017] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:31:07,021] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.2207913e-04 1.6180943e-09 9.9937755e-01 4.2060751e-08 4.0355127e-07], sampled 0.35002294636860454
[2019-03-23 18:31:14,623] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00988824], dtype=float32), 0.005838258]
[2019-03-23 18:31:14,623] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.83333333333334, 59.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3720017155133931, 6.911199999999999, 6.9112, 95.55338769695034, 432344.9454197813, 432344.9454197817, 156708.5490908217]
[2019-03-23 18:31:14,624] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:31:14,626] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.7993580e-04 2.4239114e-07 9.9921131e-01 2.6213970e-06 5.7780262e-06], sampled 0.36635188054954426
[2019-03-23 18:31:19,522] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00988824], dtype=float32), 0.005838258]
[2019-03-23 18:31:19,523] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.33333333333334, 72.66666666666667, 1.0, 2.0, 0.5528774718117909, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9716723336325424, 6.918375241291571, 6.9112, 77.32844584153969, 1177266.669259653, 1174936.298177669, 269005.5946018449]
[2019-03-23 18:31:19,524] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:31:19,528] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.3766633e-04 2.1196904e-08 9.9926025e-01 4.2219432e-07 1.6080728e-06], sampled 0.05619005128958687
[2019-03-23 18:31:19,957] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00988824], dtype=float32), 0.005838258]
[2019-03-23 18:31:19,958] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.888993655, 69.05533948333333, 1.0, 2.0, 0.2336426044024431, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4689378350738176, 6.911199999999999, 6.9112, 95.55338769695034, 532675.3217675566, 532675.321767557, 176253.4726351674]
[2019-03-23 18:31:19,960] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:31:19,964] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.1105047e-04 6.1574608e-09 9.9918789e-01 1.2576484e-07 9.2497305e-07], sampled 0.4660809389383478
[2019-03-23 18:31:22,202] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2761.3576 2123682283.7890 762.0000
[2019-03-23 18:31:22,573] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3119.7573 2108702091.6348 371.0000
[2019-03-23 18:31:22,912] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3364.9983 2097708504.4843 179.0000
[2019-03-23 18:31:23,046] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3521.1604 2103624814.4178 183.0000
[2019-03-23 18:31:23,061] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3611.7988 2175079859.6906 249.0000
[2019-03-23 18:31:24,076] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1025000, evaluation results [1025000.0, 3611.7988445000024, 2175079859.690643, 249.0, 3364.9983476886646, 2097708504.4842706, 179.0, 3521.160392809941, 2103624814.417848, 183.0, 2761.3575534078795, 2123682283.789029, 762.0, 3119.7572770063116, 2108702091.6347804, 371.0]
[2019-03-23 18:31:27,428] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.9878583e-04 2.2601387e-06 9.9907112e-01 2.1994618e-05 5.7229927e-06], sum to 1.0000
[2019-03-23 18:31:27,437] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0965
[2019-03-23 18:31:27,443] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.35, 79.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 293058.9815521742, 293058.9815521745, 123570.8226537702], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6762600.0000, 
sim time next is 6763200.0000, 
raw observation next is [17.46666666666667, 78.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 293506.8814832311, 293506.8814832314, 122668.107577898], 
processed observation next is [1.0, 0.2608695652173913, 0.4303030303030304, 0.78, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1087062524011967, 0.1087062524011968, 0.2991905062875561], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.49841872], dtype=float32), 1.0551153]. 
=============================================
[2019-03-23 18:31:28,574] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.6285208e-05 2.9181073e-09 9.9996352e-01 1.1486923e-07 9.8422611e-08], sum to 1.0000
[2019-03-23 18:31:28,580] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0558
[2019-03-23 18:31:28,585] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 86.0, 1.0, 2.0, 0.3002535366961456, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5841007465138408, 6.9112, 6.9112, 77.32846344354104, 672479.3426292185, 672479.3426292185, 178029.9522664936], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6688200.0000, 
sim time next is 6688800.0000, 
raw observation next is [18.8, 87.0, 1.0, 2.0, 0.2842939225086156, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5523211649433944, 6.911199999999999, 6.9112, 77.32846344354104, 636116.6291504581, 636116.6291504584, 174060.8526957166], 
processed observation next is [1.0, 0.43478260869565216, 0.49090909090909096, 0.87, 1.0, 1.0, 0.10536740313576952, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3604588070619921, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23559875153720672, 0.2355987515372068, 0.4245386651115039], 
reward next is 0.5755, 
noisyNet noise sample is [array([-0.06815575], dtype=float32), -0.26061654]. 
=============================================
[2019-03-23 18:31:30,104] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.0551335e-04 2.4427388e-06 9.9912900e-01 2.1731712e-05 4.1337826e-05], sum to 1.0000
[2019-03-23 18:31:30,113] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2786
[2019-03-23 18:31:30,117] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3655667519970566, 6.9112, 6.9112, 77.32846344354104, 420845.771529017, 420845.771529017, 155180.1910563816], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6715200.0000, 
sim time next is 6715800.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3561310329203553, 6.9112, 6.9112, 77.32846344354104, 410079.6129196742, 410079.6129196742, 153914.5648132337], 
processed observation next is [1.0, 0.7391304347826086, 0.4681818181818182, 0.93, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0801871898862219, 0.0, 0.0, 0.5084288129206541, 0.15188133811839785, 0.15188133811839785, 0.3754013775932529], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.05718402], dtype=float32), 0.043434363]. 
=============================================
[2019-03-23 18:31:31,335] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0361786e-04 2.2599857e-05 9.9982363e-01 4.5161905e-05 5.0395993e-06], sum to 1.0000
[2019-03-23 18:31:31,345] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0910
[2019-03-23 18:31:31,349] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.2, 91.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3156857163932118, 6.911200000000001, 6.9112, 77.32846344354104, 366009.9471613032, 366009.9471613029, 146547.8735991833], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6756000.0000, 
sim time next is 6756600.0000, 
raw observation next is [17.2, 90.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3106653740709059, 6.9112, 6.9112, 77.32846344354104, 360292.4509078863, 360292.4509078863, 145884.7738403738], 
processed observation next is [1.0, 0.17391304347826086, 0.41818181818181815, 0.905, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.015236248672722712, 0.0, 0.0, 0.5084288129206541, 0.13344164848440235, 0.13344164848440235, 0.3558165215618873], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.509452], dtype=float32), 0.16516757]. 
=============================================
[2019-03-23 18:31:31,573] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.5038906e-04 1.8334626e-04 9.9868053e-01 4.6391625e-04 1.2181215e-04], sum to 1.0000
[2019-03-23 18:31:31,580] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2212
[2019-03-23 18:31:31,586] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 95.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3505548816513631, 6.911200000000001, 6.9112, 77.32846344354104, 403832.1682905154, 403832.1682905151, 153064.7804492728], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6723000.0000, 
sim time next is 6723600.0000, 
raw observation next is [17.9, 95.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3484187455517559, 6.911200000000001, 6.9112, 77.32846344354104, 401428.3959962743, 401428.395996274, 152750.0386421158], 
processed observation next is [1.0, 0.8260869565217391, 0.44999999999999996, 0.9566666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.06916963650250844, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14867718370232383, 0.14867718370232372, 0.37256106985881904], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.48849365], dtype=float32), -0.33806977]. 
=============================================
[2019-03-23 18:31:31,769] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.2372214e-04 2.0555705e-04 9.9868971e-01 6.2826835e-04 5.2745523e-05], sum to 1.0000
[2019-03-23 18:31:31,776] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9326
[2019-03-23 18:31:31,780] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.2, 98.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3264483345397192, 6.9112, 6.9112, 77.32846344354104, 376943.185891102, 376943.185891102, 149309.0016594164], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6741600.0000, 
sim time next is 6742200.0000, 
raw observation next is [17.2, 99.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.326901955614935, 6.911200000000001, 6.9112, 77.32846344354104, 377326.9868698557, 377326.9868698554, 149499.5302425066], 
processed observation next is [1.0, 0.0, 0.41818181818181815, 0.9933333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0384313651641929, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13975073587772435, 0.1397507358777242, 0.36463300059147946], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.17423391], dtype=float32), -1.0030959]. 
=============================================
[2019-03-23 18:31:33,530] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.6595050e-05 3.2584494e-06 9.9989235e-01 1.3909328e-05 3.9491329e-06], sum to 1.0000
[2019-03-23 18:31:33,536] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2567
[2019-03-23 18:31:33,542] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.55, 49.5, 1.0, 2.0, 0.229589745472399, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4629463067927501, 6.911199999999999, 6.9112, 77.32846344354104, 523951.8991916077, 523951.899191608, 172462.5540477614], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6877800.0000, 
sim time next is 6878400.0000, 
raw observation next is [28.63333333333333, 49.66666666666666, 1.0, 2.0, 0.2317040797879056, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4674833902071875, 6.9112, 6.9112, 77.32846344354104, 528773.0568205522, 528773.0568205522, 173177.0898884635], 
processed observation next is [0.0, 0.6086956521739131, 0.9378787878787876, 0.4966666666666666, 1.0, 1.0, 0.039630099734882, 0.0, 1.0, -0.25, 1.0, 1.0, 0.23926198601026788, 0.0, 0.0, 0.5084288129206541, 0.19584187289650082, 0.19584187289650082, 0.4223831460694232], 
reward next is 0.5776, 
noisyNet noise sample is [array([-0.93705004], dtype=float32), 0.119822435]. 
=============================================
[2019-03-23 18:31:35,196] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.23895336e-04 1.09651766e-04 9.99108970e-01 3.89579101e-04
 6.78548604e-05], sum to 1.0000
[2019-03-23 18:31:35,204] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1490
[2019-03-23 18:31:35,209] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.6, 55.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 329561.1657807234, 329561.1657807237, 140974.709608677], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7239600.0000, 
sim time next is 7240200.0000, 
raw observation next is [21.41666666666667, 55.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 327275.9522154933, 327275.9522154936, 140578.1554204473], 
processed observation next is [1.0, 0.8260869565217391, 0.6098484848484851, 0.5566666666666668, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12121331563536789, 0.121213315635368, 0.342873549805969], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.06735288], dtype=float32), 0.11502141]. 
=============================================
[2019-03-23 18:31:35,230] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9600948e-05 1.3534692e-07 9.9989450e-01 3.8756434e-06 1.8123990e-06], sum to 1.0000
[2019-03-23 18:31:35,239] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8634
[2019-03-23 18:31:35,244] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.2, 96.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3169277374734328, 6.9112, 6.9112, 77.32846344354104, 366463.1238482465, 366463.1238482465, 147695.9133236848], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6848400.0000, 
sim time next is 6849000.0000, 
raw observation next is [17.2, 96.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3165979821281741, 6.9112, 6.9112, 77.32846344354104, 366082.6883812169, 366082.6883812169, 147657.6470094396], 
processed observation next is [0.0, 0.2608695652173913, 0.41818181818181815, 0.96, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.023711403040248706, 0.0, 0.0, 0.5084288129206541, 0.1355861808819322, 0.1355861808819322, 0.36014060246204777], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4178877], dtype=float32), 0.13534594]. 
=============================================
[2019-03-23 18:31:35,261] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[16.211895]
 [16.137184]
 [15.96745 ]
 [15.940182]
 [16.012947]], R is [[16.00584221]
 [15.84578419]
 [15.68732643]
 [15.53045368]
 [15.37514973]].
[2019-03-23 18:31:35,399] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.7840825e-04 1.4378758e-06 9.9927860e-01 2.3078992e-05 1.8464902e-05], sum to 1.0000
[2019-03-23 18:31:35,409] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5797
[2019-03-23 18:31:35,416] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.7, 68.0, 1.0, 2.0, 0.2006522443030159, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3964191801515447, 6.9112, 6.9112, 77.32846344354104, 453901.3000717233, 453901.3000717233, 161252.4394298004], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6814800.0000, 
sim time next is 6815400.0000, 
raw observation next is [22.7, 68.5, 1.0, 2.0, 0.200082115168752, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3954851301252704, 6.9112, 6.9112, 77.32846344354104, 452743.9081371912, 452743.9081371912, 161257.827509604], 
processed observation next is [1.0, 0.9130434782608695, 0.6681818181818181, 0.685, 1.0, 1.0, 0.00010264396093997291, 0.0, 1.0, -0.25, 1.0, 1.0, 0.13640732875038633, 0.0, 0.0, 0.5084288129206541, 0.16768292893970044, 0.16768292893970044, 0.39331177441366827], 
reward next is 0.6067, 
noisyNet noise sample is [array([-0.40736535], dtype=float32), 0.6584728]. 
=============================================
[2019-03-23 18:31:43,477] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.5075602e-04 3.5485823e-11 9.9984920e-01 8.1666487e-09 9.0596268e-09], sum to 1.0000
[2019-03-23 18:31:43,485] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0439
[2019-03-23 18:31:43,493] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.3, 56.0, 1.0, 2.0, 0.2541576243185195, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5145653777933208, 6.911199999999999, 6.9112, 77.32846344354104, 578906.5867699528, 578906.586769953, 180577.8915557944], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6964200.0000, 
sim time next is 6964800.0000, 
raw observation next is [28.3, 56.0, 1.0, 2.0, 0.254226965923221, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5147056889321667, 6.9112, 6.9112, 77.32846344354104, 579064.7920513038, 579064.7920513038, 180594.3666411058], 
processed observation next is [0.0, 0.6086956521739131, 0.9227272727272727, 0.56, 1.0, 1.0, 0.06778370740402627, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3067224127602382, 0.0, 0.0, 0.5084288129206541, 0.2144684415004829, 0.2144684415004829, 0.4404740649783068], 
reward next is 0.5595, 
noisyNet noise sample is [array([-0.97044206], dtype=float32), -0.26322728]. 
=============================================
[2019-03-23 18:31:46,410] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.9889637e-04 4.3207380e-09 9.9910057e-01 7.3146822e-08 4.4975684e-07], sum to 1.0000
[2019-03-23 18:31:46,420] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8155
[2019-03-23 18:31:46,423] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.3, 93.66666666666666, 1.0, 2.0, 0.336335470867336, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6665900495824614, 6.911200000000001, 6.9112, 77.32846344354104, 762500.2236949442, 762500.2236949439, 192662.0763338832], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7037400.0000, 
sim time next is 7038000.0000, 
raw observation next is [19.4, 93.0, 1.0, 2.0, 0.3499070168012812, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6937795621316948, 6.9112, 6.9112, 77.32846344354104, 793484.1813148888, 793484.1813148888, 196719.3935986516], 
processed observation next is [1.0, 0.4782608695652174, 0.5181818181818181, 0.93, 1.0, 1.0, 0.1873837710016015, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5625422316167069, 0.0, 0.0, 0.5084288129206541, 0.2938830301166255, 0.2938830301166255, 0.4798033990211015], 
reward next is 0.5202, 
noisyNet noise sample is [array([-0.5859969], dtype=float32), -1.4560969]. 
=============================================
[2019-03-23 18:31:46,440] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[41.644073]
 [41.78163 ]
 [42.35109 ]
 [42.758648]
 [43.224266]], R is [[41.24373627]
 [41.36139297]
 [41.4773674 ]
 [41.58987808]
 [41.69668198]].
[2019-03-23 18:31:49,655] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1455347e-04 3.4554986e-08 9.9988151e-01 3.3463448e-07 3.5404310e-06], sum to 1.0000
[2019-03-23 18:31:49,665] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3980
[2019-03-23 18:31:49,673] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 86.5, 1.0, 2.0, 0.3146380058101977, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6123454590033136, 6.9112, 6.9112, 77.32846344354104, 704930.9641878916, 704930.9641878916, 181612.7806002587], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7117800.0000, 
sim time next is 7118400.0000, 
raw observation next is [19.2, 86.0, 1.0, 2.0, 0.2797034399152094, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5454597008397271, 6.9112, 6.9112, 77.32846344354104, 627494.5582306082, 627494.5582306082, 173901.4631244354], 
processed observation next is [1.0, 0.391304347826087, 0.509090909090909, 0.86, 1.0, 1.0, 0.09962929989401174, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3506567154853244, 0.0, 0.0, 0.5084288129206541, 0.2324053919372623, 0.2324053919372623, 0.4241499100595985], 
reward next is 0.5759, 
noisyNet noise sample is [array([2.2491856], dtype=float32), 0.4319263]. 
=============================================
[2019-03-23 18:31:50,232] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.5190597e-04 1.9189030e-05 9.9957091e-01 4.5449659e-05 1.2633294e-05], sum to 1.0000
[2019-03-23 18:31:50,239] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5567
[2019-03-23 18:31:50,244] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.8, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3551553103159185, 6.911199999999999, 6.9112, 77.32846344354104, 408668.0784307547, 408668.078430755, 154063.110355961], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7070400.0000, 
sim time next is 7071000.0000, 
raw observation next is [18.8, 90.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3567970595630495, 6.911200000000001, 6.9112, 77.32846344354104, 410452.3538030108, 410452.3538030105, 154364.2388097203], 
processed observation next is [1.0, 0.8695652173913043, 0.49090909090909096, 0.905, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0811386565186422, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1520193902974114, 0.1520193902974113, 0.3764981434383422], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.03953157], dtype=float32), -1.5385143]. 
=============================================
[2019-03-23 18:31:50,258] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[9.66404 ]
 [9.833791]
 [9.785893]
 [9.888585]
 [9.674522]], R is [[10.02527046]
 [ 9.92501831]
 [ 9.82576847]
 [ 9.72751045]
 [ 9.63023567]].
[2019-03-23 18:31:50,806] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.8747765e-04 7.4679529e-06 9.9912494e-01 6.8938592e-05 1.1128225e-05], sum to 1.0000
[2019-03-23 18:31:50,821] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6205
[2019-03-23 18:31:50,825] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.9, 50.0, 1.0, 2.0, 0.3810318966635296, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7355842416082775, 6.911199999999999, 6.9112, 77.32846344354104, 848876.6099856443, 848876.6099856446, 197264.9880987589], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7135800.0000, 
sim time next is 7136400.0000, 
raw observation next is [24.0, 50.0, 1.0, 2.0, 0.3780447656745313, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7309092707509465, 6.911199999999999, 6.9112, 77.32846344354104, 843134.3747823632, 843134.3747823635, 196841.1028242687], 
processed observation next is [1.0, 0.6086956521739131, 0.7272727272727273, 0.5, 1.0, 1.0, 0.22255595709316414, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6155846725013522, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3122719906601345, 0.31227199066013467, 0.48010025079089924], 
reward next is 0.5199, 
noisyNet noise sample is [array([-0.28350365], dtype=float32), 1.041764]. 
=============================================
[2019-03-23 18:31:57,086] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.1766980e-04 2.6904521e-05 9.9964917e-01 8.2868915e-05 2.3395482e-05], sum to 1.0000
[2019-03-23 18:31:57,100] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8937
[2019-03-23 18:31:57,105] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.63333333333334, 46.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3135529679572515, 6.9112, 6.9112, 77.32846344354104, 363842.5462248254, 363842.5462248254, 145992.0788430937], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7233600.0000, 
sim time next is 7234200.0000, 
raw observation next is [23.55, 46.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3012887360195068, 6.911199999999999, 6.9112, 77.32846344354104, 349834.8318477535, 349834.8318477538, 144417.8537401024], 
processed observation next is [1.0, 0.7391304347826086, 0.7068181818181819, 0.46, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0018410514564382824, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1295684562399087, 0.1295684562399088, 0.35223866765878636], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2534876], dtype=float32), 0.46927118]. 
=============================================
[2019-03-23 18:31:58,757] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0426400e-03 4.7331087e-06 9.9778688e-01 1.3054712e-04 3.5239773e-05], sum to 1.0000
[2019-03-23 18:31:58,764] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7828
[2019-03-23 18:31:58,769] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.61666666666667, 63.0, 1.0, 2.0, 0.2052502248411738, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3831572043768974, 6.9112, 6.9112, 77.32846344354104, 445797.8556804247, 445797.8556804247, 137104.2148113007], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7289400.0000, 
sim time next is 7290000.0000, 
raw observation next is [18.8, 63.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3709746492107691, 6.9112, 6.9112, 77.32846344354104, 431617.3376204474, 431617.3376204474, 137160.1533373207], 
processed observation next is [1.0, 0.391304347826087, 0.49090909090909096, 0.63, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.10139235601538447, 0.0, 0.0, 0.5084288129206541, 0.1598582731927583, 0.1598582731927583, 0.33453695935931876], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3405724], dtype=float32), 1.1946042]. 
=============================================
[2019-03-23 18:31:58,794] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[22.684523]
 [22.704926]
 [22.343008]
 [21.687374]
 [21.49393 ]], R is [[22.45083427]
 [22.89192581]
 [22.66300583]
 [22.43637657]
 [22.21201324]].
[2019-03-23 18:31:59,895] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.0502602e-05 3.5435119e-06 9.9993122e-01 2.8945928e-05 5.7631410e-06], sum to 1.0000
[2019-03-23 18:31:59,900] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8464
[2019-03-23 18:31:59,906] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [15.5, 75.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 254370.2630565255, 254370.2630565252, 99973.14405657658], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7284000.0000, 
sim time next is 7284600.0000, 
raw observation next is [16.05, 72.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 277796.41524634, 277796.4152463397, 104971.7875398285], 
processed observation next is [1.0, 0.30434782608695654, 0.36590909090909096, 0.72, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10288756120234814, 0.10288756120234803, 0.25602875009714265], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.52975327], dtype=float32), 0.9445331]. 
=============================================
[2019-03-23 18:32:01,235] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.8836780e-05 3.7283532e-06 9.9989533e-01 2.4256427e-05 1.7805240e-05], sum to 1.0000
[2019-03-23 18:32:01,243] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3570
[2019-03-23 18:32:01,246] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 43.16666666666667, 1.0, 2.0, 0.4383944427350592, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8567868885486728, 6.911199999999999, 6.9112, 77.32844832601772, 985332.5828993893, 985332.5828993897, 219773.7090416757], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7308600.0000, 
sim time next is 7309200.0000, 
raw observation next is [25.9, 43.33333333333334, 1.0, 2.0, 0.429649495584236, 0.0, 2.0, 0.0, 1.0, 2.0, 0.838586147120193, 6.911199999999999, 6.9112, 77.32846334996225, 964785.4053839837, 964785.4053839841, 216254.1893069975], 
processed observation next is [1.0, 0.6086956521739131, 0.8136363636363636, 0.4333333333333334, 1.0, 1.0, 0.28706186948029494, 0.0, 1.0, -0.25, 1.0, 1.0, 0.7694087816002757, -8.881784197001253e-17, 0.0, 0.5084288123053806, 0.35732792791999396, 0.3573279279199941, 0.527449242212189], 
reward next is 0.4726, 
noisyNet noise sample is [array([0.2511441], dtype=float32), 0.5100383]. 
=============================================
[2019-03-23 18:32:04,035] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.9026136e-04 3.0436531e-05 9.9959868e-01 1.6189706e-04 1.8714030e-05], sum to 1.0000
[2019-03-23 18:32:04,041] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1936
[2019-03-23 18:32:04,047] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.4, 83.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3116185417948814, 6.9112, 6.9112, 77.32846344354104, 360843.0956374518, 360843.0956374518, 146565.428341724], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7350000.0000, 
sim time next is 7350600.0000, 
raw observation next is [18.3, 83.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3095452157646076, 6.9112, 6.9112, 77.32846344354104, 358512.8753445192, 358512.8753445192, 146261.954326541], 
processed observation next is [1.0, 0.043478260869565216, 0.4681818181818182, 0.835, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.013636022520867994, 0.0, 0.0, 0.5084288129206541, 0.132782546423896, 0.132782546423896, 0.3567364739671731], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.61599165], dtype=float32), 0.12381949]. 
=============================================
[2019-03-23 18:32:05,446] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.8543759e-04 4.3897326e-06 9.9966860e-01 3.2887408e-05 8.6942327e-06], sum to 1.0000
[2019-03-23 18:32:05,453] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9425
[2019-03-23 18:32:05,460] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.63333333333333, 51.66666666666667, 1.0, 2.0, 0.8205852616116756, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9735525863548986, 6.911200000000001, 6.9112, 77.32846344349771, 1483895.323069933, 1483895.323069932, 307423.1099190567], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7393200.0000, 
sim time next is 7393800.0000, 
raw observation next is [28.71666666666667, 51.33333333333333, 1.0, 2.0, 0.8252963896393103, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9736322602671846, 6.911199999999999, 6.9112, 77.32846344354077, 1489225.619924087, 1489225.619924087, 308299.5310661208], 
processed observation next is [1.0, 0.5652173913043478, 0.9416666666666668, 0.5133333333333333, 1.0, 1.0, 0.7816204870491378, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9623318003816925, -8.881784197001253e-17, 0.0, 0.5084288129206523, 0.5515650444163286, 0.5515650444163286, 0.7519500757710262], 
reward next is 0.2480, 
noisyNet noise sample is [array([1.607168], dtype=float32), -1.4280964]. 
=============================================
[2019-03-23 18:32:06,607] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.1355317e-04 1.0456221e-06 9.9914229e-01 1.9898825e-05 2.3186185e-05], sum to 1.0000
[2019-03-23 18:32:06,612] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8051
[2019-03-23 18:32:06,617] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.55, 52.0, 1.0, 2.0, 0.8077584086465569, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9733811538347826, 6.9112, 6.9112, 77.32846343654154, 1469351.057444371, 1469351.057444371, 305106.810559186], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7392600.0000, 
sim time next is 7393200.0000, 
raw observation next is [28.63333333333333, 51.66666666666667, 1.0, 2.0, 0.8205852616116756, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9735525863548986, 6.911200000000001, 6.9112, 77.32846344349771, 1483895.323069933, 1483895.323069932, 307423.1099190567], 
processed observation next is [1.0, 0.5652173913043478, 0.9378787878787876, 0.5166666666666667, 1.0, 1.0, 0.7757315770145945, 0.0, 1.0, -0.25, 1.0, 1.0, 0.962217980506998, 8.881784197001253e-17, 0.0, 0.5084288129203692, 0.5495908603962715, 0.5495908603962711, 0.7498124632172115], 
reward next is 0.2502, 
noisyNet noise sample is [array([-0.7553382], dtype=float32), 0.025541488]. 
=============================================
[2019-03-23 18:32:08,390] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2292787e-04 6.0556482e-07 9.9986374e-01 8.7796589e-06 3.9370652e-06], sum to 1.0000
[2019-03-23 18:32:08,399] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4325
[2019-03-23 18:32:08,405] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.66666666666666, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3391580364907288, 6.911200000000001, 6.9112, 77.32846344354104, 390661.2741461231, 390661.2741461229, 151723.0224621606], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7458000.0000, 
sim time next is 7458600.0000, 
raw observation next is [19.03333333333333, 88.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3454789007774994, 6.9112, 6.9112, 77.32846344354104, 397541.1448824763, 397541.1448824763, 152865.0677866751], 
processed observation next is [0.0, 0.30434782608695654, 0.5015151515151515, 0.885, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.06496985825357056, 0.0, 0.0, 0.5084288129206541, 0.1472374610675838, 0.1472374610675838, 0.37284162874798804], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.41000623], dtype=float32), -1.2306564]. 
=============================================
[2019-03-23 18:32:10,922] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.3167660e-03 9.5005621e-09 9.9767333e-01 1.5962260e-06 8.2635233e-06], sum to 1.0000
[2019-03-23 18:32:10,931] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6290
[2019-03-23 18:32:10,938] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.46666666666667, 75.33333333333333, 1.0, 2.0, 0.227840279004794, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4584953160521045, 6.9112, 6.9112, 77.32846344354104, 519845.165912204, 519845.165912204, 171278.3322338773], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7512000.0000, 
sim time next is 7512600.0000, 
raw observation next is [23.38333333333333, 75.66666666666667, 1.0, 2.0, 0.2272758824056229, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4572549777706304, 6.9112, 6.9112, 77.32846344354104, 518533.9149166713, 518533.9149166713, 171075.9244543622], 
processed observation next is [0.0, 0.9565217391304348, 0.6992424242424241, 0.7566666666666667, 1.0, 1.0, 0.03409485300702862, 0.0, 1.0, -0.25, 1.0, 1.0, 0.22464996824375774, 0.0, 0.0, 0.5084288129206541, 0.19204959811728567, 0.19204959811728567, 0.41725835232771263], 
reward next is 0.5827, 
noisyNet noise sample is [array([-0.71704507], dtype=float32), -0.46452993]. 
=============================================
[2019-03-23 18:32:14,252] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 18:32:14,254] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:32:14,255] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:32:14,255] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:32:14,256] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:32:14,256] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:32:14,258] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:32:14,258] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:32:14,259] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:32:14,260] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:32:14,261] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:32:14,261] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:32:14,263] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:32:14,280] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run43
[2019-03-23 18:32:14,281] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run43
[2019-03-23 18:32:14,281] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run43
[2019-03-23 18:32:14,304] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run43
[2019-03-23 18:32:14,373] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run43
[2019-03-23 18:32:14,398] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run6
[2019-03-23 18:32:20,717] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00996876], dtype=float32), 0.0063022105]
[2019-03-23 18:32:20,718] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [12.36666666666667, 86.5, 1.0, 2.0, 0.2097169913096514, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3914956788121421, 6.911200000000001, 6.9112, 95.55338769695034, 455463.4028605181, 455463.4028605177, 129697.9968193941]
[2019-03-23 18:32:20,720] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:32:20,722] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.7284703e-04 2.4611009e-09 9.9942565e-01 1.2771044e-07 1.4191606e-06], sampled 0.08750944513207415
[2019-03-23 18:32:22,459] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00996876], dtype=float32), 0.0063022105]
[2019-03-23 18:32:22,460] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.46997219166667, 88.68961026, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 282974.449331039, 282974.4493310386, 129022.8738934096]
[2019-03-23 18:32:22,461] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:32:22,464] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0336647e-03 1.7604012e-08 9.9896085e-01 6.5273525e-07 4.7277717e-06], sampled 0.12128007974735078
[2019-03-23 18:32:35,363] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00996876], dtype=float32), 0.0063022105]
[2019-03-23 18:32:35,363] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.82470349833334, 84.27265239833332, 1.0, 2.0, 0.2670418847241794, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5408752614077832, 6.911200000000001, 6.9112, 95.55338769695034, 607454.8610854638, 607454.8610854634, 189165.6777834683]
[2019-03-23 18:32:35,364] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:32:35,368] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.0751218e-04 2.0466367e-10 9.9969220e-01 1.8226530e-08 3.0142675e-07], sampled 0.16191841593523948
[2019-03-23 18:32:50,256] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00996876], dtype=float32), 0.0063022105]
[2019-03-23 18:32:50,256] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.15390118, 100.0, 1.0, 2.0, 0.3116155359355624, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6305164665880557, 6.9112, 6.9112, 95.55338769695034, 700265.1892309284, 700265.1892309284, 205515.7296469584]
[2019-03-23 18:32:50,257] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:32:50,259] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.1462862e-04 4.1320078e-10 9.9958485e-01 3.2808394e-08 4.9957430e-07], sampled 0.23325802019030162
[2019-03-23 18:32:55,779] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00996876], dtype=float32), 0.0063022105]
[2019-03-23 18:32:55,779] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.56849951666667, 56.27365708666667, 1.0, 2.0, 0.2624651235287914, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5306153793888791, 6.911200000000001, 6.9112, 95.55338769695034, 598644.2499571005, 598644.2499571, 186096.0506372417]
[2019-03-23 18:32:55,780] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:32:55,783] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.7473813e-04 2.9127586e-10 9.9962485e-01 2.4608934e-08 4.0749498e-07], sampled 0.46786948078073953
[2019-03-23 18:33:03,978] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00996876], dtype=float32), 0.0063022105]
[2019-03-23 18:33:03,980] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.24103094, 93.74023065, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3311933933112343, 6.9112, 6.9112, 95.55338769695034, 382779.1928499158, 382779.1928499158, 154048.3683128676]
[2019-03-23 18:33:03,981] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:33:03,983] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.5688758e-04 1.5076469e-10 9.9974293e-01 1.3396701e-08 2.3835113e-07], sampled 0.2881771007841505
[2019-03-23 18:33:28,175] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00996876], dtype=float32), 0.0063022105]
[2019-03-23 18:33:28,175] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.440979025, 73.387209775, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3102597347682518, 6.911200000000001, 6.9112, 95.55338769695034, 359416.3205279801, 359416.3205279798, 150777.7218054419]
[2019-03-23 18:33:28,176] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:33:28,180] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.8460008e-04 3.5714540e-10 9.9961483e-01 2.7589715e-08 4.4624642e-07], sampled 0.1923918124605899
[2019-03-23 18:33:39,279] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00996876], dtype=float32), 0.0063022105]
[2019-03-23 18:33:39,281] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.7, 93.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3251568046371243, 6.9112, 6.9112, 77.32846344354104, 375612.9729317323, 375612.9729317323, 148999.4508332388]
[2019-03-23 18:33:39,283] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:33:39,286] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.7263900e-04 1.7569005e-09 9.9932599e-01 9.8741062e-08 1.2905169e-06], sampled 0.33768433933236974
[2019-03-23 18:33:40,152] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00996876], dtype=float32), 0.0063022105]
[2019-03-23 18:33:40,153] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.76666666666667, 64.0, 1.0, 2.0, 0.4906658812020318, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8868433531307408, 7.041541714855033, 6.9112, 95.55292330302132, 1103284.146267299, 1050975.112359845, 255725.4808673637]
[2019-03-23 18:33:40,154] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:33:40,158] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.6610403e-04 2.2341203e-08 9.9912828e-01 9.0895247e-07 4.6049263e-06], sampled 0.769313726555574
[2019-03-23 18:33:40,718] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00996876], dtype=float32), 0.0063022105]
[2019-03-23 18:33:40,720] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.81260894833333, 91.68274168666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 337884.5473455743, 337884.5473455743, 147096.6152170924]
[2019-03-23 18:33:40,722] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:33:40,727] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.0284785e-04 3.4110077e-09 9.9919516e-01 1.6838918e-07 1.9449496e-06], sampled 0.633369343106681
[2019-03-23 18:33:50,980] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3617.8572 2175074105.4770 246.0000
[2019-03-23 18:33:51,686] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3361.7912 2097858945.5287 181.0000
[2019-03-23 18:33:51,935] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2764.6327 2123848429.4983 758.0000
[2019-03-23 18:33:51,937] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3118.0944 2108811919.5063 371.0000
[2019-03-23 18:33:51,953] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3518.6076 2104051035.7639 179.0000
[2019-03-23 18:33:52,970] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1050000, evaluation results [1050000.0, 3617.857243022161, 2175074105.476993, 246.0, 3361.791223487594, 2097858945.528674, 181.0, 3518.6076000430053, 2104051035.763917, 179.0, 2764.632673697584, 2123848429.4983068, 758.0, 3118.0944143453958, 2108811919.5063314, 371.0]
[2019-03-23 18:33:55,426] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.4657493e-04 1.1683718e-12 9.9965346e-01 4.6864153e-09 4.3389901e-09], sum to 1.0000
[2019-03-23 18:33:55,440] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4618
[2019-03-23 18:33:55,443] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.01666666666667, 96.0, 1.0, 2.0, 0.2183185537257525, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4366094989562476, 6.9112, 6.9112, 77.32846344354104, 497096.705571554, 497096.705571554, 167364.1704180957], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7596600.0000, 
sim time next is 7597200.0000, 
raw observation next is [20.03333333333333, 96.0, 1.0, 2.0, 0.2181602899735722, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4363683252285165, 6.9112, 6.9112, 77.32846344354104, 496772.7766315984, 496772.7766315984, 167382.7498341821], 
processed observation next is [0.0, 0.9565217391304348, 0.5469696969696969, 0.96, 1.0, 1.0, 0.02270036246696524, 0.0, 1.0, -0.25, 1.0, 1.0, 0.19481189318359501, 0.0, 0.0, 0.5084288129206541, 0.18398991727096237, 0.18398991727096237, 0.40825060935166363], 
reward next is 0.5917, 
noisyNet noise sample is [array([0.82114625], dtype=float32), 0.72898024]. 
=============================================
[2019-03-23 18:33:59,988] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.6792274e-05 4.5392256e-11 9.9998283e-01 2.1735809e-09 3.7142473e-07], sum to 1.0000
[2019-03-23 18:33:59,995] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0286
[2019-03-23 18:33:59,999] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.7, 85.0, 1.0, 2.0, 0.2416187700922489, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4879438732234001, 6.911199999999999, 6.9112, 77.32846344354104, 551343.9350745783, 551343.9350745785, 175812.8777559426], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7675200.0000, 
sim time next is 7675800.0000, 
raw observation next is [22.51666666666667, 86.33333333333334, 1.0, 2.0, 0.2407258971125623, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4861048204674006, 6.911200000000001, 6.9112, 77.32846344354104, 549313.8203650479, 549313.8203650477, 175574.1346785264], 
processed observation next is [1.0, 0.8695652173913043, 0.659848484848485, 0.8633333333333334, 1.0, 1.0, 0.050907371390702845, 0.0, 1.0, -0.25, 1.0, 1.0, 0.26586402923914376, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2034495630981659, 0.2034495630981658, 0.42822959677689365], 
reward next is 0.5718, 
noisyNet noise sample is [array([-0.15782924], dtype=float32), 0.40992907]. 
=============================================
[2019-03-23 18:34:00,475] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.5944761e-03 1.1453195e-07 9.9738687e-01 1.3796298e-05 4.7304984e-06], sum to 1.0000
[2019-03-23 18:34:00,483] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1140
[2019-03-23 18:34:00,486] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 42.0, 1.0, 2.0, 0.3671085816156366, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6853112971908351, 6.911199999999999, 6.9112, 77.32846344354104, 797638.2505409998, 797638.250541, 181184.4276951864], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 139200.0000, 
sim time next is 139800.0000, 
raw observation next is [23.0, 41.5, 1.0, 2.0, 0.3845310313075135, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7178351939246991, 6.911199999999999, 6.9112, 77.32846344354104, 835525.5767180694, 835525.5767180697, 185506.3185028941], 
processed observation next is [1.0, 0.6086956521739131, 0.6818181818181818, 0.415, 1.0, 1.0, 0.23066378913439184, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5969074198924273, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.30945391730298866, 0.30945391730298877, 0.45245443537291247], 
reward next is 0.5475, 
noisyNet noise sample is [array([0.07095088], dtype=float32), 0.5465223]. 
=============================================
[2019-03-23 18:34:01,321] A3C_AGENT_WORKER-Thread-22 INFO:Local step 66500, global step 1054151: loss 8.2065
[2019-03-23 18:34:01,325] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 66500, global step 1054154: learning rate 0.0000
[2019-03-23 18:34:10,189] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:34:10,189] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:34:10,259] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run6
[2019-03-23 18:34:11,714] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.4129282e-03 2.4567117e-07 9.9257457e-01 7.1383274e-06 5.1525794e-06], sum to 1.0000
[2019-03-23 18:34:11,721] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3138
[2019-03-23 18:34:11,725] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.13333333333333, 83.0, 1.0, 2.0, 0.2743161534636704, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5387667574825583, 6.9112, 6.9112, 77.32846344354104, 618344.628416449, 618344.628416449, 174383.9331002285], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7892400.0000, 
sim time next is 7893000.0000, 
raw observation next is [19.95, 85.5, 1.0, 2.0, 0.3193202529705321, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6292534450205659, 6.911200000000001, 6.9112, 77.32846344354104, 721403.306539613, 721403.3065396128, 186213.9069075097], 
processed observation next is [1.0, 0.34782608695652173, 0.5431818181818181, 0.855, 1.0, 1.0, 0.14915031621316513, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4703620643150942, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2671864098294863, 0.2671864098294862, 0.45418026075002366], 
reward next is 0.5458, 
noisyNet noise sample is [array([0.21429467], dtype=float32), -0.82046944]. 
=============================================
[2019-03-23 18:34:11,744] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[37.791515]
 [34.379375]
 [33.515705]
 [33.652096]
 [33.909492]], R is [[38.87345505]
 [39.05939484]
 [38.66880035]
 [38.28211212]
 [37.89929199]].
[2019-03-23 18:34:12,488] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.0074948e-03 2.3391954e-07 9.9696237e-01 6.0006573e-06 2.3840812e-05], sum to 1.0000
[2019-03-23 18:34:12,497] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0681
[2019-03-23 18:34:12,503] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.6, 93.0, 1.0, 2.0, 0.2971011869668644, 0.0, 2.0, 0.0, 1.0, 2.0, 0.595933229216953, 6.9112, 6.9112, 77.32846344354104, 677385.3875181315, 677385.3875181315, 186303.1155519671], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7909800.0000, 
sim time next is 7910400.0000, 
raw observation next is [20.7, 93.0, 1.0, 2.0, 0.3783033418921443, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7598198817834037, 6.9112, 6.9112, 77.32846344354104, 863051.7402242526, 863051.7402242526, 211233.3248750209], 
processed observation next is [1.0, 0.5652173913043478, 0.5772727272727273, 0.93, 1.0, 1.0, 0.22287917736518037, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6568855454048624, 0.0, 0.0, 0.5084288129206541, 0.3196487926756491, 0.3196487926756491, 0.51520323140249], 
reward next is 0.4848, 
noisyNet noise sample is [array([1.3131163], dtype=float32), -0.44839576]. 
=============================================
[2019-03-23 18:34:13,521] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:34:13,521] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:34:13,566] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:34:13,567] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:34:13,578] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run6
[2019-03-23 18:34:13,663] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run6
[2019-03-23 18:34:13,860] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.9480761e-04 9.7032931e-08 9.9949932e-01 1.7051270e-06 4.0383325e-06], sum to 1.0000
[2019-03-23 18:34:13,862] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8058
[2019-03-23 18:34:13,871] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 79.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3139283436277825, 6.9112, 6.9112, 77.32846344354104, 363272.1848208921, 363272.1848208921, 147074.3952958165], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7947600.0000, 
sim time next is 7948200.0000, 
raw observation next is [18.9, 78.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3076007842788582, 6.911199999999999, 6.9112, 77.32846344354104, 356240.9448535859, 356240.9448535861, 146067.1946834406], 
processed observation next is [1.0, 1.0, 0.49545454545454537, 0.785, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.010858263255511695, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1319410906865133, 0.13194109068651336, 0.35626145044741614], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1714906], dtype=float32), -2.087704]. 
=============================================
[2019-03-23 18:34:13,954] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.7122887e-05 4.4429319e-10 9.9990261e-01 4.2166409e-08 2.2262060e-07], sum to 1.0000
[2019-03-23 18:34:13,958] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8317
[2019-03-23 18:34:13,961] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.4, 93.5, 1.0, 2.0, 0.2173202067362011, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4350475809385106, 6.9112, 6.9112, 77.32846344354104, 495028.3709990679, 495028.3709990679, 167459.2487460155], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7938600.0000, 
sim time next is 7939200.0000, 
raw observation next is [20.3, 94.0, 1.0, 2.0, 0.2164286405889378, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4330921042399399, 6.911199999999999, 6.9112, 77.32846344354104, 492917.1106442205, 492917.1106442208, 167174.1098058719], 
processed observation next is [1.0, 0.9130434782608695, 0.5590909090909091, 0.94, 1.0, 1.0, 0.020535800736172227, 0.0, 1.0, -0.25, 1.0, 1.0, 0.19013157748562842, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18256189283119278, 0.1825618928311929, 0.4077417312338339], 
reward next is 0.5923, 
noisyNet noise sample is [array([-0.02565306], dtype=float32), 0.29796872]. 
=============================================
[2019-03-23 18:34:14,184] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:34:14,184] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:34:14,198] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run6
[2019-03-23 18:34:14,543] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:34:14,543] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:34:14,552] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run6
[2019-03-23 18:34:14,625] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67000, global step 1060780: loss 0.9111
[2019-03-23 18:34:14,626] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67000, global step 1060780: learning rate 0.0000
[2019-03-23 18:34:14,736] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:34:14,736] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:34:14,743] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run6
[2019-03-23 18:34:14,772] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:34:14,773] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:34:14,781] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run6
[2019-03-23 18:34:14,903] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:34:14,903] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:34:14,910] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run6
[2019-03-23 18:34:15,107] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:34:15,107] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:34:15,129] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run6
[2019-03-23 18:34:15,158] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:34:15,158] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:34:15,165] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run6
[2019-03-23 18:34:15,190] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:34:15,194] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:34:15,208] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run6
[2019-03-23 18:34:15,242] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:34:15,244] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:34:15,253] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run6
[2019-03-23 18:34:15,283] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:34:15,284] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:34:15,297] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run6
[2019-03-23 18:34:15,385] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:34:15,385] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:34:15,389] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run6
[2019-03-23 18:34:15,444] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:34:15,445] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:34:15,459] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run6
[2019-03-23 18:34:15,783] A3C_AGENT_WORKER-Thread-17 INFO:Local step 66500, global step 1061032: loss 0.0626
[2019-03-23 18:34:15,797] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 66500, global step 1061032: learning rate 0.0000
[2019-03-23 18:34:20,763] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6148839e-04 5.3777152e-05 9.9924868e-01 5.0920021e-04 2.6826374e-05], sum to 1.0000
[2019-03-23 18:34:20,769] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3573
[2019-03-23 18:34:20,777] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.66666666666667, 76.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3403970041734297, 6.9112, 6.9112, 77.32846344354104, 393189.1731936367, 393189.1731936367, 150809.8626511268], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 73200.0000, 
sim time next is 73800.0000, 
raw observation next is [19.5, 75.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3311178170010449, 6.911200000000001, 6.9112, 77.32846344354104, 382991.2166179075, 382991.2166179072, 149202.7335805588], 
processed observation next is [1.0, 0.8695652173913043, 0.5227272727272727, 0.755, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.04445402428720705, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14184859874737316, 0.14184859874737304, 0.3639091062940458], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.29025775], dtype=float32), 1.2037998]. 
=============================================
[2019-03-23 18:34:21,994] A3C_AGENT_WORKER-Thread-11 INFO:Local step 66500, global step 1064009: loss 0.3272
[2019-03-23 18:34:21,996] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 66500, global step 1064010: learning rate 0.0000
[2019-03-23 18:34:22,085] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.52763023e-04 3.90866177e-07 9.99827743e-01 7.09319056e-06
 1.19376855e-05], sum to 1.0000
[2019-03-23 18:34:22,093] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1809
[2019-03-23 18:34:22,098] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.33333333333333, 98.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 272832.1344458011, 272832.1344458011, 109891.1222473781], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 624000.0000, 
sim time next is 624600.0000, 
raw observation next is [14.5, 97.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 262190.0019095475, 262190.0019095475, 108139.1941870296], 
processed observation next is [1.0, 0.21739130434782608, 0.29545454545454547, 0.97, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.09710740811464721, 0.09710740811464721, 0.2637541321634868], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.99966466], dtype=float32), 0.34539646]. 
=============================================
[2019-03-23 18:34:22,672] A3C_AGENT_WORKER-Thread-16 INFO:Local step 66500, global step 1064346: loss 0.3056
[2019-03-23 18:34:22,675] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 66500, global step 1064347: learning rate 0.0000
[2019-03-23 18:34:23,697] A3C_AGENT_WORKER-Thread-19 INFO:Local step 66500, global step 1064859: loss 1.7395
[2019-03-23 18:34:23,699] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 66500, global step 1064859: learning rate 0.0000
[2019-03-23 18:34:23,738] A3C_AGENT_WORKER-Thread-14 INFO:Local step 66500, global step 1064880: loss 1.6389
[2019-03-23 18:34:23,741] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 66500, global step 1064880: learning rate 0.0000
[2019-03-23 18:34:23,945] A3C_AGENT_WORKER-Thread-10 INFO:Local step 66500, global step 1064982: loss 1.5150
[2019-03-23 18:34:23,948] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 66500, global step 1064982: learning rate 0.0000
[2019-03-23 18:34:24,019] A3C_AGENT_WORKER-Thread-9 INFO:Local step 66500, global step 1065016: loss 1.5507
[2019-03-23 18:34:24,026] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 66500, global step 1065020: learning rate 0.0000
[2019-03-23 18:34:24,405] A3C_AGENT_WORKER-Thread-21 INFO:Local step 66500, global step 1065213: loss 2.1281
[2019-03-23 18:34:24,411] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 66500, global step 1065213: learning rate 0.0000
[2019-03-23 18:34:24,727] A3C_AGENT_WORKER-Thread-18 INFO:Local step 66500, global step 1065377: loss 1.9782
[2019-03-23 18:34:24,733] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 66500, global step 1065379: learning rate 0.0000
[2019-03-23 18:34:24,825] A3C_AGENT_WORKER-Thread-3 INFO:Local step 66500, global step 1065422: loss 31.7853
[2019-03-23 18:34:24,828] A3C_AGENT_WORKER-Thread-15 INFO:Local step 66500, global step 1065424: loss 2.2654
[2019-03-23 18:34:24,828] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 66500, global step 1065424: learning rate 0.0000
[2019-03-23 18:34:24,832] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 66500, global step 1065425: learning rate 0.0000
[2019-03-23 18:34:24,859] A3C_AGENT_WORKER-Thread-13 INFO:Local step 66500, global step 1065443: loss 2.2799
[2019-03-23 18:34:24,861] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 66500, global step 1065443: learning rate 0.0000
[2019-03-23 18:34:24,915] A3C_AGENT_WORKER-Thread-2 INFO:Local step 66500, global step 1065469: loss 2.2532
[2019-03-23 18:34:24,917] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 66500, global step 1065470: learning rate 0.0000
[2019-03-23 18:34:25,099] A3C_AGENT_WORKER-Thread-20 INFO:Local step 66500, global step 1065558: loss 2.5959
[2019-03-23 18:34:25,101] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 66500, global step 1065559: learning rate 0.0000
[2019-03-23 18:34:25,141] A3C_AGENT_WORKER-Thread-12 INFO:Local step 66500, global step 1065578: loss 2.9728
[2019-03-23 18:34:25,142] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 66500, global step 1065578: learning rate 0.0000
[2019-03-23 18:34:29,115] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67500, global step 1067573: loss 2.9830
[2019-03-23 18:34:29,116] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67500, global step 1067573: learning rate 0.0000
[2019-03-23 18:34:31,423] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67000, global step 1068716: loss 0.5054
[2019-03-23 18:34:31,427] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67000, global step 1068718: learning rate 0.0000
[2019-03-23 18:34:35,790] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.8502954e-04 1.9825002e-06 9.9978298e-01 1.8956873e-05 1.1046337e-05], sum to 1.0000
[2019-03-23 18:34:35,797] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1171
[2019-03-23 18:34:35,802] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [12.0, 76.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3653324831310013, 6.9112, 6.9112, 77.32846344354104, 425049.9853888366, 425049.9853888366, 119977.2379012728], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 357600.0000, 
sim time next is 358200.0000, 
raw observation next is [12.0, 76.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.364821631586134, 6.9112, 6.9112, 77.32846344354104, 424455.3702577138, 424455.3702577138, 119893.1695960169], 
processed observation next is [1.0, 0.13043478260869565, 0.18181818181818182, 0.76, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.09260233083733432, 0.0, 0.0, 0.5084288129206541, 0.15720569268804213, 0.15720569268804213, 0.2924223648683339], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8787375], dtype=float32), 0.29154667]. 
=============================================
[2019-03-23 18:34:38,088] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67000, global step 1072043: loss 0.2675
[2019-03-23 18:34:38,089] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67000, global step 1072043: learning rate 0.0000
[2019-03-23 18:34:38,666] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67000, global step 1072330: loss 0.8579
[2019-03-23 18:34:38,668] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67000, global step 1072330: learning rate 0.0000
[2019-03-23 18:34:39,606] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67000, global step 1072794: loss 1.4206
[2019-03-23 18:34:39,609] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67000, global step 1072795: learning rate 0.0000
[2019-03-23 18:34:39,776] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67000, global step 1072882: loss 1.2819
[2019-03-23 18:34:39,777] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67000, global step 1072882: learning rate 0.0000
[2019-03-23 18:34:40,038] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67000, global step 1072999: loss 1.1835
[2019-03-23 18:34:40,039] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67000, global step 1072999: learning rate 0.0000
[2019-03-23 18:34:40,108] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67000, global step 1073034: loss 1.0047
[2019-03-23 18:34:40,111] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67000, global step 1073036: learning rate 0.0000
[2019-03-23 18:34:40,349] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67000, global step 1073146: loss 1.5780
[2019-03-23 18:34:40,351] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67000, global step 1073147: learning rate 0.0000
[2019-03-23 18:34:40,767] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67000, global step 1073359: loss 0.2694
[2019-03-23 18:34:40,768] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67000, global step 1073360: learning rate 0.0000
[2019-03-23 18:34:40,787] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67000, global step 1073370: loss 0.2789
[2019-03-23 18:34:40,789] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67000, global step 1073370: learning rate 0.0000
[2019-03-23 18:34:40,934] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67000, global step 1073442: loss 0.1139
[2019-03-23 18:34:40,935] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67000, global step 1073442: learning rate 0.0000
[2019-03-23 18:34:40,988] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67000, global step 1073465: loss 0.0343
[2019-03-23 18:34:40,994] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67000, global step 1073466: learning rate 0.0000
[2019-03-23 18:34:41,064] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67000, global step 1073501: loss 0.0517
[2019-03-23 18:34:41,067] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67000, global step 1073501: learning rate 0.0000
[2019-03-23 18:34:41,138] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67000, global step 1073541: loss 0.2566
[2019-03-23 18:34:41,143] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67000, global step 1073541: learning rate 0.0000
[2019-03-23 18:34:41,310] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67000, global step 1073625: loss 1.8046
[2019-03-23 18:34:41,316] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67000, global step 1073625: learning rate 0.0000
[2019-03-23 18:34:44,087] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 18:34:44,088] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:34:44,089] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:34:44,089] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:34:44,090] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:34:44,091] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:34:44,092] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:34:44,094] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:34:44,092] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:34:44,096] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:34:44,097] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:34:44,118] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run44
[2019-03-23 18:34:44,141] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run44
[2019-03-23 18:34:44,165] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run44
[2019-03-23 18:34:44,166] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run44
[2019-03-23 18:34:44,166] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run44
[2019-03-23 18:35:21,018] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01032489], dtype=float32), 0.006645343]
[2019-03-23 18:35:21,019] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.93333333333333, 70.16666666666667, 1.0, 2.0, 0.276950526740176, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5606139382952605, 6.9112, 6.9112, 77.32846344354104, 626327.474580209, 626327.474580209, 188994.5815842721]
[2019-03-23 18:35:21,020] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:35:21,022] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.8173570e-05 1.1117197e-05 9.9987161e-01 7.2170471e-05 6.9275420e-06], sampled 0.09113258989548523
[2019-03-23 18:35:35,083] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01032489], dtype=float32), 0.006645343]
[2019-03-23 18:35:35,084] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.02138219666667, 70.02245577333333, 1.0, 2.0, 0.2356843351666971, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4758628623555114, 6.9112, 6.9112, 95.55338769695034, 537759.4353970353, 537759.4353970353, 179090.9982954303]
[2019-03-23 18:35:35,086] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:35:35,088] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.0156010e-05 1.2407580e-05 9.9988842e-01 6.4156062e-05 4.9249793e-06], sampled 0.14711699005472434
[2019-03-23 18:36:20,883] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3118.8146 2109022190.6825 368.0000
[2019-03-23 18:36:21,668] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3615.6924 2175262156.1993 245.0000
[2019-03-23 18:36:21,683] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2760.7947 2124023427.3716 757.0000
[2019-03-23 18:36:21,716] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3363.0116 2098007323.8150 179.0000
[2019-03-23 18:36:21,855] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3519.8705 2104072647.3924 178.0000
[2019-03-23 18:36:22,874] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1075000, evaluation results [1075000.0, 3615.692385132093, 2175262156.1993065, 245.0, 3363.011604688327, 2098007323.81497, 179.0, 3519.870466329804, 2104072647.3924303, 178.0, 2760.794734038132, 2124023427.3715632, 757.0, 3118.8146269445274, 2109022190.6824877, 368.0]
[2019-03-23 18:36:24,080] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68000, global step 1075600: loss 30.6725
[2019-03-23 18:36:24,081] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68000, global step 1075600: learning rate 0.0000
[2019-03-23 18:36:26,046] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.037501e-04 3.530020e-08 9.997701e-01 8.215010e-07 2.527530e-05], sum to 1.0000
[2019-03-23 18:36:26,054] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5606
[2019-03-23 18:36:26,059] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 64.0, 1.0, 2.0, 0.2704048542853888, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5161199096967666, 6.9112, 6.9112, 77.32846344354104, 597162.263723091, 597162.263723091, 167491.4916348014], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 570000.0000, 
sim time next is 570600.0000, 
raw observation next is [21.0, 64.0, 1.0, 2.0, 0.2779860497621886, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5306003849283467, 6.911200000000001, 6.9112, 77.32846344354104, 613924.2630447859, 613924.2630447857, 169031.3105451979], 
processed observation next is [1.0, 0.6086956521739131, 0.5909090909090909, 0.64, 1.0, 1.0, 0.09748256220273574, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3294291213262096, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22737935668325404, 0.22737935668325396, 0.412271489134629], 
reward next is 0.5877, 
noisyNet noise sample is [array([-2.9760816], dtype=float32), 0.44814485]. 
=============================================
[2019-03-23 18:36:26,306] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67500, global step 1076707: loss 2.6980
[2019-03-23 18:36:26,311] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67500, global step 1076710: learning rate 0.0000
[2019-03-23 18:36:33,217] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67500, global step 1080098: loss 2.8074
[2019-03-23 18:36:33,218] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67500, global step 1080098: learning rate 0.0000
[2019-03-23 18:36:33,741] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67500, global step 1080361: loss 8.9537
[2019-03-23 18:36:33,742] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67500, global step 1080361: learning rate 0.0000
[2019-03-23 18:36:34,444] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67500, global step 1080707: loss 40.0992
[2019-03-23 18:36:34,446] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67500, global step 1080707: learning rate 0.0000
[2019-03-23 18:36:34,823] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67500, global step 1080894: loss 49.3421
[2019-03-23 18:36:34,827] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67500, global step 1080895: learning rate 0.0000
[2019-03-23 18:36:35,066] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67500, global step 1081013: loss 58.6568
[2019-03-23 18:36:35,067] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67500, global step 1081014: learning rate 0.0000
[2019-03-23 18:36:35,198] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67500, global step 1081079: loss 69.2337
[2019-03-23 18:36:35,201] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67500, global step 1081081: learning rate 0.0000
[2019-03-23 18:36:35,242] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67500, global step 1081100: loss 69.3099
[2019-03-23 18:36:35,243] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67500, global step 1081100: learning rate 0.0000
[2019-03-23 18:36:35,840] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67500, global step 1081397: loss 98.4676
[2019-03-23 18:36:35,842] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67500, global step 1081398: learning rate 0.0000
[2019-03-23 18:36:35,904] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67500, global step 1081429: loss 104.1896
[2019-03-23 18:36:35,906] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67500, global step 1081432: learning rate 0.0000
[2019-03-23 18:36:35,955] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67500, global step 1081455: loss 99.2418
[2019-03-23 18:36:35,958] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67500, global step 1081456: learning rate 0.0000
[2019-03-23 18:36:35,983] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67500, global step 1081468: loss 94.3354
[2019-03-23 18:36:35,986] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67500, global step 1081468: learning rate 0.0000
[2019-03-23 18:36:35,987] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67500, global step 1081468: loss 91.0289
[2019-03-23 18:36:35,997] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67500, global step 1081472: learning rate 0.0000
[2019-03-23 18:36:36,003] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67500, global step 1081474: loss 88.9115
[2019-03-23 18:36:36,006] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67500, global step 1081474: learning rate 0.0000
[2019-03-23 18:36:36,404] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67500, global step 1081675: loss 78.6015
[2019-03-23 18:36:36,405] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67500, global step 1081675: learning rate 0.0000
[2019-03-23 18:36:38,722] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.0998653e-04 1.6584178e-11 9.9968982e-01 1.9367155e-09 1.8253563e-07], sum to 1.0000
[2019-03-23 18:36:38,733] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7575
[2019-03-23 18:36:38,736] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.0, 55.0, 1.0, 2.0, 0.2658387498457143, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5385030574774258, 6.911199999999999, 6.9112, 77.32846344354104, 604198.2683923801, 604198.2683923803, 184543.959916233], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 835800.0000, 
sim time next is 836400.0000, 
raw observation next is [29.0, 55.0, 1.0, 2.0, 0.2651627741130516, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5371336108404737, 6.9112, 6.9112, 77.32846344354104, 602663.7507349009, 602663.7507349009, 184370.7592433648], 
processed observation next is [0.0, 0.6956521739130435, 0.9545454545454546, 0.55, 1.0, 1.0, 0.0814534676413145, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3387623012006768, 0.0, 0.0, 0.5084288129206541, 0.22320879656848183, 0.22320879656848183, 0.4496847786423532], 
reward next is 0.5503, 
noisyNet noise sample is [array([0.3425316], dtype=float32), -2.6650577]. 
=============================================
[2019-03-23 18:36:40,284] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68500, global step 1083620: loss 3.2038
[2019-03-23 18:36:40,287] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68500, global step 1083620: learning rate 0.0000
[2019-03-23 18:36:42,403] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68000, global step 1084669: loss 18.4692
[2019-03-23 18:36:42,405] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68000, global step 1084669: learning rate 0.0000
[2019-03-23 18:36:43,660] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.7444379e-04 2.6540643e-09 9.9932468e-01 1.3330681e-07 7.8322915e-07], sum to 1.0000
[2019-03-23 18:36:43,670] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7845
[2019-03-23 18:36:43,675] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.5, 66.0, 1.0, 2.0, 0.2589272201024942, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4917199564613383, 6.9112, 6.9112, 77.32846344354104, 569577.1817334956, 569577.1817334956, 164347.3048094841], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1078200.0000, 
sim time next is 1078800.0000, 
raw observation next is [20.66666666666667, 65.33333333333333, 1.0, 2.0, 0.2449455292131166, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4656975686824382, 6.9112, 6.9112, 77.32846344354104, 539279.2001628061, 539279.2001628061, 161971.8955272902], 
processed observation next is [1.0, 0.4782608695652174, 0.575757575757576, 0.6533333333333333, 1.0, 1.0, 0.05618191151639574, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2367108124034832, 0.0, 0.0, 0.5084288129206541, 0.1997330370973356, 0.1997330370973356, 0.39505340372509806], 
reward next is 0.6049, 
noisyNet noise sample is [array([-0.14116955], dtype=float32), -0.53693473]. 
=============================================
[2019-03-23 18:36:49,283] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68000, global step 1088098: loss 26.9134
[2019-03-23 18:36:49,286] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68000, global step 1088099: learning rate 0.0000
[2019-03-23 18:36:49,624] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68000, global step 1088261: loss 36.3684
[2019-03-23 18:36:49,629] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68000, global step 1088262: learning rate 0.0000
[2019-03-23 18:36:50,536] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68000, global step 1088720: loss 42.3027
[2019-03-23 18:36:50,538] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68000, global step 1088721: learning rate 0.0000
[2019-03-23 18:36:50,908] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68000, global step 1088909: loss 46.7624
[2019-03-23 18:36:50,911] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68000, global step 1088909: learning rate 0.0000
[2019-03-23 18:36:51,175] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68000, global step 1089037: loss 45.1453
[2019-03-23 18:36:51,180] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68000, global step 1089039: learning rate 0.0000
[2019-03-23 18:36:51,266] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68000, global step 1089081: loss 47.1891
[2019-03-23 18:36:51,268] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68000, global step 1089081: learning rate 0.0000
[2019-03-23 18:36:51,284] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68000, global step 1089089: loss 42.4464
[2019-03-23 18:36:51,286] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68000, global step 1089090: learning rate 0.0000
[2019-03-23 18:36:51,918] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68000, global step 1089405: loss 44.7451
[2019-03-23 18:36:51,921] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68000, global step 1089406: learning rate 0.0000
[2019-03-23 18:36:51,922] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68000, global step 1089406: loss 45.7951
[2019-03-23 18:36:51,928] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68000, global step 1089406: learning rate 0.0000
[2019-03-23 18:36:51,929] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68000, global step 1089406: loss 42.6790
[2019-03-23 18:36:51,930] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68000, global step 1089407: loss 44.4609
[2019-03-23 18:36:51,934] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68000, global step 1089407: learning rate 0.0000
[2019-03-23 18:36:51,934] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68000, global step 1089407: learning rate 0.0000
[2019-03-23 18:36:52,174] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68000, global step 1089527: loss 44.1025
[2019-03-23 18:36:52,181] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68000, global step 1089527: learning rate 0.0000
[2019-03-23 18:36:52,226] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68000, global step 1089557: loss 47.1987
[2019-03-23 18:36:52,227] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68000, global step 1089557: learning rate 0.0000
[2019-03-23 18:36:52,427] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68000, global step 1089656: loss 39.6106
[2019-03-23 18:36:52,429] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68000, global step 1089656: learning rate 0.0000
[2019-03-23 18:36:56,293] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69000, global step 1091589: loss 0.4160
[2019-03-23 18:36:56,294] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69000, global step 1091589: learning rate 0.0000
[2019-03-23 18:36:58,696] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68500, global step 1092793: loss 11.9914
[2019-03-23 18:36:58,699] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68500, global step 1092794: learning rate 0.0000
[2019-03-23 18:37:05,170] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68500, global step 1096010: loss 4.6251
[2019-03-23 18:37:05,171] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68500, global step 1096010: learning rate 0.0000
[2019-03-23 18:37:05,865] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68500, global step 1096356: loss 1.5751
[2019-03-23 18:37:05,869] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68500, global step 1096356: learning rate 0.0000
[2019-03-23 18:37:06,656] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68500, global step 1096739: loss 5.2348
[2019-03-23 18:37:06,659] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68500, global step 1096739: learning rate 0.0000
[2019-03-23 18:37:06,938] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68500, global step 1096886: loss 6.6657
[2019-03-23 18:37:06,942] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68500, global step 1096887: learning rate 0.0000
[2019-03-23 18:37:06,949] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.2615260e-03 3.8772692e-09 9.9773359e-01 4.6389621e-07 4.4453564e-06], sum to 1.0000
[2019-03-23 18:37:06,959] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8179
[2019-03-23 18:37:06,967] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.66666666666667, 80.66666666666667, 1.0, 2.0, 0.7080956746559086, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9847826406032475, 6.911200000000001, 6.9112, 77.32846344354104, 1344470.620719011, 1344470.620719011, 300033.786361895], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1335000.0000, 
sim time next is 1335600.0000, 
raw observation next is [26.0, 79.0, 1.0, 2.0, 0.7205117479563714, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9853041459631044, 6.9112, 6.9112, 77.32846344354104, 1358448.584571702, 1358448.584571702, 302275.0756548416], 
processed observation next is [1.0, 0.4782608695652174, 0.8181818181818182, 0.79, 1.0, 1.0, 0.6506396849454643, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9790059228044349, 0.0, 0.0, 0.5084288129206541, 0.5031291053969267, 0.5031291053969267, 0.7372562820849795], 
reward next is 0.2627, 
noisyNet noise sample is [array([-0.54755414], dtype=float32), -2.6615105]. 
=============================================
[2019-03-23 18:37:07,280] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68500, global step 1097052: loss 5.1024
[2019-03-23 18:37:07,280] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68500, global step 1097052: learning rate 0.0000
[2019-03-23 18:37:07,311] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68500, global step 1097066: loss 3.4696
[2019-03-23 18:37:07,314] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68500, global step 1097066: learning rate 0.0000
[2019-03-23 18:37:07,375] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.3293307e-04 2.4943658e-09 9.9956280e-01 2.0671746e-07 4.0650498e-06], sum to 1.0000
[2019-03-23 18:37:07,382] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68500, global step 1097101: loss 2.7205
[2019-03-23 18:37:07,382] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6810
[2019-03-23 18:37:07,385] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68500, global step 1097101: learning rate 0.0000
[2019-03-23 18:37:07,386] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 2 has been changed to 4 for the demand 1675846.609104627 W.
[2019-03-23 18:37:07,393] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 74.0, 1.0, 2.0, 0.5057155617369551, 1.0, 2.0, 0.4966462178100849, 1.0, 1.0, 0.9865530188920543, 6.911199999999998, 6.9112, 77.3421103, 1675846.609104627, 1675846.609104628, 356728.8013336748], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1339200.0000, 
sim time next is 1339800.0000, 
raw observation next is [27.0, 73.33333333333334, 1.0, 2.0, 0.4523960996545094, 1.0, 2.0, 0.4523960996545094, 1.0, 2.0, 0.9153689638611707, 6.9112, 6.9112, 77.3421103, 1526330.976927758, 1526330.976927758, 333980.7708924538], 
processed observation next is [1.0, 0.5217391304347826, 0.8636363636363636, 0.7333333333333334, 1.0, 1.0, 0.3154951245681367, 1.0, 1.0, 0.3154951245681367, 1.0, 1.0, 0.8790985198016726, 0.0, 0.0, 0.5085185399722538, 0.5653077692325029, 0.5653077692325029, 0.8145872460791556], 
reward next is 0.1854, 
noisyNet noise sample is [array([-0.20105775], dtype=float32), 0.8406339]. 
=============================================
[2019-03-23 18:37:07,853] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68500, global step 1097334: loss 6.8970
[2019-03-23 18:37:07,855] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68500, global step 1097335: learning rate 0.0000
[2019-03-23 18:37:07,962] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68500, global step 1097392: loss 1.6514
[2019-03-23 18:37:07,965] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68500, global step 1097392: learning rate 0.0000
[2019-03-23 18:37:07,999] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.5047192e-02 9.1472892e-11 9.8495126e-01 1.3356458e-07 1.4342179e-06], sum to 1.0000
[2019-03-23 18:37:08,000] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68500, global step 1097410: loss 3.4684
[2019-03-23 18:37:08,005] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68500, global step 1097411: learning rate 0.0000
[2019-03-23 18:37:08,010] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8417
[2019-03-23 18:37:08,013] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 83.0, 1.0, 2.0, 0.2783444675381308, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5633600044223629, 6.911200000000001, 6.9112, 77.32846344354104, 629184.3649028857, 629184.3649028854, 189483.2537506149], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1530000.0000, 
sim time next is 1530600.0000, 
raw observation next is [25.16666666666667, 82.33333333333334, 1.0, 2.0, 0.2809140393395031, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5684198987813707, 6.9112, 6.9112, 77.32846344354104, 634482.2191570983, 634482.2191570983, 190365.981936301], 
processed observation next is [0.0, 0.7391304347826086, 0.7803030303030305, 0.8233333333333335, 1.0, 1.0, 0.10114254917437886, 0.0, 1.0, -0.25, 1.0, 1.0, 0.383456998259101, 0.0, 0.0, 0.5084288129206541, 0.234993414502629, 0.234993414502629, 0.4643072730153683], 
reward next is 0.5357, 
noisyNet noise sample is [array([-0.26068187], dtype=float32), -1.6411079]. 
=============================================
[2019-03-23 18:37:08,084] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68500, global step 1097451: loss 4.8454
[2019-03-23 18:37:08,085] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68500, global step 1097451: learning rate 0.0000
[2019-03-23 18:37:08,156] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68500, global step 1097487: loss 3.3618
[2019-03-23 18:37:08,157] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68500, global step 1097487: learning rate 0.0000
[2019-03-23 18:37:08,316] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68500, global step 1097567: loss 1.9803
[2019-03-23 18:37:08,320] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68500, global step 1097567: learning rate 0.0000
[2019-03-23 18:37:08,731] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68500, global step 1097771: loss 3.6764
[2019-03-23 18:37:08,732] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68500, global step 1097772: learning rate 0.0000
[2019-03-23 18:37:10,490] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.9425242e-04 1.5857359e-11 9.9980384e-01 1.4441451e-08 1.8753473e-06], sum to 1.0000
[2019-03-23 18:37:10,496] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0633
[2019-03-23 18:37:10,500] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.2438402530436894, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4927878992906101, 6.9112, 6.9112, 77.32846344354104, 556294.4685365558, 556294.4685365558, 176728.1771812388], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1401000.0000, 
sim time next is 1401600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.243654788135904, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4924128853196464, 6.9112, 6.9112, 77.32846344354104, 555871.1985257255, 555871.1985257255, 176685.8907631925], 
processed observation next is [0.0, 0.21739130434782608, 0.5909090909090909, 1.0, 1.0, 1.0, 0.05456848516987998, 0.0, 1.0, -0.25, 1.0, 1.0, 0.27487555045663775, 0.0, 0.0, 0.5084288129206541, 0.20587822167619463, 0.20587822167619463, 0.43094119698339634], 
reward next is 0.5691, 
noisyNet noise sample is [array([-0.24223495], dtype=float32), -1.00936]. 
=============================================
[2019-03-23 18:37:12,196] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69500, global step 1099493: loss 0.0304
[2019-03-23 18:37:12,198] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69500, global step 1099493: learning rate 0.0000
[2019-03-23 18:37:13,213] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 18:37:13,214] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:37:13,215] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:37:13,217] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:37:13,218] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:37:13,217] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:37:13,219] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:37:13,222] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:37:13,221] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:37:13,224] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:37:13,223] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:37:13,242] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run45
[2019-03-23 18:37:13,269] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run45
[2019-03-23 18:37:13,295] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run45
[2019-03-23 18:37:13,296] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run45
[2019-03-23 18:37:13,296] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run45
[2019-03-23 18:37:20,448] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01008253], dtype=float32), 0.00705278]
[2019-03-23 18:37:20,450] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.4, 64.0, 1.0, 2.0, 0.2130555666209023, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3977280675164686, 6.9112, 6.9112, 95.55338769695034, 462716.9132466099, 462716.9132466099, 131252.7011397143]
[2019-03-23 18:37:20,450] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:37:20,452] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.6447824e-03 2.4225748e-09 9.9734217e-01 5.9381205e-07 1.2431259e-05], sampled 0.8569847499093286
[2019-03-23 18:37:38,340] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01008253], dtype=float32), 0.00705278]
[2019-03-23 18:37:38,341] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.46093955666667, 51.66378797333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 95.55338769695034, 311682.5143526029, 311682.5143526033, 122883.4725027533]
[2019-03-23 18:37:38,342] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:37:38,345] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.7668963e-03 3.8359340e-07 9.9712497e-01 2.3117029e-05 8.4692219e-05], sampled 0.8312784929820337
[2019-03-23 18:37:39,871] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01008253], dtype=float32), 0.00705278]
[2019-03-23 18:37:39,872] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.43322972, 81.58254670000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 301716.6804798215, 301716.6804798215, 122523.0866387284]
[2019-03-23 18:37:39,873] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:37:39,877] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.4129408e-03 4.2301376e-09 9.9757046e-01 9.1613634e-07 1.5550297e-05], sampled 0.9494413691170525
[2019-03-23 18:38:13,626] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01008253], dtype=float32), 0.00705278]
[2019-03-23 18:38:13,627] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.13333333333334, 67.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 302535.1078694084, 302535.1078694084, 132034.9653533409]
[2019-03-23 18:38:13,629] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:38:13,631] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.0325689e-03 4.4690118e-08 9.9792886e-01 5.0711637e-06 3.3464381e-05], sampled 0.556526754785762
[2019-03-23 18:38:15,675] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01008253], dtype=float32), 0.00705278]
[2019-03-23 18:38:15,676] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.084119325, 72.07737894, 1.0, 2.0, 0.2670724237177107, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5409995425456976, 6.911200000000001, 6.9112, 95.55338769695034, 606256.9434443474, 606256.943444347, 190011.9301294523]
[2019-03-23 18:38:15,677] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:38:15,680] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.9161860e-03 2.6001745e-10 9.9807930e-01 1.2882057e-07 4.4332155e-06], sampled 0.9850467882275012
[2019-03-23 18:38:28,682] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01008253], dtype=float32), 0.00705278]
[2019-03-23 18:38:28,683] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.9, 60.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 303030.5582161034, 303030.5582161034, 128279.7384218776]
[2019-03-23 18:38:28,685] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:38:28,688] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.7589989e-03 3.2435506e-07 9.9713945e-01 2.0728161e-05 8.0425249e-05], sampled 0.21858154756564774
[2019-03-23 18:38:50,611] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2766.4172 2122838203.5887 769.0000
[2019-03-23 18:38:50,739] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3524.3365 2103220589.1345 184.0000
[2019-03-23 18:38:50,746] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3127.0799 2108110857.7781 374.0000
[2019-03-23 18:38:50,750] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3620.6319 2174647188.3523 249.0000
[2019-03-23 18:38:50,838] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3360.7731 2096989363.1215 191.0000
[2019-03-23 18:38:51,853] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1100000, evaluation results [1100000.0, 3620.631909685262, 2174647188.3523035, 249.0, 3360.7731468981374, 2096989363.1215324, 191.0, 3524.3364825572735, 2103220589.1345017, 184.0, 2766.417202406398, 2122838203.588717, 769.0, 3127.079905599867, 2108110857.7781317, 374.0]
[2019-03-23 18:38:52,687] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.9368873e-03 3.6612263e-10 9.9301434e-01 1.6890177e-06 4.7108584e-05], sum to 1.0000
[2019-03-23 18:38:52,695] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9619
[2019-03-23 18:38:52,698] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.2413310020644437, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4877139092057465, 6.911199999999999, 6.9112, 77.32846344354104, 550567.9612094642, 550567.9612094646, 176158.3963247841], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1464000.0000, 
sim time next is 1464600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.241213561709674, 0.0, 2.0, 0.0, 1.0, 2.0, 0.487476329873358, 6.911200000000001, 6.9112, 77.32846344354104, 550299.9906495007, 550299.9906495004, 176131.7414585862], 
processed observation next is [0.0, 0.9565217391304348, 0.5909090909090909, 1.0, 1.0, 1.0, 0.051516952137092495, 0.0, 1.0, -0.25, 1.0, 1.0, 0.26782332839051143, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20381481135166693, 0.20381481135166682, 0.4295896133136249], 
reward next is 0.5704, 
noisyNet noise sample is [array([0.7038013], dtype=float32), 0.23668683]. 
=============================================
[2019-03-23 18:38:53,353] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69000, global step 1100748: loss 0.3749
[2019-03-23 18:38:53,356] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69000, global step 1100749: learning rate 0.0000
[2019-03-23 18:38:55,752] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.7654145e-03 1.0367616e-07 9.9013025e-01 1.7356993e-05 8.6842098e-05], sum to 1.0000
[2019-03-23 18:38:55,761] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1372
[2019-03-23 18:38:55,766] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.0, 94.0, 1.0, 2.0, 0.202990940230264, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4048030420739168, 6.911200000000001, 6.9112, 77.32846344354104, 461575.7033546082, 461575.7033546079, 163774.999749801], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1576800.0000, 
sim time next is 1577400.0000, 
raw observation next is [20.16666666666667, 94.00000000000001, 1.0, 2.0, 0.2062331126974285, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4118873845507562, 6.9112, 6.9112, 77.32846344354104, 469285.8974811581, 469285.8974811581, 164741.4228144152], 
processed observation next is [1.0, 0.2608695652173913, 0.5530303030303032, 0.9400000000000002, 1.0, 1.0, 0.007791390871785611, 0.0, 1.0, -0.25, 1.0, 1.0, 0.15983912078679458, 0.0, 0.0, 0.5084288129206541, 0.17380959165968818, 0.17380959165968818, 0.4018083483278419], 
reward next is 0.5982, 
noisyNet noise sample is [array([0.19189744], dtype=float32), -0.022336226]. 
=============================================
[2019-03-23 18:38:59,905] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69000, global step 1104027: loss 5.8267
[2019-03-23 18:38:59,907] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69000, global step 1104027: learning rate 0.0000
[2019-03-23 18:39:00,033] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8213997e-03 3.3730119e-06 9.9785393e-01 1.7767237e-04 1.4361861e-04], sum to 1.0000
[2019-03-23 18:39:00,041] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2297
[2019-03-23 18:39:00,045] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.86666666666667, 62.33333333333333, 1.0, 2.0, 0.4978666676673681, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9509682204558642, 6.951950992779256, 6.9112, 77.3283618200444, 1115222.27121936, 1101987.199659887, 257455.069265415], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1604400.0000, 
sim time next is 1605000.0000, 
raw observation next is [26.93333333333333, 62.16666666666667, 1.0, 2.0, 0.5199267344489675, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9590747321643478, 6.938410745227213, 6.9112, 77.3283719781311, 1140242.831544146, 1131405.348503471, 261799.5742792098], 
processed observation next is [1.0, 0.5652173913043478, 0.8606060606060605, 0.6216666666666667, 1.0, 1.0, 0.39990841806120936, 0.0, 1.0, -0.25, 1.0, 1.0, 0.941535331663354, 0.0027210745227212564, 0.0, 0.5084282115424846, 0.42231215983116516, 0.4190390179642485, 0.638535547022463], 
reward next is 0.2254, 
noisyNet noise sample is [array([-0.7617429], dtype=float32), 0.2108315]. 
=============================================
[2019-03-23 18:39:00,062] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[32.55869 ]
 [33.268288]
 [33.387993]
 [33.26573 ]
 [33.317825]], R is [[32.26287842]
 [32.10855484]
 [32.18167496]
 [32.29431534]
 [32.45390701]].
[2019-03-23 18:39:00,551] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69000, global step 1104345: loss 0.2311
[2019-03-23 18:39:00,553] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69000, global step 1104345: learning rate 0.0000
[2019-03-23 18:39:01,206] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69000, global step 1104671: loss 0.2276
[2019-03-23 18:39:01,209] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69000, global step 1104672: learning rate 0.0000
[2019-03-23 18:39:01,582] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69000, global step 1104853: loss 0.1215
[2019-03-23 18:39:01,589] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69000, global step 1104853: learning rate 0.0000
[2019-03-23 18:39:01,874] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69000, global step 1105000: loss 0.0186
[2019-03-23 18:39:01,879] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69000, global step 1105001: learning rate 0.0000
[2019-03-23 18:39:02,177] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69000, global step 1105145: loss 0.0090
[2019-03-23 18:39:02,179] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69000, global step 1105147: learning rate 0.0000
[2019-03-23 18:39:02,201] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69000, global step 1105161: loss 0.0074
[2019-03-23 18:39:02,203] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69000, global step 1105162: learning rate 0.0000
[2019-03-23 18:39:02,438] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69000, global step 1105275: loss 0.0613
[2019-03-23 18:39:02,440] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69000, global step 1105275: learning rate 0.0000
[2019-03-23 18:39:02,608] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69000, global step 1105338: loss 0.0540
[2019-03-23 18:39:02,609] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69000, global step 1105338: learning rate 0.0000
[2019-03-23 18:39:02,787] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69000, global step 1105424: loss 0.0350
[2019-03-23 18:39:02,789] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69000, global step 1105425: learning rate 0.0000
[2019-03-23 18:39:02,940] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69000, global step 1105503: loss 4.3298
[2019-03-23 18:39:02,941] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69000, global step 1105503: learning rate 0.0000
[2019-03-23 18:39:02,983] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69000, global step 1105518: loss 0.0476
[2019-03-23 18:39:02,985] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69000, global step 1105519: learning rate 0.0000
[2019-03-23 18:39:03,002] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69000, global step 1105531: loss 0.0766
[2019-03-23 18:39:03,004] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69000, global step 1105532: learning rate 0.0000
[2019-03-23 18:39:03,437] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69000, global step 1105744: loss 0.2165
[2019-03-23 18:39:03,439] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69000, global step 1105744: learning rate 0.0000
[2019-03-23 18:39:03,609] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.4624939e-04 1.0310626e-04 9.9818015e-01 8.9296204e-04 2.7748069e-04], sum to 1.0000
[2019-03-23 18:39:03,616] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0349
[2019-03-23 18:39:03,621] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [12.0, 72.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 196800.5818194564, 196800.5818194567, 83773.81987357195], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1723200.0000, 
sim time next is 1723800.0000, 
raw observation next is [12.0, 71.83333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 195663.5666720219, 195663.5666720219, 83517.2084118939], 
processed observation next is [1.0, 0.9565217391304348, 0.18181818181818182, 0.7183333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.07246798765630441, 0.07246798765630441, 0.20370050832169243], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8289034], dtype=float32), -1.3163464]. 
=============================================
[2019-03-23 18:39:04,396] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.0608906e-02 3.2481378e-08 9.7922528e-01 2.2882466e-06 1.6339832e-04], sum to 1.0000
[2019-03-23 18:39:04,402] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6586
[2019-03-23 18:39:04,408] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 77.16666666666667, 1.0, 2.0, 0.3001998677429752, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5725050489067454, 6.9112, 6.9112, 77.32846344354104, 662577.3983075338, 662577.3983075338, 173592.1658866812], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1681800.0000, 
sim time next is 1682400.0000, 
raw observation next is [19.0, 76.33333333333334, 1.0, 2.0, 0.3161005404121003, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6017794680389996, 6.911199999999999, 6.9112, 77.32846344354104, 696763.5983335066, 696763.598333507, 176816.137749644], 
processed observation next is [1.0, 0.4782608695652174, 0.5, 0.7633333333333334, 1.0, 1.0, 0.14512567551512534, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4311135257699995, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.25806059197537284, 0.25806059197537295, 0.4312588725601073], 
reward next is 0.5687, 
noisyNet noise sample is [array([-0.6154037], dtype=float32), -0.984645]. 
=============================================
[2019-03-23 18:39:06,951] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70000, global step 1107502: loss 9.2323
[2019-03-23 18:39:06,954] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70000, global step 1107502: learning rate 0.0000
[2019-03-23 18:39:07,957] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.2824612e-04 1.0196463e-06 9.9895549e-01 3.7327667e-05 2.7790180e-04], sum to 1.0000
[2019-03-23 18:39:07,963] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6747
[2019-03-23 18:39:07,969] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.66666666666667, 92.0, 1.0, 2.0, 0.3336916650299383, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6688132189009619, 6.9112, 6.9112, 77.32846344354104, 760668.8413801297, 760668.8413801297, 196171.8494678244], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1930800.0000, 
sim time next is 1931400.0000, 
raw observation next is [21.0, 91.0, 1.0, 2.0, 0.3951043202029101, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7939475765569345, 6.911199999999999, 6.9112, 77.32846344354104, 901537.3552347525, 901537.3552347528, 217275.573369689], 
processed observation next is [1.0, 0.34782608695652173, 0.5909090909090909, 0.91, 1.0, 1.0, 0.24388040025363758, 0.0, 1.0, -0.25, 1.0, 1.0, 0.705639395081335, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.33390272416101946, 0.3339027241610195, 0.5299404228529], 
reward next is 0.4701, 
noisyNet noise sample is [array([0.4409787], dtype=float32), -1.5675374]. 
=============================================
[2019-03-23 18:39:08,226] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6507490e-03 4.1056956e-05 9.9755055e-01 4.6523873e-04 2.9247362e-04], sum to 1.0000
[2019-03-23 18:39:08,232] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3284
[2019-03-23 18:39:08,235] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [8.0, 86.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3023116932078886, 6.9112, 6.9112, 77.32846344354104, 351701.2558859973, 351701.2558859973, 108776.5858089828], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1745400.0000, 
sim time next is 1746000.0000, 
raw observation next is [8.0, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.304059797925219, 6.9112, 6.9112, 77.32846344354104, 353735.6933803581, 353735.6933803581, 109049.2654037117], 
processed observation next is [1.0, 0.21739130434782608, 0.0, 0.87, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.005799711321741413, 0.0, 0.0, 0.5084288129206541, 0.131013219770503, 0.131013219770503, 0.26597381805783343], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.17631452], dtype=float32), -0.3564187]. 
=============================================
[2019-03-23 18:39:08,260] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[14.022284 ]
 [13.928717 ]
 [13.7803545]
 [13.555222 ]
 [13.498333 ]], R is [[14.08971405]
 [13.94881725]
 [13.80932903]
 [13.67123604]
 [13.53452396]].
[2019-03-23 18:39:08,541] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.3992849e-03 2.3735256e-04 9.9490660e-01 1.4885498e-03 9.6817175e-04], sum to 1.0000
[2019-03-23 18:39:08,550] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4439
[2019-03-23 18:39:08,559] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.2, 42.0, 1.0, 2.0, 0.2116887624025586, 0.0, 2.0, 0.0, 1.0, 2.0, 0.395176543474844, 6.9112, 6.9112, 77.32846344354104, 459788.7952596688, 459788.7952596688, 127585.0047706488], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1789200.0000, 
sim time next is 1789800.0000, 
raw observation next is [19.16666666666667, 42.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 346747.0527106086, 346747.0527106083, 115284.6255863261], 
processed observation next is [1.0, 0.7391304347826086, 0.5075757575757578, 0.4266666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12842483433726243, 0.12842483433726232, 0.28118201362518563], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.15953521], dtype=float32), -0.82382244]. 
=============================================
[2019-03-23 18:39:09,310] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69500, global step 1108675: loss 0.2852
[2019-03-23 18:39:09,314] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69500, global step 1108675: learning rate 0.0000
[2019-03-23 18:39:11,937] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.1590216e-03 2.4395663e-04 9.9578840e-01 2.4004620e-03 4.0812971e-04], sum to 1.0000
[2019-03-23 18:39:11,946] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1567
[2019-03-23 18:39:11,954] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.66666666666667, 64.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 217475.4848199894, 217475.4848199897, 89164.43876657696], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1813200.0000, 
sim time next is 1813800.0000, 
raw observation next is [14.33333333333333, 65.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 213336.9895967257, 213336.9895967254, 88205.43223057894], 
processed observation next is [1.0, 1.0, 0.28787878787878773, 0.6566666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07901369985063915, 0.07901369985063904, 0.21513520056238766], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.4771178], dtype=float32), 0.71635425]. 
=============================================
[2019-03-23 18:39:14,124] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.3975479e-03 1.5745003e-07 9.9732399e-01 8.9037749e-05 1.8929564e-04], sum to 1.0000
[2019-03-23 18:39:14,131] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2350
[2019-03-23 18:39:14,136] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 48.50000000000001, 1.0, 2.0, 0.2880684166931654, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5434987729362466, 6.911199999999999, 6.9112, 77.32846344354104, 630489.2147880815, 630489.2147880817, 168903.9209899359], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1865400.0000, 
sim time next is 1866000.0000, 
raw observation next is [23.0, 47.0, 1.0, 2.0, 0.284608983103726, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5343443721337899, 6.911199999999999, 6.9112, 77.32846344354104, 620491.4301388902, 620491.4301388904, 167310.9252067969], 
processed observation next is [1.0, 0.6086956521739131, 0.6818181818181818, 0.47, 1.0, 1.0, 0.1057612288796575, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3347776744768428, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22981164079218155, 0.22981164079218164, 0.408075427333651], 
reward next is 0.5919, 
noisyNet noise sample is [array([-0.04075886], dtype=float32), 0.61689013]. 
=============================================
[2019-03-23 18:39:14,157] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[36.239017]
 [36.369957]
 [36.48014 ]
 [36.15489 ]
 [34.935394]], R is [[36.27815247]
 [36.50341034]
 [36.73778915]
 [36.97018051]
 [37.2064476 ]].
[2019-03-23 18:39:14,866] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.3196691e-04 2.6351396e-05 9.9923623e-01 2.1769114e-04 8.7849206e-05], sum to 1.0000
[2019-03-23 18:39:14,873] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4543
[2019-03-23 18:39:14,879] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 49.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 309722.936166457, 309722.9361664567, 118599.4504605258], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1887000.0000, 
sim time next is 1887600.0000, 
raw observation next is [21.0, 49.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 311068.7184156796, 311068.7184156799, 118851.4696597669], 
processed observation next is [1.0, 0.8695652173913043, 0.5909090909090909, 0.49, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1152106364502517, 0.1152106364502518, 0.2898816333165046], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.04008116], dtype=float32), 1.2009355]. 
=============================================
[2019-03-23 18:39:16,003] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69500, global step 1112032: loss 0.1385
[2019-03-23 18:39:16,005] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69500, global step 1112033: learning rate 0.0000
[2019-03-23 18:39:16,627] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69500, global step 1112343: loss 0.1201
[2019-03-23 18:39:16,634] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69500, global step 1112344: learning rate 0.0000
[2019-03-23 18:39:17,371] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69500, global step 1112707: loss 0.1801
[2019-03-23 18:39:17,376] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69500, global step 1112709: learning rate 0.0000
[2019-03-23 18:39:17,607] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69500, global step 1112824: loss 0.2207
[2019-03-23 18:39:17,610] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69500, global step 1112825: learning rate 0.0000
[2019-03-23 18:39:17,935] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69500, global step 1112975: loss 0.2891
[2019-03-23 18:39:17,937] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69500, global step 1112976: learning rate 0.0000
[2019-03-23 18:39:18,101] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.5017720e-03 3.9358565e-05 9.9758685e-01 5.8706122e-04 2.8491355e-04], sum to 1.0000
[2019-03-23 18:39:18,110] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7076
[2019-03-23 18:39:18,113] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 61.0, 1.0, 2.0, 0.5297574475649749, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9574947377913836, 6.931512392890237, 6.9112, 77.32840194992967, 1152990.424789268, 1146393.380284947, 258514.7941884263], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1950600.0000, 
sim time next is 1951200.0000, 
raw observation next is [26.0, 61.0, 1.0, 2.0, 0.5458322126680415, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9632417299765307, 6.92157206121191, 6.9112, 77.32842572104944, 1171359.094909925, 1167990.463216928, 261558.3028722538], 
processed observation next is [1.0, 0.6086956521739131, 0.8181818181818182, 0.61, 1.0, 1.0, 0.4322902658350518, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9474881856807583, 0.001037206121190959, 0.0, 0.5084285648981179, 0.43383670181849077, 0.4325890604507141, 0.6379470801762287], 
reward next is 0.3102, 
noisyNet noise sample is [array([0.682191], dtype=float32), -0.90926725]. 
=============================================
[2019-03-23 18:39:18,347] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69500, global step 1113182: loss 0.2719
[2019-03-23 18:39:18,350] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69500, global step 1113183: learning rate 0.0000
[2019-03-23 18:39:18,360] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69500, global step 1113187: loss 0.2277
[2019-03-23 18:39:18,361] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69500, global step 1113188: learning rate 0.0000
[2019-03-23 18:39:18,511] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69500, global step 1113261: loss 0.1663
[2019-03-23 18:39:18,513] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69500, global step 1113262: learning rate 0.0000
[2019-03-23 18:39:18,588] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69500, global step 1113299: loss 0.1715
[2019-03-23 18:39:18,590] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69500, global step 1113299: learning rate 0.0000
[2019-03-23 18:39:18,903] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69500, global step 1113454: loss 0.2246
[2019-03-23 18:39:18,908] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69500, global step 1113454: learning rate 0.0000
[2019-03-23 18:39:18,940] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69500, global step 1113472: loss 0.2393
[2019-03-23 18:39:18,943] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69500, global step 1113472: learning rate 0.0000
[2019-03-23 18:39:19,055] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69500, global step 1113531: loss 0.2020
[2019-03-23 18:39:19,057] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69500, global step 1113531: learning rate 0.0000
[2019-03-23 18:39:19,103] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69500, global step 1113556: loss 0.2431
[2019-03-23 18:39:19,105] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69500, global step 1113556: learning rate 0.0000
[2019-03-23 18:39:19,585] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69500, global step 1113794: loss 0.3059
[2019-03-23 18:39:19,592] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69500, global step 1113794: learning rate 0.0000
[2019-03-23 18:39:21,393] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.95774502e-04 9.24896667e-05 9.98923361e-01 2.85747810e-04
 1.02625025e-04], sum to 1.0000
[2019-03-23 18:39:21,402] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5697
[2019-03-23 18:39:21,406] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.0, 47.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3066877052141322, 6.9112, 6.9112, 77.32846344354104, 355200.6497157856, 355200.6497157856, 145948.7243284117], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2043600.0000, 
sim time next is 2044200.0000, 
raw observation next is [24.0, 47.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3061109904586895, 6.9112, 6.9112, 77.32846344354104, 354533.91061439, 354533.91061439, 145883.8528443695], 
processed observation next is [0.0, 0.6521739130434783, 0.7272727272727273, 0.47, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.008729986369556448, 0.0, 0.0, 0.5084288129206541, 0.13130885578310741, 0.13130885578310741, 0.35581427523016956], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.05008246], dtype=float32), 0.5048906]. 
=============================================
[2019-03-23 18:39:22,723] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2824778e-04 8.8396613e-05 9.9907291e-01 6.0498173e-04 1.0536282e-04], sum to 1.0000
[2019-03-23 18:39:22,731] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6402
[2019-03-23 18:39:22,739] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [15.5, 79.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 239935.4393480825, 239935.4393480825, 99138.59361568149], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2082600.0000, 
sim time next is 2083200.0000, 
raw observation next is [15.33333333333333, 80.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 237710.5729800048, 237710.5729800051, 98437.61003562619], 
processed observation next is [0.0, 0.08695652173913043, 0.3333333333333332, 0.8033333333333332, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08804095295555733, 0.08804095295555744, 0.24009173179421023], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.37803808], dtype=float32), -2.2505412]. 
=============================================
[2019-03-23 18:39:22,996] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70500, global step 1115494: loss 13.9230
[2019-03-23 18:39:22,998] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70500, global step 1115494: learning rate 0.0000
[2019-03-23 18:39:23,781] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4501595e-03 4.7628116e-04 9.9519700e-01 2.5588672e-03 3.1753923e-04], sum to 1.0000
[2019-03-23 18:39:23,789] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6097
[2019-03-23 18:39:23,796] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 53.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 326288.0229123501, 326288.0229123498, 140532.1209019725], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2570400.0000, 
sim time next is 2571000.0000, 
raw observation next is [21.83333333333334, 53.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 325122.0539989893, 325122.053998989, 140288.8616509065], 
processed observation next is [1.0, 0.782608695652174, 0.628787878787879, 0.535, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12041557555518122, 0.1204155755551811, 0.34216795524611343], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6083068], dtype=float32), -0.02010603]. 
=============================================
[2019-03-23 18:39:23,813] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[0.6807513 ]
 [0.78871423]
 [0.9948004 ]
 [1.5281377 ]
 [3.0250242 ]], R is [[0.61091983]
 [0.60481066]
 [0.59876257]
 [0.59277493]
 [0.58684719]].
[2019-03-23 18:39:25,390] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70000, global step 1116689: loss 0.3837
[2019-03-23 18:39:25,394] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70000, global step 1116691: learning rate 0.0000
[2019-03-23 18:39:30,633] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.7719015e-04 1.7303316e-04 9.9777669e-01 9.3207537e-04 2.4100747e-04], sum to 1.0000
[2019-03-23 18:39:30,640] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1489
[2019-03-23 18:39:30,645] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.66666666666667, 91.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 251861.1803628172, 251861.1803628169, 103514.1198500021], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2184000.0000, 
sim time next is 2184600.0000, 
raw observation next is [14.78333333333333, 90.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 252860.802645816, 252860.8026458163, 103960.1170264844], 
processed observation next is [1.0, 0.2608695652173913, 0.3083333333333332, 0.9066666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09365214912808, 0.0936521491280801, 0.2535612610402058], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.0385901], dtype=float32), 0.6912909]. 
=============================================
[2019-03-23 18:39:32,004] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70000, global step 1119983: loss 0.3800
[2019-03-23 18:39:32,008] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70000, global step 1119984: learning rate 0.0000
[2019-03-23 18:39:32,704] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70000, global step 1120330: loss 0.3090
[2019-03-23 18:39:32,706] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70000, global step 1120330: learning rate 0.0000
[2019-03-23 18:39:33,408] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70000, global step 1120691: loss 0.1765
[2019-03-23 18:39:33,411] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70000, global step 1120691: learning rate 0.0000
[2019-03-23 18:39:33,583] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.3961197e-04 2.4805547e-04 9.9742150e-01 1.3042192e-03 3.8661633e-04], sum to 1.0000
[2019-03-23 18:39:33,589] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0422
[2019-03-23 18:39:33,598] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.0, 94.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 270374.2798821514, 270374.2798821514, 105021.2471598651], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2254200.0000, 
sim time next is 2254800.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999998, 6.9112, 77.32846344354104, 251327.8450168316, 251327.8450168322, 101681.5965774609], 
processed observation next is [1.0, 0.08695652173913043, 0.2727272727272727, 0.94, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -1.7763568394002506e-16, 0.0, 0.5084288129206541, 0.09308438704327096, 0.09308438704327118, 0.24800389409136805], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6906271], dtype=float32), -0.025940202]. 
=============================================
[2019-03-23 18:39:33,680] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70000, global step 1120820: loss 0.1439
[2019-03-23 18:39:33,686] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70000, global step 1120822: learning rate 0.0000
[2019-03-23 18:39:33,957] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70000, global step 1120959: loss 0.1480
[2019-03-23 18:39:33,960] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70000, global step 1120959: learning rate 0.0000
[2019-03-23 18:39:34,314] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70000, global step 1121141: loss 0.2280
[2019-03-23 18:39:34,316] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70000, global step 1121141: learning rate 0.0000
[2019-03-23 18:39:34,359] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70000, global step 1121160: loss 0.1825
[2019-03-23 18:39:34,362] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70000, global step 1121161: learning rate 0.0000
[2019-03-23 18:39:34,577] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70000, global step 1121266: loss 0.0946
[2019-03-23 18:39:34,578] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70000, global step 1121266: learning rate 0.0000
[2019-03-23 18:39:34,674] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70000, global step 1121317: loss 0.0977
[2019-03-23 18:39:34,677] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70000, global step 1121318: learning rate 0.0000
[2019-03-23 18:39:35,031] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70000, global step 1121492: loss 0.0911
[2019-03-23 18:39:35,033] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70000, global step 1121493: learning rate 0.0000
[2019-03-23 18:39:35,048] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70000, global step 1121500: loss 0.0907
[2019-03-23 18:39:35,052] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70000, global step 1121500: learning rate 0.0000
[2019-03-23 18:39:35,138] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70000, global step 1121548: loss 0.0718
[2019-03-23 18:39:35,139] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70000, global step 1121548: learning rate 0.0000
[2019-03-23 18:39:35,285] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70000, global step 1121623: loss 0.1129
[2019-03-23 18:39:35,287] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70000, global step 1121624: learning rate 0.0000
[2019-03-23 18:39:35,704] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70000, global step 1121835: loss 0.0514
[2019-03-23 18:39:35,706] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70000, global step 1121836: learning rate 0.0000
[2019-03-23 18:39:36,252] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.00274321 0.00117325 0.9904641  0.00453866 0.00108081], sum to 1.0000
[2019-03-23 18:39:36,258] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6970
[2019-03-23 18:39:36,263] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.33333333333333, 54.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 261678.4762256738, 261678.4762256741, 99161.79522657843], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2320800.0000, 
sim time next is 2321400.0000, 
raw observation next is [17.16666666666667, 54.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 259587.4369876808, 259587.4369876811, 98610.71322989716], 
processed observation next is [1.0, 0.8695652173913043, 0.4166666666666669, 0.545, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09614349518062251, 0.09614349518062264, 0.24051393470706622], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.43558535], dtype=float32), -1.2696409]. 
=============================================
[2019-03-23 18:39:39,013] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71000, global step 1123455: loss 20.5442
[2019-03-23 18:39:39,019] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71000, global step 1123458: learning rate 0.0000
[2019-03-23 18:39:41,333] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.3338219e-02 1.1976651e-05 9.7363979e-01 1.5490288e-04 2.8550199e-03], sum to 1.0000
[2019-03-23 18:39:41,342] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0474
[2019-03-23 18:39:41,348] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 56.66666666666667, 1.0, 2.0, 0.3136479762774366, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5861279931185646, 6.9112, 6.9112, 77.32846344354104, 681399.8235596066, 681399.8235596066, 172462.5398297912], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2555400.0000, 
sim time next is 2556000.0000, 
raw observation next is [21.0, 56.0, 1.0, 2.0, 0.3121664102945393, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5831047086399774, 6.911199999999999, 6.9112, 77.32846344354104, 678178.8773952522, 678178.8773952526, 172008.8893294165], 
processed observation next is [1.0, 0.6086956521739131, 0.5909090909090909, 0.56, 1.0, 1.0, 0.14020801286817408, 0.0, 1.0, -0.25, 1.0, 1.0, 0.40443529805711065, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2511773619982416, 0.2511773619982417, 0.419533876413211], 
reward next is 0.5805, 
noisyNet noise sample is [array([-1.057929], dtype=float32), -0.9664953]. 
=============================================
[2019-03-23 18:39:41,366] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[30.57875 ]
 [31.262497]
 [32.22699 ]
 [32.48388 ]
 [32.56431 ]], R is [[30.25881386]
 [30.5355854 ]
 [30.8117466 ]
 [31.09305573]
 [31.38136292]].
[2019-03-23 18:39:41,367] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70500, global step 1124630: loss 1.3550
[2019-03-23 18:39:41,369] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70500, global step 1124630: learning rate 0.0000
[2019-03-23 18:39:41,470] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.4683086e-03 2.0765706e-06 9.8961192e-01 2.1706207e-04 7.0052390e-04], sum to 1.0000
[2019-03-23 18:39:41,476] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0885
[2019-03-23 18:39:41,483] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 46.0, 1.0, 2.0, 0.2871596868855706, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5360642256151558, 6.911199999999999, 6.9112, 77.32846344354104, 623817.1149638058, 623817.1149638061, 159057.5173534362], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2394000.0000, 
sim time next is 2394600.0000, 
raw observation next is [21.83333333333334, 47.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3661178232647261, 6.9112, 6.9112, 77.32846344354104, 425964.0980225675, 425964.0980225675, 140426.9982103717], 
processed observation next is [1.0, 0.7391304347826086, 0.628787878787879, 0.47166666666666673, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.094454033235323, 0.0, 0.0, 0.5084288129206541, 0.15776448074909907, 0.15776448074909907, 0.3425048736838334], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.30437225], dtype=float32), 0.5243336]. 
=============================================
[2019-03-23 18:39:42,112] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 18:39:42,113] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:39:42,114] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:39:42,114] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:39:42,114] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:39:42,115] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:39:42,117] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:39:42,120] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:39:42,121] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:39:42,121] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:39:42,119] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:39:42,142] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run46
[2019-03-23 18:39:42,168] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run46
[2019-03-23 18:39:42,169] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run46
[2019-03-23 18:39:42,192] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run46
[2019-03-23 18:39:42,193] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run46
[2019-03-23 18:39:57,178] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00973371], dtype=float32), 0.0069513195]
[2019-03-23 18:39:57,179] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.03333333333333, 87.66666666666667, 1.0, 2.0, 0.308754840719765, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6184090769965649, 6.9112, 6.9112, 95.55338769695034, 703503.326329972, 703503.326329972, 193761.4550049533]
[2019-03-23 18:39:57,181] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:39:57,185] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.6580699e-03 8.6424770e-08 9.9522674e-01 9.7986194e-06 1.0535172e-04], sampled 0.09516785126734228
[2019-03-23 18:40:06,489] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00973371], dtype=float32), 0.0069513195]
[2019-03-23 18:40:06,490] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.6, 43.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3167863989418074, 6.911200000000001, 6.9112, 95.55338769695034, 367023.8056114382, 367023.8056114378, 151466.0135719558]
[2019-03-23 18:40:06,490] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:40:06,494] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.9939982e-03 7.1686777e-06 9.9762303e-01 1.6036999e-04 2.1541648e-04], sampled 0.7357170862663496
[2019-03-23 18:40:25,546] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00973371], dtype=float32), 0.0069513195]
[2019-03-23 18:40:25,547] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.5, 76.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.366607898143137, 6.911200000000001, 6.9112, 95.55338769695034, 421862.3096040499, 421862.3096040495, 160059.9068603394]
[2019-03-23 18:40:25,548] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:40:25,550] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.3669837e-03 8.1004117e-08 9.9654227e-01 7.9276997e-06 8.2824350e-05], sampled 0.436056816463843
[2019-03-23 18:40:42,091] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00973371], dtype=float32), 0.0069513195]
[2019-03-23 18:40:42,093] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.46666666666667, 67.83333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 339028.776709759, 339028.776709759, 148447.6307694145]
[2019-03-23 18:40:42,094] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:40:42,096] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.2011482e-03 6.8596893e-07 9.9661142e-01 3.4668425e-05 1.5203943e-04], sampled 0.2968109281172405
[2019-03-23 18:41:18,686] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3509.4025 2102728466.6049 203.0000
[2019-03-23 18:41:18,769] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3613.5835 2173574200.5309 259.0000
[2019-03-23 18:41:18,932] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3357.5866 2096028253.5171 197.0000
[2019-03-23 18:41:19,000] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3109.6557 2107232433.2201 391.0000
[2019-03-23 18:41:19,009] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2753.5450 2122719308.5728 771.0000
[2019-03-23 18:41:20,024] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1125000, evaluation results [1125000.0, 3613.583453744705, 2173574200.530935, 259.0, 3357.5866290318063, 2096028253.5171168, 197.0, 3509.402478847476, 2102728466.604911, 203.0, 2753.545018289399, 2122719308.5727527, 771.0, 3109.6556867815298, 2107232433.2200794, 391.0]
[2019-03-23 18:41:25,278] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.4403616e-03 3.9313505e-05 9.9759811e-01 4.5347310e-04 4.6864222e-04], sum to 1.0000
[2019-03-23 18:41:25,285] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5930
[2019-03-23 18:41:25,289] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [13.0, 96.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 223703.266864894, 223703.2668648943, 93479.60804337908], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2499600.0000, 
sim time next is 2500200.0000, 
raw observation next is [13.0, 97.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 224416.9321707524, 224416.9321707526, 93885.02377643113], 
processed observation next is [1.0, 0.9565217391304348, 0.22727272727272727, 0.97, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08311738228546385, 0.08311738228546393, 0.22898786286934422], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1109667], dtype=float32), -0.7745347]. 
=============================================
[2019-03-23 18:41:26,028] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70500, global step 1127995: loss 0.2870
[2019-03-23 18:41:26,032] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70500, global step 1127996: learning rate 0.0000
[2019-03-23 18:41:26,666] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70500, global step 1128315: loss 2.0215
[2019-03-23 18:41:26,668] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70500, global step 1128316: learning rate 0.0000
[2019-03-23 18:41:27,390] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70500, global step 1128677: loss 1.4218
[2019-03-23 18:41:27,391] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70500, global step 1128678: learning rate 0.0000
[2019-03-23 18:41:27,525] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7599752e-03 3.4583433e-04 9.9554044e-01 1.3820898e-03 9.7158365e-04], sum to 1.0000
[2019-03-23 18:41:27,527] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70500, global step 1128747: loss 3.1874
[2019-03-23 18:41:27,531] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70500, global step 1128747: learning rate 0.0000
[2019-03-23 18:41:27,532] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6134
[2019-03-23 18:41:27,539] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.73333333333333, 64.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 281725.0470497897, 281725.04704979, 114166.57470905], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2583600.0000, 
sim time next is 2584200.0000, 
raw observation next is [18.66666666666667, 64.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 281014.5682281378, 281014.5682281381, 113502.6569544156], 
processed observation next is [1.0, 0.9130434782608695, 0.4848484848484851, 0.64, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10407946971412511, 0.10407946971412521, 0.2768357486693063], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.65652543], dtype=float32), 0.7722433]. 
=============================================
[2019-03-23 18:41:28,034] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70500, global step 1128992: loss -7.2635
[2019-03-23 18:41:28,036] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70500, global step 1128992: learning rate 0.0000
[2019-03-23 18:41:28,085] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.41397247e-03 1.14261326e-04 9.93864954e-01 3.93142644e-03
 6.75469171e-04], sum to 1.0000
[2019-03-23 18:41:28,093] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3242
[2019-03-23 18:41:28,098] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.5, 80.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 299388.4113873733, 299388.4113873733, 128147.0248537647], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2593800.0000, 
sim time next is 2594400.0000, 
raw observation next is [17.43333333333333, 82.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 307416.8606169726, 307416.8606169729, 134879.0587869092], 
processed observation next is [0.0, 0.0, 0.42878787878787866, 0.8266666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11385809652480468, 0.11385809652480477, 0.3289733141144127], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4174906], dtype=float32), 1.1665158]. 
=============================================
[2019-03-23 18:41:28,260] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70500, global step 1129097: loss 0.8217
[2019-03-23 18:41:28,261] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70500, global step 1129098: learning rate 0.0000
[2019-03-23 18:41:28,390] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70500, global step 1129165: loss 0.6049
[2019-03-23 18:41:28,394] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70500, global step 1129166: learning rate 0.0000
[2019-03-23 18:41:28,590] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70500, global step 1129264: loss 0.8294
[2019-03-23 18:41:28,591] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70500, global step 1129264: learning rate 0.0000
[2019-03-23 18:41:28,598] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70500, global step 1129267: loss 0.7603
[2019-03-23 18:41:28,600] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70500, global step 1129267: learning rate 0.0000
[2019-03-23 18:41:29,012] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70500, global step 1129474: loss 0.7130
[2019-03-23 18:41:29,018] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70500, global step 1129474: learning rate 0.0000
[2019-03-23 18:41:29,150] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70500, global step 1129536: loss 0.9620
[2019-03-23 18:41:29,151] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70500, global step 1129537: learning rate 0.0000
[2019-03-23 18:41:29,277] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70500, global step 1129605: loss 2.3213
[2019-03-23 18:41:29,279] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70500, global step 1129607: learning rate 0.0000
[2019-03-23 18:41:29,342] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70500, global step 1129635: loss 0.7908
[2019-03-23 18:41:29,348] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70500, global step 1129635: learning rate 0.0000
[2019-03-23 18:41:29,956] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70500, global step 1129941: loss 0.4515
[2019-03-23 18:41:29,961] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70500, global step 1129942: learning rate 0.0000
[2019-03-23 18:41:33,029] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71500, global step 1131482: loss 2.8269
[2019-03-23 18:41:33,031] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71500, global step 1131482: learning rate 0.0000
[2019-03-23 18:41:33,788] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.9444731e-04 3.6910056e-05 9.9817622e-01 7.9647935e-04 2.9588043e-04], sum to 1.0000
[2019-03-23 18:41:33,798] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3241
[2019-03-23 18:41:33,809] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.66666666666667, 66.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3720380378095692, 6.9112, 6.9112, 77.32846344354104, 426622.4230798346, 426622.4230798346, 157512.035705966], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2672400.0000, 
sim time next is 2673000.0000, 
raw observation next is [22.5, 67.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3707520258480581, 6.9112, 6.9112, 77.32846344354104, 425274.655629214, 425274.655629214, 157232.3844048885], 
processed observation next is [0.0, 0.9565217391304348, 0.6590909090909091, 0.67, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.10107432264008304, 0.0, 0.0, 0.5084288129206541, 0.15750913171452371, 0.15750913171452371, 0.383493620499728], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.37139338], dtype=float32), 0.91797245]. 
=============================================
[2019-03-23 18:41:33,828] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[8.081018 ]
 [7.8990073]
 [7.7463083]
 [7.577555 ]
 [7.420303 ]], R is [[8.07899475]
 [7.99820471]
 [7.9182229 ]
 [7.83904076]
 [7.76065063]].
[2019-03-23 18:41:35,279] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71000, global step 1132607: loss 3.0794
[2019-03-23 18:41:35,280] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71000, global step 1132607: learning rate 0.0000
[2019-03-23 18:41:37,956] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.9056564e-02 1.8470979e-06 9.7021532e-01 4.9481914e-05 6.7667116e-04], sum to 1.0000
[2019-03-23 18:41:37,961] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9869
[2019-03-23 18:41:37,973] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 88.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3131646093335355, 6.9112, 6.9112, 77.32846344354104, 362298.4303757624, 362298.4303757624, 147080.6544663525], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2779800.0000, 
sim time next is 2780400.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3083124403230099, 6.9112, 6.9112, 77.32846344354104, 356684.2885806834, 356684.2885806834, 146538.088434998], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.011874914747157041, 0.0, 0.0, 0.5084288129206541, 0.1321052920669198, 0.1321052920669198, 0.3574099717926781], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8061412], dtype=float32), -1.5560708]. 
=============================================
[2019-03-23 18:41:42,090] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71000, global step 1135989: loss 1.4240
[2019-03-23 18:41:42,091] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71000, global step 1135989: learning rate 0.0000
[2019-03-23 18:41:42,730] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71000, global step 1136311: loss 0.4415
[2019-03-23 18:41:42,737] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71000, global step 1136312: learning rate 0.0000
[2019-03-23 18:41:43,348] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71000, global step 1136618: loss 0.9511
[2019-03-23 18:41:43,350] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71000, global step 1136618: learning rate 0.0000
[2019-03-23 18:41:43,760] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71000, global step 1136824: loss 0.0910
[2019-03-23 18:41:43,763] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71000, global step 1136825: learning rate 0.0000
[2019-03-23 18:41:44,086] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71000, global step 1136983: loss 0.3493
[2019-03-23 18:41:44,089] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71000, global step 1136983: learning rate 0.0000
[2019-03-23 18:41:44,388] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71000, global step 1137133: loss 0.1902
[2019-03-23 18:41:44,392] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71000, global step 1137133: learning rate 0.0000
[2019-03-23 18:41:44,454] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71000, global step 1137162: loss 0.3235
[2019-03-23 18:41:44,456] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71000, global step 1137163: learning rate 0.0000
[2019-03-23 18:41:44,493] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71000, global step 1137180: loss 0.7904
[2019-03-23 18:41:44,496] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71000, global step 1137181: learning rate 0.0000
[2019-03-23 18:41:44,761] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71000, global step 1137319: loss 0.3456
[2019-03-23 18:41:44,765] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71000, global step 1137319: learning rate 0.0000
[2019-03-23 18:41:44,974] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.8354414e-04 7.2727885e-10 9.9940574e-01 8.7600256e-08 1.0562599e-05], sum to 1.0000
[2019-03-23 18:41:44,983] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5712
[2019-03-23 18:41:44,987] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 54.0, 1.0, 2.0, 0.2231359360330784, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4484955348441341, 6.9112, 6.9112, 77.32846344354104, 508972.5469429138, 508972.5469429138, 169886.6300821014], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2836800.0000, 
sim time next is 2837400.0000, 
raw observation next is [26.83333333333333, 55.16666666666666, 1.0, 2.0, 0.2238558455079446, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4500954512257889, 6.911199999999999, 6.9112, 77.32846344354104, 510657.9851140909, 510657.9851140912, 170152.016182977], 
processed observation next is [1.0, 0.8695652173913043, 0.8560606060606059, 0.5516666666666665, 1.0, 1.0, 0.029819806884930737, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2144220731796985, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18913258707929292, 0.18913258707929304, 0.4150049175194561], 
reward next is 0.5850, 
noisyNet noise sample is [array([-0.06955301], dtype=float32), -0.091796614]. 
=============================================
[2019-03-23 18:41:45,073] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71000, global step 1137475: loss 0.3637
[2019-03-23 18:41:45,074] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71000, global step 1137475: learning rate 0.0000
[2019-03-23 18:41:45,127] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71000, global step 1137499: loss 0.3617
[2019-03-23 18:41:45,130] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71000, global step 1137500: learning rate 0.0000
[2019-03-23 18:41:45,335] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71000, global step 1137604: loss 1.2343
[2019-03-23 18:41:45,340] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71000, global step 1137604: learning rate 0.0000
[2019-03-23 18:41:45,360] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71000, global step 1137615: loss 0.3053
[2019-03-23 18:41:45,362] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71000, global step 1137615: learning rate 0.0000
[2019-03-23 18:41:46,037] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71000, global step 1137955: loss 0.3097
[2019-03-23 18:41:46,038] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71000, global step 1137955: learning rate 0.0000
[2019-03-23 18:41:48,997] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72000, global step 1139436: loss 0.0134
[2019-03-23 18:41:48,999] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72000, global step 1139436: learning rate 0.0000
[2019-03-23 18:41:51,354] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71500, global step 1140618: loss 5.2425
[2019-03-23 18:41:51,358] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71500, global step 1140619: learning rate 0.0000
[2019-03-23 18:41:58,154] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71500, global step 1143995: loss 0.2338
[2019-03-23 18:41:58,157] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71500, global step 1143995: learning rate 0.0000
[2019-03-23 18:41:58,653] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71500, global step 1144246: loss 0.3256
[2019-03-23 18:41:58,656] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71500, global step 1144249: learning rate 0.0000
[2019-03-23 18:41:59,153] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1004179e-02 4.1852810e-10 9.8894113e-01 7.3798037e-06 4.7278714e-05], sum to 1.0000
[2019-03-23 18:41:59,159] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6911
[2019-03-23 18:41:59,166] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 88.0, 1.0, 2.0, 0.2375210839824674, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4788641403508565, 6.9112, 6.9112, 77.32846344354104, 542060.3791807725, 542060.3791807725, 174091.3752176467], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3115800.0000, 
sim time next is 3116400.0000, 
raw observation next is [22.0, 88.0, 1.0, 2.0, 0.2369206231505888, 0.0, 2.0, 0.0, 1.0, 2.0, 0.477650962358276, 6.911199999999999, 6.9112, 77.32846344354104, 540689.1797453128, 540689.1797453131, 173958.4973455843], 
processed observation next is [1.0, 0.043478260869565216, 0.6363636363636364, 0.88, 1.0, 1.0, 0.04615077893823597, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2537870890832514, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20025525175752326, 0.20025525175752337, 0.4242890179160593], 
reward next is 0.5757, 
noisyNet noise sample is [array([-0.18992977], dtype=float32), -1.581031]. 
=============================================
[2019-03-23 18:41:59,483] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71500, global step 1144666: loss 0.4443
[2019-03-23 18:41:59,485] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71500, global step 1144666: learning rate 0.0000
[2019-03-23 18:41:59,623] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71500, global step 1144729: loss 0.3638
[2019-03-23 18:41:59,626] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71500, global step 1144731: learning rate 0.0000
[2019-03-23 18:42:00,313] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71500, global step 1145076: loss 0.6081
[2019-03-23 18:42:00,315] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71500, global step 1145076: learning rate 0.0000
[2019-03-23 18:42:00,377] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71500, global step 1145103: loss 0.3741
[2019-03-23 18:42:00,381] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71500, global step 1145105: learning rate 0.0000
[2019-03-23 18:42:00,526] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71500, global step 1145179: loss 0.5461
[2019-03-23 18:42:00,528] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71500, global step 1145179: learning rate 0.0000
[2019-03-23 18:42:00,586] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71500, global step 1145205: loss 0.5005
[2019-03-23 18:42:00,587] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71500, global step 1145205: learning rate 0.0000
[2019-03-23 18:42:00,817] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71500, global step 1145320: loss 0.4680
[2019-03-23 18:42:00,819] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71500, global step 1145320: learning rate 0.0000
[2019-03-23 18:42:01,205] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71500, global step 1145513: loss 0.8559
[2019-03-23 18:42:01,210] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71500, global step 1145514: learning rate 0.0000
[2019-03-23 18:42:01,313] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71500, global step 1145574: loss 0.9201
[2019-03-23 18:42:01,316] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71500, global step 1145575: learning rate 0.0000
[2019-03-23 18:42:01,320] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71500, global step 1145575: loss 0.9076
[2019-03-23 18:42:01,327] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71500, global step 1145575: learning rate 0.0000
[2019-03-23 18:42:01,387] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71500, global step 1145607: loss 1.0472
[2019-03-23 18:42:01,389] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71500, global step 1145608: learning rate 0.0000
[2019-03-23 18:42:02,071] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71500, global step 1145949: loss 1.9798
[2019-03-23 18:42:02,075] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71500, global step 1145950: learning rate 0.0000
[2019-03-23 18:42:02,239] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.0744588e-02 5.4409703e-08 9.7902232e-01 5.1943684e-05 1.8105695e-04], sum to 1.0000
[2019-03-23 18:42:02,246] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9177
[2019-03-23 18:42:02,249] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.66666666666666, 73.66666666666667, 1.0, 2.0, 0.2302068884861653, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4634284072227872, 6.9112, 6.9112, 77.32846344354104, 525281.2163482552, 525281.2163482552, 171911.6579149079], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3172800.0000, 
sim time next is 3173400.0000, 
raw observation next is [23.5, 73.5, 1.0, 2.0, 0.2190206806377628, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4401331828200887, 6.9112, 6.9112, 77.32846344354104, 499554.1619126612, 499554.1619126612, 168994.0923792404], 
processed observation next is [1.0, 0.7391304347826086, 0.7045454545454546, 0.735, 1.0, 1.0, 0.0237758507972035, 0.0, 1.0, -0.25, 1.0, 1.0, 0.20019026117155528, 0.0, 0.0, 0.5084288129206541, 0.1850200599676523, 0.1850200599676523, 0.4121807131200986], 
reward next is 0.5878, 
noisyNet noise sample is [array([-0.07133977], dtype=float32), 1.4495529]. 
=============================================
[2019-03-23 18:42:03,865] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.5897913e-04 4.7825884e-05 9.9899834e-01 6.5184070e-04 4.3028132e-05], sum to 1.0000
[2019-03-23 18:42:03,873] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6950
[2019-03-23 18:42:03,876] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.66666666666666, 53.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3378097961587893, 6.911199999999999, 6.9112, 77.32846344354104, 389485.7110798542, 389485.7110798545, 151198.929042829], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3237600.0000, 
sim time next is 3238200.0000, 
raw observation next is [23.5, 53.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3318810795090566, 6.9112, 6.9112, 77.32846344354104, 382989.7588146373, 382989.7588146373, 150164.2816659901], 
processed observation next is [0.0, 0.4782608695652174, 0.7045454545454546, 0.535, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.045544399298652304, 0.0, 0.0, 0.5084288129206541, 0.14184805882023604, 0.14184805882023604, 0.36625434552680514], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1626731], dtype=float32), -0.0150665045]. 
=============================================
[2019-03-23 18:42:05,142] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72500, global step 1147480: loss 0.4452
[2019-03-23 18:42:05,143] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72500, global step 1147480: learning rate 0.0000
[2019-03-23 18:42:07,394] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72000, global step 1148589: loss 0.6447
[2019-03-23 18:42:07,398] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72000, global step 1148590: learning rate 0.0000
[2019-03-23 18:42:08,082] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.9280068e-04 1.4000665e-04 9.9796474e-01 1.1158297e-03 8.6719221e-05], sum to 1.0000
[2019-03-23 18:42:08,092] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7537
[2019-03-23 18:42:08,103] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 50.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3496498666006375, 6.911200000000001, 6.9112, 77.32846344354104, 402093.2479905413, 402093.247990541, 153606.8128303731], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3340800.0000, 
sim time next is 3341400.0000, 
raw observation next is [25.0, 50.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3498480778103912, 6.911200000000001, 6.9112, 77.32846344354104, 402320.8370778344, 402320.8370778341, 153631.6133529661], 
processed observation next is [0.0, 0.6956521739130435, 0.7727272727272727, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.07121153972913027, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14900771743623498, 0.14900771743623487, 0.37471125208040507], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4138266], dtype=float32), 0.10346815]. 
=============================================
[2019-03-23 18:42:10,082] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.3692215e-04 2.3875722e-05 9.9857843e-01 9.9740666e-04 1.6338548e-04], sum to 1.0000
[2019-03-23 18:42:10,093] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2940
[2019-03-23 18:42:10,099] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 321853.0504820234, 321853.0504820232, 139900.4465243241], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3846600.0000, 
sim time next is 3847200.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 321724.9216838654, 321724.9216838657, 139880.7775374291], 
processed observation next is [0.0, 0.5217391304347826, 0.5, 0.73, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11915737840143163, 0.11915737840143174, 0.341172628140071], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6448177], dtype=float32), -0.57829034]. 
=============================================
[2019-03-23 18:42:10,247] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 18:42:10,249] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:42:10,250] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:42:10,252] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:42:10,253] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:42:10,253] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:42:10,255] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:42:10,253] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:42:10,256] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:42:10,256] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:42:10,259] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:42:10,275] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run47
[2019-03-23 18:42:10,275] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run47
[2019-03-23 18:42:10,325] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run47
[2019-03-23 18:42:10,326] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run47
[2019-03-23 18:42:10,361] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run47
[2019-03-23 18:42:45,962] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00939282], dtype=float32), 0.0074018715]
[2019-03-23 18:42:45,963] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.12501939, 76.97201359, 1.0, 2.0, 0.2340936073243658, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4458616573533184, 6.9112, 6.9112, 95.55338769695034, 516033.4395346669, 516033.4395346669, 165104.1407541351]
[2019-03-23 18:42:45,965] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:42:45,968] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.4532021e-04 5.3291087e-06 9.9922001e-01 2.3248605e-04 9.6826843e-05], sampled 0.8046646666020988
[2019-03-23 18:42:56,942] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00939282], dtype=float32), 0.0074018715]
[2019-03-23 18:42:56,943] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.5, 63.66666666666666, 1.0, 2.0, 0.3982367539793035, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8030417776728114, 6.911200000000001, 6.9112, 95.55338769695034, 909023.2833588732, 909023.2833588729, 225866.99421224]
[2019-03-23 18:42:56,944] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:42:56,946] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.6281493e-03 3.0705131e-08 9.9516112e-01 1.8074536e-05 1.9255508e-04], sampled 0.2734644531192876
[2019-03-23 18:43:02,406] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00939282], dtype=float32), 0.0074018715]
[2019-03-23 18:43:02,407] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.86241404833333, 68.59294154166666, 1.0, 2.0, 0.2302334836329666, 0.0, 2.0, 0.0, 1.0, 2.0, 0.464041968016756, 6.9112, 6.9112, 95.55338769695034, 525359.1362002798, 525359.1362002798, 177097.2003148567]
[2019-03-23 18:43:02,408] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:43:02,412] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.8027706e-04 3.2630298e-06 9.9911350e-01 1.8824317e-04 1.1473116e-04], sampled 0.4659091028731126
[2019-03-23 18:43:23,118] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00939282], dtype=float32), 0.0074018715]
[2019-03-23 18:43:23,119] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.21740676666667, 85.90815766, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 327108.2585432346, 327108.2585432346, 145178.73101436]
[2019-03-23 18:43:23,121] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:43:23,124] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.4812017e-04 2.5800698e-05 9.9922144e-01 4.3195003e-04 7.2643408e-05], sampled 0.12905907337758593
[2019-03-23 18:43:42,897] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00939282], dtype=float32), 0.0074018715]
[2019-03-23 18:43:42,898] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.10614717666667, 95.85782108666666, 1.0, 2.0, 0.2210744610582899, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4433385492642942, 6.911200000000001, 6.9112, 95.55338769695034, 503867.5377605315, 503867.5377605311, 173396.4443403869]
[2019-03-23 18:43:42,899] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:43:42,902] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.7069278e-04 2.9010238e-07 9.9888474e-01 4.6693847e-05 9.7510172e-05], sampled 0.8473076599469878
[2019-03-23 18:43:47,449] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3350.5254 2097626215.8257 184.0000
[2019-03-23 18:43:47,455] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3114.4302 2108266783.0587 371.0000
[2019-03-23 18:43:47,676] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3609.4217 2174966934.1460 244.0000
[2019-03-23 18:43:47,817] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3513.1304 2103553216.0077 180.0000
[2019-03-23 18:43:47,925] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2757.2945 2123679446.4038 756.0000
[2019-03-23 18:43:48,943] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1150000, evaluation results [1150000.0, 3609.4216773966546, 2174966934.145966, 244.0, 3350.5254104482365, 2097626215.825684, 184.0, 3513.130394390161, 2103553216.007734, 180.0, 2757.2944665624573, 2123679446.4037504, 756.0, 3114.4302333838737, 2108266783.0586581, 371.0]
[2019-03-23 18:43:49,471] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.8940246e-04 3.2085838e-05 9.9863487e-01 2.9238331e-04 3.5119639e-04], sum to 1.0000
[2019-03-23 18:43:49,481] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2889
[2019-03-23 18:43:49,485] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.66666666666666, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3040428916510358, 6.9112, 6.9112, 77.32846344354104, 351875.8661059612, 351875.8661059612, 145928.6732971561], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3390000.0000, 
sim time next is 3390600.0000, 
raw observation next is [16.83333333333334, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3090323587818926, 6.9112, 6.9112, 77.32846344354104, 357334.5309949424, 357334.5309949424, 146805.004164683], 
processed observation next is [1.0, 0.21739130434782608, 0.40151515151515177, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.012903369688418036, 0.0, 0.0, 0.5084288129206541, 0.1323461225907194, 0.1323461225907194, 0.3580609857675195], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0235076], dtype=float32), -0.29232427]. 
=============================================
[2019-03-23 18:43:52,969] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72000, global step 1151992: loss -0.0120
[2019-03-23 18:43:52,975] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72000, global step 1151996: learning rate 0.0000
[2019-03-23 18:43:53,478] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72000, global step 1152247: loss 0.1119
[2019-03-23 18:43:53,484] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72000, global step 1152247: learning rate 0.0000
[2019-03-23 18:43:54,324] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72000, global step 1152668: loss 0.2355
[2019-03-23 18:43:54,325] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72000, global step 1152668: learning rate 0.0000
[2019-03-23 18:43:54,428] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3436850e-02 8.2194651e-09 9.8613852e-01 1.1378816e-05 4.1319194e-04], sum to 1.0000
[2019-03-23 18:43:54,436] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7651
[2019-03-23 18:43:54,441] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.66666666666667, 66.0, 1.0, 2.0, 0.2553709616283486, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5172346957488485, 6.9112, 6.9112, 77.32846344354104, 580970.3308276375, 580970.3308276375, 181512.9121017029], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3432000.0000, 
sim time next is 3432600.0000, 
raw observation next is [26.5, 68.0, 1.0, 2.0, 0.2480459272009755, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5024427840591559, 6.9112, 6.9112, 77.32846344354104, 563975.9418519876, 563975.9418519876, 180004.8225344428], 
processed observation next is [1.0, 0.7391304347826086, 0.8409090909090909, 0.68, 1.0, 1.0, 0.06005740900121938, 0.0, 1.0, -0.25, 1.0, 1.0, 0.28920397722736557, 0.0, 0.0, 0.5084288129206541, 0.20887997846369913, 0.20887997846369913, 0.4390361525230312], 
reward next is 0.5610, 
noisyNet noise sample is [array([-1.6340955], dtype=float32), 2.202292]. 
=============================================
[2019-03-23 18:43:54,507] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72000, global step 1152763: loss 0.0730
[2019-03-23 18:43:54,510] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72000, global step 1152764: learning rate 0.0000
[2019-03-23 18:43:55,082] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72000, global step 1153044: loss 0.0447
[2019-03-23 18:43:55,084] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72000, global step 1153044: learning rate 0.0000
[2019-03-23 18:43:55,145] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72000, global step 1153081: loss -28.9254
[2019-03-23 18:43:55,146] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72000, global step 1153082: learning rate 0.0000
[2019-03-23 18:43:55,317] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72000, global step 1153167: loss 0.0790
[2019-03-23 18:43:55,319] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72000, global step 1153167: learning rate 0.0000
[2019-03-23 18:43:55,472] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72000, global step 1153247: loss 0.0810
[2019-03-23 18:43:55,474] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72000, global step 1153248: learning rate 0.0000
[2019-03-23 18:43:55,662] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72000, global step 1153337: loss 0.0066
[2019-03-23 18:43:55,666] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72000, global step 1153338: learning rate 0.0000
[2019-03-23 18:43:55,860] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72000, global step 1153439: loss 0.0875
[2019-03-23 18:43:55,865] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72000, global step 1153440: learning rate 0.0000
[2019-03-23 18:43:56,037] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72000, global step 1153528: loss 0.0232
[2019-03-23 18:43:56,039] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72000, global step 1153529: learning rate 0.0000
[2019-03-23 18:43:56,147] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72000, global step 1153581: loss 0.0133
[2019-03-23 18:43:56,148] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72000, global step 1153581: learning rate 0.0000
[2019-03-23 18:43:56,194] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72000, global step 1153606: loss 0.0438
[2019-03-23 18:43:56,199] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72000, global step 1153606: learning rate 0.0000
[2019-03-23 18:43:56,812] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72000, global step 1153912: loss -0.0250
[2019-03-23 18:43:56,814] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72000, global step 1153913: learning rate 0.0000
[2019-03-23 18:43:59,901] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73000, global step 1155448: loss 6.6840
[2019-03-23 18:43:59,903] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73000, global step 1155448: learning rate 0.0000
[2019-03-23 18:43:59,941] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.0812255e-03 7.3818773e-09 9.8980182e-01 4.6706791e-05 3.0701954e-03], sum to 1.0000
[2019-03-23 18:43:59,948] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5469
[2019-03-23 18:43:59,953] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.5, 70.0, 1.0, 2.0, 0.2718119125218162, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5505731014788614, 6.911199999999999, 6.9112, 77.32846344354104, 616724.7380282981, 616724.7380282985, 186705.4953312626], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3526200.0000, 
sim time next is 3526800.0000, 
raw observation next is [26.33333333333334, 71.33333333333333, 1.0, 2.0, 0.2736802889013183, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5543330242483818, 6.9112, 6.9112, 77.32846344354104, 620733.1625800604, 620733.1625800604, 187316.5508628532], 
processed observation next is [1.0, 0.8260869565217391, 0.8333333333333336, 0.7133333333333333, 1.0, 1.0, 0.09210036112664785, 0.0, 1.0, -0.25, 1.0, 1.0, 0.36333289178340267, 0.0, 0.0, 0.5084288129206541, 0.2299011713259483, 0.2299011713259483, 0.45686963625086147], 
reward next is 0.5431, 
noisyNet noise sample is [array([-1.1305947], dtype=float32), 1.3930413]. 
=============================================
[2019-03-23 18:44:02,488] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72500, global step 1156723: loss 0.0734
[2019-03-23 18:44:02,490] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72500, global step 1156723: learning rate 0.0000
[2019-03-23 18:44:09,123] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72500, global step 1160008: loss 0.6036
[2019-03-23 18:44:09,124] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72500, global step 1160008: learning rate 0.0000
[2019-03-23 18:44:09,641] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72500, global step 1160273: loss 0.7605
[2019-03-23 18:44:09,644] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72500, global step 1160275: learning rate 0.0000
[2019-03-23 18:44:10,514] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72500, global step 1160713: loss -0.1650
[2019-03-23 18:44:10,516] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72500, global step 1160713: learning rate 0.0000
[2019-03-23 18:44:10,629] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72500, global step 1160769: loss 4.9898
[2019-03-23 18:44:10,632] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72500, global step 1160769: learning rate 0.0000
[2019-03-23 18:44:11,240] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72500, global step 1161067: loss 2.3917
[2019-03-23 18:44:11,242] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72500, global step 1161067: learning rate 0.0000
[2019-03-23 18:44:11,315] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72500, global step 1161101: loss 0.2858
[2019-03-23 18:44:11,321] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72500, global step 1161101: learning rate 0.0000
[2019-03-23 18:44:11,323] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72500, global step 1161104: loss -0.0066
[2019-03-23 18:44:11,325] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72500, global step 1161104: learning rate 0.0000
[2019-03-23 18:44:11,556] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72500, global step 1161223: loss 1.6654
[2019-03-23 18:44:11,557] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72500, global step 1161224: learning rate 0.0000
[2019-03-23 18:44:11,757] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72500, global step 1161322: loss 0.5571
[2019-03-23 18:44:11,760] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72500, global step 1161322: learning rate 0.0000
[2019-03-23 18:44:12,119] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72500, global step 1161502: loss 0.2682
[2019-03-23 18:44:12,122] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72500, global step 1161502: learning rate 0.0000
[2019-03-23 18:44:12,159] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72500, global step 1161521: loss 0.0090
[2019-03-23 18:44:12,161] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72500, global step 1161521: learning rate 0.0000
[2019-03-23 18:44:12,261] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72500, global step 1161572: loss -2.7253
[2019-03-23 18:44:12,262] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72500, global step 1161572: learning rate 0.0000
[2019-03-23 18:44:12,562] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72500, global step 1161722: loss 0.0810
[2019-03-23 18:44:12,563] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72500, global step 1161722: learning rate 0.0000
[2019-03-23 18:44:12,941] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72500, global step 1161910: loss -6.3406
[2019-03-23 18:44:12,942] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72500, global step 1161910: learning rate 0.0000
[2019-03-23 18:44:15,803] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73500, global step 1163338: loss 0.2073
[2019-03-23 18:44:15,806] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73500, global step 1163338: learning rate 0.0000
[2019-03-23 18:44:18,489] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73000, global step 1164676: loss 0.2709
[2019-03-23 18:44:18,491] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73000, global step 1164676: learning rate 0.0000
[2019-03-23 18:44:19,965] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.6390809e-03 5.0129095e-04 9.9291176e-01 2.7631004e-03 1.1848159e-03], sum to 1.0000
[2019-03-23 18:44:19,976] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6790
[2019-03-23 18:44:19,984] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.0, 82.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 286947.2036940484, 286947.2036940484, 121600.0875760272], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3909600.0000, 
sim time next is 3910200.0000, 
raw observation next is [17.0, 82.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 286931.3384812826, 286931.3384812829, 121601.9708209972], 
processed observation next is [0.0, 0.2608695652173913, 0.4090909090909091, 0.8200000000000002, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10627086610417874, 0.10627086610417884, 0.2965901727341395], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7128713], dtype=float32), -0.3759247]. 
=============================================
[2019-03-23 18:44:25,184] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73000, global step 1168004: loss 7.9991
[2019-03-23 18:44:25,186] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73000, global step 1168006: learning rate 0.0000
[2019-03-23 18:44:25,709] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73000, global step 1168266: loss 3.4796
[2019-03-23 18:44:25,710] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73000, global step 1168266: learning rate 0.0000
[2019-03-23 18:44:26,642] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73000, global step 1168720: loss 25.5422
[2019-03-23 18:44:26,644] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73000, global step 1168720: learning rate 0.0000
[2019-03-23 18:44:26,660] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73000, global step 1168727: loss 8.9897
[2019-03-23 18:44:26,662] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73000, global step 1168728: learning rate 0.0000
[2019-03-23 18:44:27,332] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73000, global step 1169062: loss 1.6740
[2019-03-23 18:44:27,334] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73000, global step 1169063: learning rate 0.0000
[2019-03-23 18:44:27,412] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73000, global step 1169101: loss 2.2757
[2019-03-23 18:44:27,416] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73000, global step 1169102: learning rate 0.0000
[2019-03-23 18:44:27,548] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73000, global step 1169166: loss 1.3469
[2019-03-23 18:44:27,556] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73000, global step 1169169: learning rate 0.0000
[2019-03-23 18:44:27,716] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73000, global step 1169251: loss 0.5116
[2019-03-23 18:44:27,718] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73000, global step 1169252: learning rate 0.0000
[2019-03-23 18:44:27,762] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73000, global step 1169276: loss 0.2068
[2019-03-23 18:44:27,765] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73000, global step 1169277: learning rate 0.0000
[2019-03-23 18:44:28,092] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73000, global step 1169437: loss 0.0765
[2019-03-23 18:44:28,094] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73000, global step 1169437: learning rate 0.0000
[2019-03-23 18:44:28,240] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73000, global step 1169510: loss 0.1740
[2019-03-23 18:44:28,243] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73000, global step 1169511: learning rate 0.0000
[2019-03-23 18:44:28,476] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73000, global step 1169631: loss 0.4339
[2019-03-23 18:44:28,480] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73000, global step 1169633: learning rate 0.0000
[2019-03-23 18:44:28,721] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73000, global step 1169749: loss 0.2811
[2019-03-23 18:44:28,723] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73000, global step 1169750: learning rate 0.0000
[2019-03-23 18:44:29,177] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73000, global step 1169978: loss 0.4414
[2019-03-23 18:44:29,181] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73000, global step 1169978: learning rate 0.0000
[2019-03-23 18:44:31,784] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74000, global step 1171279: loss 0.0112
[2019-03-23 18:44:31,789] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74000, global step 1171279: learning rate 0.0000
[2019-03-23 18:44:31,866] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.0753950e-03 2.2980710e-04 9.9459100e-01 1.1462074e-03 9.5752365e-04], sum to 1.0000
[2019-03-23 18:44:31,870] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5985
[2019-03-23 18:44:31,875] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3714308391520367, 6.911199999999999, 6.9112, 77.32846344354104, 426629.902257141, 426629.9022571412, 156802.4179109815], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4138800.0000, 
sim time next is 4139400.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3715021418475385, 6.9112, 6.9112, 77.32846344354104, 426710.8497536741, 426710.8497536741, 156812.4208765104], 
processed observation next is [1.0, 0.9130434782608695, 0.45454545454545453, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.10214591692505501, 0.0, 0.0, 0.5084288129206541, 0.15804105546432376, 0.15804105546432376, 0.382469319211001], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.32354936], dtype=float32), 0.44409424]. 
=============================================
[2019-03-23 18:44:33,855] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.6622702e-03 5.5502960e-04 9.9422640e-01 2.7863365e-03 7.6999457e-04], sum to 1.0000
[2019-03-23 18:44:33,865] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9689
[2019-03-23 18:44:33,869] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.0, 72.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 253672.6755889918, 253672.6755889918, 104553.2272736213], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4694400.0000, 
sim time next is 4695000.0000, 
raw observation next is [17.16666666666667, 71.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 259427.4337044809, 259427.4337044812, 106058.9535496305], 
processed observation next is [1.0, 0.34782608695652173, 0.4166666666666669, 0.7133333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0960842347053633, 0.09608423470536341, 0.2586803745112939], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.664845], dtype=float32), -0.49087253]. 
=============================================
[2019-03-23 18:44:33,883] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[1.2916638]
 [1.2988929]
 [1.2998444]
 [1.2874252]
 [1.2798835]], R is [[1.25481093]
 [1.24226284]
 [1.22984028]
 [1.21754193]
 [1.20536649]].
[2019-03-23 18:44:34,401] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73500, global step 1172587: loss 0.6695
[2019-03-23 18:44:34,407] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73500, global step 1172589: learning rate 0.0000
[2019-03-23 18:44:35,933] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.2580930e-03 1.0595536e-04 9.8907745e-01 6.1227949e-03 1.4355879e-03], sum to 1.0000
[2019-03-23 18:44:35,942] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0045
[2019-03-23 18:44:35,946] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.0, 55.0, 1.0, 2.0, 0.2339711245625781, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4730269698205868, 6.9112, 6.9112, 77.32846344354104, 533670.6593333448, 533670.6593333448, 174773.3585808371], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4384800.0000, 
sim time next is 4385400.0000, 
raw observation next is [27.83333333333334, 55.5, 1.0, 2.0, 0.237418161773035, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4799757841827719, 6.911200000000001, 6.9112, 77.32846344354104, 541549.4403365052, 541549.4403365048, 175504.783186717], 
processed observation next is [1.0, 0.782608695652174, 0.9015151515151518, 0.555, 1.0, 1.0, 0.04677270221629375, 0.0, 1.0, -0.25, 1.0, 1.0, 0.25710826311824564, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2005738667912982, 0.2005738667912981, 0.4280604467968707], 
reward next is 0.5719, 
noisyNet noise sample is [array([-1.0598065], dtype=float32), 0.4152227]. 
=============================================
[2019-03-23 18:44:36,153] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.0488304e-03 1.5357635e-05 9.9488306e-01 5.7567825e-04 4.7711068e-04], sum to 1.0000
[2019-03-23 18:44:36,158] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9269
[2019-03-23 18:44:36,162] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3193365746571598, 6.9112, 6.9112, 77.32846344354104, 370044.9473056501, 370044.9473056501, 147158.7016824575], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4258800.0000, 
sim time next is 4259400.0000, 
raw observation next is [17.16666666666667, 94.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.356464475520062, 6.9112, 6.9112, 77.32846344354104, 412767.5256894949, 412767.5256894949, 151737.2880183203], 
processed observation next is [1.0, 0.30434782608695654, 0.4166666666666669, 0.9400000000000002, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.08066353645723144, 0.0, 0.0, 0.5084288129206541, 0.1528768613664796, 0.1528768613664796, 0.3700909463861471], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.98926175], dtype=float32), -1.1100984]. 
=============================================
[2019-03-23 18:44:37,701] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.1154336e-02 2.4838667e-04 9.7319454e-01 1.0259180e-02 5.1434557e-03], sum to 1.0000
[2019-03-23 18:44:37,710] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6079
[2019-03-23 18:44:37,716] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.66666666666667, 70.33333333333334, 1.0, 2.0, 0.2057136866469092, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4080438478562299, 6.9112, 6.9112, 77.32846344354104, 466446.6021575699, 466446.6021575699, 162986.7178637828], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4213200.0000, 
sim time next is 4213800.0000, 
raw observation next is [22.5, 71.0, 1.0, 2.0, 0.2035937476103285, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4035317435359962, 6.911200000000001, 6.9112, 77.32846344354104, 461437.485132498, 461437.4851324977, 162447.1636023123], 
processed observation next is [1.0, 0.782608695652174, 0.6590909090909091, 0.71, 1.0, 1.0, 0.004492184512910613, 0.0, 1.0, -0.25, 1.0, 1.0, 0.14790249076570886, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17090277227129558, 0.17090277227129544, 0.39621259415198123], 
reward next is 0.6038, 
noisyNet noise sample is [array([-2.1096694], dtype=float32), -1.7543079]. 
=============================================
[2019-03-23 18:44:39,207] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 18:44:39,210] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:44:39,211] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:44:39,212] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:44:39,212] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:44:39,213] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:44:39,215] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:44:39,216] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:44:39,214] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:44:39,220] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:44:39,219] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:44:39,236] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run48
[2019-03-23 18:44:39,261] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run48
[2019-03-23 18:44:39,290] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run48
[2019-03-23 18:44:39,291] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run48
[2019-03-23 18:44:39,344] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run48
[2019-03-23 18:44:42,184] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00942947], dtype=float32), 0.007441578]
[2019-03-23 18:44:42,184] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 219511.8452268513, 219511.845226851, 93251.45955893892]
[2019-03-23 18:44:42,186] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:44:42,187] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0348745e-02 1.8934513e-04 9.8202401e-01 4.0986030e-03 3.3393349e-03], sampled 0.662409129013673
[2019-03-23 18:45:09,486] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00942947], dtype=float32), 0.007441578]
[2019-03-23 18:45:09,486] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.43333333333333, 69.0, 1.0, 2.0, 0.2536651517681646, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5129809410861189, 6.911200000000001, 6.9112, 95.55338769695034, 578460.1953180647, 578460.1953180643, 184169.6129762018]
[2019-03-23 18:45:09,489] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:45:09,494] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.0641205e-02 2.1353748e-05 9.1442674e-01 3.1997343e-03 1.1710964e-02], sampled 0.467724935933313
[2019-03-23 18:45:13,992] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00942947], dtype=float32), 0.007441578]
[2019-03-23 18:45:13,994] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.72803979333333, 90.25556196000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3854326784677022, 6.9112, 6.9112, 95.55338769695034, 441397.082588733, 441397.082588733, 164372.6335089109]
[2019-03-23 18:45:13,996] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:45:13,998] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.6610440e-02 2.0575956e-04 9.7148907e-01 5.8698547e-03 5.8247661e-03], sampled 0.31637466096193556
[2019-03-23 18:45:31,572] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00942947], dtype=float32), 0.007441578]
[2019-03-23 18:45:31,572] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.66666666666667, 88.66666666666667, 1.0, 2.0, 0.2202421117475727, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4396209289112394, 6.911200000000001, 6.9112, 95.55338769695034, 501000.8849136348, 501000.8849136345, 171891.3301091548]
[2019-03-23 18:45:31,573] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:45:31,576] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.0797360e-02 3.0163872e-05 9.4783372e-01 3.2946549e-03 8.0439756e-03], sampled 0.8648162001762766
[2019-03-23 18:45:48,731] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00942947], dtype=float32), 0.007441578]
[2019-03-23 18:45:48,731] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.58333333333334, 82.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3737496813071935, 6.9112, 6.9112, 95.55338769695034, 430215.1927227282, 430215.1927227282, 160851.7456812563]
[2019-03-23 18:45:48,732] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:45:48,735] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.4414941e-02 1.2243757e-04 9.7638470e-01 4.5184633e-03 4.5595379e-03], sampled 0.9428620641010553
[2019-03-23 18:45:51,044] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00942947], dtype=float32), 0.007441578]
[2019-03-23 18:45:51,046] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.3, 73.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 323798.9924634334, 323798.9924634334, 131425.9679853977]
[2019-03-23 18:45:51,047] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:45:51,049] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.2176958e-03 4.3014126e-04 9.8538524e-01 5.3338935e-03 2.6331989e-03], sampled 0.20368722155045194
[2019-03-23 18:45:53,467] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00942947], dtype=float32), 0.007441578]
[2019-03-23 18:45:53,468] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.4, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3635642624410174, 6.911200000000001, 6.9112, 77.32846344354104, 417574.0006286842, 417574.0006286839, 155817.6109429174]
[2019-03-23 18:45:53,469] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:45:53,474] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.3013610e-02 1.9103479e-04 9.7693014e-01 5.2680974e-03 4.5971605e-03], sampled 0.7711117696259822
[2019-03-23 18:46:16,348] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2518.2533 2107442166.4061 853.0000
[2019-03-23 18:46:16,402] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3175.5866 2083679170.8868 365.0000
[2019-03-23 18:46:16,717] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3290.8289 2155102843.1438 388.0000
[2019-03-23 18:46:16,793] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3022.9268 2077644952.0356 333.0000
[2019-03-23 18:46:16,830] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 2849.7750 2090330721.2950 508.0000
[2019-03-23 18:46:17,844] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1175000, evaluation results [1175000.0, 3290.8288692895844, 2155102843.143818, 388.0, 3022.926813680361, 2077644952.0355556, 333.0, 3175.5866298680708, 2083679170.8868072, 365.0, 2518.2533353363237, 2107442166.4061341, 853.0, 2849.775020134147, 2090330721.294994, 508.0]
[2019-03-23 18:46:19,651] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.1421027e-02 2.4484799e-04 9.0139693e-01 1.2228236e-02 1.4708986e-02], sum to 1.0000
[2019-03-23 18:46:19,656] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4716
[2019-03-23 18:46:19,659] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.0, 61.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3937862761508071, 6.911200000000001, 6.9112, 77.32846344354104, 450602.4383630506, 450602.4383630503, 161205.8323457071], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4308000.0000, 
sim time next is 4308600.0000, 
raw observation next is [24.0, 61.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.394934167288581, 6.911199999999999, 6.9112, 77.32846344354104, 451914.1289775864, 451914.1289775867, 161362.6326848799], 
processed observation next is [1.0, 0.8695652173913043, 0.7272727272727273, 0.61, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.13562023898368716, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.167375603325032, 0.1673756033250321, 0.39356739679239], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.2669327], dtype=float32), 0.90731394]. 
=============================================
[2019-03-23 18:46:19,888] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73500, global step 1176010: loss 5.0298
[2019-03-23 18:46:19,891] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73500, global step 1176010: learning rate 0.0000
[2019-03-23 18:46:20,142] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.8658774e-02 8.4209401e-05 8.4973538e-01 1.0316745e-02 6.1204925e-02], sum to 1.0000
[2019-03-23 18:46:20,151] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9500
[2019-03-23 18:46:20,156] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 58.0, 1.0, 2.0, 0.7177877619397829, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9717641809705369, 6.911200000000001, 6.9112, 77.32846344338515, 1367333.982987689, 1367333.982987688, 289195.383269481], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4361400.0000, 
sim time next is 4362000.0000, 
raw observation next is [27.0, 58.0, 1.0, 2.0, 0.4081605146366338, 1.0, 1.0, 0.4081605146366338, 1.0, 2.0, 0.8268116972346365, 6.9112, 6.9112, 77.3421103, 1391754.617797201, 1391754.617797201, 304976.7017295943], 
processed observation next is [1.0, 0.4782608695652174, 0.8636363636363636, 0.58, 1.0, 1.0, 0.2602006432957922, 1.0, 0.5, 0.2602006432957922, 1.0, 1.0, 0.7525881389066238, 0.0, 0.0, 0.5085185399722538, 0.5154646732582226, 0.5154646732582226, 0.7438456139746203], 
reward next is 0.2562, 
noisyNet noise sample is [array([-0.25878105], dtype=float32), -1.27995]. 
=============================================
[2019-03-23 18:46:20,176] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[18.141275]
 [18.674574]
 [18.670057]
 [19.10486 ]
 [18.792711]], R is [[18.460392  ]
 [18.57043266]
 [18.7008152 ]
 [18.8216629 ]
 [18.95408058]].
[2019-03-23 18:46:20,441] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73500, global step 1176284: loss -0.4140
[2019-03-23 18:46:20,443] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73500, global step 1176284: learning rate 0.0000
[2019-03-23 18:46:21,155] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73500, global step 1176647: loss 0.1620
[2019-03-23 18:46:21,158] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73500, global step 1176647: learning rate 0.0000
[2019-03-23 18:46:21,383] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73500, global step 1176754: loss 1.3791
[2019-03-23 18:46:21,388] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73500, global step 1176756: learning rate 0.0000
[2019-03-23 18:46:21,953] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73500, global step 1177044: loss 0.9357
[2019-03-23 18:46:21,955] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73500, global step 1177044: learning rate 0.0000
[2019-03-23 18:46:22,020] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73500, global step 1177069: loss -7.4312
[2019-03-23 18:46:22,022] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73500, global step 1177069: learning rate 0.0000
[2019-03-23 18:46:22,168] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73500, global step 1177143: loss 0.0418
[2019-03-23 18:46:22,171] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73500, global step 1177144: learning rate 0.0000
[2019-03-23 18:46:22,398] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73500, global step 1177263: loss 14.8642
[2019-03-23 18:46:22,401] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73500, global step 1177263: learning rate 0.0000
[2019-03-23 18:46:22,448] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73500, global step 1177286: loss 4.3724
[2019-03-23 18:46:22,449] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73500, global step 1177286: learning rate 0.0000
[2019-03-23 18:46:22,666] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73500, global step 1177394: loss 2.2404
[2019-03-23 18:46:22,669] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73500, global step 1177395: learning rate 0.0000
[2019-03-23 18:46:22,881] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73500, global step 1177501: loss 0.3937
[2019-03-23 18:46:22,886] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73500, global step 1177502: learning rate 0.0000
[2019-03-23 18:46:23,278] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73500, global step 1177704: loss -3.4922
[2019-03-23 18:46:23,280] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73500, global step 1177704: learning rate 0.0000
[2019-03-23 18:46:23,301] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73500, global step 1177715: loss 0.2460
[2019-03-23 18:46:23,303] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73500, global step 1177717: learning rate 0.0000
[2019-03-23 18:46:23,791] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73500, global step 1177962: loss -2.1946
[2019-03-23 18:46:23,794] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73500, global step 1177963: learning rate 0.0000
[2019-03-23 18:46:25,800] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.1261975e-03 7.1541733e-09 9.9038714e-01 5.4839355e-05 3.4317414e-03], sum to 1.0000
[2019-03-23 18:46:25,810] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0746
[2019-03-23 18:46:25,816] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.2182757764020037, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4377848143967409, 6.9112, 6.9112, 77.32846344354104, 497557.9061455932, 497557.9061455932, 168213.8033736362], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4435200.0000, 
sim time next is 4435800.0000, 
raw observation next is [22.16666666666667, 82.16666666666667, 1.0, 2.0, 0.2203889709067592, 0.0, 2.0, 0.0, 1.0, 2.0, 0.442327623722218, 6.9112, 6.9112, 77.32846344354104, 502492.2899677875, 502492.2899677875, 168847.6567828723], 
processed observation next is [0.0, 0.34782608695652173, 0.6439393939393941, 0.8216666666666668, 1.0, 1.0, 0.025486213633449002, 0.0, 1.0, -0.25, 1.0, 1.0, 0.20332517674602577, 0.0, 0.0, 0.5084288129206541, 0.186108255543625, 0.186108255543625, 0.41182355312895685], 
reward next is 0.5882, 
noisyNet noise sample is [array([-1.1280575], dtype=float32), 0.8290474]. 
=============================================
[2019-03-23 18:46:26,404] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74500, global step 1179239: loss 0.1302
[2019-03-23 18:46:26,407] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74500, global step 1179239: learning rate 0.0000
[2019-03-23 18:46:28,755] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.3516519e-02 1.1517808e-10 9.7565711e-01 1.9702384e-06 8.2439772e-04], sum to 1.0000
[2019-03-23 18:46:28,765] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4574
[2019-03-23 18:46:28,770] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.66666666666667, 53.5, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5564056354013005, 6.911199999999999, 6.9112, 77.32846344354104, 323466.1045023464, 323466.1045023467, 101760.1200206947], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4648200.0000, 
sim time next is 4648800.0000, 
raw observation next is [21.33333333333334, 54.0, 1.0, 1.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 318831.7772835155, 318831.7772835158, 138001.6002320177], 
processed observation next is [1.0, 0.8260869565217391, 0.6060606060606063, 0.54, 1.0, 0.5, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11808584343833907, 0.11808584343833918, 0.33658926885857976], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.38965195], dtype=float32), 0.13635755]. 
=============================================
[2019-03-23 18:46:29,167] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74000, global step 1180618: loss 4.0361
[2019-03-23 18:46:29,171] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74000, global step 1180618: learning rate 0.0000
[2019-03-23 18:46:30,615] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.8078227e-04 3.5142835e-12 9.9948335e-01 1.7245598e-07 3.5755460e-05], sum to 1.0000
[2019-03-23 18:46:30,623] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8779
[2019-03-23 18:46:30,628] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.2054523484117425, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4082744758002644, 6.9112, 6.9112, 77.32846344354104, 466327.9541286997, 466327.9541286997, 163362.0015531737], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4510200.0000, 
sim time next is 4510800.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.2055582942309784, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4084857041933856, 6.911200000000001, 6.9112, 77.32846344354104, 466568.9707149612, 466568.9707149609, 163381.1137009489], 
processed observation next is [0.0, 0.21739130434782608, 0.5, 1.0, 1.0, 1.0, 0.006947867788722993, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1549795774191223, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17280332248702265, 0.17280332248702254, 0.39849052122182654], 
reward next is 0.6015, 
noisyNet noise sample is [array([0.9673794], dtype=float32), -0.23114607]. 
=============================================
[2019-03-23 18:46:32,687] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.2110791e-03 2.6347286e-07 9.8933357e-01 2.1120478e-04 2.2438690e-03], sum to 1.0000
[2019-03-23 18:46:32,706] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6561
[2019-03-23 18:46:32,711] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.0, 96.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 245917.0722921776, 245917.0722921773, 101405.2071761202], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4596000.0000, 
sim time next is 4596600.0000, 
raw observation next is [14.0, 95.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 243589.8426306355, 243589.8426306352, 100497.9318263357], 
processed observation next is [1.0, 0.17391304347826086, 0.2727272727272727, 0.95, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0902184602335687, 0.0902184602335686, 0.2451169068935017], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.05289899], dtype=float32), 0.8957442]. 
=============================================
[2019-03-23 18:46:34,317] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.4982155e-03 7.8999597e-05 9.9571383e-01 1.1433058e-03 5.6564610e-04], sum to 1.0000
[2019-03-23 18:46:34,322] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4621
[2019-03-23 18:46:34,325] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.83333333333334, 83.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 297969.0498357416, 297969.0498357416, 123238.2151607817], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4579800.0000, 
sim time next is 4580400.0000, 
raw observation next is [16.66666666666667, 84.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 297322.7413333947, 297322.7413333944, 122458.8515514677], 
processed observation next is [1.0, 0.0, 0.39393939393939414, 0.84, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11011953382718323, 0.11011953382718312, 0.29868012573528707], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.41150284], dtype=float32), 2.245236]. 
=============================================
[2019-03-23 18:46:35,804] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74000, global step 1183928: loss 0.5898
[2019-03-23 18:46:35,807] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74000, global step 1183929: learning rate 0.0000
[2019-03-23 18:46:36,414] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74000, global step 1184237: loss 0.0199
[2019-03-23 18:46:36,416] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74000, global step 1184237: learning rate 0.0000
[2019-03-23 18:46:37,316] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74000, global step 1184689: loss 14.1572
[2019-03-23 18:46:37,319] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74000, global step 1184689: learning rate 0.0000
[2019-03-23 18:46:37,520] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74000, global step 1184788: loss 0.1134
[2019-03-23 18:46:37,522] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74000, global step 1184789: learning rate 0.0000
[2019-03-23 18:46:37,942] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74000, global step 1185000: loss 0.5424
[2019-03-23 18:46:37,944] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74000, global step 1185000: learning rate 0.0000
[2019-03-23 18:46:38,172] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74000, global step 1185110: loss 11.2055
[2019-03-23 18:46:38,175] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74000, global step 1185110: learning rate 0.0000
[2019-03-23 18:46:38,315] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74000, global step 1185185: loss 0.0098
[2019-03-23 18:46:38,316] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74000, global step 1185185: learning rate 0.0000
[2019-03-23 18:46:38,481] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74000, global step 1185266: loss 0.0111
[2019-03-23 18:46:38,485] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74000, global step 1185267: learning rate 0.0000
[2019-03-23 18:46:38,577] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74000, global step 1185315: loss 0.0051
[2019-03-23 18:46:38,583] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74000, global step 1185317: learning rate 0.0000
[2019-03-23 18:46:38,873] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74000, global step 1185455: loss 0.0926
[2019-03-23 18:46:38,879] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74000, global step 1185456: learning rate 0.0000
[2019-03-23 18:46:38,901] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74000, global step 1185471: loss 4.1600
[2019-03-23 18:46:38,904] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74000, global step 1185472: learning rate 0.0000
[2019-03-23 18:46:39,357] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74000, global step 1185697: loss 0.0061
[2019-03-23 18:46:39,359] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74000, global step 1185698: learning rate 0.0000
[2019-03-23 18:46:39,489] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74000, global step 1185766: loss 0.0064
[2019-03-23 18:46:39,491] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74000, global step 1185767: learning rate 0.0000
[2019-03-23 18:46:40,074] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74000, global step 1186057: loss 0.0132
[2019-03-23 18:46:40,077] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74000, global step 1186059: learning rate 0.0000
[2019-03-23 18:46:41,058] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2140450e-03 5.4864072e-06 9.9695337e-01 4.6173602e-04 1.3653943e-03], sum to 1.0000
[2019-03-23 18:46:41,063] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6087
[2019-03-23 18:46:41,072] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.0, 86.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 228581.9508431006, 228581.9508431003, 94513.74752214906], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4684800.0000, 
sim time next is 4685400.0000, 
raw observation next is [14.0, 85.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 229330.3884133237, 229330.388413324, 94319.96199814175], 
processed observation next is [1.0, 0.21739130434782608, 0.2727272727272727, 0.85, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0849371808938236, 0.0849371808938237, 0.23004868780034574], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5272248], dtype=float32), -1.7599283]. 
=============================================
[2019-03-23 18:46:42,563] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75000, global step 1187290: loss 2.0974
[2019-03-23 18:46:42,568] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75000, global step 1187290: learning rate 0.0000
[2019-03-23 18:46:44,090] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.9890529e-01 3.9991787e-06 7.7085799e-01 1.8303300e-03 2.8402466e-02], sum to 1.0000
[2019-03-23 18:46:44,100] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2702
[2019-03-23 18:46:44,104] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 88.0, 1.0, 2.0, 0.2076559989820951, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4048105346260722, 6.911199999999999, 6.9112, 77.32846344354104, 465667.0386856513, 465667.0386856516, 159850.0995952804], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4760400.0000, 
sim time next is 4761000.0000, 
raw observation next is [19.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3802443148163909, 6.911199999999999, 6.9112, 77.32846344354104, 437522.8807423605, 437522.8807423608, 157241.606563568], 
processed observation next is [1.0, 0.08695652173913043, 0.5, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.11463473545198706, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16204551138605944, 0.16204551138605955, 0.383516113569678], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.59421283], dtype=float32), -0.35534337]. 
=============================================
[2019-03-23 18:46:44,125] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[29.291122]
 [29.365192]
 [27.739733]
 [26.974993]
 [27.82629 ]], R is [[28.65013313]
 [28.97375488]
 [28.68401718]
 [29.08906746]
 [28.79817772]].
[2019-03-23 18:46:45,251] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74500, global step 1188620: loss 5.4408
[2019-03-23 18:46:45,253] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74500, global step 1188620: learning rate 0.0000
[2019-03-23 18:46:47,153] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.5806169e-03 4.9300092e-10 9.9734986e-01 4.1051771e-06 6.5436368e-05], sum to 1.0000
[2019-03-23 18:46:47,165] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1232
[2019-03-23 18:46:47,171] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.200913861120936, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3992385170623259, 6.9112, 6.9112, 77.32846344354104, 456011.2451555084, 456011.2451555084, 162559.1343133792], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4857000.0000, 
sim time next is 4857600.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3966219158207714, 6.9112, 6.9112, 77.32846344354104, 453030.7295494032, 453030.7295494032, 162284.0863010067], 
processed observation next is [1.0, 0.21739130434782608, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1380313083153877, 0.0, 0.0, 0.5084288129206541, 0.16778915909237155, 0.16778915909237155, 0.3958148446366017], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5911375], dtype=float32), -1.1451108]. 
=============================================
[2019-03-23 18:46:47,998] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.6755690e-03 8.6027291e-10 9.9450690e-01 1.8380146e-05 7.9921423e-04], sum to 1.0000
[2019-03-23 18:46:48,006] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6758
[2019-03-23 18:46:48,013] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.66666666666667, 96.0, 1.0, 2.0, 0.2550992495353584, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5160308365451103, 6.9112, 6.9112, 77.32846344354104, 581674.4547466973, 581674.4547466973, 179998.5263164959], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4814400.0000, 
sim time next is 4815000.0000, 
raw observation next is [21.5, 97.0, 1.0, 2.0, 0.2484072507762981, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5023547911441394, 6.911199999999999, 6.9112, 77.32846344354104, 566522.3056705081, 566522.3056705083, 178216.3208255976], 
processed observation next is [1.0, 0.7391304347826086, 0.6136363636363636, 0.97, 1.0, 1.0, 0.06050906347037262, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2890782730630563, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20982307617426224, 0.20982307617426232, 0.4346739532331649], 
reward next is 0.5653, 
noisyNet noise sample is [array([1.6229961], dtype=float32), 0.842503]. 
=============================================
[2019-03-23 18:46:48,034] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[46.321423]
 [44.45064 ]
 [43.321793]
 [43.234726]
 [43.114834]], R is [[47.88173294]
 [47.96389389]
 [48.00836945]
 [47.94430161]
 [47.86787415]].
[2019-03-23 18:46:51,829] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74500, global step 1191901: loss 10.0719
[2019-03-23 18:46:51,831] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74500, global step 1191902: learning rate 0.0000
[2019-03-23 18:46:52,432] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74500, global step 1192208: loss 33.7731
[2019-03-23 18:46:52,433] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74500, global step 1192208: learning rate 0.0000
[2019-03-23 18:46:53,479] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74500, global step 1192730: loss 77.0994
[2019-03-23 18:46:53,480] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74500, global step 1192730: learning rate 0.0000
[2019-03-23 18:46:53,498] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74500, global step 1192740: loss 77.4407
[2019-03-23 18:46:53,501] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74500, global step 1192743: learning rate 0.0000
[2019-03-23 18:46:54,104] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74500, global step 1193041: loss 69.3720
[2019-03-23 18:46:54,106] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74500, global step 1193041: learning rate 0.0000
[2019-03-23 18:46:54,335] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74500, global step 1193158: loss 78.9370
[2019-03-23 18:46:54,337] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74500, global step 1193158: learning rate 0.0000
[2019-03-23 18:46:54,386] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74500, global step 1193185: loss 79.7673
[2019-03-23 18:46:54,388] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74500, global step 1193186: learning rate 0.0000
[2019-03-23 18:46:54,391] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74500, global step 1193188: loss 81.9172
[2019-03-23 18:46:54,396] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74500, global step 1193190: learning rate 0.0000
[2019-03-23 18:46:54,682] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74500, global step 1193335: loss 86.9205
[2019-03-23 18:46:54,686] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74500, global step 1193335: learning rate 0.0000
[2019-03-23 18:46:54,928] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74500, global step 1193457: loss 95.3956
[2019-03-23 18:46:54,929] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74500, global step 1193457: learning rate 0.0000
[2019-03-23 18:46:54,989] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74500, global step 1193485: loss 137.6807
[2019-03-23 18:46:54,991] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74500, global step 1193487: learning rate 0.0000
[2019-03-23 18:46:55,438] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74500, global step 1193712: loss 107.9911
[2019-03-23 18:46:55,441] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74500, global step 1193713: learning rate 0.0000
[2019-03-23 18:46:55,669] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74500, global step 1193832: loss 85.4332
[2019-03-23 18:46:55,676] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74500, global step 1193833: learning rate 0.0000
[2019-03-23 18:46:55,913] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74500, global step 1193949: loss 105.0425
[2019-03-23 18:46:55,915] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74500, global step 1193949: learning rate 0.0000
[2019-03-23 18:46:58,606] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.8541137e-04 1.7581722e-06 9.9894780e-01 2.8758295e-04 3.7749251e-04], sum to 1.0000
[2019-03-23 18:46:58,613] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1241
[2019-03-23 18:46:58,618] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [13.16666666666667, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 235153.5784542314, 235153.5784542317, 97463.83796494201], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5028600.0000, 
sim time next is 5029200.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 228507.3005647861, 228507.3005647864, 95587.63739816146], 
processed observation next is [0.0, 0.21739130434782608, 0.22727272727272727, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08463233354251337, 0.08463233354251348, 0.233140579019906], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0986903], dtype=float32), -0.8678867]. 
=============================================
[2019-03-23 18:46:58,702] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75500, global step 1195334: loss 18.5945
[2019-03-23 18:46:58,705] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75500, global step 1195335: learning rate 0.0000
[2019-03-23 18:47:01,338] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75000, global step 1196650: loss -2.8084
[2019-03-23 18:47:01,340] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75000, global step 1196650: learning rate 0.0000
[2019-03-23 18:47:05,648] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8685781e-03 9.3185236e-13 9.9812585e-01 6.3682108e-07 4.9708397e-06], sum to 1.0000
[2019-03-23 18:47:05,654] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7347
[2019-03-23 18:47:05,661] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.16666666666666, 81.5, 1.0, 2.0, 0.2548994652504687, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5162378921550539, 6.9112, 6.9112, 77.32846344354104, 580095.8283763395, 580095.8283763395, 181233.479961596], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5140200.0000, 
sim time next is 5140800.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.2564799423029611, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5194681991466933, 6.9112, 6.9112, 77.32846344354104, 583561.2426936119, 583561.2426936119, 181729.1520678725], 
processed observation next is [0.0, 0.5217391304347826, 0.7272727272727273, 0.83, 1.0, 1.0, 0.07059992787870138, 0.0, 1.0, -0.25, 1.0, 1.0, 0.31352599878099047, 0.0, 0.0, 0.5084288129206541, 0.21613379359022664, 0.21613379359022664, 0.44324183431188413], 
reward next is 0.5568, 
noisyNet noise sample is [array([-1.1824011], dtype=float32), -0.0013515196]. 
=============================================
[2019-03-23 18:47:06,786] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.45534165e-02 3.56025522e-11 9.84567285e-01 1.60185607e-06
 8.77525948e-04], sum to 1.0000
[2019-03-23 18:47:06,791] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2588
[2019-03-23 18:47:06,796] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 83.0, 1.0, 2.0, 0.2389825532547875, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4826538030538352, 6.9112, 6.9112, 77.32846344354104, 545316.5398360774, 545316.5398360774, 175264.2400099273], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5175600.0000, 
sim time next is 5176200.0000, 
raw observation next is [23.0, 83.0, 1.0, 2.0, 0.2393128735283774, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4833214955019441, 6.911199999999999, 6.9112, 77.32846344354104, 546070.5476518334, 546070.5476518337, 175338.0347268661], 
processed observation next is [0.0, 0.9130434782608695, 0.6818181818181818, 0.83, 1.0, 1.0, 0.049141091910471744, 0.0, 1.0, -0.25, 1.0, 1.0, 0.261887850717063, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2022483509821605, 0.20224835098216065, 0.4276537432362588], 
reward next is 0.5723, 
noisyNet noise sample is [array([0.2583007], dtype=float32), -0.65265757]. 
=============================================
[2019-03-23 18:47:08,023] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75000, global step 1199962: loss 0.0750
[2019-03-23 18:47:08,026] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75000, global step 1199963: learning rate 0.0000
[2019-03-23 18:47:08,101] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 18:47:08,103] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:47:08,103] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:47:08,104] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:47:08,105] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:47:08,105] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:47:08,106] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:47:08,111] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:47:08,113] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:47:08,113] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:47:08,115] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:47:08,135] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run49
[2019-03-23 18:47:08,160] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run49
[2019-03-23 18:47:08,185] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run49
[2019-03-23 18:47:08,212] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run49
[2019-03-23 18:47:08,237] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run49
[2019-03-23 18:47:15,257] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00940762], dtype=float32), 0.007824879]
[2019-03-23 18:47:15,258] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.0, 88.0, 1.0, 2.0, 0.210247925838928, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3924868172632799, 6.911200000000001, 6.9112, 77.32846344354104, 456657.8230064646, 456657.8230064643, 142812.6540295653]
[2019-03-23 18:47:15,259] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:47:15,263] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.8462927e-03 7.2965765e-11 9.9698263e-01 1.0955215e-06 1.6999451e-04], sampled 0.11718947367050181
[2019-03-23 18:47:26,754] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00940762], dtype=float32), 0.007824879]
[2019-03-23 18:47:26,755] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.8, 90.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3564603304421596, 6.911200000000001, 6.9112, 95.55338769695034, 409958.6173571781, 409958.6173571778, 158984.7764639676]
[2019-03-23 18:47:26,758] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:47:26,761] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.6950807e-03 8.9740142e-12 9.9822718e-01 3.2160025e-07 7.7308971e-05], sampled 0.33709632328544525
[2019-03-23 18:47:47,847] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00940762], dtype=float32), 0.007824879]
[2019-03-23 18:47:47,848] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 94.0, 1.0, 2.0, 0.2506666547514391, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5071285917136129, 6.9112, 6.9112, 77.32846344354104, 571498.5747714925, 571498.5747714925, 179049.5996538404]
[2019-03-23 18:47:47,849] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:47:47,853] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.4910285e-03 7.4960281e-12 9.9741876e-01 3.1790850e-07 8.9946567e-05], sampled 0.5350791172734645
[2019-03-23 18:48:20,140] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00940762], dtype=float32), 0.007824879]
[2019-03-23 18:48:20,140] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.48866986666667, 82.13244255666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 253230.0835820885, 253230.0835820882, 107366.1657630327]
[2019-03-23 18:48:20,141] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:48:20,147] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.7574638e-03 2.3338462e-08 9.9175900e-01 4.2467251e-05 1.4411249e-03], sampled 0.49853909195652724
[2019-03-23 18:48:29,403] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00940762], dtype=float32), 0.007824879]
[2019-03-23 18:48:29,405] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.7, 92.33333333333334, 1.0, 2.0, 0.3963554142140784, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8009691064086945, 6.9112, 6.9112, 95.55335695050906, 904423.3531427175, 904423.3531427175, 226923.2508755105]
[2019-03-23 18:48:29,408] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:48:29,412] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.4918239e-03 2.5025053e-11 9.9737000e-01 7.3793586e-07 1.3740556e-04], sampled 0.6500592530955361
[2019-03-23 18:48:45,480] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2765.2697 2123046850.0304 767.0000
[2019-03-23 18:48:45,582] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3366.0113 2096915816.0642 187.0000
[2019-03-23 18:48:45,776] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3528.3399 2103043301.1947 184.0000
[2019-03-23 18:48:45,834] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3127.6403 2107740058.0416 379.0000
[2019-03-23 18:48:45,851] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3609.3071 2174231221.6163 258.0000
[2019-03-23 18:48:46,866] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1200000, evaluation results [1200000.0, 3609.3070833851916, 2174231221.6162753, 258.0, 3366.011326030566, 2096915816.064187, 187.0, 3528.3398676976067, 2103043301.1946898, 184.0, 2765.2697473106305, 2123046850.030414, 767.0, 3127.64027043519, 2107740058.0416021, 379.0]
[2019-03-23 18:48:47,167] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75000, global step 1200148: loss 0.2660
[2019-03-23 18:48:47,171] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75000, global step 1200149: learning rate 0.0000
[2019-03-23 18:48:48,220] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75000, global step 1200683: loss 0.1342
[2019-03-23 18:48:48,222] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75000, global step 1200683: learning rate 0.0000
[2019-03-23 18:48:48,284] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75000, global step 1200707: loss 0.3032
[2019-03-23 18:48:48,286] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75000, global step 1200707: learning rate 0.0000
[2019-03-23 18:48:48,918] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75000, global step 1201027: loss 0.1934
[2019-03-23 18:48:48,921] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75000, global step 1201029: learning rate 0.0000
[2019-03-23 18:48:49,215] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75000, global step 1201182: loss 0.1240
[2019-03-23 18:48:49,218] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75000, global step 1201182: learning rate 0.0000
[2019-03-23 18:48:49,247] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75000, global step 1201196: loss 0.0898
[2019-03-23 18:48:49,249] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75000, global step 1201197: learning rate 0.0000
[2019-03-23 18:48:49,284] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75000, global step 1201214: loss 0.2236
[2019-03-23 18:48:49,287] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75000, global step 1201214: learning rate 0.0000
[2019-03-23 18:48:49,478] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75000, global step 1201309: loss 0.0719
[2019-03-23 18:48:49,482] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75000, global step 1201310: learning rate 0.0000
[2019-03-23 18:48:49,690] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75000, global step 1201418: loss 0.0357
[2019-03-23 18:48:49,695] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75000, global step 1201418: learning rate 0.0000
[2019-03-23 18:48:49,794] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75000, global step 1201469: loss 0.0281
[2019-03-23 18:48:49,797] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75000, global step 1201470: learning rate 0.0000
[2019-03-23 18:48:50,204] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75000, global step 1201673: loss 0.0207
[2019-03-23 18:48:50,208] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75000, global step 1201674: learning rate 0.0000
[2019-03-23 18:48:50,605] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75000, global step 1201870: loss 0.0181
[2019-03-23 18:48:50,608] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75000, global step 1201870: learning rate 0.0000
[2019-03-23 18:48:50,712] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75000, global step 1201929: loss 0.0226
[2019-03-23 18:48:50,716] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75000, global step 1201929: learning rate 0.0000
[2019-03-23 18:48:51,765] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0196053e-03 3.5382977e-09 9.9781787e-01 9.2224500e-06 1.1531924e-03], sum to 1.0000
[2019-03-23 18:48:51,776] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3274
[2019-03-23 18:48:51,784] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.15, 75.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3888428574001337, 6.9112, 6.9112, 77.32846344354104, 444183.5119101137, 444183.5119101137, 161191.6921966798], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5298600.0000, 
sim time next is 5299200.0000, 
raw observation next is [22.7, 73.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3938842036492206, 6.9112, 6.9112, 77.32846344354104, 449451.5083401317, 449451.5083401317, 162289.8723732726], 
processed observation next is [1.0, 0.34782608695652173, 0.6681818181818181, 0.73, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.13412029092745803, 0.0, 0.0, 0.5084288129206541, 0.1664635216074562, 0.1664635216074562, 0.395828957007982], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8004638], dtype=float32), 0.3024129]. 
=============================================
[2019-03-23 18:48:53,562] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76000, global step 1203350: loss 29.4375
[2019-03-23 18:48:53,564] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76000, global step 1203350: learning rate 0.0000
[2019-03-23 18:48:55,430] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.8977349e-04 2.8389118e-09 9.9960989e-01 4.2166273e-05 1.5809949e-04], sum to 1.0000
[2019-03-23 18:48:55,441] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3037
[2019-03-23 18:48:55,449] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.28333333333333, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 307812.1152165401, 307812.1152165404, 125243.3955858244], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5890200.0000, 
sim time next is 5890800.0000, 
raw observation next is [16.46666666666667, 86.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 295627.938148035, 295627.9381480352, 122511.7697562936], 
processed observation next is [1.0, 0.17391304347826086, 0.38484848484848494, 0.86, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10949182894371667, 0.10949182894371674, 0.29880919452754534], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.9919815], dtype=float32), -0.37560904]. 
=============================================
[2019-03-23 18:48:55,492] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.3635177e-04 3.2897224e-10 9.9880195e-01 1.5359418e-06 2.6014820e-04], sum to 1.0000
[2019-03-23 18:48:55,505] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2912
[2019-03-23 18:48:55,509] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.5, 87.0, 1.0, 2.0, 0.2201009957557121, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4376272347770582, 6.9112, 6.9112, 77.32846344354104, 499743.4841302434, 499743.4841302434, 166174.3276505884], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5371200.0000, 
sim time next is 5371800.0000, 
raw observation next is [20.41666666666667, 87.0, 1.0, 2.0, 0.2182165698423192, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4333057033466491, 6.9112, 6.9112, 77.32846344354104, 495105.6881572517, 495105.6881572517, 165498.0932967936], 
processed observation next is [1.0, 0.17391304347826086, 0.5643939393939396, 0.87, 1.0, 1.0, 0.022770712302899003, 0.0, 1.0, -0.25, 1.0, 1.0, 0.19043671906664159, 0.0, 0.0, 0.5084288129206541, 0.1833724770952784, 0.1833724770952784, 0.4036538860897405], 
reward next is 0.5963, 
noisyNet noise sample is [array([-1.3387176], dtype=float32), 1.4733907]. 
=============================================
[2019-03-23 18:48:56,250] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75500, global step 1204697: loss 0.4994
[2019-03-23 18:48:56,255] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75500, global step 1204697: learning rate 0.0000
[2019-03-23 18:49:02,717] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75500, global step 1207923: loss 18.8142
[2019-03-23 18:49:02,719] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75500, global step 1207923: learning rate 0.0000
[2019-03-23 18:49:03,140] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75500, global step 1208118: loss 14.9598
[2019-03-23 18:49:03,142] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75500, global step 1208119: learning rate 0.0000
[2019-03-23 18:49:03,685] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.2756734e-04 1.2392699e-04 9.9602169e-01 2.7423357e-03 7.8443269e-04], sum to 1.0000
[2019-03-23 18:49:03,695] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6419
[2019-03-23 18:49:03,701] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.7, 75.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 298556.0863775608, 298556.0863775605, 121877.4193241618], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6044400.0000, 
sim time next is 6045000.0000, 
raw observation next is [17.61666666666667, 75.83333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 297201.3594138383, 297201.3594138381, 121867.8701932954], 
processed observation next is [1.0, 1.0, 0.4371212121212123, 0.7583333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11007457756068086, 0.11007457756068077, 0.29723870778852535], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.05308058], dtype=float32), -0.053726397]. 
=============================================
[2019-03-23 18:49:03,715] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[1.5294633]
 [1.5963515]
 [1.6424122]
 [1.6711813]
 [1.7079935]], R is [[1.46891582]
 [1.45422673]
 [1.43968451]
 [1.42528772]
 [1.41103482]].
[2019-03-23 18:49:04,006] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.2434883e-03 5.7802213e-06 9.6944302e-01 2.1211051e-03 2.2186575e-02], sum to 1.0000
[2019-03-23 18:49:04,009] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0955
[2019-03-23 18:49:04,016] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.8, 87.0, 1.0, 2.0, 0.2113205020817778, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4213817648984637, 6.9112, 6.9112, 77.32846344354104, 480507.5778131796, 480507.5778131796, 165260.1957555754], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5535000.0000, 
sim time next is 5535600.0000, 
raw observation next is [20.7, 87.0, 1.0, 2.0, 0.2095686830444158, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4174262654144503, 6.9112, 6.9112, 77.32846344354104, 476259.09217609, 476259.09217609, 164660.4502564829], 
processed observation next is [1.0, 0.043478260869565216, 0.5772727272727273, 0.87, 1.0, 1.0, 0.011960853805519749, 0.0, 1.0, -0.25, 1.0, 1.0, 0.16775180773492906, 0.0, 0.0, 0.5084288129206541, 0.17639225636151482, 0.17639225636151482, 0.40161085428410465], 
reward next is 0.5984, 
noisyNet noise sample is [array([1.2594644], dtype=float32), -0.27378747]. 
=============================================
[2019-03-23 18:49:04,083] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75500, global step 1208595: loss 13.6008
[2019-03-23 18:49:04,085] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75500, global step 1208596: learning rate 0.0000
[2019-03-23 18:49:04,253] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75500, global step 1208679: loss 8.8579
[2019-03-23 18:49:04,256] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75500, global step 1208680: learning rate 0.0000
[2019-03-23 18:49:05,071] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75500, global step 1209091: loss 0.4561
[2019-03-23 18:49:05,073] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75500, global step 1209091: learning rate 0.0000
[2019-03-23 18:49:05,183] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75500, global step 1209148: loss 0.5456
[2019-03-23 18:49:05,186] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75500, global step 1209149: learning rate 0.0000
[2019-03-23 18:49:05,237] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75500, global step 1209170: loss 0.3538
[2019-03-23 18:49:05,238] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75500, global step 1209170: learning rate 0.0000
[2019-03-23 18:49:05,351] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75500, global step 1209231: loss 0.0784
[2019-03-23 18:49:05,353] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75500, global step 1209232: learning rate 0.0000
[2019-03-23 18:49:05,413] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75500, global step 1209255: loss 0.0409
[2019-03-23 18:49:05,414] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75500, global step 1209255: learning rate 0.0000
[2019-03-23 18:49:05,750] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75500, global step 1209428: loss 0.0763
[2019-03-23 18:49:05,750] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75500, global step 1209428: learning rate 0.0000
[2019-03-23 18:49:05,962] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75500, global step 1209539: loss -1.3355
[2019-03-23 18:49:05,966] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75500, global step 1209541: learning rate 0.0000
[2019-03-23 18:49:06,288] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75500, global step 1209691: loss 0.0825
[2019-03-23 18:49:06,290] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75500, global step 1209692: learning rate 0.0000
[2019-03-23 18:49:06,638] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75500, global step 1209868: loss -2.1487
[2019-03-23 18:49:06,640] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75500, global step 1209868: learning rate 0.0000
[2019-03-23 18:49:06,835] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75500, global step 1209969: loss 0.0812
[2019-03-23 18:49:06,842] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75500, global step 1209970: learning rate 0.0000
[2019-03-23 18:49:09,658] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76500, global step 1211376: loss 0.0153
[2019-03-23 18:49:09,663] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76500, global step 1211376: learning rate 0.0000
[2019-03-23 18:49:10,380] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.63818035e-04 1.00160425e-04 9.94602501e-01 2.76644132e-03
 1.86702295e-03], sum to 1.0000
[2019-03-23 18:49:10,392] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8658
[2019-03-23 18:49:10,398] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.06666666666667, 64.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 265506.0120608422, 265506.0120608425, 102581.6787368724], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5818200.0000, 
sim time next is 5818800.0000, 
raw observation next is [17.53333333333333, 63.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 270228.3601099845, 270228.3601099848, 105018.3814000113], 
processed observation next is [1.0, 0.34782608695652173, 0.43333333333333324, 0.6366666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1000845778185128, 0.10008457781851289, 0.25614239365856417], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.6469278], dtype=float32), 0.3210592]. 
=============================================
[2019-03-23 18:49:11,291] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.8677857e-04 1.2731786e-04 9.9613816e-01 2.3064238e-03 7.4140052e-04], sum to 1.0000
[2019-03-23 18:49:11,297] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1394
[2019-03-23 18:49:11,302] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [15.5, 85.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 258056.8789274665, 258056.8789274668, 105601.1779934139], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5667600.0000, 
sim time next is 5668200.0000, 
raw observation next is [15.5, 84.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 254065.2162612343, 254065.2162612341, 104206.943386515], 
processed observation next is [0.0, 0.6086956521739131, 0.3409090909090909, 0.84, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09409822824490159, 0.09409822824490152, 0.2541632765524756], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.14739539], dtype=float32), -0.1660234]. 
=============================================
[2019-03-23 18:49:12,434] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76000, global step 1212749: loss 0.0729
[2019-03-23 18:49:12,436] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76000, global step 1212749: learning rate 0.0000
[2019-03-23 18:49:14,671] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.2027796e-03 8.7405286e-05 9.9521035e-01 2.5874360e-03 9.1208512e-04], sum to 1.0000
[2019-03-23 18:49:14,681] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3998
[2019-03-23 18:49:14,688] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [10.71666666666667, 87.83333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 145976.272943368, 145976.2729433683, 74804.76290550189], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5727000.0000, 
sim time next is 5727600.0000, 
raw observation next is [11.1, 86.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 150442.7336004584, 150442.7336004587, 75524.51038691669], 
processed observation next is [0.0, 0.30434782608695654, 0.1409090909090909, 0.86, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.055719530963132737, 0.055719530963132854, 0.18420612289491875], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.2740479], dtype=float32), -0.029663619]. 
=============================================
[2019-03-23 18:49:18,825] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76000, global step 1215923: loss 11.7408
[2019-03-23 18:49:18,826] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76000, global step 1215923: learning rate 0.0000
[2019-03-23 18:49:19,076] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76000, global step 1216048: loss 7.5127
[2019-03-23 18:49:19,077] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76000, global step 1216048: learning rate 0.0000
[2019-03-23 18:49:20,244] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76000, global step 1216633: loss 18.7271
[2019-03-23 18:49:20,248] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76000, global step 1216634: learning rate 0.0000
[2019-03-23 18:49:20,445] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76000, global step 1216732: loss -10.9616
[2019-03-23 18:49:20,447] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76000, global step 1216732: learning rate 0.0000
[2019-03-23 18:49:21,123] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76000, global step 1217069: loss 12.2855
[2019-03-23 18:49:21,127] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76000, global step 1217070: learning rate 0.0000
[2019-03-23 18:49:21,270] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76000, global step 1217145: loss 11.5758
[2019-03-23 18:49:21,271] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76000, global step 1217146: learning rate 0.0000
[2019-03-23 18:49:21,287] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76000, global step 1217151: loss 17.5142
[2019-03-23 18:49:21,290] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76000, global step 1217152: learning rate 0.0000
[2019-03-23 18:49:21,518] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76000, global step 1217262: loss 10.9895
[2019-03-23 18:49:21,522] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76000, global step 1217262: learning rate 0.0000
[2019-03-23 18:49:21,662] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76000, global step 1217336: loss 13.1384
[2019-03-23 18:49:21,664] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76000, global step 1217336: learning rate 0.0000
[2019-03-23 18:49:21,959] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76000, global step 1217484: loss 3.5949
[2019-03-23 18:49:21,960] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76000, global step 1217484: learning rate 0.0000
[2019-03-23 18:49:22,048] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76000, global step 1217524: loss 4.5334
[2019-03-23 18:49:22,052] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76000, global step 1217525: learning rate 0.0000
[2019-03-23 18:49:22,253] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76000, global step 1217626: loss 2.2509
[2019-03-23 18:49:22,255] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76000, global step 1217626: learning rate 0.0000
[2019-03-23 18:49:22,363] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.7617408e-04 2.5290754e-05 9.9567574e-01 1.8632537e-03 1.4595669e-03], sum to 1.0000
[2019-03-23 18:49:22,372] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7817
[2019-03-23 18:49:22,374] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.9, 55.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3115494780957931, 6.9112, 6.9112, 77.32846344354104, 360215.0618025628, 360215.0618025628, 147117.9915372764], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5863200.0000, 
sim time next is 5863800.0000, 
raw observation next is [22.8, 56.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3125432548680577, 6.911200000000001, 6.9112, 77.32846344354104, 361237.9103423876, 361237.9103423873, 147357.5594015383], 
processed observation next is [1.0, 0.8695652173913043, 0.6727272727272727, 0.56, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.017918935525796695, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13379181864532874, 0.13379181864532863, 0.3594086814671666], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8544752], dtype=float32), -1.2377629]. 
=============================================
[2019-03-23 18:49:22,662] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76000, global step 1217835: loss 2.2733
[2019-03-23 18:49:22,669] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76000, global step 1217836: learning rate 0.0000
[2019-03-23 18:49:22,939] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76000, global step 1217972: loss 4.5603
[2019-03-23 18:49:22,940] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76000, global step 1217973: learning rate 0.0000
[2019-03-23 18:49:25,814] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77000, global step 1219409: loss 2.8127
[2019-03-23 18:49:25,816] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77000, global step 1219409: learning rate 0.0000
[2019-03-23 18:49:28,420] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76500, global step 1220712: loss 0.0386
[2019-03-23 18:49:28,423] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76500, global step 1220712: learning rate 0.0000
[2019-03-23 18:49:29,259] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.7411385e-02 1.8955504e-04 9.1925901e-01 9.2977695e-03 4.3842282e-02], sum to 1.0000
[2019-03-23 18:49:29,260] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7968
[2019-03-23 18:49:29,265] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.7, 80.83333333333333, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 285916.4893313827, 285916.4893313824, 119935.4522783564], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6051000.0000, 
sim time next is 6051600.0000, 
raw observation next is [16.6, 81.0, 1.0, 2.0, 0.2, 0.0, 1.0, 0.0, 1.0, 1.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 282717.681084291, 282717.6810842913, 114084.4906240724], 
processed observation next is [1.0, 0.043478260869565216, 0.390909090909091, 0.81, 1.0, 1.0, 0.0, 0.0, 0.5, -0.25, 1.0, 0.5, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10471025225344112, 0.10471025225344123, 0.2782548551806644], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0039448], dtype=float32), 0.8886531]. 
=============================================
[2019-03-23 18:49:29,715] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.1702775e-02 4.1269403e-05 5.9622490e-01 7.5728960e-02 2.7630210e-01], sum to 1.0000
[2019-03-23 18:49:29,723] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3392
[2019-03-23 18:49:29,729] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.5, 69.5, 1.0, 2.0, 0.3584515064251251, 1.0, 1.0, 0.3584515064251251, 1.0, 2.0, 0.7260404981134824, 6.9112, 6.9112, 77.3421103, 1220286.437333538, 1220286.437333538, 283732.2741240248], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6016200.0000, 
sim time next is 6016800.0000, 
raw observation next is [25.5, 70.0, 1.0, 2.0, 0.591694176454082, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9754433656562915, 6.911200000000001, 6.9112, 77.32846335137546, 1221702.364791835, 1221702.364791835, 274803.5802650155], 
processed observation next is [1.0, 0.6521739130434783, 0.7954545454545454, 0.7, 1.0, 1.0, 0.4896177205676024, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9649190937947022, 8.881784197001253e-17, 0.0, 0.5084288123146724, 0.4524823573303092, 0.4524823573303092, 0.6702526347927207], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.39792505], dtype=float32), 0.6730396]. 
=============================================
[2019-03-23 18:49:34,775] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76500, global step 1223888: loss -1.2477
[2019-03-23 18:49:34,779] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76500, global step 1223889: learning rate 0.0000
[2019-03-23 18:49:35,126] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76500, global step 1224069: loss -2.9792
[2019-03-23 18:49:35,128] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76500, global step 1224069: learning rate 0.0000
[2019-03-23 18:49:36,264] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.7726550e-02 6.1220337e-05 6.8801302e-01 1.4460887e-02 2.7973834e-01], sum to 1.0000
[2019-03-23 18:49:36,272] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6136
[2019-03-23 18:49:36,279] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.8, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3355970119978393, 6.9112, 6.9112, 77.32846344354104, 386887.5301668243, 386887.5301668243, 150980.6696073546], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6652800.0000, 
sim time next is 6653400.0000, 
raw observation next is [18.8, 87.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.336383823018057, 6.9112, 6.9112, 77.32846344354104, 387706.636619507, 387706.636619507, 151159.0354488803], 
processed observation next is [1.0, 0.0, 0.49090909090909096, 0.875, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.05197689002579577, 0.0, 0.0, 0.5084288129206541, 0.1435950505998174, 0.1435950505998174, 0.3686805742655617], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.44184965], dtype=float32), 0.007603753]. 
=============================================
[2019-03-23 18:49:36,430] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76500, global step 1224664: loss -1.5712
[2019-03-23 18:49:36,431] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76500, global step 1224664: learning rate 0.0000
[2019-03-23 18:49:36,442] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76500, global step 1224666: loss 7.5756
[2019-03-23 18:49:36,446] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76500, global step 1224666: learning rate 0.0000
[2019-03-23 18:49:37,075] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 18:49:37,076] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:49:37,078] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:49:37,079] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:49:37,080] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:49:37,081] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:49:37,083] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:49:37,084] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:49:37,079] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:49:37,085] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:49:37,081] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:49:37,098] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run50
[2019-03-23 18:49:37,098] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run50
[2019-03-23 18:49:37,148] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run50
[2019-03-23 18:49:37,148] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run50
[2019-03-23 18:49:37,195] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run50
[2019-03-23 18:49:56,734] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00894917], dtype=float32), 0.0077737025]
[2019-03-23 18:49:56,735] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.055802495, 70.64805572333333, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 486790.8326198172, 486790.8326198172, 201723.4545645235]
[2019-03-23 18:49:56,737] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:49:56,740] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.4837020e-02 1.6396320e-05 2.7897140e-01 5.9189154e-03 6.7025632e-01], sampled 0.4970937400147918
[2019-03-23 18:50:02,240] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00894917], dtype=float32), 0.0077737025]
[2019-03-23 18:50:02,241] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.61666666666667, 42.5, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 277230.4075482194, 277230.4075482191, 126307.3712697355]
[2019-03-23 18:50:02,242] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:50:02,245] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.04305319 0.00093674 0.55176884 0.02657895 0.3776623 ], sampled 0.6572040591491983
[2019-03-23 18:50:05,623] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00894917], dtype=float32), 0.0077737025]
[2019-03-23 18:50:05,624] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.05, 87.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7023255886123695, 7.048648943094387, 6.9112, 95.55290362988548, 458983.7130354835, 403822.4014586678, 130475.4367710715]
[2019-03-23 18:50:05,625] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:50:05,627] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.6067957e-02 1.6443655e-05 2.7826637e-01 5.7470514e-03 6.6990221e-01], sampled 0.08353749435702917
[2019-03-23 18:50:31,518] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00894917], dtype=float32), 0.0077737025]
[2019-03-23 18:50:31,520] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.9909834, 75.16166274, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 240955.2667082282, 240955.2667082278, 125336.4841111487]
[2019-03-23 18:50:31,524] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:50:31,528] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.5342175e-02 1.1335038e-05 2.6626319e-01 4.6248916e-03 6.7375839e-01], sampled 0.15466818972511098
[2019-03-23 18:51:09,899] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00894917], dtype=float32), 0.0077737025]
[2019-03-23 18:51:09,902] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.93333333333333, 81.33333333333334, 1.0, 2.0, 0.2306858499649568, 0.0, 1.0, 0.0, 1.0, 2.0, 0.4652763736269142, 6.911199999999999, 6.9112, 77.32846344354104, 526454.5404583409, 526454.5404583411, 172808.7177392843]
[2019-03-23 18:51:09,904] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:51:09,907] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.9416997e-02 3.6027702e-06 2.4194692e-01 2.8542681e-03 7.0577824e-01], sampled 0.5192249369180433
[2019-03-23 18:51:14,131] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 1152.7523 2309094231.2944 254.0000
[2019-03-23 18:51:14,612] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 1099.2842 2321053499.0140 287.0000
[2019-03-23 18:51:14,883] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 1407.8321 2383320525.6175 218.0000
[2019-03-23 18:51:14,970] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 1047.6997 2324221794.1741 397.0000
[2019-03-23 18:51:15,044] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 1156.0040 2319305369.0266 254.0000
[2019-03-23 18:51:16,062] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1225000, evaluation results [1225000.0, 1407.8320853494754, 2383320525.6175084, 218.0, 1152.7523159437778, 2309094231.2943892, 254.0, 1099.2841757218325, 2321053499.014041, 287.0, 1047.699680600515, 2324221794.174083, 397.0, 1156.0040449024405, 2319305369.026569, 254.0]
[2019-03-23 18:51:16,197] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76500, global step 1225064: loss -1.4404
[2019-03-23 18:51:16,199] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76500, global step 1225064: loss 2.9977
[2019-03-23 18:51:16,200] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76500, global step 1225064: learning rate 0.0000
[2019-03-23 18:51:16,202] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76500, global step 1225064: learning rate 0.0000
[2019-03-23 18:51:16,342] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76500, global step 1225135: loss 1.8298
[2019-03-23 18:51:16,343] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76500, global step 1225135: learning rate 0.0000
[2019-03-23 18:51:16,657] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76500, global step 1225291: loss -2.2413
[2019-03-23 18:51:16,659] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76500, global step 1225291: learning rate 0.0000
[2019-03-23 18:51:16,722] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76500, global step 1225320: loss -1.3720
[2019-03-23 18:51:16,724] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76500, global step 1225321: learning rate 0.0000
[2019-03-23 18:51:17,129] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76500, global step 1225524: loss 0.6420
[2019-03-23 18:51:17,132] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76500, global step 1225525: learning rate 0.0000
[2019-03-23 18:51:17,169] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76500, global step 1225545: loss -1.5475
[2019-03-23 18:51:17,173] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76500, global step 1225545: learning rate 0.0000
[2019-03-23 18:51:17,252] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76500, global step 1225587: loss 4.1007
[2019-03-23 18:51:17,254] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76500, global step 1225587: learning rate 0.0000
[2019-03-23 18:51:17,725] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76500, global step 1225823: loss -0.6986
[2019-03-23 18:51:17,726] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76500, global step 1225823: learning rate 0.0000
[2019-03-23 18:51:18,082] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76500, global step 1226007: loss -0.3140
[2019-03-23 18:51:18,083] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76500, global step 1226007: learning rate 0.0000
[2019-03-23 18:51:20,780] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77500, global step 1227359: loss -0.9717
[2019-03-23 18:51:20,782] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77500, global step 1227360: learning rate 0.0000
[2019-03-23 18:51:23,714] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77000, global step 1228782: loss -0.1846
[2019-03-23 18:51:23,716] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77000, global step 1228782: learning rate 0.0000
[2019-03-23 18:51:25,036] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.6489235e-02 4.6588284e-05 5.2005023e-01 6.8554250e-03 4.4655854e-01], sum to 1.0000
[2019-03-23 18:51:25,040] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6324
[2019-03-23 18:51:25,052] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [19.0, 88.5, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 407549.1993134398, 407549.1993134401, 177537.4818331507], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6832200.0000, 
sim time next is 6832800.0000, 
raw observation next is [18.8, 90.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 407380.7070143162, 407380.7070143162, 177484.5394105368], 
processed observation next is [0.0, 0.08695652173913043, 0.49090909090909096, 0.9, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5085185399722538, 0.15088174333863563, 0.15088174333863563, 0.43288912051350437], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5018284], dtype=float32), 1.4947052]. 
=============================================
[2019-03-23 18:51:26,078] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.6026492e-02 9.0702735e-05 5.4528123e-01 4.4632088e-03 3.7413830e-01], sum to 1.0000
[2019-03-23 18:51:26,087] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8324
[2019-03-23 18:51:26,090] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [12.61666666666667, 86.5, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 203350.0521227161, 203350.0521227161, 109265.0036838196], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6498600.0000, 
sim time next is 6499200.0000, 
raw observation next is [12.53333333333333, 87.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 198786.4180313033, 198786.4180313036, 107938.7244795136], 
processed observation next is [1.0, 0.21739130434782608, 0.2060606060606059, 0.87, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.07362459927085307, 0.07362459927085319, 0.26326518165735024], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.29609808], dtype=float32), -0.579037]. 
=============================================
[2019-03-23 18:51:27,905] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3036193e-02 1.1538950e-07 9.3910331e-01 1.4673580e-03 4.6392996e-02], sum to 1.0000
[2019-03-23 18:51:27,910] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1482
[2019-03-23 18:51:27,921] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 68.0, 1.0, 2.0, 0.2522808685471993, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5088965322477349, 6.9112, 6.9112, 77.32846344354104, 575764.5352624675, 575764.5352624675, 177656.536728272], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6411000.0000, 
sim time next is 6411600.0000, 
raw observation next is [25.0, 68.0, 1.0, 2.0, 0.2483234735584113, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5008923607360102, 6.911199999999999, 6.9112, 77.32846344354104, 566728.2770314986, 566728.277031499, 176727.2410087672], 
processed observation next is [1.0, 0.21739130434782608, 0.7727272727272727, 0.68, 1.0, 1.0, 0.06040434194801412, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2869890867657289, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.209899361863518, 0.20989936186351812, 0.43104205124089556], 
reward next is 0.5690, 
noisyNet noise sample is [array([0.18799104], dtype=float32), 0.7336471]. 
=============================================
[2019-03-23 18:51:29,936] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77000, global step 1231873: loss 0.8547
[2019-03-23 18:51:29,937] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77000, global step 1231873: learning rate 0.0000
[2019-03-23 18:51:30,280] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77000, global step 1232040: loss 0.3992
[2019-03-23 18:51:30,281] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77000, global step 1232040: learning rate 0.0000
[2019-03-23 18:51:31,632] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77000, global step 1232715: loss 0.0498
[2019-03-23 18:51:31,635] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77000, global step 1232716: learning rate 0.0000
[2019-03-23 18:51:31,769] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77000, global step 1232784: loss 0.0952
[2019-03-23 18:51:31,771] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77000, global step 1232784: learning rate 0.0000
[2019-03-23 18:51:32,331] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77000, global step 1233066: loss -2.1030
[2019-03-23 18:51:32,333] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77000, global step 1233067: learning rate 0.0000
[2019-03-23 18:51:32,340] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77000, global step 1233071: loss 3.0270
[2019-03-23 18:51:32,341] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77000, global step 1233071: learning rate 0.0000
[2019-03-23 18:51:32,548] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77000, global step 1233172: loss 3.2578
[2019-03-23 18:51:32,557] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77000, global step 1233172: learning rate 0.0000
[2019-03-23 18:51:32,656] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.7143731e-03 2.2732607e-09 9.6218544e-01 1.6207691e-06 3.4098540e-02], sum to 1.0000
[2019-03-23 18:51:32,664] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0464
[2019-03-23 18:51:32,669] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.2, 90.5, 1.0, 2.0, 0.3139282339465375, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6081578995322078, 6.9112, 6.9112, 77.32846344354104, 701044.7939592308, 701044.7939592308, 180293.4520499014], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6447000.0000, 
sim time next is 6447600.0000, 
raw observation next is [18.3, 90.0, 1.0, 2.0, 0.334097997463764, 0.0, 2.0, 0.0, 1.0, 2.0, 0.647796910643762, 6.9112, 6.9112, 77.32846344354104, 746588.5454016336, 746588.5454016336, 185577.9156260884], 
processed observation next is [1.0, 0.6521739130434783, 0.4681818181818182, 0.9, 1.0, 1.0, 0.16762249682970498, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4968527294910886, 0.0, 0.0, 0.5084288129206541, 0.2765142760746791, 0.2765142760746791, 0.4526290625026546], 
reward next is 0.5474, 
noisyNet noise sample is [array([0.11606564], dtype=float32), -0.68871176]. 
=============================================
[2019-03-23 18:51:32,776] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77000, global step 1233288: loss 4.5719
[2019-03-23 18:51:32,782] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77000, global step 1233288: learning rate 0.0000
[2019-03-23 18:51:32,950] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77000, global step 1233374: loss -2.4090
[2019-03-23 18:51:32,951] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77000, global step 1233375: learning rate 0.0000
[2019-03-23 18:51:33,068] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.1976146e-02 7.2487092e-07 9.7246605e-01 9.1355375e-04 1.4643425e-02], sum to 1.0000
[2019-03-23 18:51:33,074] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9995
[2019-03-23 18:51:33,078] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [15.0, 80.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 229184.0381849104, 229184.0381849107, 117814.6361997732], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6480000.0000, 
sim time next is 6480600.0000, 
raw observation next is [15.0, 79.5, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.3421103, 228564.9974961643, 228564.9974961641, 116768.838375358], 
processed observation next is [1.0, 0.0, 0.3181818181818182, 0.795, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5085185399722538, 0.08465370277635714, 0.08465370277635707, 0.28480204481794635], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.4291876], dtype=float32), 1.08138]. 
=============================================
[2019-03-23 18:51:33,088] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77000, global step 1233441: loss 11.9264
[2019-03-23 18:51:33,090] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77000, global step 1233442: learning rate 0.0000
[2019-03-23 18:51:33,228] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77000, global step 1233511: loss 9.1405
[2019-03-23 18:51:33,230] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77000, global step 1233512: learning rate 0.0000
[2019-03-23 18:51:33,375] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77000, global step 1233584: loss 7.7597
[2019-03-23 18:51:33,377] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77000, global step 1233585: learning rate 0.0000
[2019-03-23 18:51:33,901] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77000, global step 1233842: loss -63.0103
[2019-03-23 18:51:33,903] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77000, global step 1233843: learning rate 0.0000
[2019-03-23 18:51:34,044] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77000, global step 1233918: loss 23.1582
[2019-03-23 18:51:34,051] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77000, global step 1233920: learning rate 0.0000
[2019-03-23 18:51:36,993] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78000, global step 1235377: loss 1.2320
[2019-03-23 18:51:36,996] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78000, global step 1235378: learning rate 0.0000
[2019-03-23 18:51:39,746] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77500, global step 1236759: loss 10.4643
[2019-03-23 18:51:39,749] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77500, global step 1236760: learning rate 0.0000
[2019-03-23 18:51:40,876] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.4715148e-02 5.8938515e-08 9.1822177e-01 1.2004569e-04 5.6943003e-02], sum to 1.0000
[2019-03-23 18:51:40,881] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2133
[2019-03-23 18:51:40,893] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.71666666666667, 90.5, 1.0, 2.0, 0.2121724971677754, 0.0, 2.0, 0.0, 1.0, 2.0, 0.413229634996303, 6.9112, 6.9112, 77.32846344354104, 475492.1625038179, 475492.1625038179, 160438.0756465001], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6660600.0000, 
sim time next is 6661200.0000, 
raw observation next is [18.63333333333333, 91.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3760263822077257, 6.911200000000001, 6.9112, 77.32846344354104, 432704.6094582826, 432704.6094582823, 156669.4501860434], 
processed observation next is [1.0, 0.08695652173913043, 0.48333333333333317, 0.91, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.10860911743960819, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16026096646603058, 0.16026096646603047, 0.38212061020986193], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.8516095], dtype=float32), 1.8667679]. 
=============================================
[2019-03-23 18:51:40,962] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.0548825e-03 4.7733901e-09 9.9163204e-01 4.7099006e-06 6.3083288e-03], sum to 1.0000
[2019-03-23 18:51:40,968] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6906
[2019-03-23 18:51:40,973] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.53333333333333, 76.0, 1.0, 2.0, 0.3832803870683459, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7676533083052308, 6.911199999999999, 6.9112, 77.32846344354104, 873573.7450896271, 873573.7450896275, 211438.488315965], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6778200.0000, 
sim time next is 6778800.0000, 
raw observation next is [22.6, 76.0, 1.0, 2.0, 0.3922258319862948, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7860648298775801, 6.911199999999999, 6.9112, 77.32846344354104, 894195.1952892456, 894195.1952892459, 214800.2785221672], 
processed observation next is [1.0, 0.4782608695652174, 0.6636363636363637, 0.76, 1.0, 1.0, 0.24028228998286846, 0.0, 1.0, -0.25, 1.0, 1.0, 0.694378328396543, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.33118340566268356, 0.33118340566268367, 0.5239031183467493], 
reward next is 0.4761, 
noisyNet noise sample is [array([0.76214474], dtype=float32), 1.2505388]. 
=============================================
[2019-03-23 18:51:43,721] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.0371681e-02 9.0680061e-08 7.5238794e-01 9.8158140e-05 2.2714217e-01], sum to 1.0000
[2019-03-23 18:51:43,729] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9914
[2019-03-23 18:51:43,734] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [19.1, 88.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3638867799741836, 6.9112, 6.9112, 77.32846344354104, 418395.6395305149, 418395.6395305149, 155446.4561343774], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6679800.0000, 
sim time next is 6680400.0000, 
raw observation next is [19.0, 89.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 416105.3121279007, 416105.312127901, 178835.5962668583], 
processed observation next is [1.0, 0.30434782608695654, 0.5, 0.89, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.15411307856588916, 0.15411307856588927, 0.4361843811386788], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.90543395], dtype=float32), -1.8608106]. 
=============================================
[2019-03-23 18:51:45,972] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77500, global step 1239855: loss 6.9386
[2019-03-23 18:51:45,974] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77500, global step 1239855: learning rate 0.0000
[2019-03-23 18:51:46,451] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77500, global step 1240095: loss -1.7366
[2019-03-23 18:51:46,457] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77500, global step 1240095: learning rate 0.0000
[2019-03-23 18:51:47,805] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77500, global step 1240766: loss 4.9582
[2019-03-23 18:51:47,806] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77500, global step 1240766: loss 1.6626
[2019-03-23 18:51:47,807] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77500, global step 1240766: learning rate 0.0000
[2019-03-23 18:51:47,808] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77500, global step 1240768: learning rate 0.0000
[2019-03-23 18:51:48,226] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77500, global step 1240985: loss -0.9060
[2019-03-23 18:51:48,227] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77500, global step 1240985: learning rate 0.0000
[2019-03-23 18:51:48,402] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77500, global step 1241070: loss 1.0133
[2019-03-23 18:51:48,405] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77500, global step 1241070: learning rate 0.0000
[2019-03-23 18:51:48,549] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77500, global step 1241144: loss 8.1230
[2019-03-23 18:51:48,557] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77500, global step 1241146: learning rate 0.0000
[2019-03-23 18:51:48,781] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77500, global step 1241252: loss -1.3508
[2019-03-23 18:51:48,783] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77500, global step 1241252: learning rate 0.0000
[2019-03-23 18:51:49,035] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77500, global step 1241380: loss 0.3879
[2019-03-23 18:51:49,037] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77500, global step 1241382: learning rate 0.0000
[2019-03-23 18:51:49,118] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.1499261e-02 2.3618210e-07 2.2527356e-01 1.8382387e-04 7.5304312e-01], sum to 1.0000
[2019-03-23 18:51:49,125] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9593
[2019-03-23 18:51:49,129] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [18.71666666666667, 87.5, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 392697.3529333971, 392697.3529333973, 174431.7853220165], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6930600.0000, 
sim time next is 6931200.0000, 
raw observation next is [18.63333333333333, 88.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 391689.0233117686, 391689.0233117689, 174075.7231876419], 
processed observation next is [0.0, 0.21739130434782608, 0.48333333333333317, 0.88, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.14507000863398836, 0.14507000863398847, 0.42457493460400464], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.0929532], dtype=float32), 0.42754638]. 
=============================================
[2019-03-23 18:51:49,188] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77500, global step 1241453: loss 7.3775
[2019-03-23 18:51:49,192] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77500, global step 1241454: learning rate 0.0000
[2019-03-23 18:51:49,213] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77500, global step 1241464: loss -2.1506
[2019-03-23 18:51:49,214] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77500, global step 1241464: learning rate 0.0000
[2019-03-23 18:51:49,431] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77500, global step 1241570: loss -3.2604
[2019-03-23 18:51:49,435] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77500, global step 1241571: learning rate 0.0000
[2019-03-23 18:51:50,104] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77500, global step 1241902: loss 1.6215
[2019-03-23 18:51:50,105] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77500, global step 1241902: learning rate 0.0000
[2019-03-23 18:51:50,251] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77500, global step 1241974: loss -4.0155
[2019-03-23 18:51:50,255] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77500, global step 1241975: learning rate 0.0000
[2019-03-23 18:51:51,549] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.5026326e-02 1.8414327e-04 3.6729568e-01 7.6230736e-03 5.6987077e-01], sum to 1.0000
[2019-03-23 18:51:51,559] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7381
[2019-03-23 18:51:51,567] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.06666666666667, 68.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 456158.0909389089, 456158.0909389092, 188575.9827750906], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6810000.0000, 
sim time next is 6810600.0000, 
raw observation next is [22.88333333333333, 69.5, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 461394.8019912381, 461394.8019912384, 189588.3346768914], 
processed observation next is [1.0, 0.8260869565217391, 0.6765151515151513, 0.695, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.17088696370045856, 0.17088696370045867, 0.4624105723826619], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.81475383], dtype=float32), -1.0418708]. 
=============================================
[2019-03-23 18:51:53,230] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78500, global step 1243442: loss 8.9766
[2019-03-23 18:51:53,233] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78500, global step 1243442: learning rate 0.0000
[2019-03-23 18:51:54,716] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.1813564e-02 2.0152587e-04 3.2208297e-01 7.0651150e-03 6.4883679e-01], sum to 1.0000
[2019-03-23 18:51:54,723] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5915
[2019-03-23 18:51:54,729] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.0, 74.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 451905.0953275031, 451905.0953275031, 187567.6297035891], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6909600.0000, 
sim time next is 6910200.0000, 
raw observation next is [21.9, 74.5, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 450526.8546362513, 450526.8546362513, 187264.7124619451], 
processed observation next is [0.0, 1.0, 0.6318181818181817, 0.745, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5085185399722538, 0.1668617980134264, 0.1668617980134264, 0.45674320112669536], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6681941], dtype=float32), -0.22469762]. 
=============================================
[2019-03-23 18:51:55,807] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78000, global step 1244725: loss 9.3921
[2019-03-23 18:51:55,810] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78000, global step 1244725: learning rate 0.0000
[2019-03-23 18:51:57,218] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.4651979e-02 2.1672901e-04 6.7045659e-01 7.1739932e-03 2.6750070e-01], sum to 1.0000
[2019-03-23 18:51:57,229] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2185
[2019-03-23 18:51:57,231] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.2, 90.5, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 385500.6222337585, 385500.6222337585, 172581.0095507268], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7081800.0000, 
sim time next is 7082400.0000, 
raw observation next is [18.1, 91.0, 1.0, 2.0, 0.2, 0.0, 1.0, 0.0, 1.0, 2.0, 0.3319215132416939, 6.9112, 6.9112, 77.32846344354104, 382912.9387527006, 382912.9387527006, 150289.016712392], 
processed observation next is [1.0, 1.0, 0.45909090909090916, 0.91, 1.0, 1.0, 0.0, 0.0, 0.5, -0.25, 1.0, 1.0, 0.04560216177384843, 0.0, 0.0, 0.5084288129206541, 0.14181960694544465, 0.14181960694544465, 0.3665585773472976], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6693981], dtype=float32), -0.27235317]. 
=============================================
[2019-03-23 18:52:00,059] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.0043496e-02 8.0545133e-06 4.6758157e-01 1.5790967e-03 4.9078768e-01], sum to 1.0000
[2019-03-23 18:52:00,066] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2683
[2019-03-23 18:52:00,073] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.36666666666667, 69.66666666666666, 1.0, 2.0, 0.2496735401297134, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5049876452953875, 6.9112, 6.9112, 77.32846344354104, 569355.1011734855, 569355.1011734855, 178614.8896901731], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6982800.0000, 
sim time next is 6983400.0000, 
raw observation next is [25.18333333333334, 70.33333333333334, 1.0, 2.0, 0.2488018657821209, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5031022900275705, 6.9112, 6.9112, 77.32846344354104, 567459.0977820582, 567459.0977820582, 178237.300158312], 
processed observation next is [0.0, 0.8260869565217391, 0.7810606060606063, 0.7033333333333335, 1.0, 1.0, 0.06100233222765112, 0.0, 1.0, -0.25, 1.0, 1.0, 0.29014612861081496, 0.0, 0.0, 0.5084288129206541, 0.2101700362155771, 0.2101700362155771, 0.43472512233734634], 
reward next is 0.5653, 
noisyNet noise sample is [array([-1.8828515], dtype=float32), -0.9785251]. 
=============================================
[2019-03-23 18:52:00,842] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.6608447e-02 2.7682373e-07 4.7223821e-01 9.3078423e-05 4.4106001e-01], sum to 1.0000
[2019-03-23 18:52:00,849] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9350
[2019-03-23 18:52:00,854] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [18.8, 97.0, 1.0, 2.0, 0.3101074483850283, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6144539195271645, 6.9112, 6.9112, 77.32846344354104, 702894.4697381989, 702894.4697381989, 185461.6452714969], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7032600.0000, 
sim time next is 7033200.0000, 
raw observation next is [18.8, 97.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.389727598416088, 6.911199999999999, 6.9112, 77.3421103, 667314.9213777027, 667314.9213777031, 215736.0444053906], 
processed observation next is [1.0, 0.391304347826087, 0.49090909090909096, 0.97, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.12818228345155433, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.24715367458433435, 0.2471536745843345, 0.5261854741594892], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.54523104], dtype=float32), -0.20417856]. 
=============================================
[2019-03-23 18:52:02,046] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78000, global step 1247835: loss -2.1843
[2019-03-23 18:52:02,047] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78000, global step 1247835: learning rate 0.0000
[2019-03-23 18:52:02,494] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78000, global step 1248066: loss -0.1067
[2019-03-23 18:52:02,498] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78000, global step 1248067: learning rate 0.0000
[2019-03-23 18:52:03,844] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78000, global step 1248727: loss 0.3253
[2019-03-23 18:52:03,847] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78000, global step 1248728: learning rate 0.0000
[2019-03-23 18:52:04,008] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78000, global step 1248799: loss 1.7294
[2019-03-23 18:52:04,011] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78000, global step 1248799: learning rate 0.0000
[2019-03-23 18:52:04,335] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78000, global step 1248937: loss 0.3536
[2019-03-23 18:52:04,337] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78000, global step 1248937: learning rate 0.0000
[2019-03-23 18:52:04,661] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78000, global step 1249082: loss 4.2751
[2019-03-23 18:52:04,662] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78000, global step 1249082: learning rate 0.0000
[2019-03-23 18:52:04,844] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78000, global step 1249179: loss 0.9322
[2019-03-23 18:52:04,846] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78000, global step 1249179: learning rate 0.0000
[2019-03-23 18:52:05,069] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78000, global step 1249302: loss -12.3074
[2019-03-23 18:52:05,071] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78000, global step 1249303: learning rate 0.0000
[2019-03-23 18:52:05,236] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78000, global step 1249390: loss 0.4261
[2019-03-23 18:52:05,239] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78000, global step 1249390: learning rate 0.0000
[2019-03-23 18:52:05,323] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78000, global step 1249435: loss -2.6902
[2019-03-23 18:52:05,332] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78000, global step 1249436: learning rate 0.0000
[2019-03-23 18:52:05,426] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78000, global step 1249485: loss 0.1957
[2019-03-23 18:52:05,427] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78000, global step 1249485: learning rate 0.0000
[2019-03-23 18:52:05,504] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78000, global step 1249525: loss 0.0217
[2019-03-23 18:52:05,507] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78000, global step 1249525: learning rate 0.0000
[2019-03-23 18:52:06,308] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78000, global step 1249949: loss 0.0472
[2019-03-23 18:52:06,310] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78000, global step 1249949: learning rate 0.0000
[2019-03-23 18:52:06,377] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78000, global step 1249988: loss 1.0628
[2019-03-23 18:52:06,384] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78000, global step 1249988: learning rate 0.0000
[2019-03-23 18:52:06,403] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 18:52:06,405] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:52:06,406] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:52:06,406] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:52:06,406] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:52:06,406] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:52:06,408] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:52:06,411] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:52:06,410] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:52:06,412] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:52:06,413] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:52:06,437] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run51
[2019-03-23 18:52:06,459] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run51
[2019-03-23 18:52:06,485] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run51
[2019-03-23 18:52:06,511] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run51
[2019-03-23 18:52:06,512] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run51
[2019-03-23 18:52:14,590] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0092832], dtype=float32), 0.0077968733]
[2019-03-23 18:52:14,592] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [14.3, 73.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 220264.4920123404, 220264.4920123401, 117056.3412329719]
[2019-03-23 18:52:14,593] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:52:14,595] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.4286693e-02 1.9383817e-06 8.5498881e-01 4.0712164e-04 1.2031550e-01], sampled 0.50223220337288
[2019-03-23 18:52:29,013] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0092832], dtype=float32), 0.0077968733]
[2019-03-23 18:52:29,015] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.86666666666667, 89.33333333333334, 1.0, 2.0, 0.2052803333045032, 1.0, 1.0, 0.2052803333045032, 1.0, 2.0, 0.4128985241444406, 6.9112, 6.9112, 95.55338769695034, 702525.5610453524, 702525.5610453524, 228691.0447594302]
[2019-03-23 18:52:29,017] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:52:29,019] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.04072203e-02 3.88589712e-08 8.70257080e-01 4.95438690e-05
 1.09286144e-01], sampled 0.35428938944427457
[2019-03-23 18:52:39,947] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0092832], dtype=float32), 0.0077968733]
[2019-03-23 18:52:39,948] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [28.3, 48.33333333333334, 1.0, 2.0, 0.2485708271277912, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5001337802143333, 6.9112, 6.9112, 95.55338769695034, 567091.9320736434, 567091.9320736434, 180427.8094149503]
[2019-03-23 18:52:39,948] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:52:39,952] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.0445583e-02 1.2423286e-07 8.6717403e-01 1.0023540e-04 1.1227999e-01], sampled 0.7230846928074154
[2019-03-23 18:52:41,480] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0092832], dtype=float32), 0.0077968733]
[2019-03-23 18:52:41,482] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.7, 84.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.390664679418681, 6.9112, 6.9112, 95.55338769695034, 446662.5027791384, 446662.5027791384, 165698.7854578987]
[2019-03-23 18:52:41,483] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:52:41,485] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.6199615e-02 1.6385762e-07 8.8569212e-01 1.0568690e-04 9.8002262e-02], sampled 0.2302239293743984
[2019-03-23 18:52:42,283] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0092832], dtype=float32), 0.0077968733]
[2019-03-23 18:52:42,283] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.68333333333333, 90.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 502926.5878271064, 502926.587827106, 203110.7635747361]
[2019-03-23 18:52:42,285] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:52:42,287] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.0905402e-02 3.5970695e-07 8.6694974e-01 1.7290289e-04 1.1197168e-01], sampled 0.5398706437076956
[2019-03-23 18:52:59,303] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0092832], dtype=float32), 0.0077968733]
[2019-03-23 18:52:59,304] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.88969005666667, 82.89124884333334, 1.0, 2.0, 0.2023013093611046, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3885739310453599, 6.911200000000001, 6.9112, 95.55338769695034, 448788.4922250687, 448788.4922250684, 161178.1141958663]
[2019-03-23 18:52:59,305] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:52:59,309] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.79517493e-02 1.63451588e-07 8.80900979e-01 1.06755440e-04
 1.01040326e-01], sampled 0.7539759790999384
[2019-03-23 18:53:09,912] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0092832], dtype=float32), 0.0077968733]
[2019-03-23 18:53:09,912] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.15, 82.66666666666666, 1.0, 2.0, 0.2863224224836609, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5546128172159422, 6.9112, 6.9112, 95.55338769695034, 639222.0384268691, 639222.0384268691, 178740.3425598961]
[2019-03-23 18:53:09,913] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:53:09,917] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.98058449e-02 4.33016609e-08 8.67882192e-01 5.34595893e-05
 1.12258434e-01], sampled 0.5750567044278612
[2019-03-23 18:53:18,451] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0092832], dtype=float32), 0.0077968733]
[2019-03-23 18:53:18,453] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.38341342666667, 66.74700109666666, 1.0, 2.0, 0.3598995381449665, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7289199706628291, 6.911200000000001, 6.9112, 95.55338769695034, 818992.4952062999, 818992.4952062996, 216847.0236372697]
[2019-03-23 18:53:18,454] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:53:18,460] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.0462103e-02 4.7125628e-08 8.6618435e-01 5.7655263e-05 1.1329590e-01], sampled 0.628096497468726
[2019-03-23 18:53:34,306] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0092832], dtype=float32), 0.0077968733]
[2019-03-23 18:53:34,307] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.83853264, 70.792960515, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 243638.0058038697, 243638.0058038697, 102007.9562405731]
[2019-03-23 18:53:34,308] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:53:34,310] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.87121537e-02 1.27190715e-05 8.83589625e-01 9.27528657e-04
 9.67579409e-02], sampled 0.7268479697607718
[2019-03-23 18:53:44,621] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 2876.1469 2134503745.2913 244.0000
[2019-03-23 18:53:44,778] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 2717.8496 2129026707.8207 246.0000
[2019-03-23 18:53:44,781] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 2619.8897 2135844397.7337 383.0000
[2019-03-23 18:53:44,799] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2289.6223 2152213800.7005 726.0000
[2019-03-23 18:53:44,897] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 2903.1528 2207739098.9085 279.0000
[2019-03-23 18:53:45,913] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1250000, evaluation results [1250000.0, 2903.152771006634, 2207739098.908487, 279.0, 2717.849601077976, 2129026707.8207126, 246.0, 2876.1469416499785, 2134503745.2913084, 244.0, 2289.622260509306, 2152213800.7004786, 726.0, 2619.8897268913424, 2135844397.7336545, 383.0]
[2019-03-23 18:53:46,464] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.9008097e-03 2.6481155e-05 9.2434496e-01 1.3003523e-03 6.7427397e-02], sum to 1.0000
[2019-03-23 18:53:46,476] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5995
[2019-03-23 18:53:46,481] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.5, 84.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3632514597106256, 6.9112, 6.9112, 77.32846344354104, 417952.8514375623, 417952.8514375623, 155101.2203635509], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7066200.0000, 
sim time next is 7066800.0000, 
raw observation next is [19.4, 84.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3589837415122839, 6.9112, 6.9112, 77.32846344354104, 413261.1054204163, 413261.1054204163, 154364.1865042024], 
processed observation next is [1.0, 0.8260869565217391, 0.5181818181818181, 0.84, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.08426248787469132, 0.0, 0.0, 0.5084288129206541, 0.15305966867422824, 0.15305966867422824, 0.3764980158639083], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.67871064], dtype=float32), 0.7405547]. 
=============================================
[2019-03-23 18:53:47,755] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.1437078e-02 5.3613257e-06 8.1171352e-01 1.1739251e-03 1.4567015e-01], sum to 1.0000
[2019-03-23 18:53:47,766] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2445
[2019-03-23 18:53:47,771] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.63333333333333, 51.66666666666666, 1.0, 2.0, 0.3686618114954116, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7144375088208984, 6.9112, 6.9112, 77.32846344354104, 823580.4666098611, 823580.4666098611, 194833.2684113097], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7134000.0000, 
sim time next is 7134600.0000, 
raw observation next is [23.71666666666667, 50.83333333333334, 1.0, 2.0, 0.3687244436267727, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7119307902467306, 6.9112, 6.9112, 77.32846344354104, 821524.0389664406, 821524.0389664406, 193787.3209535721], 
processed observation next is [1.0, 0.5652173913043478, 0.7143939393939395, 0.5083333333333334, 1.0, 1.0, 0.21090555453346585, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5884725574953295, 0.0, 0.0, 0.5084288129206541, 0.3042681625801632, 0.3042681625801632, 0.47265200232578564], 
reward next is 0.5273, 
noisyNet noise sample is [array([2.2724042], dtype=float32), -1.0151205]. 
=============================================
[2019-03-23 18:53:48,809] A3C_AGENT_WORKER-Thread-22 INFO:Local step 79000, global step 1251435: loss 0.8383
[2019-03-23 18:53:48,811] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 79000, global step 1251435: learning rate 0.0000
[2019-03-23 18:53:51,447] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78500, global step 1252759: loss 3.8558
[2019-03-23 18:53:51,449] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78500, global step 1252759: learning rate 0.0000
[2019-03-23 18:53:51,771] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1623919e-02 5.1642146e-06 6.7331302e-01 9.3296909e-04 3.1412491e-01], sum to 1.0000
[2019-03-23 18:53:51,779] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7649
[2019-03-23 18:53:51,789] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [19.95, 58.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.324441724875096, 6.911199999999999, 6.9112, 77.3421103, 566190.8522274985, 566190.8522274988, 191836.4217893411], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7205400.0000, 
sim time next is 7206000.0000, 
raw observation next is [20.33333333333334, 56.33333333333333, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3359701015506792, 6.911199999999999, 6.9112, 77.3421103, 586181.9686643904, 586181.9686643907, 193888.1144546464], 
processed observation next is [1.0, 0.391304347826087, 0.5606060606060609, 0.5633333333333332, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.05138585935811315, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.2171044328386631, 0.21710443283866324, 0.4728978401332839], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.0344605], dtype=float32), -0.7053312]. 
=============================================
[2019-03-23 18:53:51,809] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[17.92351 ]
 [17.799564]
 [16.676891]
 [16.145332]
 [16.337801]], R is [[17.24238396]
 [17.06995964]
 [17.53036499]
 [17.99441528]
 [18.47847748]].
[2019-03-23 18:53:51,894] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0885184e-02 4.9160386e-04 8.2447517e-01 1.4090035e-03 1.6273902e-01], sum to 1.0000
[2019-03-23 18:53:51,902] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3156
[2019-03-23 18:53:51,905] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.23333333333333, 56.33333333333334, 1.0, 2.0, 0.2, 0.0, 1.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 323824.6051200256, 323824.6051200259, 139859.349456889], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7240800.0000, 
sim time next is 7241400.0000, 
raw observation next is [21.05, 57.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 321643.7691744252, 321643.7691744255, 137723.2344281293], 
processed observation next is [1.0, 0.8260869565217391, 0.5931818181818183, 0.57, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11912732191645378, 0.1191273219164539, 0.3359103278734861], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.70540303], dtype=float32), 0.0019529365]. 
=============================================
[2019-03-23 18:53:54,517] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.22401896e-02 1.16082716e-04 6.06312215e-01 2.95461388e-03
 3.58376920e-01], sum to 1.0000
[2019-03-23 18:53:54,525] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9565
[2019-03-23 18:53:54,530] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.41666666666667, 55.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 327275.8886966557, 327275.888696656, 140582.8141246604], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7240200.0000, 
sim time next is 7240800.0000, 
raw observation next is [21.23333333333333, 56.33333333333334, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 323850.3108625794, 323850.3108625794, 159766.1643579535], 
processed observation next is [1.0, 0.8260869565217391, 0.6015151515151514, 0.5633333333333335, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5085185399722538, 0.11994455957873311, 0.11994455957873311, 0.3896735716047646], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.28841332], dtype=float32), 0.3626247]. 
=============================================
[2019-03-23 18:53:57,661] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78500, global step 1255845: loss 0.5539
[2019-03-23 18:53:57,663] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78500, global step 1255846: learning rate 0.0000
[2019-03-23 18:53:57,977] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78500, global step 1256000: loss 3.2068
[2019-03-23 18:53:57,977] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78500, global step 1256000: learning rate 0.0000
[2019-03-23 18:53:59,480] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78500, global step 1256745: loss 0.0125
[2019-03-23 18:53:59,481] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78500, global step 1256745: learning rate 0.0000
[2019-03-23 18:53:59,577] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78500, global step 1256792: loss 0.1521
[2019-03-23 18:53:59,580] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78500, global step 1256792: learning rate 0.0000
[2019-03-23 18:53:59,883] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78500, global step 1256941: loss 0.1386
[2019-03-23 18:53:59,886] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78500, global step 1256942: learning rate 0.0000
[2019-03-23 18:54:00,171] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78500, global step 1257085: loss -0.3172
[2019-03-23 18:54:00,173] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78500, global step 1257085: learning rate 0.0000
[2019-03-23 18:54:00,275] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78500, global step 1257137: loss 0.0539
[2019-03-23 18:54:00,279] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78500, global step 1257137: learning rate 0.0000
[2019-03-23 18:54:00,631] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78500, global step 1257308: loss 0.4688
[2019-03-23 18:54:00,631] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78500, global step 1257308: learning rate 0.0000
[2019-03-23 18:54:00,707] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78500, global step 1257351: loss 1.4515
[2019-03-23 18:54:00,715] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78500, global step 1257353: learning rate 0.0000
[2019-03-23 18:54:00,918] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78500, global step 1257454: loss -0.1837
[2019-03-23 18:54:00,922] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78500, global step 1257454: learning rate 0.0000
[2019-03-23 18:54:00,999] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78500, global step 1257492: loss -1.1666
[2019-03-23 18:54:01,000] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78500, global step 1257492: learning rate 0.0000
[2019-03-23 18:54:01,121] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78500, global step 1257550: loss -1.7742
[2019-03-23 18:54:01,125] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78500, global step 1257552: learning rate 0.0000
[2019-03-23 18:54:01,896] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78500, global step 1257940: loss 4.0177
[2019-03-23 18:54:01,898] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78500, global step 1257941: learning rate 0.0000
[2019-03-23 18:54:01,967] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78500, global step 1257973: loss -0.0218
[2019-03-23 18:54:01,969] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78500, global step 1257974: learning rate 0.0000
[2019-03-23 18:54:05,455] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:54:05,455] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:54:05,505] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run7
[2019-03-23 18:54:07,278] A3C_AGENT_WORKER-Thread-17 INFO:Local step 79000, global step 1260673: loss -0.5194
[2019-03-23 18:54:07,281] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 79000, global step 1260673: learning rate 0.0000
[2019-03-23 18:54:10,463] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.0252424e-02 7.1593398e-08 2.1528631e-01 2.5900954e-05 7.2443521e-01], sum to 1.0000
[2019-03-23 18:54:10,471] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4399
[2019-03-23 18:54:10,478] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [20.18333333333333, 95.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 489460.4575497409, 489460.4575497412, 195416.9546312078], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7542600.0000, 
sim time next is 7543200.0000, 
raw observation next is [20.36666666666667, 94.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 492461.2121285888, 492461.2121285888, 197030.5506535702], 
processed observation next is [0.0, 0.30434782608695654, 0.5621212121212124, 0.94, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5085185399722538, 0.18239304152910696, 0.18239304152910696, 0.48056231866724436], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.26197964], dtype=float32), 1.1130842]. 
=============================================
[2019-03-23 18:54:13,467] A3C_AGENT_WORKER-Thread-11 INFO:Local step 79000, global step 1263745: loss -0.0249
[2019-03-23 18:54:13,471] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 79000, global step 1263746: learning rate 0.0000
[2019-03-23 18:54:13,827] A3C_AGENT_WORKER-Thread-16 INFO:Local step 79000, global step 1263922: loss 0.2367
[2019-03-23 18:54:13,829] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 79000, global step 1263923: learning rate 0.0000
[2019-03-23 18:54:15,341] A3C_AGENT_WORKER-Thread-19 INFO:Local step 79000, global step 1264671: loss 0.0529
[2019-03-23 18:54:15,344] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 79000, global step 1264672: learning rate 0.0000
[2019-03-23 18:54:15,600] A3C_AGENT_WORKER-Thread-14 INFO:Local step 79000, global step 1264802: loss -7.0883
[2019-03-23 18:54:15,601] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 79000, global step 1264802: learning rate 0.0000
[2019-03-23 18:54:15,785] A3C_AGENT_WORKER-Thread-10 INFO:Local step 79000, global step 1264890: loss 0.1282
[2019-03-23 18:54:15,787] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 79000, global step 1264891: learning rate 0.0000
[2019-03-23 18:54:16,063] A3C_AGENT_WORKER-Thread-9 INFO:Local step 79000, global step 1265033: loss -3.5667
[2019-03-23 18:54:16,064] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 79000, global step 1265033: learning rate 0.0000
[2019-03-23 18:54:16,260] A3C_AGENT_WORKER-Thread-20 INFO:Local step 79000, global step 1265128: loss 0.0688
[2019-03-23 18:54:16,264] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 79000, global step 1265129: learning rate 0.0000
[2019-03-23 18:54:16,502] A3C_AGENT_WORKER-Thread-2 INFO:Local step 79000, global step 1265250: loss 0.2384
[2019-03-23 18:54:16,507] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 79000, global step 1265250: learning rate 0.0000
[2019-03-23 18:54:16,544] A3C_AGENT_WORKER-Thread-15 INFO:Local step 79000, global step 1265268: loss 0.0427
[2019-03-23 18:54:16,549] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 79000, global step 1265269: learning rate 0.0000
[2019-03-23 18:54:16,645] A3C_AGENT_WORKER-Thread-13 INFO:Local step 79000, global step 1265318: loss 1.9997
[2019-03-23 18:54:16,647] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 79000, global step 1265318: learning rate 0.0000
[2019-03-23 18:54:16,756] A3C_AGENT_WORKER-Thread-21 INFO:Local step 79000, global step 1265373: loss 0.3951
[2019-03-23 18:54:16,758] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 79000, global step 1265374: learning rate 0.0000
[2019-03-23 18:54:16,889] A3C_AGENT_WORKER-Thread-3 INFO:Local step 79000, global step 1265437: loss 0.7354
[2019-03-23 18:54:16,893] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 79000, global step 1265437: learning rate 0.0000
[2019-03-23 18:54:17,845] A3C_AGENT_WORKER-Thread-18 INFO:Local step 79000, global step 1265917: loss 0.1389
[2019-03-23 18:54:17,848] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 79000, global step 1265917: learning rate 0.0000
[2019-03-23 18:54:17,849] A3C_AGENT_WORKER-Thread-12 INFO:Local step 79000, global step 1265918: loss 0.7330
[2019-03-23 18:54:17,852] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 79000, global step 1265918: learning rate 0.0000
[2019-03-23 18:54:23,928] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:54:23,928] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:54:23,970] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run7
[2019-03-23 18:54:29,925] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:54:29,926] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:54:29,978] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run7
[2019-03-23 18:54:30,167] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:54:30,168] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:54:30,214] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run7
[2019-03-23 18:54:31,619] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.3951825e-02 1.2747528e-05 2.7106503e-01 2.5434903e-04 7.0471597e-01], sum to 1.0000
[2019-03-23 18:54:31,619] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0393
[2019-03-23 18:54:31,625] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 40.0, 1.0, 2.0, 0.2365867488446113, 1.0, 2.0, 0.2365867488446113, 1.0, 2.0, 0.4420620111304466, 6.9112, 6.9112, 77.3421103, 771047.573810731, 771047.573810731, 207812.8283564248], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 141600.0000, 
sim time next is 142200.0000, 
raw observation next is [23.0, 39.5, 1.0, 2.0, 0.3461387036112337, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6462560896808185, 6.9112, 6.9112, 77.32846344354104, 752040.5095706752, 752040.5095706752, 171272.5918565099], 
processed observation next is [1.0, 0.6521739130434783, 0.6818181818181818, 0.395, 1.0, 1.0, 0.18267337951404214, 0.0, 0.5, -0.25, 1.0, 1.0, 0.4946515566868836, 0.0, 0.0, 0.5084288129206541, 0.278533522063213, 0.278533522063213, 0.41773802891831685], 
reward next is 0.5823, 
noisyNet noise sample is [array([-1.3638905], dtype=float32), 0.20249914]. 
=============================================
[2019-03-23 18:54:31,641] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:54:31,641] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:54:31,707] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run7
[2019-03-23 18:54:31,906] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:54:31,906] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:54:31,910] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run7
[2019-03-23 18:54:31,945] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:54:31,946] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:54:31,987] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run7
[2019-03-23 18:54:32,041] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:54:32,042] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:54:32,057] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run7
[2019-03-23 18:54:32,213] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:54:32,214] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:54:32,235] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run7
[2019-03-23 18:54:32,255] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:54:32,258] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:54:32,277] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run7
[2019-03-23 18:54:32,308] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:54:32,311] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:54:32,319] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run7
[2019-03-23 18:54:32,376] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:54:32,376] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:54:32,391] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run7
[2019-03-23 18:54:32,447] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:54:32,448] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:54:32,453] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run7
[2019-03-23 18:54:32,504] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:54:32,505] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:54:32,508] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run7
[2019-03-23 18:54:32,874] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:54:32,874] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:54:32,877] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run7
[2019-03-23 18:54:32,926] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:54:32,926] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:54:32,940] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run7
[2019-03-23 18:54:36,824] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 18:54:36,827] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:54:36,828] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:54:36,831] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:54:36,832] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:54:36,832] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:54:36,833] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:54:36,835] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:54:36,833] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:54:36,835] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:54:36,837] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:54:36,854] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run52
[2019-03-23 18:54:36,881] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run52
[2019-03-23 18:54:36,882] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run52
[2019-03-23 18:54:36,930] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run52
[2019-03-23 18:54:36,930] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run52
[2019-03-23 18:54:47,755] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0092832], dtype=float32), 0.0076861745]
[2019-03-23 18:54:47,756] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.37300925333333, 88.01642167666668, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 333465.6474320219, 333465.6474320219, 136383.3233681226]
[2019-03-23 18:54:47,758] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:54:47,760] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.8945718e-02 7.2403770e-07 1.0023410e-01 4.0632349e-05 8.8077885e-01], sampled 0.9055888713314175
[2019-03-23 18:55:09,098] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0092832], dtype=float32), 0.0076861745]
[2019-03-23 18:55:09,099] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.06666666666667, 64.66666666666667, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 376071.5859963798, 376071.5859963798, 175017.4238406867]
[2019-03-23 18:55:09,100] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:55:09,102] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.58013029e-02 2.53832718e-06 1.14338115e-01 9.87886160e-05
 8.59759331e-01], sampled 0.04173380065735477
[2019-03-23 18:55:27,179] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0092832], dtype=float32), 0.0076861745]
[2019-03-23 18:55:27,181] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.41093785333333, 83.01361795499999, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3994200441927299, 6.9112, 6.9112, 95.55338769695034, 665387.4677499958, 665387.4677499958, 236569.7307784262]
[2019-03-23 18:55:27,183] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:55:27,190] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.7459119e-02 1.7505052e-07 7.1262859e-02 1.8640199e-05 9.1125923e-01], sampled 0.6415319417586558
[2019-03-23 18:55:46,724] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0092832], dtype=float32), 0.0076861745]
[2019-03-23 18:55:46,726] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.3, 51.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 353453.251978022, 353453.251978022, 166405.6185842112]
[2019-03-23 18:55:46,728] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:55:46,731] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.2622814e-02 1.0654163e-05 1.3780537e-01 2.7394242e-04 8.2928717e-01], sampled 0.25003121995013544
[2019-03-23 18:56:09,751] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0092832], dtype=float32), 0.0076861745]
[2019-03-23 18:56:09,754] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.13116001, 66.87299699, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3359150356262227, 6.911199999999999, 6.9112, 95.55338769695034, 565780.8996377002, 565780.8996377006, 217395.8768438523]
[2019-03-23 18:56:09,755] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:56:09,757] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.7112438e-02 6.4209345e-08 6.2875867e-02 9.8352748e-06 9.2000180e-01], sampled 0.0713825790677396
[2019-03-23 18:56:14,844] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 1138.4877 2469790429.8782 84.0000
[2019-03-23 18:56:15,036] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 734.9309 2419207124.8362 102.0000
[2019-03-23 18:56:15,565] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 852.9977 2418538665.0239 141.0000
[2019-03-23 18:56:15,585] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 780.4082 2407871916.6385 104.0000
[2019-03-23 18:56:15,603] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 845.8120 2411545689.0916 94.0000
[2019-03-23 18:56:16,620] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1275000, evaluation results [1275000.0, 1138.487658784056, 2469790429.8782043, 84.0, 780.4082258126383, 2407871916.638455, 104.0, 734.93094788656, 2419207124.836166, 102.0, 852.9977205833476, 2418538665.0238895, 141.0, 845.8120174820798, 2411545689.091603, 94.0]
[2019-03-23 18:56:17,606] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0989931e-01 3.3327044e-04 4.6438074e-01 3.3385784e-03 4.2204809e-01], sum to 1.0000
[2019-03-23 18:56:17,616] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0944
[2019-03-23 18:56:17,621] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.0, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 254147.3731672341, 254147.3731672338, 102734.6714322207], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 84600.0000, 
sim time next is 85200.0000, 
raw observation next is [16.0, 77.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4345779853689571, 6.9112, 6.9112, 77.32846344354104, 252762.4387260021, 252762.4387260021, 67257.07160347149], 
processed observation next is [1.0, 1.0, 0.36363636363636365, 0.77, 0.0, 0.5, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.19225426481279587, 0.0, 0.0, 0.5084288129206541, 0.09361571804666743, 0.09361571804666743, 0.16404163805724753], 
reward next is 0.8360, 
noisyNet noise sample is [array([1.6515669], dtype=float32), -0.5740863]. 
=============================================
[2019-03-23 18:56:21,265] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.2750153e-02 6.5293584e-06 6.8133451e-02 2.0335653e-04 8.6890656e-01], sum to 1.0000
[2019-03-23 18:56:21,273] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6718
[2019-03-23 18:56:21,276] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.0, 50.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 302591.934570613, 302591.9345706133, 156586.2924893227], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 219600.0000, 
sim time next is 220200.0000, 
raw observation next is [21.0, 55.33333333333334, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 297996.7755162695, 297996.7755162695, 155136.88883981], 
processed observation next is [0.0, 0.5652173913043478, 0.5909090909090909, 0.5533333333333335, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5085185399722538, 0.11036917611713686, 0.11036917611713686, 0.3783826557068537], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.25639418], dtype=float32), 0.48705843]. 
=============================================
[2019-03-23 18:56:22,561] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.005152e-01 9.421250e-06 6.377163e-02 3.379104e-04 8.353659e-01], sum to 1.0000
[2019-03-23 18:56:22,569] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8803
[2019-03-23 18:56:22,578] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [14.0, 88.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 219517.317191696, 219517.3171916963, 114892.0630229595], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 180000.0000, 
sim time next is 180600.0000, 
raw observation next is [13.83333333333333, 89.00000000000001, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.3421103, 218046.0472625841, 218046.0472625839, 114436.7478568418], 
processed observation next is [0.0, 0.08695652173913043, 0.265151515151515, 0.8900000000000001, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5085185399722538, 0.08075779528243855, 0.08075779528243848, 0.2791140191630288], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.60747296], dtype=float32), -0.034115396]. 
=============================================
[2019-03-23 18:56:24,144] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.7285159e-01 1.9120713e-05 4.0909123e-02 4.2689312e-04 6.8579328e-01], sum to 1.0000
[2019-03-23 18:56:24,152] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8742
[2019-03-23 18:56:24,153] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.8897332e-02 5.4640964e-06 4.5128398e-02 1.7012675e-04 9.1579872e-01], sum to 1.0000
[2019-03-23 18:56:24,159] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [14.0, 94.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.4028657770374922, 6.9112, 6.9112, 77.32846344354104, 234346.1170417123, 234346.1170417123, 62771.64756300996], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 198000.0000, 
sim time next is 198600.0000, 
raw observation next is [14.5, 91.16666666666667, 1.0, 1.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 241083.9705942993, 241083.9705942996, 127569.4524278498], 
processed observation next is [0.0, 0.30434782608695654, 0.29545454545454547, 0.9116666666666667, 1.0, 0.5, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.08929035947937011, 0.08929035947937022, 0.3111450059215849], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.44761088], dtype=float32), 0.23620754]. 
=============================================
[2019-03-23 18:56:24,163] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2078
[2019-03-23 18:56:24,167] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [18.66666666666667, 73.66666666666667, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 302676.5091601416, 302676.5091601416, 156707.7052670647], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 208200.0000, 
sim time next is 208800.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 310668.4372857236, 310668.4372857236, 158277.1543608913], 
processed observation next is [0.0, 0.43478260869565216, 0.5, 0.73, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5085185399722538, 0.11506238417989761, 0.11506238417989761, 0.3860418399046129], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4980341], dtype=float32), 0.4677326]. 
=============================================
[2019-03-23 18:56:30,980] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.5925170e-01 4.7832956e-11 1.4554504e-03 4.3927638e-08 3.9292894e-02], sum to 1.0000
[2019-03-23 18:56:30,990] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1235
[2019-03-23 18:56:30,994] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7542596251088239, 7.232394675731679, 6.9112, 77.32751038952576, 537385.9607984615, 433069.7853747141, 132271.4682320573], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 880800.0000, 
sim time next is 881400.0000, 
raw observation next is [19.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.761931190291222, 7.298788567755461, 6.9112, 77.32727450480145, 563562.4805761918, 437683.5767664443, 132998.609006105], 
processed observation next is [0.0, 0.17391304347826086, 0.5, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6599017004160316, 0.038758856775546136, 0.0, 0.5084209957381435, 0.20872684465784883, 0.1621050284320164, 0.3243868512344024], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.10376399], dtype=float32), 0.7543076]. 
=============================================
[2019-03-23 18:56:35,073] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9723035e-01 8.8344367e-15 2.6129102e-03 4.4974341e-12 1.5663457e-04], sum to 1.0000
[2019-03-23 18:56:35,080] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4179
[2019-03-23 18:56:35,086] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.66666666666667, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.37006311854839, 6.911200000000001, 6.9112, 77.32846344354104, 215230.5260255428, 215230.5260255425, 70423.56889389986], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 422400.0000, 
sim time next is 423000.0000, 
raw observation next is [14.5, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3696670122783324, 6.9112, 6.9112, 77.32846344354104, 215000.0977599503, 215000.0977599503, 70519.60496724275], 
processed observation next is [1.0, 0.9130434782608695, 0.29545454545454547, 0.88, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.09952430325476055, 0.0, 0.0, 0.5084288129206541, 0.07962966583701862, 0.07962966583701862, 0.1719990365054701], 
reward next is 0.8280, 
noisyNet noise sample is [array([-1.2596966], dtype=float32), -1.574984]. 
=============================================
[2019-03-23 18:56:35,109] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[59.8999  ]
 [59.91501 ]
 [59.93999 ]
 [59.914593]
 [59.885048]], R is [[60.11831665]
 [60.34537125]
 [60.56958771]
 [60.79163361]
 [61.01161194]].
[2019-03-23 18:56:38,159] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9996674e-01 1.7927525e-16 2.0727903e-05 7.2205649e-12 1.2505384e-05], sum to 1.0000
[2019-03-23 18:56:38,166] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1949
[2019-03-23 18:56:38,175] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 559381.8090129258 W.
[2019-03-23 18:56:38,179] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7510113380696194, 7.288184521733811, 6.9112, 77.32752962594758, 559381.8090129258, 436946.4255667671, 111449.8102408206], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 480000.0000, 
sim time next is 480600.0000, 
raw observation next is [14.0, 100.0, 1.0, 1.0, 0.4967124899816686, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32823663687648, 539474.8983684422, 539474.8983684418, 115167.7016103334], 
processed observation next is [1.0, 0.5652173913043478, 0.2727272727272727, 1.0, 1.0, 0.5, 0.3708906124770857, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084273216839466, 0.19980551791423784, 0.19980551791423773, 0.2808968331959351], 
reward next is 0.7191, 
noisyNet noise sample is [array([-1.3450657], dtype=float32), 0.42278287]. 
=============================================
[2019-03-23 18:56:54,089] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9993408e-01 4.4722150e-11 4.4268708e-07 4.3651971e-09 6.5437576e-05], sum to 1.0000
[2019-03-23 18:56:54,094] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6338
[2019-03-23 18:56:54,100] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 616969.992596114 W.
[2019-03-23 18:56:54,107] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 56.0, 1.0, 2.0, 0.5434666122319481, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 616969.992596114, 616969.9925961138, 149443.3941577293], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 826800.0000, 
sim time next is 827400.0000, 
raw observation next is [29.0, 55.5, 1.0, 2.0, 0.2701381659114359, 1.0, 1.0, 0.2701381659114359, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 612136.8321640952, 612136.8321640952, 185281.3367248084], 
processed observation next is [0.0, 0.5652173913043478, 0.9545454545454546, 0.555, 1.0, 1.0, 0.08767270738929488, 1.0, 0.5, 0.08767270738929488, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2267173452459612, 0.2267173452459612, 0.451905699328801], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.02940831], dtype=float32), -2.379321]. 
=============================================
[2019-03-23 18:56:57,333] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9585211e-01 2.4579101e-06 2.1197827e-04 5.4202534e-05 3.8792279e-03], sum to 1.0000
[2019-03-23 18:56:57,339] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4861
[2019-03-23 18:56:57,347] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 563754.636923826 W.
[2019-03-23 18:56:57,353] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.33333333333334, 88.66666666666667, 1.0, 2.0, 0.2473916068271807, 1.0, 1.0, 0.2473916068271807, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 563754.636923826, 563754.6369238256, 179118.0250360631], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1358400.0000, 
sim time next is 1359000.0000, 
raw observation next is [22.5, 86.0, 1.0, 2.0, 0.2327534579561907, 1.0, 2.0, 0.2327534579561907, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 530748.7623123038, 530748.7623123035, 176241.1644111145], 
processed observation next is [1.0, 0.7391304347826086, 0.6590909090909091, 0.86, 1.0, 1.0, 0.04094182244523837, 1.0, 1.0, 0.04094182244523837, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1965736156712236, 0.19657361567122353, 0.4298564985636939], 
reward next is 0.5701, 
noisyNet noise sample is [array([1.1562515], dtype=float32), -0.42548832]. 
=============================================
[2019-03-23 18:56:57,367] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[10.088365]
 [ 9.9073  ]
 [ 9.844908]
 [ 9.968564]
 [ 9.84066 ]], R is [[ 9.95666885]
 [ 9.85710239]
 [ 9.75853157]
 [10.042449  ]
 [10.25131512]].
[2019-03-23 18:56:58,272] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9317741e-01 2.9715791e-06 7.7746162e-04 2.0216663e-05 6.0218573e-03], sum to 1.0000
[2019-03-23 18:56:58,281] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2684
[2019-03-23 18:56:58,291] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 587064.0458120551 W.
[2019-03-23 18:56:58,297] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.5, 76.0, 1.0, 1.0, 0.5145327704020467, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32809958756305, 587064.0458120551, 587064.0458120551, 141982.4341747359], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 912600.0000, 
sim time next is 913200.0000, 
raw observation next is [23.66666666666667, 75.33333333333333, 1.0, 2.0, 0.2349348197332529, 0.0, 2.0, 0.0, 1.0, 1.0, 0.4733390063215425, 6.911199999999999, 6.9112, 77.32846119119864, 536132.4333880122, 536132.4333880126, 173249.5484528112], 
processed observation next is [0.0, 0.5652173913043478, 0.7121212121212124, 0.7533333333333333, 1.0, 1.0, 0.0436685246665661, 0.0, 1.0, -0.25, 1.0, 0.5, 0.24762715188791792, -8.881784197001253e-17, 0.0, 0.5084287981116727, 0.198567567921486, 0.19856756792148614, 0.42255987427514924], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3536572], dtype=float32), 0.70139474]. 
=============================================
[2019-03-23 18:57:06,795] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 18:57:06,796] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:57:06,796] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:57:06,797] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:57:06,797] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:57:06,798] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:57:06,799] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:57:06,798] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:57:06,801] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:57:06,802] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:57:06,799] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:57:06,820] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run53
[2019-03-23 18:57:06,846] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run53
[2019-03-23 18:57:06,847] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run53
[2019-03-23 18:57:06,896] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run53
[2019-03-23 18:57:06,896] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run53
[2019-03-23 18:57:11,519] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0092832], dtype=float32), 0.008476684]
[2019-03-23 18:57:11,520] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.73775502666667, 45.90408401333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4796749587328449, 6.911200000000001, 6.9112, 95.55338769695034, 278984.3331017653, 278984.3331017649, 92015.96026384286]
[2019-03-23 18:57:11,521] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:57:11,523] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.9428636e-01 1.3604428e-06 2.4689320e-03 2.8728113e-05 3.2146098e-03], sampled 0.015382249969181139
[2019-03-23 18:57:11,679] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0092832], dtype=float32), 0.008476684]
[2019-03-23 18:57:11,681] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.06666666666667, 85.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.700307917813561, 7.056771782680952, 6.9112, 95.55272373460419, 462785.9058817437, 404364.8284786628, 129015.6234350849]
[2019-03-23 18:57:11,682] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:57:11,686] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.9461633e-01 1.2292452e-06 2.2609185e-03 2.9144025e-05 3.0924184e-03], sampled 0.8320914138293045
[2019-03-23 18:57:32,192] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0092832], dtype=float32), 0.008476684]
[2019-03-23 18:57:32,195] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.0, 41.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6830546981878892, 6.951203529938946, 6.9112, 95.55295059171463, 413370.9903567185, 397316.6780137675, 104296.6064092601]
[2019-03-23 18:57:32,196] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:57:32,198] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.9266875e-01 2.4857088e-06 3.2196776e-03 4.8553753e-05 4.0605841e-03], sampled 0.08125358001560778
[2019-03-23 18:58:44,452] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0092832], dtype=float32), 0.008476684]
[2019-03-23 18:58:44,453] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.8, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5177822578600368, 6.9112, 6.9112, 77.32846344354104, 301171.3025212978, 301171.3025212978, 97427.64330648683]
[2019-03-23 18:58:44,454] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:58:44,459] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.9357986e-01 1.8252781e-06 2.6470898e-03 3.5937232e-05 3.7352741e-03], sampled 0.4739007300838016
[2019-03-23 18:58:45,276] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6199.3794 1733935420.3332 3390.0000
[2019-03-23 18:58:45,496] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6681.4765 1805423427.3257 2381.0000
[2019-03-23 18:58:45,650] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6399.2719 1710171672.5303 2921.0000
[2019-03-23 18:58:45,814] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6290.0389 1692978597.3536 3013.0000
[2019-03-23 18:58:45,834] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6114.8586 1698779649.9693 3197.0000
[2019-03-23 18:58:46,851] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1300000, evaluation results [1300000.0, 6681.4764884261995, 1805423427.3256629, 2381.0, 6290.038851181312, 1692978597.3536131, 3013.0, 6114.858647488289, 1698779649.9693234, 3197.0, 6199.379391762809, 1733935420.3331795, 3390.0, 6399.271910749982, 1710171672.5302644, 2921.0]
[2019-03-23 18:58:53,373] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.9999964e-01 3.3251197e-18 3.0199715e-07 1.6310775e-14 1.1167928e-09], sum to 1.0000
[2019-03-23 18:58:53,379] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2460
[2019-03-23 18:58:53,383] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5540896464974497, 6.9112, 6.9112, 77.32846344354104, 322295.7139877601, 322295.7139877601, 106412.1855461673], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1126800.0000, 
sim time next is 1127400.0000, 
raw observation next is [17.16666666666667, 88.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5562818858977611, 6.911200000000001, 6.9112, 77.32846344354104, 323571.9636691248, 323571.9636691245, 108500.579225851], 
processed observation next is [1.0, 0.043478260869565216, 0.4166666666666669, 0.8800000000000001, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3661169798539444, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11984146802560178, 0.11984146802560168, 0.26463555908744146], 
reward next is 0.7354, 
noisyNet noise sample is [array([1.392672], dtype=float32), -0.18288074]. 
=============================================
[2019-03-23 18:59:03,347] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9999702e-01 4.8123665e-11 6.5557072e-07 3.0486618e-08 2.4372487e-06], sum to 1.0000
[2019-03-23 18:59:03,355] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1003
[2019-03-23 18:59:03,359] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6886922788817199, 6.9112, 6.9112, 77.32846344354104, 397779.2668036151, 397779.2668036151, 123464.9031336419], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1297800.0000, 
sim time next is 1298400.0000, 
raw observation next is [18.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.692317429607121, 6.911199999999999, 6.9112, 77.32846344354104, 399873.9731274626, 399873.9731274628, 123824.371560835], 
processed observation next is [1.0, 0.0, 0.45454545454545453, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5604534708673157, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14810147152868985, 0.1481014715286899, 0.3020106623435], 
reward next is 0.6980, 
noisyNet noise sample is [array([-0.18470523], dtype=float32), 1.0565058]. 
=============================================
[2019-03-23 18:59:07,327] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9546474e-01 1.2838552e-05 2.9884311e-03 3.2747659e-04 1.2065041e-03], sum to 1.0000
[2019-03-23 18:59:07,333] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8594
[2019-03-23 18:59:07,347] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 559636.6765078908 W.
[2019-03-23 18:59:07,354] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4905002522550145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 559636.6765078908, 559636.676507891, 140396.051056013], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1393200.0000, 
sim time next is 1393800.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 1.0, 0.3312251670085443, 6.911199999999999, 6.9112, 77.3421103, 559623.0912595821, 559623.0912595823, 210117.6970969405], 
processed observation next is [0.0, 0.13043478260869565, 0.5909090909090909, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.5, 0.04460738144077762, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.207267811577623, 0.20726781157762308, 0.5124821880413183], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.32036176], dtype=float32), -2.0809882]. 
=============================================
[2019-03-23 18:59:09,228] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9236274e-01 3.3199402e-05 4.1371281e-03 3.8166714e-04 3.0852130e-03], sum to 1.0000
[2019-03-23 18:59:09,232] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0331
[2019-03-23 18:59:09,240] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 583628.9639156511 W.
[2019-03-23 18:59:09,244] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.2568114638650887, 1.0, 2.0, 0.2568114638650887, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 583628.9639156511, 583628.9639156507, 182068.8505641171], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1418400.0000, 
sim time next is 1419000.0000, 
raw observation next is [23.16666666666667, 88.0, 1.0, 2.0, 0.2572408879721726, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5209640016156399, 6.9112, 6.9112, 77.32846344354104, 585490.6243785275, 585490.6243785275, 181747.6070261449], 
processed observation next is [0.0, 0.43478260869565216, 0.6893939393939396, 0.88, 1.0, 1.0, 0.07155110996521573, 0.0, 0.5, -0.25, 1.0, 0.5, 0.3156628594509142, 0.0, 0.0, 0.5084288129206541, 0.21684837939945464, 0.21684837939945464, 0.4432868464052314], 
reward next is 0.5567, 
noisyNet noise sample is [array([2.0982242], dtype=float32), 0.11558888]. 
=============================================
[2019-03-23 18:59:09,263] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[15.579936]
 [15.355079]
 [15.697846]
 [15.579306]
 [15.534089]], R is [[15.77915859]
 [16.17729759]
 [16.57213974]
 [17.05476761]
 [17.53176308]].
[2019-03-23 18:59:11,417] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.7991496e-01 4.4977769e-05 1.7157024e-02 5.1425380e-04 2.3688308e-03], sum to 1.0000
[2019-03-23 18:59:11,426] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7910
[2019-03-23 18:59:11,435] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 559587.8561193969 W.
[2019-03-23 18:59:11,439] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3314680171184473, 6.9112, 6.9112, 77.3421103, 559587.8561193969, 559587.8561193969, 210523.2245659996], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1446600.0000, 
sim time next is 1447200.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4895316501000312, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 558420.9972943126, 558420.9972943128, 140588.0058965653], 
processed observation next is [0.0, 0.782608695652174, 0.5909090909090909, 1.0, 1.0, 1.0, 0.36191456262503896, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20682259159048613, 0.20682259159048622, 0.34289757535747634], 
reward next is 0.6571, 
noisyNet noise sample is [array([-2.1103313], dtype=float32), -1.1305649]. 
=============================================
[2019-03-23 18:59:12,211] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.8239326e-01 3.1678228e-05 8.5119726e-03 4.6235998e-04 8.6007155e-03], sum to 1.0000
[2019-03-23 18:59:12,218] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7369
[2019-03-23 18:59:12,224] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 555238.6231955909 W.
[2019-03-23 18:59:12,227] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [20.0, 100.0, 1.0, 1.0, 0.2432924768680222, 1.0, 1.0, 0.2432924768680222, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32815677302062, 555238.6231955909, 555238.6231955909, 176007.5427654241], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1483800.0000, 
sim time next is 1484400.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 1.0, 0.3, 6.9112, 6.9112, 77.3421103, 509278.2297601745, 509278.2297601745, 201183.2207775638], 
processed observation next is [0.0, 0.17391304347826086, 0.5454545454545454, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.5085185399722538, 0.1886215665778424, 0.1886215665778424, 0.49069078238430197], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7844548], dtype=float32), -0.121687636]. 
=============================================
[2019-03-23 18:59:13,794] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.67412055e-01 1.10773944e-04 2.55928095e-02 1.13650854e-03
 5.74792083e-03], sum to 1.0000
[2019-03-23 18:59:13,798] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0249
[2019-03-23 18:59:13,803] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 695493.0893424724 W.
[2019-03-23 18:59:13,808] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [19.18333333333333, 71.83333333333334, 1.0, 2.0, 0.3148964305395723, 1.0, 2.0, 0.3148964305395723, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 695493.0893424724, 695493.0893424724, 171727.7291618096], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1685400.0000, 
sim time next is 1686000.0000, 
raw observation next is [19.36666666666667, 70.66666666666667, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 1.0, 0.3157536729980949, 6.911199999999999, 6.9112, 77.3421103, 547881.0023367803, 547881.0023367807, 193286.0791343642], 
processed observation next is [1.0, 0.5217391304347826, 0.5166666666666668, 0.7066666666666667, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.022505247140135624, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.20291888975436306, 0.2029188897543632, 0.4714294613033273], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3313769], dtype=float32), -0.3023128]. 
=============================================
[2019-03-23 18:59:13,825] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[15.34925 ]
 [16.238586]
 [16.287098]
 [16.391706]
 [16.714842]], R is [[15.90744591]
 [16.32952309]
 [16.74799156]
 [17.23330307]
 [17.06097031]].
[2019-03-23 18:59:14,337] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9964714e-01 1.4157976e-10 3.5224424e-04 5.6630154e-09 5.7182785e-07], sum to 1.0000
[2019-03-23 18:59:14,343] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7655
[2019-03-23 18:59:14,348] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.33333333333333, 55.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5273269567706061, 6.911200000000001, 6.9112, 77.32846344354104, 306724.7873231794, 306724.7873231791, 93644.13563950289], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2061600.0000, 
sim time next is 2062200.0000, 
raw observation next is [20.16666666666667, 55.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5230460333861516, 6.911200000000001, 6.9112, 77.32846344354104, 304233.9682854072, 304233.9682854069, 92680.48154583044], 
processed observation next is [0.0, 0.8695652173913043, 0.5530303030303032, 0.555, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.31863719055164524, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11267924751311377, 0.11267924751311366, 0.22604995498983033], 
reward next is 0.7740, 
noisyNet noise sample is [array([-0.6552623], dtype=float32), -0.07834643]. 
=============================================
[2019-03-23 18:59:14,509] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9296254e-01 3.4904759e-05 5.9483564e-03 8.6128268e-05 9.6818007e-04], sum to 1.0000
[2019-03-23 18:59:14,514] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3751
[2019-03-23 18:59:14,523] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 572482.9876311477 W.
[2019-03-23 18:59:14,534] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.5, 91.5, 1.0, 2.0, 0.2512807418551882, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5086744444914038, 6.9112, 6.9112, 77.32846344354104, 572482.9876311477, 572482.9876311477, 179743.4560775844], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1521000.0000, 
sim time next is 1521600.0000, 
raw observation next is [23.0, 88.66666666666666, 1.0, 2.0, 0.2531200356938612, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5124737981748676, 6.911199999999999, 6.9112, 77.32846344354104, 576521.6858162549, 576521.6858162553, 180350.7557180463], 
processed observation next is [0.0, 0.6086956521739131, 0.6818181818181818, 0.8866666666666666, 1.0, 1.0, 0.0664000446173265, 0.0, 1.0, -0.25, 1.0, 1.0, 0.303533997392668, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21352655030231665, 0.21352655030231676, 0.43987989199523486], 
reward next is 0.5601, 
noisyNet noise sample is [array([-0.7215224], dtype=float32), 0.32103622]. 
=============================================
[2019-03-23 18:59:19,088] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.4176620e-01 2.1073405e-05 5.4473236e-02 9.3871291e-04 2.8007985e-03], sum to 1.0000
[2019-03-23 18:59:19,096] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5844
[2019-03-23 18:59:19,109] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1279201.034933182 W.
[2019-03-23 18:59:19,114] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.1, 64.66666666666667, 1.0, 2.0, 0.6414108802939256, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9737876077910487, 6.911199999999999, 6.9112, 81.25881066886622, 1279201.034933182, 1279201.034933182, 281613.2017007035], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1599000.0000, 
sim time next is 1599600.0000, 
raw observation next is [26.2, 64.33333333333334, 1.0, 2.0, 0.4184770593073285, 1.0, 1.0, 0.4184770593073285, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 951668.6765671335, 951668.6765671335, 212640.1054325458], 
processed observation next is [1.0, 0.5217391304347826, 0.8272727272727273, 0.6433333333333334, 1.0, 1.0, 0.2730963241341606, 1.0, 0.5, 0.2730963241341606, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.35246988021004944, 0.35246988021004944, 0.5186344034940141], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.65041786], dtype=float32), 0.43435574]. 
=============================================
[2019-03-23 18:59:19,166] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9858272e-01 2.7959541e-09 1.4125798e-03 3.4477225e-07 4.3981527e-06], sum to 1.0000
[2019-03-23 18:59:19,172] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5390
[2019-03-23 18:59:19,176] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 53.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5510811513163622, 6.911199999999999, 6.9112, 77.32846344354104, 320545.3698573204, 320545.3698573207, 106709.9143771357], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2156400.0000, 
sim time next is 2157000.0000, 
raw observation next is [21.33333333333334, 58.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5610277592481565, 6.9112, 6.9112, 77.32846344354104, 326304.8790110871, 326304.8790110871, 110465.4636516783], 
processed observation next is [0.0, 1.0, 0.6060606060606063, 0.5883333333333334, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3728967989259379, 0.0, 0.0, 0.5084288129206541, 0.12085365889299524, 0.12085365889299524, 0.26942796012604464], 
reward next is 0.7306, 
noisyNet noise sample is [array([-1.8526461], dtype=float32), 1.2539675]. 
=============================================
[2019-03-23 18:59:19,206] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[32.114914]
 [32.93022 ]
 [31.918947]
 [29.016424]
 [30.390951]], R is [[35.39797974]
 [35.78372955]
 [36.16493988]
 [36.54197311]
 [36.91445541]].
[2019-03-23 18:59:22,028] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9980861e-01 1.5450172e-15 1.9143040e-04 2.2233094e-12 1.7293106e-08], sum to 1.0000
[2019-03-23 18:59:22,035] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1900
[2019-03-23 18:59:22,041] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.0, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6602463460759562, 6.911199999999999, 6.9112, 77.32846315602664, 381996.6776232027, 381996.677623203, 120233.2453547452], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1651200.0000, 
sim time next is 1651800.0000, 
raw observation next is [18.0, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6622900854624678, 6.911200000000001, 6.9112, 77.3284634417613, 382955.1704380552, 382955.1704380549, 120591.9550495034], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 0.93, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5175572649463827, 8.881784197001253e-17, 0.0, 0.5084288129089525, 0.14183524831039082, 0.1418352483103907, 0.29412671963293513], 
reward next is 0.7059, 
noisyNet noise sample is [array([-2.068476], dtype=float32), -0.7272039]. 
=============================================
[2019-03-23 18:59:30,583] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.1626749e-21 8.4634646e-09 1.1499002e-15 1.2100844e-13], sum to 1.0000
[2019-03-23 18:59:30,591] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1074
[2019-03-23 18:59:30,598] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.16666666666667, 51.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4330895128692261, 6.911200000000001, 6.9112, 77.32846344354104, 251896.4782471685, 251896.4782471682, 68213.85330502606], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1799400.0000, 
sim time next is 1800000.0000, 
raw observation next is [17.0, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4296319125645096, 6.911199999999999, 6.9112, 77.32846344354104, 249884.928550127, 249884.9285501273, 67653.0605353448], 
processed observation next is [1.0, 0.8695652173913043, 0.4090909090909091, 0.52, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.18518844652072805, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09254997353708407, 0.09254997353708419, 0.1650074647203532], 
reward next is 0.8350, 
noisyNet noise sample is [array([0.8081946], dtype=float32), 0.883631]. 
=============================================
[2019-03-23 18:59:30,621] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[81.40843 ]
 [79.18775 ]
 [79.358574]
 [77.76554 ]
 [76.24925 ]], R is [[81.17138672]
 [81.19329834]
 [81.21357727]
 [81.23218536]
 [81.2490921 ]].
[2019-03-23 18:59:32,137] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9999583e-01 1.2598472e-16 4.2131956e-06 1.8773079e-11 2.5667586e-11], sum to 1.0000
[2019-03-23 18:59:32,146] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8907
[2019-03-23 18:59:32,155] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 548691.6210688009 W.
[2019-03-23 18:59:32,163] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.83333333333333, 54.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7477814961388807, 7.261070215926357, 6.9112, 77.32740396001748, 548691.6210688009, 435062.4878826339, 107855.0683057097], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1849800.0000, 
sim time next is 1850400.0000, 
raw observation next is [19.0, 52.0, 1.0, 1.0, 0.448119692002375, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32825218810551, 486672.2857977697, 486672.2857977697, 106355.672794984], 
processed observation next is [1.0, 0.43478260869565216, 0.5, 0.52, 1.0, 0.5, 0.3101496150029687, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084274239321042, 0.1802489947399147, 0.1802489947399147, 0.2594040799877658], 
reward next is 0.7406, 
noisyNet noise sample is [array([-0.5123494], dtype=float32), -0.66199315]. 
=============================================
[2019-03-23 18:59:32,255] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9999976e-01 1.1569563e-17 2.8198673e-07 9.7182929e-14 2.7213239e-13], sum to 1.0000
[2019-03-23 18:59:32,265] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1016
[2019-03-23 18:59:32,271] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 569790.9458078165 W.
[2019-03-23 18:59:32,278] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.66666666666667, 50.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7541569699403443, 7.314586338607223, 6.9112, 77.32730038467281, 569790.9458078165, 438781.2841862895, 107250.2819789974], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1851600.0000, 
sim time next is 1852200.0000, 
raw observation next is [20.0, 49.0, 1.0, 1.0, 0.2336097757138671, 1.0, 1.0, 0.2336097757138671, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.3282200785069, 507426.1686646247, 507426.1686646247, 148661.2848288567], 
processed observation next is [1.0, 0.43478260869565216, 0.5454545454545454, 0.49, 1.0, 0.5, 0.042012219642333856, 1.0, 0.5, 0.042012219642333856, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084272128139159, 0.18793561802393507, 0.18793561802393507, 0.36258849958257733], 
reward next is 0.6374, 
noisyNet noise sample is [array([-0.29349503], dtype=float32), 0.22102681]. 
=============================================
[2019-03-23 18:59:35,989] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.9999213e-01 3.3084416e-12 7.8670309e-06 4.4268362e-09 1.5353526e-08], sum to 1.0000
[2019-03-23 18:59:35,994] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4805
[2019-03-23 18:59:36,001] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 631118.013956501 W.
[2019-03-23 18:59:36,006] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7864566241164834, 7.470136640432501, 6.9112, 77.32689892984932, 631118.013956501, 449590.4981242642, 137465.7315063944], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1925400.0000, 
sim time next is 1926000.0000, 
raw observation next is [19.0, 100.0, 1.0, 1.0, 0.2326770929685192, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4630812489706272, 6.9112, 6.9112, 77.32812634456884, 528583.898121227, 528583.898121227, 168871.9000361311], 
processed observation next is [1.0, 0.30434782608695654, 0.5, 1.0, 1.0, 0.5, 0.040846366210649, 0.0, 1.0, -0.25, 1.0, 1.0, 0.23297321281518174, 0.0, 0.0, 0.5084265965203452, 0.195771814118973, 0.195771814118973, 0.4118826830149539], 
reward next is 0.5881, 
noisyNet noise sample is [array([-0.82760227], dtype=float32), -0.46808925]. 
=============================================
[2019-03-23 18:59:36,022] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[40.316765]
 [39.823547]
 [40.61922 ]
 [43.256668]
 [43.432552]], R is [[40.49611282]
 [40.09115219]
 [39.69024277]
 [39.29334259]
 [38.9004097 ]].
[2019-03-23 18:59:37,170] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 18:59:37,171] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:59:37,172] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:59:37,175] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:59:37,177] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:59:37,177] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:59:37,180] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:59:37,181] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:59:37,182] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:59:37,184] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:59:37,183] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:59:37,203] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run54
[2019-03-23 18:59:37,226] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run54
[2019-03-23 18:59:37,227] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run54
[2019-03-23 18:59:37,286] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run54
[2019-03-23 18:59:37,315] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run54
[2019-03-23 18:59:40,071] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00873675], dtype=float32), 0.008955198]
[2019-03-23 18:59:40,071] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.368440165, 40.882460165, 1.0, 2.0, 0.724048263773372, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 806287.2013398245, 806287.2013398248, 160996.76424238]
[2019-03-23 18:59:40,073] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:59:40,075] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.9975973e-01 1.4131390e-08 2.2964150e-04 1.2457015e-06 9.3063727e-06], sampled 0.2299690938449278
[2019-03-23 18:59:40,077] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 806287.2013398245 W.
[2019-03-23 19:00:25,523] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00873675], dtype=float32), 0.008955198]
[2019-03-23 19:00:25,525] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.5, 64.33333333333333, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7810966006062025, 7.632814378170074, 6.9112, 95.55115257759951, 732418.6050606392, 442824.0457476223, 143714.8918936758]
[2019-03-23 19:00:25,526] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:00:25,529] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.9998319e-01 5.4391616e-11 1.6537409e-05 1.5006885e-08 2.4316904e-07], sampled 0.36066510418406494
[2019-03-23 19:00:25,533] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 732418.6050606392 W.
[2019-03-23 19:00:27,383] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00873675], dtype=float32), 0.008955198]
[2019-03-23 19:00:27,384] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.01714137333333, 79.10378130999999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7035580871514039, 7.081788853725203, 6.9112, 95.55265436290082, 474495.9927491947, 406035.0780808901, 129501.2806719438]
[2019-03-23 19:00:27,389] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:00:27,392] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.9981624e-01 7.9310096e-09 1.7783800e-04 8.4135723e-07 5.1676693e-06], sampled 0.3999820984617426
[2019-03-23 19:00:55,484] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00873675], dtype=float32), 0.008955198]
[2019-03-23 19:00:55,486] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.86666666666667, 80.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4861187744838379, 6.911200000000001, 6.9112, 95.55338769695034, 282733.0100743384, 282733.0100743381, 94836.09767841983]
[2019-03-23 19:00:55,487] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:00:55,491] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.9999738e-01 1.5442388e-12 2.6274681e-06 8.0630941e-10 1.9550185e-08], sampled 0.10007474428769703
[2019-03-23 19:01:01,915] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00873675], dtype=float32), 0.008955198]
[2019-03-23 19:01:01,917] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.4, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6504274093311463, 6.9112, 6.9112, 95.55338769695034, 377431.6617389313, 377431.6617389313, 122766.8455457065]
[2019-03-23 19:01:01,920] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:01:01,924] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.9999857e-01 3.0574813e-13 1.3770451e-06 2.3166614e-10 7.9045144e-09], sampled 0.15759278119172404
[2019-03-23 19:01:09,658] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00873675], dtype=float32), 0.008955198]
[2019-03-23 19:01:09,659] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [28.72829465666667, 65.41596474666667, 1.0, 2.0, 0.5810188413583762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 653334.948802697, 653334.948802697, 160480.5295167209]
[2019-03-23 19:01:09,661] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:01:09,665] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.9991345e-01 1.7829723e-09 8.4021216e-05 2.2758853e-07 2.2833717e-06], sampled 0.6336171219827534
[2019-03-23 19:01:09,666] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 653334.948802697 W.
[2019-03-23 19:01:15,989] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6551.9021 1698718306.6077 2957.0000
[2019-03-23 19:01:16,140] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6478.5594 1679021204.4203 3057.0000
[2019-03-23 19:01:16,189] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6862.1899 1793146758.4044 2407.0000
[2019-03-23 19:01:16,327] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6291.8407 1685749856.4132 3227.0000
[2019-03-23 19:01:16,440] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6328.7217 1723331313.4172 3425.0000
[2019-03-23 19:01:17,457] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1325000, evaluation results [1325000.0, 6862.189901098289, 1793146758.4044244, 2407.0, 6478.55935793923, 1679021204.4202542, 3057.0, 6291.840676794725, 1685749856.4131956, 3227.0, 6328.721692693343, 1723331313.417224, 3425.0, 6551.902087951225, 1698718306.6076703, 2957.0]
[2019-03-23 19:01:24,559] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.0223156e-18 7.0372459e-09 7.6295451e-15 2.9087511e-12], sum to 1.0000
[2019-03-23 19:01:24,568] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5625
[2019-03-23 19:01:24,574] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.83333333333334, 42.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.644082588740149, 6.9112, 6.9112, 77.32846344354104, 372220.5069541993, 372220.5069541993, 119058.8354875205], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2634600.0000, 
sim time next is 2635200.0000, 
raw observation next is [26.0, 42.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.643889409378827, 6.9112, 6.9112, 77.32846344354104, 372142.7993548589, 372142.7993548589, 119016.03672591], 
processed observation next is [0.0, 0.5217391304347826, 0.8181818181818182, 0.42, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.49127058482689573, 0.0, 0.0, 0.5084288129206541, 0.1378306664277255, 0.1378306664277255, 0.29028301640465853], 
reward next is 0.7097, 
noisyNet noise sample is [array([0.346613], dtype=float32), 0.8548487]. 
=============================================
[2019-03-23 19:01:24,681] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 9.6793168e-18 1.6728137e-08 1.1917140e-14 2.4688818e-10], sum to 1.0000
[2019-03-23 19:01:24,688] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5393
[2019-03-23 19:01:24,693] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.0, 56.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5189869411241185, 6.911199999999998, 6.9112, 77.32846344354104, 301872.2315836595, 301872.2315836601, 91737.81453257702], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2062800.0000, 
sim time next is 2063400.0000, 
raw observation next is [19.83333333333334, 57.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5154709270644772, 6.9112, 6.9112, 77.32846344354104, 299826.4880298654, 299826.4880298654, 91753.66101721031], 
processed observation next is [0.0, 0.9130434782608695, 0.5378787878787882, 0.5733333333333335, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3078156100921103, 0.0, 0.0, 0.5084288129206541, 0.11104684741846865, 0.11104684741846865, 0.2237894171151471], 
reward next is 0.7762, 
noisyNet noise sample is [array([-0.16691512], dtype=float32), 1.4760231]. 
=============================================
[2019-03-23 19:01:29,042] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9999678e-01 6.1073694e-12 3.1927159e-06 2.3707203e-08 1.9017618e-08], sum to 1.0000
[2019-03-23 19:01:29,049] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0860
[2019-03-23 19:01:29,056] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5614929808155134, 6.911199999999999, 6.9112, 77.32846344354104, 326604.2874073279, 326604.2874073281, 106978.9414198778], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2166600.0000, 
sim time next is 2167200.0000, 
raw observation next is [17.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.560958400433833, 6.911199999999999, 6.9112, 77.32846344354104, 326293.3454026976, 326293.3454026979, 106929.8227196431], 
processed observation next is [1.0, 0.08695652173913043, 0.4090909090909091, 0.88, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3727977149054758, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1208493871861843, 0.12084938718618442, 0.2608044456576661], 
reward next is 0.7392, 
noisyNet noise sample is [array([-0.09046309], dtype=float32), 2.2901561]. 
=============================================
[2019-03-23 19:01:32,731] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.3635258e-15 5.7769917e-08 4.6540974e-12 4.6056392e-10], sum to 1.0000
[2019-03-23 19:01:32,736] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6259
[2019-03-23 19:01:32,742] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6107400719341806, 6.911199999999999, 6.9112, 77.32846344354104, 354002.7727720167, 354002.772772017, 115320.0097123489], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2785200.0000, 
sim time next is 2785800.0000, 
raw observation next is [18.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6103810788080044, 6.9112, 6.9112, 77.32846344354104, 353794.7631565205, 353794.7631565205, 115289.612219721], 
processed observation next is [1.0, 0.21739130434782608, 0.45454545454545453, 0.88, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.44340154115429203, 0.0, 0.0, 0.5084288129206541, 0.13103509746537795, 0.13103509746537795, 0.281194176145661], 
reward next is 0.7188, 
noisyNet noise sample is [array([-0.08393349], dtype=float32), -0.23208395]. 
=============================================
[2019-03-23 19:01:36,658] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9996924e-01 3.2921352e-10 3.0177524e-05 3.0024944e-07 2.5567110e-07], sum to 1.0000
[2019-03-23 19:01:36,668] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2484
[2019-03-23 19:01:36,674] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.0, 51.66666666666666, 1.0, 1.0, 0.4970856608326052, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32823185462802, 539880.4209152439, 539880.4209152439, 113345.3465613583], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2299200.0000, 
sim time next is 2299800.0000, 
raw observation next is [20.0, 52.33333333333334, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.772758848690424, 7.470746957364669, 6.9112, 77.32711900108865, 631358.8809075761, 449632.6334404699, 108031.6904218136], 
processed observation next is [1.0, 0.6086956521739131, 0.5454545454545454, 0.5233333333333334, 0.0, 0.5, -0.25, 0.0, 1.0, -0.25, 1.0, 0.5, 0.6753697838434629, 0.05595469573646694, 0.0, 0.5084199733129642, 0.23383662255836152, 0.16653060497795183, 0.26349192785808195], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3418288], dtype=float32), 0.19731283]. 
=============================================
[2019-03-23 19:01:41,242] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9999368e-01 1.8310559e-10 5.9822037e-06 1.2018263e-07 2.8845412e-07], sum to 1.0000
[2019-03-23 19:01:41,252] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8554
[2019-03-23 19:01:41,260] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 565277.8791995462 W.
[2019-03-23 19:01:41,264] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.5, 85.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3241180982172636, 6.911199999999999, 6.9112, 77.3421103, 565277.8791995462, 565277.8791995465, 191867.2775407936], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2457000.0000, 
sim time next is 2457600.0000, 
raw observation next is [16.66666666666666, 86.0, 1.0, 2.0, 0.5087619054207999, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846342475028, 552569.0959278808, 552569.0959278811, 120711.3034091804], 
processed observation next is [1.0, 0.43478260869565216, 0.39393939393939365, 0.86, 1.0, 1.0, 0.38595238177599983, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288127971063, 0.20465522071402995, 0.20465522071403003, 0.29441781319312293], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.1481109], dtype=float32), 1.0857295]. 
=============================================
[2019-03-23 19:01:43,875] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 9.3936673e-23 2.5638079e-12 7.3245301e-17 1.4583755e-15], sum to 1.0000
[2019-03-23 19:01:43,884] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2428
[2019-03-23 19:01:43,890] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.0, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4470699075941992, 6.911199999999999, 6.9112, 77.32846344354104, 260030.0244805695, 260030.0244805698, 80880.28569303677], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2419200.0000, 
sim time next is 2419800.0000, 
raw observation next is [16.5, 75.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4445405887299169, 6.9112, 6.9112, 77.32846344354104, 258558.501447915, 258558.501447915, 80357.40530806678], 
processed observation next is [1.0, 0.0, 0.38636363636363635, 0.7566666666666667, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.20648655532845278, 0.0, 0.0, 0.5084288129206541, 0.09576240794367223, 0.09576240794367223, 0.19599367148308972], 
reward next is 0.8040, 
noisyNet noise sample is [array([-0.3490682], dtype=float32), 0.10181334]. 
=============================================
[2019-03-23 19:01:52,132] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 3.1130052e-17 3.6910228e-09 1.4500179e-12 3.6608759e-12], sum to 1.0000
[2019-03-23 19:01:52,138] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0854
[2019-03-23 19:01:52,146] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6113644961336359, 6.9112, 6.9112, 77.32846344354104, 354364.3765368244, 354364.3765368244, 115373.085550217], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2781600.0000, 
sim time next is 2782200.0000, 
raw observation next is [18.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.611593547852571, 6.911199999999999, 6.9112, 77.32846344354104, 354497.1919219194, 354497.1919219196, 115392.4415257596], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 0.88, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.44513363978938725, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13129525626737756, 0.13129525626737762, 0.28144497933112095], 
reward next is 0.7186, 
noisyNet noise sample is [array([0.05821113], dtype=float32), 1.1294838]. 
=============================================
[2019-03-23 19:01:57,408] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9999654e-01 1.7972195e-12 3.5061271e-06 3.4131947e-10 3.2456766e-09], sum to 1.0000
[2019-03-23 19:01:57,415] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6576
[2019-03-23 19:01:57,419] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.0, 83.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6639038868835121, 6.911199999999999, 6.9112, 77.32846344354104, 383761.9540639752, 383761.9540639755, 120838.0793516106], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2685000.0000, 
sim time next is 2685600.0000, 
raw observation next is [18.8, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6559350714495068, 6.911199999999999, 6.9112, 77.32846344354104, 379378.8442141926, 379378.8442141929, 119923.7266869983], 
processed observation next is [0.0, 0.08695652173913043, 0.49090909090909096, 0.84, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5084786734992954, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14051068304229355, 0.14051068304229367, 0.29249689435853243], 
reward next is 0.7075, 
noisyNet noise sample is [array([-0.9790697], dtype=float32), -0.9672487]. 
=============================================
[2019-03-23 19:02:02,830] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9998164e-01 2.0692429e-08 7.3990236e-06 8.0791324e-06 2.9198850e-06], sum to 1.0000
[2019-03-23 19:02:02,837] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5997
[2019-03-23 19:02:02,841] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1263700.569466335 W.
[2019-03-23 19:02:02,853] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 71.33333333333333, 1.0, 2.0, 0.5600370059904348, 1.0, 1.0, 0.5600370059904348, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1263700.569466335, 1263700.569466335, 250025.909176857], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2972400.0000, 
sim time next is 2973000.0000, 
raw observation next is [26.0, 70.66666666666667, 1.0, 2.0, 0.6000834201106807, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9787722804480675, 6.911199999999999, 6.9112, 77.32846344354104, 1228933.424922542, 1228933.424922543, 278995.3049043913], 
processed observation next is [1.0, 0.391304347826087, 0.8181818181818182, 0.7066666666666667, 1.0, 1.0, 0.5001042751383509, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9696746863543824, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4551605277490896, 0.45516052774909005, 0.6804763534253446], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.56088746], dtype=float32), 0.14099264]. 
=============================================
[2019-03-23 19:02:02,868] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[25.974287]
 [24.04922 ]
 [24.73681 ]
 [24.704412]
 [24.353628]], R is [[24.72129822]
 [24.47408485]
 [24.51750183]
 [24.65275764]
 [24.7969017 ]].
[2019-03-23 19:02:03,023] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9964261e-01 1.3439433e-07 6.5988082e-05 2.8186868e-04 9.4477728e-06], sum to 1.0000
[2019-03-23 19:02:03,028] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9192
[2019-03-23 19:02:03,034] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1247101.340441903 W.
[2019-03-23 19:02:03,037] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.66666666666667, 65.66666666666667, 1.0, 2.0, 0.6124833637142837, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9715502007401521, 6.911199999999999, 6.9112, 77.32846344354104, 1247101.340441903, 1247101.340441904, 274031.4237495858], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2803800.0000, 
sim time next is 2804400.0000, 
raw observation next is [26.0, 65.0, 1.0, 2.0, 0.4930398797033014, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9474412172520524, 6.954531956271012, 6.9112, 77.32835714317832, 1110452.962380054, 1096379.648621057, 254782.3302291796], 
processed observation next is [1.0, 0.4782608695652174, 0.8181818181818182, 0.65, 1.0, 1.0, 0.3662998496291267, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9249160246457894, 0.004333195627101194, 0.0, 0.5084281140037893, 0.4112788749555755, 0.40606653652631736, 0.6214203176321454], 
reward next is 0.1619, 
noisyNet noise sample is [array([2.2603607], dtype=float32), 1.3484869]. 
=============================================
[2019-03-23 19:02:03,669] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9991822e-01 1.5585927e-07 3.5253870e-05 3.2775657e-05 1.3556640e-05], sum to 1.0000
[2019-03-23 19:02:03,676] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5805
[2019-03-23 19:02:03,687] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1336429.927494736 W.
[2019-03-23 19:02:03,689] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.5908457681121506, 1.0, 2.0, 0.5908457681121506, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1336429.927494736, 1336429.927494736, 257549.4779349593], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2814000.0000, 
sim time next is 2814600.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.726677612958806, 0.0, 1.0, 0.0, 1.0, 1.0, 0.977439932286712, 6.911199999999999, 6.9112, 77.32846344354104, 1373960.5937806, 1373960.593780601, 296342.7381925269], 
processed observation next is [1.0, 0.5652173913043478, 0.9090909090909091, 0.58, 1.0, 1.0, 0.6583470161985074, 0.0, 0.5, -0.25, 1.0, 0.5, 0.96777133183816, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5088742939928148, 0.5088742939928151, 0.7227871663232364], 
reward next is 0.2772, 
noisyNet noise sample is [array([-1.0210004], dtype=float32), -1.2853625]. 
=============================================
[2019-03-23 19:02:07,263] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 19:02:07,265] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:02:07,267] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:02:07,267] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:02:07,268] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:02:07,270] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:02:07,270] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:02:07,274] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:02:07,273] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:02:07,275] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:02:07,277] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:02:07,293] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run55
[2019-03-23 19:02:07,293] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run55
[2019-03-23 19:02:07,336] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run55
[2019-03-23 19:02:07,368] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run55
[2019-03-23 19:02:07,387] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run55
[2019-03-23 19:02:27,830] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00728475], dtype=float32), 0.009036196]
[2019-03-23 19:02:27,831] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.8, 74.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7255014700204733, 7.267216162882161, 6.9112, 95.55199351064161, 561290.966694686, 418415.1395360068, 132008.0059051661]
[2019-03-23 19:02:27,834] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:02:27,838] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.99805391e-01 2.87276549e-07 1.21878766e-04 6.75546617e-05
 4.93196376e-06], sampled 0.31749970347234135
[2019-03-23 19:02:27,839] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 561290.966694686 W.
[2019-03-23 19:02:42,574] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00728475], dtype=float32), 0.009036196]
[2019-03-23 19:02:42,574] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 79.66666666666667, 1.0, 1.0, 0.4840733298285192, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32815890094913, 550705.3131907578, 550705.3131907575, 136258.041352519]
[2019-03-23 19:02:42,577] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:02:42,579] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.9897122e-01 3.1400627e-06 5.9318432e-04 3.9783705e-04 3.4703422e-05], sampled 0.07309855090296613
[2019-03-23 19:02:42,580] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 550705.3131907578 W.
[2019-03-23 19:02:47,320] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00728475], dtype=float32), 0.009036196]
[2019-03-23 19:02:47,322] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.35, 87.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7694219880473521, 7.558261939692746, 6.9112, 95.55137894780623, 697522.7318182795, 437846.5572886863, 141133.8890981568]
[2019-03-23 19:02:47,323] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:02:47,325] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.9909389e-01 1.8481049e-06 4.3895401e-04 4.3165978e-04 3.3585922e-05], sampled 0.33723308659393003
[2019-03-23 19:02:47,326] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 697522.7318182795 W.
[2019-03-23 19:03:04,269] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00728475], dtype=float32), 0.009036196]
[2019-03-23 19:03:04,270] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.34478901, 100.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7719947758877297, 7.559060386094286, 6.9112, 95.55137328742696, 697896.4562317379, 437899.8679544448, 142420.6331658714]
[2019-03-23 19:03:04,271] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:03:04,274] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.9892610e-01 3.9666133e-06 6.1658450e-04 4.1378831e-04 3.9542494e-05], sampled 0.00046752320901211064
[2019-03-23 19:03:04,275] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 697896.4562317379 W.
[2019-03-23 19:03:05,787] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00728475], dtype=float32), 0.009036196]
[2019-03-23 19:03:05,789] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.75, 89.0, 1.0, 1.0, 0.4657459611168359, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 95.55309842716014, 529619.5439233246, 529619.5439233242, 138465.5191030354]
[2019-03-23 19:03:05,791] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:03:05,794] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.97576177e-01 1.30113840e-05 1.25795114e-03 1.04254705e-03
 1.10304245e-04], sampled 0.09547320992744568
[2019-03-23 19:03:20,289] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00728475], dtype=float32), 0.009036196]
[2019-03-23 19:03:20,292] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.8, 73.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5301359740343813, 6.911199999999999, 6.9112, 95.55338769695034, 308340.5535906574, 308340.5535906578, 92437.14742769575]
[2019-03-23 19:03:20,295] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:03:20,299] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.9999976e-01 1.9479035e-11 2.7575231e-07 5.4808961e-08 3.4057550e-09], sampled 0.015124955282275754
[2019-03-23 19:03:23,475] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00728475], dtype=float32), 0.009036196]
[2019-03-23 19:03:23,477] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.482846225, 86.31395286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7540139157470767, 7.462008910087006, 6.9112, 95.55150332729424, 652468.9637502319, 431420.3622497281, 137639.2756224817]
[2019-03-23 19:03:23,479] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:03:23,482] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.9994063e-01 4.4049898e-08 4.0678453e-05 1.7490045e-05 1.1350916e-06], sampled 0.13094389194033962
[2019-03-23 19:03:23,484] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 652468.9637502319 W.
[2019-03-23 19:03:24,653] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00728475], dtype=float32), 0.009036196]
[2019-03-23 19:03:24,654] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.16666666666666, 59.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5204912156265116, 6.9112, 6.9112, 95.55338769695034, 302729.504232137, 302729.504232137, 101750.9528997493]
[2019-03-23 19:03:24,656] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:03:24,659] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.9999940e-01 5.1144120e-11 4.9919606e-07 1.1178806e-07 7.1385244e-09], sampled 0.846118079995589
[2019-03-23 19:03:28,011] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00728475], dtype=float32), 0.009036196]
[2019-03-23 19:03:28,012] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.85, 79.5, 1.0, 1.0, 0.4652965152384215, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 95.55310426378246, 528669.999925483, 528669.999925483, 138048.7666280406]
[2019-03-23 19:03:28,013] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:03:28,017] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.9711728e-01 1.8570694e-05 1.5228564e-03 1.1867910e-03 1.5436334e-04], sampled 0.6013942243508632
[2019-03-23 19:03:45,682] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6469.6574 1679629782.9133 3057.0000
[2019-03-23 19:03:45,723] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6851.3031 1793816853.8095 2409.0000
[2019-03-23 19:03:45,952] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6546.4489 1698931696.8996 2956.0000
[2019-03-23 19:03:46,037] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6286.4320 1686132191.7297 3226.0000
[2019-03-23 19:03:46,070] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6322.4114 1723717328.2886 3421.0000
[2019-03-23 19:03:47,086] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1350000, evaluation results [1350000.0, 6851.30310250017, 1793816853.8095496, 2409.0, 6469.657413240765, 1679629782.913335, 3057.0, 6286.432021142841, 1686132191.7297294, 3226.0, 6322.411402502485, 1723717328.2885723, 3421.0, 6546.448938825935, 1698931696.8996346, 2956.0]
[2019-03-23 19:03:55,952] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 3.8401731e-20 1.3518032e-11 1.1306749e-14 5.2327341e-15], sum to 1.0000
[2019-03-23 19:03:55,959] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7956
[2019-03-23 19:03:55,963] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 68.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7297631342210609, 7.045237330016673, 6.9112, 77.32800883445347, 463596.5496257573, 420064.2222991189, 128756.3896450421], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3229800.0000, 
sim time next is 3230400.0000, 
raw observation next is [22.0, 67.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.728260335167753, 7.035403204069145, 6.9112, 77.32801988051432, 459719.2963989271, 419380.8674983008, 128459.7678664869], 
processed observation next is [0.0, 0.391304347826087, 0.6363636363636364, 0.6733333333333335, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6118004788110758, 0.01242032040691452, 0.0, 0.508425896527219, 0.1702664060736767, 0.15532624722159288, 0.3133165069914315], 
reward next is 0.0657, 
noisyNet noise sample is [array([-0.09379595], dtype=float32), -2.1649668]. 
=============================================
[2019-03-23 19:03:56,855] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9999857e-01 2.0927892e-14 1.4393084e-06 1.3916941e-10 9.7149181e-12], sum to 1.0000
[2019-03-23 19:03:56,866] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0538
[2019-03-23 19:03:56,874] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 737284.998535161 W.
[2019-03-23 19:03:56,878] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [17.66666666666667, 90.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8069229849840135, 7.739420346324803, 6.9112, 77.32652901984525, 737284.998535161, 468302.6990265339, 134683.0048798359], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3054000.0000, 
sim time next is 3054600.0000, 
raw observation next is [18.0, 88.5, 1.0, 1.0, 0.2206777178445956, 1.0, 1.0, 0.2206777178445956, 1.0, 2.0, 0.4288362116100231, 6.9112, 6.9112, 77.3421103, 740870.9478375003, 740870.9478375003, 214393.9861166325], 
processed observation next is [1.0, 0.34782608695652173, 0.45454545454545453, 0.885, 1.0, 0.5, 0.0258471473057445, 1.0, 0.5, 0.0258471473057445, 1.0, 1.0, 0.18405173087146162, 0.0, 0.0, 0.5085185399722538, 0.2743966473472223, 0.2743966473472223, 0.5229121612600792], 
reward next is 0.4771, 
noisyNet noise sample is [array([-0.28528848], dtype=float32), -1.4936023]. 
=============================================
[2019-03-23 19:03:58,564] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9943262e-01 5.3977921e-08 5.3956622e-04 2.4622546e-05 3.1246313e-06], sum to 1.0000
[2019-03-23 19:03:58,572] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5365
[2019-03-23 19:03:58,576] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1289892.25081673 W.
[2019-03-23 19:03:58,585] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.6, 71.0, 1.0, 2.0, 0.3823966778653635, 1.0, 2.0, 0.3823966778653635, 1.0, 1.0, 0.7737335734523115, 6.911199999999999, 6.9112, 77.3421103, 1289892.25081673, 1289892.25081673, 299055.3041957761], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3085200.0000, 
sim time next is 3085800.0000, 
raw observation next is [26.66666666666667, 70.83333333333334, 1.0, 2.0, 0.3694956081690768, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7475381367203392, 6.911199999999999, 6.9112, 77.32846344354104, 834304.8673024254, 834304.8673024258, 218324.8242432597], 
processed observation next is [1.0, 0.7391304347826086, 0.8484848484848487, 0.7083333333333335, 1.0, 1.0, 0.21186951021134595, 0.0, 0.5, -0.25, 1.0, 1.0, 0.6393401953147704, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.30900180270460204, 0.30900180270460215, 0.5324995713250237], 
reward next is 0.4675, 
noisyNet noise sample is [array([-1.4909718], dtype=float32), -0.43264827]. 
=============================================
[2019-03-23 19:04:00,474] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9970895e-01 2.2077883e-07 2.0194847e-04 5.6580539e-05 3.2169213e-05], sum to 1.0000
[2019-03-23 19:04:00,482] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2920
[2019-03-23 19:04:00,493] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 582393.981132301 W.
[2019-03-23 19:04:00,499] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.66666666666667, 88.66666666666667, 1.0, 2.0, 0.5109224756306837, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 582393.981132301, 582393.981132301, 143763.9906997179], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3111600.0000, 
sim time next is 3112200.0000, 
raw observation next is [22.5, 88.5, 1.0, 2.0, 0.2520868347412106, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5096956722723426, 6.911199999999999, 6.9112, 77.32846344354104, 574988.5490750336, 574988.5490750339, 178938.4134015747], 
processed observation next is [1.0, 0.0, 0.6590909090909091, 0.885, 1.0, 1.0, 0.0651085434265132, 0.0, 1.0, -0.25, 1.0, 0.5, 0.29956524610334656, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2129587218796421, 0.21295872187964218, 0.4364351546379871], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.25485873], dtype=float32), -0.3437901]. 
=============================================
[2019-03-23 19:04:11,474] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 3.4898399e-21 9.3344135e-14 3.6196708e-18 8.2468578e-16], sum to 1.0000
[2019-03-23 19:04:11,482] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1743
[2019-03-23 19:04:11,486] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.33333333333334, 59.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6329245123381405, 6.9112, 6.9112, 77.32846344354104, 366576.7519417403, 366576.7519417403, 117450.0811878551], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3323400.0000, 
sim time next is 3324000.0000, 
raw observation next is [22.66666666666667, 58.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6397050849017911, 6.911199999999999, 6.9112, 77.32846344354104, 370254.4407490553, 370254.4407490556, 118241.0254299714], 
processed observation next is [0.0, 0.4782608695652174, 0.6666666666666669, 0.5800000000000001, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.48529297843113023, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13713127435150196, 0.13713127435150207, 0.28839274495114975], 
reward next is 0.7116, 
noisyNet noise sample is [array([0.89266926], dtype=float32), 1.4850765]. 
=============================================
[2019-03-23 19:04:11,503] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[65.4893  ]
 [65.70676 ]
 [65.69616 ]
 [65.70131 ]
 [65.737076]], R is [[65.46807861]
 [65.52693939]
 [65.58724976]
 [65.64886475]
 [65.71128082]].
[2019-03-23 19:04:18,058] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9991429e-01 2.5861277e-10 8.5302039e-05 1.2417370e-07 2.1513642e-07], sum to 1.0000
[2019-03-23 19:04:18,064] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7751
[2019-03-23 19:04:18,068] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 591711.8266320161 W.
[2019-03-23 19:04:18,073] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.2598418544785085, 0.0, 2.0, 0.0, 1.0, 1.0, 0.526136414358899, 6.911200000000001, 6.9112, 77.32846344354104, 591711.8266320161, 591711.8266320159, 182110.6571226065], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3452400.0000, 
sim time next is 3453000.0000, 
raw observation next is [22.83333333333334, 89.83333333333334, 1.0, 2.0, 0.2606378561223209, 1.0, 1.0, 0.2606378561223209, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592635.5572224587, 592635.5572224587, 182488.519061975], 
processed observation next is [1.0, 1.0, 0.6742424242424245, 0.8983333333333334, 1.0, 1.0, 0.07579732015290108, 1.0, 0.5, 0.07579732015290108, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21949465082313283, 0.21949465082313283, 0.44509394893164633], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.253862], dtype=float32), 1.8202829]. 
=============================================
[2019-03-23 19:04:18,096] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[24.853102]
 [25.024443]
 [26.38009 ]
 [25.353262]
 [25.80946 ]], R is [[25.11491394]
 [24.86376572]
 [24.61512756]
 [24.36897659]
 [24.77149391]].
[2019-03-23 19:04:18,787] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.9920964e-01 3.9948141e-08 7.8874291e-04 1.3076531e-06 2.6508476e-07], sum to 1.0000
[2019-03-23 19:04:18,797] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9364
[2019-03-23 19:04:18,807] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 560424.3102681924 W.
[2019-03-23 19:04:18,812] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.2459078384802914, 1.0, 2.0, 0.2459078384802914, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344344301, 560424.3102681924, 560424.3102681921, 178812.4362504294], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3479400.0000, 
sim time next is 3480000.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.2477823895005242, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5009107402978887, 6.911199999999999, 6.9112, 77.32846344354043, 565214.2171277785, 565214.2171277787, 177825.8141992789], 
processed observation next is [1.0, 0.2608695652173913, 0.5909090909090909, 1.0, 1.0, 1.0, 0.05972798687565523, 0.0, 0.5, -0.25, 1.0, 0.5, 0.28701534328269823, -8.881784197001253e-17, 0.0, 0.5084288129206501, 0.20933859893621423, 0.20933859893621432, 0.4337214980470217], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.54296225], dtype=float32), -1.8195889]. 
=============================================
[2019-03-23 19:04:18,829] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[22.150816]
 [22.86162 ]
 [22.979343]
 [22.291517]
 [22.844303]], R is [[21.24238777]
 [21.59383583]
 [21.37789726]
 [21.16411781]
 [20.9524765 ]].
[2019-03-23 19:04:23,017] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9999988e-01 3.8279329e-19 1.0565894e-07 6.1941185e-16 2.4649029e-16], sum to 1.0000
[2019-03-23 19:04:23,022] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6781
[2019-03-23 19:04:23,026] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.96666666666667, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.566773747086507, 6.9112, 6.9112, 77.32846344354104, 329644.1561145851, 329644.1561145851, 110482.9958355783], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4075800.0000, 
sim time next is 4076400.0000, 
raw observation next is [15.93333333333333, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.561846977697947, 6.911199999999999, 6.9112, 77.32846344354104, 326799.4602401027, 326799.460240103, 109669.9878728512], 
processed observation next is [1.0, 0.17391304347826086, 0.36060606060606043, 1.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3740671109970672, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12103683712596397, 0.12103683712596408, 0.2674877752996371], 
reward next is 0.7325, 
noisyNet noise sample is [array([0.7811977], dtype=float32), 1.2600015]. 
=============================================
[2019-03-23 19:04:31,458] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.7564483e-01 3.0282828e-11 2.4355184e-02 6.4103767e-10 8.1178272e-11], sum to 1.0000
[2019-03-23 19:04:31,464] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8849
[2019-03-23 19:04:31,471] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1004506.759127051 W.
[2019-03-23 19:04:31,475] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.83333333333333, 69.0, 1.0, 2.0, 0.4399540566918217, 1.0, 1.0, 0.4399540566918217, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344353835, 1004506.759127051, 1004506.759127051, 211785.2078556057], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3750600.0000, 
sim time next is 3751200.0000, 
raw observation next is [24.0, 69.0, 1.0, 2.0, 0.4850799251509195, 1.0, 2.0, 0.4850799251509195, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354103, 1107575.451253146, 1107575.451253146, 222968.4333120784], 
processed observation next is [1.0, 0.43478260869565216, 0.7272727272727273, 0.69, 1.0, 1.0, 0.3563499064386494, 1.0, 1.0, 0.3563499064386494, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.508428812920654, 0.41021313009375776, 0.41021313009375776, 0.5438254471026303], 
reward next is 0.4562, 
noisyNet noise sample is [array([-1.6803464], dtype=float32), 0.32036316]. 
=============================================
[2019-03-23 19:04:37,219] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 19:04:37,220] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:04:37,221] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:04:37,221] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:04:37,222] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:04:37,222] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:04:37,223] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:04:37,223] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:04:37,224] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:04:37,225] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:04:37,225] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:04:37,248] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run56
[2019-03-23 19:04:37,272] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run56
[2019-03-23 19:04:37,294] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run56
[2019-03-23 19:04:37,333] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run56
[2019-03-23 19:04:37,366] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run56
[2019-03-23 19:04:50,084] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00617039], dtype=float32), 0.009919435]
[2019-03-23 19:04:50,086] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.8, 65.66666666666667, 1.0, 2.0, 0.4578985892397927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.5533869925772, 521982.8094263719, 521982.8094263719, 139115.3741449212]
[2019-03-23 19:04:50,087] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:04:50,089] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.5967439e-01 1.2897731e-12 1.4032568e-01 1.0704966e-11 1.2822000e-10], sampled 0.7540087324537315
[2019-03-23 19:04:54,788] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00617039], dtype=float32), 0.009919435]
[2019-03-23 19:04:54,791] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.46725164, 100.0, 1.0, 2.0, 0.5590869342677017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769694852, 629795.5466397868, 629795.5466397868, 157288.7943064607]
[2019-03-23 19:04:54,791] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:04:54,793] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.45660293e-01 1.09216725e-14 5.43397702e-02 1.38967546e-13
 2.57586595e-12], sampled 0.27236879866892616
[2019-03-23 19:04:54,794] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 629795.5466397868 W.
[2019-03-23 19:05:47,984] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00617039], dtype=float32), 0.009919435]
[2019-03-23 19:05:47,986] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.8, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.471059496251704, 6.911200000000001, 6.9112, 95.55338769695034, 273972.3414920888, 273972.3414920885, 92262.97978647887]
[2019-03-23 19:05:47,987] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:05:47,990] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.9991119e-01 1.3063212e-22 8.8760142e-05 9.1540710e-21 1.3555408e-18], sampled 0.40391565430192056
[2019-03-23 19:06:01,032] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00617039], dtype=float32), 0.009919435]
[2019-03-23 19:06:01,034] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.63333333333333, 57.0, 1.0, 2.0, 0.6351875746582895, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9232512187309401, 6.981764966789624, 6.9112, 95.55311190375117, 1272007.981260573, 1243688.632154412, 275411.2977605318]
[2019-03-23 19:06:01,036] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:06:01,040] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.8702092e-01 2.2129906e-12 6.1297911e-01 3.2203202e-11 3.1548442e-10], sampled 0.47717670999527606
[2019-03-23 19:06:01,983] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00617039], dtype=float32), 0.009919435]
[2019-03-23 19:06:01,987] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.06533183333333, 57.63912563333333, 1.0, 2.0, 0.4968387600277503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 566849.3517455858, 566849.3517455854, 145260.4689204108]
[2019-03-23 19:06:01,988] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:06:01,990] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.0494407e-01 7.3650010e-12 2.9505593e-01 5.6417454e-11 5.0473625e-10], sampled 0.6279287107381006
[2019-03-23 19:06:01,994] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 566849.3517455858 W.
[2019-03-23 19:06:06,428] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00617039], dtype=float32), 0.009919435]
[2019-03-23 19:06:06,430] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.3, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6403341287117208, 6.911199999999999, 6.9112, 95.55338769695034, 370774.7861110545, 370774.7861110548, 122466.6841561376]
[2019-03-23 19:06:06,432] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:06:06,435] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.9870360e-01 3.3753544e-20 1.2964285e-03 1.2655686e-18 1.0342686e-16], sampled 0.9195211484526075
[2019-03-23 19:06:06,894] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00617039], dtype=float32), 0.009919435]
[2019-03-23 19:06:06,895] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.90282235, 51.95706288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6846852837332029, 6.958499486858518, 6.9112, 95.55309858439057, 416786.0438004591, 397803.6711711704, 125584.835272185]
[2019-03-23 19:06:06,896] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:06:06,899] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.9131000e-01 1.2464728e-15 8.6899400e-03 2.0423875e-14 5.3588335e-13], sampled 0.06917262664703328
[2019-03-23 19:06:16,597] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6087.4702 1746892721.4860 2936.0000
[2019-03-23 19:06:16,645] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 5774.1113 1734225854.6191 3188.0000
[2019-03-23 19:06:16,692] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 5841.9402 1771554077.8874 3521.0000
[2019-03-23 19:06:16,703] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6271.2905 1854369367.9750 2370.0000
[2019-03-23 19:06:16,772] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 5886.1878 1734729619.9612 3026.0000
[2019-03-23 19:06:17,791] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1375000, evaluation results [1375000.0, 6271.2904608961, 1854369367.975035, 2370.0, 5886.18783458893, 1734729619.9612138, 3026.0, 5774.1112874432865, 1734225854.6191485, 3188.0, 5841.940156061936, 1771554077.8873777, 3521.0, 6087.470154546163, 1746892721.4859571, 2936.0]
[2019-03-23 19:06:17,893] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9991560e-01 8.7174292e-23 8.4342617e-05 1.1022140e-21 1.1653581e-18], sum to 1.0000
[2019-03-23 19:06:17,904] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6680
[2019-03-23 19:06:17,912] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.559484506272299, 6.9112, 6.9112, 77.32846344354104, 325435.6612986395, 325435.6612986395, 106752.231854403], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3818400.0000, 
sim time next is 3819000.0000, 
raw observation next is [17.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5587703592005144, 6.9112, 6.9112, 77.32846344354104, 325020.2117726508, 325020.2117726508, 106699.0042915134], 
processed observation next is [0.0, 0.17391304347826086, 0.4090909090909091, 0.88, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.36967194171502066, 0.0, 0.0, 0.5084288129206541, 0.12037785621209288, 0.12037785621209288, 0.26024147388174], 
reward next is 0.7398, 
noisyNet noise sample is [array([1.1337119], dtype=float32), 1.6296031]. 
=============================================
[2019-03-23 19:06:17,931] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[77.2424 ]
 [77.23578]
 [77.1649 ]
 [77.02432]
 [76.97706]], R is [[77.23499298]
 [77.20227814]
 [77.17015076]
 [77.13832092]
 [77.10625458]].
[2019-03-23 19:06:20,718] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9685657e-01 3.0918864e-18 3.1434142e-03 7.9966703e-20 6.0432399e-17], sum to 1.0000
[2019-03-23 19:06:20,734] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4270
[2019-03-23 19:06:20,738] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.66666666666666, 61.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6752698183800974, 6.911199999999999, 6.9112, 77.32846344354104, 389433.041479672, 389433.0414796722, 122588.9289567607], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3922800.0000, 
sim time next is 3923400.0000, 
raw observation next is [22.83333333333334, 59.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.665528499936599, 6.911199999999999, 6.9112, 77.32846344354104, 384110.6801028, 384110.6801028003, 121429.2585444001], 
processed observation next is [0.0, 0.391304347826087, 0.6742424242424245, 0.59, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5221835713379986, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1422632148528889, 0.142263214852889, 0.29616892327902467], 
reward next is 0.7038, 
noisyNet noise sample is [array([-1.4151363], dtype=float32), -1.3143195]. 
=============================================
[2019-03-23 19:06:25,478] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9856538e-01 2.8259590e-22 1.4345897e-03 4.3915887e-19 2.0312785e-17], sum to 1.0000
[2019-03-23 19:06:25,488] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4408
[2019-03-23 19:06:25,491] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.5, 58.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5830186750251264, 6.9112, 6.9112, 77.32846344354104, 338783.7324627059, 338783.7324627059, 112393.8528870677], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3965400.0000, 
sim time next is 3966000.0000, 
raw observation next is [21.33333333333334, 59.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5767677877929023, 6.9112, 6.9112, 77.32846344354104, 335273.074745846, 335273.074745846, 111810.0793676038], 
processed observation next is [0.0, 0.9130434782608695, 0.6060606060606063, 0.59, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.39538255398986044, 0.0, 0.0, 0.5084288129206541, 0.12417521286883185, 0.12417521286883185, 0.2727075106526922], 
reward next is 0.7273, 
noisyNet noise sample is [array([0.7965398], dtype=float32), -0.48165992]. 
=============================================
[2019-03-23 19:06:25,501] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[71.9958  ]
 [72.064575]
 [72.09134 ]
 [72.20235 ]
 [72.22026 ]], R is [[71.90657043]
 [71.91337585]
 [71.91901398]
 [71.9238739 ]
 [71.92789459]].
[2019-03-23 19:06:25,762] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.0539269e-01 1.6516451e-13 3.9460734e-01 6.0001545e-11 3.9060432e-11], sum to 1.0000
[2019-03-23 19:06:25,778] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7759
[2019-03-23 19:06:25,785] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.2307687649806909, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4644852882050041, 6.911199999999999, 6.9112, 77.32846344354104, 526550.0463463241, 526550.0463463244, 171967.7846862104], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4494600.0000, 
sim time next is 4495200.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.2307876204655358, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4645227576668534, 6.9112, 6.9112, 77.32846344354104, 526592.9989613142, 526592.9989613142, 171971.3350309626], 
processed observation next is [0.0, 0.0, 0.5909090909090909, 0.94, 1.0, 1.0, 0.03848452558191974, 0.0, 1.0, -0.25, 1.0, 1.0, 0.23503251095264777, 0.0, 0.0, 0.5084288129206541, 0.19503444405974601, 0.19503444405974601, 0.4194422805633234], 
reward next is 0.5806, 
noisyNet noise sample is [array([-0.7109637], dtype=float32), 0.64601195]. 
=============================================
[2019-03-23 19:06:27,240] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9967670e-01 2.3289171e-21 3.2336838e-04 3.9423159e-18 1.8158074e-18], sum to 1.0000
[2019-03-23 19:06:27,247] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0994
[2019-03-23 19:06:27,253] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6619542396655637, 6.9112, 6.9112, 77.32846344354104, 382334.9903288561, 382334.9903288561, 120876.7565456361], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4174800.0000, 
sim time next is 4175400.0000, 
raw observation next is [18.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.663223599800383, 6.9112, 6.9112, 77.32846344354104, 383067.4905217605, 383067.4905217605, 120997.4607959916], 
processed observation next is [1.0, 0.30434782608695654, 0.45454545454545453, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5188908568576901, 0.0, 0.0, 0.5084288129206541, 0.14187684834139278, 0.14187684834139278, 0.2951157580390039], 
reward next is 0.7049, 
noisyNet noise sample is [array([-1.1868583], dtype=float32), -1.2417023]. 
=============================================
[2019-03-23 19:06:35,856] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.8357542e-01 1.6725926e-10 7.1642464e-01 5.4386362e-10 2.9956295e-09], sum to 1.0000
[2019-03-23 19:06:35,862] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.2498967e-03 7.6291112e-10 9.9075013e-01 2.8480907e-09 2.8113160e-08], sum to 1.0000
[2019-03-23 19:06:35,865] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0841
[2019-03-23 19:06:35,868] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3666746307761147, 6.911199999999999, 6.9112, 77.32846344169145, 421163.1236665892, 421163.1236665895, 156197.88731101], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4146000.0000, 
sim time next is 4146600.0000, 
raw observation next is [18.0, 100.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7222913187260194, 6.974943524211128, 6.9112, 77.32827059910254, 435881.9709436139, 415179.4296892321, 128376.7272575758], 
processed observation next is [1.0, 1.0, 0.45454545454545453, 1.0, 0.0, 0.5, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.603273312465742, 0.006374352421112839, 0.0, 0.5084275449830206, 0.1614377670161533, 0.15377015914416003, 0.3131139689209166], 
reward next is 0.3682, 
noisyNet noise sample is [array([-1.8587271], dtype=float32), 0.34475258]. 
=============================================
[2019-03-23 19:06:35,874] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5983
[2019-03-23 19:06:35,877] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.33333333333334, 59.66666666666667, 1.0, 2.0, 0.4163126930757189, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8283265734990422, 6.911199999999999, 6.9112, 77.32846344354104, 946025.3919851405, 946025.3919851409, 219646.5538825728], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4203600.0000, 
sim time next is 4204200.0000, 
raw observation next is [24.16666666666666, 60.33333333333334, 1.0, 2.0, 0.4039847999386645, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8032131135918594, 6.911199999999999, 6.9112, 77.32846344354104, 917630.6368472326, 917630.6368472328, 215022.9536259133], 
processed observation next is [1.0, 0.6521739130434783, 0.7348484848484845, 0.6033333333333334, 1.0, 1.0, 0.25498099992333056, 0.0, 1.0, -0.25, 1.0, 1.0, 0.7188758765597991, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.33986319883230837, 0.3398631988323085, 0.5244462283558861], 
reward next is 0.4756, 
noisyNet noise sample is [array([0.5835393], dtype=float32), 2.5750222]. 
=============================================
[2019-03-23 19:06:42,262] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.2811291e-02 1.1374175e-08 9.4718856e-01 4.5547885e-08 5.3583118e-08], sum to 1.0000
[2019-03-23 19:06:42,272] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9607
[2019-03-23 19:06:42,279] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.1, 49.0, 1.0, 2.0, 0.5754149842874704, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9634062365078763, 6.911200000000001, 6.9112, 77.3284605264669, 1204246.729923591, 1204246.72992359, 260374.6384423978], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4287600.0000, 
sim time next is 4288200.0000, 
raw observation next is [27.08333333333334, 49.33333333333334, 1.0, 2.0, 0.6941819022445432, 0.0, 2.0, 0.0, 1.0, 2.0, 0.963899590785476, 6.911199999999999, 6.9112, 78.26345941519878, 1340031.40382526, 1340031.40382526, 277210.172176568], 
processed observation next is [1.0, 0.6521739130434783, 0.8674242424242427, 0.4933333333333334, 1.0, 1.0, 0.617727377805679, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9484279868363945, -8.881784197001253e-17, 0.0, 0.5145763408914203, 0.4963079273426889, 0.4963079273426889, 0.676122371162361], 
reward next is 0.3239, 
noisyNet noise sample is [array([-0.5284141], dtype=float32), -0.05784452]. 
=============================================
[2019-03-23 19:06:55,152] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.8423587e-02 4.5079229e-14 9.6157640e-01 7.2270220e-14 2.5348098e-14], sum to 1.0000
[2019-03-23 19:06:55,162] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4913
[2019-03-23 19:06:55,167] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.2062132829011461, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4098718394707394, 6.911199999999999, 6.9112, 77.32846344354104, 468108.59629214, 468108.5962921403, 163545.3158704586], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4507200.0000, 
sim time next is 4507800.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.2056639862855558, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4087067635729842, 6.911200000000001, 6.9112, 77.32846344354104, 466815.8117903312, 466815.8117903309, 163406.0905812263], 
processed observation next is [0.0, 0.17391304347826086, 0.5, 1.0, 1.0, 1.0, 0.007079982856944729, 0.0, 1.0, -0.25, 1.0, 1.0, 0.15529537653283457, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17289474510753008, 0.17289474510752997, 0.3985514404420154], 
reward next is 0.6014, 
noisyNet noise sample is [array([-0.16479154], dtype=float32), 0.61661714]. 
=============================================
[2019-03-23 19:06:55,563] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.8052808e-03 3.8941781e-16 9.9819475e-01 8.4195059e-16 9.3702444e-14], sum to 1.0000
[2019-03-23 19:06:55,572] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2803
[2019-03-23 19:06:55,575] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.0, 94.0, 1.0, 2.0, 0.2116102753292588, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4220859780494795, 6.911199999999999, 6.9112, 77.32846344354104, 481236.9680445365, 481236.9680445368, 165390.821968655], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4503000.0000, 
sim time next is 4503600.0000, 
raw observation next is [20.0, 94.0, 1.0, 2.0, 0.2117352906893074, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4223354536428977, 6.911200000000001, 6.9112, 77.32846344354104, 481521.4781384878, 481521.4781384875, 165413.9763617766], 
processed observation next is [0.0, 0.13043478260869565, 0.5454545454545454, 0.94, 1.0, 1.0, 0.014669113361634248, 0.0, 1.0, -0.25, 1.0, 1.0, 0.17476493377556818, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17834128819943992, 0.1783412881994398, 0.40344872283360145], 
reward next is 0.5966, 
noisyNet noise sample is [array([0.6859448], dtype=float32), -0.39622736]. 
=============================================
[2019-03-23 19:07:03,751] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.6158210e-06 2.4325661e-11 9.9999440e-01 1.1911365e-11 5.6460531e-12], sum to 1.0000
[2019-03-23 19:07:03,760] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1046
[2019-03-23 19:07:03,763] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.16666666666666, 64.33333333333334, 1.0, 2.0, 0.2070232225438376, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4130597952773231, 6.9112, 6.9112, 77.32846344354101, 470867.878899141, 470867.878899141, 164629.2710203048], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4729800.0000, 
sim time next is 4730400.0000, 
raw observation next is [24.0, 65.0, 1.0, 2.0, 0.2077051101707239, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4142057124955892, 6.9112, 6.9112, 77.32846344354104, 472301.2863849388, 472301.2863849388, 164620.4546586665], 
processed observation next is [1.0, 0.782608695652174, 0.7272727272727273, 0.65, 1.0, 1.0, 0.009631387713404868, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1631510178508417, 0.0, 0.0, 0.5084288129206541, 0.17492640236479215, 0.17492640236479215, 0.4015133040455281], 
reward next is 0.5985, 
noisyNet noise sample is [array([0.89497215], dtype=float32), 1.6073081]. 
=============================================
[2019-03-23 19:07:05,284] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.3092318e-04 5.0913863e-13 9.9966908e-01 7.4889617e-12 1.3742661e-11], sum to 1.0000
[2019-03-23 19:07:05,294] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9090
[2019-03-23 19:07:05,302] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 60.0, 1.0, 2.0, 0.3280894839202255, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6311406788374057, 6.911199999999999, 6.9112, 77.32846344354104, 728935.8406204485, 728935.8406204487, 182065.4961638387], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4705200.0000, 
sim time next is 4705800.0000, 
raw observation next is [22.33333333333334, 59.0, 1.0, 2.0, 0.3742276616929543, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7226596199173188, 6.911199999999999, 6.9112, 77.32846344354104, 833882.9064955274, 833882.9064955277, 195389.7602533074], 
processed observation next is [1.0, 0.4782608695652174, 0.6515151515151518, 0.59, 1.0, 1.0, 0.21778457711619284, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6037994570247411, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.30884552092426937, 0.30884552092426953, 0.4765603908617254], 
reward next is 0.5234, 
noisyNet noise sample is [array([-1.1201723], dtype=float32), 0.034912456]. 
=============================================
[2019-03-23 19:07:07,636] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 19:07:07,637] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:07:07,640] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:07:07,640] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:07:07,641] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:07:07,644] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:07:07,645] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:07:07,646] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:07:07,649] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:07:07,651] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:07:07,654] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:07:07,672] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run57
[2019-03-23 19:07:07,696] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run57
[2019-03-23 19:07:07,720] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run57
[2019-03-23 19:07:07,743] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run57
[2019-03-23 19:07:07,769] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run57
[2019-03-23 19:07:25,261] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00638241], dtype=float32), 0.009669035]
[2019-03-23 19:07:25,263] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.66213142, 98.88832952333334, 1.0, 2.0, 0.2197889113280545, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4399638516727691, 6.911199999999999, 6.9112, 95.55338769695034, 500593.6626160602, 500593.6626160605, 172596.536248009]
[2019-03-23 19:07:25,264] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:07:25,267] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.9907175e-04 4.1200056e-12 9.9960095e-01 2.2366794e-11 2.5169158e-11], sampled 0.18321312680761703
[2019-03-23 19:07:37,308] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00638241], dtype=float32), 0.009669035]
[2019-03-23 19:07:37,308] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.16666666666667, 94.00000000000001, 1.0, 2.0, 0.200989950281644, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3752042050982336, 6.9112, 6.9112, 77.32846344354104, 436540.5020823609, 436540.5020823609, 131772.9302730147]
[2019-03-23 19:07:37,309] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:07:37,311] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.29026792e-03 2.70328829e-11 9.98709679e-01 1.06191375e-10
 1.32714284e-10], sampled 0.5530047452321109
[2019-03-23 19:08:04,261] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00638241], dtype=float32), 0.009669035]
[2019-03-23 19:08:04,262] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.93333333333333, 70.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3158916972352522, 6.911199999999999, 6.9112, 95.55338769695034, 365913.5034880708, 365913.5034880711, 151440.364879321]
[2019-03-23 19:08:04,267] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:08:04,269] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.6350366e-04 7.8253161e-11 9.9983644e-01 2.4275346e-10 1.2757001e-10], sampled 0.282329606373516
[2019-03-23 19:08:10,017] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00638241], dtype=float32), 0.009669035]
[2019-03-23 19:08:10,018] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.31377425, 83.901721605, 1.0, 2.0, 0.3054409434725092, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6180229231877337, 6.9112, 6.9112, 95.55338769695034, 686381.6620209693, 686381.6620209693, 203630.7700629138]
[2019-03-23 19:08:10,021] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:08:10,028] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.4458597e-03 1.0565494e-12 9.9855417e-01 7.7187024e-12 1.6547022e-11], sampled 0.7832318341008722
[2019-03-23 19:08:13,646] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00638241], dtype=float32), 0.009669035]
[2019-03-23 19:08:13,647] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [27.85062223, 69.839455055, 1.0, 2.0, 0.4559865734543266, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8714914558214318, 6.980815682304931, 6.9112, 95.55316931735096, 1024973.966533723, 997035.5704043338, 251764.0302736719]
[2019-03-23 19:08:13,648] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:08:13,651] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.2777499e-04 3.9703037e-12 9.9917221e-01 4.9791570e-11 1.0373299e-10], sampled 0.2655406069600882
[2019-03-23 19:08:26,670] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00638241], dtype=float32), 0.009669035]
[2019-03-23 19:08:26,673] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.68333333333334, 78.66666666666667, 1.0, 2.0, 0.2057305944536935, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4091404344145755, 6.911200000000001, 6.9112, 95.55338769695034, 467109.0573844466, 467109.0573844462, 168243.3087871046]
[2019-03-23 19:08:26,674] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:08:26,679] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.7278872e-04 1.1337106e-11 9.9972719e-01 5.0794851e-11 4.4419295e-11], sampled 0.3810237045477691
[2019-03-23 19:08:46,640] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2761.4632 2123706173.6223 758.0000
[2019-03-23 19:08:47,750] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3358.4906 2097718015.9281 182.0000
[2019-03-23 19:08:47,851] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3612.8735 2174833368.9208 249.0000
[2019-03-23 19:08:47,852] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3520.0430 2103786947.7619 183.0000
[2019-03-23 19:08:47,890] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3118.7182 2108779618.2831 370.0000
[2019-03-23 19:08:48,905] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1400000, evaluation results [1400000.0, 3612.873544183571, 2174833368.920848, 249.0, 3358.49059171168, 2097718015.9281473, 182.0, 3520.0430208442963, 2103786947.7619126, 183.0, 2761.4631821882726, 2123706173.6223352, 758.0, 3118.718155167317, 2108779618.2831142, 370.0]
[2019-03-23 19:08:54,716] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2457013e-02 2.7817516e-11 9.8754299e-01 5.3951846e-11 4.5646223e-10], sum to 1.0000
[2019-03-23 19:08:54,726] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5500
[2019-03-23 19:08:54,731] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.33333333333333, 68.66666666666667, 1.0, 2.0, 0.8856745357500817, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9836249799679646, 6.911199999999999, 6.9112, 77.32846344354104, 1546311.079041227, 1546311.079041227, 329222.6346428651], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5395800.0000, 
sim time next is 5396400.0000, 
raw observation next is [27.7, 67.0, 1.0, 2.0, 0.9041595267217113, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9840917085388146, 6.911199999999999, 6.9112, 77.32846344354104, 1566354.208299574, 1566354.208299574, 333087.0482561337], 
processed observation next is [1.0, 0.4782608695652174, 0.8954545454545454, 0.67, 1.0, 1.0, 0.8801994084021392, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9772738693411637, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5801311882591015, 0.5801311882591015, 0.8124074347710578], 
reward next is 0.1876, 
noisyNet noise sample is [array([1.3170081], dtype=float32), 0.69656277]. 
=============================================
[2019-03-23 19:08:55,999] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0312251e-03 4.2890549e-11 9.9896884e-01 1.2915573e-10 1.9985353e-09], sum to 1.0000
[2019-03-23 19:08:56,001] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4653
[2019-03-23 19:08:56,004] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.66666666666666, 90.0, 1.0, 2.0, 0.3827569027982969, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7665751861040256, 6.911200000000001, 6.9112, 77.32846344354104, 872366.3751490691, 872366.3751490688, 211243.7858460549], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4877400.0000, 
sim time next is 4878000.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.3929864939637223, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7877261923350397, 6.9112, 6.9112, 77.32846344354104, 895988.2204126912, 895988.2204126912, 215153.8585204522], 
processed observation next is [1.0, 0.4782608695652174, 0.5909090909090909, 0.88, 1.0, 1.0, 0.24123311745465287, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6967517033357711, 0.0, 0.0, 0.5084288129206541, 0.3318474890417375, 0.3318474890417375, 0.5247655085864688], 
reward next is 0.4752, 
noisyNet noise sample is [array([-0.74096984], dtype=float32), 1.3808246]. 
=============================================
[2019-03-23 19:08:56,038] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[34.15948 ]
 [34.28239 ]
 [34.451366]
 [34.604534]
 [34.79388 ]], R is [[34.23550415]
 [34.37792206]
 [34.52398682]
 [34.67060089]
 [34.82442474]].
[2019-03-23 19:08:58,413] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.9489448e-03 3.5262610e-13 9.9805105e-01 5.6575214e-13 2.2472595e-12], sum to 1.0000
[2019-03-23 19:08:58,420] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8106
[2019-03-23 19:08:58,424] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.0, 98.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3194712227355451, 6.911200000000001, 6.9112, 77.32846344354104, 369305.3286415192, 369305.328641519, 148084.2499810513], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4940400.0000, 
sim time next is 4941000.0000, 
raw observation next is [17.0, 97.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3151827487490375, 6.911200000000001, 6.9112, 77.32846344354104, 364555.9211714517, 364555.9211714515, 147386.1310165155], 
processed observation next is [1.0, 0.17391304347826086, 0.4090909090909091, 0.97, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.021689641070053604, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1350207115449821, 0.13502071154498205, 0.3594783683329646], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3129908], dtype=float32), -0.6068183]. 
=============================================
[2019-03-23 19:08:58,438] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[29.180538]
 [29.189476]
 [29.916996]
 [30.131195]
 [30.258005]], R is [[28.69894028]
 [28.41195107]
 [28.12783241]
 [27.8465538 ]
 [27.56808853]].
[2019-03-23 19:09:01,360] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.10976526e-03 7.10669934e-12 9.98890221e-01 1.03578535e-11
 2.13627067e-11], sum to 1.0000
[2019-03-23 19:09:01,368] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0272
[2019-03-23 19:09:01,376] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.5, 71.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3463429023702277, 6.911199999999999, 6.9112, 77.32846344354104, 398105.1195237249, 398105.1195237252, 153371.8081017601], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5046600.0000, 
sim time next is 5047200.0000, 
raw observation next is [22.0, 69.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3516293343995306, 6.9112, 6.9112, 77.32846344354104, 403865.8730537347, 403865.8730537347, 154316.2070337355], 
processed observation next is [0.0, 0.43478260869565216, 0.6363636363636364, 0.69, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.07375619199932944, 0.0, 0.0, 0.5084288129206541, 0.14957995298286472, 0.14957995298286472, 0.37638099276520853], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5757084], dtype=float32), -0.7183639]. 
=============================================
[2019-03-23 19:09:02,460] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.6962076e-06 1.8986894e-09 9.9999034e-01 5.2396305e-09 2.0310829e-10], sum to 1.0000
[2019-03-23 19:09:02,470] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7028
[2019-03-23 19:09:02,473] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 73.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 301054.5943376464, 301054.5943376461, 122924.2248676677], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4996800.0000, 
sim time next is 4997400.0000, 
raw observation next is [17.83333333333333, 74.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 302352.9389430756, 302352.9389430756, 123513.8369999688], 
processed observation next is [1.0, 0.8695652173913043, 0.44696969696969674, 0.745, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.11198256997891688, 0.11198256997891688, 0.3012532609755337], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9022372], dtype=float32), -1.0133319]. 
=============================================
[2019-03-23 19:09:02,548] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.1709460e-05 2.9767629e-11 9.9996829e-01 9.1007923e-11 4.2724726e-12], sum to 1.0000
[2019-03-23 19:09:02,557] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4985
[2019-03-23 19:09:02,563] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 260831.1855078023, 260831.1855078026, 106414.1874258862], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5022600.0000, 
sim time next is 5023200.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 259994.2629017019, 259994.2629017022, 106247.785527528], 
processed observation next is [0.0, 0.13043478260869565, 0.2727272727272727, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09629417144507478, 0.09629417144507489, 0.2591409403110439], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4870138], dtype=float32), 1.8368301]. 
=============================================
[2019-03-23 19:09:02,854] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5680962e-05 4.6900810e-11 9.9998426e-01 5.7297715e-11 1.3314903e-10], sum to 1.0000
[2019-03-23 19:09:02,860] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4308
[2019-03-23 19:09:02,866] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 265375.6661055167, 265375.6661055164, 107312.1913058169], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5019000.0000, 
sim time next is 5019600.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 263624.173694831, 263624.173694831, 106967.5717435297], 
processed observation next is [0.0, 0.08695652173913043, 0.2727272727272727, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.09763858284993741, 0.09763858284993741, 0.2608965164476334], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.76176614], dtype=float32), -0.94715285]. 
=============================================
[2019-03-23 19:09:09,726] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5298283e-01 1.1305712e-15 8.4701717e-01 1.6449488e-12 5.1499305e-11], sum to 1.0000
[2019-03-23 19:09:09,738] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4676
[2019-03-23 19:09:09,747] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.16666666666666, 81.5, 1.0, 2.0, 0.2549009751498344, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5162417784295152, 6.9112, 6.9112, 77.32846344354104, 580095.8283758549, 580095.8283758549, 181236.8002579222], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5140200.0000, 
sim time next is 5140800.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.2564803483652932, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5194692063133703, 6.9112, 6.9112, 77.32846344354104, 583561.2426936085, 583561.2426936085, 181730.0056875244], 
processed observation next is [0.0, 0.5217391304347826, 0.7272727272727273, 0.83, 1.0, 1.0, 0.0706004354566165, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3135274375905291, 0.0, 0.0, 0.5084288129206541, 0.2161337935902254, 0.2161337935902254, 0.4432439163110351], 
reward next is 0.5568, 
noisyNet noise sample is [array([0.8153613], dtype=float32), -0.7027129]. 
=============================================
[2019-03-23 19:09:11,706] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.03794797e-05 1.13332254e-14 9.99939561e-01 7.28436544e-14
 2.42572303e-12], sum to 1.0000
[2019-03-23 19:09:11,717] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9857
[2019-03-23 19:09:11,722] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.2196503239747877, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4407286633345993, 6.9112, 6.9112, 77.32846344354104, 500764.4016974586, 500764.4016974586, 168616.942922011], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5185800.0000, 
sim time next is 5186400.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.219232182382024, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4398866994830272, 6.911200000000001, 6.9112, 77.32846344354104, 499809.5134760256, 499809.5134760253, 168532.6560813822], 
processed observation next is [1.0, 0.0, 0.6363636363636364, 0.83, 1.0, 1.0, 0.024040227977529978, 0.0, 1.0, -0.25, 1.0, 1.0, 0.19983814211861034, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18511463462075023, 0.18511463462075012, 0.4110552587350786], 
reward next is 0.5889, 
noisyNet noise sample is [array([0.8899163], dtype=float32), -0.7589545]. 
=============================================
[2019-03-23 19:09:12,458] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1809903e-02 1.6682810e-15 9.8819005e-01 1.4989049e-14 3.7363003e-13], sum to 1.0000
[2019-03-23 19:09:12,464] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1890
[2019-03-23 19:09:12,472] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.06666666666667, 83.16666666666667, 1.0, 2.0, 0.2227184675101232, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4473024598932275, 6.9112, 6.9112, 77.32846344354104, 507910.2025580572, 507910.2025580572, 169531.5950395544], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5183400.0000, 
sim time next is 5184000.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.2212988313644893, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4441321677102598, 6.9112, 6.9112, 77.32846344354104, 504560.0296136694, 504560.0296136694, 169011.7077281771], 
processed observation next is [1.0, 0.0, 0.6363636363636364, 0.83, 1.0, 1.0, 0.026623539205611613, 0.0, 1.0, -0.25, 1.0, 1.0, 0.20590309672894264, 0.0, 0.0, 0.5084288129206541, 0.18687408504209976, 0.18687408504209976, 0.4122236773857978], 
reward next is 0.5878, 
noisyNet noise sample is [array([-0.44261035], dtype=float32), -0.849391]. 
=============================================
[2019-03-23 19:09:12,500] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[51.783936]
 [51.9866  ]
 [52.11718 ]
 [52.302258]
 [52.468647]], R is [[51.90034866]
 [51.96785355]
 [52.03335953]
 [52.09677124]
 [52.15810776]].
[2019-03-23 19:09:15,157] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.2838451e-03 2.9223366e-13 9.9771619e-01 5.6103728e-12 1.0823025e-11], sum to 1.0000
[2019-03-23 19:09:15,158] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5036
[2019-03-23 19:09:15,164] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.83333333333333, 65.66666666666666, 1.0, 2.0, 0.3712106827316319, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7414876459276288, 6.9112, 6.9112, 77.32846344354104, 845077.1383972933, 845077.1383972933, 206212.6822683934], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5301600.0000, 
sim time next is 5302200.0000, 
raw observation next is [24.11666666666666, 63.83333333333334, 1.0, 2.0, 0.3723411316280413, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7436937072403637, 6.9112, 6.9112, 77.32846344354104, 847625.8211689317, 847625.8211689317, 206545.0698303461], 
processed observation next is [1.0, 0.34782608695652173, 0.7325757575757573, 0.6383333333333334, 1.0, 1.0, 0.21542641453505157, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6338481532005196, 0.0, 0.0, 0.5084288129206541, 0.3139354893218265, 0.3139354893218265, 0.5037684630008441], 
reward next is 0.4962, 
noisyNet noise sample is [array([-1.4887066], dtype=float32), -0.4450636]. 
=============================================
[2019-03-23 19:09:36,487] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.2349997e-05 1.0442496e-09 9.9997771e-01 1.6208397e-09 2.6625938e-10], sum to 1.0000
[2019-03-23 19:09:36,496] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2078
[2019-03-23 19:09:36,499] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.2, 96.33333333333333, 1.0, 2.0, 0.2015207633499144, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3994963667098912, 6.911199999999999, 6.9112, 77.32846344354104, 456784.9907222936, 456784.9907222939, 162130.1751829051], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5628000.0000, 
sim time next is 5628600.0000, 
raw observation next is [19.1, 96.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3959738496262498, 6.9112, 6.9112, 77.32846344354104, 452963.2394714702, 452963.2394714702, 161623.7859216664], 
processed observation next is [0.0, 0.13043478260869565, 0.5045454545454546, 0.965, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1371054994660712, 0.0, 0.0, 0.5084288129206541, 0.16776416276721118, 0.16776416276721118, 0.3942043559065034], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0617731], dtype=float32), 0.28025818]. 
=============================================
[2019-03-23 19:09:36,536] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.5322776e-06 1.6960542e-09 9.9999642e-01 1.1996767e-09 3.9087542e-11], sum to 1.0000
[2019-03-23 19:09:36,545] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0465
[2019-03-23 19:09:36,552] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.18333333333333, 96.16666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 331174.8649201384, 331174.8649201384, 141318.2744613379], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5647800.0000, 
sim time next is 5648400.0000, 
raw observation next is [16.1, 96.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 327029.2250260091, 327029.2250260088, 140581.9493755782], 
processed observation next is [0.0, 0.391304347826087, 0.3681818181818182, 0.96, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12112193519481818, 0.12112193519481806, 0.34288280335506877], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.13452984], dtype=float32), 0.15742713]. 
=============================================
[2019-03-23 19:09:38,586] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 19:09:38,589] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:09:38,589] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:09:38,590] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:09:38,590] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:09:38,590] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:09:38,593] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:09:38,596] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:09:38,596] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:09:38,598] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:09:38,600] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:09:38,616] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run58
[2019-03-23 19:09:38,643] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run58
[2019-03-23 19:09:38,667] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run58
[2019-03-23 19:09:38,667] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run58
[2019-03-23 19:09:38,668] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run58
[2019-03-23 19:09:41,113] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00654145], dtype=float32), 0.009644618]
[2019-03-23 19:09:41,113] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.64347065, 51.46585227833333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 292810.5563382776, 292810.5563382772, 109072.9211008439]
[2019-03-23 19:09:41,114] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:09:41,117] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.4659717e-06 1.4855034e-08 9.9999058e-01 2.7100347e-08 1.8350508e-09], sampled 0.5582687417496467
[2019-03-23 19:09:48,667] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00654145], dtype=float32), 0.009644618]
[2019-03-23 19:09:48,668] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.66666666666667, 92.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3903957821480558, 6.9112, 6.9112, 77.32846344354104, 446675.0952701232, 446675.0952701232, 160789.9770618979]
[2019-03-23 19:09:48,668] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:09:48,670] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.3411155e-06 1.4535860e-09 9.9999571e-01 2.6151352e-09 1.9599340e-10], sampled 0.013393841632333037
[2019-03-23 19:09:49,667] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00654145], dtype=float32), 0.009644618]
[2019-03-23 19:09:49,667] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.13333333333333, 73.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 95.55338769695034, 311232.7997664104, 311232.7997664108, 131711.152013251]
[2019-03-23 19:09:49,669] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:09:49,672] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.4706170e-06 4.1484736e-09 9.9999452e-01 7.2071820e-09 3.9902534e-10], sampled 0.02398141367631923
[2019-03-23 19:10:07,519] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00654145], dtype=float32), 0.009644618]
[2019-03-23 19:10:07,520] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [28.7, 47.33333333333334, 1.0, 2.0, 0.3114578888249958, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6275166950132955, 6.911200000000001, 6.9112, 95.55338769695034, 710790.4410573079, 710790.4410573075, 197155.1186316777]
[2019-03-23 19:10:07,521] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:10:07,523] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.9837541e-05 6.4629836e-11 9.9996018e-01 4.4109821e-10 2.4944949e-10], sampled 0.4809880033068066
[2019-03-23 19:10:10,384] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00654145], dtype=float32), 0.009644618]
[2019-03-23 19:10:10,385] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.73333333333333, 41.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3842768859886636, 6.9112, 6.9112, 95.55338769695034, 440413.186496412, 440413.186496412, 163922.1286161493]
[2019-03-23 19:10:10,386] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:10:10,388] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.5421225e-06 2.6745017e-09 9.9999547e-01 5.1287570e-09 3.4394890e-10], sampled 0.01432497966795554
[2019-03-23 19:10:14,455] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00654145], dtype=float32), 0.009644618]
[2019-03-23 19:10:14,457] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.1, 90.0, 1.0, 2.0, 0.2239526598957962, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4494078357866151, 6.911200000000001, 6.9112, 95.55338769695034, 510544.2911126846, 510544.2911126842, 174187.3694410618]
[2019-03-23 19:10:14,457] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:10:14,459] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.6374844e-06 1.1815899e-09 9.9999535e-01 2.5367983e-09 2.7275726e-10], sampled 0.11717713811599295
[2019-03-23 19:10:57,937] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00654145], dtype=float32), 0.009644618]
[2019-03-23 19:10:57,938] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.36806672, 100.0, 1.0, 2.0, 0.3092469936198635, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6238222004129198, 6.911200000000001, 6.9112, 95.55338769695034, 705770.7881054537, 705770.7881054534, 197191.4005507372]
[2019-03-23 19:10:57,940] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:10:57,942] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.6126431e-05 1.6121703e-11 9.9992383e-01 1.5243799e-10 1.3148849e-10], sampled 0.969404811286234
[2019-03-23 19:11:16,427] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00654145], dtype=float32), 0.009644618]
[2019-03-23 19:11:16,427] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.05786693, 57.48152416, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 95.55338769695034, 296812.0455576113, 296812.0455576117, 124283.6616075885]
[2019-03-23 19:11:16,428] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:11:16,431] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.67685776e-06 1.03072315e-08 9.99991298e-01 1.86082509e-08
 1.23481170e-09], sampled 0.7656125267473416
[2019-03-23 19:11:18,221] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3614.9266 2175244236.8672 245.0000
[2019-03-23 19:11:18,276] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3120.3682 2108963837.5466 368.0000
[2019-03-23 19:11:18,813] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2760.4741 2123983995.6919 757.0000
[2019-03-23 19:11:18,821] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3363.0106 2098009196.3145 179.0000
[2019-03-23 19:11:19,003] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3520.5852 2104036914.9924 178.0000
[2019-03-23 19:11:20,021] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1425000, evaluation results [1425000.0, 3614.926595969671, 2175244236.867197, 245.0, 3363.010561098141, 2098009196.3145123, 179.0, 3520.5851756758652, 2104036914.9923701, 178.0, 2760.474142687843, 2123983995.6918697, 757.0, 3120.368164850975, 2108963837.5465617, 368.0]
[2019-03-23 19:11:25,325] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.3892757e-05 2.2625818e-10 9.9996614e-01 4.2071377e-09 3.6711270e-09], sum to 1.0000
[2019-03-23 19:11:25,333] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4398
[2019-03-23 19:11:25,340] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.35, 63.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 225302.9263007614, 225302.9263007611, 92937.83672803755], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5783400.0000, 
sim time next is 5784000.0000, 
raw observation next is [16.26666666666667, 63.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 224064.5260193654, 224064.5260193654, 92624.82924963269], 
processed observation next is [0.0, 0.9565217391304348, 0.3757575757575759, 0.6333333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.08298686148865386, 0.08298686148865386, 0.22591421768203096], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2261903], dtype=float32), -0.62472373]. 
=============================================
[2019-03-23 19:11:25,372] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[9.584517]
 [9.63717 ]
 [9.680926]
 [9.743264]
 [9.880532]], R is [[9.44147873]
 [9.34706402]
 [9.25359344]
 [9.16105747]
 [9.06944656]].
[2019-03-23 19:11:28,990] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.7671877e-05 5.3170927e-12 9.9991226e-01 4.4399224e-11 1.2626855e-10], sum to 1.0000
[2019-03-23 19:11:28,996] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9124
[2019-03-23 19:11:28,999] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.4, 78.50000000000001, 1.0, 2.0, 0.2593602993305495, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5251322729692688, 6.911199999999999, 6.9112, 77.32846344354104, 590687.3573835361, 590687.3573835363, 181919.1593138846], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6394200.0000, 
sim time next is 6394800.0000, 
raw observation next is [24.4, 78.0, 1.0, 2.0, 0.2577156554006296, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5217267875174134, 6.911199999999999, 6.9112, 77.32846344354104, 587102.897299976, 587102.8972999762, 181343.7225112357], 
processed observation next is [1.0, 0.0, 0.7454545454545454, 0.78, 1.0, 1.0, 0.07214456925078695, 0.0, 1.0, -0.25, 1.0, 1.0, 0.31675255359630494, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21744551751850963, 0.2174455175185097, 0.44230176222252615], 
reward next is 0.5577, 
noisyNet noise sample is [array([0.96529937], dtype=float32), -0.17116779]. 
=============================================
[2019-03-23 19:11:31,344] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.415459e-04 3.950357e-10 9.991585e-01 8.637379e-10 2.740009e-10], sum to 1.0000
[2019-03-23 19:11:31,354] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9479
[2019-03-23 19:11:31,357] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.41666666666667, 93.0, 1.0, 2.0, 0.4173482683357715, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8369966873201493, 6.9112, 6.9112, 77.32846344354104, 951763.7396956108, 951763.7396956108, 224117.7786977881], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6436200.0000, 
sim time next is 6436800.0000, 
raw observation next is [20.5, 93.0, 1.0, 2.0, 0.4118562595353697, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8265665870717707, 6.911199999999999, 6.9112, 77.32846344354104, 939449.194872512, 939449.1948725122, 222522.9594586094], 
processed observation next is [1.0, 0.5217391304347826, 0.5681818181818182, 0.93, 1.0, 1.0, 0.2648203244192121, 0.0, 1.0, -0.25, 1.0, 1.0, 0.7522379815311009, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.34794414624907855, 0.3479441462490786, 0.5427389255088034], 
reward next is 0.4573, 
noisyNet noise sample is [array([0.5525571], dtype=float32), 2.6592069]. 
=============================================
[2019-03-23 19:11:37,689] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.7470173e-05 5.9860049e-08 9.9994242e-01 1.1862491e-07 1.3288989e-08], sum to 1.0000
[2019-03-23 19:11:37,696] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1692
[2019-03-23 19:11:37,703] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.25, 78.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3578380731384207, 6.911199999999999, 6.9112, 77.32846344354104, 411806.2848330311, 411806.2848330314, 154348.5663000981], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6031800.0000, 
sim time next is 6032400.0000, 
raw observation next is [20.16666666666666, 78.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3537351434101038, 6.9112, 6.9112, 77.32846344354104, 407258.8083367005, 407258.8083367005, 153677.026893468], 
processed observation next is [1.0, 0.8260869565217391, 0.5530303030303028, 0.78, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.07676449058586261, 0.0, 0.0, 0.5084288129206541, 0.15083659568025945, 0.15083659568025945, 0.37482201681333654], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6084499], dtype=float32), 0.41222247]. 
=============================================
[2019-03-23 19:11:39,442] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.1271040e-06 5.9420653e-08 9.9999070e-01 1.1197658e-07 5.1131046e-09], sum to 1.0000
[2019-03-23 19:11:39,447] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2284
[2019-03-23 19:11:39,450] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [11.36666666666667, 96.16666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 230451.1696041964, 230451.1696041964, 91381.56232069733], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6588600.0000, 
sim time next is 6589200.0000, 
raw observation next is [11.63333333333333, 96.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 219379.2245679525, 219379.2245679522, 90039.08845251933], 
processed observation next is [1.0, 0.2608695652173913, 0.16515151515151497, 0.9633333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08125156465479723, 0.0812515646547971, 0.21960753281102274], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.94423604], dtype=float32), 1.1327003]. 
=============================================
[2019-03-23 19:11:40,422] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.0503443e-04 4.0718229e-10 9.9959499e-01 3.2666652e-09 6.6312550e-10], sum to 1.0000
[2019-03-23 19:11:40,428] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0418
[2019-03-23 19:11:40,434] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.55, 56.5, 1.0, 2.0, 0.281193060584705, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5249258414561596, 6.9112, 6.9112, 77.32846344354104, 610847.2488974921, 610847.2488974921, 161604.1799085112], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6089400.0000, 
sim time next is 6090000.0000, 
raw observation next is [20.73333333333333, 56.0, 1.0, 2.0, 0.2670853257471572, 0.0, 2.0, 0.0, 1.0, 2.0, 0.498589791180803, 6.9112, 6.9112, 77.32846344354104, 580182.1446116333, 580182.1446116333, 159596.7090816484], 
processed observation next is [1.0, 0.4782608695652174, 0.5787878787878786, 0.56, 1.0, 1.0, 0.0838566571839465, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2836997016868614, 0.0, 0.0, 0.5084288129206541, 0.2148822757820864, 0.2148822757820864, 0.389260266052801], 
reward next is 0.6107, 
noisyNet noise sample is [array([0.99217], dtype=float32), -0.72155404]. 
=============================================
[2019-03-23 19:11:40,448] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[25.707052]
 [25.695484]
 [25.44688 ]
 [24.87192 ]
 [24.10787 ]], R is [[25.74990845]
 [26.09825134]
 [26.44644165]
 [26.79157829]
 [27.1386795 ]].
[2019-03-23 19:11:42,675] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.5278675e-04 2.5469284e-09 9.9944705e-01 8.8496144e-08 6.6954708e-09], sum to 1.0000
[2019-03-23 19:11:42,685] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7781
[2019-03-23 19:11:42,689] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.7, 43.5, 1.0, 2.0, 0.3634721303174696, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6955783796945096, 6.9112, 6.9112, 77.32846344354104, 804466.0494285449, 804466.0494285449, 189911.2002963003], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6103800.0000, 
sim time next is 6104400.0000, 
raw observation next is [24.8, 43.0, 1.0, 2.0, 0.3727648829963778, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7133586082177259, 6.911200000000001, 6.9112, 77.32846344354104, 825048.0467663457, 825048.0467663455, 192446.5896662431], 
processed observation next is [1.0, 0.6521739130434783, 0.7636363636363637, 0.43, 1.0, 1.0, 0.2159561037454722, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5905122974538942, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3055733506542021, 0.30557335065420205, 0.46938192601522705], 
reward next is 0.5306, 
noisyNet noise sample is [array([-1.3985047], dtype=float32), -0.8533801]. 
=============================================
[2019-03-23 19:11:43,243] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.0454631e-06 5.5440847e-08 9.9999380e-01 2.0142675e-08 1.2952329e-09], sum to 1.0000
[2019-03-23 19:11:43,249] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0713
[2019-03-23 19:11:43,253] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.0, 61.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 308014.7679305127, 308014.7679305124, 127975.2711511102], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6120000.0000, 
sim time next is 6120600.0000, 
raw observation next is [19.9, 61.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 306100.2671935021, 306100.2671935024, 126938.3959910611], 
processed observation next is [1.0, 0.8695652173913043, 0.5409090909090909, 0.6133333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1133704693309267, 0.11337046933092682, 0.30960584388063683], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6236181], dtype=float32), -0.39659646]. 
=============================================
[2019-03-23 19:11:58,658] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.9241583e-02 3.3963897e-14 9.8075837e-01 6.0225484e-11 7.9360449e-13], sum to 1.0000
[2019-03-23 19:11:58,669] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8952
[2019-03-23 19:11:58,676] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 76.0, 1.0, 2.0, 0.2610215125382477, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5286546248511925, 6.9112, 6.9112, 77.32846344354104, 593958.2517192913, 593958.2517192913, 182798.8389006531], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6390000.0000, 
sim time next is 6390600.0000, 
raw observation next is [24.9, 76.5, 1.0, 2.0, 0.2606197636559521, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5278298678041479, 6.911200000000001, 6.9112, 77.32846344354104, 593092.8776276096, 593092.8776276094, 182657.9407324349], 
processed observation next is [0.0, 1.0, 0.7681818181818181, 0.765, 1.0, 1.0, 0.07577470456994008, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3254712397202113, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21966402875096652, 0.21966402875096644, 0.4455071725181339], 
reward next is 0.5545, 
noisyNet noise sample is [array([-1.8619317], dtype=float32), -0.43051982]. 
=============================================
[2019-03-23 19:11:59,084] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.8940791e-02 7.8006645e-14 9.7105926e-01 5.3699130e-13 2.0327906e-11], sum to 1.0000
[2019-03-23 19:11:59,090] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6906
[2019-03-23 19:11:59,094] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.63333333333333, 62.0, 1.0, 2.0, 0.2409817143199127, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4872154830513757, 6.9112, 6.9112, 77.32846344354104, 549661.2003516847, 549661.2003516847, 176347.6919774566], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6952800.0000, 
sim time next is 6953400.0000, 
raw observation next is [26.9, 61.0, 1.0, 2.0, 0.2429291156858171, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4912876350102671, 6.911200000000001, 6.9112, 77.32846344354104, 554013.143876793, 554013.1438767927, 176974.6841792314], 
processed observation next is [0.0, 0.4782608695652174, 0.859090909090909, 0.61, 1.0, 1.0, 0.05366139460727136, 0.0, 1.0, -0.25, 1.0, 1.0, 0.27326805001466736, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2051900532877011, 0.205190053287701, 0.4316455711688571], 
reward next is 0.5684, 
noisyNet noise sample is [array([-0.5480818], dtype=float32), 0.7758281]. 
=============================================
[2019-03-23 19:12:01,429] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.1858122e-05 9.6574491e-09 9.9994814e-01 1.3889788e-08 3.0037799e-09], sum to 1.0000
[2019-03-23 19:12:01,436] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3579
[2019-03-23 19:12:01,440] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.8, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3378444614192031, 6.9112, 6.9112, 77.32846344354104, 389475.6455335019, 389475.6455335019, 151251.4090651696], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6651000.0000, 
sim time next is 6651600.0000, 
raw observation next is [18.8, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3370646954267572, 6.9112, 6.9112, 77.32846344354104, 388577.2600851679, 388577.2600851679, 151157.7825147856], 
processed observation next is [1.0, 1.0, 0.49090909090909096, 0.87, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.052949564895367465, 0.0, 0.0, 0.5084288129206541, 0.14391750373524737, 0.14391750373524737, 0.36867751832874535], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.437203], dtype=float32), 1.2912376]. 
=============================================
[2019-03-23 19:12:08,153] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.78654841e-03 1.07906954e-10 9.98213530e-01 2.29367791e-09
 4.15450840e-10], sum to 1.0000
[2019-03-23 19:12:08,160] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7773
[2019-03-23 19:12:08,167] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.55, 59.0, 1.0, 2.0, 0.4022365029602502, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7915872274337006, 6.911199999999999, 6.9112, 77.32846344354104, 908131.7740013017, 908131.774001302, 210237.164738817], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6615000.0000, 
sim time next is 6615600.0000, 
raw observation next is [23.46666666666667, 59.33333333333334, 1.0, 2.0, 0.3915162982575757, 0.0, 2.0, 0.0, 1.0, 2.0, 0.770412987236711, 6.9112, 6.9112, 77.32846344354104, 883850.1541941302, 883850.1541941302, 206732.6449905423], 
processed observation next is [1.0, 0.5652173913043478, 0.7030303030303031, 0.5933333333333334, 1.0, 1.0, 0.23939537282196963, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6720185531953016, 0.0, 0.0, 0.5084288129206541, 0.327351908960789, 0.327351908960789, 0.5042259633915666], 
reward next is 0.4958, 
noisyNet noise sample is [array([1.9912393], dtype=float32), 0.17491558]. 
=============================================
[2019-03-23 19:12:08,651] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.0394588e-03 1.2477752e-13 9.9696046e-01 2.1265986e-12 7.0477660e-12], sum to 1.0000
[2019-03-23 19:12:08,659] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7190
[2019-03-23 19:12:08,664] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.38333333333333, 92.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.342790456633958, 6.9112, 6.9112, 77.32846344354104, 394688.1696236137, 394688.1696236137, 152309.9304971218], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6663000.0000, 
sim time next is 6663600.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3409864112971658, 6.9112, 6.9112, 77.32846344354104, 392668.9668405033, 392668.9668405033, 152036.4495728357], 
processed observation next is [1.0, 0.13043478260869565, 0.4681818181818182, 0.93, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.058552016138808276, 0.0, 0.0, 0.5084288129206541, 0.14543295068166787, 0.14543295068166787, 0.3708206087142334], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5492524], dtype=float32), 0.659936]. 
=============================================
[2019-03-23 19:12:09,679] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 19:12:09,682] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:12:09,682] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:12:09,682] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:12:09,683] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:12:09,683] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:12:09,684] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:12:09,683] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:12:09,685] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:12:09,684] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:12:09,685] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:12:09,706] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run59
[2019-03-23 19:12:09,706] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run59
[2019-03-23 19:12:09,730] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run59
[2019-03-23 19:12:09,731] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run59
[2019-03-23 19:12:09,806] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run59
[2019-03-23 19:12:18,028] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00638184], dtype=float32), 0.0099629]
[2019-03-23 19:12:18,030] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.33333333333333, 79.66666666666667, 1.0, 2.0, 0.2567693393859309, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4939223143890309, 6.911199999999999, 6.9112, 77.32846344354104, 570368.729332178, 570368.7293321784, 166266.8090671405]
[2019-03-23 19:12:18,031] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:12:18,034] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.1999384e-02 4.4695688e-12 9.1800064e-01 6.0749947e-11 1.8351001e-10], sampled 0.6784577800947125
[2019-03-23 19:12:19,400] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00638184], dtype=float32), 0.0099629]
[2019-03-23 19:12:19,403] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.2, 43.0, 1.0, 2.0, 0.210930910800595, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3937618005610877, 6.9112, 6.9112, 95.55338769695034, 458100.7984534182, 458100.7984534182, 144191.1382990529]
[2019-03-23 19:12:19,404] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:12:19,407] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.765103e-03 7.108363e-11 9.912349e-01 5.699545e-10 7.029921e-10], sampled 0.5889457325787862
[2019-03-23 19:12:53,746] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00638184], dtype=float32), 0.0099629]
[2019-03-23 19:12:53,747] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.4, 76.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3640568723629969, 6.911199999999999, 6.9112, 95.55338769695034, 419040.802119965, 419040.8021199654, 159630.5878859222]
[2019-03-23 19:12:53,748] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:12:53,751] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.7000092e-02 2.4378663e-12 9.8299992e-01 2.1267273e-11 3.7116366e-11], sampled 0.6803443846213861
[2019-03-23 19:13:05,458] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00638184], dtype=float32), 0.0099629]
[2019-03-23 19:13:05,460] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.75, 72.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 248835.3339982424, 248835.3339982424, 106744.7254986183]
[2019-03-23 19:13:05,461] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:13:05,467] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.1955998e-03 5.3545657e-11 9.9280435e-01 2.5992458e-10 2.4880736e-10], sampled 0.7572951639299251
[2019-03-23 19:13:37,885] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00638184], dtype=float32), 0.0099629]
[2019-03-23 19:13:37,886] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.82392618, 89.27333971333334, 1.0, 2.0, 0.2929095970604121, 0.0, 2.0, 0.0, 1.0, 2.0, 0.592947244624784, 6.911199999999999, 6.9112, 95.55338769695034, 667297.7095759995, 667297.7095759999, 195234.2201697231]
[2019-03-23 19:13:37,886] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:13:37,889] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.1505673e-02 1.3774887e-11 9.2849427e-01 2.5105201e-10 6.5847588e-10], sampled 0.8011233112238071
[2019-03-23 19:13:49,437] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2657.6315 2115803598.2546 867.0000
[2019-03-23 19:13:49,568] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 2993.0402 2098570898.4897 483.0000
[2019-03-23 19:13:49,613] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3218.2133 2088219955.7575 284.0000
[2019-03-23 19:13:49,841] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3371.9915 2092476750.6251 307.0000
[2019-03-23 19:13:49,867] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3509.1110 2165725512.0756 341.0000
[2019-03-23 19:13:50,884] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1450000, evaluation results [1450000.0, 3509.111015324215, 2165725512.0756226, 341.0, 3218.2133245712475, 2088219955.7574627, 284.0, 3371.991508486048, 2092476750.6251206, 307.0, 2657.631514445115, 2115803598.2545977, 867.0, 2993.0401710387678, 2098570898.489685, 483.0]
[2019-03-23 19:13:51,471] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.6174236e-04 5.4028192e-08 9.9903822e-01 1.8119213e-08 2.8866083e-08], sum to 1.0000
[2019-03-23 19:13:51,478] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5964
[2019-03-23 19:13:51,482] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.8, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3416028516002544, 6.9112, 6.9112, 77.32846344354104, 393802.0607554184, 393802.0607554184, 151707.7029573327], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6647400.0000, 
sim time next is 6648000.0000, 
raw observation next is [18.8, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3399815243758804, 6.9112, 6.9112, 77.32846344354104, 391934.4890670407, 391934.4890670407, 151511.719950099], 
processed observation next is [1.0, 0.9565217391304348, 0.49090909090909096, 0.87, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0571164633941149, 0.0, 0.0, 0.5084288129206541, 0.14516092187668173, 0.14516092187668173, 0.36954078036609517], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.2708347], dtype=float32), -1.4077922]. 
=============================================
[2019-03-23 19:13:51,504] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[15.168345]
 [15.177476]
 [15.17534 ]
 [15.113767]
 [15.223826]], R is [[15.01346874]
 [14.86333466]
 [14.71470165]
 [14.56755447]
 [14.42187881]].
[2019-03-23 19:13:51,759] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6951887e-02 2.6039618e-10 9.8304808e-01 4.2489336e-09 4.4528186e-09], sum to 1.0000
[2019-03-23 19:13:51,766] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0509
[2019-03-23 19:13:51,770] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.45, 65.0, 1.0, 2.0, 0.3604144347834538, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7080082215482594, 6.9112, 6.9112, 77.32846344354104, 812689.278335938, 812689.278335938, 196639.6177906653], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6622200.0000, 
sim time next is 6622800.0000, 
raw observation next is [22.36666666666667, 65.33333333333334, 1.0, 2.0, 0.3591013458817164, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7051116134443776, 6.9112, 6.9112, 77.32846344354104, 809488.8595884431, 809488.8595884431, 196111.095533301], 
processed observation next is [1.0, 0.6521739130434783, 0.6530303030303032, 0.6533333333333334, 1.0, 1.0, 0.19887668235214545, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5787308763491108, 0.0, 0.0, 0.5084288129206541, 0.2998106887364604, 0.2998106887364604, 0.47831974520317316], 
reward next is 0.5217, 
noisyNet noise sample is [array([1.5854993], dtype=float32), -0.41789538]. 
=============================================
[2019-03-23 19:13:56,991] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6198368e-04 4.8743370e-08 9.9983788e-01 9.6101424e-08 1.1041365e-08], sum to 1.0000
[2019-03-23 19:13:57,003] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0789
[2019-03-23 19:13:57,006] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.16666666666666, 93.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3070390198793652, 6.911200000000001, 6.9112, 77.32846344354104, 355624.4246604269, 355624.4246604266, 145969.9921672739], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6752400.0000, 
sim time next is 6753000.0000, 
raw observation next is [17.18333333333333, 93.16666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3051165580348757, 6.911199999999999, 6.9112, 77.32846344354104, 353404.4075844029, 353404.4075844032, 145751.1749609519], 
processed observation next is [1.0, 0.13043478260869565, 0.41742424242424225, 0.9316666666666665, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.00730936862125101, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13089052132755663, 0.13089052132755674, 0.35549067063646805], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.4769399], dtype=float32), 0.6400014]. 
=============================================
[2019-03-23 19:13:57,016] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[2.9327688]
 [2.9690223]
 [3.032867 ]
 [2.797354 ]
 [2.7367606]], R is [[2.81854606]
 [2.79036069]
 [2.76245713]
 [2.73483253]
 [2.70748425]].
[2019-03-23 19:13:59,331] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.4769931e-05 2.6688659e-07 9.9992287e-01 1.8695149e-06 2.7022989e-07], sum to 1.0000
[2019-03-23 19:13:59,344] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4538
[2019-03-23 19:13:59,350] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.55, 56.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3910790654252857, 6.9112, 6.9112, 77.32846344291083, 446169.6048283677, 446169.6048283677, 161973.1656348255], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6802200.0000, 
sim time next is 6802800.0000, 
raw observation next is [25.36666666666667, 57.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3957148874742608, 6.911199999999999, 6.9112, 77.32846344353715, 451335.6492003283, 451335.6492003286, 162711.9947322173], 
processed observation next is [1.0, 0.7391304347826086, 0.7893939393939395, 0.5733333333333335, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.13673555353465833, -8.881784197001253e-17, 0.0, 0.5084288129206285, 0.16716135155567713, 0.16716135155567727, 0.3968585237371154], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.35757256], dtype=float32), 0.41345775]. 
=============================================
[2019-03-23 19:13:59,605] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.7233185e-05 6.1963938e-08 9.9996257e-01 1.9999075e-07 4.5690474e-08], sum to 1.0000
[2019-03-23 19:13:59,612] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9089
[2019-03-23 19:13:59,618] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.06666666666667, 68.0, 1.0, 2.0, 0.2011800553071097, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3990364417321115, 6.911199999999999, 6.9112, 77.32846344354104, 456152.4641430235, 456152.4641430238, 162191.3865090852], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6810000.0000, 
sim time next is 6810600.0000, 
raw observation next is [22.88333333333333, 69.5, 1.0, 2.0, 0.2034151428600629, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4037288663501633, 6.911200000000001, 6.9112, 77.32846344354104, 461389.1115028213, 461389.1115028211, 162721.9070063483], 
processed observation next is [1.0, 0.8260869565217391, 0.6765151515151513, 0.695, 1.0, 1.0, 0.004268928575078615, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1481840947859476, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17088485611215604, 0.17088485611215595, 0.3968827000154837], 
reward next is 0.6031, 
noisyNet noise sample is [array([-0.15137954], dtype=float32), 0.08795683]. 
=============================================
[2019-03-23 19:14:03,668] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.7188754e-01 2.0795223e-12 7.2811240e-01 1.0891768e-10 2.8419541e-11], sum to 1.0000
[2019-03-23 19:14:03,673] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3789
[2019-03-23 19:14:03,679] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.38333333333334, 49.16666666666667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7905414381040743, 7.453265662514363, 6.9112, 77.32717531563691, 624466.7486429461, 448417.8412680393, 140435.8921996849], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6876600.0000, 
sim time next is 6877200.0000, 
raw observation next is [28.46666666666667, 49.33333333333334, 1.0, 1.0, 0.2512123232120245, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5064183466686383, 6.9112, 6.9112, 77.32813771062544, 573322.3879580928, 573322.3879580928, 177109.2718580086], 
processed observation next is [0.0, 0.6086956521739131, 0.9303030303030304, 0.4933333333333334, 1.0, 0.5, 0.06401540401503064, 0.0, 1.0, -0.25, 1.0, 1.0, 0.294883352383769, 0.0, 0.0, 0.5084266712513097, 0.212341625169664, 0.212341625169664, 0.43197383380002097], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.2129549], dtype=float32), 0.22528559]. 
=============================================
[2019-03-23 19:14:06,871] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.2718896e-04 1.1689118e-10 9.9957281e-01 9.2674153e-09 2.3311503e-10], sum to 1.0000
[2019-03-23 19:14:06,878] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6384
[2019-03-23 19:14:06,882] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.6, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3838797976627713, 6.9112, 6.9112, 77.32846344354104, 439212.1871467398, 439212.1871467398, 159923.2048465506], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6942600.0000, 
sim time next is 6943200.0000, 
raw observation next is [21.96666666666667, 75.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3906856427965613, 6.9112, 6.9112, 77.32846344354104, 446577.9141561026, 446577.9141561026, 161195.9771741443], 
processed observation next is [0.0, 0.34782608695652173, 0.6348484848484849, 0.7566666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1295509182808019, 0.0, 0.0, 0.5084288129206541, 0.16539922746522318, 0.16539922746522318, 0.3931609199369373], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.39259738], dtype=float32), 0.7849486]. 
=============================================
[2019-03-23 19:14:15,070] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2572398e-03 2.1373969e-08 9.9874264e-01 3.8398550e-08 1.7173245e-09], sum to 1.0000
[2019-03-23 19:14:15,078] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5968
[2019-03-23 19:14:15,081] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.1, 87.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 249874.7790733079, 249874.7790733082, 99357.20227054623], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7266600.0000, 
sim time next is 7267200.0000, 
raw observation next is [14.0, 87.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 239163.6272624309, 239163.6272624306, 96924.64271469855], 
processed observation next is [1.0, 0.08695652173913043, 0.2727272727272727, 0.8733333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08857912120830774, 0.08857912120830762, 0.23640156759682573], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.3968547], dtype=float32), -0.4175028]. 
=============================================
[2019-03-23 19:14:16,875] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.1947049e-04 4.5554163e-08 9.9978048e-01 1.2774262e-07 9.1954515e-09], sum to 1.0000
[2019-03-23 19:14:16,887] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7604
[2019-03-23 19:14:16,894] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.7, 95.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3391315314543853, 6.911200000000001, 6.9112, 77.32846344354104, 391272.8255845904, 391272.8255845901, 151103.0758616095], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7108200.0000, 
sim time next is 7108800.0000, 
raw observation next is [17.7, 94.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3366383919213809, 6.9112, 6.9112, 77.32846344354104, 388544.8883257391, 388544.8883257391, 150662.4814400856], 
processed observation next is [1.0, 0.2608695652173913, 0.44090909090909086, 0.9433333333333335, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.052340559887687016, 0.0, 0.0, 0.5084288129206541, 0.1439055141947182, 0.1439055141947182, 0.367469466927038], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.84146], dtype=float32), -0.25632355]. 
=============================================
[2019-03-23 19:14:20,793] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.8582547e-04 1.8308291e-10 9.9941421e-01 6.0963595e-10 1.1784028e-10], sum to 1.0000
[2019-03-23 19:14:20,804] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7857
[2019-03-23 19:14:20,810] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.35, 65.0, 1.0, 2.0, 0.2078405470992428, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3879927685552313, 6.911200000000001, 6.9112, 77.32846344354104, 451426.5765175346, 451426.5765175343, 137780.7722397916], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7203000.0000, 
sim time next is 7203600.0000, 
raw observation next is [18.8, 63.0, 1.0, 2.0, 0.2011776631789944, 0.0, 2.0, 0.0, 1.0, 2.0, 0.375554623954193, 6.9112, 6.9112, 77.32846344354104, 436948.3886696394, 436948.3886696394, 137758.0589211557], 
processed observation next is [1.0, 0.391304347826087, 0.49090909090909096, 0.63, 1.0, 1.0, 0.0014720789737429976, 0.0, 1.0, -0.25, 1.0, 1.0, 0.10793517707741856, 0.0, 0.0, 0.5084288129206541, 0.1618327365443109, 0.1618327365443109, 0.33599526566135535], 
reward next is 0.6640, 
noisyNet noise sample is [array([1.6190689], dtype=float32), -2.173587]. 
=============================================
[2019-03-23 19:14:28,632] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0220921e-03 1.0914262e-09 9.9897790e-01 2.4551796e-09 1.5655441e-09], sum to 1.0000
[2019-03-23 19:14:28,641] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9738
[2019-03-23 19:14:28,653] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.4, 83.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3116185417948814, 6.9112, 6.9112, 77.32846344354104, 360843.0956374518, 360843.0956374518, 146565.428341724], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7350000.0000, 
sim time next is 7350600.0000, 
raw observation next is [18.3, 83.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3095452157646076, 6.9112, 6.9112, 77.32846344354104, 358512.8753445192, 358512.8753445192, 146261.954326541], 
processed observation next is [1.0, 0.043478260869565216, 0.4681818181818182, 0.835, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.013636022520867994, 0.0, 0.0, 0.5084288129206541, 0.132782546423896, 0.132782546423896, 0.3567364739671731], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.26818296], dtype=float32), -0.799101]. 
=============================================
[2019-03-23 19:14:33,729] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:14:33,729] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:14:33,775] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run8
[2019-03-23 19:14:40,026] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.7326235e-02 4.4685631e-13 9.6267372e-01 5.8533381e-13 2.9795636e-12], sum to 1.0000
[2019-03-23 19:14:40,034] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1368
[2019-03-23 19:14:40,038] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.45, 85.16666666666667, 1.0, 2.0, 0.5115445749136044, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 582881.5154910461, 582881.5154910458, 144077.8317600276], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7581000.0000, 
sim time next is 7581600.0000, 
raw observation next is [22.7, 91.0, 1.0, 2.0, 0.2577144022828251, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5217700637342909, 6.9112, 6.9112, 77.32846344354104, 587004.8842809207, 587004.8842809207, 181446.5839063161], 
processed observation next is [0.0, 0.782608695652174, 0.6681818181818181, 0.91, 1.0, 1.0, 0.07214300285353137, 0.0, 1.0, -0.25, 1.0, 0.5, 0.3168143767632728, 0.0, 0.0, 0.5084288129206541, 0.217409216400341, 0.217409216400341, 0.44255264367394176], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.4030135], dtype=float32), 0.5844269]. 
=============================================
[2019-03-23 19:14:40,387] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 19:14:40,388] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:14:40,388] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:14:40,390] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:14:40,391] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:14:40,393] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:14:40,394] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:14:40,394] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:14:40,394] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:14:40,395] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:14:40,395] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:14:40,417] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run60
[2019-03-23 19:14:40,444] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run60
[2019-03-23 19:14:40,444] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run60
[2019-03-23 19:14:40,471] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run60
[2019-03-23 19:14:40,492] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run60
[2019-03-23 19:14:44,534] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00643903], dtype=float32), 0.010095601]
[2019-03-23 19:14:44,535] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.3, 35.83333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3199405095614802, 6.911199999999999, 6.9112, 95.55338769695034, 370858.8631537178, 370858.8631537181, 151639.0373133298]
[2019-03-23 19:14:44,537] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:14:44,539] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.9636373e-04 2.7063738e-13 9.9950361e-01 1.0825424e-12 5.0933624e-12], sampled 0.20699795030344015
[2019-03-23 19:15:12,006] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00643903], dtype=float32), 0.010095601]
[2019-03-23 19:15:12,007] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.84984406, 59.30011628666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3845435434067537, 6.911199999999999, 6.9112, 95.55338769695034, 439248.3349174722, 439248.3349174725, 165218.2125150241]
[2019-03-23 19:15:12,008] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:15:12,012] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.6996082e-04 1.8726073e-13 9.9962997e-01 8.7120919e-13 4.1835550e-12], sampled 0.9512607602205838
[2019-03-23 19:15:39,377] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00643903], dtype=float32), 0.010095601]
[2019-03-23 19:15:39,378] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.0, 95.0, 1.0, 2.0, 0.2132679063721986, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4260753446009248, 6.911200000000001, 6.9112, 77.32846344354104, 485373.3485780273, 485373.348578027, 166123.2896895479]
[2019-03-23 19:15:39,380] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:15:39,382] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0539838e-03 2.8025661e-14 9.9894601e-01 2.1198351e-13 2.2533282e-12], sampled 0.4977092078745906
[2019-03-23 19:15:53,050] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00643903], dtype=float32), 0.010095601]
[2019-03-23 19:15:53,051] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.24391187, 40.66548321, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3022268366736017, 6.9112, 6.9112, 95.55338769695034, 351436.9941173296, 351436.9941173296, 137503.9437866099]
[2019-03-23 19:15:53,051] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:15:53,054] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.2534675e-04 1.7238141e-13 9.9957460e-01 8.8313628e-13 4.7284611e-12], sampled 0.7684805524578072
[2019-03-23 19:16:20,765] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3116.0103 2108552316.5803 373.0000
[2019-03-23 19:16:21,062] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2760.6282 2123787978.4723 758.0000
[2019-03-23 19:16:21,235] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3610.2722 2175051836.5133 247.0000
[2019-03-23 19:16:21,314] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3360.5144 2097721500.4224 182.0000
[2019-03-23 19:16:21,359] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3519.1808 2103825952.5861 180.0000
[2019-03-23 19:16:22,376] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1475000, evaluation results [1475000.0, 3610.272210291391, 2175051836.513315, 247.0, 3360.514411890702, 2097721500.4224105, 182.0, 3519.180752367247, 2103825952.5860667, 180.0, 2760.628182395967, 2123787978.4722836, 758.0, 3116.01026282302, 2108552316.580299, 373.0]
[2019-03-23 19:16:22,476] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3347047e-03 8.0149603e-15 9.9866533e-01 1.0199539e-12 7.5523794e-13], sum to 1.0000
[2019-03-23 19:16:22,482] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2744
[2019-03-23 19:16:22,487] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.2, 60.0, 1.0, 2.0, 0.2475491366043002, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5008128665479235, 6.911199999999999, 6.9112, 77.32846344354104, 564395.5700972982, 564395.5700972986, 178307.6467254173], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7563600.0000, 
sim time next is 7564200.0000, 
raw observation next is [27.38333333333333, 59.33333333333333, 1.0, 2.0, 0.248795616088736, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5034110792908012, 6.911199999999999, 6.9112, 77.32846344354104, 567156.3498311719, 567156.3498311721, 178722.5146329789], 
processed observation next is [0.0, 0.5652173913043478, 0.8810606060606059, 0.5933333333333333, 1.0, 1.0, 0.06099452011091997, 0.0, 1.0, -0.25, 1.0, 1.0, 0.29058725612971603, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21005790734487848, 0.21005790734487859, 0.43590857227555835], 
reward next is 0.5641, 
noisyNet noise sample is [array([0.63874066], dtype=float32), 0.53504986]. 
=============================================
[2019-03-23 19:16:23,829] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.4312764e-03 2.0517466e-14 9.9856865e-01 1.8319775e-12 8.1972406e-12], sum to 1.0000
[2019-03-23 19:16:23,838] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9596
[2019-03-23 19:16:23,848] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.0, 96.0, 1.0, 2.0, 0.2178988303214131, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4357396186072912, 6.9112, 6.9112, 77.32846344354104, 496125.616411851, 496125.616411851, 167263.6434498948], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7603200.0000, 
sim time next is 7603800.0000, 
raw observation next is [20.0, 96.0, 1.0, 2.0, 0.2175853880845915, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4350940646623711, 6.911200000000001, 6.9112, 77.32846344354104, 495402.3814129931, 495402.3814129928, 167191.3595976499], 
processed observation next is [1.0, 0.0, 0.5454545454545454, 0.96, 1.0, 1.0, 0.02198173510573935, 0.0, 1.0, -0.25, 1.0, 1.0, 0.19299152094624447, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18348236348629374, 0.18348236348629363, 0.40778380389670704], 
reward next is 0.5922, 
noisyNet noise sample is [array([-0.85645354], dtype=float32), 0.0642877]. 
=============================================
[2019-03-23 19:16:24,686] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6537130e-02 4.8842268e-14 9.8346287e-01 5.1844510e-13 1.0143163e-10], sum to 1.0000
[2019-03-23 19:16:24,695] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2230
[2019-03-23 19:16:24,699] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.0, 96.0, 1.0, 2.0, 0.2166359424211106, 0.0, 2.0, 0.0, 1.0, 2.0, 0.433186027787709, 6.9112, 6.9112, 77.32846344354104, 493234.9068481887, 493234.9068481887, 167003.5625996653], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7609200.0000, 
sim time next is 7609800.0000, 
raw observation next is [20.0, 96.0, 1.0, 2.0, 0.2166769681721322, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4332689066829524, 6.9112, 6.9112, 77.32846344354104, 493328.7764960498, 493328.7764960498, 167011.941679087], 
processed observation next is [1.0, 0.043478260869565216, 0.5454545454545454, 0.96, 1.0, 1.0, 0.02084621021516523, 0.0, 1.0, -0.25, 1.0, 1.0, 0.19038415240421777, 0.0, 0.0, 0.5084288129206541, 0.1827143616652036, 0.1827143616652036, 0.4073461992172854], 
reward next is 0.5927, 
noisyNet noise sample is [array([-2.6757731], dtype=float32), 1.1692272]. 
=============================================
[2019-03-23 19:16:25,414] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.2221340e-04 9.9753616e-10 9.9967778e-01 3.2243191e-10 1.5776317e-08], sum to 1.0000
[2019-03-23 19:16:25,425] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4640
[2019-03-23 19:16:25,432] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.23333333333333, 67.33333333333333, 1.0, 2.0, 0.640675420071869, 0.0, 2.0, 0.0, 1.0, 2.0, 0.976183124052992, 6.911199999999999, 6.9112, 77.32846344354104, 1277040.645706423, 1277040.645706424, 282392.9728008267], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7645200.0000, 
sim time next is 7645800.0000, 
raw observation next is [26.41666666666667, 66.16666666666667, 1.0, 2.0, 0.6417793774196058, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9760907989508828, 6.911199999999999, 6.9112, 77.32846344354104, 1278360.069872997, 1278360.069872998, 282462.262961186], 
processed observation next is [1.0, 0.4782608695652174, 0.8371212121212124, 0.6616666666666667, 1.0, 1.0, 0.5522242217745071, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9658439985012613, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.47346669254555446, 0.4734666925455548, 0.6889323486858195], 
reward next is 0.3111, 
noisyNet noise sample is [array([-0.16831878], dtype=float32), 0.074141234]. 
=============================================
[2019-03-23 19:16:25,437] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1185356e-03 8.5173249e-14 9.9888152e-01 9.5287916e-13 8.5347181e-12], sum to 1.0000
[2019-03-23 19:16:25,445] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1619
[2019-03-23 19:16:25,454] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.2, 87.5, 1.0, 2.0, 0.3304411475724262, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6669355987813842, 6.911200000000001, 6.9112, 77.32846344354104, 754253.0147710152, 754253.0147710148, 198818.7222737148], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7633800.0000, 
sim time next is 7634400.0000, 
raw observation next is [22.56666666666667, 85.66666666666667, 1.0, 2.0, 0.3804010772449728, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7684344187858195, 6.911200000000001, 6.9112, 77.32846344354104, 868248.6042790259, 868248.6042790256, 215716.3237608086], 
processed observation next is [1.0, 0.34782608695652173, 0.6621212121212122, 0.8566666666666667, 1.0, 1.0, 0.22550134655621598, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6691920268368851, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.32157355714038, 0.32157355714037983, 0.5261373750263624], 
reward next is 0.4739, 
noisyNet noise sample is [array([0.53011274], dtype=float32), 2.4803128]. 
=============================================
[2019-03-23 19:16:31,369] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.1477982e-06 1.5827345e-09 9.9999881e-01 7.2411466e-10 5.4871902e-11], sum to 1.0000
[2019-03-23 19:16:31,379] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7583
[2019-03-23 19:16:31,383] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.65, 78.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 234078.7600089303, 234078.7600089303, 95105.80641700671], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7788600.0000, 
sim time next is 7789200.0000, 
raw observation next is [14.56666666666667, 79.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 230751.4157596551, 230751.4157596548, 94485.85099425945], 
processed observation next is [1.0, 0.13043478260869565, 0.29848484848484863, 0.7933333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08546348731839078, 0.08546348731839067, 0.23045329510794987], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9245826], dtype=float32), -1.2062536]. 
=============================================
[2019-03-23 19:16:33,583] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:16:33,584] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:16:33,649] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run8
[2019-03-23 19:16:39,272] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0477772e-03 2.0449928e-10 9.9795222e-01 3.6005743e-09 1.0806747e-08], sum to 1.0000
[2019-03-23 19:16:39,281] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6131
[2019-03-23 19:16:39,287] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.18333333333333, 92.0, 1.0, 2.0, 0.3876695626045816, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7745566206528189, 6.9112, 6.9112, 77.32846344354104, 882680.094276569, 882680.094276569, 211731.4785361196], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7902600.0000, 
sim time next is 7903200.0000, 
raw observation next is [20.36666666666667, 91.0, 1.0, 2.0, 0.3579307647325088, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7155940728327501, 6.9112, 6.9112, 77.32846344354104, 815141.4456037289, 815141.4456037289, 202404.4398328922], 
processed observation next is [1.0, 0.4782608695652174, 0.5621212121212124, 0.91, 1.0, 1.0, 0.19741345591563597, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5937058183325002, 0.0, 0.0, 0.5084288129206541, 0.3019042391124922, 0.3019042391124922, 0.4936693654460786], 
reward next is 0.5063, 
noisyNet noise sample is [array([-0.4991396], dtype=float32), 2.2555745]. 
=============================================
[2019-03-23 19:16:40,011] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:16:40,011] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:16:40,040] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run8
[2019-03-23 19:16:40,523] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:16:40,524] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:16:40,579] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run8
[2019-03-23 19:16:41,830] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.1654959e-05 3.8598356e-09 9.9993837e-01 5.4122968e-09 1.4349101e-08], sum to 1.0000
[2019-03-23 19:16:41,832] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1079
[2019-03-23 19:16:41,835] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.0, 88.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3071817303226211, 6.9112, 6.9112, 77.32846344354104, 357369.0073777969, 357369.0073777969, 131626.3669870989], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 493800.0000, 
sim time next is 494400.0000, 
raw observation next is [16.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 313681.8441290491, 313681.8441290488, 123442.1878952359], 
processed observation next is [1.0, 0.7391304347826086, 0.36363636363636365, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1161784607885367, 0.1161784607885366, 0.301078507061551], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.21340172], dtype=float32), -0.7335229]. 
=============================================
[2019-03-23 19:16:42,035] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:16:42,035] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:16:42,077] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run8
[2019-03-23 19:16:42,192] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:16:42,192] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:16:42,221] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run8
[2019-03-23 19:16:42,319] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:16:42,320] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:16:42,347] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run8
[2019-03-23 19:16:42,579] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:16:42,580] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:16:42,586] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:16:42,588] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:16:42,596] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run8
[2019-03-23 19:16:42,618] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:16:42,619] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:16:42,631] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:16:42,631] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:16:42,645] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run8
[2019-03-23 19:16:42,685] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run8
[2019-03-23 19:16:42,723] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run8
[2019-03-23 19:16:42,800] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:16:42,801] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:16:42,814] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run8
[2019-03-23 19:16:42,845] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:16:42,846] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:16:42,849] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:16:42,868] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:16:42,872] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run8
[2019-03-23 19:16:42,918] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run8
[2019-03-23 19:16:42,956] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:16:42,957] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:16:43,011] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run8
[2019-03-23 19:16:43,357] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:16:43,357] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:16:43,360] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run8
[2019-03-23 19:16:46,697] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.4023987e-04 1.4153307e-09 9.9905974e-01 3.4702804e-08 3.9324028e-08], sum to 1.0000
[2019-03-23 19:16:46,707] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3490
[2019-03-23 19:16:46,711] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.66666666666667, 83.33333333333334, 1.0, 2.0, 0.4133479201968704, 0.0, 2.0, 0.0, 1.0, 2.0, 0.821080961063275, 6.9112, 6.9112, 77.32846344354104, 938455.8198074932, 938455.8198074932, 217850.9550075138], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 51600.0000, 
sim time next is 52200.0000, 
raw observation next is [20.5, 86.0, 1.0, 2.0, 0.4029044829407991, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8017857625152874, 6.911199999999999, 6.9112, 77.32846344354104, 915610.0519820467, 915610.0519820469, 215056.7600827875], 
processed observation next is [1.0, 0.6086956521739131, 0.5681818181818182, 0.86, 1.0, 1.0, 0.2536306036759989, 0.0, 1.0, -0.25, 1.0, 1.0, 0.716836803593268, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3391148340674247, 0.33911483406742476, 0.52452868312875], 
reward next is 0.4755, 
noisyNet noise sample is [array([-1.0487443], dtype=float32), -0.90278316]. 
=============================================
[2019-03-23 19:16:51,985] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.9747865e-05 6.4121807e-08 9.9995005e-01 4.5234749e-08 6.4520769e-08], sum to 1.0000
[2019-03-23 19:16:51,992] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9645
[2019-03-23 19:16:51,995] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [15.16666666666667, 76.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 241004.3765676401, 241004.3765676398, 97038.89701679433], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 168600.0000, 
sim time next is 169200.0000, 
raw observation next is [15.0, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 238886.4927088717, 238886.492708872, 96469.49990277694], 
processed observation next is [1.0, 1.0, 0.3181818181818182, 0.77, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08847647878106359, 0.08847647878106371, 0.2352914631775047], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.6455162], dtype=float32), -0.12794635]. 
=============================================
[2019-03-23 19:16:54,893] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.8407685e-05 3.4505525e-09 9.9997163e-01 1.2669740e-08 4.9297871e-10], sum to 1.0000
[2019-03-23 19:16:54,899] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5414
[2019-03-23 19:16:54,903] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.66666666666667, 75.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 280014.9157525974, 280014.9157525974, 118846.0766492737], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 206400.0000, 
sim time next is 207000.0000, 
raw observation next is [18.0, 75.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 287517.6630636335, 287517.6630636335, 123737.31866531], 
processed observation next is [0.0, 0.391304347826087, 0.45454545454545453, 0.75, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.10648802335690129, 0.10648802335690129, 0.30179833820807317], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9865587], dtype=float32), 1.4392687]. 
=============================================
[2019-03-23 19:16:54,920] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[3.078601 ]
 [3.1532123]
 [3.2440765]
 [3.4260352]
 [3.5482907]], R is [[2.98560476]
 [2.9557488 ]
 [2.92619133]
 [2.8969295 ]
 [2.86796021]].
[2019-03-23 19:16:59,275] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.8274884e-05 3.9772281e-08 9.9998164e-01 1.1062965e-07 2.5384978e-08], sum to 1.0000
[2019-03-23 19:16:59,285] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4447
[2019-03-23 19:16:59,291] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [12.0, 76.0, 1.0, 2.0, 0.2108372548245477, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3935869653715856, 6.9112, 6.9112, 77.32846344354104, 457938.4465256208, 457938.4465256208, 123326.0183409737], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 364800.0000, 
sim time next is 365400.0000, 
raw observation next is [12.0, 76.0, 1.0, 2.0, 0.2019321925746521, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3769631650365919, 6.911199999999999, 6.9112, 77.32846344354104, 438587.9300786806, 438587.9300786809, 121511.9952308887], 
processed observation next is [1.0, 0.21739130434782608, 0.18181818181818182, 0.76, 1.0, 1.0, 0.002415240718315094, 0.0, 1.0, -0.25, 1.0, 1.0, 0.10994737862370271, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16243997410321503, 0.16243997410321515, 0.29637072007533827], 
reward next is 0.7036, 
noisyNet noise sample is [array([-0.14840566], dtype=float32), -0.7506242]. 
=============================================
[2019-03-23 19:17:00,560] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.8470077e-04 4.9686457e-07 9.9981171e-01 2.4575654e-06 5.9709959e-07], sum to 1.0000
[2019-03-23 19:17:00,569] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6332
[2019-03-23 19:17:00,573] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.83333333333333, 64.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 321331.5560293314, 321331.5560293314, 117426.0260758168], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 407400.0000, 
sim time next is 408000.0000, 
raw observation next is [17.66666666666667, 65.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 277143.2149203471, 277143.2149203474, 108318.9967874148], 
processed observation next is [1.0, 0.7391304347826086, 0.4393939393939396, 0.6533333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1026456351556841, 0.10264563515568421, 0.2641926750912556], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.44519272], dtype=float32), 0.17198618]. 
=============================================
[2019-03-23 19:17:00,593] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[-0.1970623 ]
 [ 0.24588902]
 [ 0.28858083]
 [ 0.44752985]
 [ 0.6043769 ]], R is [[-0.49255687]
 [-0.48763129]
 [-0.48275498]
 [-0.47792742]
 [-0.47314814]].
[2019-03-23 19:17:01,240] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.0336083e-05 2.9380467e-07 9.9997926e-01 1.1543991e-07 2.3070859e-08], sum to 1.0000
[2019-03-23 19:17:01,252] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4951
[2019-03-23 19:17:01,256] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.0, 43.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 266689.4838761288, 266689.4838761285, 101911.2381818859], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 327600.0000, 
sim time next is 328200.0000, 
raw observation next is [19.66666666666667, 44.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 263639.8115714522, 263639.8115714525, 101206.5906055638], 
processed observation next is [0.0, 0.8260869565217391, 0.5303030303030305, 0.445, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09764437465609341, 0.0976443746560935, 0.24684534294039953], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.05456529], dtype=float32), 0.08756998]. 
=============================================
[2019-03-23 19:17:07,662] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.7588014e-03 8.0322632e-12 9.9724114e-01 1.5494624e-10 2.0965583e-10], sum to 1.0000
[2019-03-23 19:17:07,668] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0099
[2019-03-23 19:17:07,675] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.66666666666667, 92.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 254663.7316207033, 254663.7316207036, 104493.8227205237], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 544800.0000, 
sim time next is 545400.0000, 
raw observation next is [15.0, 91.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 259407.9792752028, 259407.9792752025, 106724.4930471689], 
processed observation next is [1.0, 0.30434782608695654, 0.3181818181818182, 0.91, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09607702936118621, 0.0960770293611861, 0.26030364157846075], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5077908], dtype=float32), 0.45553958]. 
=============================================
[2019-03-23 19:17:09,695] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4390615e-03 2.7319069e-10 9.9856097e-01 3.5802383e-10 1.0766965e-09], sum to 1.0000
[2019-03-23 19:17:09,702] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9798
[2019-03-23 19:17:09,705] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.2236530141498761, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4175111804064766, 6.911199999999999, 6.9112, 77.32846344354104, 485788.1788750521, 485788.1788750524, 138734.6248648404], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 475800.0000, 
sim time next is 476400.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3355917265697114, 6.911199999999999, 6.9112, 77.32846344354104, 390433.8912581481, 390433.8912581484, 129138.0608137609], 
processed observation next is [1.0, 0.5217391304347826, 0.2727272727272727, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.05084532367101634, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14460514491042523, 0.14460514491042534, 0.31497088003356316], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.2733805], dtype=float32), 0.63883346]. 
=============================================
[2019-03-23 19:17:09,997] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.9487910e-06 1.7328228e-08 9.9999309e-01 1.3302748e-08 2.9194753e-08], sum to 1.0000
[2019-03-23 19:17:10,001] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7591
[2019-03-23 19:17:10,004] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 302812.2768639579, 302812.2768639579, 121008.8788727374], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 496800.0000, 
sim time next is 497400.0000, 
raw observation next is [15.83333333333333, 89.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 300922.0992305602, 300922.0992305599, 120046.0631880667], 
processed observation next is [1.0, 0.782608695652174, 0.3560606060606059, 0.8900000000000001, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11145262934465192, 0.11145262934465182, 0.2927952760684554], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.47076055], dtype=float32), 0.61574364]. 
=============================================
[2019-03-23 19:17:12,453] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 19:17:12,455] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:17:12,456] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:17:12,458] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:17:12,458] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:17:12,465] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:17:12,466] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:17:12,466] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:17:12,466] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:17:12,467] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:17:12,469] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:17:12,484] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run61
[2019-03-23 19:17:12,510] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run61
[2019-03-23 19:17:12,535] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run61
[2019-03-23 19:17:12,560] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run61
[2019-03-23 19:17:12,561] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run61
[2019-03-23 19:17:34,899] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00688019], dtype=float32), 0.010165623]
[2019-03-23 19:17:34,900] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.01752022166666, 52.62167506, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 294626.8629114916, 294626.8629114916, 113696.7015023543]
[2019-03-23 19:17:34,901] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:17:34,905] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.5670513e-05 8.9973512e-10 9.9994433e-01 1.4937187e-09 7.8079443e-10], sampled 0.7531857691523026
[2019-03-23 19:17:46,535] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00688019], dtype=float32), 0.010165623]
[2019-03-23 19:17:46,537] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.65693931666667, 84.905140355, 1.0, 2.0, 0.4506907561600925, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8667063015995947, 6.973502805306362, 6.9112, 95.55310395361785, 1016761.934229131, 991758.3832145594, 249030.8804398523]
[2019-03-23 19:17:46,537] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:17:46,540] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.5980445e-04 3.8154573e-09 9.9974018e-01 2.1033545e-08 2.8601663e-08], sampled 0.9862999400095614
[2019-03-23 19:17:52,068] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00688019], dtype=float32), 0.010165623]
[2019-03-23 19:17:52,070] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.50347622, 50.89602306, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 327796.4537302096, 327796.4537302096, 145294.0811692396]
[2019-03-23 19:17:52,071] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:17:52,075] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0263444e-05 2.2787303e-09 9.9998975e-01 2.7826497e-09 5.6703364e-10], sampled 0.025168925585114077
[2019-03-23 19:17:53,472] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00688019], dtype=float32), 0.010165623]
[2019-03-23 19:17:53,474] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.63333333333333, 59.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3716423972344207, 6.9112, 6.9112, 95.55338769695034, 426681.5382165882, 426681.5382165882, 161584.1852672097]
[2019-03-23 19:17:53,476] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:17:53,480] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.8539023e-05 1.9193688e-10 9.9995148e-01 3.5240300e-10 2.1491485e-10], sampled 0.6250894433732285
[2019-03-23 19:18:15,893] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00688019], dtype=float32), 0.010165623]
[2019-03-23 19:18:15,894] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [14.01666666666667, 83.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 212348.2511433873, 212348.2511433869, 95161.35583076319]
[2019-03-23 19:18:15,896] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:18:15,898] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.3646105e-05 6.2320044e-10 9.9996638e-01 7.7872053e-10 2.9924135e-10], sampled 0.39460508513982195
[2019-03-23 19:18:36,071] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00688019], dtype=float32), 0.010165623]
[2019-03-23 19:18:36,072] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.03333333333333, 55.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 288391.3988137332, 288391.3988137335, 109592.5296518998]
[2019-03-23 19:18:36,072] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:18:36,075] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.2398646e-05 1.5280470e-08 9.9997759e-01 1.9120691e-08 4.2135380e-09], sampled 0.26985495598720355
[2019-03-23 19:18:39,223] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00688019], dtype=float32), 0.010165623]
[2019-03-23 19:18:39,226] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.3, 58.0, 1.0, 2.0, 0.2019989826357219, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3986357352159223, 6.911200000000001, 6.9112, 95.55338769695034, 456597.7020529396, 456597.7020529393, 165899.5107070481]
[2019-03-23 19:18:39,227] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:18:39,229] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.6025383e-05 5.8652877e-10 9.9996400e-01 1.1918809e-09 6.0549810e-10], sampled 0.507782053714252
[2019-03-23 19:18:54,361] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3518.9973 2103816966.5883 178.0000
[2019-03-23 19:18:54,508] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3359.2557 2097861616.8943 180.0000
[2019-03-23 19:18:54,525] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3118.1614 2108774501.4292 370.0000
[2019-03-23 19:18:54,682] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3612.9000 2175166714.4579 246.0000
[2019-03-23 19:18:54,802] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2757.8085 2123849937.7957 758.0000
[2019-03-23 19:18:55,819] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1500000, evaluation results [1500000.0, 3612.9000062185983, 2175166714.4579268, 246.0, 3359.2556548764082, 2097861616.894285, 180.0, 3518.997318266639, 2103816966.588303, 178.0, 2757.808477534794, 2123849937.795711, 758.0, 3118.1613939869867, 2108774501.429156, 370.0]
[2019-03-23 19:19:08,770] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.9997826e-03 4.6839832e-13 9.9100024e-01 2.4056703e-12 1.5234435e-11], sum to 1.0000
[2019-03-23 19:19:08,780] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8947
[2019-03-23 19:19:08,784] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.66666666666666, 70.33333333333334, 1.0, 2.0, 0.2188378048251186, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4385502721805396, 6.911200000000001, 6.9112, 77.32846344354104, 498692.1694187069, 498692.1694187066, 168068.6488438911], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 775200.0000, 
sim time next is 775800.0000, 
raw observation next is [23.5, 71.0, 1.0, 2.0, 0.2175427292416481, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4357209519797202, 6.911200000000001, 6.9112, 77.32846344354104, 495638.1752688276, 495638.1752688274, 167656.1496458203], 
processed observation next is [1.0, 1.0, 0.7045454545454546, 0.71, 1.0, 1.0, 0.02192841155206012, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1938870742567432, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18356969454401023, 0.18356969454401015, 0.40891743816053727], 
reward next is 0.5911, 
noisyNet noise sample is [array([0.43619734], dtype=float32), 1.7868193]. 
=============================================
[2019-03-23 19:19:15,287] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3690777e-02 4.7379584e-14 9.8630917e-01 1.3524898e-12 1.6105764e-11], sum to 1.0000
[2019-03-23 19:19:15,296] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4319
[2019-03-23 19:19:15,302] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.0, 74.0, 1.0, 2.0, 0.233506432465318, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4708325420207909, 6.9112, 6.9112, 77.32846344354104, 532894.9632400925, 532894.9632400925, 173283.8058017106], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 914400.0000, 
sim time next is 915000.0000, 
raw observation next is [23.66666666666667, 74.66666666666667, 1.0, 2.0, 0.2325083173941954, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4683794744170217, 6.911199999999999, 6.9112, 77.32846344354104, 530583.9271236982, 530583.9271236985, 172668.8251718522], 
processed observation next is [0.0, 0.6086956521739131, 0.7121212121212124, 0.7466666666666667, 1.0, 1.0, 0.040635396742744224, 0.0, 1.0, -0.25, 1.0, 1.0, 0.24054210631003106, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1965125656013697, 0.19651256560136982, 0.4211434760289078], 
reward next is 0.5789, 
noisyNet noise sample is [array([-2.7749164], dtype=float32), -0.69363314]. 
=============================================
[2019-03-23 19:19:15,314] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[54.381123]
 [54.75156 ]
 [54.23526 ]
 [53.431885]
 [53.510838]], R is [[55.0030365 ]
 [55.03036499]
 [55.05833435]
 [55.08695221]
 [55.1161499 ]].
[2019-03-23 19:19:35,762] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.3953368e-05 1.2747058e-10 9.9993598e-01 1.6311612e-09 2.0566864e-09], sum to 1.0000
[2019-03-23 19:19:35,769] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4440
[2019-03-23 19:19:35,777] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3541798795376802, 6.911199999999999, 6.9112, 77.32846344354104, 408176.8406723777, 408176.840672378, 153349.7405475416], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1292400.0000, 
sim time next is 1293000.0000, 
raw observation next is [18.0, 94.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3514818232009889, 6.911199999999999, 6.9112, 77.32846344354104, 405132.3000985034, 405132.3000985037, 152958.3126356958], 
processed observation next is [1.0, 1.0, 0.45454545454545453, 0.9400000000000002, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.07354546171569848, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15004900003648275, 0.15004900003648286, 0.3730690552090141], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.4313183], dtype=float32), -1.1050365]. 
=============================================
[2019-03-23 19:19:35,790] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[35.80572 ]
 [35.828674]
 [35.79107 ]
 [35.432957]
 [35.019146]], R is [[35.41682053]
 [35.06265259]
 [34.71202469]
 [34.36490631]
 [34.02125931]].
[2019-03-23 19:19:36,002] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.3719259e-03 8.2056605e-11 9.9762815e-01 3.8545242e-10 8.0067828e-09], sum to 1.0000
[2019-03-23 19:19:36,012] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2986
[2019-03-23 19:19:36,018] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.33333333333334, 47.33333333333334, 1.0, 2.0, 0.2176095611932156, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4062293777119891, 6.9112, 6.9112, 77.32846344354104, 472655.0440725543, 472655.0440725543, 149816.9217619733], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1862400.0000, 
sim time next is 1863000.0000, 
raw observation next is [22.5, 48.0, 1.0, 2.0, 0.2457157620677476, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4587281366527726, 6.9112, 6.9112, 77.32846344354104, 533736.1398290531, 533736.1398290531, 159102.304851721], 
processed observation next is [1.0, 0.5652173913043478, 0.6590909090909091, 0.48, 1.0, 1.0, 0.05714470258468447, 0.0, 1.0, -0.25, 1.0, 1.0, 0.22675448093253234, 0.0, 0.0, 0.5084288129206541, 0.19768005178853817, 0.19768005178853817, 0.3880544020773683], 
reward next is 0.6119, 
noisyNet noise sample is [array([-0.32128718], dtype=float32), -1.7120187]. 
=============================================
[2019-03-23 19:19:36,038] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[33.996952]
 [31.087515]
 [33.31364 ]
 [36.216125]
 [39.14898 ]], R is [[36.83850479]
 [37.10471344]
 [36.73366547]
 [36.36632919]
 [36.00266647]].
[2019-03-23 19:19:45,155] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.3949563e-02 1.2122002e-13 9.3605047e-01 1.0199271e-12 4.8393591e-11], sum to 1.0000
[2019-03-23 19:19:45,160] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4318
[2019-03-23 19:19:45,163] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.66666666666667, 100.0, 1.0, 2.0, 0.2286078585832311, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4610939503420642, 6.9112, 6.9112, 77.32846344354104, 521709.5799041325, 521709.5799041325, 172379.3388817565], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1489200.0000, 
sim time next is 1489800.0000, 
raw observation next is [20.83333333333333, 100.0, 1.0, 2.0, 0.2316940784228996, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4677527192494047, 6.9112, 6.9112, 77.32846344354104, 528715.7522405231, 528715.7522405231, 173475.5619057427], 
processed observation next is [0.0, 0.21739130434782608, 0.5833333333333331, 1.0, 1.0, 1.0, 0.03961759802862449, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2396467417848639, 0.0, 0.0, 0.5084288129206541, 0.19582064897797152, 0.19582064897797152, 0.42311112659937244], 
reward next is 0.5769, 
noisyNet noise sample is [array([-1.341867], dtype=float32), 0.013546092]. 
=============================================
[2019-03-23 19:19:45,206] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 19:19:45,208] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:19:45,210] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:19:45,211] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:19:45,211] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:19:45,212] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:19:45,213] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:19:45,214] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:19:45,215] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:19:45,214] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:19:45,219] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:19:45,243] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run62
[2019-03-23 19:19:45,268] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run62
[2019-03-23 19:19:45,268] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run62
[2019-03-23 19:19:45,270] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run62
[2019-03-23 19:19:45,340] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run62
[2019-03-23 19:20:03,467] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00640758], dtype=float32), 0.010637889]
[2019-03-23 19:20:03,469] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.45049886, 69.74853973833333, 1.0, 2.0, 0.2636890844570062, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5338294379132604, 6.9112, 6.9112, 95.55338769695034, 600629.030482422, 600629.030482422, 187577.9175315459]
[2019-03-23 19:20:03,470] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:20:03,472] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.4268430e-02 8.2594508e-14 9.7573155e-01 9.3635134e-12 1.2108375e-10], sampled 0.7702312243764523
[2019-03-23 19:20:57,494] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00640758], dtype=float32), 0.010637889]
[2019-03-23 19:20:57,496] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.1, 73.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3062206090146018, 6.911200000000001, 6.9112, 95.55338769695034, 353980.2108862676, 353980.2108862672, 151101.2231813425]
[2019-03-23 19:20:57,498] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:20:57,502] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.3134508e-03 4.1190068e-12 9.9568653e-01 6.5453004e-11 2.4108560e-10], sampled 0.2321740248885411
[2019-03-23 19:21:06,880] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00640758], dtype=float32), 0.010637889]
[2019-03-23 19:21:06,883] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.71666666666667, 71.0, 1.0, 2.0, 0.2304154742027628, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4623772789101708, 6.9112, 6.9112, 95.55338769695034, 525284.1607274794, 525284.1607274794, 175516.6804961333]
[2019-03-23 19:21:06,884] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:21:06,887] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.0860771e-02 1.5220308e-13 9.7913927e-01 8.7218279e-12 8.9230637e-11], sampled 0.32003892344972185
[2019-03-23 19:21:13,777] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00640758], dtype=float32), 0.010637889]
[2019-03-23 19:21:13,779] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.7, 44.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3948440856979895, 6.911200000000001, 6.9112, 95.55338769695034, 451190.7332410396, 451190.7332410392, 166482.7755593164]
[2019-03-23 19:21:13,780] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:21:13,782] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.0892794e-03 1.1603533e-12 9.9391067e-01 2.7110677e-11 1.3259856e-10], sampled 0.4302355494633838
[2019-03-23 19:21:26,955] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3443.3694 2098609930.5197 246.0000
[2019-03-23 19:21:26,986] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3268.0326 2092398761.3399 248.0000
[2019-03-23 19:21:27,141] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2710.8410 2119571844.7334 805.0000
[2019-03-23 19:21:27,142] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3553.2634 2170076612.6589 298.0000
[2019-03-23 19:21:27,395] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3064.6593 2103638270.8346 419.0000
[2019-03-23 19:21:28,414] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1525000, evaluation results [1525000.0, 3553.263381886736, 2170076612.658936, 298.0, 3268.0326167757103, 2092398761.339909, 248.0, 3443.3694490958023, 2098609930.519666, 246.0, 2710.840954878959, 2119571844.7334228, 805.0, 3064.659306239302, 2103638270.8345664, 419.0]
[2019-03-23 19:21:33,513] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.9164973e-03 3.2594344e-12 9.9608350e-01 4.8120491e-10 6.4284253e-09], sum to 1.0000
[2019-03-23 19:21:33,519] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6358
[2019-03-23 19:21:33,527] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.16666666666667, 94.00000000000001, 1.0, 2.0, 0.2307076653480701, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4647472862365152, 6.9112, 6.9112, 77.32846344354104, 526472.0225354659, 526472.0225354659, 172284.7060713753], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1581000.0000, 
sim time next is 1581600.0000, 
raw observation next is [21.33333333333334, 94.0, 1.0, 2.0, 0.2266394624600826, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4570274828181425, 6.911200000000001, 6.9112, 77.32846344354104, 517215.7511714012, 517215.7511714009, 171873.7636759174], 
processed observation next is [1.0, 0.30434782608695654, 0.6060606060606063, 0.94, 1.0, 1.0, 0.03329932807510323, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2243249754544893, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19156138932274117, 0.19156138932274108, 0.419204301648579], 
reward next is 0.5808, 
noisyNet noise sample is [array([0.2810621], dtype=float32), -0.42947146]. 
=============================================
[2019-03-23 19:21:33,529] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.5631709e-02 1.6473543e-10 9.6436834e-01 2.2690723e-09 2.2903317e-08], sum to 1.0000
[2019-03-23 19:21:33,538] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6211
[2019-03-23 19:21:33,548] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3490518176370765, 6.9112, 6.9112, 77.32846344354104, 401275.7230454521, 401275.7230454521, 153653.5992499065], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1664400.0000, 
sim time next is 1665000.0000, 
raw observation next is [19.0, 91.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3509774359398877, 6.9112, 6.9112, 77.32846344354104, 403242.8299959054, 403242.8299959054, 154119.4400833763], 
processed observation next is [1.0, 0.2608695652173913, 0.5, 0.91, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.07282490848555391, 0.0, 0.0, 0.5084288129206541, 0.14934919629477977, 0.14934919629477977, 0.37590107337408857], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4669192], dtype=float32), -1.1984192]. 
=============================================
[2019-03-23 19:21:33,561] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[40.985374]
 [40.995518]
 [40.823154]
 [40.63422 ]
 [40.57173 ]], R is [[40.66637039]
 [40.2597084 ]
 [39.85711288]
 [39.45854187]
 [39.06395721]].
[2019-03-23 19:21:56,457] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1053408e-04 4.1587350e-10 9.9978954e-01 1.4814052e-08 8.6147613e-09], sum to 1.0000
[2019-03-23 19:21:56,463] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2317
[2019-03-23 19:21:56,468] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.33333333333334, 71.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 297654.5276169069, 297654.5276169066, 123603.0634493406], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2017200.0000, 
sim time next is 2017800.0000, 
raw observation next is [18.5, 70.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 300139.7425020227, 300139.742502023, 124827.9778185347], 
processed observation next is [0.0, 0.34782608695652173, 0.4772727272727273, 0.705, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11116286759334175, 0.11116286759334185, 0.30445848248423096], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.09439627], dtype=float32), -0.73723716]. 
=============================================
[2019-03-23 19:21:56,817] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.61693778e-05 8.51798454e-09 9.99943852e-01 1.24482495e-08
 5.37659250e-09], sum to 1.0000
[2019-03-23 19:21:56,823] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6059
[2019-03-23 19:21:56,828] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.33333333333333, 75.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 249655.6033732582, 249655.6033732582, 102463.6074036322], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2007600.0000, 
sim time next is 2008200.0000, 
raw observation next is [16.16666666666667, 76.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 247601.6056257341, 247601.6056257338, 101767.6901453387], 
processed observation next is [0.0, 0.21739130434782608, 0.37121212121212144, 0.7616666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09170429837990152, 0.0917042983799014, 0.24821387840326511], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.64052236], dtype=float32), -1.2534499]. 
=============================================
[2019-03-23 19:22:01,090] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.8229561e-05 2.4706779e-09 9.9992180e-01 5.6153242e-09 5.9364904e-08], sum to 1.0000
[2019-03-23 19:22:01,095] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4373
[2019-03-23 19:22:01,104] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [15.66666666666667, 79.83333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 244138.6986297634, 244138.6986297634, 100771.9466871647], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2098200.0000, 
sim time next is 2098800.0000, 
raw observation next is [16.0, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 243125.3953650302, 243125.3953650302, 100587.7301360187], 
processed observation next is [0.0, 0.30434782608695654, 0.36363636363636365, 0.77, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.09004644272778897, 0.09004644272778897, 0.2453359271610212], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.58628434], dtype=float32), -0.906351]. 
=============================================
[2019-03-23 19:22:02,270] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6027293e-04 4.4008902e-07 9.9983871e-01 3.6387021e-07 6.2056671e-08], sum to 1.0000
[2019-03-23 19:22:02,279] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9595
[2019-03-23 19:22:02,288] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.5, 48.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3813391176838066, 6.9112, 6.9112, 77.32846344354104, 436388.4311690807, 436388.4311690807, 159512.5216559483], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2125800.0000, 
sim time next is 2126400.0000, 
raw observation next is [26.66666666666667, 47.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.38012914472495, 6.9112, 6.9112, 77.32846344354104, 435102.3425396877, 435102.3425396877, 159266.3806777145], 
processed observation next is [0.0, 0.6086956521739131, 0.8484848484848487, 0.47, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.11447020674992862, 0.0, 0.0, 0.5084288129206541, 0.16114901575543988, 0.16114901575543988, 0.38845458701881586], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6396532], dtype=float32), -0.2667231]. 
=============================================
[2019-03-23 19:22:05,844] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7579470e-03 1.4615193e-09 9.9824178e-01 3.9631963e-08 2.4138055e-07], sum to 1.0000
[2019-03-23 19:22:05,850] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9778
[2019-03-23 19:22:05,854] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 77.0, 1.0, 2.0, 0.253311763356269, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4729331681946424, 6.9112, 6.9112, 77.32846344354104, 550245.2765279933, 550245.2765279933, 160420.4221828476], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2196000.0000, 
sim time next is 2196600.0000, 
raw observation next is [18.16666666666667, 76.33333333333334, 1.0, 2.0, 0.2674146554332862, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4994375188834552, 6.911200000000001, 6.9112, 77.32846344354104, 580897.9659782234, 580897.965978223, 163039.3053124658], 
processed observation next is [1.0, 0.43478260869565216, 0.4621212121212123, 0.7633333333333334, 1.0, 1.0, 0.08426831929160772, 0.0, 1.0, -0.25, 1.0, 1.0, 0.28491074126207894, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21514739480674938, 0.21514739480674927, 0.39765684222552633], 
reward next is 0.6023, 
noisyNet noise sample is [array([0.47996616], dtype=float32), 0.16014545]. 
=============================================
[2019-03-23 19:22:07,689] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.9154385e-04 3.4457020e-07 9.9950528e-01 2.3674975e-06 4.1785984e-07], sum to 1.0000
[2019-03-23 19:22:07,696] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5257
[2019-03-23 19:22:07,701] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.33333333333333, 81.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3806500942545918, 6.911200000000001, 6.9112, 77.32846344354104, 436880.5888211131, 436880.5888211128, 158295.2336914346], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2230800.0000, 
sim time next is 2231400.0000, 
raw observation next is [20.16666666666667, 82.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3783138780305842, 6.9112, 6.9112, 77.32846344354104, 434329.1635730913, 434329.1635730913, 157874.7241797664], 
processed observation next is [1.0, 0.8260869565217391, 0.5530303030303032, 0.8216666666666668, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1118769686151203, 0.0, 0.0, 0.5084288129206541, 0.160862653175219, 0.160862653175219, 0.38506030287747905], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.98111695], dtype=float32), 2.1507652]. 
=============================================
[2019-03-23 19:22:08,866] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.9025452e-04 4.9858187e-07 9.9980682e-01 1.1521562e-06 1.3273320e-06], sum to 1.0000
[2019-03-23 19:22:08,875] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6051
[2019-03-23 19:22:08,883] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.66666666666667, 78.66666666666666, 1.0, 2.0, 0.2362682588898447, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4410610786384374, 6.911199999999999, 6.9112, 77.32846344354104, 513203.7342950111, 513203.7342950114, 155504.6770737869], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2464800.0000, 
sim time next is 2465400.0000, 
raw observation next is [17.83333333333333, 77.83333333333334, 1.0, 2.0, 0.21456148246031, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4005392824786, 6.911200000000001, 6.9112, 77.32846344354104, 466031.3447116595, 466031.3447116592, 151980.6615312601], 
processed observation next is [1.0, 0.5217391304347826, 0.44696969696969674, 0.7783333333333334, 1.0, 1.0, 0.0182018530753875, 0.0, 1.0, -0.25, 1.0, 1.0, 0.14362754639800002, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17260420174505905, 0.17260420174505894, 0.3706845403201466], 
reward next is 0.6293, 
noisyNet noise sample is [array([-0.35065326], dtype=float32), 0.28825286]. 
=============================================
[2019-03-23 19:22:11,087] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.4535652e-04 2.9759885e-06 9.9973804e-01 1.1798404e-05 1.7632518e-06], sum to 1.0000
[2019-03-23 19:22:11,095] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2187
[2019-03-23 19:22:11,100] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.0, 49.0, 1.0, 2.0, 0.2067356254689882, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3859301219333749, 6.9112, 6.9112, 77.32846344354104, 449025.594929533, 449025.594929533, 132835.1651881709], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2293800.0000, 
sim time next is 2294400.0000, 
raw observation next is [20.0, 49.0, 1.0, 2.0, 0.2325035165859453, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4340331295218032, 6.9112, 6.9112, 77.32846344354104, 505022.002964083, 505022.002964083, 137933.1855215635], 
processed observation next is [1.0, 0.5652173913043478, 0.5454545454545454, 0.49, 1.0, 1.0, 0.04062939573243163, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1914758993168617, 0.0, 0.0, 0.5084288129206541, 0.1870451862829937, 0.1870451862829937, 0.33642240371113047], 
reward next is 0.6636, 
noisyNet noise sample is [array([-0.75178516], dtype=float32), -1.4992136]. 
=============================================
[2019-03-23 19:22:11,608] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2876267e-04 6.6995329e-07 9.9986541e-01 3.5095140e-06 1.6371280e-06], sum to 1.0000
[2019-03-23 19:22:11,615] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8612
[2019-03-23 19:22:11,621] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.66666666666667, 49.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.331058432613898, 6.9112, 6.9112, 77.32846344354104, 385157.6807249016, 385157.6807249016, 124212.7572033123], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2292600.0000, 
sim time next is 2293200.0000, 
raw observation next is [20.0, 49.0, 1.0, 2.0, 0.206409646425043, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3853215904725195, 6.911199999999999, 6.9112, 77.32846344354104, 448317.2486012555, 448317.2486012558, 132460.4912495655], 
processed observation next is [1.0, 0.5652173913043478, 0.5454545454545454, 0.49, 1.0, 1.0, 0.00801205803130374, 0.0, 1.0, -0.25, 1.0, 1.0, 0.12188798638931361, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1660434254078724, 0.16604342540787254, 0.32307436890137925], 
reward next is 0.6769, 
noisyNet noise sample is [array([-0.17264624], dtype=float32), 1.965723]. 
=============================================
[2019-03-23 19:22:12,510] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.5079252e-04 5.4000957e-05 9.9939907e-01 8.3828207e-05 1.2286177e-05], sum to 1.0000
[2019-03-23 19:22:12,511] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7406
[2019-03-23 19:22:12,522] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.0, 53.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 252317.4392530376, 252317.4392530376, 96607.77181230114], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2328000.0000, 
sim time next is 2328600.0000, 
raw observation next is [17.0, 52.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 252455.3536196688, 252455.3536196691, 96512.51497680228], 
processed observation next is [1.0, 0.9565217391304348, 0.4090909090909091, 0.525, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09350198282209955, 0.09350198282209966, 0.2353963779922007], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0505912], dtype=float32), -0.042275652]. 
=============================================
[2019-03-23 19:22:17,703] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 19:22:17,705] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:22:17,705] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:22:17,706] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:22:17,706] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:22:17,706] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:22:17,707] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:22:17,707] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:22:17,708] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:22:17,707] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:22:17,711] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:22:17,730] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run63
[2019-03-23 19:22:17,758] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run63
[2019-03-23 19:22:17,783] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run63
[2019-03-23 19:22:17,783] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run63
[2019-03-23 19:22:17,829] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run63
[2019-03-23 19:22:46,048] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00660346], dtype=float32), 0.010530063]
[2019-03-23 19:22:46,049] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.3, 80.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3511461122332777, 6.911200000000001, 6.9112, 95.55338769695034, 405247.7676934951, 405247.7676934948, 157002.0258701286]
[2019-03-23 19:22:46,051] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:22:46,053] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.5913032e-04 2.5980347e-09 9.9974090e-01 2.0540321e-08 2.8958045e-08], sampled 0.700036112378494
[2019-03-23 19:22:59,996] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00660346], dtype=float32), 0.010530063]
[2019-03-23 19:22:59,998] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.6, 84.5, 1.0, 2.0, 0.3924270684469052, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7947886334288614, 6.9112, 6.9112, 95.55338769695034, 893117.1419698239, 893117.1419698239, 228439.2475549075]
[2019-03-23 19:23:00,002] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:23:00,005] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.3234325e-03 1.6578383e-09 9.9867648e-01 3.4873050e-08 1.0565466e-07], sampled 0.38947562333583285
[2019-03-23 19:23:05,191] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00660346], dtype=float32), 0.010530063]
[2019-03-23 19:23:05,193] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.108412225, 75.07697999, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 95.55338769695034, 297435.45501934, 297435.4550193404, 131876.7854603816]
[2019-03-23 19:23:05,195] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:23:05,197] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.1655683e-04 9.2904653e-09 9.9978334e-01 5.2641500e-08 5.4312416e-08], sampled 0.9985796618151226
[2019-03-23 19:23:17,020] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00660346], dtype=float32), 0.010530063]
[2019-03-23 19:23:17,022] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.8, 87.0, 1.0, 2.0, 0.2345504352218151, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4548549325246783, 6.9112, 6.9112, 95.55338769695034, 524023.6946335539, 524023.6946335539, 168329.8366439052]
[2019-03-23 19:23:17,023] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:23:17,025] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.1101034e-03 1.2218347e-10 9.9888986e-01 2.3682574e-09 9.6226582e-09], sampled 0.27586915200180717
[2019-03-23 19:23:20,627] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00660346], dtype=float32), 0.010530063]
[2019-03-23 19:23:20,629] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 78.0, 1.0, 2.0, 0.2088042055918838, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4162625726992596, 6.9112, 6.9112, 77.32846344354104, 474726.1753925642, 474726.1753925642, 164737.8076392733]
[2019-03-23 19:23:20,629] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:23:20,633] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.8942511e-04 6.4547934e-10 9.9901056e-01 8.8894154e-09 2.5793764e-08], sampled 0.04081815858700999
[2019-03-23 19:23:58,087] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2758.6958 2123798803.2919 759.0000
[2019-03-23 19:23:58,550] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3120.1138 2108664596.5598 373.0000
[2019-03-23 19:23:58,625] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3517.6767 2103745946.9019 183.0000
[2019-03-23 19:23:58,711] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3358.7267 2097812945.9112 182.0000
[2019-03-23 19:23:58,793] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3607.0371 2174712560.0543 250.0000
[2019-03-23 19:23:59,809] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1550000, evaluation results [1550000.0, 3607.0370636632542, 2174712560.054307, 250.0, 3358.726730295903, 2097812945.9111779, 182.0, 3517.67666677738, 2103745946.9018745, 183.0, 2758.6957646347037, 2123798803.291947, 759.0, 3120.113835724727, 2108664596.5598257, 373.0]
[2019-03-23 19:24:00,928] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2352024e-04 9.5444157e-08 9.9987590e-01 3.1998326e-07 1.9763820e-07], sum to 1.0000
[2019-03-23 19:24:00,935] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8869
[2019-03-23 19:24:00,939] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 241047.476385838, 241047.476385838, 99535.23762221713], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2432400.0000, 
sim time next is 2433000.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 241775.3902657131, 241775.3902657128, 99673.17779773254], 
processed observation next is [1.0, 0.13043478260869565, 0.2727272727272727, 0.94, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.089546440839153, 0.08954644083915289, 0.24310531170178667], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3022755], dtype=float32), -1.4893987]. 
=============================================
[2019-03-23 19:24:00,953] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[7.144735 ]
 [6.998589 ]
 [6.8662767]
 [6.734687 ]
 [6.8037825]], R is [[7.17351055]
 [7.10177565]
 [7.0307579 ]
 [6.96045017]
 [6.89084578]].
[2019-03-23 19:24:03,184] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.4850186e-04 4.5475718e-07 9.9974638e-01 1.5924501e-06 3.1198854e-06], sum to 1.0000
[2019-03-23 19:24:03,190] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0106
[2019-03-23 19:24:03,195] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.66666666666667, 82.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 327825.2065260095, 327825.2065260092, 140771.5182966938], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2482800.0000, 
sim time next is 2483400.0000, 
raw observation next is [16.83333333333333, 88.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 327310.4574549129, 327310.4574549129, 140279.9007508751], 
processed observation next is [1.0, 0.7391304347826086, 0.4015151515151513, 0.8833333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.12122609535367145, 0.12122609535367145, 0.3421460993923783], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.2898213], dtype=float32), 1.4264157]. 
=============================================
[2019-03-23 19:24:07,172] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4502890e-03 1.0882847e-09 9.9754936e-01 9.3041457e-08 2.0001639e-07], sum to 1.0000
[2019-03-23 19:24:07,179] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0282
[2019-03-23 19:24:07,183] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.33333333333333, 68.33333333333333, 1.0, 2.0, 0.2853567931365305, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5333078388963365, 6.9112, 6.9112, 77.32846344354104, 619898.0647317544, 619898.0647317544, 166642.973728766], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2547600.0000, 
sim time next is 2548200.0000, 
raw observation next is [19.66666666666667, 66.16666666666667, 1.0, 2.0, 0.2878493756801908, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5381022758187448, 6.9112, 6.9112, 77.32846344354104, 625393.6088415553, 625393.6088415553, 167191.3003902263], 
processed observation next is [1.0, 0.4782608695652174, 0.5303030303030305, 0.6616666666666667, 1.0, 1.0, 0.1098117196002385, 0.0, 1.0, -0.25, 1.0, 1.0, 0.34014610831249265, 0.0, 0.0, 0.5084288129206541, 0.23162726253390936, 0.23162726253390936, 0.4077836594883568], 
reward next is 0.5922, 
noisyNet noise sample is [array([-0.7214577], dtype=float32), -0.46761575]. 
=============================================
[2019-03-23 19:24:11,379] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.3211436e-05 1.8678982e-08 9.9996674e-01 3.7443588e-08 7.1027628e-09], sum to 1.0000
[2019-03-23 19:24:11,389] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8968
[2019-03-23 19:24:11,394] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 42.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3490065975261922, 6.911199999999999, 6.9112, 77.32846344354104, 400914.4232849595, 400914.4232849598, 153933.4419903742], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2639400.0000, 
sim time next is 2640000.0000, 
raw observation next is [27.0, 42.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3494816125870545, 6.9112, 6.9112, 77.32846344354104, 401450.3368464043, 401450.3368464043, 154001.3995114428], 
processed observation next is [0.0, 0.5652173913043478, 0.8636363636363636, 0.42, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.07068801798150647, 0.0, 0.0, 0.5084288129206541, 0.14868530994311271, 0.14868530994311271, 0.37561316954010443], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.16132681], dtype=float32), 0.11939089]. 
=============================================
[2019-03-23 19:24:11,415] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[9.412823]
 [9.15733 ]
 [9.008496]
 [8.92198 ]
 [8.883156]], R is [[9.48879719]
 [9.39390945]
 [9.29997063]
 [9.20697117]
 [9.11490154]].
[2019-03-23 19:24:18,819] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.7264434e-04 7.0994028e-09 9.9962711e-01 2.1761943e-07 1.9400185e-08], sum to 1.0000
[2019-03-23 19:24:18,825] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3789
[2019-03-23 19:24:18,830] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.83333333333334, 78.83333333333333, 1.0, 2.0, 0.2284894011661835, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4594440598641543, 6.9112, 6.9112, 77.32846344354104, 521242.2063967424, 521242.2063967424, 171124.1749948272], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2851800.0000, 
sim time next is 2852400.0000, 
raw observation next is [22.66666666666667, 79.66666666666667, 1.0, 2.0, 0.2269422290359479, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4561622294681036, 6.911199999999999, 6.9112, 77.32846344354104, 517663.9536168706, 517663.9536168709, 170671.8746833823], 
processed observation next is [1.0, 0.0, 0.6666666666666669, 0.7966666666666667, 1.0, 1.0, 0.03367778629493487, 0.0, 1.0, -0.25, 1.0, 1.0, 0.22308889924014802, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1917273902284706, 0.1917273902284707, 0.41627286508142025], 
reward next is 0.5837, 
noisyNet noise sample is [array([-0.36349332], dtype=float32), -1.7243977]. 
=============================================
[2019-03-23 19:24:23,479] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.2802358e-02 1.1462564e-10 9.4719768e-01 1.6346503e-09 3.1067819e-09], sum to 1.0000
[2019-03-23 19:24:23,489] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7794
[2019-03-23 19:24:23,495] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.33333333333334, 86.33333333333334, 1.0, 2.0, 0.2595427207568896, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5201513458099809, 6.9112, 6.9112, 77.32846344354104, 591519.8802593278, 591519.8802593278, 176726.4733027194], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2864400.0000, 
sim time next is 2865000.0000, 
raw observation next is [21.16666666666666, 87.16666666666667, 1.0, 2.0, 0.2419701926048803, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4845656344395008, 6.911199999999999, 6.9112, 77.32846344354104, 551287.7203528241, 551287.7203528243, 172575.9602227002], 
processed observation next is [1.0, 0.13043478260869565, 0.5984848484848482, 0.8716666666666667, 1.0, 1.0, 0.05246274075610038, 0.0, 1.0, -0.25, 1.0, 1.0, 0.26366519205642974, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20418063716771262, 0.2041806371677127, 0.42091697615292734], 
reward next is 0.5791, 
noisyNet noise sample is [array([0.16845055], dtype=float32), -0.9220903]. 
=============================================
[2019-03-23 19:24:23,519] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[49.22925]
 [49.43051]
 [49.63177]
 [50.04259]
 [50.67197]], R is [[50.34809494]
 [50.41357422]
 [50.46500778]
 [50.52556229]
 [50.57405472]].
[2019-03-23 19:24:23,888] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.7026185e-03 2.5910472e-11 9.9429744e-01 8.0345748e-09 4.0477799e-10], sum to 1.0000
[2019-03-23 19:24:23,895] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2054
[2019-03-23 19:24:23,903] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.2635771971834168, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5292717103905179, 6.911199999999999, 6.9112, 77.32846344354104, 601116.0068250684, 601116.0068250686, 178371.372559386], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2860200.0000, 
sim time next is 2860800.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.2532445279519618, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5083697968669845, 6.9112, 6.9112, 77.32846344354104, 577484.0710144525, 577484.0710144525, 175874.7964058671], 
processed observation next is [1.0, 0.08695652173913043, 0.6363636363636364, 0.83, 1.0, 1.0, 0.06655565993995222, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2976711383814064, 0.0, 0.0, 0.5084288129206541, 0.21388298926461202, 0.21388298926461202, 0.42896291806309045], 
reward next is 0.5710, 
noisyNet noise sample is [array([0.32120392], dtype=float32), 1.1137407]. 
=============================================
[2019-03-23 19:24:26,900] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.1946400e-03 2.9634754e-12 9.9380541e-01 1.3640402e-09 4.3596639e-08], sum to 1.0000
[2019-03-23 19:24:26,905] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2048
[2019-03-23 19:24:26,914] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 97.0, 1.0, 2.0, 0.2602408462282653, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5269406461323954, 6.9112, 6.9112, 77.32846344354104, 592630.4927421316, 592630.4927421316, 182199.3286686413], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2928600.0000, 
sim time next is 2929200.0000, 
raw observation next is [22.0, 98.0, 1.0, 2.0, 0.2624878783917532, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5315943373196853, 6.911200000000001, 6.9112, 77.32846344354104, 597424.4238375918, 597424.4238375915, 183055.6491022937], 
processed observation next is [1.0, 0.9130434782608695, 0.6363636363636364, 0.98, 1.0, 1.0, 0.07810984798969148, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3308490533138362, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22126830512503398, 0.2212683051250339, 0.44647719293242366], 
reward next is 0.5535, 
noisyNet noise sample is [array([1.967132], dtype=float32), 1.982235]. 
=============================================
[2019-03-23 19:24:40,865] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.9829663e-04 2.8845577e-09 9.9960178e-01 2.2983229e-09 2.2389724e-08], sum to 1.0000
[2019-03-23 19:24:40,874] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1173
[2019-03-23 19:24:40,878] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3171029390956247, 6.9112, 6.9112, 77.32846344354104, 366848.4370799233, 366848.4370799233, 147530.878323375], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3217200.0000, 
sim time next is 3217800.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3163716089608331, 6.9112, 6.9112, 77.32846344354104, 366003.6382282531, 366003.6382282531, 147446.9566501563], 
processed observation next is [0.0, 0.21739130434782608, 0.45454545454545453, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.02338801280119017, 0.0, 0.0, 0.5084288129206541, 0.13555690304750115, 0.13555690304750115, 0.35962672353696656], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.76591325], dtype=float32), 0.65672916]. 
=============================================
[2019-03-23 19:24:49,041] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 19:24:49,042] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:24:49,043] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:24:49,045] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:24:49,044] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:24:49,052] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:24:49,051] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:24:49,049] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:24:49,052] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:24:49,058] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:24:49,053] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:24:49,076] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run64
[2019-03-23 19:24:49,100] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run64
[2019-03-23 19:24:49,102] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run64
[2019-03-23 19:24:49,126] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run64
[2019-03-23 19:24:49,185] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run64
[2019-03-23 19:25:03,926] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00614106], dtype=float32), 0.011138713]
[2019-03-23 19:25:03,928] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.75, 78.0, 1.0, 2.0, 0.2378010751521752, 0.0, 2.0, 0.0, 1.0, 2.0, 0.480259271385616, 6.9112, 6.9112, 95.55338769695034, 542563.5235732263, 542563.5235732263, 179692.5755342818]
[2019-03-23 19:25:03,930] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:25:03,932] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0580741e-02 4.8767948e-11 9.8941922e-01 1.1591149e-09 2.1330218e-08], sampled 0.8318329877736617
[2019-03-23 19:25:11,581] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00614106], dtype=float32), 0.011138713]
[2019-03-23 19:25:11,583] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.34616140666667, 99.78317604833335, 1.0, 2.0, 0.255212028088193, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5136029130608217, 6.911199999999999, 6.9112, 95.55338769695034, 582273.409859027, 582273.4098590274, 182042.2030826197]
[2019-03-23 19:25:11,583] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:25:11,586] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.8944802e-03 1.2188124e-10 9.9610549e-01 1.7826206e-09 2.0019971e-08], sampled 0.08159142316067969
[2019-03-23 19:25:29,597] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00614106], dtype=float32), 0.011138713]
[2019-03-23 19:25:29,598] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.26666666666667, 81.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 276185.5600695416, 276185.5600695416, 115896.3304228435]
[2019-03-23 19:25:29,599] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:25:29,604] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.1596390e-05 4.7222606e-08 9.9990833e-01 8.3637325e-08 4.0975475e-08], sampled 0.21312295912339196
[2019-03-23 19:25:48,465] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00614106], dtype=float32), 0.011138713]
[2019-03-23 19:25:48,468] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.55373270166666, 90.66848794999999, 1.0, 2.0, 0.2275456261067786, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4360472971085538, 6.911200000000001, 6.9112, 95.55338769695034, 503934.1222717909, 503934.1222717905, 164968.6218391895]
[2019-03-23 19:25:48,470] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:25:48,475] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.6393661e-03 1.9581428e-10 9.9736065e-01 2.5047431e-09 2.2252815e-08], sampled 0.6986311531232003
[2019-03-23 19:25:51,127] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00614106], dtype=float32), 0.011138713]
[2019-03-23 19:25:51,128] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.55, 82.33333333333333, 1.0, 2.0, 0.2517825935116592, 0.0, 2.0, 0.0, 1.0, 2.0, 0.506980493191752, 6.911200000000001, 6.9112, 95.55338769695034, 574496.8502159613, 574496.850215961, 181473.4450332041]
[2019-03-23 19:25:51,129] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:25:51,134] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.3945235e-03 2.8728268e-11 9.9160540e-01 6.8702566e-10 1.2914925e-08], sampled 0.7251750999971044
[2019-03-23 19:26:30,893] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2744.3518 2122117059.4305 754.0000
[2019-03-23 19:26:31,117] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3104.0560 2106830636.2582 370.0000
[2019-03-23 19:26:31,173] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3493.3111 2101723348.7428 185.0000
[2019-03-23 19:26:31,354] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3323.6360 2094999103.0301 182.0000
[2019-03-23 19:26:31,377] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3583.8588 2172259257.8328 246.0000
[2019-03-23 19:26:32,394] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1575000, evaluation results [1575000.0, 3583.8587897475327, 2172259257.8328004, 246.0, 3323.6359691345774, 2094999103.03011, 182.0, 3493.3111391948346, 2101723348.7428205, 185.0, 2744.351830765173, 2122117059.4304717, 754.0, 3104.055984225634, 2106830636.2581677, 370.0]
[2019-03-23 19:26:33,380] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.0621368e-03 1.8935333e-09 9.9793684e-01 1.9518572e-08 1.1166453e-06], sum to 1.0000
[2019-03-23 19:26:33,388] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2922
[2019-03-23 19:26:33,394] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3549335036079103, 6.9112, 6.9112, 77.32846344354104, 410498.9397689569, 410498.9397689569, 152043.5774826427], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3378000.0000, 
sim time next is 3378600.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3212514904572544, 6.9112, 6.9112, 77.32846344354104, 371598.6419391138, 371598.6419391138, 148051.0024006862], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.03035927208179198, 0.0, 0.0, 0.5084288129206541, 0.13762912664411622, 0.13762912664411622, 0.3611000058553322], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.2706577], dtype=float32), 0.62186813]. 
=============================================
[2019-03-23 19:26:35,727] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.3079123e-01 2.9036146e-10 6.6920865e-01 1.3364865e-08 1.2954233e-07], sum to 1.0000
[2019-03-23 19:26:35,735] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6110
[2019-03-23 19:26:35,744] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.16666666666667, 89.0, 1.0, 2.0, 0.268746483849876, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5443416887322463, 6.9112, 6.9112, 77.32846344354104, 611324.7907807819, 611324.7907807819, 184918.1129196216], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3444600.0000, 
sim time next is 3445200.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.2652088909775741, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5370673160627907, 6.911199999999999, 6.9112, 77.32846344354104, 603755.4980429822, 603755.4980429824, 183617.2819812136], 
processed observation next is [1.0, 0.9130434782608695, 0.6818181818181818, 0.89, 1.0, 1.0, 0.08151111372196762, 0.0, 1.0, -0.25, 1.0, 1.0, 0.33866759437541527, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22361314742332675, 0.22361314742332683, 0.4478470292224722], 
reward next is 0.5522, 
noisyNet noise sample is [array([0.36769545], dtype=float32), -1.6330024]. 
=============================================
[2019-03-23 19:26:36,607] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.7057282e-03 2.8303965e-11 9.9429423e-01 4.6064144e-09 1.6009174e-08], sum to 1.0000
[2019-03-23 19:26:36,616] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7689
[2019-03-23 19:26:36,624] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.2460778057580854, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4973196260963186, 6.9112, 6.9112, 77.32846344354104, 561397.7327374378, 561397.7327374378, 177249.8239548871], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3650400.0000, 
sim time next is 3651000.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.3035290851243276, 0.0, 2.0, 0.0, 1.0, 2.0, 0.613525255444635, 6.911199999999999, 6.9112, 77.32846344354104, 692512.2736871514, 692512.2736871516, 191998.840710399], 
processed observation next is [1.0, 0.2608695652173913, 0.5909090909090909, 1.0, 1.0, 1.0, 0.12941135640540946, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4478932220637643, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2564860272915375, 0.25648602729153763, 0.4682898553912171], 
reward next is 0.5317, 
noisyNet noise sample is [array([0.22271849], dtype=float32), -0.03127106]. 
=============================================
[2019-03-23 19:26:36,641] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[46.361446]
 [46.37572 ]
 [45.426296]
 [46.666016]
 [47.21003 ]], R is [[45.29688263]
 [45.41159821]
 [45.52190399]
 [45.6301651 ]
 [45.73568344]].
[2019-03-23 19:26:38,244] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.7090776e-02 2.8439464e-09 9.5290875e-01 1.4418887e-08 4.9683860e-07], sum to 1.0000
[2019-03-23 19:26:38,251] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5791
[2019-03-23 19:26:38,255] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.5, 56.5, 1.0, 2.0, 0.9128765571052528, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9779417245351552, 6.911200000000001, 6.9112, 77.32846344354104, 1585259.94240751, 1585259.942407509, 328465.8439425032], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3681000.0000, 
sim time next is 3681600.0000, 
raw observation next is [28.66666666666666, 56.0, 1.0, 2.0, 0.93717300075398, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9783262001575709, 6.9112, 6.9112, 77.32846344354104, 1612431.694234527, 1612431.694234527, 333411.5755896484], 
processed observation next is [1.0, 0.6086956521739131, 0.9393939393939391, 0.56, 1.0, 1.0, 0.921466250942475, 0.0, 1.0, -0.25, 1.0, 1.0, 0.96903742879653, 0.0, 0.0, 0.5084288129206541, 0.5971969237905655, 0.5971969237905655, 0.813198964852801], 
reward next is 0.1868, 
noisyNet noise sample is [array([0.79215205], dtype=float32), -0.40172166]. 
=============================================
[2019-03-23 19:26:38,334] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.6723307e-03 2.9224815e-12 9.9332762e-01 9.4347370e-11 8.0967698e-11], sum to 1.0000
[2019-03-23 19:26:38,342] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3795
[2019-03-23 19:26:38,349] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.2493496538377781, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5039375466792166, 6.911200000000001, 6.9112, 77.32846344354104, 568863.893145429, 568863.8931454286, 178010.1285901051], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3480600.0000, 
sim time next is 3481200.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.2466159130828279, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4984103162834691, 6.9112, 6.9112, 77.32846344354104, 562624.6179647557, 562624.6179647557, 177377.0146151054], 
processed observation next is [1.0, 0.30434782608695654, 0.5909090909090909, 1.0, 1.0, 1.0, 0.058269891353534865, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2834433089763845, 0.0, 0.0, 0.5084288129206541, 0.20837948813509471, 0.20837948813509471, 0.4326268649148912], 
reward next is 0.5674, 
noisyNet noise sample is [array([-0.7248678], dtype=float32), 0.35572773]. 
=============================================
[2019-03-23 19:26:42,531] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1969362e-02 2.3651725e-11 9.8803061e-01 5.3460164e-10 3.0559453e-09], sum to 1.0000
[2019-03-23 19:26:42,539] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8840
[2019-03-23 19:26:42,543] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.2598871247860066, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5262476575125385, 6.9112, 6.9112, 77.32846344354104, 591762.0347431514, 591762.0347431514, 182173.0542485534], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3546600.0000, 
sim time next is 3547200.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.2596648180112774, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5257972220372694, 6.911200000000001, 6.9112, 77.32846344354104, 591256.3298592609, 591256.3298592606, 182117.6388293343], 
processed observation next is [1.0, 0.043478260869565216, 0.6818181818181818, 0.89, 1.0, 1.0, 0.07458102251409672, 0.0, 1.0, -0.25, 1.0, 1.0, 0.32256746005324205, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21898382587380036, 0.21898382587380022, 0.4441893629983763], 
reward next is 0.5558, 
noisyNet noise sample is [array([0.31754127], dtype=float32), -0.8262738]. 
=============================================
[2019-03-23 19:26:48,970] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1119511e-01 4.7266067e-08 8.8873369e-01 1.1287187e-05 5.9837075e-05], sum to 1.0000
[2019-03-23 19:26:48,979] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3193
[2019-03-23 19:26:48,986] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 70.0, 1.0, 2.0, 0.4752356300498538, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9420976011027453, 6.946749674231207, 6.9112, 77.32837806527135, 1080761.727379067, 1069215.933053066, 254607.1290210677], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3674400.0000, 
sim time next is 3675000.0000, 
raw observation next is [26.5, 68.0, 1.0, 2.0, 0.5409124200808643, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9688165906410653, 6.926324267606773, 6.9112, 77.32840444646267, 1162577.377164616, 1157665.328138313, 268145.317610677], 
processed observation next is [1.0, 0.5217391304347826, 0.8409090909090909, 0.68, 1.0, 1.0, 0.4261405251010803, 0.0, 1.0, -0.25, 1.0, 1.0, 0.955452272344379, 0.0015124267606773322, 0.0, 0.508428425019315, 0.4305842137646726, 0.42876493634752333, 0.654012969782139], 
reward next is 0.2704, 
noisyNet noise sample is [array([2.3308716], dtype=float32), 0.6007257]. 
=============================================
[2019-03-23 19:26:49,009] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[32.1801  ]
 [32.358833]
 [31.736557]
 [31.637302]
 [32.138268]], R is [[32.08841324]
 [31.96878624]
 [32.08065796]
 [32.14982224]
 [32.149189  ]].
[2019-03-23 19:26:50,246] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.9911215e-02 9.3375451e-07 9.0986633e-01 5.0166713e-05 1.7142369e-04], sum to 1.0000
[2019-03-23 19:26:50,253] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6692
[2019-03-23 19:26:50,259] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.16666666666667, 54.5, 1.0, 2.0, 0.7898217364312244, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9742015197075862, 6.911199999999999, 6.9112, 77.32846344354104, 1448382.787348785, 1448382.787348785, 303068.9211239376], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3689400.0000, 
sim time next is 3690000.0000, 
raw observation next is [28.0, 55.0, 1.0, 2.0, 0.6737657941135806, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9737065983407699, 6.911199999999999, 6.9112, 77.32846344354104, 1316231.233535144, 1316231.233535144, 284723.1340902176], 
processed observation next is [1.0, 0.7391304347826086, 0.9090909090909091, 0.55, 1.0, 1.0, 0.5922072426419758, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9624379976296714, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.48749304945746075, 0.48749304945746075, 0.6944466685127259], 
reward next is 0.3056, 
noisyNet noise sample is [array([-0.07760516], dtype=float32), -0.02067504]. 
=============================================
[2019-03-23 19:26:50,278] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[24.556084]
 [24.2681  ]
 [24.506506]
 [24.231829]
 [23.951355]], R is [[24.81320763]
 [24.82588196]
 [24.83566666]
 [24.84173965]
 [24.84826279]].
[2019-03-23 19:27:00,688] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.43007181e-04 6.17343332e-08 9.99656916e-01 1.08892834e-07
 3.86273324e-09], sum to 1.0000
[2019-03-23 19:27:00,696] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1391
[2019-03-23 19:27:00,702] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 305488.4461892591, 305488.4461892594, 131527.1825541414], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3893400.0000, 
sim time next is 3894000.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 305406.2327507673, 305406.2327507673, 131508.069837269], 
processed observation next is [0.0, 0.043478260869565216, 0.45454545454545453, 0.77, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.11311341953732122, 0.11311341953732122, 0.3207513898469975], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.34802157], dtype=float32), -1.1678753]. 
=============================================
[2019-03-23 19:27:00,726] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[-0.10711173]
 [-0.13092259]
 [-0.04731039]
 [ 0.00350841]
 [ 0.0899274 ]], R is [[-0.00553413]
 [-0.00547879]
 [-0.005424  ]
 [-0.00536976]
 [-0.00531606]].
[2019-03-23 19:27:01,251] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.4419717e-04 2.9621633e-08 9.9975568e-01 8.3026023e-08 1.3959401e-08], sum to 1.0000
[2019-03-23 19:27:01,256] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7376
[2019-03-23 19:27:01,262] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.75, 78.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 300208.9507096658, 300208.9507096655, 129366.7539519278], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3900600.0000, 
sim time next is 3901200.0000, 
raw observation next is [17.66666666666667, 79.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 299204.5031951981, 299204.5031951978, 128788.7715412316], 
processed observation next is [0.0, 0.13043478260869565, 0.4393939393939396, 0.79, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11081648266488818, 0.11081648266488807, 0.31411895497861364], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2298776], dtype=float32), -0.37307262]. 
=============================================
[2019-03-23 19:27:03,172] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5372114e-05 1.3751629e-09 9.9998462e-01 2.7791254e-08 2.4267430e-09], sum to 1.0000
[2019-03-23 19:27:03,178] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9194
[2019-03-23 19:27:03,182] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 45.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3402686739953799, 6.9112, 6.9112, 77.32846344354104, 391461.5976313567, 391461.5976313567, 152309.468939572], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3937800.0000, 
sim time next is 3938400.0000, 
raw observation next is [26.0, 45.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3397362331828512, 6.9112, 6.9112, 77.32846344354104, 390849.9105148989, 390849.9105148989, 152243.99496194], 
processed observation next is [0.0, 0.6086956521739131, 0.8181818181818182, 0.45, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.05676604740407313, 0.0, 0.0, 0.5084288129206541, 0.14475922611662922, 0.14475922611662922, 0.3713268169803415], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1829023], dtype=float32), 0.32628495]. 
=============================================
[2019-03-23 19:27:08,168] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.4317673e-03 5.5333797e-12 9.9756819e-01 5.8097988e-10 1.4346543e-09], sum to 1.0000
[2019-03-23 19:27:08,177] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5083
[2019-03-23 19:27:08,182] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.33333333333333, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3291330524251073, 6.911199999999999, 6.9112, 77.32846344354104, 380617.7378690891, 380617.7378690894, 149051.5039909871], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4038000.0000, 
sim time next is 4038600.0000, 
raw observation next is [17.16666666666667, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3224554225193984, 6.9112, 6.9112, 77.32846344354104, 373221.290819184, 373221.290819184, 147955.4846329242], 
processed observation next is [1.0, 0.7391304347826086, 0.4166666666666669, 0.94, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.03207917502771202, 0.0, 0.0, 0.5084288129206541, 0.13823010771080887, 0.13823010771080887, 0.360867035690059], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.06651], dtype=float32), -0.83692205]. 
=============================================
[2019-03-23 19:27:10,588] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.2808844e-04 4.8735349e-09 9.9967194e-01 4.9050296e-08 2.5407516e-09], sum to 1.0000
[2019-03-23 19:27:10,595] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5649
[2019-03-23 19:27:10,601] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [15.96666666666667, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 329644.1561145856, 329644.1561145856, 141367.1242028781], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4075800.0000, 
sim time next is 4076400.0000, 
raw observation next is [15.93333333333333, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 326799.4602401032, 326799.460240103, 140853.0020779799], 
processed observation next is [1.0, 0.17391304347826086, 0.36060606060606043, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12103683712596415, 0.12103683712596408, 0.34354390750726804], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6268034], dtype=float32), 0.00409576]. 
=============================================
[2019-03-23 19:27:10,839] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3534127e-04 1.7477385e-08 9.9986458e-01 4.8003695e-08 5.9983249e-09], sum to 1.0000
[2019-03-23 19:27:10,844] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8832
[2019-03-23 19:27:10,848] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [15.93333333333333, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 327250.0094619076, 327250.0094619076, 140879.7343526889], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4081200.0000, 
sim time next is 4081800.0000, 
raw observation next is [15.96666666666667, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 326050.3443872437, 326050.3443872437, 140759.7934020087], 
processed observation next is [1.0, 0.21739130434782608, 0.3621212121212123, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.12075938681009026, 0.12075938681009026, 0.343316569273192], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1358315], dtype=float32), -0.062075235]. 
=============================================
[2019-03-23 19:27:21,671] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 19:27:21,672] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:27:21,673] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:27:21,674] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:27:21,674] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:27:21,675] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:27:21,676] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:27:21,678] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:27:21,679] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:27:21,675] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:27:21,682] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:27:21,705] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run65
[2019-03-23 19:27:21,731] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run65
[2019-03-23 19:27:21,754] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run65
[2019-03-23 19:27:21,781] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run65
[2019-03-23 19:27:21,782] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run65
[2019-03-23 19:27:39,166] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0063426], dtype=float32), 0.011147936]
[2019-03-23 19:27:39,167] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.66666666666667, 94.33333333333333, 1.0, 2.0, 0.2435865929505044, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4922563234527094, 6.9112, 6.9112, 77.32846344354104, 555723.81854184, 555723.81854184, 176647.4119881501]
[2019-03-23 19:27:39,168] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:27:39,171] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.4479533e-03 1.8603868e-10 9.9255204e-01 7.6027016e-09 1.2893617e-08], sampled 0.151578485371351
[2019-03-23 19:28:03,842] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0063426], dtype=float32), 0.011147936]
[2019-03-23 19:28:03,844] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.8, 89.33333333333334, 1.0, 2.0, 0.2203856381270588, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4407292980563206, 6.9112, 6.9112, 95.55338769695034, 501749.4630985062, 501749.4630985062, 172434.7516423666]
[2019-03-23 19:28:03,845] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:28:03,848] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.9539583e-03 3.6889664e-10 9.9404597e-01 1.2641978e-08 1.9133854e-08], sampled 0.3555198464707414
[2019-03-23 19:29:03,236] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3096.7078 2106917676.8185 382.0000
[2019-03-23 19:29:03,602] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3325.4425 2095830501.5348 196.0000
[2019-03-23 19:29:03,788] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2751.2200 2122914068.9807 765.0000
[2019-03-23 19:29:03,849] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3590.4867 2172658872.4047 256.0000
[2019-03-23 19:29:03,893] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3490.2934 2101769460.9138 199.0000
[2019-03-23 19:29:04,911] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1600000, evaluation results [1600000.0, 3590.4866580617977, 2172658872.4047046, 256.0, 3325.442504952871, 2095830501.5347605, 196.0, 3490.2933526174766, 2101769460.9137514, 199.0, 2751.21998308116, 2122914068.9807332, 765.0, 3096.707802499844, 2106917676.8184915, 382.0]
[2019-03-23 19:29:22,247] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3381088e-03 1.2824161e-13 9.9866188e-01 2.2711361e-11 7.6026858e-11], sum to 1.0000
[2019-03-23 19:29:22,255] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3866
[2019-03-23 19:29:22,259] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.33333333333333, 52.0, 1.0, 2.0, 0.2344931413763715, 0.0, 2.0, 0.0, 1.0, 2.0, 0.440369681777609, 6.9112, 6.9112, 77.32846344354104, 511281.4076560979, 511281.4076560979, 158219.6328943171], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4621200.0000, 
sim time next is 4621800.0000, 
raw observation next is [22.66666666666667, 51.0, 1.0, 2.0, 0.2433750688885317, 0.0, 2.0, 0.0, 1.0, 2.0, 0.458646144328941, 6.9112, 6.9112, 77.32846344354104, 532130.5006652328, 532130.5006652328, 160259.0487863109], 
processed observation next is [1.0, 0.4782608695652174, 0.6666666666666669, 0.51, 1.0, 1.0, 0.0542188361106646, 0.0, 1.0, -0.25, 1.0, 1.0, 0.22663734904134433, 0.0, 0.0, 0.5084288129206541, 0.19708537061675288, 0.19708537061675288, 0.39087572874709975], 
reward next is 0.6091, 
noisyNet noise sample is [array([-0.19454451], dtype=float32), 0.15649346]. 
=============================================
[2019-03-23 19:29:24,086] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.1737225e-05 1.6545809e-07 9.9995685e-01 1.1335046e-06 1.2496604e-07], sum to 1.0000
[2019-03-23 19:29:24,092] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1863
[2019-03-23 19:29:24,099] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.33333333333334, 70.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 294402.2368452307, 294402.2368452307, 120937.8608376241], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4660800.0000, 
sim time next is 4661400.0000, 
raw observation next is [18.16666666666666, 71.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 294630.6610925209, 294630.6610925212, 121382.731059384], 
processed observation next is [1.0, 0.9565217391304348, 0.4621212121212119, 0.715, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10912246707130405, 0.10912246707130416, 0.29605544160825364], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.6692506], dtype=float32), 0.84443307]. 
=============================================
[2019-03-23 19:29:34,060] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.9044564e-04 8.0932230e-14 9.9980956e-01 3.0838981e-11 6.0191796e-11], sum to 1.0000
[2019-03-23 19:29:34,067] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7031
[2019-03-23 19:29:34,071] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.0, 94.00000000000001, 1.0, 2.0, 0.3049498899474646, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6088115266341484, 6.911199999999999, 6.9112, 80.71506555913322, 693934.051204159, 693934.0512041593, 187979.5557448614], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4846200.0000, 
sim time next is 4846800.0000, 
raw observation next is [20.0, 94.0, 1.0, 2.0, 0.2620668350296604, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5232689802827951, 6.9112, 6.9112, 77.32846344354104, 596346.1895060474, 596346.1895060474, 176093.9619490834], 
processed observation next is [1.0, 0.08695652173913043, 0.5454545454545454, 0.94, 1.0, 1.0, 0.07758354378707547, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3189556861182788, 0.0, 0.0, 0.5084288129206541, 0.22086895907631385, 0.22086895907631385, 0.4294974681684961], 
reward next is 0.5705, 
noisyNet noise sample is [array([1.5326133], dtype=float32), -0.6920317]. 
=============================================
[2019-03-23 19:29:35,101] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.3968066e-05 7.7400973e-15 9.9993598e-01 5.0579085e-12 4.0036390e-12], sum to 1.0000
[2019-03-23 19:29:35,106] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3652
[2019-03-23 19:29:35,108] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3962502450514294, 6.9112, 6.9112, 77.32846344354104, 452609.886308312, 452609.886308312, 162230.072708083], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4859400.0000, 
sim time next is 4860000.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.200342270155885, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3980806703683359, 6.9112, 6.9112, 77.32846344354104, 454699.6339689923, 454699.6339689923, 162447.8041305939], 
processed observation next is [1.0, 0.2608695652173913, 0.5, 1.0, 1.0, 1.0, 0.00042783769485622153, 0.0, 1.0, -0.25, 1.0, 1.0, 0.140115243383337, 0.0, 0.0, 0.5084288129206541, 0.16840727184036752, 0.16840727184036752, 0.39621415641608265], 
reward next is 0.6038, 
noisyNet noise sample is [array([-0.00490107], dtype=float32), -0.04758606]. 
=============================================
[2019-03-23 19:29:35,121] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[53.898254]
 [53.919884]
 [53.935535]
 [53.983986]
 [54.112785]], R is [[53.97363281]
 [53.43389511]
 [52.89955521]
 [52.37055969]
 [51.84685516]].
[2019-03-23 19:29:37,187] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3347842e-04 2.1243984e-11 9.9986649e-01 3.7335182e-10 1.6247627e-10], sum to 1.0000
[2019-03-23 19:29:37,194] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2307
[2019-03-23 19:29:37,199] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.2093979297886323, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4175396302668713, 6.911199999999999, 6.9112, 77.32846344354104, 476129.1111338623, 476129.1111338626, 164902.6391814601], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4908600.0000, 
sim time next is 4909200.0000, 
raw observation next is [21.66666666666667, 79.66666666666666, 1.0, 2.0, 0.2077210863176171, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4137479851228529, 6.9112, 6.9112, 77.32846344354104, 472059.324363443, 472059.324363443, 164327.1184954272], 
processed observation next is [1.0, 0.8260869565217391, 0.6212121212121214, 0.7966666666666665, 1.0, 1.0, 0.00965135789702136, 0.0, 1.0, -0.25, 1.0, 1.0, 0.16249712160407556, 0.0, 0.0, 0.5084288129206541, 0.17483678680127518, 0.17483678680127518, 0.4007978499888468], 
reward next is 0.5992, 
noisyNet noise sample is [array([-1.7984588], dtype=float32), 0.8059842]. 
=============================================
[2019-03-23 19:29:40,543] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.0464093e-03 3.0519852e-13 9.9795353e-01 4.0784556e-10 5.6819133e-10], sum to 1.0000
[2019-03-23 19:29:40,551] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7824
[2019-03-23 19:29:40,555] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.3400252092004791, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6414469300322578, 6.911199999999999, 6.9112, 77.32846344354104, 744220.8854957323, 744220.8854957327, 180468.1336987118], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4966200.0000, 
sim time next is 4966800.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.3361822839258226, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6343003510681189, 6.9112, 6.9112, 77.32846344354104, 735897.7647482587, 735897.7647482587, 179582.0561872606], 
processed observation next is [1.0, 0.4782608695652174, 0.5, 0.73, 1.0, 1.0, 0.17022785490727824, 0.0, 1.0, -0.25, 1.0, 1.0, 0.47757193009731275, 0.0, 0.0, 0.5084288129206541, 0.27255472768454025, 0.27255472768454025, 0.4380050150908795], 
reward next is 0.5620, 
noisyNet noise sample is [array([2.3514419], dtype=float32), -0.09694479]. 
=============================================
[2019-03-23 19:29:41,267] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.2136348e-05 4.0445091e-12 9.9997783e-01 1.1751726e-09 1.8868489e-10], sum to 1.0000
[2019-03-23 19:29:41,275] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3615
[2019-03-23 19:29:41,281] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.0, 61.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 308562.8054544231, 308562.8054544234, 129072.3887858286], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4988400.0000, 
sim time next is 4989000.0000, 
raw observation next is [20.0, 60.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 308101.3472024469, 308101.3472024472, 127457.615225134], 
processed observation next is [1.0, 0.7391304347826086, 0.5454545454545454, 0.6066666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11411161007498033, 0.11411161007498044, 0.31087223225642435], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7032226], dtype=float32), 1.4764608]. 
=============================================
[2019-03-23 19:29:41,299] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[31.540049]
 [37.815834]
 [45.314865]
 [50.74842 ]
 [51.25737 ]], R is [[27.68865395]
 [27.41176796]
 [27.13765144]
 [26.86627579]
 [26.59761238]].
[2019-03-23 19:29:43,352] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5418378e-05 6.3358798e-09 9.9998462e-01 1.1823330e-08 2.3582432e-09], sum to 1.0000
[2019-03-23 19:29:43,361] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1193
[2019-03-23 19:29:43,366] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 267274.2769193621, 267274.2769193618, 107694.8964118428], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5018400.0000, 
sim time next is 5019000.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 265375.6661055167, 265375.6661055164, 107312.1913058169], 
processed observation next is [0.0, 0.08695652173913043, 0.2727272727272727, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09828728374278398, 0.09828728374278384, 0.2617370519654071], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9783808], dtype=float32), 1.3621461]. 
=============================================
[2019-03-23 19:29:43,375] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[ 0.40155658]
 [ 0.662494  ]
 [ 0.24782023]
 [ 0.17099246]
 [-0.025991  ]], R is [[0.46465194]
 [0.46000543]
 [0.45540538]
 [0.45085132]
 [0.44634283]].
[2019-03-23 19:29:52,775] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4099052e-02 6.9708475e-11 9.8590058e-01 2.6647844e-09 4.1059542e-07], sum to 1.0000
[2019-03-23 19:29:52,780] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8788
[2019-03-23 19:29:52,783] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.33333333333333, 92.16666666666667, 1.0, 2.0, 0.4019397835844609, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8108424499799247, 6.911199999999999, 6.9112, 77.32846344354104, 917641.7056196101, 917641.7056196104, 222312.3109924301], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5215800.0000, 
sim time next is 5216400.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.3842324412665482, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7745804066448614, 6.9112, 6.9112, 77.32846344354104, 877178.2245038176, 877178.2245038176, 215496.8950013831], 
processed observation next is [1.0, 0.391304347826087, 0.5909090909090909, 0.94, 1.0, 1.0, 0.23029055158318523, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6779720094926592, 0.0, 0.0, 0.5084288129206541, 0.3248808238903028, 0.3248808238903028, 0.5256021829302027], 
reward next is 0.4744, 
noisyNet noise sample is [array([0.937513], dtype=float32), -1.2996552]. 
=============================================
[2019-03-23 19:29:53,925] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 19:29:53,925] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:29:53,926] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:29:53,926] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:29:53,927] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:29:53,928] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:29:53,928] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:29:53,927] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:29:53,930] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:29:53,929] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:29:53,932] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:29:53,945] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run66
[2019-03-23 19:29:53,973] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run66
[2019-03-23 19:29:53,974] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run66
[2019-03-23 19:29:53,974] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run66
[2019-03-23 19:29:54,056] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run66
[2019-03-23 19:29:56,088] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00638958], dtype=float32), 0.011281959]
[2019-03-23 19:29:56,090] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [11.49006548833333, 90.64436323333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 334937.4677592248, 334937.4677592248, 114382.0207718471]
[2019-03-23 19:29:56,091] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:29:56,094] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.8194524e-05 1.0268401e-09 9.9995184e-01 8.3131182e-09 3.2235747e-09], sampled 0.8572365488036975
[2019-03-23 19:31:18,311] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00638958], dtype=float32), 0.011281959]
[2019-03-23 19:31:18,311] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.86258266666667, 59.75803403, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.313863608644065, 6.9112, 6.9112, 95.55338769695034, 365119.3429913925, 365119.3429913925, 137999.9337818758]
[2019-03-23 19:31:18,312] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:31:18,318] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.3984470e-05 3.2197320e-08 9.9996591e-01 1.2175897e-07 2.2511161e-08], sampled 0.33509397034788535
[2019-03-23 19:31:23,969] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00638958], dtype=float32), 0.011281959]
[2019-03-23 19:31:23,970] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [28.15, 62.83333333333333, 1.0, 2.0, 0.3509585878215578, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7103749695977541, 6.911200000000001, 6.9112, 95.55338769695034, 793515.3336591767, 793515.3336591764, 216411.833299365]
[2019-03-23 19:31:23,973] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:31:23,975] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.3547400e-04 6.1976244e-11 9.9906451e-01 4.7071813e-09 1.0709241e-08], sampled 0.2444713092663494
[2019-03-23 19:31:25,512] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00638958], dtype=float32), 0.011281959]
[2019-03-23 19:31:25,513] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.18333333333333, 83.0, 1.0, 2.0, 0.2189192622473358, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4397651409092917, 6.9112, 6.9112, 95.55338769695034, 499222.9691682346, 499222.9691682346, 173517.1431005383]
[2019-03-23 19:31:25,513] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:31:25,517] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.8495357e-04 1.0291745e-12 9.9961507e-01 8.2246383e-11 2.2626634e-10], sampled 0.18904879423125864
[2019-03-23 19:31:36,150] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3120.1206 2108952058.5652 367.0000
[2019-03-23 19:31:36,158] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3361.9700 2097972406.8665 180.0000
[2019-03-23 19:31:36,182] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3612.4758 2175124185.1405 246.0000
[2019-03-23 19:31:36,429] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2759.8327 2123915156.3358 757.0000
[2019-03-23 19:31:36,664] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3517.0811 2104010157.9814 181.0000
[2019-03-23 19:31:37,683] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1625000, evaluation results [1625000.0, 3612.4757825069614, 2175124185.1405306, 246.0, 3361.9700129149246, 2097972406.8664527, 180.0, 3517.0811322617865, 2104010157.9813666, 181.0, 2759.8326880751943, 2123915156.3358448, 757.0, 3120.120570114474, 2108952058.565175, 367.0]
[2019-03-23 19:31:39,622] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.6335964e-04 1.5275566e-10 9.9963665e-01 4.5506098e-08 1.4326998e-08], sum to 1.0000
[2019-03-23 19:31:39,630] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0573
[2019-03-23 19:31:39,635] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.9, 69.0, 1.0, 2.0, 0.869852208017902, 0.0, 2.0, 0.0, 1.0, 2.0, 0.981594589755011, 6.911199999999999, 6.9112, 77.32846344353746, 1531628.976644357, 1531628.976644357, 324396.6423412664], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5495400.0000, 
sim time next is 5496000.0000, 
raw observation next is [27.0, 69.0, 1.0, 2.0, 0.8749814012268358, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9821467864115708, 6.911199999999999, 6.9112, 77.32846344354103, 1536606.472710913, 1536606.472710913, 325860.0138553233], 
processed observation next is [1.0, 0.6086956521739131, 0.8636363636363636, 0.69, 1.0, 1.0, 0.8437267515335447, 0.0, 1.0, -0.25, 1.0, 1.0, 0.974495409159387, -8.881784197001253e-17, 0.0, 0.508428812920654, 0.5691135084114493, 0.5691135084114493, 0.7947805215983496], 
reward next is 0.2052, 
noisyNet noise sample is [array([-0.80637515], dtype=float32), -0.33645368]. 
=============================================
[2019-03-23 19:31:39,654] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[41.128475]
 [41.183575]
 [41.414127]
 [41.699314]
 [42.048603]], R is [[40.71889877]
 [40.52050018]
 [40.3298111 ]
 [40.15922165]
 [40.05696106]].
[2019-03-23 19:31:40,214] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.8688428e-04 1.5610586e-11 9.9981314e-01 2.4024713e-10 2.5697591e-10], sum to 1.0000
[2019-03-23 19:31:40,221] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4179
[2019-03-23 19:31:40,227] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.8, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3425218455499237, 6.9112, 6.9112, 77.32846344354104, 394233.7926373002, 394233.7926373002, 152414.5804453717], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5284800.0000, 
sim time next is 5285400.0000, 
raw observation next is [18.8, 89.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3448208775860557, 6.911199999999999, 6.9112, 77.32846344354104, 396884.1616517096, 396884.1616517099, 152690.2314551025], 
processed observation next is [1.0, 0.17391304347826086, 0.49090909090909096, 0.895, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0640298251229367, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14699413394507763, 0.14699413394507774, 0.3724151986709817], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.1744638], dtype=float32), -1.0905955]. 
=============================================
[2019-03-23 19:32:08,464] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.6814334e-03 1.4415935e-08 9.9631798e-01 4.8746091e-07 9.0932694e-08], sum to 1.0000
[2019-03-23 19:32:08,472] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0321
[2019-03-23 19:32:08,475] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [12.0, 84.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3665580814791846, 6.9112, 6.9112, 77.32846344354104, 426476.5462842387, 426476.5462842387, 121291.3670830518], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5804400.0000, 
sim time next is 5805000.0000, 
raw observation next is [11.9, 84.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3654601733093264, 6.911200000000001, 6.9112, 77.32846344354104, 425198.6128539467, 425198.6128539465, 121078.460970387], 
processed observation next is [1.0, 0.17391304347826086, 0.17727272727272728, 0.845, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.09351453329903774, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15748096772368395, 0.1574809677236839, 0.2953133194399683], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.4752809], dtype=float32), -0.89585984]. 
=============================================
[2019-03-23 19:32:08,491] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[28.96997 ]
 [29.026056]
 [28.65693 ]
 [28.445032]
 [27.983274]], R is [[28.99984932]
 [28.70985031]
 [28.42275238]
 [28.13852501]
 [27.85713959]].
[2019-03-23 19:32:21,746] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.1508703e-03 5.8759962e-08 9.9684060e-01 3.8491025e-06 4.6510136e-06], sum to 1.0000
[2019-03-23 19:32:21,760] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3496
[2019-03-23 19:32:21,771] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.46666666666667, 53.83333333333334, 1.0, 2.0, 0.2168861550542781, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4048789369315276, 6.9112, 6.9112, 77.32846344354104, 471083.0211377472, 471083.0211377472, 154091.4863762521], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6091800.0000, 
sim time next is 6092400.0000, 
raw observation next is [21.83333333333334, 52.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3607248023768487, 6.9112, 6.9112, 77.32846344354104, 419583.7413007013, 419583.7413007013, 150612.5779788035], 
processed observation next is [1.0, 0.5217391304347826, 0.628787878787879, 0.5266666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.08674971768121241, 0.0, 0.0, 0.5084288129206541, 0.1554013856669264, 0.1554013856669264, 0.36734775116781343], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.6279019], dtype=float32), 1.3648107]. 
=============================================
[2019-03-23 19:32:23,650] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.51343386e-03 8.88968732e-10 9.91486311e-01 1.05117685e-07
 1.68363457e-07], sum to 1.0000
[2019-03-23 19:32:23,661] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0426
[2019-03-23 19:32:23,666] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.48333333333333, 89.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3347828648629927, 6.9112, 6.9112, 77.32846344354104, 386060.2699580935, 386060.2699580935, 150776.5003369251], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6675000.0000, 
sim time next is 6675600.0000, 
raw observation next is [18.66666666666667, 89.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3329469199570488, 6.911199999999999, 6.9112, 77.32846344354104, 383700.1908358458, 383700.1908358461, 150793.3358310917], 
processed observation next is [1.0, 0.2608695652173913, 0.4848484848484851, 0.89, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.047067028510069706, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.142111181791054, 0.14211118179105411, 0.36778862397827244], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.53334665], dtype=float32), 0.37079993]. 
=============================================
[2019-03-23 19:32:26,792] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.0793555e-03 4.0707349e-10 9.9792033e-01 1.0056586e-08 3.5698622e-07], sum to 1.0000
[2019-03-23 19:32:26,802] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2821
[2019-03-23 19:32:26,806] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.55, 73.5, 1.0, 2.0, 0.3212632456419358, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6238692402458939, 6.911200000000001, 6.9112, 77.32846344354104, 718673.1419304566, 718673.1419304563, 182704.3646965857], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6172200.0000, 
sim time next is 6172800.0000, 
raw observation next is [20.36666666666667, 76.0, 1.0, 2.0, 0.3077627990329469, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5992277494823337, 6.9112, 6.9112, 77.32846344354104, 689727.9462602743, 689727.9462602743, 180039.0124112188], 
processed observation next is [1.0, 0.43478260869565216, 0.5621212121212124, 0.76, 1.0, 1.0, 0.1347034987911836, 0.0, 1.0, -0.25, 1.0, 1.0, 0.427468213546191, 0.0, 0.0, 0.5084288129206541, 0.2554547949112127, 0.2554547949112127, 0.43911954246638735], 
reward next is 0.5609, 
noisyNet noise sample is [array([-0.8187526], dtype=float32), -0.98435163]. 
=============================================
[2019-03-23 19:32:26,846] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 19:32:26,847] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:32:26,848] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:32:26,849] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:32:26,849] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:32:26,850] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:32:26,851] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:32:26,852] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:32:26,852] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:32:26,854] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:32:26,856] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:32:26,870] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run67
[2019-03-23 19:32:26,896] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run67
[2019-03-23 19:32:26,897] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run67
[2019-03-23 19:32:26,945] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run67
[2019-03-23 19:32:26,970] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run67
[2019-03-23 19:32:45,941] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00620811], dtype=float32), 0.011616714]
[2019-03-23 19:32:45,943] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [28.49484410333334, 53.71084853333334, 1.0, 2.0, 0.465605462499481, 0.0, 2.0, 0.0, 1.0, 2.0, 0.870720788601291, 7.012278184613521, 6.9112, 95.55301417830712, 1060306.434155784, 1019741.468284312, 246828.2243552323]
[2019-03-23 19:32:45,944] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:32:45,946] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.5031779e-03 5.6131520e-11 9.9549675e-01 1.4029462e-08 6.3870949e-08], sampled 0.8298799694646404
[2019-03-23 19:32:51,508] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00620811], dtype=float32), 0.011616714]
[2019-03-23 19:32:51,508] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.32528227666667, 59.14690090666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3747274844769675, 6.9112, 6.9112, 95.55338769695034, 428948.5324196417, 428948.5324196417, 163106.7939205972]
[2019-03-23 19:32:51,509] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:32:51,512] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.1356271e-04 1.0018372e-10 9.9978644e-01 3.5992131e-09 4.4205093e-09], sampled 0.17242494533590236
[2019-03-23 19:33:18,554] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00620811], dtype=float32), 0.011616714]
[2019-03-23 19:33:18,555] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.60438324666667, 93.95216821333334, 1.0, 2.0, 0.2037606458909323, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3848015384222425, 6.9112, 6.9112, 95.55338769695034, 446177.8101043666, 446177.8101043666, 158904.7347925357]
[2019-03-23 19:33:18,556] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:33:18,558] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.5877779e-04 4.9085432e-12 9.9954128e-01 3.5603295e-10 9.5515185e-10], sampled 0.6951838304670359
[2019-03-23 19:33:45,229] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00620811], dtype=float32), 0.011616714]
[2019-03-23 19:33:45,230] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.81902977, 80.41554743500001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 307069.8155891617, 307069.8155891617, 141919.6320038857]
[2019-03-23 19:33:45,231] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:33:45,234] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.6502089e-04 2.3288277e-10 9.9983490e-01 5.6123626e-09 4.9995998e-09], sampled 0.02755142079476358
[2019-03-23 19:34:09,423] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3111.9344 2108301527.2244 370.0000
[2019-03-23 19:34:09,496] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2757.7809 2123837550.6276 758.0000
[2019-03-23 19:34:09,573] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3513.6542 2103642461.6163 184.0000
[2019-03-23 19:34:09,622] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3356.2794 2097471465.7636 183.0000
[2019-03-23 19:34:09,710] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3602.9302 2174397843.2001 247.0000
[2019-03-23 19:34:10,728] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1650000, evaluation results [1650000.0, 3602.930158967383, 2174397843.200099, 247.0, 3356.279426960326, 2097471465.7636042, 183.0, 3513.6541700588746, 2103642461.6162684, 184.0, 2757.7808999361987, 2123837550.6275582, 758.0, 3111.9344166051847, 2108301527.224411, 370.0]
[2019-03-23 19:34:11,000] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.0248486e-04 2.1868711e-09 9.9919730e-01 1.5858686e-07 1.7446153e-07], sum to 1.0000
[2019-03-23 19:34:11,011] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9231
[2019-03-23 19:34:11,020] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.2, 84.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 305463.1745515838, 305463.1745515838, 132755.9940424026], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6156000.0000, 
sim time next is 6156600.0000, 
raw observation next is [17.28333333333333, 83.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 313049.6824647572, 313049.6824647569, 134660.7385911353], 
processed observation next is [1.0, 0.2608695652173913, 0.4219696969696969, 0.835, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11594432683879896, 0.11594432683879885, 0.3284408258320373], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.63648313], dtype=float32), 0.16871953]. 
=============================================
[2019-03-23 19:34:18,328] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.18246234e-04 1.85915600e-14 9.99781787e-01 1.11218691e-11
 1.04899015e-11], sum to 1.0000
[2019-03-23 19:34:18,338] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3034
[2019-03-23 19:34:18,342] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.6, 73.66666666666667, 1.0, 2.0, 0.243347448719213, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4919347725517665, 6.911199999999999, 6.9112, 77.32846344354104, 555097.8028887861, 555097.8028887863, 176797.8186524237], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6304800.0000, 
sim time next is 6305400.0000, 
raw observation next is [24.4, 75.0, 1.0, 2.0, 0.2433483978110085, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4919488075479999, 6.9112, 6.9112, 77.32846344354104, 555093.126277018, 555093.126277018, 176813.896136221], 
processed observation next is [0.0, 1.0, 0.7454545454545454, 0.75, 1.0, 1.0, 0.05418549726376062, 0.0, 1.0, -0.25, 1.0, 1.0, 0.27421258221142847, 0.0, 0.0, 0.5084288129206541, 0.20559004676926593, 0.20559004676926593, 0.43125340521029515], 
reward next is 0.5687, 
noisyNet noise sample is [array([1.4255601], dtype=float32), -0.2771115]. 
=============================================
[2019-03-23 19:34:18,765] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.8362251e-03 1.3162180e-12 9.9716371e-01 2.2280033e-10 8.9151675e-10], sum to 1.0000
[2019-03-23 19:34:18,777] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0969
[2019-03-23 19:34:18,784] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.25, 70.0, 1.0, 2.0, 0.2458726976427262, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4971738913197944, 6.911199999999999, 6.9112, 77.32846344354104, 560778.1615736595, 560778.1615736597, 177553.4716190413], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6301800.0000, 
sim time next is 6302400.0000, 
raw observation next is [25.16666666666666, 70.33333333333333, 1.0, 2.0, 0.2450650569247732, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4954906253804949, 6.9112, 6.9112, 77.32846344354104, 558968.1703768374, 558968.1703768374, 177299.7106590385], 
processed observation next is [0.0, 0.9565217391304348, 0.78030303030303, 0.7033333333333333, 1.0, 1.0, 0.05633132115596649, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2792723219721356, 0.0, 0.0, 0.5084288129206541, 0.20702524828771754, 0.20702524828771754, 0.43243831868058175], 
reward next is 0.5676, 
noisyNet noise sample is [array([-0.46368617], dtype=float32), -1.2384204]. 
=============================================
[2019-03-23 19:34:19,058] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.1905215e-03 7.6875145e-14 9.9780947e-01 1.0816201e-10 8.2546614e-10], sum to 1.0000
[2019-03-23 19:34:19,064] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1025
[2019-03-23 19:34:19,069] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.8, 79.0, 1.0, 2.0, 0.2434976465159066, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4922508840561159, 6.9112, 6.9112, 77.32846344354104, 555433.5624498741, 555433.5624498741, 176848.2215035191], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6307200.0000, 
sim time next is 6307800.0000, 
raw observation next is [23.9, 78.50000000000001, 1.0, 2.0, 0.2437797301588797, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4928575372500982, 6.9112, 6.9112, 77.32846344354104, 556056.0363623926, 556056.0363623926, 176960.4826306901], 
processed observation next is [0.0, 0.0, 0.7227272727272727, 0.7850000000000001, 1.0, 1.0, 0.054724662698599595, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2755107675001403, 0.0, 0.0, 0.5084288129206541, 0.2059466801342195, 0.2059466801342195, 0.4316109332455856], 
reward next is 0.5684, 
noisyNet noise sample is [array([-0.5648122], dtype=float32), -1.0051433]. 
=============================================
[2019-03-23 19:34:26,913] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.0896781e-04 1.6985953e-11 9.9959105e-01 7.8626222e-10 7.6610995e-10], sum to 1.0000
[2019-03-23 19:34:26,920] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0325
[2019-03-23 19:34:26,925] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.2872569325129307, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5597902958526978, 6.911200000000001, 6.9112, 77.32846344354104, 644133.031352826, 644133.0313528257, 175432.6993330744], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6702000.0000, 
sim time next is 6702600.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.2823927271898456, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5502185147092197, 6.911200000000001, 6.9112, 77.32846344354104, 633144.556611079, 633144.5566110788, 174297.1756652916], 
processed observation next is [1.0, 0.5652173913043478, 0.4681818181818182, 0.93, 1.0, 1.0, 0.10299090898730698, 0.0, 1.0, -0.25, 1.0, 1.0, 0.357455021013171, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23449798393002927, 0.23449798393002919, 0.4251150625982722], 
reward next is 0.5749, 
noisyNet noise sample is [array([1.0328655], dtype=float32), -0.37571827]. 
=============================================
[2019-03-23 19:34:32,894] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.1929516e-04 1.6918892e-09 9.9958056e-01 2.3812511e-08 1.5761137e-07], sum to 1.0000
[2019-03-23 19:34:32,903] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1946
[2019-03-23 19:34:32,908] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.4, 81.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 219992.5725017779, 219992.5725017779, 92535.30259467036], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6573000.0000, 
sim time next is 6573600.0000, 
raw observation next is [14.4, 81.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 219534.7610363242, 219534.7610363245, 92358.5928426561], 
processed observation next is [1.0, 0.08695652173913043, 0.29090909090909095, 0.81, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08130917075419415, 0.08130917075419425, 0.22526486059184414], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1440505], dtype=float32), 1.0277088]. 
=============================================
[2019-03-23 19:34:39,324] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.9140253e-05 3.5177429e-08 9.9994814e-01 1.7213886e-06 9.0653123e-07], sum to 1.0000
[2019-03-23 19:34:39,333] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7057
[2019-03-23 19:34:39,337] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3569958435965016, 6.9112, 6.9112, 77.32846344354104, 411099.0584096946, 411099.0584096946, 153999.4194213711], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6717600.0000, 
sim time next is 6718200.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3567798701115956, 6.9112, 6.9112, 77.32846344354104, 410849.3698832141, 410849.3698832141, 153973.6314184796], 
processed observation next is [1.0, 0.782608695652174, 0.4681818181818182, 0.93, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.08111410015942233, 0.0, 0.0, 0.5084288129206541, 0.1521664332900793, 0.1521664332900793, 0.3755454424840966], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.35530102], dtype=float32), 0.29821563]. 
=============================================
[2019-03-23 19:34:40,103] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.2362269e-04 5.3389936e-06 9.9915349e-01 1.3093647e-05 4.4283306e-06], sum to 1.0000
[2019-03-23 19:34:40,111] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4313
[2019-03-23 19:34:40,119] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.2, 96.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3184277917880057, 6.911199999999999, 6.9112, 77.32846344354104, 368194.653806314, 368194.6538063143, 147869.2775210674], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6737400.0000, 
sim time next is 6738000.0000, 
raw observation next is [17.2, 96.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3172591817465164, 6.9112, 6.9112, 77.32846344354104, 366845.3698344065, 366845.3698344065, 147734.5331509935], 
processed observation next is [1.0, 1.0, 0.41818181818181815, 0.96, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.024655973923594882, 0.0, 0.0, 0.5084288129206541, 0.1358686554942246, 0.1358686554942246, 0.3603281296365695], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3428593], dtype=float32), 1.6679046]. 
=============================================
[2019-03-23 19:34:40,139] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[2.4200253]
 [2.4847274]
 [2.6239035]
 [2.8212616]
 [3.1449144]], R is [[2.35690856]
 [2.33333945]
 [2.31000614]
 [2.286906  ]
 [2.26403689]].
[2019-03-23 19:34:41,623] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.1421478e-05 5.1950366e-07 9.9996495e-01 2.7893068e-06 2.5478548e-07], sum to 1.0000
[2019-03-23 19:34:41,631] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0182
[2019-03-23 19:34:41,638] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.1, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 317217.2598162385, 317217.2598162388, 139097.5333681728], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6759000.0000, 
sim time next is 6759600.0000, 
raw observation next is [17.06666666666667, 86.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 312491.4532767451, 312491.4532767451, 136696.0618547839], 
processed observation next is [1.0, 0.21739130434782608, 0.4121212121212123, 0.86, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.11573757528768337, 0.11573757528768337, 0.3334050289141071], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.27773216], dtype=float32), -0.8057528]. 
=============================================
[2019-03-23 19:34:42,133] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.7200504e-04 1.8963166e-06 9.9961287e-01 9.1661013e-06 4.0759564e-06], sum to 1.0000
[2019-03-23 19:34:42,141] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4664
[2019-03-23 19:34:42,145] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.2, 97.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3238293315671621, 6.9112, 6.9112, 77.32846344354104, 374017.2386652732, 374017.2386652732, 148907.7928215052], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6744000.0000, 
sim time next is 6744600.0000, 
raw observation next is [17.2, 96.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3199928860140261, 6.9112, 6.9112, 77.32846344354104, 369827.4351684641, 369827.4351684641, 148224.9326860879], 
processed observation next is [1.0, 0.043478260869565216, 0.41818181818181815, 0.965, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.028561265734323004, 0.0, 0.0, 0.5084288129206541, 0.13697312413646817, 0.13697312413646817, 0.36152422606362905], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.32201442], dtype=float32), 0.5111988]. 
=============================================
[2019-03-23 19:34:43,980] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1055932e-03 1.4517317e-06 9.9879175e-01 8.2935665e-05 1.8183086e-05], sum to 1.0000
[2019-03-23 19:34:43,988] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7886
[2019-03-23 19:34:43,996] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 62.0, 1.0, 2.0, 0.5781160441705008, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9654129665155241, 6.9112, 6.9112, 77.328463443538, 1207977.496505382, 1207977.496505382, 262926.3287187775], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6789600.0000, 
sim time next is 6790200.0000, 
raw observation next is [25.08333333333334, 61.66666666666667, 1.0, 2.0, 0.4620467798689049, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9230831605353363, 6.920493263065594, 6.9112, 77.32844112435451, 1054421.931516157, 1051403.670623709, 241893.5137319025], 
processed observation next is [1.0, 0.6086956521739131, 0.7765151515151518, 0.6166666666666667, 1.0, 1.0, 0.3275584748361311, 0.0, 1.0, -0.25, 1.0, 1.0, 0.8901188007647663, 0.0009293263065593748, 0.0, 0.5084286661736866, 0.3905266413022804, 0.38940876689767, 0.5899841798339085], 
reward next is 0.3635, 
noisyNet noise sample is [array([-0.25690782], dtype=float32), 0.30685136]. 
=============================================
[2019-03-23 19:34:45,854] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.63332399e-04 1.08011454e-10 9.99536633e-01 4.06011758e-09
 2.04946748e-09], sum to 1.0000
[2019-03-23 19:34:45,866] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4005
[2019-03-23 19:34:45,869] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.63333333333333, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3514801967265474, 6.9112, 6.9112, 77.32846344354104, 404729.0919011828, 404729.0919011828, 153337.1055119961], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6837600.0000, 
sim time next is 6838200.0000, 
raw observation next is [18.55, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3475599279805384, 6.9112, 6.9112, 77.32846344354104, 400391.3412523658, 400391.3412523658, 152690.5242612121], 
processed observation next is [0.0, 0.13043478260869565, 0.47954545454545455, 0.9, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.06794275425791205, 0.0, 0.0, 0.5084288129206541, 0.14829308935272806, 0.14829308935272806, 0.37241591283222464], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.30077967], dtype=float32), -0.84469813]. 
=============================================
[2019-03-23 19:34:46,371] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.8961748e-04 7.0433670e-10 9.9971038e-01 5.3251636e-08 1.5081113e-08], sum to 1.0000
[2019-03-23 19:34:46,380] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7909
[2019-03-23 19:34:46,387] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.61666666666667, 93.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3238096507170147, 6.9112, 6.9112, 77.32846344354104, 374119.9514625591, 374119.9514625591, 148781.0388979824], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6844200.0000, 
sim time next is 6844800.0000, 
raw observation next is [17.53333333333333, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3229761923085843, 6.9112, 6.9112, 77.32846344354104, 373212.6608539017, 373212.6608539017, 148629.5620342324], 
processed observation next is [0.0, 0.21739130434782608, 0.43333333333333324, 0.94, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.03282313186940619, 0.0, 0.0, 0.5084288129206541, 0.138226911427371, 0.138226911427371, 0.36251112691276194], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9481098], dtype=float32), -1.1761395]. 
=============================================
[2019-03-23 19:34:47,704] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.5049308e-04 4.1928609e-14 9.9924952e-01 3.1165088e-12 3.6331829e-10], sum to 1.0000
[2019-03-23 19:34:47,712] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9392
[2019-03-23 19:34:47,719] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.1, 48.33333333333333, 1.0, 2.0, 0.2232435391867209, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4484167719370732, 6.9112, 6.9112, 77.32846344354104, 509127.8089092245, 509127.8089092245, 169681.8944140932], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6884400.0000, 
sim time next is 6885000.0000, 
raw observation next is [28.0, 48.5, 1.0, 2.0, 0.22225225031836, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4462350175412174, 6.9112, 6.9112, 77.32846344354104, 506802.1577135648, 506802.1577135648, 169340.4806146899], 
processed observation next is [0.0, 0.6956521739130435, 0.9090909090909091, 0.485, 1.0, 1.0, 0.027815312897949973, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2089071679160249, 0.0, 0.0, 0.5084288129206541, 0.18770450285687584, 0.18770450285687584, 0.41302556247485345], 
reward next is 0.5870, 
noisyNet noise sample is [array([-1.2224084], dtype=float32), 0.2018438]. 
=============================================
[2019-03-23 19:34:47,745] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[52.47905 ]
 [52.67204 ]
 [52.908672]
 [53.120754]
 [53.349884]], R is [[52.35480118]
 [52.41739655]
 [52.47878647]
 [52.53865433]
 [52.59585571]].
[2019-03-23 19:34:48,699] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.2785248e-04 1.7548305e-13 9.9977213e-01 1.1932274e-11 2.2889086e-10], sum to 1.0000
[2019-03-23 19:34:48,709] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4692
[2019-03-23 19:34:48,715] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.0, 68.0, 1.0, 2.0, 0.216950175849895, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4345312316589485, 6.9112, 6.9112, 77.32846344354104, 494286.171616079, 494286.171616079, 167539.9579282854], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6900000.0000, 
sim time next is 6900600.0000, 
raw observation next is [23.9, 68.5, 1.0, 2.0, 0.216835536233715, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4342303351405016, 6.9112, 6.9112, 77.32846344354104, 493993.1403640204, 493993.1403640204, 167469.3634980427], 
processed observation next is [0.0, 0.8695652173913043, 0.7227272727272727, 0.685, 1.0, 1.0, 0.02104442029214372, 0.0, 1.0, -0.25, 1.0, 1.0, 0.191757621629288, 0.0, 0.0, 0.5084288129206541, 0.1829604223570446, 0.1829604223570446, 0.408461862190348], 
reward next is 0.5915, 
noisyNet noise sample is [array([-0.01439636], dtype=float32), -1.1503887]. 
=============================================
[2019-03-23 19:34:50,965] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.9640134e-05 5.2600949e-12 9.9997032e-01 2.9217903e-10 9.0780528e-10], sum to 1.0000
[2019-03-23 19:34:50,976] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6113
[2019-03-23 19:34:50,980] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.36666666666667, 63.0, 1.0, 2.0, 0.2391980518445066, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4834587448552231, 6.9112, 6.9112, 77.32846344354104, 545673.291154663, 545673.291154663, 175751.1744013431], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6952200.0000, 
sim time next is 6952800.0000, 
raw observation next is [26.63333333333333, 62.0, 1.0, 2.0, 0.2409817143199127, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4872154830513757, 6.9112, 6.9112, 77.32846344354104, 549661.2003516847, 549661.2003516847, 176347.6919774566], 
processed observation next is [0.0, 0.4782608695652174, 0.8469696969696968, 0.62, 1.0, 1.0, 0.05122714289989085, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2674506900733939, 0.0, 0.0, 0.5084288129206541, 0.20357822235247583, 0.20357822235247583, 0.4301163218962356], 
reward next is 0.5699, 
noisyNet noise sample is [array([3.6248395], dtype=float32), -0.08529978]. 
=============================================
[2019-03-23 19:34:51,513] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1886536e-03 2.6287010e-13 9.9881136e-01 1.9796159e-10 2.5129692e-09], sum to 1.0000
[2019-03-23 19:34:51,519] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8228
[2019-03-23 19:34:51,524] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.1, 64.0, 1.0, 2.0, 0.2372090614006336, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4792525951061102, 6.911199999999999, 6.9112, 77.32846344354104, 541211.7624018831, 541211.7624018835, 175081.6391383688], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6951600.0000, 
sim time next is 6952200.0000, 
raw observation next is [26.36666666666667, 63.0, 1.0, 2.0, 0.2391980518445066, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4834587448552231, 6.9112, 6.9112, 77.32846344354104, 545673.291154663, 545673.291154663, 175751.1744013431], 
processed observation next is [0.0, 0.4782608695652174, 0.8348484848484851, 0.63, 1.0, 1.0, 0.048997564805633234, 0.0, 1.0, -0.25, 1.0, 1.0, 0.26208392122174734, 0.0, 0.0, 0.5084288129206541, 0.20210121894617147, 0.20210121894617147, 0.4286614009788856], 
reward next is 0.5713, 
noisyNet noise sample is [array([-0.0509383], dtype=float32), 0.911698]. 
=============================================
[2019-03-23 19:34:53,038] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.8272999e-02 3.7837592e-14 9.7172695e-01 8.1971175e-12 1.5546439e-11], sum to 1.0000
[2019-03-23 19:34:53,054] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7010
[2019-03-23 19:34:53,058] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.0, 75.33333333333333, 1.0, 2.0, 0.2403529453648364, 0.0, 2.0, 0.0, 1.0, 2.0, 0.485201996541669, 6.911199999999999, 6.9112, 77.32846344354104, 548491.4040324783, 548491.4040324786, 175330.1900637134], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6990000.0000, 
sim time next is 6990600.0000, 
raw observation next is [23.9, 75.66666666666667, 1.0, 2.0, 0.23882971523352, 0.0, 2.0, 0.0, 1.0, 2.0, 0.482006199152653, 6.9112, 6.9112, 77.32846344354104, 545030.2689421668, 545030.2689421668, 174867.4554968059], 
processed observation next is [0.0, 0.9130434782608695, 0.7227272727272727, 0.7566666666666667, 1.0, 1.0, 0.048537144041899995, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2600088559323615, 0.0, 0.0, 0.5084288129206541, 0.2018630625711729, 0.2018630625711729, 0.42650598901659975], 
reward next is 0.5735, 
noisyNet noise sample is [array([-0.7723797], dtype=float32), -0.3077535]. 
=============================================
[2019-03-23 19:34:55,751] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.566672e-03 6.861476e-08 9.904203e-01 5.260009e-06 7.766550e-06], sum to 1.0000
[2019-03-23 19:34:55,759] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0253
[2019-03-23 19:34:55,766] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.8, 97.0, 1.0, 2.0, 0.3104272316565809, 0.0, 2.0, 0.0, 1.0, 2.0, 0.614039589463749, 6.911199999999999, 6.9112, 77.32846344354104, 702916.8408460031, 702916.8408460035, 185022.4268544701], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7032600.0000, 
sim time next is 7033200.0000, 
raw observation next is [18.8, 97.0, 1.0, 2.0, 0.2947458083938091, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5828798679271867, 6.911200000000001, 6.9112, 77.32846344354104, 667287.9099860733, 667287.9099860729, 180991.6943349172], 
processed observation next is [1.0, 0.391304347826087, 0.49090909090909096, 0.97, 1.0, 1.0, 0.11843226049226135, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4041140970388382, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24714367036521231, 0.2471436703652122, 0.4414431569144322], 
reward next is 0.5586, 
noisyNet noise sample is [array([0.25534934], dtype=float32), -0.6737227]. 
=============================================
[2019-03-23 19:34:59,716] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 19:34:59,718] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:34:59,719] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:34:59,721] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:34:59,720] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:34:59,723] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:34:59,722] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:34:59,723] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:34:59,724] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:34:59,727] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:34:59,726] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:34:59,743] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run68
[2019-03-23 19:34:59,770] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run68
[2019-03-23 19:34:59,795] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run68
[2019-03-23 19:34:59,820] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run68
[2019-03-23 19:34:59,820] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run68
[2019-03-23 19:35:49,880] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00623472], dtype=float32), 0.0116714565]
[2019-03-23 19:35:49,881] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.63158206833333, 97.80389097333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3543922711073728, 6.911200000000001, 6.9112, 95.55338769695034, 408057.1190923208, 408057.1190923205, 158282.4590961941]
[2019-03-23 19:35:49,883] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:35:49,885] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.1776071e-04 1.7351401e-09 9.9968219e-01 4.7382521e-08 7.1229920e-08], sampled 0.12973332132189863
[2019-03-23 19:36:08,170] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00623472], dtype=float32), 0.0116714565]
[2019-03-23 19:36:08,171] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.88333333333333, 48.33333333333333, 1.0, 2.0, 0.3278341904576694, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6584312347620611, 6.9112, 6.9112, 95.55338769695034, 747707.2191655609, 747707.2191655609, 200362.7814090245]
[2019-03-23 19:36:08,173] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:36:08,177] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0840581e-03 1.6688708e-09 9.9891543e-01 9.7601408e-08 3.0080156e-07], sampled 0.645696624317402
[2019-03-23 19:36:32,197] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00623472], dtype=float32), 0.0116714565]
[2019-03-23 19:36:32,199] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [13.01032876666667, 96.60309192666668, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 206099.7286084192, 206099.7286084192, 94731.66546357321]
[2019-03-23 19:36:32,200] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:36:32,205] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.2771593e-04 5.6179812e-09 9.9987221e-01 7.4027092e-08 5.4236704e-08], sampled 0.5223671056289622
[2019-03-23 19:36:42,332] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3120.1150 2108773440.9818 367.0000
[2019-03-23 19:36:42,429] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3359.3304 2097850343.1942 180.0000
[2019-03-23 19:36:42,456] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3516.0721 2103872531.9955 181.0000
[2019-03-23 19:36:42,553] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00623472], dtype=float32), 0.0116714565]
[2019-03-23 19:36:42,554] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.26666666666667, 90.33333333333334, 1.0, 2.0, 0.2331871988238354, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4688035039897385, 6.9112, 6.9112, 77.32846344354104, 531941.5974279875, 531941.5974279875, 172036.0186985991]
[2019-03-23 19:36:42,554] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:36:42,555] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.7322666e-04 1.0752083e-07 9.9931991e-01 2.7804931e-06 4.0131840e-06], sampled 0.6408497409564975
[2019-03-23 19:36:42,646] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2758.3547 2123869454.0080 758.0000
[2019-03-23 19:36:42,664] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3612.4405 2175082068.7430 247.0000
[2019-03-23 19:36:43,684] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1675000, evaluation results [1675000.0, 3612.4405124014365, 2175082068.7430143, 247.0, 3359.330385272037, 2097850343.1941729, 180.0, 3516.07214489982, 2103872531.9954762, 181.0, 2758.3547315778915, 2123869454.0079527, 758.0, 3120.1150391209007, 2108773440.9817522, 367.0]
[2019-03-23 19:36:49,726] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3386377e-04 1.6190589e-07 9.9985588e-01 2.5640527e-06 7.4783356e-06], sum to 1.0000
[2019-03-23 19:36:49,735] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4984
[2019-03-23 19:36:49,738] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.8, 46.0, 1.0, 2.0, 0.325422623512881, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6174586713549837, 6.9112, 6.9112, 77.32846344354104, 715472.0455493454, 715472.0455493454, 178262.8044209725], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7232400.0000, 
sim time next is 7233000.0000, 
raw observation next is [23.71666666666667, 46.0, 1.0, 2.0, 0.2207893473967706, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4175412925567123, 6.911199999999999, 6.9112, 77.32846344354104, 484056.373637364, 484056.3736373642, 157042.9476239692], 
processed observation next is [1.0, 0.7391304347826086, 0.7143939393939395, 0.46, 1.0, 1.0, 0.025986684245963253, 0.0, 1.0, -0.25, 1.0, 1.0, 0.16791613222387475, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1792801383842089, 0.17928013838420895, 0.3830315795706566], 
reward next is 0.6170, 
noisyNet noise sample is [array([-0.6331474], dtype=float32), 0.4603838]. 
=============================================
[2019-03-23 19:36:49,751] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[21.007925]
 [20.59653 ]
 [21.56744 ]
 [22.998383]
 [23.707632]], R is [[19.30251122]
 [19.67469788]
 [20.06389618]
 [20.43924332]
 [20.78832245]].
[2019-03-23 19:36:50,384] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.4852058e-04 3.3830609e-05 9.9963486e-01 6.2046594e-05 2.0559397e-05], sum to 1.0000
[2019-03-23 19:36:50,392] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7329
[2019-03-23 19:36:50,398] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.46666666666667, 46.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.302217997993729, 6.911199999999999, 6.9112, 77.32846344354104, 351055.7028183984, 351055.7028183987, 144365.7326902554], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7234800.0000, 
sim time next is 7235400.0000, 
raw observation next is [23.38333333333333, 46.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3024737024005901, 6.9112, 6.9112, 77.32846344354104, 351473.4027506759, 351473.4027506759, 144276.711992801], 
processed observation next is [1.0, 0.7391304347826086, 0.6992424242424241, 0.46, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.003533860572271627, 0.0, 0.0, 0.5084288129206541, 0.13017533435210218, 0.13017533435210218, 0.35189441949463657], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2239602], dtype=float32), -1.1314746]. 
=============================================
[2019-03-23 19:36:52,266] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.9978560e-04 1.3185145e-07 9.9979490e-01 3.0031579e-06 2.2963141e-06], sum to 1.0000
[2019-03-23 19:36:52,275] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2000
[2019-03-23 19:36:52,277] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.8, 81.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3157865254930594, 6.9112, 6.9112, 77.32846344354104, 365416.4720644839, 365416.4720644839, 147289.669804097], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7347600.0000, 
sim time next is 7348200.0000, 
raw observation next is [18.7, 81.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.315420364995561, 6.911200000000001, 6.9112, 77.32846344354104, 365041.9175410689, 365041.9175410686, 147198.2890920128], 
processed observation next is [1.0, 0.043478260869565216, 0.48636363636363633, 0.815, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.022029092850801412, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1352007102003959, 0.13520071020039576, 0.3590202172975922], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.02734322], dtype=float32), 0.11449336]. 
=============================================
[2019-03-23 19:36:59,504] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:36:59,504] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:36:59,539] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run9
[2019-03-23 19:37:07,609] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0447234e-03 9.0351717e-13 9.9795520e-01 8.1763529e-10 5.0290039e-09], sum to 1.0000
[2019-03-23 19:37:07,621] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9746
[2019-03-23 19:37:07,627] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.3, 56.0, 1.0, 2.0, 0.2537512290777933, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5137311630077499, 6.911200000000001, 6.9112, 77.32846344354104, 578004.9305567789, 578004.9305567786, 180454.168716122], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7567200.0000, 
sim time next is 7567800.0000, 
raw observation next is [28.2, 56.16666666666667, 1.0, 2.0, 0.253229553653145, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5126367646595485, 6.9112, 6.9112, 77.32846344354104, 576893.0009884045, 576893.0009884045, 180244.3771620745], 
processed observation next is [0.0, 0.6086956521739131, 0.9181818181818181, 0.5616666666666668, 1.0, 1.0, 0.06653694206643121, 0.0, 1.0, -0.25, 1.0, 1.0, 0.30376680665649797, 0.0, 0.0, 0.5084288129206541, 0.21366407444014981, 0.21366407444014981, 0.4396204321026207], 
reward next is 0.5604, 
noisyNet noise sample is [array([0.72273636], dtype=float32), -2.0438714]. 
=============================================
[2019-03-23 19:37:12,517] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.0480654e-03 1.4446226e-08 9.9494779e-01 3.6271101e-07 3.7490427e-06], sum to 1.0000
[2019-03-23 19:37:12,524] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9856
[2019-03-23 19:37:12,529] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.5, 72.0, 1.0, 2.0, 0.5735142055988134, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9761508032753363, 6.911199999999999, 6.9112, 77.32845786454479, 1200578.012924847, 1200578.012924847, 272854.8279098536], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7642800.0000, 
sim time next is 7643400.0000, 
raw observation next is [25.68333333333333, 70.83333333333333, 1.0, 2.0, 0.6205140912819931, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9762607531403514, 6.911199999999999, 6.9112, 77.32846340900659, 1254029.114891142, 1254029.114891143, 279647.3407703634], 
processed observation next is [1.0, 0.4782608695652174, 0.8037878787878786, 0.7083333333333333, 1.0, 1.0, 0.5256426141024914, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9660867902005023, -8.881784197001253e-17, 0.0, 0.5084288126935927, 0.46445522773745995, 0.4644552277374604, 0.6820666848057644], 
reward next is 0.3179, 
noisyNet noise sample is [array([-0.6171329], dtype=float32), 0.21156909]. 
=============================================
[2019-03-23 19:37:16,886] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:37:16,887] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:37:16,905] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.8073871e-04 1.3601668e-10 9.9941933e-01 5.0815299e-09 2.6795627e-08], sum to 1.0000
[2019-03-23 19:37:16,920] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1135
[2019-03-23 19:37:16,926] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.6, 49.5, 1.0, 2.0, 0.3482158109610839, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6500426457658891, 6.911200000000001, 6.9112, 77.32846344354104, 756556.8638803451, 756556.8638803449, 176825.0011577747], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7749000.0000, 
sim time next is 7749600.0000, 
raw observation next is [21.23333333333333, 50.66666666666666, 1.0, 2.0, 0.3205532915814625, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5984027698897344, 6.911200000000001, 6.9112, 77.32846344354104, 696412.3618988699, 696412.3618988696, 168427.3124399787], 
processed observation next is [1.0, 0.6956521739130435, 0.6015151515151514, 0.5066666666666666, 1.0, 1.0, 0.1506916144768281, 0.0, 1.0, -0.25, 1.0, 1.0, 0.42628967127104916, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.25793050440698884, 0.2579305044069887, 0.41079832302433833], 
reward next is 0.5892, 
noisyNet noise sample is [array([-1.5761178], dtype=float32), 0.00087586086]. 
=============================================
[2019-03-23 19:37:16,937] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run9
[2019-03-23 19:37:20,670] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2851665e-03 7.6311582e-11 9.9871480e-01 4.7299280e-09 6.2445533e-09], sum to 1.0000
[2019-03-23 19:37:20,680] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8677
[2019-03-23 19:37:20,683] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.8, 45.0, 1.0, 2.0, 0.3744240325138488, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7094618937917658, 6.911199999999999, 6.9112, 77.32846344354104, 822418.8438105066, 822418.8438105069, 190291.2281456259], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7826400.0000, 
sim time next is 7827000.0000, 
raw observation next is [23.9, 45.16666666666666, 1.0, 2.0, 0.3412238734499169, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6473333062791813, 6.9112, 6.9112, 77.32846344354104, 750143.1150832915, 750143.1150832915, 182030.1496975934], 
processed observation next is [1.0, 0.6086956521739131, 0.7227272727272727, 0.45166666666666655, 1.0, 1.0, 0.1765298418123961, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4961904375416876, 0.0, 0.0, 0.5084288129206541, 0.27783078336418204, 0.27783078336418204, 0.44397597487217905], 
reward next is 0.5560, 
noisyNet noise sample is [array([0.6008841], dtype=float32), -0.5813879]. 
=============================================
[2019-03-23 19:37:20,695] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[42.888515]
 [43.20128 ]
 [43.45565 ]
 [43.955418]
 [45.269066]], R is [[43.39746094]
 [43.49935913]
 [43.60834503]
 [43.71160889]
 [43.80582428]].
[2019-03-23 19:37:21,210] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.0783000e-04 1.7228009e-11 9.9959213e-01 7.7342388e-10 2.5447259e-08], sum to 1.0000
[2019-03-23 19:37:21,218] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8505
[2019-03-23 19:37:21,223] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.3, 48.0, 1.0, 2.0, 0.3344717301895143, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6339482173723746, 6.9112, 6.9112, 77.32846344354104, 734768.0375710068, 734768.0375710068, 180179.353011764], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7837200.0000, 
sim time next is 7837800.0000, 
raw observation next is [23.11666666666667, 48.5, 1.0, 2.0, 0.2162705257285615, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4082657182324282, 6.911199999999999, 6.9112, 77.32846344354104, 473478.8372703359, 473478.8372703362, 156069.4477330275], 
processed observation next is [1.0, 0.7391304347826086, 0.6871212121212124, 0.485, 1.0, 1.0, 0.02033815716070187, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1546653117606117, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1753625323223466, 0.17536253232234675, 0.38065718959275], 
reward next is 0.6193, 
noisyNet noise sample is [array([-0.16654101], dtype=float32), -1.1270777]. 
=============================================
[2019-03-23 19:37:22,568] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:37:22,569] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:37:22,599] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run9
[2019-03-23 19:37:24,415] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:37:24,416] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:37:24,476] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run9
[2019-03-23 19:37:26,747] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:37:26,747] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:37:26,777] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.7663092e-03 8.0495931e-12 9.9623352e-01 5.4356137e-09 9.2004498e-08], sum to 1.0000
[2019-03-23 19:37:26,782] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4676
[2019-03-23 19:37:26,792] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.18333333333334, 92.66666666666666, 1.0, 2.0, 0.230232961189617, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4635066728995705, 6.9112, 6.9112, 77.32846344354104, 525345.3602960713, 525345.3602960713, 171939.328779201], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7930200.0000, 
sim time next is 7930800.0000, 
raw observation next is [21.1, 93.0, 1.0, 2.0, 0.229116677825812, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4611205797790869, 6.9112, 6.9112, 77.32846344354104, 522770.6323288757, 522770.6323288757, 171589.8516765531], 
processed observation next is [1.0, 0.8260869565217391, 0.5954545454545456, 0.93, 1.0, 1.0, 0.03639584728226498, 0.0, 1.0, -0.25, 1.0, 1.0, 0.230172256827267, 0.0, 0.0, 0.5084288129206541, 0.1936187527143984, 0.1936187527143984, 0.4185118333574466], 
reward next is 0.5815, 
noisyNet noise sample is [array([-0.5054868], dtype=float32), 2.2385757]. 
=============================================
[2019-03-23 19:37:26,815] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run9
[2019-03-23 19:37:27,433] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:37:27,433] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:37:27,441] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run9
[2019-03-23 19:37:27,513] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:37:27,513] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:37:27,521] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run9
[2019-03-23 19:37:27,563] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:37:27,564] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:37:27,588] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run9
[2019-03-23 19:37:27,821] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:37:27,822] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:37:27,840] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run9
[2019-03-23 19:37:27,903] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:37:27,903] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:37:27,918] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run9
[2019-03-23 19:37:27,945] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:37:27,946] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:37:27,961] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run9
[2019-03-23 19:37:27,993] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:37:27,994] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:37:28,005] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run9
[2019-03-23 19:37:28,065] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:37:28,065] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:37:28,072] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run9
[2019-03-23 19:37:28,175] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:37:28,176] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:37:28,179] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run9
[2019-03-23 19:37:28,232] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:37:28,232] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:37:28,261] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run9
[2019-03-23 19:37:28,357] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:37:28,358] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:37:28,364] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run9
[2019-03-23 19:37:30,463] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.2784296e-03 1.5667186e-10 9.9672145e-01 1.0606663e-08 1.1584889e-07], sum to 1.0000
[2019-03-23 19:37:30,470] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5263
[2019-03-23 19:37:30,473] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.33333333333334, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3352006693172532, 6.9112, 6.9112, 77.32846344354104, 386534.0548766736, 386534.0548766736, 150833.9096647075], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 22800.0000, 
sim time next is 23400.0000, 
raw observation next is [17.5, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3402348424738101, 6.9112, 6.9112, 77.32846344354104, 391990.3134290471, 391990.3134290471, 151768.1953714759], 
processed observation next is [1.0, 0.2608695652173913, 0.4318181818181818, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.05747834639115728, 0.0, 0.0, 0.5084288129206541, 0.14518159756631374, 0.14518159756631374, 0.3701663301743314], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3480228], dtype=float32), 2.6154375]. 
=============================================
[2019-03-23 19:37:33,752] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 19:37:33,754] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:37:33,754] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:37:33,755] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:37:33,756] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:37:33,757] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:37:33,758] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:37:33,756] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:37:33,759] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:37:33,761] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:37:33,760] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:37:33,780] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run69
[2019-03-23 19:37:33,807] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run69
[2019-03-23 19:37:33,808] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run69
[2019-03-23 19:37:33,831] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run69
[2019-03-23 19:37:33,854] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run69
[2019-03-23 19:37:39,219] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00613705], dtype=float32), 0.012239251]
[2019-03-23 19:37:39,220] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.0, 51.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3189031387708965, 6.9112, 6.9112, 77.32846344354104, 371010.6589083578, 371010.6589083578, 124946.2590258354]
[2019-03-23 19:37:39,222] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:37:39,226] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.0655402e-04 2.0393566e-06 9.9978310e-01 6.0213429e-06 2.2219749e-06], sampled 0.14938762732115685
[2019-03-23 19:37:48,284] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00613705], dtype=float32), 0.012239251]
[2019-03-23 19:37:48,285] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.7, 85.0, 1.0, 2.0, 0.2608642545883599, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5283439916875915, 6.911199999999999, 6.9112, 77.32846344354104, 593562.970648845, 593562.9706488453, 182790.584525497]
[2019-03-23 19:37:48,286] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:37:48,288] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0318168e-03 1.1403646e-09 9.9896789e-01 5.2121393e-08 3.9995899e-07], sampled 0.643126598812305
[2019-03-23 19:37:59,924] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00613705], dtype=float32), 0.012239251]
[2019-03-23 19:37:59,926] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.88305205333334, 70.91446291, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 348395.5922094298, 348395.5922094298, 145752.0014095673]
[2019-03-23 19:37:59,928] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:37:59,931] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.04234954e-04 3.41650860e-07 9.99893427e-01 1.36250299e-06
 6.71119267e-07], sampled 0.29051186166773835
[2019-03-23 19:38:18,405] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00613705], dtype=float32), 0.012239251]
[2019-03-23 19:38:18,405] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.06666666666667, 89.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3915448626650648, 6.9112, 6.9112, 95.55338769695034, 447607.5511889667, 447607.5511889667, 165871.101327016]
[2019-03-23 19:38:18,406] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:38:18,409] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.3485717e-04 9.9986441e-10 9.9986517e-01 1.9810566e-08 5.0809110e-08], sampled 0.001368661394662407
[2019-03-23 19:38:28,201] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00613705], dtype=float32), 0.012239251]
[2019-03-23 19:38:28,203] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.05730174333333, 92.00621656666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 343693.1599663359, 343693.1599663359, 141922.2709817203]
[2019-03-23 19:38:28,204] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:38:28,207] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.4427029e-05 2.6906440e-07 9.9990356e-01 1.1355411e-06 5.8142354e-07], sampled 0.18931920267064706
[2019-03-23 19:38:35,685] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00613705], dtype=float32), 0.012239251]
[2019-03-23 19:38:35,686] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.44356417, 100.0, 1.0, 2.0, 0.2517962148337005, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5096923415188537, 6.911200000000001, 6.9112, 95.55338769695034, 573639.2865532106, 573639.2865532102, 184530.3189964536]
[2019-03-23 19:38:35,689] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:38:35,692] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.3280948e-04 2.0490967e-11 9.9926716e-01 1.9165971e-09 2.6238144e-08], sampled 0.029338629343127143
[2019-03-23 19:38:58,053] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00613705], dtype=float32), 0.012239251]
[2019-03-23 19:38:58,054] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.01666666666667, 83.66666666666667, 1.0, 2.0, 0.2652865413470925, 0.0, 2.0, 0.0, 1.0, 2.0, 0.528010077155637, 6.911200000000001, 6.9112, 95.55338769695034, 602655.9596626692, 602655.9596626689, 180672.4172672211]
[2019-03-23 19:38:58,056] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:38:58,059] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.2610657e-03 4.1428576e-11 9.9873894e-01 3.8238475e-09 5.2043891e-08], sampled 0.7822165952950131
[2019-03-23 19:38:58,273] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00613705], dtype=float32), 0.012239251]
[2019-03-23 19:38:58,276] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.4, 85.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3918341820801904, 6.911200000000001, 6.9112, 95.55338769695034, 448304.8234624724, 448304.823462472, 165599.5162074847]
[2019-03-23 19:38:58,278] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:38:58,281] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.5496927e-04 2.7755631e-08 9.9984443e-01 2.6348656e-07 3.2970829e-07], sampled 0.23447361488588359
[2019-03-23 19:39:03,773] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00613705], dtype=float32), 0.012239251]
[2019-03-23 19:39:03,774] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.93333333333333, 83.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.354039469619766, 6.9112, 6.9112, 77.32846344354104, 406896.2375636079, 406896.2375636079, 154376.8396093675]
[2019-03-23 19:39:03,775] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:39:03,777] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.26486120e-04 1.24133726e-08 9.99873281e-01 1.24101120e-07
 1.63883797e-07], sampled 0.7992207819254115
[2019-03-23 19:39:09,631] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00613705], dtype=float32), 0.012239251]
[2019-03-23 19:39:09,632] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.84225957, 88.52702475, 1.0, 2.0, 0.224024235041835, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4483072654374281, 6.9112, 6.9112, 95.55338769695034, 510181.5244328065, 510181.5244328065, 173349.9714398105]
[2019-03-23 19:39:09,632] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:39:09,635] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.0370053e-05 5.1075159e-07 9.9991548e-01 2.4647779e-06 1.2165527e-06], sampled 0.8899289790377473
[2019-03-23 19:39:16,808] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3118.4412 2108966776.9376 369.0000
[2019-03-23 19:39:17,415] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3362.6880 2097887272.9722 178.0000
[2019-03-23 19:39:17,440] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3611.1458 2175141117.1546 246.0000
[2019-03-23 19:39:17,458] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3519.3611 2103795802.9354 179.0000
[2019-03-23 19:39:17,543] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2761.6519 2123882141.5843 757.0000
[2019-03-23 19:39:18,561] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1700000, evaluation results [1700000.0, 3611.1458384069288, 2175141117.1545634, 246.0, 3362.687957742132, 2097887272.9721599, 178.0, 3519.361102925371, 2103795802.935383, 179.0, 2761.651936081941, 2123882141.5843318, 757.0, 3118.4411890842534, 2108966776.937559, 369.0]
[2019-03-23 19:39:19,059] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9164135e-05 9.0615131e-08 9.9989855e-01 1.5269867e-06 5.9892744e-07], sum to 1.0000
[2019-03-23 19:39:19,069] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5633
[2019-03-23 19:39:19,074] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [15.5, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 283425.1615492334, 283425.1615492331, 118821.9305400684], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 246600.0000, 
sim time next is 247200.0000, 
raw observation next is [15.33333333333333, 96.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 284568.2171813726, 284568.2171813729, 119547.7842666626], 
processed observation next is [0.0, 0.8695652173913043, 0.3333333333333332, 0.96, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10539563599310095, 0.10539563599310109, 0.2915799616260063], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7555509], dtype=float32), -0.21486741]. 
=============================================
[2019-03-23 19:39:19,989] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4502562e-04 3.7718333e-08 9.9985409e-01 3.4837362e-07 5.3078344e-07], sum to 1.0000
[2019-03-23 19:39:19,996] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5570
[2019-03-23 19:39:20,001] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 57.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 304335.1904771002, 304335.1904771005, 133679.1270471537], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 217800.0000, 
sim time next is 218400.0000, 
raw observation next is [21.33333333333334, 54.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 301031.3108836804, 301031.3108836804, 131874.0826558755], 
processed observation next is [0.0, 0.5217391304347826, 0.6060606060606063, 0.5466666666666665, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.11149307810506683, 0.11149307810506683, 0.32164410403872074], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1805032], dtype=float32), 0.17778702]. 
=============================================
[2019-03-23 19:39:20,291] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.8210285e-04 8.7283958e-10 9.9961746e-01 8.7356948e-09 3.1560450e-07], sum to 1.0000
[2019-03-23 19:39:20,299] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2671
[2019-03-23 19:39:20,309] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.0, 70.5, 1.0, 2.0, 0.20302803514645, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3790088630453136, 6.9112, 6.9112, 77.32846344354104, 440969.1318102703, 440969.1318102703, 132864.3079754518], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 117000.0000, 
sim time next is 117600.0000, 
raw observation next is [17.33333333333334, 68.33333333333333, 1.0, 2.0, 0.2216221769496305, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4137200522613413, 6.9112, 6.9112, 77.32846344354104, 481374.8909579843, 481374.8909579843, 137078.4662328638], 
processed observation next is [1.0, 0.34782608695652173, 0.42424242424242453, 0.6833333333333332, 1.0, 1.0, 0.027027721187038098, 0.0, 1.0, -0.25, 1.0, 1.0, 0.16245721751620187, 0.0, 0.0, 0.5084288129206541, 0.1782869966511053, 0.1782869966511053, 0.33433772251918004], 
reward next is 0.6657, 
noisyNet noise sample is [array([0.19845071], dtype=float32), 0.31266275]. 
=============================================
[2019-03-23 19:39:21,429] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.7141418e-04 1.0964698e-08 9.9962592e-01 8.2903262e-07 1.7449483e-06], sum to 1.0000
[2019-03-23 19:39:21,437] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7763
[2019-03-23 19:39:21,450] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.5, 46.0, 1.0, 2.0, 0.2120543731744519, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3958590586894175, 6.9112, 6.9112, 77.32846344354104, 460583.2794035059, 460583.2794035059, 139171.580498525], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 131400.0000, 
sim time next is 132000.0000, 
raw observation next is [21.66666666666667, 46.0, 1.0, 2.0, 0.2166902700416031, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4045132625265717, 6.9112, 6.9112, 77.32846344354104, 470657.3472551859, 470657.3472551859, 141035.2052104647], 
processed observation next is [1.0, 0.5217391304347826, 0.6212121212121214, 0.46, 1.0, 1.0, 0.02086283755200386, 0.0, 1.0, -0.25, 1.0, 1.0, 0.14930466075224533, 0.0, 0.0, 0.5084288129206541, 0.17431753602043923, 0.17431753602043923, 0.34398830539137726], 
reward next is 0.6560, 
noisyNet noise sample is [array([0.12661037], dtype=float32), 0.17508274]. 
=============================================
[2019-03-23 19:39:21,470] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[25.864506]
 [28.097475]
 [29.059826]
 [29.414268]
 [29.855358]], R is [[23.92965126]
 [24.35091209]
 [24.76194382]
 [25.15004349]
 [25.52820969]].
[2019-03-23 19:39:22,490] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.5392319e-04 5.2121942e-07 9.9982613e-01 5.9842082e-06 1.3512424e-05], sum to 1.0000
[2019-03-23 19:39:22,498] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2301
[2019-03-23 19:39:22,502] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.16666666666667, 51.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 292483.5829781686, 292483.5829781683, 108271.4789234022], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 157800.0000, 
sim time next is 158400.0000, 
raw observation next is [19.0, 52.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 289639.4188183566, 289639.4188183566, 107727.8854188013], 
processed observation next is [1.0, 0.8695652173913043, 0.5, 0.52, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.10727385882161355, 0.10727385882161355, 0.26275094004585686], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.2269132], dtype=float32), 1.5253758]. 
=============================================
[2019-03-23 19:39:22,777] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.1318074e-05 2.8865220e-06 9.9989951e-01 9.3598628e-06 6.9404850e-06], sum to 1.0000
[2019-03-23 19:39:22,788] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0020
[2019-03-23 19:39:22,792] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.66666666666667, 66.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 265670.3614706471, 265670.3614706471, 102373.7609504989], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 163200.0000, 
sim time next is 163800.0000, 
raw observation next is [16.5, 67.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 261113.4381194207, 261113.4381194204, 101609.8187685312], 
processed observation next is [1.0, 0.9130434782608695, 0.38636363636363635, 0.675, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09670868078497062, 0.09670868078497052, 0.24782882626471026], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8046322], dtype=float32), -1.0808536]. 
=============================================
[2019-03-23 19:39:31,512] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.4056314e-04 6.4688203e-07 9.9944943e-01 7.0842407e-06 2.3005325e-06], sum to 1.0000
[2019-03-23 19:39:31,523] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3202
[2019-03-23 19:39:31,526] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.66666666666667, 49.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 251785.8892265645, 251785.8892265642, 98478.06294938544], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 330000.0000, 
sim time next is 330600.0000, 
raw observation next is [18.33333333333333, 50.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 247561.9063356163, 247561.906335616, 97498.86596880629], 
processed observation next is [0.0, 0.8260869565217391, 0.4696969696969695, 0.505, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09168959493911716, 0.09168959493911703, 0.23780211211903973], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9082928], dtype=float32), 1.2446679]. 
=============================================
[2019-03-23 19:39:37,161] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.1825961e-04 1.6250498e-05 9.9959642e-01 3.2206168e-05 3.6878522e-05], sum to 1.0000
[2019-03-23 19:39:37,167] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3418
[2019-03-23 19:39:37,176] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.33333333333334, 67.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3386812978129602, 6.911200000000001, 6.9112, 77.32846344354104, 390621.9738593232, 390621.973859323, 151176.5439679383], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 582000.0000, 
sim time next is 582600.0000, 
raw observation next is [21.16666666666666, 68.16666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3372092646842562, 6.9112, 6.9112, 77.32846344354104, 389002.9354973461, 389002.9354973461, 150925.0489376053], 
processed observation next is [1.0, 0.7391304347826086, 0.5984848484848482, 0.6816666666666665, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.053156092406080324, 0.0, 0.0, 0.5084288129206541, 0.14407516129531336, 0.14407516129531336, 0.36810987545757384], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3166424], dtype=float32), 0.36813253]. 
=============================================
[2019-03-23 19:39:46,281] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.4643171e-04 9.2371168e-09 9.9965310e-01 3.1632371e-08 4.9819727e-07], sum to 1.0000
[2019-03-23 19:39:46,285] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3626
[2019-03-23 19:39:46,290] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [15.83333333333333, 89.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 282836.6987694572, 282836.6987694569, 116410.9026748238], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 616200.0000, 
sim time next is 616800.0000, 
raw observation next is [15.66666666666667, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 277795.798777292, 277795.798777292, 114898.1177852589], 
processed observation next is [1.0, 0.13043478260869565, 0.3484848484848486, 0.9, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.10288733288047852, 0.10288733288047852, 0.2802393116713632], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.30627704], dtype=float32), 0.5552196]. 
=============================================
[2019-03-23 19:39:47,007] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.5657954e-03 1.1969407e-08 9.9542671e-01 1.7261822e-06 5.7278962e-06], sum to 1.0000
[2019-03-23 19:39:47,017] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3512
[2019-03-23 19:39:47,021] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.0, 78.0, 1.0, 2.0, 0.2723557652726755, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5285882524827309, 6.9112, 6.9112, 77.32846344354104, 608946.6629538839, 608946.6629538839, 171237.4154531211], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 637200.0000, 
sim time next is 637800.0000, 
raw observation next is [20.33333333333334, 76.5, 1.0, 2.0, 0.3148353116244948, 0.0, 2.0, 0.0, 1.0, 2.0, 0.613137780360592, 6.911199999999999, 6.9112, 77.32846344354104, 705701.734411776, 705701.7344117762, 181831.6312722975], 
processed observation next is [1.0, 0.391304347826087, 0.5606060606060609, 0.765, 1.0, 1.0, 0.14354413953061848, 0.0, 1.0, -0.25, 1.0, 1.0, 0.44733968622941717, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2613710127451022, 0.26137101274510227, 0.4434917835909695], 
reward next is 0.5565, 
noisyNet noise sample is [array([-0.17257732], dtype=float32), 1.7132033]. 
=============================================
[2019-03-23 19:39:49,489] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.6922548e-04 1.1542450e-06 9.9896264e-01 2.6963386e-05 4.0026483e-05], sum to 1.0000
[2019-03-23 19:39:49,496] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1924
[2019-03-23 19:39:49,508] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3172868590121657, 6.9112, 6.9112, 77.32846344354104, 367016.7922733523, 367016.7922733523, 147596.6136083416], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 694800.0000, 
sim time next is 695400.0000, 
raw observation next is [17.83333333333333, 89.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.314926712317668, 6.9112, 6.9112, 77.32846344354104, 364391.1046602378, 364391.1046602378, 147223.8086733925], 
processed observation next is [1.0, 0.043478260869565216, 0.44696969696969674, 0.8900000000000001, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.021323874739525732, 0.0, 0.0, 0.5084288129206541, 0.13495966839268067, 0.13495966839268067, 0.3590824601790061], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.6653074], dtype=float32), -0.8717187]. 
=============================================
[2019-03-23 19:39:52,703] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.6007670e-03 1.3734386e-07 9.9736017e-01 5.4367274e-06 3.3405973e-05], sum to 1.0000
[2019-03-23 19:39:52,712] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1357
[2019-03-23 19:39:52,719] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.0, 55.0, 1.0, 2.0, 0.7682746044509797, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9738549659333797, 6.9112, 6.9112, 77.32846344354104, 1424006.288934554, 1424006.288934554, 299231.2036197545], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 746400.0000, 
sim time next is 747000.0000, 
raw observation next is [28.0, 55.0, 1.0, 2.0, 0.7944345385806981, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9739374118015597, 6.911199999999999, 6.9112, 77.32846344354104, 1453812.404270687, 1453812.404270688, 303534.2313785718], 
processed observation next is [1.0, 0.6521739130434783, 0.9090909090909091, 0.55, 1.0, 1.0, 0.7430431732258727, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9627677311450854, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5384490386187729, 0.5384490386187734, 0.7403273936062728], 
reward next is 0.2597, 
noisyNet noise sample is [array([0.4293291], dtype=float32), 0.14458558]. 
=============================================
[2019-03-23 19:39:52,746] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[25.993044]
 [26.109043]
 [26.067097]
 [26.137829]
 [26.165169]], R is [[25.95259476]
 [25.96323776]
 [25.98933029]
 [26.00873566]
 [26.0222683 ]].
[2019-03-23 19:39:53,933] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.6606599e-02 4.5834871e-11 9.6339339e-01 3.4622305e-09 2.3441563e-08], sum to 1.0000
[2019-03-23 19:39:53,942] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8793
[2019-03-23 19:39:53,949] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 58.0, 1.0, 2.0, 0.2362431001989399, 0.0, 2.0, 0.0, 1.0, 2.0, 0.476976983497164, 6.9112, 6.9112, 77.32846344354104, 539094.7020128143, 539094.7020128143, 174502.5474521094], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 758400.0000, 
sim time next is 759000.0000, 
raw observation next is [27.0, 58.0, 1.0, 2.0, 0.237490682105942, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4794963875394036, 6.9112, 6.9112, 77.32846344354104, 541943.105891519, 541943.105891519, 174776.2977123512], 
processed observation next is [1.0, 0.782608695652174, 0.8636363636363636, 0.58, 1.0, 1.0, 0.0468633526324275, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2564234107705766, 0.0, 0.0, 0.5084288129206541, 0.20071966884871073, 0.20071966884871073, 0.42628365295695414], 
reward next is 0.5737, 
noisyNet noise sample is [array([0.56952816], dtype=float32), 1.0472572]. 
=============================================
[2019-03-23 19:39:53,962] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[45.846977]
 [45.304726]
 [44.202038]
 [43.32078 ]
 [41.58321 ]], R is [[45.87951279]
 [45.99510193]
 [46.10911942]
 [46.22208405]
 [46.33526993]].
[2019-03-23 19:39:54,612] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.3745126e-03 1.4344876e-13 9.9462551e-01 3.2460045e-11 1.2402411e-09], sum to 1.0000
[2019-03-23 19:39:54,620] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6586
[2019-03-23 19:39:54,624] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.0, 88.0, 1.0, 2.0, 0.2000654128698141, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3957290392860353, 6.911199999999999, 6.9112, 77.32846344354104, 452895.6870338526, 452895.6870338529, 161401.8652801135], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 784800.0000, 
sim time next is 785400.0000, 
raw observation next is [20.0, 88.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3935409971529484, 6.9112, 6.9112, 77.32846344354104, 450470.500832469, 450470.500832469, 161044.6609973344], 
processed observation next is [0.0, 0.08695652173913043, 0.5454545454545454, 0.8800000000000001, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.13362999593278344, 0.0, 0.0, 0.5084288129206541, 0.1668409262342478, 0.1668409262342478, 0.39279185609105954], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.35973936], dtype=float32), 1.1602812]. 
=============================================
[2019-03-23 19:40:01,407] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.7210192e-04 1.0972383e-14 9.9982786e-01 1.4729086e-11 6.8367073e-10], sum to 1.0000
[2019-03-23 19:40:01,414] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0393
[2019-03-23 19:40:01,421] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 83.0, 1.0, 2.0, 0.236744286323743, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4780749975071036, 6.9112, 6.9112, 77.32846344354104, 540220.7314226032, 540220.7314226032, 174706.3070435964], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 903600.0000, 
sim time next is 904200.0000, 
raw observation next is [23.5, 80.0, 1.0, 2.0, 0.2390101065631708, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4828465506677457, 6.9112, 6.9112, 77.32846344354104, 545338.8459045241, 545338.8459045241, 175427.1291302573], 
processed observation next is [0.0, 0.4782608695652174, 0.7045454545454546, 0.8, 1.0, 1.0, 0.04876263320396347, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2612093580967796, 0.0, 0.0, 0.5084288129206541, 0.2019773503350089, 0.2019773503350089, 0.42787104665916414], 
reward next is 0.5721, 
noisyNet noise sample is [array([0.8744106], dtype=float32), 0.8339138]. 
=============================================
[2019-03-23 19:40:07,064] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1622225e-04 4.3077311e-08 9.9978310e-01 4.7591035e-07 2.4505266e-07], sum to 1.0000
[2019-03-23 19:40:07,066] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5122
[2019-03-23 19:40:07,072] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 238292.6974644286, 238292.6974644288, 97447.32129185295], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1024200.0000, 
sim time next is 1024800.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 239906.6135485761, 239906.6135485761, 97746.30124366208], 
processed observation next is [1.0, 0.8695652173913043, 0.22727272727272727, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.08885430131428744, 0.08885430131428744, 0.2384056127894197], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.32712698], dtype=float32), 0.38551143]. 
=============================================
[2019-03-23 19:40:07,523] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 19:40:07,524] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:40:07,524] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:40:07,524] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:40:07,525] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:40:07,526] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:40:07,525] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:40:07,529] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:40:07,530] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:40:07,527] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:40:07,532] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:40:07,550] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run70
[2019-03-23 19:40:07,551] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run70
[2019-03-23 19:40:07,600] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run70
[2019-03-23 19:40:07,601] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run70
[2019-03-23 19:40:07,601] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run70
[2019-03-23 19:40:15,930] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00618976], dtype=float32), 0.012323011]
[2019-03-23 19:40:15,931] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.58507263, 58.34697156999999, 1.0, 2.0, 0.2051542159815125, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3883596579254933, 6.911199999999999, 6.9112, 95.55338769695034, 450073.548098588, 450073.5480985884, 159451.4562566223]
[2019-03-23 19:40:15,932] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:40:15,936] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.4652064e-05 3.9131137e-10 9.9998534e-01 4.2483599e-09 1.7662168e-09], sampled 0.1159417848715516
[2019-03-23 19:40:29,842] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00618976], dtype=float32), 0.012323011]
[2019-03-23 19:40:29,842] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.46666666666667, 67.66666666666667, 1.0, 2.0, 0.2519970615142234, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5092431415850015, 6.9112, 6.9112, 95.55338769695034, 574862.3207625155, 574862.3207625155, 183302.2968677836]
[2019-03-23 19:40:29,843] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:40:29,845] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.0524956e-05 2.8685164e-11 9.9996948e-01 9.6519603e-10 1.1897549e-09], sampled 0.8374656862251207
[2019-03-23 19:40:34,093] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00618976], dtype=float32), 0.012323011]
[2019-03-23 19:40:34,094] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [12.98333333333333, 83.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 202475.037721138, 202475.0377211376, 91355.81038449574]
[2019-03-23 19:40:34,094] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:40:34,098] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.8718112e-05 5.3605312e-08 9.9997091e-01 2.6185845e-07 3.9424357e-08], sampled 0.8859700394561228
[2019-03-23 19:41:15,505] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00618976], dtype=float32), 0.012323011]
[2019-03-23 19:41:15,506] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.733624295, 94.12283277, 1.0, 2.0, 0.2859051066396427, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5791446392387527, 6.911200000000001, 6.9112, 95.55338769695034, 648964.4865334007, 648964.4865334004, 195079.8530779904]
[2019-03-23 19:41:15,508] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:41:15,511] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.4965606e-04 1.0732651e-13 9.9985027e-01 2.6412834e-11 2.7640648e-10], sampled 0.28629794821405874
[2019-03-23 19:41:24,358] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00618976], dtype=float32), 0.012323011]
[2019-03-23 19:41:24,359] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.8, 56.5, 1.0, 2.0, 0.4770805829080378, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9323019877042059, 6.954090438004982, 6.9112, 77.32833864084199, 1088125.955154709, 1074196.040633795, 243867.0665024553]
[2019-03-23 19:41:24,363] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:41:24,366] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.7929504e-04 6.7388382e-12 9.9932075e-01 2.0944140e-09 2.1732783e-08], sampled 0.9620715311301979
[2019-03-23 19:41:26,197] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00618976], dtype=float32), 0.012323011]
[2019-03-23 19:41:26,199] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.8, 80.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 288844.2991395907, 288844.2991395904, 117792.9838111804]
[2019-03-23 19:41:26,201] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:41:26,205] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.64663754e-05 1.56141795e-07 9.99952555e-01 6.76480965e-07
 1.10251065e-07], sampled 0.8651700565319872
[2019-03-23 19:41:41,408] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00618976], dtype=float32), 0.012323011]
[2019-03-23 19:41:41,409] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.68333333333333, 76.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 241616.809699609, 241616.8096996087, 98917.0327829162]
[2019-03-23 19:41:41,412] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:41:41,414] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.6544009e-05 3.9632036e-07 9.9993145e-01 1.4252079e-06 2.2777481e-07], sampled 0.9505866227279567
[2019-03-23 19:41:51,289] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2761.7161 2123936198.5488 758.0000
[2019-03-23 19:41:51,438] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00618976], dtype=float32), 0.012323011]
[2019-03-23 19:41:51,439] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.7, 93.0, 1.0, 2.0, 0.3783033418921443, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7598198817834037, 6.9112, 6.9112, 77.32846344354104, 863051.7402242526, 863051.7402242526, 211233.3248750209]
[2019-03-23 19:41:51,440] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:41:51,442] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.3899752e-04 3.0135429e-13 9.9966097e-01 1.0564111e-10 1.4446818e-09], sampled 0.19550845547217444
[2019-03-23 19:41:51,753] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3120.3682 2108933698.9926 368.0000
[2019-03-23 19:41:51,801] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3613.2829 2175201263.4078 247.0000
[2019-03-23 19:41:51,827] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3519.8688 2104065818.8031 178.0000
[2019-03-23 19:41:51,882] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3361.7345 2098001413.6555 179.0000
[2019-03-23 19:41:52,900] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1725000, evaluation results [1725000.0, 3613.2828546445453, 2175201263.4078474, 247.0, 3361.7344887442896, 2098001413.6555188, 179.0, 3519.8687787924955, 2104065818.8031247, 178.0, 2761.7160734650415, 2123936198.5487998, 758.0, 3120.3681648522256, 2108933698.9926417, 368.0]
[2019-03-23 19:41:56,253] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4858168e-04 1.2166229e-12 9.9985135e-01 1.5015404e-09 1.2527219e-08], sum to 1.0000
[2019-03-23 19:41:56,262] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5425
[2019-03-23 19:41:56,269] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 69.0, 1.0, 2.0, 0.352961801352818, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6945847989447529, 6.9112, 6.9112, 77.32846344354104, 796769.668313924, 796769.668313924, 195047.1253796287], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1087800.0000, 
sim time next is 1088400.0000, 
raw observation next is [22.0, 69.0, 1.0, 2.0, 0.3163574527480676, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6224669185848843, 6.9112, 6.9112, 77.32846344354104, 714016.6628996583, 714016.6628996583, 184997.9615742349], 
processed observation next is [1.0, 0.6086956521739131, 0.6363636363636364, 0.69, 1.0, 1.0, 0.14544681593508446, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4606670265498348, 0.0, 0.0, 0.5084288129206541, 0.26445061588876234, 0.26445061588876234, 0.45121454042496323], 
reward next is 0.5488, 
noisyNet noise sample is [array([0.11475894], dtype=float32), -0.88340205]. 
=============================================
[2019-03-23 19:41:57,511] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.3264982e-04 1.1851936e-05 9.9911171e-01 3.4512210e-05 9.3139297e-06], sum to 1.0000
[2019-03-23 19:41:57,514] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3275
[2019-03-23 19:41:57,520] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 78.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3060285956764096, 6.9112, 6.9112, 77.32846344354104, 354444.8312208222, 354444.8312208222, 145868.1797078158], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1119000.0000, 
sim time next is 1119600.0000, 
raw observation next is [19.0, 78.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3043203095038469, 6.911200000000001, 6.9112, 77.32846344354104, 352467.9116858825, 352467.9116858822, 145678.4105708193], 
processed observation next is [1.0, 1.0, 0.5, 0.78, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.00617187071978133, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1305436709947713, 0.13054367099477118, 0.35531319651419346], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.31085625], dtype=float32), -0.15633702]. 
=============================================
[2019-03-23 19:42:01,448] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.4534810e-04 3.1088645e-09 9.9934608e-01 2.6229421e-07 8.3523682e-06], sum to 1.0000
[2019-03-23 19:42:01,460] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8181
[2019-03-23 19:42:01,468] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 66.0, 1.0, 2.0, 0.6817695903039065, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9790820476209042, 6.9112, 6.9112, 77.32846344354104, 1321414.597890571, 1321414.597890571, 291051.1505376746], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1183800.0000, 
sim time next is 1184400.0000, 
raw observation next is [27.0, 66.0, 1.0, 2.0, 0.6827645287885631, 0.0, 2.0, 0.0, 1.0, 2.0, 0.979060760377988, 6.9112, 6.9112, 77.32846344354104, 1322564.563493121, 1322564.563493121, 291180.3359266825], 
processed observation next is [1.0, 0.7391304347826086, 0.8636363636363636, 0.66, 1.0, 1.0, 0.6034556609857038, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9700868005399828, 0.0, 0.0, 0.5084288129206541, 0.4898387272196744, 0.4898387272196744, 0.7101959412845915], 
reward next is 0.2898, 
noisyNet noise sample is [array([0.78715247], dtype=float32), 1.2885551]. 
=============================================
[2019-03-23 19:42:06,105] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.2181981e-03 5.3613596e-11 9.9478096e-01 2.5025068e-07 6.4631871e-07], sum to 1.0000
[2019-03-23 19:42:06,116] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8699
[2019-03-23 19:42:06,123] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.16666666666666, 61.33333333333334, 1.0, 2.0, 0.7040573986543114, 0.0, 2.0, 0.0, 1.0, 2.0, 0.975781616853921, 6.911200000000001, 6.9112, 77.32846344354104, 1349519.811921085, 1349519.811921085, 291260.6611125359], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1270200.0000, 
sim time next is 1270800.0000, 
raw observation next is [27.0, 62.0, 1.0, 2.0, 0.7365227848718027, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9756070504843879, 6.911199999999999, 6.9112, 77.32846344354104, 1386640.697527892, 1386640.697527893, 296057.6639881194], 
processed observation next is [1.0, 0.7391304347826086, 0.8636363636363636, 0.62, 1.0, 1.0, 0.6706534810897532, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9651529292634112, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.513570628714034, 0.5135706287140344, 0.7220918633856571], 
reward next is 0.2779, 
noisyNet noise sample is [array([0.03082821], dtype=float32), -0.2811689]. 
=============================================
[2019-03-23 19:42:06,808] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.3571286e-04 7.8696002e-15 9.9966431e-01 1.6777725e-12 3.3913362e-11], sum to 1.0000
[2019-03-23 19:42:06,817] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8622
[2019-03-23 19:42:06,825] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.33333333333333, 82.33333333333334, 1.0, 2.0, 0.269323727180311, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5455690994212762, 6.9112, 6.9112, 77.32846344354104, 611718.4280815541, 611718.4280815541, 185691.9805885572], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1536600.0000, 
sim time next is 1537200.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.2642225356076102, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5351930391783174, 6.911200000000001, 6.9112, 77.32846344354104, 600927.1305036757, 600927.1305036753, 183848.0270447864], 
processed observation next is [0.0, 0.8260869565217391, 0.7272727272727273, 0.83, 1.0, 1.0, 0.08027816950951276, 0.0, 1.0, -0.25, 1.0, 1.0, 0.33599005596902487, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22256560389025024, 0.22256560389025012, 0.44840982206045465], 
reward next is 0.5516, 
noisyNet noise sample is [array([-1.3659283], dtype=float32), -0.77058256]. 
=============================================
[2019-03-23 19:42:10,507] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6758723e-02 6.0733286e-11 9.8323846e-01 1.2653699e-07 2.7069614e-06], sum to 1.0000
[2019-03-23 19:42:10,516] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3943
[2019-03-23 19:42:10,524] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 84.83333333333334, 1.0, 2.0, 0.6416157514570232, 0.0, 2.0, 0.0, 1.0, 2.0, 0.967574952639677, 6.911199999999999, 6.9112, 77.32843725304465, 1280870.325992424, 1280870.325992424, 273820.1030358101], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1354200.0000, 
sim time next is 1354800.0000, 
raw observation next is [22.0, 86.66666666666667, 1.0, 2.0, 0.5453268981889174, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9626251312338358, 6.921869958023215, 6.9112, 77.32843710624306, 1170808.793183298, 1167343.410236015, 261021.9172948334], 
processed observation next is [1.0, 0.6956521739130435, 0.6363636363636364, 0.8666666666666667, 1.0, 1.0, 0.43165862273614675, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9466073303340512, 0.0010669958023214576, 0.0, 0.5084286397549069, 0.43363288636418446, 0.43234941119852405, 0.6366388226703253], 
reward next is 0.3100, 
noisyNet noise sample is [array([0.7303037], dtype=float32), -0.66585803]. 
=============================================
[2019-03-23 19:42:12,350] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.2993212e-03 3.0729417e-14 9.9270058e-01 9.3719435e-11 8.3461245e-08], sum to 1.0000
[2019-03-23 19:42:12,358] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4994
[2019-03-23 19:42:12,365] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 83.0, 1.0, 2.0, 0.2783444675381308, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5633600044223629, 6.911200000000001, 6.9112, 77.32846344354104, 629184.3649028857, 629184.3649028854, 189483.2537506149], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1530000.0000, 
sim time next is 1530600.0000, 
raw observation next is [25.16666666666667, 82.33333333333334, 1.0, 2.0, 0.2809140393395031, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5684198987813707, 6.9112, 6.9112, 77.32846344354104, 634482.2191570983, 634482.2191570983, 190365.981936301], 
processed observation next is [0.0, 0.7391304347826086, 0.7803030303030305, 0.8233333333333335, 1.0, 1.0, 0.10114254917437886, 0.0, 1.0, -0.25, 1.0, 1.0, 0.383456998259101, 0.0, 0.0, 0.5084288129206541, 0.234993414502629, 0.234993414502629, 0.4643072730153683], 
reward next is 0.5357, 
noisyNet noise sample is [array([-1.6251916], dtype=float32), 2.5623357]. 
=============================================
[2019-03-23 19:42:34,553] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.5658360e-03 1.2853049e-04 9.9573529e-01 2.6114960e-04 3.0909941e-04], sum to 1.0000
[2019-03-23 19:42:34,561] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6928
[2019-03-23 19:42:34,565] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.0, 67.83333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 206863.7607797788, 206863.7607797785, 86922.32665331995], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1815000.0000, 
sim time next is 1815600.0000, 
raw observation next is [14.0, 68.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 205950.4678071891, 205950.4678071891, 86857.24357916428], 
processed observation next is [1.0, 0.0, 0.2727272727272727, 0.6866666666666668, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.07627795103969967, 0.07627795103969967, 0.21184693555893727], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.06629369], dtype=float32), 1.3629271]. 
=============================================
[2019-03-23 19:42:34,987] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.1604917e-04 3.3457043e-06 9.9917114e-01 3.2855278e-05 7.6579076e-05], sum to 1.0000
[2019-03-23 19:42:34,991] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6881
[2019-03-23 19:42:34,997] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.66666666666667, 50.0, 1.0, 2.0, 0.2109230077087011, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3937470472198997, 6.9112, 6.9112, 77.32846344354104, 458124.7895167906, 458124.7895167906, 133132.250167654], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1851600.0000, 
sim time next is 1852200.0000, 
raw observation next is [20.0, 49.0, 1.0, 2.0, 0.2131887839460737, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3979767550778427, 6.911199999999999, 6.9112, 77.32846344354104, 463048.3993105945, 463048.3993105948, 134288.7185893529], 
processed observation next is [1.0, 0.43478260869565216, 0.5454545454545454, 0.49, 1.0, 1.0, 0.016485979932592126, 0.0, 1.0, -0.25, 1.0, 1.0, 0.13996679296834671, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17149940715207204, 0.17149940715207213, 0.3275334599740315], 
reward next is 0.6725, 
noisyNet noise sample is [array([0.22267003], dtype=float32), -0.98025376]. 
=============================================
[2019-03-23 19:42:35,579] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.7005544e-04 6.0432558e-06 9.9958867e-01 2.7538619e-05 7.6550341e-06], sum to 1.0000
[2019-03-23 19:42:35,593] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3925
[2019-03-23 19:42:35,596] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 60.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 285346.4438153273, 285346.4438153273, 112592.7175762656], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1990800.0000, 
sim time next is 1991400.0000, 
raw observation next is [18.83333333333334, 60.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 284951.2250776177, 284951.2250776177, 112103.4309352733], 
processed observation next is [0.0, 0.043478260869565216, 0.4924242424242427, 0.6066666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.10553749076948803, 0.10553749076948803, 0.2734230022811544], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.98001266], dtype=float32), 0.7674614]. 
=============================================
[2019-03-23 19:42:41,466] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 19:42:41,468] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:42:41,469] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:42:41,469] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:42:41,469] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:42:41,470] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:42:41,470] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:42:41,471] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:42:41,472] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:42:41,473] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:42:41,475] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:42:41,497] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run71
[2019-03-23 19:42:41,522] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run71
[2019-03-23 19:42:41,523] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run71
[2019-03-23 19:42:41,578] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run71
[2019-03-23 19:42:41,612] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run71
[2019-03-23 19:42:52,671] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00588543], dtype=float32), 0.012574819]
[2019-03-23 19:42:52,672] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 94.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3900188571136494, 6.9112, 6.9112, 77.32846344354104, 447133.3248828492, 447133.3248828492, 159966.3838946573]
[2019-03-23 19:42:52,673] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:42:52,675] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.8229424e-04 4.0560555e-09 9.9961710e-01 1.7339852e-07 5.0955572e-07], sampled 0.4962735863710741
[2019-03-23 19:43:08,445] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00588543], dtype=float32), 0.012574819]
[2019-03-23 19:43:08,448] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.95187532333334, 97.77965093666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 316078.4097390132, 316078.4097390128, 128929.8093260595]
[2019-03-23 19:43:08,449] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:43:08,452] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.6280800e-04 5.6986600e-08 9.9963462e-01 1.0513240e-06 1.4669956e-06], sampled 0.9888889962758171
[2019-03-23 19:43:33,182] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00588543], dtype=float32), 0.012574819]
[2019-03-23 19:43:33,183] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.05, 63.66666666666667, 1.0, 2.0, 0.231736558319909, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4651828099452637, 6.9112, 6.9112, 95.55338769695034, 528353.1192539564, 528353.1192539564, 175904.1561028819]
[2019-03-23 19:43:33,185] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:43:33,188] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.3006686e-03 2.7052895e-09 9.9869722e-01 2.5190113e-07 1.9160843e-06], sampled 0.12324495938990698
[2019-03-23 19:44:01,813] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00588543], dtype=float32), 0.012574819]
[2019-03-23 19:44:01,814] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.0, 69.0, 1.0, 2.0, 0.2109058609623845, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4189297412495098, 6.9112, 6.9112, 95.55338769695034, 478553.9704080362, 478553.9704080362, 168900.2777837907]
[2019-03-23 19:44:01,816] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:44:01,820] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.4423734e-04 1.4914515e-06 9.9973994e-01 9.9202362e-06 4.4205422e-06], sampled 0.7390258193319165
[2019-03-23 19:44:24,623] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2759.8721 2123664788.1010 755.0000
[2019-03-23 19:44:25,215] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3354.7169 2097623101.0090 182.0000
[2019-03-23 19:44:25,528] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3119.6572 2108491075.9015 367.0000
[2019-03-23 19:44:25,579] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3517.5491 2103620122.4795 180.0000
[2019-03-23 19:44:25,635] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3612.1512 2174713216.1437 247.0000
[2019-03-23 19:44:26,650] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1750000, evaluation results [1750000.0, 3612.1512472676345, 2174713216.143671, 247.0, 3354.716883458187, 2097623101.0090027, 182.0, 3517.5490689306785, 2103620122.4794862, 180.0, 2759.8721109144776, 2123664788.1010156, 755.0, 3119.6571757371457, 2108491075.9014628, 367.0]
[2019-03-23 19:44:28,318] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1630411e-03 5.3396980e-05 9.9832934e-01 2.7869284e-04 1.7551862e-04], sum to 1.0000
[2019-03-23 19:44:28,323] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6392
[2019-03-23 19:44:28,328] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 64.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3050863373019086, 6.911200000000001, 6.9112, 77.32846344354104, 353375.827638871, 353375.8276388707, 145741.3013104187], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1983600.0000, 
sim time next is 1984200.0000, 
raw observation next is [20.66666666666667, 64.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3030984522151501, 6.911199999999999, 6.9112, 77.32846344354104, 351297.2333974668, 351297.2333974671, 145288.5053659957], 
processed observation next is [1.0, 1.0, 0.575757575757576, 0.6466666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.004426360307357277, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13011008644350625, 0.13011008644350633, 0.35436220820974557], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4436228], dtype=float32), -0.55879843]. 
=============================================
[2019-03-23 19:44:30,440] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.0886676e-04 1.4831187e-05 9.9950600e-01 5.2585940e-05 1.7627090e-05], sum to 1.0000
[2019-03-23 19:44:30,449] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4084
[2019-03-23 19:44:30,452] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.83333333333334, 48.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 330247.0308303386, 330247.0308303386, 141050.9469006171], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2033400.0000, 
sim time next is 2034000.0000, 
raw observation next is [23.0, 47.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 331890.5854435464, 331890.5854435461, 141282.176993375], 
processed observation next is [0.0, 0.5652173913043478, 0.6818181818181818, 0.47, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12292243905316534, 0.12292243905316523, 0.3445906755935976], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3203082], dtype=float32), 1.1747781]. 
=============================================
[2019-03-23 19:44:30,477] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[-6.284622 ]
 [-6.259006 ]
 [-6.216168 ]
 [-6.1655803]
 [-6.136453 ]], R is [[-6.30536652]
 [-6.24231291]
 [-6.17988968]
 [-6.11809063]
 [-6.05690956]].
[2019-03-23 19:44:34,575] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.4358324e-03 4.1258404e-06 9.9632013e-01 3.5053192e-05 2.0490316e-04], sum to 1.0000
[2019-03-23 19:44:34,583] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3726
[2019-03-23 19:44:34,590] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.33333333333333, 64.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3387445756772397, 6.911199999999999, 6.9112, 77.32846344354104, 394103.4632867638, 394103.4632867641, 130019.2244300967], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2364000.0000, 
sim time next is 2364600.0000, 
raw observation next is [18.66666666666667, 62.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3384253872189094, 6.911200000000001, 6.9112, 77.32846344354104, 393731.9615209153, 393731.961520915, 130189.0703174734], 
processed observation next is [1.0, 0.34782608695652173, 0.4848484848484851, 0.62, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.05489341031272775, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14582665241515383, 0.1458266524151537, 0.3175343178474961], 
reward next is 0.0000, 
noisyNet noise sample is [array([-3.6023192], dtype=float32), -0.07680877]. 
=============================================
[2019-03-23 19:44:38,987] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.3944057e-03 1.2020841e-06 9.9443531e-01 1.3228355e-05 1.5575942e-04], sum to 1.0000
[2019-03-23 19:44:38,995] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0662
[2019-03-23 19:44:38,999] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.43333333333333, 92.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 251891.3234914349, 251891.3234914352, 103064.7019383942], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2182800.0000, 
sim time next is 2183400.0000, 
raw observation next is [14.55, 92.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 251404.8826328927, 251404.8826328925, 103182.2898324333], 
processed observation next is [1.0, 0.2608695652173913, 0.2977272727272728, 0.92, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09311291949366396, 0.09311291949366389, 0.2516641215425202], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.6912829], dtype=float32), -0.5006774]. 
=============================================
[2019-03-23 19:44:41,587] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.9651408e-04 4.1353587e-06 9.9955899e-01 1.9897900e-05 2.0335119e-05], sum to 1.0000
[2019-03-23 19:44:41,594] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7339
[2019-03-23 19:44:41,600] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.5, 91.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 251681.7498960425, 251681.7498960428, 102497.1958851555], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2251800.0000, 
sim time next is 2252400.0000, 
raw observation next is [14.33333333333333, 92.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 249562.895681839, 249562.895681839, 101789.9755414041], 
processed observation next is [1.0, 0.043478260869565216, 0.28787878787878773, 0.92, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.09243070210438481, 0.09243070210438481, 0.24826823302781487], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.31822878], dtype=float32), 0.7272794]. 
=============================================
[2019-03-23 19:44:44,431] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7698588e-03 4.2435331e-05 9.9756765e-01 3.3303665e-04 2.8713030e-04], sum to 1.0000
[2019-03-23 19:44:44,439] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2877
[2019-03-23 19:44:44,445] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.16666666666667, 45.66666666666667, 1.0, 2.0, 0.2873636633129744, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5364450049187756, 6.9112, 6.9112, 77.32846344354104, 624260.5118380392, 624260.5118380392, 159935.5527812801], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2393400.0000, 
sim time next is 2394000.0000, 
raw observation next is [22.0, 46.0, 1.0, 2.0, 0.2871596868855706, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5360642256151558, 6.911199999999999, 6.9112, 77.32846344354104, 623817.1149638058, 623817.1149638061, 159057.5173534362], 
processed observation next is [1.0, 0.7391304347826086, 0.6363636363636364, 0.46, 1.0, 1.0, 0.10894960860696322, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3372346080216511, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23104337591252067, 0.23104337591252078, 0.3879451642766737], 
reward next is 0.6121, 
noisyNet noise sample is [array([-0.16599973], dtype=float32), 0.29112983]. 
=============================================
[2019-03-23 19:44:44,464] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[ 6.8800197]
 [ 7.586212 ]
 [ 8.865252 ]
 [10.496188 ]
 [12.23644  ]], R is [[7.23110104]
 [7.76870346]
 [8.2974472 ]
 [8.81376648]
 [9.3149929 ]].
[2019-03-23 19:44:44,521] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.7657374e-04 1.3701085e-06 9.9973804e-01 3.7804322e-05 4.6115896e-05], sum to 1.0000
[2019-03-23 19:44:44,536] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8921
[2019-03-23 19:44:44,549] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 60.0, 1.0, 2.0, 0.2196589142488166, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4127915602567489, 6.9112, 6.9112, 77.32846344354104, 479180.5530418289, 479180.5530418289, 155942.7598152364], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2552400.0000, 
sim time next is 2553000.0000, 
raw observation next is [21.0, 59.33333333333333, 1.0, 2.0, 0.2359077211898518, 0.0, 2.0, 0.0, 1.0, 2.0, 0.442764320026995, 6.9112, 6.9112, 77.32846344354104, 514124.5857006753, 514124.5857006753, 158364.4949214149], 
processed observation next is [1.0, 0.5652173913043478, 0.5909090909090909, 0.5933333333333333, 1.0, 1.0, 0.04488465148731472, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2039490286099929, 0.0, 0.0, 0.5084288129206541, 0.19041651322247233, 0.19041651322247233, 0.3862548656619876], 
reward next is 0.6137, 
noisyNet noise sample is [array([0.4821438], dtype=float32), 2.27751]. 
=============================================
[2019-03-23 19:44:44,581] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[11.68012 ]
 [13.946169]
 [15.116169]
 [16.688915]
 [18.44429 ]], R is [[12.10614014]
 [12.60473061]
 [13.09195232]
 [13.57529736]
 [14.05390549]].
[2019-03-23 19:44:47,227] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6752396e-03 5.1545427e-08 9.9828243e-01 8.4724361e-06 3.3803015e-05], sum to 1.0000
[2019-03-23 19:44:47,236] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2390
[2019-03-23 19:44:47,241] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [12.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 197734.3300852345, 197734.3300852345, 85424.67002263619], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2343600.0000, 
sim time next is 2344200.0000, 
raw observation next is [12.16666666666667, 88.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 250277.0627789807, 250277.0627789807, 95017.1682678905], 
processed observation next is [1.0, 0.13043478260869565, 0.18939393939393953, 0.8800000000000001, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.09269520843665952, 0.09269520843665952, 0.23174919089729393], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.312375], dtype=float32), -1.020832]. 
=============================================
[2019-03-23 19:44:47,661] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2322624e-03 6.6665065e-09 9.9875915e-01 1.0186413e-06 7.4833524e-06], sum to 1.0000
[2019-03-23 19:44:47,672] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4391
[2019-03-23 19:44:47,677] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.2754379074462737, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5572850608344577, 6.9112, 6.9112, 77.32846344354104, 627967.5930985311, 627967.5930985311, 185215.3510334593], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2957400.0000, 
sim time next is 2958000.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.2580137301108119, 0.0, 2.0, 0.0, 1.0, 2.0, 0.522014411464297, 6.9112, 6.9112, 77.32846344354104, 588236.5818487263, 588236.5818487263, 180835.5852005022], 
processed observation next is [1.0, 0.21739130434782608, 0.6363636363636364, 0.94, 1.0, 1.0, 0.07251716263851488, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3171634449489957, 0.0, 0.0, 0.5084288129206541, 0.21786540068471344, 0.21786540068471344, 0.4410624029280541], 
reward next is 0.5589, 
noisyNet noise sample is [array([1.2293098], dtype=float32), 0.19367608]. 
=============================================
[2019-03-23 19:44:47,688] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[33.904438]
 [33.941055]
 [33.99124 ]
 [34.596127]
 [34.74574 ]], R is [[34.31587601]
 [34.52097321]
 [34.72620773]
 [34.92486572]
 [35.13249969]].
[2019-03-23 19:44:56,035] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.5067533e-05 5.7315083e-07 9.9995053e-01 1.0295068e-05 3.5884227e-06], sum to 1.0000
[2019-03-23 19:44:56,041] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1996
[2019-03-23 19:44:56,045] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.83333333333334, 95.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 341110.4678529106, 341110.4678529109, 143816.6732964778], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2616600.0000, 
sim time next is 2617200.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 342941.9391186578, 342941.9391186575, 144230.4289023921], 
processed observation next is [0.0, 0.30434782608695654, 0.4090909090909091, 0.94, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1270155330069103, 0.12701553300691018, 0.35178153390827344], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6571093], dtype=float32), 1.096567]. 
=============================================
[2019-03-23 19:44:56,843] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.4499560e-04 1.4697331e-06 9.9933237e-01 1.7324337e-05 3.8702556e-06], sum to 1.0000
[2019-03-23 19:44:56,850] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8481
[2019-03-23 19:44:56,853] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.8, 84.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3285410868537709, 6.9112, 6.9112, 77.32846344354104, 379378.8442141857, 379378.8442141857, 149533.4154014964], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2685600.0000, 
sim time next is 2686200.0000, 
raw observation next is [18.66666666666667, 84.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3253261143357329, 6.9112, 6.9112, 77.32846344354104, 375828.3432836352, 375828.3432836352, 148999.3585830087], 
processed observation next is [0.0, 0.08695652173913043, 0.4848484848484851, 0.845, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.03618016333676128, 0.0, 0.0, 0.5084288129206541, 0.13919568269764268, 0.13919568269764268, 0.36341306971465537], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.1766262], dtype=float32), 2.4875026]. 
=============================================
[2019-03-23 19:45:00,077] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.0884409e-04 9.0362310e-12 9.9969113e-01 2.4253737e-09 5.2698425e-08], sum to 1.0000
[2019-03-23 19:45:00,084] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6811
[2019-03-23 19:45:00,087] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.75, 99.83333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3141832739700625, 6.9112, 6.9112, 77.32846344354104, 363412.814240325, 363412.814240325, 147260.4763640441], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2699400.0000, 
sim time next is 2700000.0000, 
raw observation next is [16.8, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3159070258656562, 6.911200000000001, 6.9112, 77.32846344354104, 365277.1143717997, 365277.1143717995, 147586.1266713746], 
processed observation next is [0.0, 0.2608695652173913, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.02272432266522319, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1352878201377036, 0.13528782013770352, 0.35996616261310876], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.13891117], dtype=float32), 0.6771192]. 
=============================================
[2019-03-23 19:45:00,103] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[44.81188 ]
 [44.595787]
 [44.33996 ]
 [44.20885 ]
 [44.0642  ]], R is [[44.47537613]
 [44.03062439]
 [43.59031677]
 [43.15441513]
 [42.72286987]].
[2019-03-23 19:45:03,411] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.8100549e-04 1.0297002e-07 9.9971312e-01 1.3195116e-06 4.3897940e-06], sum to 1.0000
[2019-03-23 19:45:03,412] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8257
[2019-03-23 19:45:03,428] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.05, 79.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3466803527839113, 6.9112, 6.9112, 77.32846344354104, 399143.5646982844, 399143.5646982844, 152805.2806377678], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2681400.0000, 
sim time next is 2682000.0000, 
raw observation next is [20.0, 80.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3481736002806793, 6.911200000000001, 6.9112, 77.32846344354104, 400740.2721214349, 400740.2721214346, 153102.7981029513], 
processed observation next is [0.0, 0.043478260869565216, 0.5454545454545454, 0.8, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.068819428972399, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14842232300793887, 0.14842232300793876, 0.37342145878768607], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3218986], dtype=float32), -1.243516]. 
=============================================
[2019-03-23 19:45:03,523] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[11.877465]
 [11.961628]
 [11.57475 ]
 [10.037655]
 [10.559726]], R is [[12.14739895]
 [12.02592468]
 [11.9056654 ]
 [11.7866087 ]
 [11.66874313]].
[2019-03-23 19:45:06,513] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.6961591e-03 5.7346142e-12 9.9730080e-01 1.2555419e-08 3.1330815e-06], sum to 1.0000
[2019-03-23 19:45:06,522] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2202
[2019-03-23 19:45:06,527] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.33333333333334, 64.33333333333334, 1.0, 2.0, 0.246036121794765, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4977370567846064, 6.911199999999999, 6.9112, 77.32846344354104, 560958.8820090027, 560958.882009003, 177933.6180174543], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2726400.0000, 
sim time next is 2727000.0000, 
raw observation next is [26.0, 65.5, 1.0, 2.0, 0.2446565605392045, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4947544095017379, 6.9112, 6.9112, 77.32846344354104, 557974.8189840426, 557974.8189840426, 177330.2089839987], 
processed observation next is [0.0, 0.5652173913043478, 0.8181818181818182, 0.655, 1.0, 1.0, 0.05582070067400562, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2782205850024827, 0.0, 0.0, 0.5084288129206541, 0.20665734036446023, 0.20665734036446023, 0.4325127048390212], 
reward next is 0.5675, 
noisyNet noise sample is [array([-1.3328537], dtype=float32), -2.017015]. 
=============================================
[2019-03-23 19:45:06,538] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[47.618217]
 [47.712296]
 [47.872074]
 [47.970554]
 [48.089165]], R is [[47.65270233]
 [47.74219131]
 [47.82958603]
 [47.91563797]
 [48.00204086]].
[2019-03-23 19:45:08,951] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1231470e-03 3.3919815e-07 9.9884427e-01 1.2745784e-05 1.9380659e-05], sum to 1.0000
[2019-03-23 19:45:08,958] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4944
[2019-03-23 19:45:08,963] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3054048162811272, 6.911200000000001, 6.9112, 77.32846344354104, 353329.3887082158, 353329.3887082156, 146205.3298776922], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2786400.0000, 
sim time next is 2787000.0000, 
raw observation next is [18.0, 89.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3153718701573042, 6.9112, 6.9112, 77.32846344354104, 364697.9513995443, 364697.9513995443, 147485.5013830465], 
processed observation next is [1.0, 0.2608695652173913, 0.45454545454545453, 0.8900000000000001, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.021959814510434623, 0.0, 0.0, 0.5084288129206541, 0.13507331533316455, 0.13507331533316455, 0.3597207350806012], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.08412972], dtype=float32), -0.37720785]. 
=============================================
[2019-03-23 19:45:09,000] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[13.242669]
 [13.158637]
 [12.974813]
 [12.67636 ]
 [12.57891 ]], R is [[13.73976898]
 [13.60237122]
 [13.46634769]
 [13.33168411]
 [13.19836712]].
[2019-03-23 19:45:13,387] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.2998134e-02 1.3936071e-09 9.7699183e-01 2.0873388e-07 9.7811362e-06], sum to 1.0000
[2019-03-23 19:45:13,398] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4165
[2019-03-23 19:45:13,402] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 74.0, 1.0, 2.0, 0.6044892541107597, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9803187898643524, 6.911199999999999, 6.9112, 77.32845661478319, 1232579.018615016, 1232579.018615016, 280973.2868364563], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2883600.0000, 
sim time next is 2884200.0000, 
raw observation next is [26.0, 74.0, 1.0, 2.0, 0.7607783290877741, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9809274578733113, 6.911199999999999, 6.9112, 77.32846340127045, 1409013.968477478, 1409013.968477478, 305074.0527246041], 
processed observation next is [1.0, 0.391304347826087, 0.8181818181818182, 0.74, 1.0, 1.0, 0.7009729113597176, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9727535112475877, -8.881784197001253e-17, 0.0, 0.5084288126427282, 0.5218570253620289, 0.5218570253620289, 0.7440830554258636], 
reward next is 0.2559, 
noisyNet noise sample is [array([1.0514485], dtype=float32), -0.78077114]. 
=============================================
[2019-03-23 19:45:15,049] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 19:45:15,050] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:45:15,051] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:45:15,051] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:45:15,053] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:45:15,053] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:45:15,053] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:45:15,055] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:45:15,056] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:45:15,057] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:45:15,057] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:45:15,079] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run72
[2019-03-23 19:45:15,106] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run72
[2019-03-23 19:45:15,106] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run72
[2019-03-23 19:45:15,107] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run72
[2019-03-23 19:45:15,107] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run72
[2019-03-23 19:45:24,746] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00530998], dtype=float32), 0.0131629985]
[2019-03-23 19:45:24,747] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.36666666666667, 42.33333333333333, 1.0, 2.0, 0.2254775861713469, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4209172566505929, 6.9112, 6.9112, 95.55338769695034, 489706.2146664172, 489706.2146664172, 147358.0294543866]
[2019-03-23 19:45:24,748] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:45:24,750] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.9387885e-03 8.9666564e-12 9.9606091e-01 7.8300930e-09 2.2315446e-07], sampled 0.3964681814592059
[2019-03-23 19:45:36,711] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00530998], dtype=float32), 0.0131629985]
[2019-03-23 19:45:36,712] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.4, 57.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3827724664940507, 6.911200000000001, 6.9112, 95.55338769695034, 438633.5976507603, 438633.5976507599, 163769.4115688194]
[2019-03-23 19:45:36,713] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:45:36,716] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.7113236e-03 4.3975318e-12 9.9728858e-01 4.2352872e-09 1.1699129e-07], sampled 0.15619473663566985
[2019-03-23 19:45:40,180] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00530998], dtype=float32), 0.0131629985]
[2019-03-23 19:45:40,182] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.5, 70.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 274751.6844286419, 274751.6844286415, 115007.2781371827]
[2019-03-23 19:45:40,182] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:45:40,185] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.1640842e-04 3.6182356e-11 9.9928349e-01 9.3975006e-09 7.0370916e-08], sampled 0.6013271061259581
[2019-03-23 19:45:42,856] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00530998], dtype=float32), 0.0131629985]
[2019-03-23 19:45:42,857] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.41034576666667, 49.18084906666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 95.55338769695034, 327565.9145667734, 327565.9145667737, 123258.1970784269]
[2019-03-23 19:45:42,858] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:45:42,859] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.5507689e-03 1.8789217e-10 9.9844885e-01 4.4118281e-08 3.6503053e-07], sampled 0.1772693187097074
[2019-03-23 19:46:03,370] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00530998], dtype=float32), 0.0131629985]
[2019-03-23 19:46:03,372] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.55, 66.5, 1.0, 2.0, 0.426019794651167, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8492071634495757, 6.930454076086179, 6.9112, 95.55323513512226, 968418.3120920788, 960691.1972018755, 240357.5075655154]
[2019-03-23 19:46:03,374] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:46:03,378] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.2411920e-02 1.9691448e-11 9.8758477e-01 7.9332587e-08 3.2270823e-06], sampled 0.5588102667520307
[2019-03-23 19:46:28,929] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00530998], dtype=float32), 0.0131629985]
[2019-03-23 19:46:28,931] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.1, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 316974.8027233001, 316974.8027233004, 135322.7521667392]
[2019-03-23 19:46:28,931] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:46:28,935] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.77126192e-03 9.52026132e-12 9.98228610e-01 5.85440763e-09
 1.05794165e-07], sampled 0.6738500360726144
[2019-03-23 19:46:54,234] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00530998], dtype=float32), 0.0131629985]
[2019-03-23 19:46:54,236] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.66726059333333, 78.50553624333334, 1.0, 2.0, 0.2373339627679536, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4792551719225405, 6.911200000000001, 6.9112, 95.55338769695034, 541511.953290393, 541511.9532903926, 179521.9254829428]
[2019-03-23 19:46:54,237] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:46:54,240] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.0639791e-03 5.4512933e-14 9.9393600e-01 4.4413059e-10 3.9438891e-08], sampled 0.26953655555850997
[2019-03-23 19:46:59,453] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3104.2411 2107214222.4017 391.0000
[2019-03-23 19:46:59,543] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3503.4998 2102279370.4435 198.0000
[2019-03-23 19:46:59,796] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3586.6972 2173146572.5700 273.0000
[2019-03-23 19:47:00,006] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3347.4473 2096637842.4778 194.0000
[2019-03-23 19:47:00,014] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2751.6545 2122655929.7943 766.0000
[2019-03-23 19:47:01,028] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1775000, evaluation results [1775000.0, 3586.697193712183, 2173146572.5700183, 273.0, 3347.447281811997, 2096637842.4777722, 194.0, 3503.499831487692, 2102279370.4435027, 198.0, 2751.654488063628, 2122655929.7942758, 766.0, 3104.241060864906, 2107214222.4016664, 391.0]
[2019-03-23 19:47:01,968] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0132403e-01 3.0938845e-13 8.9862770e-01 1.5404590e-08 4.8219805e-05], sum to 1.0000
[2019-03-23 19:47:01,976] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5139
[2019-03-23 19:47:01,982] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.0, 85.66666666666666, 1.0, 2.0, 0.6269979077402836, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9796478295133721, 6.911199999999999, 6.9112, 77.32846344354104, 1258722.895375078, 1258722.895375078, 283601.4214986704], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2911200.0000, 
sim time next is 2911800.0000, 
raw observation next is [23.5, 87.33333333333334, 1.0, 2.0, 0.6064088285830429, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9780703680822321, 6.911199999999999, 6.9112, 77.32846344354104, 1236679.654734041, 1236679.654734041, 279315.9480932491], 
processed observation next is [1.0, 0.6956521739130435, 0.7045454545454546, 0.8733333333333334, 1.0, 1.0, 0.5080110357288036, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9686719544031889, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.45802950175334856, 0.45802950175334856, 0.6812584099835344], 
reward next is 0.3187, 
noisyNet noise sample is [array([-0.53284156], dtype=float32), -0.06963499]. 
=============================================
[2019-03-23 19:47:02,323] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.8968716e-02 2.0313754e-11 9.7102386e-01 1.1509602e-06 6.2203949e-06], sum to 1.0000
[2019-03-23 19:47:02,331] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0933
[2019-03-23 19:47:02,336] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.27130659262041, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5495801475541544, 6.9112, 6.9112, 77.32846344354104, 616612.1978146909, 616612.1978146909, 185959.4851193852], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2931600.0000, 
sim time next is 2932200.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.2721940331262359, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5513780659250985, 6.9112, 6.9112, 77.32846344354104, 618624.9369745821, 618624.9369745821, 186193.1983166654], 
processed observation next is [1.0, 0.9565217391304348, 0.6363636363636364, 1.0, 1.0, 1.0, 0.09024254140779488, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3591115227501408, 0.0, 0.0, 0.5084288129206541, 0.22912034702762302, 0.22912034702762302, 0.45412975199186684], 
reward next is 0.5459, 
noisyNet noise sample is [array([2.0086677], dtype=float32), -0.5743669]. 
=============================================
[2019-03-23 19:47:04,056] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.3303008e-03 8.6701438e-11 9.9266452e-01 8.5441320e-07 4.3651412e-06], sum to 1.0000
[2019-03-23 19:47:04,065] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8747
[2019-03-23 19:47:04,071] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.2715624251842957, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5489902260353641, 6.9112, 6.9112, 77.32846344354104, 619489.5868542738, 619489.5868542738, 183579.5194924872], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2948400.0000, 
sim time next is 2949000.0000, 
raw observation next is [21.16666666666667, 99.00000000000001, 1.0, 2.0, 0.2753959672155942, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5567376195557648, 6.9112, 6.9112, 77.32846344354104, 628241.7603586357, 628241.7603586357, 184550.7688450804], 
processed observation next is [1.0, 0.13043478260869565, 0.5984848484848487, 0.9900000000000001, 1.0, 1.0, 0.0942449590194927, 0.0, 1.0, -0.25, 1.0, 1.0, 0.36676802793680696, 0.0, 0.0, 0.5084288129206541, 0.23268213346616137, 0.23268213346616137, 0.45012382645141563], 
reward next is 0.5499, 
noisyNet noise sample is [array([-0.4313108], dtype=float32), -0.16499928]. 
=============================================
[2019-03-23 19:47:04,088] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[43.600964]
 [42.757427]
 [43.007336]
 [41.540493]
 [41.37722 ]], R is [[43.74044037]
 [43.85528183]
 [43.96107864]
 [44.06019592]
 [44.14704514]].
[2019-03-23 19:47:06,008] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3941966e-01 1.6258014e-07 8.5864931e-01 6.4648461e-04 1.2844038e-03], sum to 1.0000
[2019-03-23 19:47:06,018] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4116
[2019-03-23 19:47:06,025] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.4548490418199873, 1.0, 2.0, 0.4548490418199873, 1.0, 1.0, 0.9191451719667155, 6.9112, 6.9112, 77.3421103, 1536722.820780257, 1536722.820780257, 333860.1484777717], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2987400.0000, 
sim time next is 2988000.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.9228804050881159, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9783427668910735, 6.911199999999999, 6.9112, 77.32846344255778, 1596161.208733116, 1596161.208733116, 330752.5338130405], 
processed observation next is [1.0, 0.6086956521739131, 0.9090909090909091, 0.58, 1.0, 1.0, 0.9036005063601449, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9690610955586766, -8.881784197001253e-17, 0.0, 0.5084288129141892, 0.5911708180493023, 0.5911708180493023, 0.8067134971049769], 
reward next is 0.1933, 
noisyNet noise sample is [array([0.681351], dtype=float32), -0.093400136]. 
=============================================
[2019-03-23 19:47:06,039] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[31.023567]
 [30.004276]
 [30.365986]
 [30.10872 ]
 [30.16768 ]], R is [[31.09308624]
 [30.78215599]
 [30.76111794]
 [30.45350647]
 [30.35442734]].
[2019-03-23 19:47:09,032] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.1023872e-03 8.8843741e-08 9.9145985e-01 1.0883708e-04 3.2883009e-04], sum to 1.0000
[2019-03-23 19:47:09,036] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2615
[2019-03-23 19:47:09,040] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 69.0, 1.0, 2.0, 0.4936897428485713, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9361857641042454, 6.95482279518639, 6.9112, 77.32833021934258, 1109915.175902871, 1095747.408675563, 243788.9798172634], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3063600.0000, 
sim time next is 3064200.0000, 
raw observation next is [23.16666666666667, 69.0, 1.0, 2.0, 0.4424177848496379, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8836638529732971, 6.9112, 6.9112, 77.32843707381593, 1007319.994678539, 1007319.994678539, 231204.5945742065], 
processed observation next is [1.0, 0.4782608695652174, 0.6893939393939396, 0.69, 1.0, 1.0, 0.30302223106204734, 0.0, 1.0, -0.25, 1.0, 1.0, 0.8338055042475674, 0.0, 0.0, 0.508428639541701, 0.37308147951057, 0.37308147951057, 0.5639136453029427], 
reward next is 0.4361, 
noisyNet noise sample is [array([-1.1483575], dtype=float32), -0.6810662]. 
=============================================
[2019-03-23 19:47:10,493] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4685093e-02 5.5059509e-08 9.8459423e-01 5.6334557e-05 6.6435331e-04], sum to 1.0000
[2019-03-23 19:47:10,499] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5302
[2019-03-23 19:47:10,505] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.66666666666666, 56.0, 1.0, 2.0, 0.9371730007605078, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9783262001636068, 6.9112, 6.9112, 77.32846344354104, 1612431.694234527, 1612431.694234527, 333411.5755975002], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3681600.0000, 
sim time next is 3682200.0000, 
raw observation next is [28.83333333333334, 55.5, 1.0, 2.0, 0.9552279703317508, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9786817624518884, 6.9112, 6.9112, 77.32846344354104, 1632507.77775968, 1632507.77775968, 337229.5011478863], 
processed observation next is [1.0, 0.6086956521739131, 0.9469696969696972, 0.555, 1.0, 1.0, 0.9440349629146885, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9695453749312691, 0.0, 0.0, 0.5084288129206541, 0.604632510281363, 0.604632510281363, 0.8225109784094787], 
reward next is 0.1775, 
noisyNet noise sample is [array([0.34139407], dtype=float32), 0.54263747]. 
=============================================
[2019-03-23 19:47:19,139] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.3808715e-05 8.4126945e-08 9.9993372e-01 1.3932852e-06 1.1243272e-06], sum to 1.0000
[2019-03-23 19:47:19,145] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6846
[2019-03-23 19:47:19,156] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.66666666666667, 70.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3607660949063439, 6.911199999999999, 6.9112, 77.32846344354104, 414581.7063083567, 414581.706308357, 155261.0866669314], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3228000.0000, 
sim time next is 3228600.0000, 
raw observation next is [21.83333333333334, 69.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3621962799930724, 6.911199999999999, 6.9112, 77.32846344354104, 416086.4544643463, 416086.4544643466, 155568.0682533353], 
processed observation next is [0.0, 0.34782608695652173, 0.628787878787879, 0.6966666666666665, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.08885182856153204, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15410609424605418, 0.1541060942460543, 0.37943431281301293], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.30803332], dtype=float32), -1.2222787]. 
=============================================
[2019-03-23 19:47:22,555] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.5122947e-04 7.1819579e-07 9.9974328e-01 2.5589225e-06 2.2839804e-06], sum to 1.0000
[2019-03-23 19:47:22,560] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4649
[2019-03-23 19:47:22,567] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 68.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 301289.5586233109, 301289.5586233109, 127412.5143110871], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3315600.0000, 
sim time next is 3316200.0000, 
raw observation next is [19.5, 66.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 304673.0484853435, 304673.0484853438, 132201.8558096284], 
processed observation next is [0.0, 0.391304347826087, 0.5227272727272727, 0.6616666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11284186980938649, 0.1128418698093866, 0.32244355075519127], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.07344551], dtype=float32), 4.9281316]. 
=============================================
[2019-03-23 19:47:24,674] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.6237914e-05 7.7336452e-08 9.9994159e-01 8.5423056e-07 1.2295114e-06], sum to 1.0000
[2019-03-23 19:47:24,683] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9795
[2019-03-23 19:47:24,692] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 50.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.351785582380481, 6.911200000000001, 6.9112, 77.32846344354104, 404545.6002680939, 404545.6002680936, 153874.311571162], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3344400.0000, 
sim time next is 3345000.0000, 
raw observation next is [24.83333333333334, 51.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3529963649740044, 6.9112, 6.9112, 77.32846344354104, 405847.7160408788, 405847.7160408788, 154107.9965916563], 
processed observation next is [0.0, 0.7391304347826086, 0.7651515151515155, 0.5116666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.07570909282000628, 0.0, 0.0, 0.5084288129206541, 0.15031396890402918, 0.15031396890402918, 0.3758731624186739], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4026562], dtype=float32), -1.050197]. 
=============================================
[2019-03-23 19:47:24,703] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[0.13845444]
 [0.14094281]
 [0.13268465]
 [0.12593597]
 [0.11473466]], R is [[0.19811721]
 [0.19613604]
 [0.19417468]
 [0.19223294]
 [0.19031061]].
[2019-03-23 19:47:30,496] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.4020839e-02 7.7129165e-09 9.5580322e-01 3.6216454e-05 1.3967995e-04], sum to 1.0000
[2019-03-23 19:47:30,501] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1904
[2019-03-23 19:47:30,510] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.66666666666667, 71.33333333333333, 1.0, 2.0, 0.6952351141999896, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9822089478791981, 6.911200000000001, 6.9112, 77.32846344354104, 1333275.123870013, 1333275.123870013, 295875.5749582115], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3498000.0000, 
sim time next is 3498600.0000, 
raw observation next is [26.83333333333333, 70.66666666666667, 1.0, 2.0, 0.7011420819374264, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9825122868739189, 6.9112, 6.9112, 77.32846344354104, 1339576.929300048, 1339576.929300048, 297046.2556644114], 
processed observation next is [1.0, 0.4782608695652174, 0.8560606060606059, 0.7066666666666667, 1.0, 1.0, 0.626427602421783, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9750175526770269, 0.0, 0.0, 0.5084288129206541, 0.4961396034444622, 0.4961396034444622, 0.7245030625961254], 
reward next is 0.2755, 
noisyNet noise sample is [array([0.3992947], dtype=float32), -0.8884287]. 
=============================================
[2019-03-23 19:47:31,534] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.4705102e-02 3.9425547e-08 9.2528570e-01 4.7427054e-07 8.6118825e-06], sum to 1.0000
[2019-03-23 19:47:31,541] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0233
[2019-03-23 19:47:31,548] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 569200.3194171117 W.
[2019-03-23 19:47:31,554] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4989041176398594, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846342767462, 569200.3194171117, 569200.3194171115, 141462.9231208092], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3478800.0000, 
sim time next is 3479400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4912077504077353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344344283, 560442.49253334, 560442.49253334, 140483.7979851592], 
processed observation next is [1.0, 0.2608695652173913, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3640096880096691, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129200084, 0.20757129353086667, 0.20757129353086667, 0.34264340971990054], 
reward next is 0.6574, 
noisyNet noise sample is [array([1.4016337], dtype=float32), 0.5967463]. 
=============================================
[2019-03-23 19:47:34,228] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.1515353e-01 2.0042910e-08 7.8467929e-01 3.2254407e-05 1.3485222e-04], sum to 1.0000
[2019-03-23 19:47:34,239] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1254
[2019-03-23 19:47:34,245] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1518411.076235836 W.
[2019-03-23 19:47:34,251] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.8, 61.0, 1.0, 2.0, 0.8625782908460581, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9855409756696335, 6.9112, 6.9112, 77.32846344354104, 1518411.076235836, 1518411.076235836, 326476.4737786701], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3515400.0000, 
sim time next is 3516000.0000, 
raw observation next is [28.73333333333333, 60.66666666666667, 1.0, 2.0, 0.4580178076263069, 1.0, 1.0, 0.4580178076263069, 1.0, 2.0, 0.9267438121527548, 6.9112, 6.9112, 77.3421103, 1545323.837892611, 1545323.837892611, 337013.0304641406], 
processed observation next is [1.0, 0.6956521739130435, 0.9424242424242423, 0.6066666666666667, 1.0, 1.0, 0.3225222595328836, 1.0, 0.5, 0.3225222595328836, 1.0, 1.0, 0.8953483030753642, 0.0, 0.0, 0.5085185399722538, 0.5723421621824485, 0.5723421621824485, 0.8219830011320503], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.0210218], dtype=float32), 0.49961954]. 
=============================================
[2019-03-23 19:47:34,270] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[38.133022]
 [36.93324 ]
 [36.174694]
 [35.678173]
 [34.64507 ]], R is [[37.43961716]
 [37.26893616]
 [37.06658936]
 [36.82228088]
 [36.68018723]].
[2019-03-23 19:47:36,401] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.4217724e-01 4.7634241e-10 8.5773844e-01 2.1263133e-07 8.4153973e-05], sum to 1.0000
[2019-03-23 19:47:36,408] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3578
[2019-03-23 19:47:36,412] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.2644829783111989, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5345641718833564, 6.9112, 6.9112, 77.32846344354104, 603390.4185107809, 603390.4185107809, 181672.1645854376], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3567600.0000, 
sim time next is 3568200.0000, 
raw observation next is [21.16666666666667, 99.00000000000001, 1.0, 2.0, 0.2850147133518154, 0.0, 2.0, 0.0, 1.0, 2.0, 0.576184902994848, 6.9112, 6.9112, 77.32846344354104, 650197.8013379236, 650197.8013379236, 187055.8817067512], 
processed observation next is [1.0, 0.30434782608695654, 0.5984848484848487, 0.9900000000000001, 1.0, 1.0, 0.10626839168976922, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3945498614212115, 0.0, 0.0, 0.5084288129206541, 0.24081400049552726, 0.24081400049552726, 0.4562338578213444], 
reward next is 0.5438, 
noisyNet noise sample is [array([0.6207423], dtype=float32), -0.58044165]. 
=============================================
[2019-03-23 19:47:37,870] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0320764e-01 1.2285484e-10 8.9678341e-01 9.3900596e-08 8.9145688e-06], sum to 1.0000
[2019-03-23 19:47:37,875] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8416
[2019-03-23 19:47:37,880] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.83333333333334, 58.66666666666667, 1.0, 2.0, 0.2555953195071359, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5175978831201761, 6.911200000000001, 6.9112, 77.32846344354104, 581860.9234956668, 581860.9234956665, 181241.1365856119], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3694200.0000, 
sim time next is 3694800.0000, 
raw observation next is [27.66666666666667, 59.33333333333334, 1.0, 2.0, 0.2560417142360874, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5184164357999561, 6.911199999999999, 6.9112, 77.32846344354104, 583116.6992714397, 583116.6992714399, 181119.1127290873], 
processed observation next is [1.0, 0.782608695652174, 0.8939393939393941, 0.5933333333333334, 1.0, 1.0, 0.07005214279510924, 0.0, 1.0, -0.25, 1.0, 1.0, 0.31202347971422306, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.215969147878311, 0.2159691478783111, 0.4417539334855788], 
reward next is 0.5582, 
noisyNet noise sample is [array([0.34183645], dtype=float32), -0.25372615]. 
=============================================
[2019-03-23 19:47:40,110] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.0163744e-01 2.1318464e-10 6.9828647e-01 9.8705684e-08 7.5967102e-05], sum to 1.0000
[2019-03-23 19:47:40,118] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3709
[2019-03-23 19:47:40,121] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.2532829276572134, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5119092411951999, 6.911200000000001, 6.9112, 77.32846344354104, 577832.0342506554, 577832.0342506551, 178956.4295324557], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3640800.0000, 
sim time next is 3641400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.2518519623494183, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5090003806582944, 6.9112, 6.9112, 77.32846344354104, 574573.4022529251, 574573.4022529251, 178599.8527151285], 
processed observation next is [1.0, 0.13043478260869565, 0.5909090909090909, 1.0, 1.0, 1.0, 0.06481495293677288, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2985719723689921, 0.0, 0.0, 0.5084288129206541, 0.21280496379737968, 0.21280496379737968, 0.4356093968661671], 
reward next is 0.5644, 
noisyNet noise sample is [array([0.7686171], dtype=float32), 0.6829183]. 
=============================================
[2019-03-23 19:47:41,067] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.55787194e-01 4.84974230e-08 7.39217997e-01 1.20116856e-04
 4.87464387e-03], sum to 1.0000
[2019-03-23 19:47:41,072] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6257
[2019-03-23 19:47:41,077] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.66666666666666, 56.0, 1.0, 2.0, 0.9371730010425111, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9783262004243547, 6.9112, 6.9112, 77.32846344354104, 1612431.694234526, 1612431.694234526, 333411.5759378843], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3681600.0000, 
sim time next is 3682200.0000, 
raw observation next is [28.83333333333334, 55.5, 1.0, 2.0, 0.9552279705167858, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9786817626145164, 6.9112, 6.9112, 77.32846344354104, 1632507.77775968, 1632507.77775968, 337229.5013625437], 
processed observation next is [1.0, 0.6086956521739131, 0.9469696969696972, 0.555, 1.0, 1.0, 0.9440349631459821, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9695453751635951, 0.0, 0.0, 0.5084288129206541, 0.604632510281363, 0.604632510281363, 0.8225109789330335], 
reward next is 0.1775, 
noisyNet noise sample is [array([-1.8245239], dtype=float32), -0.4409714]. 
=============================================
[2019-03-23 19:47:42,961] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.2691599e-02 4.1608303e-07 9.3697751e-01 8.1810787e-05 2.4863979e-04], sum to 1.0000
[2019-03-23 19:47:42,967] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9271
[2019-03-23 19:47:42,971] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 78.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3829412974920883, 6.911199999999999, 6.9112, 77.32846343870382, 439023.4124648835, 439023.4124648838, 159025.8410616931], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4313400.0000, 
sim time next is 4314000.0000, 
raw observation next is [21.0, 78.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3817355014274742, 6.9112, 6.9112, 77.3284634435111, 437659.3745301559, 437659.3745301559, 158850.9648779977], 
processed observation next is [1.0, 0.9565217391304348, 0.5909090909090909, 0.78, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.11676500203924887, 0.0, 0.0, 0.5084288129204573, 0.16209606464079848, 0.16209606464079848, 0.3874413777512139], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3297572], dtype=float32), -0.1462097]. 
=============================================
[2019-03-23 19:47:43,007] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[18.506748]
 [19.442247]
 [22.2055  ]
 [20.997908]
 [20.265049]], R is [[17.91547775]
 [17.7363224 ]
 [17.55895996]
 [17.38337135]
 [17.20953751]].
[2019-03-23 19:47:46,109] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.9142861e-01 3.6533058e-07 5.0283098e-01 3.5155282e-04 5.3885086e-03], sum to 1.0000
[2019-03-23 19:47:46,114] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2704
[2019-03-23 19:47:46,123] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1067638.598708718 W.
[2019-03-23 19:47:46,129] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333333, 78.16666666666667, 1.0, 2.0, 0.4687366961249434, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9240836423056591, 6.933668043993807, 6.9112, 77.32840345393373, 1067638.598708718, 1060341.443231468, 240068.6843636257], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3765000.0000, 
sim time next is 3765600.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.8769968106561735, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32844992692996, 996543.3948120122, 996543.3948120126, 187869.3082357784], 
processed observation next is [1.0, 0.6086956521739131, 0.5909090909090909, 0.83, 1.0, 1.0, 0.8462460133202168, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084287240499561, 0.3690901462266712, 0.3690901462266713, 0.45821782496531316], 
reward next is 0.5418, 
noisyNet noise sample is [array([2.0077105], dtype=float32), -0.6654573]. 
=============================================
[2019-03-23 19:47:49,400] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.8548667e-03 3.1162363e-06 9.9806005e-01 5.7464760e-05 2.4551897e-05], sum to 1.0000
[2019-03-23 19:47:49,408] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9838
[2019-03-23 19:47:49,414] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.0, 89.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 333516.8153104829, 333516.8153104829, 141717.686914871], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3815400.0000, 
sim time next is 3816000.0000, 
raw observation next is [17.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 328772.1702185383, 328772.1702185383, 140874.9577816128], 
processed observation next is [0.0, 0.17391304347826086, 0.4090909090909091, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.12176747045131049, 0.12176747045131049, 0.3435974580039336], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7734801], dtype=float32), -0.086122185]. 
=============================================
[2019-03-23 19:47:49,428] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[-0.15657139]
 [-0.11513788]
 [-0.0773617 ]
 [-0.04108173]
 [-0.1193611 ]], R is [[-0.22314689]
 [-0.22091542]
 [-0.21870627]
 [-0.21651921]
 [-0.21435402]].
[2019-03-23 19:47:49,900] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 19:47:49,902] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:47:49,907] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:47:49,908] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:47:49,909] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:47:49,910] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:47:49,911] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:47:49,911] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:47:49,912] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:47:49,913] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:47:49,913] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:47:49,938] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run73
[2019-03-23 19:47:49,966] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run73
[2019-03-23 19:47:49,993] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run73
[2019-03-23 19:47:49,993] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run73
[2019-03-23 19:47:50,017] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run73
[2019-03-23 19:48:10,232] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00523546], dtype=float32), 0.013182834]
[2019-03-23 19:48:10,235] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.3, 53.83333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 314865.785575994, 314865.785575994, 125005.3977599795]
[2019-03-23 19:48:10,236] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:48:10,238] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.9181511e-03 1.7051389e-05 9.9480236e-01 1.6347267e-04 9.8975936e-05], sampled 0.9453132419806886
[2019-03-23 19:48:21,090] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00523546], dtype=float32), 0.013182834]
[2019-03-23 19:48:21,092] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.48333333333333, 66.83333333333333, 1.0, 2.0, 0.2066600779131638, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4111773463032311, 6.9112, 6.9112, 95.55338769695034, 469333.9710944173, 469333.9710944173, 168519.8484370754]
[2019-03-23 19:48:21,094] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:48:21,097] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.1536661e-03 2.5844397e-06 9.9572265e-01 6.3418374e-05 5.7657242e-05], sampled 0.5832060385722541
[2019-03-23 19:48:46,916] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00523546], dtype=float32), 0.013182834]
[2019-03-23 19:48:46,919] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.23639111, 77.46183231, 1.0, 2.0, 0.2352004112284659, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4753923316020012, 6.911200000000001, 6.9112, 95.55338769695034, 536485.4832774607, 536485.4832774603, 179574.8114478653]
[2019-03-23 19:48:46,920] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:48:46,926] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.2613541e-02 3.7291755e-07 9.8728704e-01 2.8213879e-05 7.0784197e-05], sampled 0.7568174916561247
[2019-03-23 19:48:47,424] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00523546], dtype=float32), 0.013182834]
[2019-03-23 19:48:47,427] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.63717307, 71.6906002, 1.0, 2.0, 0.2598728335286282, 0.0, 2.0, 0.0, 1.0, 2.0, 0.526285926259603, 6.9112, 6.9112, 95.55338769695034, 591446.9594663258, 591446.9594663258, 187097.6286291184]
[2019-03-23 19:48:47,428] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:48:47,431] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.6053310e-01 3.9290327e-09 8.3935291e-01 5.3864856e-06 1.0858180e-04], sampled 0.5620104018708989
[2019-03-23 19:48:52,682] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00523546], dtype=float32), 0.013182834]
[2019-03-23 19:48:52,684] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.3, 85.0, 1.0, 2.0, 0.2682704830851289, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5230006209085591, 6.9112, 6.9112, 95.55338769695034, 601628.7656398898, 601628.7656398898, 176177.7628345831]
[2019-03-23 19:48:52,685] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:48:52,690] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.8037967e-01 4.1370130e-09 8.1948274e-01 6.2180643e-06 1.3131750e-04], sampled 0.48186918897483966
[2019-03-23 19:49:05,187] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00523546], dtype=float32), 0.013182834]
[2019-03-23 19:49:05,188] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.6, 42.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 293731.3310226157, 293731.3310226157, 111414.4448586321]
[2019-03-23 19:49:05,190] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:49:05,193] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.6701875e-03 2.6394971e-05 9.9396944e-01 2.1310196e-04 1.2080886e-04], sampled 0.027249430538393904
[2019-03-23 19:49:10,098] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00523546], dtype=float32), 0.013182834]
[2019-03-23 19:49:10,099] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.2, 53.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 333138.0558205671, 333138.0558205674, 141867.0749311274]
[2019-03-23 19:49:10,102] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:49:10,105] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.5127176e-03 1.1714602e-05 9.9418229e-01 1.6630946e-04 1.2687354e-04], sampled 0.32678517485873915
[2019-03-23 19:49:16,768] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00523546], dtype=float32), 0.013182834]
[2019-03-23 19:49:16,770] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.45, 43.66666666666667, 1.0, 2.0, 0.3058713386210938, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6118733377064293, 6.911200000000001, 6.9112, 95.55338769695034, 696578.2384597055, 696578.2384597051, 192499.5353041815]
[2019-03-23 19:49:16,771] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:49:16,774] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.0829820e-01 1.7540200e-08 6.9112509e-01 2.5791045e-05 5.5097009e-04], sampled 0.16207886099206037
[2019-03-23 19:49:16,775] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 696578.2384597055 W.
[2019-03-23 19:49:26,492] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00523546], dtype=float32), 0.013182834]
[2019-03-23 19:49:26,493] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [14.8, 86.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 264788.2639448452, 264788.2639448452, 108737.4058077274]
[2019-03-23 19:49:26,494] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:49:26,497] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.5198146e-03 9.6901313e-06 9.9527574e-01 1.1467314e-04 8.0040627e-05], sampled 0.7074808863726121
[2019-03-23 19:49:34,779] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3140.9984 2070847805.8886 227.0000
[2019-03-23 19:49:34,840] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2617.8631 2101036918.7516 719.0000
[2019-03-23 19:49:34,910] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 2917.6256 2081004805.2738 367.0000
[2019-03-23 19:49:34,987] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3327.3369 2142923815.6981 298.0000
[2019-03-23 19:49:35,083] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3262.4707 2076483961.6827 244.0000
[2019-03-23 19:49:36,099] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1800000, evaluation results [1800000.0, 3327.336927782402, 2142923815.6981306, 298.0, 3140.9984173140074, 2070847805.888589, 227.0, 3262.470671742533, 2076483961.6827412, 244.0, 2617.8631491393985, 2101036918.7516472, 719.0, 2917.6255802734186, 2081004805.2738461, 367.0]
[2019-03-23 19:49:37,878] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.9218446e-03 6.5755266e-06 9.9696976e-01 7.5092474e-05 2.6744525e-05], sum to 1.0000
[2019-03-23 19:49:37,888] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6921
[2019-03-23 19:49:37,897] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.33333333333334, 57.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3104052297188694, 6.9112, 6.9112, 77.32846344354104, 359124.8409203329, 359124.8409203329, 146751.8817462061], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3865200.0000, 
sim time next is 3865800.0000, 
raw observation next is [22.16666666666667, 57.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.306457056722482, 6.9112, 6.9112, 77.32846344354104, 354823.0249299374, 354823.0249299374, 146037.5088967469], 
processed observation next is [0.0, 0.7391304347826086, 0.6439393939393941, 0.57, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.009224366746402908, 0.0, 0.0, 0.5084288129206541, 0.13141593515923608, 0.13141593515923608, 0.3561890460896266], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.35873377], dtype=float32), -0.3467897]. 
=============================================
[2019-03-23 19:49:38,359] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5236381e-01 1.4636864e-08 8.4667110e-01 7.3857955e-05 8.9124590e-04], sum to 1.0000
[2019-03-23 19:49:38,369] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0258
[2019-03-23 19:49:38,375] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 628423.0373215597 W.
[2019-03-23 19:49:38,379] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [18.0, 96.0, 1.0, 2.0, 0.2797168513585191, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5466252685890811, 6.9112, 6.9112, 77.32846344354104, 628423.0373215597, 628423.0373215597, 174389.037388883], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4030800.0000, 
sim time next is 4031400.0000, 
raw observation next is [18.0, 95.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3602682956125408, 6.9112, 6.9112, 77.3421103, 620364.2204287305, 620364.2204287305, 206296.6316896515], 
processed observation next is [1.0, 0.6521739130434783, 0.45454545454545453, 0.95, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0860975651607726, 0.0, 0.0, 0.5085185399722538, 0.22976452608471498, 0.22976452608471498, 0.5031625163162231], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.35988665], dtype=float32), 0.55555356]. 
=============================================
[2019-03-23 19:49:42,692] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.254758e-02 9.237831e-06 9.872820e-01 7.877876e-05 8.235568e-05], sum to 1.0000
[2019-03-23 19:49:42,700] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2262
[2019-03-23 19:49:42,707] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.16666666666666, 49.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3249840549161404, 6.9112, 6.9112, 77.32846344354104, 375290.1504259466, 375290.1504259466, 149101.5641480436], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3952200.0000, 
sim time next is 3952800.0000, 
raw observation next is [24.0, 50.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3224921273257171, 6.911200000000001, 6.9112, 77.32846344354104, 372522.4393481197, 372522.4393481194, 148704.2004065046], 
processed observation next is [0.0, 0.782608695652174, 0.7272727272727273, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.032131610465310136, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13797127383263694, 0.13797127383263683, 0.36269317172318194], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.79595816], dtype=float32), -1.0282085]. 
=============================================
[2019-03-23 19:49:43,422] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0497043e-01 4.0391305e-07 8.9461845e-01 2.5374413e-05 3.8535683e-04], sum to 1.0000
[2019-03-23 19:49:43,429] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5450
[2019-03-23 19:49:43,435] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.5, 80.0, 1.0, 1.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 304499.7885062752, 304499.7885062755, 133589.3087940153], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3981600.0000, 
sim time next is 3982200.0000, 
raw observation next is [17.41666666666667, 80.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.302818486585633, 6.911200000000001, 6.9112, 77.32846344354104, 352291.059178581, 352291.0591785807, 136913.6261863723], 
processed observation next is [1.0, 0.08695652173913043, 0.42803030303030326, 0.8033333333333335, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.004026409408047137, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1304781700661411, 0.130478170066141, 0.3339356736252983], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.02839683], dtype=float32), -2.1422908]. 
=============================================
[2019-03-23 19:49:48,019] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9879587e-01 2.0407336e-18 1.2040966e-03 1.1039664e-12 4.4769016e-10], sum to 1.0000
[2019-03-23 19:49:48,029] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7752
[2019-03-23 19:49:48,038] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.734033622842268, 7.080233714941771, 6.9112, 77.32788423874996, 477394.4369664472, 422496.1548923019, 129240.7670498822], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4150200.0000, 
sim time next is 4150800.0000, 
raw observation next is [18.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7332565661634209, 7.073781581845111, 6.9112, 77.32790554965916, 474850.5832047553, 422047.791743617, 129156.7018338231], 
processed observation next is [1.0, 0.043478260869565216, 0.45454545454545453, 1.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6189379516620299, 0.016258158184511106, 0.0, 0.5084251448104723, 0.1758705863721316, 0.15631399694208037, 0.3150163459361539], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.11563036], dtype=float32), 0.3215386]. 
=============================================
[2019-03-23 19:49:58,908] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9999559e-01 5.7494810e-17 4.3618938e-06 1.5000466e-11 1.5720661e-10], sum to 1.0000
[2019-03-23 19:49:58,917] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5819
[2019-03-23 19:49:58,921] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.637175416852973, 6.911199999999999, 6.9112, 77.32846344354104, 370044.9473056495, 370044.9473056498, 117065.9400971658], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4258800.0000, 
sim time next is 4259400.0000, 
raw observation next is [17.16666666666667, 94.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7088694576461019, 6.921809678097543, 6.9112, 77.32843781637254, 414932.9461279142, 411487.1408292404, 123937.5102765031], 
processed observation next is [1.0, 0.30434782608695654, 0.4166666666666669, 0.9400000000000002, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.584099225208717, 0.0010609678097543095, 0.0, 0.5084286444239547, 0.1536788689362645, 0.1524026447515705, 0.3022866104304954], 
reward next is 0.6447, 
noisyNet noise sample is [array([0.9214537], dtype=float32), 0.33384144]. 
=============================================
[2019-03-23 19:50:03,714] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.4637775e-01 7.2948586e-07 4.3767326e-02 3.6310553e-04 9.4910460e-03], sum to 1.0000
[2019-03-23 19:50:03,721] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7104
[2019-03-23 19:50:03,726] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1389374.01750747 W.
[2019-03-23 19:50:03,735] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 58.0, 1.0, 2.0, 0.7374340408555391, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9727516231028637, 6.911199999999999, 6.9112, 77.32846344354104, 1389374.01750747, 1389374.01750747, 293230.1539576032], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4362600.0000, 
sim time next is 4363200.0000, 
raw observation next is [27.0, 58.0, 1.0, 2.0, 0.3938661542210377, 1.0, 1.0, 0.3938661542210377, 1.0, 2.0, 0.7978556075142916, 6.9112, 6.9112, 77.3421103, 1342962.576445699, 1342962.576445699, 298315.1354733044], 
processed observation next is [1.0, 0.5217391304347826, 0.8636363636363636, 0.58, 1.0, 1.0, 0.24233269277629713, 1.0, 0.5, 0.24233269277629713, 1.0, 1.0, 0.7112222964489882, 0.0, 0.0, 0.5085185399722538, 0.49739354683174036, 0.49739354683174036, 0.7275978913983034], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6061585], dtype=float32), 0.09820225]. 
=============================================
[2019-03-23 19:50:06,272] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.7739476e-01 1.7656897e-07 2.2498436e-02 1.8935756e-05 8.7583685e-05], sum to 1.0000
[2019-03-23 19:50:06,279] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7043
[2019-03-23 19:50:06,283] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.83333333333333, 83.83333333333334, 1.0, 1.0, 0.44058134371713, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32825762652547, 499424.2428304167, 499424.2428304167, 130332.6612658509], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4421400.0000, 
sim time next is 4422000.0000, 
raw observation next is [20.66666666666667, 84.66666666666667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.754566431610131, 7.212935675401738, 6.9112, 77.32770540527822, 529714.0219746375, 431717.4068201789, 133410.0333622317], 
processed observation next is [0.0, 0.17391304347826086, 0.575757575757576, 0.8466666666666667, 0.0, 0.5, -0.25, 0.0, 1.0, -0.25, 1.0, 0.5, 0.6493806165859015, 0.030173567540173796, 0.0, 0.508423828876268, 0.19619037850912502, 0.15989533585932553, 0.3253903252737359], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.11659189], dtype=float32), 1.6112487]. 
=============================================
[2019-03-23 19:50:06,299] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[14.161842]
 [13.801219]
 [16.100668]
 [15.084105]
 [12.512713]], R is [[11.40450191]
 [11.29045677]
 [11.17755222]
 [11.06577682]
 [10.95511913]].
[2019-03-23 19:50:10,942] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.2755538e-01 1.9566271e-07 7.2284222e-02 2.1800399e-05 1.3836438e-04], sum to 1.0000
[2019-03-23 19:50:10,948] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1918
[2019-03-23 19:50:10,953] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.66666666666667, 53.5, 1.0, 1.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 323466.1045023467, 323466.104502347, 140084.1954141172], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4648200.0000, 
sim time next is 4648800.0000, 
raw observation next is [21.33333333333334, 54.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5484585793100467, 6.9112, 6.9112, 77.32846344354104, 318831.7772835155, 318831.7772835155, 97652.24831096885], 
processed observation next is [1.0, 0.8260869565217391, 0.6060606060606063, 0.54, 0.0, 0.5, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.35494082758578105, 0.0, 0.0, 0.5084288129206541, 0.11808584343833907, 0.11808584343833907, 0.23817621539260694], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7660605], dtype=float32), -0.486847]. 
=============================================
[2019-03-23 19:50:23,972] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.8760390e-01 1.4611008e-09 1.2382325e-02 1.4938533e-06 1.2236794e-05], sum to 1.0000
[2019-03-23 19:50:23,979] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1899
[2019-03-23 19:50:23,985] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.0, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7394866030894319, 7.125119920045383, 6.9112, 77.32774737526223, 495091.4873311711, 425615.3160807873, 129853.6645574812], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4752000.0000, 
sim time next is 4752600.0000, 
raw observation next is [19.83333333333334, 83.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7383044839194511, 7.116075798394702, 6.9112, 77.32777199911452, 491525.7134729775, 424986.8395620889, 129685.1866951065], 
processed observation next is [1.0, 0.0, 0.5378787878787882, 0.8383333333333334, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6261492627420732, 0.020487579839470183, 0.0, 0.5084242667257173, 0.18204656054554721, 0.15740253317114403, 0.3163053334026988], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.03126485], dtype=float32), 0.9835178]. 
=============================================
[2019-03-23 19:50:24,828] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 19:50:24,829] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:50:24,829] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:50:24,830] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:50:24,831] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:50:24,831] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:50:24,831] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:50:24,833] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:50:24,834] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:50:24,835] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:50:24,836] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:50:24,855] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run74
[2019-03-23 19:50:24,881] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run74
[2019-03-23 19:50:24,906] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run74
[2019-03-23 19:50:24,907] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run74
[2019-03-23 19:50:24,971] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run74
[2019-03-23 19:50:31,492] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00349718], dtype=float32), 0.013230862]
[2019-03-23 19:50:31,493] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.83333333333333, 89.0, 1.0, 1.0, 0.4967538204452396, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32818126852324, 539519.8121333433, 539519.8121333433, 119595.8708015906]
[2019-03-23 19:50:31,494] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:50:31,496] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.6262802e-01 1.7531920e-06 2.3551492e-01 5.5331952e-04 1.3019011e-03], sampled 0.015197354395220075
[2019-03-23 19:50:39,548] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00349718], dtype=float32), 0.013230862]
[2019-03-23 19:50:39,550] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.40974341666667, 89.44113584666667, 1.0, 2.0, 0.6693286311019944, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 752093.041286399, 752093.041286399, 173254.1700627541]
[2019-03-23 19:50:39,551] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:50:39,553] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.2741669e-01 2.0950076e-05 2.3843436e-01 8.2222698e-03 2.5905736e-02], sampled 0.16650755622452484
[2019-03-23 19:50:39,555] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 752093.041286399 W.
[2019-03-23 19:50:46,030] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00349718], dtype=float32), 0.013230862]
[2019-03-23 19:50:46,031] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [12.5, 71.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3447882146757877, 6.911199999999999, 6.9112, 77.32846344354104, 200979.3424372083, 200979.3424372086, 59767.31622900427]
[2019-03-23 19:50:46,034] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:50:46,037] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.9981028e-01 7.5197785e-16 1.8976572e-04 3.4821281e-11 5.1750260e-10], sampled 0.5588073519564072
[2019-03-23 19:51:12,193] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00349718], dtype=float32), 0.013230862]
[2019-03-23 19:51:12,194] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.41294478166667, 87.48313158333333, 1.0, 2.0, 0.5825820979693808, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 658054.3036532138, 658054.3036532138, 159985.4002631778]
[2019-03-23 19:51:12,197] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:51:12,199] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.4445391e-01 5.1098632e-06 2.4427944e-01 2.6839089e-03 8.5776746e-03], sampled 0.1536424782382143
[2019-03-23 19:51:12,200] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 658054.3036532138 W.
[2019-03-23 19:51:30,325] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00349718], dtype=float32), 0.013230862]
[2019-03-23 19:51:30,327] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.29454166833333, 44.56758414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6205775788119542, 6.9112, 6.9112, 95.5533876969501, 359356.2874343174, 359356.2874343174, 120708.9949847806]
[2019-03-23 19:51:30,328] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:51:30,331] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.8602539e-01 1.1668965e-11 1.3974434e-02 5.1072639e-08 1.7707278e-07], sampled 0.18589778707294347
[2019-03-23 19:51:44,221] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00349718], dtype=float32), 0.013230862]
[2019-03-23 19:51:44,222] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.9, 43.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.634852145714712, 6.9112, 6.9112, 95.55338769695034, 367772.2455708554, 367772.2455708554, 121847.8489743499]
[2019-03-23 19:51:44,225] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:51:44,227] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.1843537e-01 1.2391831e-07 1.8138683e-01 5.4370321e-05 1.2331444e-04], sampled 0.3597371326261548
[2019-03-23 19:51:57,858] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00349718], dtype=float32), 0.013230862]
[2019-03-23 19:51:57,861] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.1, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7243184076273284, 7.266022599691754, 6.9112, 95.55206172229377, 560732.3345440566, 418335.4045699693, 131432.1468126239]
[2019-03-23 19:51:57,862] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:51:57,864] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.3963374e-01 4.1254174e-07 2.5981560e-01 1.8648268e-04 3.6366345e-04], sampled 0.11633392421082911
[2019-03-23 19:51:57,866] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 560732.3345440566 W.
[2019-03-23 19:52:09,006] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 5945.8255 1761597275.6830 2645.0000
[2019-03-23 19:52:09,161] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 5631.6847 1755931226.1760 2860.0000
[2019-03-23 19:52:09,740] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6143.2764 1857071311.4934 2151.0000
[2019-03-23 19:52:09,829] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 5921.1743 1743753470.6569 2806.0000
[2019-03-23 19:52:09,870] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 5837.9089 1782031761.4785 3174.0000
[2019-03-23 19:52:10,885] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1825000, evaluation results [1825000.0, 6143.276373234145, 1857071311.4933743, 2151.0, 5921.174267503044, 1743753470.6568792, 2806.0, 5631.684736439048, 1755931226.1759748, 2860.0, 5837.908921403826, 1782031761.4784846, 3174.0, 5945.825538177117, 1761597275.6829805, 2645.0]
[2019-03-23 19:52:13,224] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.9249150e-01 1.3490667e-07 1.4636701e-01 2.6879171e-03 5.8453426e-02], sum to 1.0000
[2019-03-23 19:52:13,237] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5450
[2019-03-23 19:52:13,243] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 574403.2866782722 W.
[2019-03-23 19:52:13,246] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.01666666666667, 99.83333333333334, 1.0, 2.0, 0.251823588165612, 0.0, 1.0, 0.0, 1.0, 2.0, 0.509138799849056, 6.9112, 6.9112, 77.32846344354104, 574403.2866782722, 574403.2866782722, 178842.8312570651], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4817400.0000, 
sim time next is 4818000.0000, 
raw observation next is [21.03333333333333, 99.66666666666667, 1.0, 2.0, 0.2512646346448758, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5078099972278116, 6.9112, 6.9112, 77.32846344354104, 573234.2477062718, 573234.2477062718, 178458.3818540069], 
processed observation next is [1.0, 0.782608695652174, 0.5924242424242423, 0.9966666666666667, 1.0, 1.0, 0.06408079330609474, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2968714246111595, 0.0, 0.0, 0.5084288129206541, 0.21230898063195253, 0.21230898063195253, 0.4352643459853827], 
reward next is 0.5647, 
noisyNet noise sample is [array([-0.53571415], dtype=float32), 0.2848897]. 
=============================================
[2019-03-23 19:52:13,262] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[28.973625]
 [29.245234]
 [29.22357 ]
 [29.102144]
 [29.267633]], R is [[29.93380165]
 [30.19826126]
 [29.89627838]
 [29.59731674]
 [29.30134392]].
[2019-03-23 19:52:17,404] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.5390416e-01 1.2974031e-08 7.4076247e-01 7.3518910e-05 5.2598375e-03], sum to 1.0000
[2019-03-23 19:52:17,414] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8355
[2019-03-23 19:52:17,421] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.66666666666666, 74.66666666666667, 1.0, 2.0, 0.2108165050632562, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4210117969325676, 6.9112, 6.9112, 77.32846344354104, 479705.1466662485, 479705.1466662485, 165561.4303947387], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4902000.0000, 
sim time next is 4902600.0000, 
raw observation next is [22.83333333333334, 73.83333333333333, 1.0, 2.0, 0.2120141459425659, 0.0, 2.0, 0.0, 1.0, 2.0, 0.423577561980415, 6.911200000000001, 6.9112, 77.32846344354104, 482522.1380291688, 482522.1380291685, 165893.8090250727], 
processed observation next is [1.0, 0.7391304347826086, 0.6742424242424245, 0.7383333333333333, 1.0, 1.0, 0.015017682428207363, 0.0, 1.0, -0.25, 1.0, 1.0, 0.17653937425773578, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17871190297376624, 0.1787119029737661, 0.4046190464026163], 
reward next is 0.5954, 
noisyNet noise sample is [array([1.2568926], dtype=float32), 1.9412045]. 
=============================================
[2019-03-23 19:52:27,010] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9967730e-01 9.5155995e-20 3.2270097e-04 6.7621629e-14 4.3722014e-12], sum to 1.0000
[2019-03-23 19:52:27,017] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1866
[2019-03-23 19:52:27,026] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.1, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4043338310564029, 6.911199999999999, 6.9112, 77.32846344354104, 235167.3590242715, 235167.3590242718, 70277.25343893848], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5680800.0000, 
sim time next is 5681400.0000, 
raw observation next is [16.1, 68.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4049584630683197, 6.911199999999999, 6.9112, 77.32846344354104, 235530.7434733007, 235530.743473301, 69911.79742063477], 
processed observation next is [0.0, 0.782608695652174, 0.3681818181818182, 0.6816666666666668, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.149940661526171, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08723360869381508, 0.08723360869381519, 0.17051657907471895], 
reward next is 0.8295, 
noisyNet noise sample is [array([-1.1116081], dtype=float32), -1.1873215]. 
=============================================
[2019-03-23 19:52:28,176] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.7380960e-01 2.3855307e-11 5.2618784e-01 5.2154303e-07 2.0543384e-06], sum to 1.0000
[2019-03-23 19:52:28,189] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3774
[2019-03-23 19:52:28,194] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.0, 83.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7527931715802993, 7.191312186258277, 6.9112, 77.32777277715276, 521188.6744716018, 430214.7782090173, 133552.0480692091], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5103000.0000, 
sim time next is 5103600.0000, 
raw observation next is [20.66666666666666, 84.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7697411428727426, 7.34020462789227, 6.9112, 77.3272231976403, 579891.2085927695, 440561.5148146155, 135073.234775861], 
processed observation next is [0.0, 0.043478260869565216, 0.5757575757575755, 0.8466666666666667, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6710587755324896, 0.04290046278922697, 0.0, 0.5084206583974299, 0.21477452170102573, 0.16317093141282055, 0.32944691408746585], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.877623], dtype=float32), -0.8827514]. 
=============================================
[2019-03-23 19:52:40,339] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.5379112e-02 3.0955572e-08 9.7066283e-01 3.9299528e-05 3.9187567e-03], sum to 1.0000
[2019-03-23 19:52:40,344] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1343
[2019-03-23 19:52:40,349] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.7, 51.0, 1.0, 2.0, 0.880827180692173, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9778975598648437, 6.9112, 6.9112, 77.32846344354104, 1548856.095089136, 1548856.095089136, 322593.005390432], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5326200.0000, 
sim time next is 5326800.0000, 
raw observation next is [29.8, 51.0, 1.0, 2.0, 0.8937368021898395, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9784365468317233, 6.9112, 6.9112, 77.32846344354104, 1562916.976707082, 1562916.976707082, 325496.7118594247], 
processed observation next is [1.0, 0.6521739130434783, 0.990909090909091, 0.51, 1.0, 1.0, 0.8671710027372994, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9691950669024619, 0.0, 0.0, 0.5084288129206541, 0.5788581395211415, 0.5788581395211415, 0.7938944191693286], 
reward next is 0.2061, 
noisyNet noise sample is [array([0.820567], dtype=float32), 2.7856023]. 
=============================================
[2019-03-23 19:52:41,026] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1584768e-01 9.4364163e-15 8.8415211e-01 4.3923803e-10 2.2304795e-07], sum to 1.0000
[2019-03-23 19:52:41,034] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6157
[2019-03-23 19:52:41,041] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.71666666666667, 51.83333333333334, 1.0, 2.0, 0.2427694900210747, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4910605328074042, 6.9112, 6.9112, 77.32846344354104, 553570.4216004944, 553570.4216004944, 177079.0619110439], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5335800.0000, 
sim time next is 5336400.0000, 
raw observation next is [28.63333333333334, 50.66666666666667, 1.0, 2.0, 0.2382187457121418, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4813251926290518, 6.9112, 6.9112, 77.32846344354104, 543504.6431941066, 543504.6431941066, 175342.8092275364], 
processed observation next is [1.0, 0.782608695652174, 0.9378787878787882, 0.5066666666666667, 1.0, 1.0, 0.047773432140177235, 0.0, 1.0, -0.25, 1.0, 1.0, 0.25903598947007406, 0.0, 0.0, 0.5084288129206541, 0.20129801599781727, 0.20129801599781727, 0.4276653883598449], 
reward next is 0.5723, 
noisyNet noise sample is [array([-0.20720936], dtype=float32), -0.5746443]. 
=============================================
[2019-03-23 19:52:41,630] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.4735346e-02 6.7284795e-13 9.5526367e-01 6.3390648e-09 8.8036154e-07], sum to 1.0000
[2019-03-23 19:52:41,635] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1231
[2019-03-23 19:52:41,641] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.25, 87.0, 1.0, 2.0, 0.2082851887995075, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4126508653197458, 6.911200000000001, 6.9112, 77.32846344354104, 471957.3311010795, 471957.3311010792, 163171.720018482], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5373000.0000, 
sim time next is 5373600.0000, 
raw observation next is [20.16666666666666, 87.0, 1.0, 2.0, 0.2149647225809107, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4254499410156783, 6.9112, 6.9112, 77.32846344354104, 486810.1205946115, 486810.1205946115, 164140.8577243587], 
processed observation next is [1.0, 0.17391304347826086, 0.5530303030303028, 0.87, 1.0, 1.0, 0.018705903226138368, 0.0, 1.0, -0.25, 1.0, 1.0, 0.179214201450969, 0.0, 0.0, 0.5084288129206541, 0.18030004466467092, 0.18030004466467092, 0.4003435554252651], 
reward next is 0.5997, 
noisyNet noise sample is [array([-0.7805833], dtype=float32), 0.2823363]. 
=============================================
[2019-03-23 19:52:45,616] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4934871e-04 9.2237275e-13 9.9985063e-01 4.6920001e-09 9.3201278e-09], sum to 1.0000
[2019-03-23 19:52:45,624] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6941
[2019-03-23 19:52:45,627] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.9, 96.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3907511318773754, 6.911200000000001, 6.9112, 77.32846344354104, 447569.1542469403, 447569.15424694, 160416.1401049536], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5428200.0000, 
sim time next is 5428800.0000, 
raw observation next is [18.8, 97.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3901208960704592, 6.9112, 6.9112, 77.32846344354104, 446908.8309264296, 446908.8309264296, 160278.2819858238], 
processed observation next is [1.0, 0.8695652173913043, 0.49090909090909096, 0.97, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.12874413724351316, 0.0, 0.0, 0.5084288129206541, 0.16552178923201097, 0.16552178923201097, 0.3909226389898141], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.16196291], dtype=float32), -0.43403864]. 
=============================================
[2019-03-23 19:52:47,576] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.5743362e-03 1.3727139e-10 9.9733269e-01 5.5907658e-06 8.7397595e-05], sum to 1.0000
[2019-03-23 19:52:47,590] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2835
[2019-03-23 19:52:47,597] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.25, 82.83333333333334, 1.0, 2.0, 0.409660278993406, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8244424717488446, 6.9112, 6.9112, 77.32846344354104, 935101.3056346566, 935101.3056346566, 223440.5930198591], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5478600.0000, 
sim time next is 5479200.0000, 
raw observation next is [22.7, 82.0, 1.0, 2.0, 0.4548208466651263, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9173778193464128, 6.911199999999999, 6.9112, 77.32846344354104, 1038499.669351031, 1038499.669351031, 242719.6755675336], 
processed observation next is [1.0, 0.43478260869565216, 0.6681818181818181, 0.82, 1.0, 1.0, 0.31852605833140785, 0.0, 1.0, -0.25, 1.0, 1.0, 0.8819683133520183, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3846295071670485, 0.3846295071670485, 0.5919992087013014], 
reward next is 0.4080, 
noisyNet noise sample is [array([-1.1464018], dtype=float32), -1.0780398]. 
=============================================
[2019-03-23 19:52:50,982] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.0954855e-03 2.1997558e-15 9.9290425e-01 2.6976107e-10 2.1090268e-07], sum to 1.0000
[2019-03-23 19:52:50,992] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8917
[2019-03-23 19:52:50,998] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.0, 93.0, 1.0, 2.0, 0.23730424871335, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4728200052132695, 6.9112, 6.9112, 77.32846344354104, 539411.0411615721, 539411.0411615721, 170110.1155810398], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5544600.0000, 
sim time next is 5545200.0000, 
raw observation next is [20.0, 93.0, 1.0, 2.0, 0.2218248701982336, 0.0, 2.0, 0.0, 1.0, 2.0, 0.442005137938367, 6.911199999999999, 6.9112, 77.32846344354104, 504222.573061463, 504222.5730614632, 167049.0129184262], 
processed observation next is [1.0, 0.17391304347826086, 0.5454545454545454, 0.93, 1.0, 1.0, 0.02728108774779199, 0.0, 1.0, -0.25, 1.0, 1.0, 0.20286448276909572, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1867491011338752, 0.18674910113387524, 0.40743661687421023], 
reward next is 0.5926, 
noisyNet noise sample is [array([0.30693743], dtype=float32), 0.4010683]. 
=============================================
[2019-03-23 19:52:54,973] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.0177700e-05 3.1202854e-10 9.9995959e-01 1.0174481e-07 1.0913834e-07], sum to 1.0000
[2019-03-23 19:52:54,981] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2940
[2019-03-23 19:52:54,987] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.8, 93.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3634712212556092, 6.9112, 6.9112, 77.32846344354104, 417448.531666485, 417448.531666485, 155822.6289223738], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6235200.0000, 
sim time next is 6235800.0000, 
raw observation next is [18.71666666666667, 93.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3625430385794554, 6.9112, 6.9112, 77.32846344354104, 416426.431527683, 416426.431527683, 155664.9611880001], 
processed observation next is [0.0, 0.17391304347826086, 0.48712121212121223, 0.935, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0893471979706506, 0.0, 0.0, 0.5084288129206541, 0.15423201167691963, 0.15423201167691963, 0.3796706370439027], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1080444], dtype=float32), 0.18154132]. 
=============================================
[2019-03-23 19:52:59,468] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 19:52:59,470] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:52:59,470] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:52:59,470] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:52:59,471] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:52:59,471] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:52:59,473] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:52:59,472] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:52:59,474] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:52:59,476] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:52:59,475] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:52:59,499] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run75
[2019-03-23 19:52:59,525] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run75
[2019-03-23 19:52:59,546] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run75
[2019-03-23 19:52:59,549] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run75
[2019-03-23 19:52:59,549] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run75
[2019-03-23 19:53:05,283] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00329927], dtype=float32), 0.013536688]
[2019-03-23 19:53:05,284] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.47507556333333, 50.63490465333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 314360.913657801, 314360.913657801, 117943.0022201282]
[2019-03-23 19:53:05,284] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:53:05,287] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.0401875e-05 8.8590926e-11 9.9992955e-01 1.8384711e-08 2.9427138e-08], sampled 0.32670122762225495
[2019-03-23 19:54:40,472] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00329927], dtype=float32), 0.013536688]
[2019-03-23 19:54:40,475] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.61303329833333, 89.04488316166666, 1.0, 2.0, 0.2181209650479873, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4383208574890987, 6.911200000000001, 6.9112, 95.55338769695034, 497451.1583819412, 497451.1583819409, 173481.2699317108]
[2019-03-23 19:54:40,475] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:54:40,478] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0492929e-04 5.2219513e-13 9.9989510e-01 1.1562531e-09 7.7459630e-09], sampled 0.726587159532121
[2019-03-23 19:54:44,957] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3513.7520 2103632899.2446 180.0000
[2019-03-23 19:54:45,224] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3353.3823 2097328276.6424 182.0000
[2019-03-23 19:54:45,226] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3113.0749 2108433463.8311 369.0000
[2019-03-23 19:54:45,291] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3607.5501 2174295034.5624 245.0000
[2019-03-23 19:54:45,311] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2758.7932 2123442254.0537 754.0000
[2019-03-23 19:54:46,331] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1850000, evaluation results [1850000.0, 3607.55013105262, 2174295034.5624204, 245.0, 3353.3823046099724, 2097328276.6424353, 182.0, 3513.7519551494897, 2103632899.2446437, 180.0, 2758.793237018324, 2123442254.0536845, 754.0, 3113.074918867456, 2108433463.8310764, 369.0]
[2019-03-23 19:54:50,694] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.4673807e-05 2.2883052e-10 9.9990523e-01 5.0169010e-08 7.3615851e-08], sum to 1.0000
[2019-03-23 19:54:50,703] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6127
[2019-03-23 19:54:50,712] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [15.35, 62.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 213331.6425302906, 213331.6425302903, 88939.08999679284], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5787000.0000, 
sim time next is 5787600.0000, 
raw observation next is [15.1, 62.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 210168.5346503376, 210168.5346503376, 87952.0462424913], 
processed observation next is [0.0, 1.0, 0.3227272727272727, 0.62, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.07784019801864356, 0.07784019801864356, 0.21451718595729585], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6226956], dtype=float32), -0.2969355]. 
=============================================
[2019-03-23 19:54:51,122] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.2934381e-04 1.4878161e-15 9.9907070e-01 2.0795406e-10 7.5291053e-09], sum to 1.0000
[2019-03-23 19:54:51,131] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3279
[2019-03-23 19:54:51,134] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.5, 70.5, 1.0, 2.0, 0.2378336670560666, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4794672670113072, 6.911199999999999, 6.9112, 77.32846344354104, 542773.103711047, 542773.1037110473, 174134.2992333166], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6414600.0000, 
sim time next is 6415200.0000, 
raw observation next is [24.4, 71.0, 1.0, 2.0, 0.2348088281985342, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4733072539388758, 6.9112, 6.9112, 77.32846344354104, 535863.0885063449, 535863.0885063449, 173422.4564173607], 
processed observation next is [1.0, 0.2608695652173913, 0.7454545454545454, 0.71, 1.0, 1.0, 0.04351103524816772, 0.0, 1.0, -0.25, 1.0, 1.0, 0.24758179134125116, 0.0, 0.0, 0.5084288129206541, 0.19846781055790552, 0.19846781055790552, 0.4229816010179529], 
reward next is 0.5770, 
noisyNet noise sample is [array([-0.6599516], dtype=float32), -0.10259073]. 
=============================================
[2019-03-23 19:54:54,281] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.3844814e-05 9.8907535e-11 9.9997616e-01 1.5248741e-08 3.1141035e-08], sum to 1.0000
[2019-03-23 19:54:54,287] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1501
[2019-03-23 19:54:54,290] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.85, 49.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3102989219231631, 6.9112, 6.9112, 77.32846344354104, 358824.7777768279, 358824.7777768279, 146920.6368955926], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5859000.0000, 
sim time next is 5859600.0000, 
raw observation next is [23.66666666666667, 50.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3094275010668978, 6.911199999999999, 6.9112, 77.32846344354104, 357946.9600855766, 357946.9600855769, 146690.4301877692], 
processed observation next is [1.0, 0.8260869565217391, 0.7121212121212124, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.013467858666996894, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13257294817984316, 0.1325729481798433, 0.35778153704333954], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8415339], dtype=float32), -1.1425525]. 
=============================================
[2019-03-23 19:55:02,961] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.75095727e-03 7.40486006e-10 9.92132485e-01 1.11845793e-05
 1.05329396e-04], sum to 1.0000
[2019-03-23 19:55:02,972] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5597
[2019-03-23 19:55:02,976] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.1, 58.0, 1.0, 2.0, 0.2858909364879148, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5744924485475783, 6.9112, 6.9112, 77.32846344354104, 652171.7836743697, 652171.7836743697, 184139.2398138286], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6008400.0000, 
sim time next is 6009000.0000, 
raw observation next is [26.1, 58.33333333333334, 1.0, 2.0, 0.3462749461494093, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6963809343036952, 6.9112, 6.9112, 77.32846344354104, 790183.8931772348, 790183.8931772348, 201581.1663189575], 
processed observation next is [1.0, 0.5652173913043478, 0.8227272727272728, 0.5833333333333335, 1.0, 1.0, 0.1828436826867616, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5662584775767074, 0.0, 0.0, 0.5084288129206541, 0.29266070117675363, 0.29266070117675363, 0.49166138126575], 
reward next is 0.5083, 
noisyNet noise sample is [array([0.17665128], dtype=float32), 0.32211488]. 
=============================================
[2019-03-23 19:55:02,992] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[30.054178]
 [30.80327 ]
 [30.306631]
 [30.505787]
 [30.424318]], R is [[31.5488987 ]
 [31.78429031]
 [32.02655029]
 [32.25049591]
 [32.43024826]].
[2019-03-23 19:55:03,922] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.9652187e-04 1.8126839e-09 9.9980241e-01 3.5079395e-07 6.8066572e-07], sum to 1.0000
[2019-03-23 19:55:03,934] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8272
[2019-03-23 19:55:03,936] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.51666666666667, 80.83333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 279113.8770824423, 279113.877082442, 113470.8604244217], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6052200.0000, 
sim time next is 6052800.0000, 
raw observation next is [16.43333333333334, 80.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 275380.6546022744, 275380.6546022746, 111915.9281922388], 
processed observation next is [1.0, 0.043478260869565216, 0.3833333333333337, 0.8066666666666668, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10199283503787941, 0.10199283503787948, 0.27296567851765563], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.06073139], dtype=float32), 0.37194306]. 
=============================================
[2019-03-23 19:55:06,694] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.9983614e-03 2.0484417e-12 9.9099296e-01 1.3497457e-07 8.5483398e-06], sum to 1.0000
[2019-03-23 19:55:06,699] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1198
[2019-03-23 19:55:06,703] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.98333333333333, 64.0, 1.0, 2.0, 0.2024216772673155, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3778769257234379, 6.9112, 6.9112, 77.32846344354104, 439651.5502084343, 439651.5502084343, 133655.2958250122], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6081000.0000, 
sim time next is 6081600.0000, 
raw observation next is [18.26666666666667, 63.0, 1.0, 2.0, 0.2028509030980834, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3786781963163967, 6.911199999999999, 6.9112, 77.32846344354104, 440584.2334525276, 440584.2334525278, 134478.7348566657], 
processed observation next is [1.0, 0.391304347826087, 0.4666666666666668, 0.63, 1.0, 1.0, 0.003563628872604238, 0.0, 1.0, -0.25, 1.0, 1.0, 0.11239742330913818, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16317934572315837, 0.16317934572315843, 0.32799691428455047], 
reward next is 0.6720, 
noisyNet noise sample is [array([0.60260713], dtype=float32), -1.8769846]. 
=============================================
[2019-03-23 19:55:11,746] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7452032e-03 2.7695162e-12 9.9825448e-01 2.3547299e-08 3.0755157e-07], sum to 1.0000
[2019-03-23 19:55:11,755] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5683
[2019-03-23 19:55:11,758] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.05, 72.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3468567609642237, 6.911200000000001, 6.9112, 77.32846344354104, 399314.879975106, 399314.8799751057, 152856.6827096964], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6204600.0000, 
sim time next is 6205200.0000, 
raw observation next is [20.86666666666667, 73.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3489057803382912, 6.9112, 6.9112, 77.32846344354104, 401653.7341402482, 401653.7341402482, 153126.113564288], 
processed observation next is [1.0, 0.8260869565217391, 0.5848484848484851, 0.7333333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.06986540048327321, 0.0, 0.0, 0.5084288129206541, 0.148760642274166, 0.148760642274166, 0.3734783257665561], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5402866], dtype=float32), -0.6615873]. 
=============================================
[2019-03-23 19:55:23,495] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.4103117e-03 3.0798817e-18 9.9458969e-01 3.8547041e-11 5.9155205e-08], sum to 1.0000
[2019-03-23 19:55:23,499] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0024
[2019-03-23 19:55:23,505] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 560348.3742844616 W.
[2019-03-23 19:55:23,509] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.6, 71.0, 1.0, 2.0, 0.2455326035487369, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4953983661612916, 6.911199999999999, 6.9112, 77.32846344354104, 560348.3742844616, 560348.3742844618, 176227.230566278], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6416400.0000, 
sim time next is 6417000.0000, 
raw observation next is [24.7, 71.0, 1.0, 2.0, 0.2498202833437081, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5043082704272472, 6.9112, 6.9112, 77.32846344354104, 570109.6660890091, 570109.6660890091, 177465.1732654899], 
processed observation next is [1.0, 0.2608695652173913, 0.759090909090909, 0.71, 1.0, 1.0, 0.0622753541796351, 0.0, 1.0, -0.25, 1.0, 1.0, 0.29186895775321037, 0.0, 0.0, 0.5084288129206541, 0.2111517281811145, 0.2111517281811145, 0.43284188601338996], 
reward next is 0.5672, 
noisyNet noise sample is [array([1.0607015], dtype=float32), 0.8571851]. 
=============================================
[2019-03-23 19:55:23,540] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[59.36159 ]
 [59.390682]
 [59.372665]
 [59.338333]
 [59.254898]], R is [[59.26669312]
 [59.24420547]
 [59.22472382]
 [59.20949554]
 [59.19268417]].
[2019-03-23 19:55:34,907] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 19:55:34,908] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:55:34,908] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:55:34,909] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:55:34,910] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:55:34,911] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:55:34,912] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:55:34,913] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:55:34,914] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:55:34,915] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:55:34,915] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:55:34,935] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run76
[2019-03-23 19:55:34,960] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run76
[2019-03-23 19:55:34,987] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run76
[2019-03-23 19:55:35,011] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run76
[2019-03-23 19:55:35,012] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run76
[2019-03-23 19:55:53,021] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00318164], dtype=float32), 0.013827711]
[2019-03-23 19:55:53,023] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.02921303, 98.71520064166668, 1.0, 2.0, 0.203871932174601, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4044646684097886, 6.911200000000001, 6.9112, 95.55338769695034, 462274.3452799727, 462274.3452799724, 167356.0502525746]
[2019-03-23 19:55:53,025] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:55:53,029] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.7285025e-05 1.6291792e-13 9.9990273e-01 1.9404227e-09 1.9294442e-08], sampled 0.03638872696650719
[2019-03-23 19:55:56,199] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00318164], dtype=float32), 0.013827711]
[2019-03-23 19:55:56,200] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.7, 57.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 95.55338769695034, 312973.9413910108, 312973.9413910112, 134446.3315027364]
[2019-03-23 19:55:56,201] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:55:56,204] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.7675192e-05 9.1655667e-12 9.9995232e-01 1.0507227e-08 2.3148871e-08], sampled 0.5727302063558601
[2019-03-23 19:55:57,504] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00318164], dtype=float32), 0.013827711]
[2019-03-23 19:55:57,506] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [11.66666666666667, 85.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3679942183365364, 6.911199999999999, 6.9112, 77.32846344354104, 428148.1732179042, 428148.1732179045, 121132.5208277983]
[2019-03-23 19:55:57,507] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:55:57,512] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.3506835e-04 2.8937779e-12 9.9986494e-01 8.5630365e-09 4.3456506e-08], sampled 0.3421105994746414
[2019-03-23 19:56:07,194] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00318164], dtype=float32), 0.013827711]
[2019-03-23 19:56:07,195] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [13.91077591666667, 94.48647713333332, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 252765.9219445299, 252765.9219445295, 106157.0458326889]
[2019-03-23 19:56:07,202] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:56:07,205] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.0512230e-05 1.1319503e-11 9.9993944e-01 1.3731121e-08 3.5729787e-08], sampled 0.7976366822318174
[2019-03-23 19:56:10,280] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00318164], dtype=float32), 0.013827711]
[2019-03-23 19:56:10,282] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.1, 80.33333333333334, 1.0, 2.0, 0.2008571389059288, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3976686250820016, 6.9112, 6.9112, 95.55338769695034, 454900.4648559582, 454900.4648559582, 166381.1913377859]
[2019-03-23 19:56:10,284] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:56:10,286] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.0150635e-04 9.4113941e-15 9.9979848e-01 3.4493480e-10 7.2881923e-09], sampled 0.37258252018227456
[2019-03-23 19:56:38,117] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00318164], dtype=float32), 0.013827711]
[2019-03-23 19:56:38,118] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.55, 52.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3354153937234181, 6.911200000000001, 6.9112, 95.55338769695034, 387338.0857698392, 387338.0857698388, 154861.6275244569]
[2019-03-23 19:56:38,118] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:56:38,123] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.3367359e-05 1.3092015e-11 9.9995661e-01 1.6020822e-08 3.6800255e-08], sampled 0.8026730870361496
[2019-03-23 19:56:44,919] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00318164], dtype=float32), 0.013827711]
[2019-03-23 19:56:44,920] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.34616262, 97.13635979, 1.0, 2.0, 0.2109447535343047, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4198627033199724, 6.911199999999999, 6.9112, 95.55338769695034, 479164.2031290034, 479164.2031290038, 169395.1328706738]
[2019-03-23 19:56:44,921] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:56:44,926] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.6403437e-04 1.1907867e-13 9.9973601e-01 2.8601310e-09 5.5200569e-08], sampled 0.23371678207349322
[2019-03-23 19:56:46,737] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00318164], dtype=float32), 0.013827711]
[2019-03-23 19:56:46,738] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.72545291666667, 87.02377434, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3915317555555105, 6.911200000000001, 6.9112, 95.55338769695034, 449477.2533787345, 449477.2533787342, 164243.0255008562]
[2019-03-23 19:56:46,739] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:56:46,743] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.0566060e-05 5.8674116e-13 9.9991941e-01 3.7742436e-09 2.4587093e-08], sampled 0.13619270362963565
[2019-03-23 19:57:20,508] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3611.0811 2174832736.3331 245.0000
[2019-03-23 19:57:20,868] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3359.2748 2097591344.6109 179.0000
[2019-03-23 19:57:20,902] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3517.9389 2103766614.5156 180.0000
[2019-03-23 19:57:21,020] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3115.9667 2108718300.2020 370.0000
[2019-03-23 19:57:21,269] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2758.6565 2123624822.5826 756.0000
[2019-03-23 19:57:22,286] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1875000, evaluation results [1875000.0, 3611.08114650988, 2174832736.333051, 245.0, 3359.2747913119106, 2097591344.610937, 179.0, 3517.938853620562, 2103766614.5156157, 180.0, 2758.656518182576, 2123624822.582649, 756.0, 3115.9667130882895, 2108718300.2019813, 370.0]
[2019-03-23 19:57:22,451] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.5584808e-05 1.6439310e-12 9.9990404e-01 5.0842077e-09 3.1762531e-07], sum to 1.0000
[2019-03-23 19:57:22,458] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0881
[2019-03-23 19:57:22,462] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.61666666666667, 73.0, 1.0, 2.0, 0.2095275352794237, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4172981706281192, 6.9112, 6.9112, 77.32846344354104, 476138.7301653822, 476138.7301653822, 164625.5756877754], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6905400.0000, 
sim time next is 6906000.0000, 
raw observation next is [22.53333333333333, 73.0, 1.0, 2.0, 0.2082456483414122, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4143698699167872, 6.9112, 6.9112, 77.32846344354104, 473002.816162949, 473002.816162949, 164172.2463951197], 
processed observation next is [0.0, 0.9565217391304348, 0.6606060606060605, 0.73, 1.0, 1.0, 0.010307060426765248, 0.0, 1.0, -0.25, 1.0, 1.0, 0.16338552845255316, 0.0, 0.0, 0.5084288129206541, 0.17518622820849963, 0.17518622820849963, 0.40042011315882853], 
reward next is 0.5996, 
noisyNet noise sample is [array([1.5065883], dtype=float32), 1.1722463]. 
=============================================
[2019-03-23 19:57:22,488] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[23.131418]
 [23.515621]
 [24.149218]
 [24.666143]
 [25.111357]], R is [[23.04391098]
 [23.41194725]
 [23.7753315 ]
 [24.13420486]
 [24.48849106]].
[2019-03-23 19:57:23,839] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.0709726e-05 4.7212711e-12 9.9997926e-01 3.0904388e-08 3.1880592e-08], sum to 1.0000
[2019-03-23 19:57:23,852] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0033
[2019-03-23 19:57:23,860] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.63333333333333, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3325970119910668, 6.9112, 6.9112, 77.32846344354104, 383503.622525898, 383503.622525898, 150552.1206441279], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6672000.0000, 
sim time next is 6672600.0000, 
raw observation next is [18.55, 88.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3298600204221045, 6.911199999999999, 6.9112, 77.32846344354104, 380403.5938163807, 380403.5938163809, 150174.5171231351], 
processed observation next is [1.0, 0.21739130434782608, 0.47954545454545455, 0.885, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.042657172031577865, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14089021993199285, 0.1408902199319929, 0.36627931005642705], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.4380076], dtype=float32), 1.3796577]. 
=============================================
[2019-03-23 19:57:27,444] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.0495116e-05 2.7593433e-10 9.9997938e-01 6.5780704e-08 2.4441883e-08], sum to 1.0000
[2019-03-23 19:57:27,453] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2849
[2019-03-23 19:57:27,457] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.18333333333333, 93.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3418438466291839, 6.911200000000001, 6.9112, 77.32846344354104, 395912.5611690438, 395912.5611690435, 149939.746193805], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6747000.0000, 
sim time next is 6747600.0000, 
raw observation next is [17.16666666666667, 93.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3171163368860197, 6.9112, 6.9112, 77.32846344354104, 367264.8328952009, 367264.8328952009, 147123.4194483782], 
processed observation next is [1.0, 0.08695652173913043, 0.4166666666666669, 0.9333333333333335, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.024451909837171017, 0.0, 0.0, 0.5084288129206541, 0.13602401218340773, 0.13602401218340773, 0.3588376084106785], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.04996467], dtype=float32), 0.65880674]. 
=============================================
[2019-03-23 19:57:28,062] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.0336589e-06 3.0512751e-10 9.9999082e-01 9.0332016e-08 1.7771828e-08], sum to 1.0000
[2019-03-23 19:57:28,073] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0250
[2019-03-23 19:57:28,077] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.7, 76.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 289506.6364545124, 289506.6364545127, 121647.9600657815], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6765600.0000, 
sim time next is 6766200.0000, 
raw observation next is [17.7, 76.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 292423.4329327655, 292423.4329327655, 123053.2382922359], 
processed observation next is [1.0, 0.30434782608695654, 0.44090909090909086, 0.765, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.10830497516028352, 0.10830497516028352, 0.30012984949325827], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.503006], dtype=float32), -0.0924153]. 
=============================================
[2019-03-23 19:57:32,353] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.8516810e-05 4.7091674e-14 9.9996150e-01 2.5224106e-10 4.4519012e-08], sum to 1.0000
[2019-03-23 19:57:32,364] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0445
[2019-03-23 19:57:32,373] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.38333333333333, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3404098279894412, 6.9112, 6.9112, 77.32846344354104, 392500.4300626648, 392500.4300626648, 151493.6631295719], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6839400.0000, 
sim time next is 6840000.0000, 
raw observation next is [18.3, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3371251785866727, 6.9112, 6.9112, 77.32846344354104, 388883.6315345434, 388883.6315345434, 150936.5880926542], 
processed observation next is [0.0, 0.17391304347826086, 0.4681818181818182, 0.9, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.05303596940953242, 0.0, 0.0, 0.5084288129206541, 0.14403097464242348, 0.14403097464242348, 0.36813801973818094], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.49101016], dtype=float32), 0.28415206]. 
=============================================
[2019-03-23 19:57:32,389] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[24.460726]
 [24.693174]
 [24.941011]
 [25.23129 ]
 [25.646366]], R is [[23.80499649]
 [23.56694603]
 [23.33127594]
 [23.09796333]
 [22.86698341]].
[2019-03-23 19:57:35,979] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.2404386e-05 2.7144116e-14 9.9995756e-01 4.9253568e-10 6.8232535e-09], sum to 1.0000
[2019-03-23 19:57:35,988] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7991
[2019-03-23 19:57:35,992] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.53333333333333, 73.0, 1.0, 2.0, 0.2082456483414122, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4143698699167872, 6.9112, 6.9112, 77.32846344354104, 473002.816162949, 473002.816162949, 164172.2463951197], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6906000.0000, 
sim time next is 6906600.0000, 
raw observation next is [22.45, 73.0, 1.0, 2.0, 0.2064999881008023, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4105116846296308, 6.911200000000001, 6.9112, 77.32846344354104, 468802.7765014977, 468802.7765014974, 163636.3411755653], 
processed observation next is [0.0, 0.9565217391304348, 0.6568181818181817, 0.73, 1.0, 1.0, 0.008124985126002869, 0.0, 1.0, -0.25, 1.0, 1.0, 0.15787383518518686, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17363065796351768, 0.17363065796351757, 0.3991130272574763], 
reward next is 0.6009, 
noisyNet noise sample is [array([-2.6495976], dtype=float32), -0.8678669]. 
=============================================
[2019-03-23 19:57:36,479] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.5206447e-05 4.7920557e-14 9.9997485e-01 9.5653893e-12 2.1092954e-09], sum to 1.0000
[2019-03-23 19:57:36,490] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6021
[2019-03-23 19:57:36,495] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.4, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3770960101791709, 6.911200000000001, 6.9112, 77.32846344354104, 432511.6028482381, 432511.6028482378, 158090.9447748919], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6919800.0000, 
sim time next is 6920400.0000, 
raw observation next is [19.4, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3771442069949985, 6.9112, 6.9112, 77.32846344354104, 432564.3422708478, 432564.3422708478, 158099.479364243], 
processed observation next is [0.0, 0.08695652173913043, 0.5181818181818181, 0.9, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.11020600999285504, 0.0, 0.0, 0.5084288129206541, 0.16020901565586956, 0.16020901565586956, 0.3856084862542512], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3240402], dtype=float32), -1.3741771]. 
=============================================
[2019-03-23 19:57:45,446] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.6863694e-05 3.0392931e-11 9.9995148e-01 5.3831524e-08 1.6547385e-06], sum to 1.0000
[2019-03-23 19:57:45,454] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6217
[2019-03-23 19:57:45,457] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.7, 94.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3267325017597582, 6.9112, 6.9112, 77.32846344354104, 377212.6909169267, 377212.6909169267, 149399.8035256783], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7086000.0000, 
sim time next is 7086600.0000, 
raw observation next is [17.7, 95.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3292111499822993, 6.911200000000001, 6.9112, 77.32846344354104, 379928.0829551502, 379928.0829551499, 149832.1887623314], 
processed observation next is [1.0, 0.0, 0.44090909090909086, 0.95, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.041730214260427556, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1407141047982038, 0.14071410479820365, 0.3654443628349547], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.15817882], dtype=float32), -0.8545115]. 
=============================================
[2019-03-23 19:57:48,926] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.6943421e-03 1.3295643e-08 9.9709785e-01 1.0949070e-05 1.9683749e-04], sum to 1.0000
[2019-03-23 19:57:48,931] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3141
[2019-03-23 19:57:48,935] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.8, 52.0, 1.0, 2.0, 0.3989929764906666, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7740809714711241, 6.911200000000001, 6.9112, 77.32846344354104, 892114.4854371776, 892114.4854371772, 204191.2899927052], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7146000.0000, 
sim time next is 7146600.0000, 
raw observation next is [23.61666666666667, 52.16666666666667, 1.0, 2.0, 0.2464253917661969, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4761211758458334, 6.9112, 6.9112, 77.32846344354104, 549159.1404561462, 549159.1404561462, 165110.1419212498], 
processed observation next is [1.0, 0.7391304347826086, 0.7098484848484851, 0.5216666666666667, 1.0, 1.0, 0.05803173970774612, 0.0, 1.0, -0.25, 1.0, 1.0, 0.25160167977976206, 0.0, 0.0, 0.5084288129206541, 0.20339227424301712, 0.20339227424301712, 0.40270766322256046], 
reward next is 0.5973, 
noisyNet noise sample is [array([0.5916637], dtype=float32), -0.30797306]. 
=============================================
[2019-03-23 19:57:51,083] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.5799267e-04 2.0183777e-11 9.9943799e-01 1.9897975e-07 3.7670038e-06], sum to 1.0000
[2019-03-23 19:57:51,091] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8854
[2019-03-23 19:57:51,105] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.7, 79.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 223726.6277330149, 223726.6277330146, 93344.47294874443], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7198200.0000, 
sim time next is 7198800.0000, 
raw observation next is [15.16666666666667, 77.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 227790.7954775517, 227790.7954775514, 94924.71083201167], 
processed observation next is [1.0, 0.30434782608695654, 0.3257575757575759, 0.7766666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08436696128798211, 0.084366961287982, 0.23152368495612602], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.25420618], dtype=float32), 2.149459]. 
=============================================
[2019-03-23 19:57:52,867] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.1987811e-04 2.4470479e-09 9.9951088e-01 1.1622221e-05 5.7602600e-05], sum to 1.0000
[2019-03-23 19:57:52,876] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3554
[2019-03-23 19:57:52,884] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.66666666666666, 71.16666666666667, 1.0, 2.0, 0.4338286019339933, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8644309150508789, 6.911199999999999, 6.9112, 77.32846344354104, 986604.6346777442, 986604.6346777445, 226700.2105092031], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7377000.0000, 
sim time next is 7377600.0000, 
raw observation next is [23.13333333333333, 69.33333333333334, 1.0, 2.0, 0.4113903937469693, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8212192081806391, 6.911199999999999, 6.9112, 77.32846344354104, 936358.1759241127, 936358.1759241129, 219484.2558450488], 
processed observation next is [1.0, 0.391304347826087, 0.6878787878787876, 0.6933333333333335, 1.0, 1.0, 0.2642379921837116, 0.0, 1.0, -0.25, 1.0, 1.0, 0.7445988688294845, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.34679932441633804, 0.3467993244163381, 0.5353274532806068], 
reward next is 0.4647, 
noisyNet noise sample is [array([-0.7976649], dtype=float32), -1.1976303]. 
=============================================
[2019-03-23 19:57:58,902] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:57:58,903] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:57:58,924] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run10
[2019-03-23 19:58:02,541] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.3938667e-04 1.8793408e-11 9.9975640e-01 8.1873850e-08 4.0665350e-06], sum to 1.0000
[2019-03-23 19:58:02,549] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2565
[2019-03-23 19:58:02,553] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.8, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3632933288333152, 6.911199999999999, 6.9112, 77.32846344354104, 418005.1064006044, 418005.1064006047, 155102.8293614238], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7426200.0000, 
sim time next is 7426800.0000, 
raw observation next is [18.8, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3610116350897293, 6.911199999999999, 6.9112, 77.32846344354104, 415383.3110193202, 415383.3110193205, 154813.8081274401], 
processed observation next is [1.0, 1.0, 0.49090909090909096, 0.9, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.08715947869961327, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15384567074789637, 0.15384567074789648, 0.3775946539693661], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.21538061], dtype=float32), 0.80545574]. 
=============================================
[2019-03-23 19:58:02,708] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.6010142e-04 3.5018283e-10 9.9932516e-01 1.4455615e-06 1.3332023e-05], sum to 1.0000
[2019-03-23 19:58:02,715] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0678
[2019-03-23 19:58:02,724] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.8, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3655905454285165, 6.911199999999999, 6.9112, 77.32846344354104, 420645.4461756428, 420645.4461756431, 155394.0779731873], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7425600.0000, 
sim time next is 7426200.0000, 
raw observation next is [18.8, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3632933288333152, 6.911199999999999, 6.9112, 77.32846344354104, 418005.1064006044, 418005.1064006047, 155102.8293614238], 
processed observation next is [1.0, 0.9565217391304348, 0.49090909090909096, 0.9, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.09041904119045034, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15481670607429793, 0.15481670607429804, 0.3782995838083507], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6873798], dtype=float32), 0.60208166]. 
=============================================
[2019-03-23 19:58:04,306] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.8755971e-05 1.7431869e-16 9.9997127e-01 5.2334928e-11 3.1058947e-09], sum to 1.0000
[2019-03-23 19:58:04,313] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2037
[2019-03-23 19:58:04,318] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.66666666666666, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3391580365098909, 6.911200000000001, 6.9112, 77.32846344354104, 390661.2741461231, 390661.2741461229, 151723.0224854552], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7458000.0000, 
sim time next is 7458600.0000, 
raw observation next is [19.03333333333333, 88.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3454789007856215, 6.9112, 6.9112, 77.32846344354104, 397541.1448824763, 397541.1448824763, 152865.0677964241], 
processed observation next is [0.0, 0.30434782608695654, 0.5015151515151515, 0.885, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.06496985826517358, 0.0, 0.0, 0.5084288129206541, 0.1472374610675838, 0.1472374610675838, 0.3728416287717661], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.29918158], dtype=float32), -0.16980511]. 
=============================================
[2019-03-23 19:58:06,677] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.6873223e-02 3.6604959e-17 9.7312683e-01 9.1188210e-11 2.4393110e-08], sum to 1.0000
[2019-03-23 19:58:06,687] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7140
[2019-03-23 19:58:06,691] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.5, 83.33333333333334, 1.0, 2.0, 0.2320116294263969, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4674033127110879, 6.9112, 6.9112, 77.32846344354104, 529452.7776144287, 529452.7776144287, 172585.3887215773], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7521600.0000, 
sim time next is 7522200.0000, 
raw observation next is [22.4, 84.0, 1.0, 2.0, 0.2323429971120254, 0.0, 2.0, 0.0, 1.0, 2.0, 0.468045549388402, 6.9112, 6.9112, 77.32846344354104, 530206.3516643425, 530206.3516643425, 172633.2965560457], 
processed observation next is [0.0, 0.043478260869565216, 0.6545454545454544, 0.84, 1.0, 1.0, 0.04042874639003175, 0.0, 1.0, -0.25, 1.0, 1.0, 0.24006507055486, 0.0, 0.0, 0.5084288129206541, 0.19637272283864535, 0.19637272283864535, 0.4210568208684042], 
reward next is 0.5789, 
noisyNet noise sample is [array([1.0124258], dtype=float32), 0.11657231]. 
=============================================
[2019-03-23 19:58:07,030] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.0064918e-03 1.4177866e-10 9.9382979e-01 4.4924312e-07 1.6325772e-04], sum to 1.0000
[2019-03-23 19:58:07,034] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.2493789e-03 4.1417933e-17 9.9775058e-01 1.6472852e-12 8.5427452e-09], sum to 1.0000
[2019-03-23 19:58:07,036] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5724
[2019-03-23 19:58:07,042] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 41.5, 1.0, 2.0, 0.3845310313075135, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7178351939246991, 6.911199999999999, 6.9112, 77.32846344354104, 835525.5767180694, 835525.5767180697, 185506.3185028941], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 139800.0000, 
sim time next is 140400.0000, 
raw observation next is [23.0, 41.0, 1.0, 2.0, 0.3854872468413951, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7196202388425663, 6.911199999999999, 6.9112, 77.32846344354104, 837605.0741915789, 837605.0741915791, 185130.0253944741], 
processed observation next is [1.0, 0.6521739130434783, 0.6818181818181818, 0.41, 1.0, 1.0, 0.23185905855174388, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5994574840608091, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3102241015524366, 0.31022410155243674, 0.4515366473035954], 
reward next is 0.5485, 
noisyNet noise sample is [array([0.45379007], dtype=float32), -0.058778226]. 
=============================================
[2019-03-23 19:58:07,046] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5755
[2019-03-23 19:58:07,048] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.35, 91.5, 1.0, 2.0, 0.2306455120752344, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4643914139944299, 6.911200000000001, 6.9112, 77.32846344354104, 526296.5555374571, 526296.5555374568, 172071.7367741808], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7529400.0000, 
sim time next is 7530000.0000, 
raw observation next is [21.26666666666667, 92.0, 1.0, 2.0, 0.230065713521997, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4631556709947736, 6.911200000000001, 6.9112, 77.32846344354104, 524960.9808319473, 524960.980831947, 171892.2926233536], 
processed observation next is [0.0, 0.13043478260869565, 0.6030303030303031, 0.92, 1.0, 1.0, 0.037582141902496244, 0.0, 1.0, -0.25, 1.0, 1.0, 0.23307952999253376, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19442999290072122, 0.19442999290072108, 0.41924949420330143], 
reward next is 0.5808, 
noisyNet noise sample is [array([0.20597664], dtype=float32), 0.7750629]. 
=============================================
[2019-03-23 19:58:07,062] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[57.384457]
 [57.387707]
 [57.39177 ]
 [57.20916 ]
 [56.74915 ]], R is [[57.37444687]
 [57.38101578]
 [57.38720322]
 [57.39313889]
 [57.39883804]].
[2019-03-23 19:58:10,463] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.3911048e-05 1.1702072e-14 9.9994612e-01 3.3411918e-10 6.4824675e-09], sum to 1.0000
[2019-03-23 19:58:10,470] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1155
[2019-03-23 19:58:10,474] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.33333333333334, 76.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 273338.1063524649, 273338.1063524646, 114779.7817631363], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 205800.0000, 
sim time next is 206400.0000, 
raw observation next is [17.66666666666667, 75.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 280014.9157525974, 280014.9157525974, 118846.0766492737], 
processed observation next is [0.0, 0.391304347826087, 0.4393939393939396, 0.7566666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.10370922805651756, 0.10370922805651756, 0.2898684796323749], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6654258], dtype=float32), 0.0330166]. 
=============================================
[2019-03-23 19:58:10,688] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 19:58:10,694] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:58:10,695] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:58:10,696] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:58:10,696] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:58:10,697] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:58:10,698] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:58:10,699] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:58:10,700] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:58:10,699] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:58:10,702] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:58:10,720] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run77
[2019-03-23 19:58:10,744] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run77
[2019-03-23 19:58:10,770] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run77
[2019-03-23 19:58:10,771] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run77
[2019-03-23 19:58:10,794] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run77
[2019-03-23 19:58:35,833] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00303272], dtype=float32), 0.014063791]
[2019-03-23 19:58:35,834] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.0, 90.0, 1.0, 2.0, 0.209769832036116, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4160802857174121, 6.9112, 6.9112, 95.55338769695034, 475597.9531557263, 475597.9531557263, 168364.4750676872]
[2019-03-23 19:58:35,835] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:58:35,839] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.2131251e-03 5.8144101e-18 9.9878687e-01 8.2632434e-12 2.5289240e-09], sampled 0.5352826837196454
[2019-03-23 19:58:44,190] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00303272], dtype=float32), 0.014063791]
[2019-03-23 19:58:44,191] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.163293, 57.85439792, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3661960345927448, 6.911199999999999, 6.9112, 95.55338769695034, 425610.754827586, 425610.7548275864, 156009.5191849655]
[2019-03-23 19:58:44,192] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:58:44,195] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.7138689e-04 2.2078298e-17 9.9932861e-01 8.5607970e-12 1.7146196e-09], sampled 0.5729135512866012
[2019-03-23 19:59:56,854] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3514.7489 2103718577.1112 182.0000
[2019-03-23 19:59:56,953] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3358.8187 2097526272.3758 184.0000
[2019-03-23 19:59:56,998] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2756.2643 2123525356.3443 759.0000
[2019-03-23 19:59:57,044] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3119.6021 2108749048.2619 368.0000
[2019-03-23 19:59:57,235] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3611.1251 2174709583.4357 248.0000
[2019-03-23 19:59:58,254] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1900000, evaluation results [1900000.0, 3611.1251237051392, 2174709583.4357166, 248.0, 3358.8186581357404, 2097526272.37583, 184.0, 3514.7488822988153, 2103718577.1112304, 182.0, 2756.264262123874, 2123525356.3443284, 759.0, 3119.602094419266, 2108749048.2618923, 368.0]
[2019-03-23 19:59:58,728] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.8683798e-04 4.2245133e-15 9.9971145e-01 2.4465217e-09 1.6809238e-06], sum to 1.0000
[2019-03-23 19:59:58,738] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9107
[2019-03-23 19:59:58,742] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.0, 96.0, 1.0, 2.0, 0.2163337642814205, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4325810075419673, 6.9112, 6.9112, 77.32846344354104, 492546.1759293742, 492546.1759293742, 166945.4059433903], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7608600.0000, 
sim time next is 7609200.0000, 
raw observation next is [20.0, 96.0, 1.0, 2.0, 0.2166359424211106, 0.0, 2.0, 0.0, 1.0, 2.0, 0.433186027787709, 6.9112, 6.9112, 77.32846344354104, 493234.9068481887, 493234.9068481887, 167003.5625996653], 
processed observation next is [1.0, 0.043478260869565216, 0.5454545454545454, 0.96, 1.0, 1.0, 0.020794928026388222, 0.0, 1.0, -0.25, 1.0, 1.0, 0.19026575398244144, 0.0, 0.0, 0.5084288129206541, 0.1826795951289588, 0.1826795951289588, 0.40732576243820806], 
reward next is 0.5927, 
noisyNet noise sample is [array([1.0514306], dtype=float32), 2.4773724]. 
=============================================
[2019-03-23 19:59:59,105] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.3336699e-03 1.8606231e-14 9.9466634e-01 3.6991338e-10 5.5582028e-08], sum to 1.0000
[2019-03-23 19:59:59,112] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7146
[2019-03-23 19:59:59,123] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.0, 96.0, 1.0, 2.0, 0.2180878817247554, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4360303297448939, 6.9112, 6.9112, 77.32846344354104, 496513.2129724653, 496513.2129724653, 167243.6250418337], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7596000.0000, 
sim time next is 7596600.0000, 
raw observation next is [20.01666666666667, 96.0, 1.0, 2.0, 0.2183185537257525, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4366094989562476, 6.9112, 6.9112, 77.32846344354104, 497096.705571554, 497096.705571554, 167364.1704180957], 
processed observation next is [0.0, 0.9565217391304348, 0.5462121212121214, 0.96, 1.0, 1.0, 0.022898192157190626, 0.0, 1.0, -0.25, 1.0, 1.0, 0.19515642708035377, 0.0, 0.0, 0.5084288129206541, 0.1841098909524274, 0.1841098909524274, 0.4082052937026724], 
reward next is 0.5918, 
noisyNet noise sample is [array([-1.1129634], dtype=float32), 0.99277276]. 
=============================================
[2019-03-23 20:00:00,845] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.0202661e-04 1.7614421e-14 9.9959463e-01 2.4346374e-08 3.3647311e-06], sum to 1.0000
[2019-03-23 20:00:00,855] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8974
[2019-03-23 20:00:00,860] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.5, 93.0, 1.0, 2.0, 0.2137261265026064, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4279210352251878, 6.9112, 6.9112, 77.32846344354104, 486868.59425632, 486868.59425632, 166819.3152702445], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7628400.0000, 
sim time next is 7629000.0000, 
raw observation next is [20.6, 93.0, 1.0, 2.0, 0.2437697249218357, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4885493902966753, 6.9112, 6.9112, 77.32846344354104, 555555.050915594, 555555.050915594, 173215.2552448025], 
processed observation next is [1.0, 0.30434782608695654, 0.5727272727272728, 0.93, 1.0, 1.0, 0.054712156152294626, 0.0, 1.0, -0.25, 1.0, 1.0, 0.26935627185239336, 0.0, 0.0, 0.5084288129206541, 0.20576112996873852, 0.20576112996873852, 0.42247623230439635], 
reward next is 0.5775, 
noisyNet noise sample is [array([-0.11681715], dtype=float32), 1.090574]. 
=============================================
[2019-03-23 20:00:00,876] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[48.90271 ]
 [48.87712 ]
 [48.871857]
 [48.870674]
 [48.90566 ]], R is [[48.32715988]
 [48.43701172]
 [48.54628372]
 [48.65387344]
 [48.75965881]].
[2019-03-23 20:00:02,257] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.4195075e-03 1.4025561e-09 9.9390393e-01 3.0894033e-05 1.6455759e-03], sum to 1.0000
[2019-03-23 20:00:02,266] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4906
[2019-03-23 20:00:02,271] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.71666666666667, 53.33333333333334, 1.0, 2.0, 0.4915286454567321, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9490619346401745, 6.955958684360144, 6.9112, 77.3283536431582, 1107816.529588762, 1093279.845022986, 256646.7385732283], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7654200.0000, 
sim time next is 7654800.0000, 
raw observation next is [28.63333333333334, 53.66666666666667, 1.0, 2.0, 0.5462185406180055, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9684608839152103, 6.922196966314671, 6.9112, 77.32840818701021, 1170204.097869726, 1166632.510689727, 266835.2438370677], 
processed observation next is [1.0, 0.6086956521739131, 0.9378787878787882, 0.5366666666666667, 1.0, 1.0, 0.4327731757725068, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9549441198788721, 0.0010996966314671397, 0.0, 0.5084284496131328, 0.4334089251369355, 0.4320861150702693, 0.650817667895287], 
reward next is 0.2942, 
noisyNet noise sample is [array([0.2288507], dtype=float32), -0.31133243]. 
=============================================
[2019-03-23 20:00:03,858] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.8070910e-04 1.8565690e-13 9.9961913e-01 7.3004482e-09 9.8431137e-08], sum to 1.0000
[2019-03-23 20:00:03,870] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6362
[2019-03-23 20:00:03,874] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.38333333333333, 99.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3766644160531797, 6.911200000000001, 6.9112, 77.32846344354104, 431840.4271786676, 431840.4271786673, 158190.7965151201], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7703400.0000, 
sim time next is 7704000.0000, 
raw observation next is [18.3, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3758536160164991, 6.911199999999999, 6.9112, 77.32846344354104, 430980.8860293704, 430980.8860293707, 158022.9369457229], 
processed observation next is [1.0, 0.17391304347826086, 0.4681818181818182, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.10836230859499871, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1596225503812483, 0.15962255038124842, 0.38542179742859245], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.33452535], dtype=float32), -0.78601116]. 
=============================================
[2019-03-23 20:00:03,890] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[31.426697]
 [31.740025]
 [32.26354 ]
 [33.069904]
 [32.88661 ]], R is [[30.85932159]
 [30.55072784]
 [30.24522018]
 [29.9427681 ]
 [29.64334106]].
[2019-03-23 20:00:04,669] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:00:04,670] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:00:04,734] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run10
[2019-03-23 20:00:05,740] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.5789029e-04 1.5189499e-12 9.9973243e-01 2.9010041e-08 9.6484591e-06], sum to 1.0000
[2019-03-23 20:00:05,746] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2089
[2019-03-23 20:00:05,752] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.01666666666667, 48.16666666666666, 1.0, 2.0, 0.360141596504222, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6791442316088706, 6.911199999999999, 6.9112, 77.32846344354104, 788055.073846591, 788055.0738465913, 185373.425005365], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7743000.0000, 
sim time next is 7743600.0000, 
raw observation next is [23.3, 48.0, 1.0, 2.0, 0.3674585669635184, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6964622507527182, 6.911200000000001, 6.9112, 77.32846344354104, 807286.2870434107, 807286.2870434104, 188506.7495221003], 
processed observation next is [1.0, 0.6521739130434783, 0.6954545454545454, 0.48, 1.0, 1.0, 0.209323208704398, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5663746439324546, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2989949211271892, 0.298994921127189, 0.4597725598100007], 
reward next is 0.5402, 
noisyNet noise sample is [array([0.15501481], dtype=float32), -0.030553233]. 
=============================================
[2019-03-23 20:00:10,883] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:00:10,884] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:00:10,887] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.8623495e-03 1.9455949e-12 9.9512982e-01 5.0433937e-07 7.2992707e-06], sum to 1.0000
[2019-03-23 20:00:10,898] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5729
[2019-03-23 20:00:10,901] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.1, 45.5, 1.0, 2.0, 0.3081705499230553, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5862522951101771, 6.911200000000001, 6.9112, 77.32846344354104, 678887.269035562, 678887.2690355617, 174852.9237377637], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7828200.0000, 
sim time next is 7828800.0000, 
raw observation next is [24.2, 45.66666666666666, 1.0, 2.0, 0.3418382941026251, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6522431134260046, 6.9112, 6.9112, 77.32846344354104, 754842.5673044021, 754842.5673044021, 183534.9370533341], 
processed observation next is [1.0, 0.6086956521739131, 0.7363636363636363, 0.45666666666666655, 1.0, 1.0, 0.17729786762828137, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5032044477514352, 0.0, 0.0, 0.5084288129206541, 0.27957132122385264, 0.27957132122385264, 0.44764618793496125], 
reward next is 0.5524, 
noisyNet noise sample is [array([-0.75688756], dtype=float32), 1.4924303]. 
=============================================
[2019-03-23 20:00:10,929] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run10
[2019-03-23 20:00:12,526] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:00:12,527] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:00:12,539] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.2370666e-04 2.3635047e-11 9.9957460e-01 1.6009274e-07 1.5002856e-06], sum to 1.0000
[2019-03-23 20:00:12,545] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7185
[2019-03-23 20:00:12,548] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.1, 66.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 302014.4477021217, 302014.4477021214, 125716.4861031719], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7864200.0000, 
sim time next is 7864800.0000, 
raw observation next is [19.0, 67.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 299415.5285997028, 299415.528599703, 124813.6289113481], 
processed observation next is [1.0, 0.0, 0.5, 0.67, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11089464022211215, 0.11089464022211222, 0.3044234851496295], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.13322327], dtype=float32), -1.2848629]. 
=============================================
[2019-03-23 20:00:12,589] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run10
[2019-03-23 20:00:14,768] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:00:14,769] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:00:14,811] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run10
[2019-03-23 20:00:15,684] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.9124908e-04 4.3283758e-13 9.9960762e-01 1.4822746e-08 1.1513940e-06], sum to 1.0000
[2019-03-23 20:00:15,690] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0459
[2019-03-23 20:00:15,695] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.9, 96.0, 1.0, 2.0, 0.2134064402433121, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4263293549333653, 6.9112, 6.9112, 77.32846344354104, 485677.0539028645, 485677.0539028645, 166134.8797146471], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7941600.0000, 
sim time next is 7942200.0000, 
raw observation next is [19.81666666666667, 93.5, 1.0, 2.0, 0.2102263394852764, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4186325210972457, 6.9112, 6.9112, 77.32846344354104, 477694.0203219989, 477694.0203219989, 164718.4010858844], 
processed observation next is [1.0, 0.9565217391304348, 0.5371212121212122, 0.935, 1.0, 1.0, 0.01278292435659547, 0.0, 1.0, -0.25, 1.0, 1.0, 0.16947503013892246, 0.0, 0.0, 0.5084288129206541, 0.17692371123036996, 0.17692371123036996, 0.40175219777044974], 
reward next is 0.5982, 
noisyNet noise sample is [array([-0.983984], dtype=float32), -0.5040392]. 
=============================================
[2019-03-23 20:00:16,763] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:00:16,764] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:00:16,780] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run10
[2019-03-23 20:00:16,877] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:00:16,878] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:00:16,910] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run10
[2019-03-23 20:00:16,977] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:00:16,977] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:00:16,991] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run10
[2019-03-23 20:00:17,029] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:00:17,034] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:00:17,036] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:00:17,043] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:00:17,075] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run10
[2019-03-23 20:00:17,116] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run10
[2019-03-23 20:00:17,155] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:00:17,156] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:00:17,168] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run10
[2019-03-23 20:00:17,276] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:00:17,276] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:00:17,281] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:00:17,281] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:00:17,292] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run10
[2019-03-23 20:00:17,324] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run10
[2019-03-23 20:00:17,424] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:00:17,425] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:00:17,434] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run10
[2019-03-23 20:00:17,470] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:00:17,470] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:00:17,482] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run10
[2019-03-23 20:00:17,520] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:00:17,520] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:00:17,535] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run10
[2019-03-23 20:00:19,127] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.17466356e-04 1.71180773e-07 9.99874830e-01 2.78094399e-06
 4.67188056e-06], sum to 1.0000
[2019-03-23 20:00:19,134] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5647
[2019-03-23 20:00:19,139] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.0, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 250157.3272193348, 250157.3272193345, 101969.6089651652], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 85800.0000, 
sim time next is 86400.0000, 
raw observation next is [16.0, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 248864.7016678201, 248864.7016678204, 101707.5922224774], 
processed observation next is [1.0, 0.0, 0.36363636363636365, 0.77, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09217211172882227, 0.09217211172882236, 0.2480672981036034], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1303837], dtype=float32), 0.97151655]. 
=============================================
[2019-03-23 20:00:19,431] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.5810109e-05 1.7523892e-09 9.9995339e-01 4.0009860e-07 4.9235030e-07], sum to 1.0000
[2019-03-23 20:00:19,438] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6244
[2019-03-23 20:00:19,443] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3332330093891047, 6.911200000000001, 6.9112, 77.32846344354104, 384804.1644088887, 384804.1644088885, 150074.8817987568], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 21600.0000, 
sim time next is 22200.0000, 
raw observation next is [17.16666666666667, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3327541679002065, 6.911199999999999, 6.9112, 77.32846344354104, 384036.6511989605, 384036.6511989608, 150229.0473469785], 
processed observation next is [1.0, 0.2608695652173913, 0.4166666666666669, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.046791668428866465, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14223579674035575, 0.14223579674035586, 0.3664123106023866], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.76344466], dtype=float32), 0.59009534]. 
=============================================
[2019-03-23 20:00:24,220] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.5974705e-05 5.7527355e-10 9.9998391e-01 3.0878251e-08 6.5631866e-08], sum to 1.0000
[2019-03-23 20:00:24,229] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7123
[2019-03-23 20:00:24,233] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [13.33333333333333, 92.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 208176.3252267966, 208176.3252267966, 90351.24731699463], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 184800.0000, 
sim time next is 185400.0000, 
raw observation next is [13.5, 91.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 209490.0626140104, 209490.0626140106, 90771.2001939905], 
processed observation next is [0.0, 0.13043478260869565, 0.25, 0.91, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07758891207926312, 0.07758891207926318, 0.22139317120485488], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.14667968], dtype=float32), 0.24840255]. 
=============================================
[2019-03-23 20:00:27,887] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.8208371e-05 5.5858771e-09 9.9995112e-01 4.1789036e-07 2.5052830e-07], sum to 1.0000
[2019-03-23 20:00:27,894] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5930
[2019-03-23 20:00:27,898] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.5, 52.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 271085.1894282, 271085.1894282, 111868.6010586882], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 304200.0000, 
sim time next is 304800.0000, 
raw observation next is [20.66666666666667, 51.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 272439.7278200043, 272439.7278200043, 111895.303608286], 
processed observation next is [0.0, 0.5217391304347826, 0.575757575757576, 0.5133333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.10090360289629788, 0.10090360289629788, 0.2729153746543561], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7632745], dtype=float32), -0.6853054]. 
=============================================
[2019-03-23 20:00:42,629] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.4810102e-05 3.4001377e-09 9.9992454e-01 2.4605772e-06 2.8096134e-05], sum to 1.0000
[2019-03-23 20:00:42,646] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1491
[2019-03-23 20:00:42,653] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 58.0, 1.0, 2.0, 0.2312566539565409, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4669281435028881, 6.9112, 6.9112, 77.32846344354104, 527705.9912611725, 527705.9912611725, 173445.0236328036], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 756000.0000, 
sim time next is 756600.0000, 
raw observation next is [27.0, 58.0, 1.0, 2.0, 0.2343441720748811, 0.0, 2.0, 0.0, 1.0, 2.0, 0.473137363437105, 6.9112, 6.9112, 77.32846344354104, 534760.148857882, 534760.148857882, 174083.2870903304], 
processed observation next is [1.0, 0.782608695652174, 0.8636363636363636, 0.58, 1.0, 1.0, 0.04293021509360135, 0.0, 1.0, -0.25, 1.0, 1.0, 0.24733909062443574, 0.0, 0.0, 0.5084288129206541, 0.19805931439180816, 0.19805931439180816, 0.42459338314714734], 
reward next is 0.5754, 
noisyNet noise sample is [array([0.48916933], dtype=float32), 0.5338446]. 
=============================================
[2019-03-23 20:00:45,589] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.4407388e-05 5.4761435e-09 9.9995482e-01 5.1806461e-07 2.0883570e-07], sum to 1.0000
[2019-03-23 20:00:45,595] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3489
[2019-03-23 20:00:45,600] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 238232.2293173193, 238232.2293173191, 99022.84457801934], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 529200.0000, 
sim time next is 529800.0000, 
raw observation next is [14.0, 94.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 241440.2315209266, 241440.2315209266, 99612.12143859599], 
processed observation next is [1.0, 0.13043478260869565, 0.2727272727272727, 0.9400000000000002, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.08942230797071356, 0.08942230797071356, 0.24295639375267314], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6537807], dtype=float32), 1.0522391]. 
=============================================
[2019-03-23 20:00:47,411] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 20:00:47,416] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:00:47,416] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:00:47,417] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:00:47,417] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:00:47,418] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:00:47,418] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:00:47,418] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:00:47,419] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:00:47,419] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:00:47,421] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:00:47,442] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run78
[2019-03-23 20:00:47,442] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run78
[2019-03-23 20:00:47,489] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run78
[2019-03-23 20:00:47,490] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run78
[2019-03-23 20:00:47,549] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run78
[2019-03-23 20:00:49,175] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00319203], dtype=float32), 0.014272793]
[2019-03-23 20:00:49,175] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 83.0, 1.0, 2.0, 0.483847009103031, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9328601034343864, 6.960857269191219, 6.9112, 77.32831247584413, 1098764.120916452, 1082636.487035846, 242254.1984512538]
[2019-03-23 20:00:49,176] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:00:49,178] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.6338799e-03 5.9611118e-08 9.9568719e-01 8.1639555e-05 1.5972394e-03], sampled 0.7637126216585397
[2019-03-23 20:01:32,586] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00319203], dtype=float32), 0.014272793]
[2019-03-23 20:01:32,587] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.08256319, 83.62068298, 1.0, 2.0, 0.219970433626813, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4417389724137143, 6.9112, 6.9112, 95.55338769695034, 501575.9298498375, 501575.9298498375, 173623.8651177836]
[2019-03-23 20:01:32,587] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:01:32,591] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.9416931e-04 1.4130701e-13 9.9930549e-01 3.6627026e-09 3.3407349e-07], sampled 0.9934098215384505
[2019-03-23 20:02:19,625] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00319203], dtype=float32), 0.014272793]
[2019-03-23 20:02:19,626] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.66666666666667, 83.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3808956477572635, 6.9112, 6.9112, 77.32846344354104, 436057.7829173497, 436057.7829173497, 159300.33280654]
[2019-03-23 20:02:19,629] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:02:19,630] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.5935646e-04 5.2139293e-13 9.9974054e-01 4.1885118e-09 1.7807542e-07], sampled 0.4401750686495761
[2019-03-23 20:02:28,738] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00319203], dtype=float32), 0.014272793]
[2019-03-23 20:02:28,739] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.93333333333334, 87.33333333333334, 1.0, 2.0, 0.230989815290766, 0.0, 2.0, 0.0, 1.0, 2.0, 0.465231271696816, 6.911199999999999, 6.9112, 77.32846344354104, 527105.1552834045, 527105.1552834047, 172270.0781417121]
[2019-03-23 20:02:28,745] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:02:28,749] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.2438026e-04 7.7390800e-15 9.9917549e-01 4.7064630e-10 6.5513554e-08], sampled 0.2592269408386979
[2019-03-23 20:02:34,155] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3517.4885 2103819660.4976 182.0000
[2019-03-23 20:02:34,212] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3359.8246 2097830269.7436 181.0000
[2019-03-23 20:02:34,365] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3610.8423 2175059061.9611 246.0000
[2019-03-23 20:02:34,367] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2760.8333 2123846968.2770 756.0000
[2019-03-23 20:02:34,390] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3119.2911 2108709329.6213 368.0000
[2019-03-23 20:02:35,405] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1925000, evaluation results [1925000.0, 3610.84230091997, 2175059061.961092, 246.0, 3359.824559055595, 2097830269.7436242, 181.0, 3517.4884781411743, 2103819660.4976475, 182.0, 2760.83332934209, 2123846968.277019, 756.0, 3119.291122094965, 2108709329.6212764, 368.0]
[2019-03-23 20:02:38,455] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3334815e-03 7.9604920e-11 9.9865544e-01 2.4411119e-07 1.0804120e-05], sum to 1.0000
[2019-03-23 20:02:38,464] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6842
[2019-03-23 20:02:38,469] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.66666666666667, 90.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 309075.0370585172, 309075.0370585169, 137747.4042115539], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 631200.0000, 
sim time next is 631800.0000, 
raw observation next is [17.0, 88.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 313647.4933773316, 313647.4933773314, 138535.1126364428], 
processed observation next is [1.0, 0.30434782608695654, 0.4090909090909091, 0.885, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11616573828790058, 0.11616573828790053, 0.3378905186254702], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.1910417], dtype=float32), -0.36665273]. 
=============================================
[2019-03-23 20:02:45,017] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.7950220e-03 2.1252097e-10 9.9374431e-01 4.1569338e-06 4.5652592e-04], sum to 1.0000
[2019-03-23 20:02:45,022] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3211
[2019-03-23 20:02:45,031] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.33333333333334, 60.0, 1.0, 2.0, 0.5846085397783698, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9700420968204526, 6.911199999999999, 6.9112, 77.32846344343051, 1215578.983803879, 1215578.983803879, 268622.3028942759], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 732000.0000, 
sim time next is 732600.0000, 
raw observation next is [26.5, 59.5, 1.0, 2.0, 0.5858185133971869, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9703675449053432, 6.911199999999999, 6.9112, 77.32846344354036, 1216908.028190922, 1216908.028190923, 269116.6436203691], 
processed observation next is [1.0, 0.4782608695652174, 0.8409090909090909, 0.595, 1.0, 1.0, 0.4822731417464836, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9576679212933475, -8.881784197001253e-17, 0.0, 0.5084288129206497, 0.45070667710774887, 0.45070667710774925, 0.6563820576106563], 
reward next is 0.3436, 
noisyNet noise sample is [array([0.16541189], dtype=float32), -0.2580357]. 
=============================================
[2019-03-23 20:03:00,158] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1125982e-04 2.4572644e-08 9.9988663e-01 5.5297443e-07 1.5390416e-06], sum to 1.0000
[2019-03-23 20:03:00,163] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2326
[2019-03-23 20:03:00,166] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [12.83333333333333, 95.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 201216.0152936901, 201216.0152936901, 88538.26886262262], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1037400.0000, 
sim time next is 1038000.0000, 
raw observation next is [12.66666666666667, 96.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 199414.6663694289, 199414.6663694286, 88048.03393761227], 
processed observation next is [1.0, 0.0, 0.21212121212121227, 0.96, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07385728384052921, 0.07385728384052911, 0.2147513022868592], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.25175053], dtype=float32), 0.11349699]. 
=============================================
[2019-03-23 20:03:00,181] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[-2.0754375]
 [-2.436425 ]
 [-3.1566234]
 [-3.121354 ]
 [-3.1137426]], R is [[-1.9439559 ]
 [-1.92451632]
 [-1.90527117]
 [-1.88621843]
 [-1.8673563 ]].
[2019-03-23 20:03:04,124] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.9334732e-05 6.4630434e-08 9.9992585e-01 3.3084154e-06 1.4791366e-06], sum to 1.0000
[2019-03-23 20:03:04,132] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9341
[2019-03-23 20:03:04,136] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 78.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3065145180808853, 6.9112, 6.9112, 77.32846344354104, 355007.906801542, 355007.906801542, 145921.4829707968], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1118400.0000, 
sim time next is 1119000.0000, 
raw observation next is [19.0, 78.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3060285956764096, 6.9112, 6.9112, 77.32846344354104, 354444.8312208222, 354444.8312208222, 145868.1797078158], 
processed observation next is [1.0, 0.9565217391304348, 0.5, 0.78, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.00861227953772803, 0.0, 0.0, 0.5084288129206541, 0.13127586341511932, 0.13127586341511932, 0.35577604806784346], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.32608563], dtype=float32), 0.6252319]. 
=============================================
[2019-03-23 20:03:04,155] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[-0.82577664]
 [-0.8839535 ]
 [-0.94301635]
 [-1.021445  ]
 [-1.088793  ]], R is [[-0.78356248]
 [-0.77572685]
 [-0.76796961]
 [-0.76028991]
 [-0.75268704]].
[2019-03-23 20:03:11,179] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0525875e-04 2.1966216e-14 9.9979156e-01 1.6301739e-08 3.2250862e-06], sum to 1.0000
[2019-03-23 20:03:11,185] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5444
[2019-03-23 20:03:11,190] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.5, 86.0, 1.0, 2.0, 0.2583853115953387, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5232786960634591, 6.911199999999999, 6.9112, 77.32846344354104, 588108.2530948699, 588108.2530948701, 182018.2632087925], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1420200.0000, 
sim time next is 1420800.0000, 
raw observation next is [23.66666666666667, 85.0, 1.0, 2.0, 0.2583418165336123, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5232111425648991, 6.9112, 6.9112, 77.32846344354104, 587927.9910571856, 587927.9910571856, 182077.9316750895], 
processed observation next is [0.0, 0.43478260869565216, 0.7121212121212124, 0.85, 1.0, 1.0, 0.07292727066701539, 0.0, 1.0, -0.25, 1.0, 1.0, 0.31887306080699873, 0.0, 0.0, 0.5084288129206541, 0.21775110779895762, 0.21775110779895762, 0.44409251628070606], 
reward next is 0.5559, 
noisyNet noise sample is [array([0.18461286], dtype=float32), -0.12760577]. 
=============================================
[2019-03-23 20:03:15,855] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.3658821e-02 2.9866717e-14 9.4633770e-01 7.8904229e-08 3.4352661e-06], sum to 1.0000
[2019-03-23 20:03:15,865] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5613
[2019-03-23 20:03:15,870] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.0, 80.5, 1.0, 2.0, 0.2533168106000752, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5128012820012496, 6.9112, 6.9112, 77.32846344354104, 577114.8536393715, 577114.8536393715, 180239.2121988143], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1423800.0000, 
sim time next is 1424400.0000, 
raw observation next is [24.0, 79.66666666666667, 1.0, 2.0, 0.2509455643767843, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5078545263035777, 6.911200000000001, 6.9112, 77.32846344354104, 571943.0704805969, 571943.0704805965, 179388.7872450669], 
processed observation next is [0.0, 0.4782608695652174, 0.7272727272727273, 0.7966666666666667, 1.0, 1.0, 0.06368195547098034, 0.0, 1.0, -0.25, 1.0, 1.0, 0.29693503757653966, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2118307668446655, 0.21183076684466537, 0.4375336274269924], 
reward next is 0.5625, 
noisyNet noise sample is [array([-0.29678148], dtype=float32), -0.41446486]. 
=============================================
[2019-03-23 20:03:15,903] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.6498927e-03 1.4678464e-10 9.9783260e-01 9.3864492e-06 5.0813123e-04], sum to 1.0000
[2019-03-23 20:03:15,911] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7004
[2019-03-23 20:03:15,914] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 76.33333333333334, 1.0, 2.0, 0.7774327088273203, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9865530188920543, 6.911199999999999, 6.9112, 77.32846344354104, 1422534.383465404, 1422534.383465404, 312230.7107293272], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1347600.0000, 
sim time next is 1348200.0000, 
raw observation next is [26.5, 79.5, 1.0, 2.0, 0.7703426953726364, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9865530188920543, 6.9112, 6.9112, 77.32846344354104, 1414551.530061571, 1414551.530061571, 311049.0696638266], 
processed observation next is [1.0, 0.6086956521739131, 0.8409090909090909, 0.795, 1.0, 1.0, 0.7129283692157956, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9807900269886491, 0.0, 0.0, 0.5084288129206541, 0.5239079740968782, 0.5239079740968782, 0.7586562674727478], 
reward next is 0.2413, 
noisyNet noise sample is [array([-0.4855118], dtype=float32), 1.1589762]. 
=============================================
[2019-03-23 20:03:18,111] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.0133048e-02 6.8017432e-18 9.5986676e-01 2.8227719e-11 1.0761694e-07], sum to 1.0000
[2019-03-23 20:03:18,119] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2662
[2019-03-23 20:03:18,125] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.33333333333333, 94.33333333333334, 1.0, 2.0, 0.2652788611339994, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5372950739923618, 6.911199999999999, 6.9112, 77.32846344354104, 603564.1798760366, 603564.179876037, 183933.0894210186], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1518600.0000, 
sim time next is 1519200.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.25259035978047, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5108287320101391, 6.911199999999999, 6.9112, 77.32846344354104, 576057.1545915568, 576057.154591557, 179214.7152012472], 
processed observation next is [0.0, 0.6086956521739131, 0.5909090909090909, 1.0, 1.0, 1.0, 0.0657379497255875, 0.0, 1.0, -0.25, 1.0, 1.0, 0.30118390287162733, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21335450170057657, 0.21335450170057665, 0.43710906146645656], 
reward next is 0.5629, 
noisyNet noise sample is [array([0.52894723], dtype=float32), 0.52038306]. 
=============================================
[2019-03-23 20:03:19,932] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.5374608e-04 2.1141102e-16 9.9914610e-01 7.9222996e-11 1.5819718e-07], sum to 1.0000
[2019-03-23 20:03:19,942] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2488
[2019-03-23 20:03:19,945] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 83.0, 1.0, 2.0, 0.2440930703765027, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4931236715437365, 6.911200000000001, 6.9112, 77.32846344354104, 556940.1909741461, 556940.1909741459, 176575.5454037775], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1440000.0000, 
sim time next is 1440600.0000, 
raw observation next is [22.66666666666667, 85.83333333333334, 1.0, 2.0, 0.2429018896677324, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4906873752821717, 6.911199999999999, 6.9112, 77.32846344354104, 554230.6065853063, 554230.6065853067, 176272.3330658469], 
processed observation next is [0.0, 0.6956521739130435, 0.6666666666666669, 0.8583333333333334, 1.0, 1.0, 0.053627362084665495, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2724105361173882, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20527059503159495, 0.20527059503159506, 0.42993251967279733], 
reward next is 0.5701, 
noisyNet noise sample is [array([1.8751208], dtype=float32), 0.27520093]. 
=============================================
[2019-03-23 20:03:19,962] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.6159009e-05 4.0775863e-09 9.9993312e-01 2.0592496e-07 4.4321553e-07], sum to 1.0000
[2019-03-23 20:03:19,971] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1786
[2019-03-23 20:03:19,980] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [15.0, 59.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 237663.2802231181, 237663.2802231181, 92542.84554314101], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1712400.0000, 
sim time next is 1713000.0000, 
raw observation next is [14.5, 61.16666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 231986.4862860882, 231986.4862860882, 91209.18956122693], 
processed observation next is [1.0, 0.8260869565217391, 0.29545454545454547, 0.6116666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.08592092084669933, 0.08592092084669933, 0.22246143795421203], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5963179], dtype=float32), -0.21734548]. 
=============================================
[2019-03-23 20:03:19,994] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[1.6790828]
 [1.5465515]
 [1.4949548]
 [1.4292233]
 [1.4243345]], R is [[1.63343084]
 [1.61709654]
 [1.60092556]
 [1.58491635]
 [1.56906724]].
[2019-03-23 20:03:20,524] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.6543738e-04 5.4064420e-10 9.9922681e-01 8.1864677e-08 7.6098936e-06], sum to 1.0000
[2019-03-23 20:03:20,535] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6767
[2019-03-23 20:03:20,539] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [12.0, 73.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 195505.1874730904, 195505.1874730907, 83606.44644432662], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1722600.0000, 
sim time next is 1723200.0000, 
raw observation next is [12.0, 72.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 196800.5818194564, 196800.5818194567, 83773.81987357195], 
processed observation next is [1.0, 0.9565217391304348, 0.18181818181818182, 0.7266666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07288910437757644, 0.07288910437757656, 0.20432638993554134], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.47153986], dtype=float32), 1.0462459]. 
=============================================
[2019-03-23 20:03:21,113] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.3018088e-03 3.6676802e-15 9.9269754e-01 8.6988168e-09 5.4395070e-07], sum to 1.0000
[2019-03-23 20:03:21,123] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1193
[2019-03-23 20:03:21,127] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.33333333333334, 81.66666666666667, 1.0, 2.0, 0.282788081904051, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5720901868099323, 6.9112, 6.9112, 77.32846344354104, 638303.950529538, 638303.950529538, 191020.590155287], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1531200.0000, 
sim time next is 1531800.0000, 
raw observation next is [25.5, 81.0, 1.0, 2.0, 0.2844578073725872, 0.0, 2.0, 0.0, 1.0, 2.0, 0.575339922903614, 6.911199999999999, 6.9112, 77.32846344354104, 641662.7606774697, 641662.76067747, 191615.7665844306], 
processed observation next is [0.0, 0.7391304347826086, 0.7954545454545454, 0.81, 1.0, 1.0, 0.10557225921573397, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3933427470051629, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23765287432498877, 0.23765287432498888, 0.4673555282547088], 
reward next is 0.5326, 
noisyNet noise sample is [array([1.2784756], dtype=float32), -0.027727896]. 
=============================================
[2019-03-23 20:03:23,442] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 20:03:23,443] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:03:23,444] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:03:23,445] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:03:23,446] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:03:23,447] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:03:23,447] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:03:23,447] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:03:23,448] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:03:23,449] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:03:23,450] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:03:23,475] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run79
[2019-03-23 20:03:23,495] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run79
[2019-03-23 20:03:23,517] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run79
[2019-03-23 20:03:23,552] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run79
[2019-03-23 20:03:23,569] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run79
[2019-03-23 20:03:25,454] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00283875], dtype=float32), 0.014683861]
[2019-03-23 20:03:25,454] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.26666666666667, 53.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 250699.8183428008, 250699.8183428004, 101172.7533536275]
[2019-03-23 20:03:25,456] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:03:25,458] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.5248467e-04 7.7071474e-12 9.9964714e-01 2.5623708e-08 3.6235937e-07], sampled 0.5776325703046349
[2019-03-23 20:03:25,988] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00283875], dtype=float32), 0.014683861]
[2019-03-23 20:03:25,989] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.4025781, 62.16828067, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3335362199651504, 6.9112, 6.9112, 95.55338769695034, 386508.4737522224, 386508.4737522224, 153308.5758990133]
[2019-03-23 20:03:25,991] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:03:25,993] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.1010163e-03 5.1017946e-13 9.9889851e-01 1.0954002e-08 5.2581095e-07], sampled 0.8926896306729074
[2019-03-23 20:03:39,496] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00283875], dtype=float32), 0.014683861]
[2019-03-23 20:03:39,497] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.0, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3652790641943856, 6.911200000000001, 6.9112, 95.55338769695034, 420528.5192871483, 420528.5192871479, 159711.0419947746]
[2019-03-23 20:03:39,498] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:03:39,501] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.2582625e-04 3.0646688e-15 9.9917418e-01 3.2961753e-10 3.1926337e-08], sampled 0.6546787359050733
[2019-03-23 20:03:42,365] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00283875], dtype=float32), 0.014683861]
[2019-03-23 20:03:42,369] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.43333333333333, 67.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 254430.9179133097, 254430.9179133093, 108122.2066930581]
[2019-03-23 20:03:42,371] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:03:42,373] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.5574767e-04 1.4945444e-12 9.9964404e-01 1.0518825e-08 2.3030826e-07], sampled 0.6046168157089155
[2019-03-23 20:03:43,418] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00283875], dtype=float32), 0.014683861]
[2019-03-23 20:03:43,420] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.18536603333333, 45.49388769333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 95.55338769695034, 256154.4399829975, 256154.4399829978, 99490.92533652441]
[2019-03-23 20:03:43,421] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:03:43,423] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.7109908e-05 9.4275455e-12 9.9992275e-01 1.2306462e-08 6.0646087e-08], sampled 0.19760828096263716
[2019-03-23 20:04:13,297] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00283875], dtype=float32), 0.014683861]
[2019-03-23 20:04:13,298] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.64418187, 82.679227715, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3043734015141885, 6.911200000000001, 6.9112, 95.55338769695034, 352052.8154283363, 352052.8154283359, 150680.7049835981]
[2019-03-23 20:04:13,301] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:04:13,304] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.9762453e-04 7.1187393e-14 9.9970227e-01 1.5316254e-09 6.1173800e-08], sampled 0.6478612576594975
[2019-03-23 20:04:40,660] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00283875], dtype=float32), 0.014683861]
[2019-03-23 20:04:40,661] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.32094547, 68.54452892500001, 1.0, 2.0, 0.2177960142161527, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4343486245240159, 6.9112, 6.9112, 95.55338769695034, 495221.5152673967, 495221.5152673967, 171180.0677791112]
[2019-03-23 20:04:40,664] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:04:40,667] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.0545945e-04 1.2512309e-15 9.9919456e-01 1.9914358e-10 2.2427438e-08], sampled 0.8628041336470644
[2019-03-23 20:04:43,428] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00283875], dtype=float32), 0.014683861]
[2019-03-23 20:04:43,428] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.4, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3510071451509866, 6.911200000000001, 6.9112, 95.55338769695034, 404705.023861704, 404705.0238617037, 157349.0282871564]
[2019-03-23 20:04:43,431] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:04:43,433] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.1220016e-03 9.7263633e-15 9.9887782e-01 1.3547248e-09 1.5695117e-07], sampled 0.26211129638092234
[2019-03-23 20:05:06,860] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2752.3207 2123004413.5328 762.0000
[2019-03-23 20:05:07,418] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3346.6253 2096847619.8850 186.0000
[2019-03-23 20:05:07,520] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3507.3913 2103123228.4225 185.0000
[2019-03-23 20:05:07,622] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3105.7911 2107765571.1094 374.0000
[2019-03-23 20:05:07,758] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3601.3709 2173904885.7220 248.0000
[2019-03-23 20:05:08,774] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1950000, evaluation results [1950000.0, 3601.3709456616216, 2173904885.7219577, 248.0, 3346.6252976979135, 2096847619.8849928, 186.0, 3507.3913176805627, 2103123228.422524, 185.0, 2752.3206843051116, 2123004413.5327811, 762.0, 3105.7910741399505, 2107765571.1094148, 374.0]
[2019-03-23 20:05:10,110] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.7025613e-04 1.0141219e-15 9.9972957e-01 8.6831442e-10 9.4388582e-08], sum to 1.0000
[2019-03-23 20:05:10,117] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6367
[2019-03-23 20:05:10,120] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.2587556784818077, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5240898589328657, 6.911199999999999, 6.9112, 77.32846344354104, 588677.044754659, 588677.0447546592, 182339.1003814461], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1525200.0000, 
sim time next is 1525800.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.2586571815203222, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5238902039472977, 6.911199999999999, 6.9112, 77.32846344354104, 588453.6895724321, 588453.6895724324, 182314.175808316], 
processed observation next is [0.0, 0.6521739130434783, 0.7272727272727273, 0.83, 1.0, 1.0, 0.07332147690040272, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3198431484961396, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21794581095275262, 0.21794581095275276, 0.44466872148369757], 
reward next is 0.5553, 
noisyNet noise sample is [array([0.5970543], dtype=float32), -1.1296848]. 
=============================================
[2019-03-23 20:05:13,938] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.3395628e-03 3.9305966e-08 9.8167247e-01 7.5993885e-05 1.0911940e-02], sum to 1.0000
[2019-03-23 20:05:13,945] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5536
[2019-03-23 20:05:13,956] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 62.0, 1.0, 2.0, 0.743477952878606, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9757031026218798, 6.911199999999999, 6.9112, 77.32846344312989, 1394496.62667057, 1394496.62667057, 297240.7438323955], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1607400.0000, 
sim time next is 1608000.0000, 
raw observation next is [27.0, 62.0, 1.0, 2.0, 0.7420555855881131, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9757071167126656, 6.911199999999999, 6.9112, 77.3284634435385, 1392872.745528259, 1392872.745528259, 297022.1179770207], 
processed observation next is [1.0, 0.6086956521739131, 0.8636363636363636, 0.62, 1.0, 1.0, 0.6775694819851413, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9652958810180937, -8.881784197001253e-17, 0.0, 0.5084288129206374, 0.515878794640096, 0.515878794640096, 0.7244441901878553], 
reward next is 0.2756, 
noisyNet noise sample is [array([1.307349], dtype=float32), -2.7581017]. 
=============================================
[2019-03-23 20:05:13,969] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[31.4566  ]
 [31.311752]
 [31.150646]
 [31.173666]
 [31.284536]], R is [[31.42876053]
 [31.38949585]
 [31.352911  ]
 [31.32073402]
 [31.25848389]].
[2019-03-23 20:05:18,034] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.8478049e-02 1.2918763e-09 9.8061579e-01 7.8404564e-06 8.9842122e-04], sum to 1.0000
[2019-03-23 20:05:18,041] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3390
[2019-03-23 20:05:18,046] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.5, 61.0, 1.0, 2.0, 0.6283213089752759, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9669057989445251, 6.911199999999999, 6.9112, 77.32846344354104, 1265615.656239697, 1265615.656239697, 271312.7188960453], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1956600.0000, 
sim time next is 1957200.0000, 
raw observation next is [25.66666666666666, 61.0, 1.0, 2.0, 0.6400518330073126, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9677424597615967, 6.911199999999999, 6.9112, 77.32846344354104, 1279090.578901717, 1279090.578901717, 273790.0272972678], 
processed observation next is [1.0, 0.6521739130434783, 0.8030303030303028, 0.61, 1.0, 1.0, 0.5500647912591408, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9539177996594238, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4737372514450804, 0.4737372514450804, 0.66778055438358], 
reward next is 0.3322, 
noisyNet noise sample is [array([0.34230548], dtype=float32), 0.9621953]. 
=============================================
[2019-03-23 20:05:27,769] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0860659e-02 2.2553443e-12 9.8907381e-01 2.8225222e-06 6.2712454e-05], sum to 1.0000
[2019-03-23 20:05:27,776] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0900
[2019-03-23 20:05:27,785] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.16666666666667, 44.0, 1.0, 2.0, 0.3090727566528149, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5772476921180381, 6.9112, 6.9112, 77.32846344354104, 671453.2978604994, 671453.2978604994, 171306.6322320504], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1875000.0000, 
sim time next is 1875600.0000, 
raw observation next is [23.0, 44.0, 1.0, 2.0, 0.3031383501725944, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5659280615162052, 6.9112, 6.9112, 77.32846344354104, 658552.2037427676, 658552.2037427676, 168943.193276524], 
processed observation next is [1.0, 0.7391304347826086, 0.6818181818181818, 0.44, 1.0, 1.0, 0.12892293771574295, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3798972307374361, 0.0, 0.0, 0.5084288129206541, 0.24390822360843242, 0.24390822360843242, 0.41205656896713166], 
reward next is 0.5879, 
noisyNet noise sample is [array([0.11842225], dtype=float32), -0.7371607]. 
=============================================
[2019-03-23 20:05:29,888] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7364911e-04 5.5460919e-10 9.9982077e-01 2.3990407e-07 5.4140432e-06], sum to 1.0000
[2019-03-23 20:05:29,897] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7712
[2019-03-23 20:05:29,904] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.5, 66.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 275042.1877832452, 275042.1877832449, 113344.891324569], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1899000.0000, 
sim time next is 1899600.0000, 
raw observation next is [18.33333333333334, 66.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 272957.7530481738, 272957.7530481738, 112343.4770209247], 
processed observation next is [1.0, 1.0, 0.46969696969696995, 0.6666666666666665, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.10109546409191622, 0.10109546409191622, 0.27400848053884075], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.4500428], dtype=float32), 1.4574019]. 
=============================================
[2019-03-23 20:05:30,540] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.4425713e-03 4.0248720e-12 9.9653208e-01 2.3352442e-07 2.5037320e-05], sum to 1.0000
[2019-03-23 20:05:30,547] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4984
[2019-03-23 20:05:30,552] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.2016332729879283, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4006239129715914, 6.911199999999999, 6.9112, 77.32846344354098, 457617.4289375206, 457617.4289375209, 162658.3443642262], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1923000.0000, 
sim time next is 1923600.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3963854544244695, 6.911199999999999, 6.9112, 77.32846344354104, 452759.6479178136, 452759.6479178139, 162252.5335199086], 
processed observation next is [1.0, 0.2608695652173913, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1376935063206707, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16768875848807913, 0.16768875848807924, 0.39573788663392345], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2446252], dtype=float32), -0.8126338]. 
=============================================
[2019-03-23 20:05:33,049] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.49938105e-05 1.67294587e-08 9.99983668e-01 7.23622975e-07
 5.78868026e-07], sum to 1.0000
[2019-03-23 20:05:33,057] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6786
[2019-03-23 20:05:33,064] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 50.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 333129.9888656656, 333129.9888656659, 142138.3143370618], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2035800.0000, 
sim time next is 2036400.0000, 
raw observation next is [23.0, 51.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 333443.2306736806, 333443.2306736806, 142509.5413966483], 
processed observation next is [0.0, 0.5652173913043478, 0.6818181818181818, 0.51, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.12349749284210393, 0.12349749284210393, 0.3475842473088983], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.18438421], dtype=float32), 1.0886577]. 
=============================================
[2019-03-23 20:05:39,437] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3568247e-04 7.7106384e-09 9.9982941e-01 2.0397292e-06 3.2912154e-05], sum to 1.0000
[2019-03-23 20:05:39,445] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5161
[2019-03-23 20:05:39,450] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 77.16666666666666, 1.0, 2.0, 0.213839872436097, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4056200091017783, 6.9112, 6.9112, 77.32846344354104, 469919.2811398479, 469919.2811398479, 156398.0446625246], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2206200.0000, 
sim time next is 2206800.0000, 
raw observation next is [19.0, 78.0, 1.0, 2.0, 0.2155878188113215, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4099258267438864, 6.911199999999999, 6.9112, 77.32846344354104, 474652.253736495, 474652.2537364953, 157035.8242006465], 
processed observation next is [1.0, 0.5652173913043478, 0.5, 0.78, 1.0, 1.0, 0.019484773514151857, 0.0, 1.0, -0.25, 1.0, 1.0, 0.15703689534840914, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17579713101351666, 0.17579713101351677, 0.38301420536743047], 
reward next is 0.6170, 
noisyNet noise sample is [array([0.12670289], dtype=float32), -0.8164567]. 
=============================================
[2019-03-23 20:05:44,498] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.5014280e-04 1.9411193e-07 9.9954361e-01 2.0994412e-05 1.8502757e-04], sum to 1.0000
[2019-03-23 20:05:44,507] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5793
[2019-03-23 20:05:44,510] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.0, 82.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 270200.5004147231, 270200.5004147234, 108973.0167121566], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2188800.0000, 
sim time next is 2189400.0000, 
raw observation next is [16.16666666666667, 81.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 285162.0826557829, 285162.0826557832, 112224.0611473536], 
processed observation next is [1.0, 0.34782608695652173, 0.37121212121212144, 0.8116666666666668, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10561558616880849, 0.1056155861688086, 0.2737172223106185], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.6034508], dtype=float32), 0.7736004]. 
=============================================
[2019-03-23 20:05:47,443] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5009089e-05 1.5927929e-08 9.9998367e-01 3.8052983e-07 9.9462966e-07], sum to 1.0000
[2019-03-23 20:05:47,450] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2015
[2019-03-23 20:05:47,455] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 243764.534831819, 243764.5348318187, 100101.2954544157], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2253600.0000, 
sim time next is 2254200.0000, 
raw observation next is [14.0, 94.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 270374.2798821514, 270374.2798821514, 105021.2471598651], 
processed observation next is [1.0, 0.08695652173913043, 0.2727272727272727, 0.9400000000000002, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.1001386221785746, 0.1001386221785746, 0.25614938331674414], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.14253128], dtype=float32), -0.5215064]. 
=============================================
[2019-03-23 20:05:51,251] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.8522914e-05 2.1502291e-07 9.9993575e-01 4.5170782e-06 9.8273995e-07], sum to 1.0000
[2019-03-23 20:05:51,257] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9688
[2019-03-23 20:05:51,261] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 53.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 315104.685516066, 315104.6855160663, 125292.4318899773], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2400000.0000, 
sim time next is 2400600.0000, 
raw observation next is [21.0, 53.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 313938.9212085549, 313938.9212085546, 125057.0887151464], 
processed observation next is [1.0, 0.782608695652174, 0.5909090909090909, 0.53, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11627367452168699, 0.11627367452168688, 0.30501728954913754], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.16180165], dtype=float32), 1.1000954]. 
=============================================
[2019-03-23 20:05:51,502] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.1722091e-05 1.3256161e-07 9.9993467e-01 2.6587750e-06 1.0885228e-05], sum to 1.0000
[2019-03-23 20:05:51,508] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9828
[2019-03-23 20:05:51,514] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.66666666666667, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 247284.5676204636, 247284.5676204636, 101885.1999534231], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2443200.0000, 
sim time next is 2443800.0000, 
raw observation next is [14.83333333333333, 89.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 248417.0160909597, 248417.0160909597, 102406.4538649412], 
processed observation next is [1.0, 0.2608695652173913, 0.3106060606060605, 0.89, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.092006302255911, 0.092006302255911, 0.24977183869497854], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3980612], dtype=float32), 1.9187933]. 
=============================================
[2019-03-23 20:05:57,305] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 20:05:57,307] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:05:57,308] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:05:57,308] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:05:57,311] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:05:57,312] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:05:57,312] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:05:57,312] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:05:57,312] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:05:57,313] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:05:57,315] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:05:57,337] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run80
[2019-03-23 20:05:57,362] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run80
[2019-03-23 20:05:57,388] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run80
[2019-03-23 20:05:57,424] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run80
[2019-03-23 20:05:57,424] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run80
[2019-03-23 20:06:13,036] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0027265], dtype=float32), 0.014743282]
[2019-03-23 20:06:13,037] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.33333333333334, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3753596901580664, 6.9112, 6.9112, 77.32846344354104, 432748.5192705041, 432748.5192705041, 155833.0099487294]
[2019-03-23 20:06:13,038] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:06:13,042] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.0973866e-05 2.5667393e-09 9.9997771e-01 5.0516826e-07 8.0059334e-07], sampled 0.6784420223815665
[2019-03-23 20:06:15,992] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0027265], dtype=float32), 0.014743282]
[2019-03-23 20:06:15,995] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.5, 94.0, 1.0, 2.0, 0.208726188741076, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4182193770115392, 6.911200000000001, 6.9112, 77.32846344354104, 475609.6802628671, 475609.6802628668, 166096.5642253499]
[2019-03-23 20:06:15,995] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:06:15,998] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.3713215e-05 5.2039373e-10 9.9995315e-01 4.8637287e-07 2.5668221e-06], sampled 0.8103726966855825
[2019-03-23 20:06:22,565] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0027265], dtype=float32), 0.014743282]
[2019-03-23 20:06:22,566] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.86337291, 54.29375021333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 95.55338769695034, 301568.737619933, 301568.7376199334, 128293.527331825]
[2019-03-23 20:06:22,568] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:06:22,570] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.2629541e-05 1.6194338e-08 9.9996591e-01 8.2912169e-07 5.9748788e-07], sampled 0.7423524296795417
[2019-03-23 20:06:34,045] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0027265], dtype=float32), 0.014743282]
[2019-03-23 20:06:34,046] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.8, 46.0, 1.0, 2.0, 0.2035240875531124, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4062320953146529, 6.911200000000001, 6.9112, 95.55338769695034, 462946.690697333, 462946.6906973327, 168740.8460736638]
[2019-03-23 20:06:34,050] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:06:34,052] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.47566404e-05 1.35764475e-08 9.99973178e-01 1.07627295e-06
 9.07462152e-07], sampled 0.6991493607810002
[2019-03-23 20:07:03,776] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0027265], dtype=float32), 0.014743282]
[2019-03-23 20:07:03,777] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.56161528, 87.81339815, 1.0, 2.0, 0.2363622573019913, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4776704193239705, 6.9112, 6.9112, 95.55338769695034, 539169.9272820088, 539169.9272820088, 179743.8365153588]
[2019-03-23 20:07:03,778] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:07:03,781] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.7115162e-05 7.7931300e-11 9.9995112e-01 1.7966164e-07 1.5723472e-06], sampled 0.5644341265483569
[2019-03-23 20:07:05,058] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0027265], dtype=float32), 0.014743282]
[2019-03-23 20:07:05,060] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.06473104666667, 97.23802785166667, 1.0, 2.0, 0.2262110830219771, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4535366968631538, 6.9112, 6.9112, 95.55338769695034, 515538.5747075368, 515538.5747075368, 174363.0946722354]
[2019-03-23 20:07:05,063] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:07:05,068] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.9681745e-05 2.4471217e-10 9.9994755e-01 3.4882041e-07 2.3773166e-06], sampled 0.04806460630120246
[2019-03-23 20:07:15,594] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0027265], dtype=float32), 0.014743282]
[2019-03-23 20:07:15,595] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [13.3, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 209134.6111293994, 209134.611129399, 93834.71707125916]
[2019-03-23 20:07:15,596] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:07:15,598] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.5867164e-05 3.8484977e-08 9.9995065e-01 1.9104082e-06 1.4954923e-06], sampled 0.4684061030091998
[2019-03-23 20:07:22,369] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0027265], dtype=float32), 0.014743282]
[2019-03-23 20:07:22,370] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [11.02770316166667, 97.85023265333334, 1.0, 2.0, 0.2038907364234648, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3806193373323412, 6.911199999999999, 6.9112, 71.1967921412525, 442861.1102842414, 442861.1102842417, 119019.935974417]
[2019-03-23 20:07:22,372] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:07:22,374] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.0762992e-05 3.0970075e-08 9.9995482e-01 2.2182446e-06 2.1036517e-06], sampled 0.8134221386409967
[2019-03-23 20:07:34,515] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0027265], dtype=float32), 0.014743282]
[2019-03-23 20:07:34,517] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [28.177909095, 48.26443723, 1.0, 2.0, 0.2620144424993601, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5269205996248931, 6.911200000000001, 6.9112, 95.55338769695034, 597715.0249489138, 597715.0249489135, 183360.9340015519]
[2019-03-23 20:07:34,517] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:07:34,519] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.9000008e-05 5.4131427e-10 9.9990439e-01 7.5001645e-07 5.8501405e-06], sampled 0.515860414436404
[2019-03-23 20:07:42,026] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3118.5732 2108989751.6876 368.0000
[2019-03-23 20:07:42,043] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3519.4069 2104093158.9370 178.0000
[2019-03-23 20:07:42,202] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3613.2304 2175228158.0224 245.0000
[2019-03-23 20:07:42,255] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2761.6742 2123991507.9531 757.0000
[2019-03-23 20:07:42,256] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3359.7832 2098090453.0283 179.0000
[2019-03-23 20:07:43,272] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1975000, evaluation results [1975000.0, 3613.230412368674, 2175228158.0224185, 245.0, 3359.783206971785, 2098090453.0283022, 179.0, 3519.4069184785994, 2104093158.9369724, 178.0, 2761.6742491790005, 2123991507.9530792, 757.0, 3118.573171529057, 2108989751.687561, 368.0]
[2019-03-23 20:07:47,412] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.7457549e-06 4.2811386e-09 9.9999237e-01 6.8108596e-07 9.4328080e-08], sum to 1.0000
[2019-03-23 20:07:47,422] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1608
[2019-03-23 20:07:47,429] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.66666666666666, 43.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3231304295845168, 6.9112, 6.9112, 77.32846344354104, 372687.9675948397, 372687.9675948397, 149341.6327922792], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2634000.0000, 
sim time next is 2634600.0000, 
raw observation next is [25.83333333333334, 42.83333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3226980276740776, 6.911199999999999, 6.9112, 77.32846344354104, 372220.5069471597, 372220.5069471599, 149260.6480421744], 
processed observation next is [0.0, 0.4782608695652174, 0.8106060606060609, 0.4283333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.03242575382011091, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13785944701746655, 0.13785944701746664, 0.36405036107847416], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.88847315], dtype=float32), 0.49620908]. 
=============================================
[2019-03-23 20:07:47,786] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.9384218e-04 7.2995863e-06 9.9827731e-01 3.3450042e-04 8.8705757e-04], sum to 1.0000
[2019-03-23 20:07:47,792] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9407
[2019-03-23 20:07:47,797] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.5, 60.0, 1.0, 2.0, 0.4329860755671963, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8769447634320451, 6.9112, 6.9112, 77.32843891564335, 985638.8239128917, 985638.8239128917, 239083.8413259081], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2809800.0000, 
sim time next is 2810400.0000, 
raw observation next is [27.66666666666666, 59.33333333333333, 1.0, 2.0, 0.4767641481804047, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9425106710866564, 6.951218164209071, 6.9112, 77.32836718246357, 1085244.407443395, 1072247.342400501, 254160.8381412149], 
processed observation next is [1.0, 0.5217391304347826, 0.8939393939393937, 0.5933333333333333, 1.0, 1.0, 0.34595518522550583, 0.0, 1.0, -0.25, 1.0, 1.0, 0.917872387266652, 0.004001816420907111, 0.0, 0.5084281800113324, 0.4019423731271833, 0.3971286453335189, 0.6199044832712558], 
reward next is 0.1800, 
noisyNet noise sample is [array([2.1718445], dtype=float32), -0.15321735]. 
=============================================
[2019-03-23 20:07:57,460] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.3353105e-05 3.9753799e-13 9.9990654e-01 4.1064673e-08 1.1808554e-07], sum to 1.0000
[2019-03-23 20:07:57,469] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6838
[2019-03-23 20:07:57,475] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.75, 99.83333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3141832739700625, 6.9112, 6.9112, 77.32846344354104, 363412.814240325, 363412.814240325, 147260.4763640441], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2699400.0000, 
sim time next is 2700000.0000, 
raw observation next is [16.8, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3159070258656562, 6.911200000000001, 6.9112, 77.32846344354104, 365277.1143717997, 365277.1143717995, 147586.1266713746], 
processed observation next is [0.0, 0.2608695652173913, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.02272432266522319, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1352878201377036, 0.13528782013770352, 0.35996616261310876], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.4464974], dtype=float32), -0.8724093]. 
=============================================
[2019-03-23 20:07:57,494] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[37.08674 ]
 [36.663315]
 [36.176903]
 [35.830338]
 [35.506775]], R is [[37.00550461]
 [36.63544846]
 [36.26909256]
 [35.90640259]
 [35.54734039]].
[2019-03-23 20:07:58,571] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.2559530e-03 3.4090548e-16 9.9174386e-01 5.2430321e-10 2.2357250e-07], sum to 1.0000
[2019-03-23 20:07:58,578] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0764
[2019-03-23 20:07:58,584] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 65.0, 1.0, 2.0, 0.2261792729893863, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4548918382829054, 6.9112, 6.9112, 77.32846344354104, 515993.2660426903, 515993.2660426903, 170723.5131421046], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2732400.0000, 
sim time next is 2733000.0000, 
raw observation next is [25.16666666666667, 64.33333333333334, 1.0, 2.0, 0.2255202537214814, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4535984450647489, 6.9112, 6.9112, 77.32846344354104, 514496.9480359228, 514496.9480359228, 170614.779452718], 
processed observation next is [0.0, 0.6521739130434783, 0.7803030303030305, 0.6433333333333334, 1.0, 1.0, 0.031900317151851744, 0.0, 1.0, -0.25, 1.0, 1.0, 0.21942635009249845, 0.0, 0.0, 0.5084288129206541, 0.19055442519848992, 0.19055442519848992, 0.41613360842126346], 
reward next is 0.5839, 
noisyNet noise sample is [array([1.0194013], dtype=float32), 0.63996345]. 
=============================================
[2019-03-23 20:07:58,614] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[58.58033 ]
 [58.822   ]
 [59.018112]
 [59.200443]
 [59.285713]], R is [[58.45772171]
 [58.45674896]
 [58.45388031]
 [58.44910431]
 [58.44250488]].
[2019-03-23 20:07:59,871] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7930251e-04 2.3874826e-13 9.9981803e-01 4.6005127e-08 2.7427072e-06], sum to 1.0000
[2019-03-23 20:07:59,879] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3232
[2019-03-23 20:07:59,887] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.2079514154144356, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4146000950283804, 6.911199999999999, 6.9112, 77.32846344354104, 472807.5207987658, 472807.5207987661, 164605.9256994856], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2761200.0000, 
sim time next is 2761800.0000, 
raw observation next is [21.83333333333334, 78.0, 1.0, 2.0, 0.2065128353769088, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4111215046367139, 6.9112, 6.9112, 77.32846344354104, 469183.6117769734, 469183.6117769734, 163979.1343497936], 
processed observation next is [0.0, 1.0, 0.628787878787879, 0.78, 1.0, 1.0, 0.00814104422113597, 0.0, 1.0, -0.25, 1.0, 1.0, 0.158745006623877, 0.0, 0.0, 0.5084288129206541, 0.1737717080655457, 0.1737717080655457, 0.3999491081702283], 
reward next is 0.6001, 
noisyNet noise sample is [array([-1.2817538], dtype=float32), -0.41348863]. 
=============================================
[2019-03-23 20:08:03,645] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.8243531e-03 6.3443846e-09 9.8791844e-01 1.2108085e-04 3.1361701e-03], sum to 1.0000
[2019-03-23 20:08:03,653] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1531
[2019-03-23 20:08:03,656] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.66666666666666, 54.0, 1.0, 2.0, 0.7085324918760039, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9760060478969682, 6.911199999999999, 6.9112, 77.32846344354104, 1354456.72085142, 1354456.72085142, 292158.1038330801], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2817600.0000, 
sim time next is 2818200.0000, 
raw observation next is [28.83333333333334, 53.0, 1.0, 2.0, 0.6629497522924657, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9756187940011394, 6.911200000000001, 6.9112, 77.32846344354104, 1302790.315910568, 1302790.315910567, 285037.7964892406], 
processed observation next is [1.0, 0.6086956521739131, 0.9469696969696972, 0.53, 1.0, 1.0, 0.578687190365582, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9651697057159134, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4825149318187289, 0.48251493181872857, 0.6952141377786356], 
reward next is 0.3048, 
noisyNet noise sample is [array([0.35928735], dtype=float32), -0.061126154]. 
=============================================
[2019-03-23 20:08:05,010] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.0997414e-03 1.9215277e-10 9.9321377e-01 3.7220675e-06 6.8286440e-04], sum to 1.0000
[2019-03-23 20:08:05,021] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1426
[2019-03-23 20:08:05,026] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.83333333333334, 83.83333333333334, 1.0, 2.0, 0.2833202028911168, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5685899783594615, 6.911199999999999, 6.9112, 77.32846344354104, 646056.894854254, 646056.8948542542, 182962.1950059682], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2862600.0000, 
sim time next is 2863200.0000, 
raw observation next is [21.66666666666667, 84.66666666666667, 1.0, 2.0, 0.2646387988941254, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5308946393756301, 6.9112, 6.9112, 77.32846344354104, 603354.7997337161, 603354.7997337161, 178265.9359796135], 
processed observation next is [1.0, 0.13043478260869565, 0.6212121212121214, 0.8466666666666667, 1.0, 1.0, 0.08079849861765673, 0.0, 1.0, -0.25, 1.0, 1.0, 0.32984948482232873, 0.0, 0.0, 0.5084288129206541, 0.22346474064211705, 0.22346474064211705, 0.4347949658039354], 
reward next is 0.5652, 
noisyNet noise sample is [array([1.7310925], dtype=float32), -0.23819475]. 
=============================================
[2019-03-23 20:08:12,144] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.6381586e-02 1.2171929e-09 9.7705078e-01 6.0201175e-05 6.5074652e-03], sum to 1.0000
[2019-03-23 20:08:12,150] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3014
[2019-03-23 20:08:12,158] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.0, 62.33333333333334, 1.0, 2.0, 0.676740416029224, 1.0, 2.0, 0.676740416029224, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1522156.215228192, 1522156.215228192, 284555.4348392234], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2996400.0000, 
sim time next is 2997000.0000, 
raw observation next is [28.0, 60.5, 1.0, 2.0, 0.7760809009434404, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9806492446534709, 6.911199999999999, 6.9112, 77.32846344354104, 1426692.973706075, 1426692.973706076, 307318.1080456434], 
processed observation next is [1.0, 0.6956521739130435, 0.9090909090909091, 0.605, 1.0, 1.0, 0.7201011261793006, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9723560637906727, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.528404805076324, 0.5284048050763244, 0.7495563610869352], 
reward next is 0.2504, 
noisyNet noise sample is [array([0.67510945], dtype=float32), 1.4711267]. 
=============================================
[2019-03-23 20:08:12,172] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[38.50494 ]
 [37.410736]
 [37.932304]
 [37.666363]
 [37.8651  ]], R is [[38.8016243 ]
 [38.71957016]
 [38.55099106]
 [38.32302094]
 [38.11945343]].
[2019-03-23 20:08:20,854] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.4210916e-04 7.0778330e-09 9.9985719e-01 3.2976092e-07 3.7637261e-07], sum to 1.0000
[2019-03-23 20:08:20,862] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1494
[2019-03-23 20:08:20,866] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.33333333333333, 53.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3260163833965896, 6.9112, 6.9112, 77.32846344354104, 376555.4868163084, 376555.4868163084, 149148.7247927126], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3238800.0000, 
sim time next is 3239400.0000, 
raw observation next is [23.16666666666667, 53.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3201741242837221, 6.911200000000001, 6.9112, 77.32846344354104, 370133.5441822193, 370133.544182219, 148148.6826094433], 
processed observation next is [0.0, 0.4782608695652174, 0.6893939393939396, 0.5316666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.028820177548174456, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13708649784526641, 0.1370864978452663, 0.36133825026693484], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.48776886], dtype=float32), 0.031198995]. 
=============================================
[2019-03-23 20:08:27,016] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1984058e-05 4.8789028e-10 9.9998736e-01 1.6182406e-07 5.2319513e-07], sum to 1.0000
[2019-03-23 20:08:27,022] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6139
[2019-03-23 20:08:27,026] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.83333333333334, 60.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.320247361108106, 6.9112, 6.9112, 77.32846344354104, 370344.4458169891, 370344.4458169891, 148030.251848092], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3273000.0000, 
sim time next is 3273600.0000, 
raw observation next is [21.66666666666667, 61.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.317862792657267, 6.9112, 6.9112, 77.32846344354104, 367675.0367586098, 367675.0367586098, 147669.9176290408], 
processed observation next is [0.0, 0.9130434782608695, 0.6212121212121214, 0.6133333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.025518275224667195, 0.0, 0.0, 0.5084288129206541, 0.13617593954022586, 0.13617593954022586, 0.3601705308025386], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6061065], dtype=float32), -0.9205022]. 
=============================================
[2019-03-23 20:08:27,582] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.8723851e-04 1.8521243e-08 9.9971062e-01 1.4857463e-06 5.5356719e-07], sum to 1.0000
[2019-03-23 20:08:27,587] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9755
[2019-03-23 20:08:27,592] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.6470584e-05 9.2694119e-09 9.9991977e-01 1.6264416e-06 2.0325422e-06], sum to 1.0000
[2019-03-23 20:08:27,593] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9334
[2019-03-23 20:08:27,597] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.83333333333334, 83.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 309336.3246070933, 309336.3246070936, 125420.7599688153], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3283800.0000, 
sim time next is 3284400.0000, 
raw observation next is [16.66666666666667, 84.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 307253.5173813893, 307253.5173813896, 124364.554457473], 
processed observation next is [0.0, 0.0, 0.39393939393939414, 0.84, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11379759903014418, 0.1137975990301443, 0.3033281816035927], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.78948325], dtype=float32), 0.24404183]. 
=============================================
[2019-03-23 20:08:27,604] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [15.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 251488.6863958591, 251488.6863958591, 103340.0278987864], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3303000.0000, 
sim time next is 3303600.0000, 
raw observation next is [15.33333333333333, 86.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 253907.8566234342, 253907.8566234339, 104443.2765492649], 
processed observation next is [0.0, 0.21739130434782608, 0.3333333333333332, 0.86, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09403994689756823, 0.09403994689756812, 0.2547396989006461], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3112584], dtype=float32), 0.6912984]. 
=============================================
[2019-03-23 20:08:31,882] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 20:08:31,887] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:08:31,888] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:08:31,897] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:08:31,898] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:08:31,899] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:08:31,899] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:08:31,900] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:08:31,901] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:08:31,901] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:08:31,902] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:08:31,911] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run81
[2019-03-23 20:08:31,937] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run81
[2019-03-23 20:08:31,969] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run81
[2019-03-23 20:08:31,970] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run81
[2019-03-23 20:08:32,003] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run81
[2019-03-23 20:09:22,641] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00259898], dtype=float32), 0.015152512]
[2019-03-23 20:09:22,642] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.33333333333334, 61.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 345269.6573106358, 345269.6573106358, 144772.8435680958]
[2019-03-23 20:09:22,645] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:09:22,647] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.91606508e-05 1.08459894e-10 9.99920368e-01 6.39280557e-08
 3.94425427e-07], sampled 0.3243496479882777
[2019-03-23 20:09:47,600] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00259898], dtype=float32), 0.015152512]
[2019-03-23 20:09:47,603] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [11.7, 79.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 175622.2471714707, 175622.247171471, 80270.8237898539]
[2019-03-23 20:09:47,603] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:09:47,606] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0102055e-04 6.8654787e-10 9.9989808e-01 1.7869436e-07 6.4183848e-07], sampled 0.14743997886327265
[2019-03-23 20:10:17,802] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3325.2692 2094339030.2630 187.0000
[2019-03-23 20:10:17,957] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3481.5080 2101066399.7010 194.0000
[2019-03-23 20:10:17,968] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3085.6034 2106133760.2172 378.0000
[2019-03-23 20:10:18,006] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2732.2177 2121342225.8400 749.0000
[2019-03-23 20:10:18,055] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3565.9712 2171487606.6566 256.0000
[2019-03-23 20:10:19,073] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 2000000, evaluation results [2000000.0, 3565.9711779169766, 2171487606.656554, 256.0, 3325.2691592861343, 2094339030.263008, 187.0, 3481.5080143536425, 2101066399.7010272, 194.0, 2732.2176586955684, 2121342225.8399873, 749.0, 3085.603404963604, 2106133760.2171667, 378.0]
[2019-03-23 20:10:20,625] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3939067e-02 1.9564092e-12 9.8597819e-01 1.0533911e-07 8.2643746e-05], sum to 1.0000
[2019-03-23 20:10:20,636] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3043
[2019-03-23 20:10:20,640] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.33333333333334, 71.33333333333333, 1.0, 2.0, 0.2736802889013198, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5543330242483842, 6.9112, 6.9112, 77.32846344354104, 620733.1625800604, 620733.1625800604, 187316.5508628553], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3526800.0000, 
sim time next is 3527400.0000, 
raw observation next is [26.16666666666667, 72.66666666666667, 1.0, 2.0, 0.2755602110060995, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5581117053535193, 6.9112, 6.9112, 77.32846344354104, 624771.5419407645, 624771.5419407645, 187926.8431517953], 
processed observation next is [1.0, 0.8260869565217391, 0.825757575757576, 0.7266666666666667, 1.0, 1.0, 0.09445026375762437, 0.0, 1.0, -0.25, 1.0, 1.0, 0.36873100764788475, 0.0, 0.0, 0.5084288129206541, 0.23139686738546833, 0.23139686738546833, 0.458358154028769], 
reward next is 0.5416, 
noisyNet noise sample is [array([0.2639186], dtype=float32), -0.3029783]. 
=============================================
[2019-03-23 20:10:22,272] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.4538466e-02 7.7026181e-12 9.5111185e-01 1.0880227e-05 1.4338805e-02], sum to 1.0000
[2019-03-23 20:10:22,278] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7371
[2019-03-23 20:10:22,285] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 74.0, 1.0, 2.0, 0.2754958854402028, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5579397362755443, 6.911200000000001, 6.9112, 77.32846344354104, 624346.4566765664, 624346.4566765662, 188043.9422787449], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3437400.0000, 
sim time next is 3438000.0000, 
raw observation next is [26.0, 74.0, 1.0, 2.0, 0.2754237096997204, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5577938842370642, 6.9112, 6.9112, 77.32846344354104, 624184.7722412533, 624184.7722412533, 188023.8653226538], 
processed observation next is [1.0, 0.8260869565217391, 0.8181818181818182, 0.74, 1.0, 1.0, 0.0942796371246505, 0.0, 1.0, -0.25, 1.0, 1.0, 0.36827697748152033, 0.0, 0.0, 0.5084288129206541, 0.23117954527453827, 0.23117954527453827, 0.4585947934698873], 
reward next is 0.5414, 
noisyNet noise sample is [array([-0.392379], dtype=float32), -0.5894966]. 
=============================================
[2019-03-23 20:10:22,298] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[48.26052 ]
 [48.049618]
 [47.49094 ]
 [48.604954]
 [48.56593 ]], R is [[47.75574112]
 [47.81953812]
 [47.88215637]
 [47.94301605]
 [48.00320435]].
[2019-03-23 20:10:24,117] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0926209e-02 4.2489581e-11 9.8299652e-01 1.1486240e-05 6.0658283e-03], sum to 1.0000
[2019-03-23 20:10:24,126] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7539
[2019-03-23 20:10:24,131] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.2659689514512898, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5375804772410723, 6.9112, 6.9112, 77.32846344354104, 606776.2708203051, 606776.2708203051, 182053.9447811442], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3472800.0000, 
sim time next is 3473400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.2634085006587401, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5323943759299186, 6.9112, 6.9112, 77.32846344354104, 600936.6641990814, 600936.6641990814, 181411.1883050858], 
processed observation next is [1.0, 0.17391304347826086, 0.5909090909090909, 1.0, 1.0, 1.0, 0.07926062582342512, 0.0, 1.0, -0.25, 1.0, 1.0, 0.33199196561416944, 0.0, 0.0, 0.5084288129206541, 0.22256913488854865, 0.22256913488854865, 0.4424663129392336], 
reward next is 0.5575, 
noisyNet noise sample is [array([1.7733176], dtype=float32), 2.4737573]. 
=============================================
[2019-03-23 20:10:27,043] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.9744686e-02 1.5937827e-10 9.5983189e-01 1.2662615e-06 4.2222047e-04], sum to 1.0000
[2019-03-23 20:10:27,053] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4762
[2019-03-23 20:10:27,059] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.66666666666667, 75.33333333333334, 1.0, 2.0, 0.2772012434501139, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5614591379042387, 6.9112, 6.9112, 77.32846344354104, 628677.9858594427, 628677.9858594427, 188271.4354431802], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3529200.0000, 
sim time next is 3529800.0000, 
raw observation next is [25.5, 76.0, 1.0, 2.0, 0.276609894122361, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5602892123543189, 6.911199999999999, 6.9112, 77.32846344354104, 627591.5345537869, 627591.5345537872, 187981.9157226787], 
processed observation next is [1.0, 0.8695652173913043, 0.7954545454545454, 0.76, 1.0, 1.0, 0.09576236765295121, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3718417319347414, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23244130909399513, 0.23244130909399527, 0.4584924773723871], 
reward next is 0.5415, 
noisyNet noise sample is [array([0.9059087], dtype=float32), 1.614045]. 
=============================================
[2019-03-23 20:10:27,060] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.5203899e-03 1.3327649e-08 9.9182409e-01 6.5671324e-05 2.5897962e-03], sum to 1.0000
[2019-03-23 20:10:27,068] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9631
[2019-03-23 20:10:27,072] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3326752748736911, 6.911199999999999, 6.9112, 77.32846344354104, 383500.6045159469, 383500.6045159471, 150651.547271007], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4173600.0000, 
sim time next is 4174200.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3316906626993879, 6.9112, 6.9112, 77.32846344354104, 382366.4556820476, 382366.4556820476, 150534.0038352473], 
processed observation next is [1.0, 0.30434782608695654, 0.45454545454545453, 0.94, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.045272375284839884, 0.0, 0.0, 0.5084288129206541, 0.14161720580816578, 0.14161720580816578, 0.3671561069152373], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.759764], dtype=float32), 0.3904794]. 
=============================================
[2019-03-23 20:10:27,637] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.7032836e-02 7.5739874e-12 9.3268126e-01 4.1873877e-06 2.8163701e-04], sum to 1.0000
[2019-03-23 20:10:27,644] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2307
[2019-03-23 20:10:27,650] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.2613462604369589, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5292042670462684, 6.911199999999999, 6.9112, 77.32846344354104, 595080.9271535518, 595080.9271535521, 182538.2480853614], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3540000.0000, 
sim time next is 3540600.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.2614990116599566, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5295136887130016, 6.9112, 6.9112, 77.32846344354104, 595428.633474392, 595428.633474392, 182576.3382832328], 
processed observation next is [1.0, 1.0, 0.6818181818181818, 0.89, 1.0, 1.0, 0.07687376457494573, 0.0, 1.0, -0.25, 1.0, 1.0, 0.32787669816143095, 0.0, 0.0, 0.5084288129206541, 0.2205291235090341, 0.2205291235090341, 0.4453081421542263], 
reward next is 0.5547, 
noisyNet noise sample is [array([-0.472035], dtype=float32), 0.017347282]. 
=============================================
[2019-03-23 20:10:39,179] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.4979627e-02 1.1750761e-10 9.7426653e-01 5.1485040e-06 7.4874552e-04], sum to 1.0000
[2019-03-23 20:10:39,187] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3096
[2019-03-23 20:10:39,191] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 72.33333333333334, 1.0, 2.0, 0.3618458883524852, 0.0, 2.0, 0.0, 1.0, 2.0, 0.723832593954679, 6.9112, 6.9112, 81.5106177893273, 824230.5757761075, 824230.5757761075, 205592.3087396963], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3744600.0000, 
sim time next is 3745200.0000, 
raw observation next is [23.0, 71.66666666666667, 1.0, 2.0, 0.5011619010023023, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9407300360733593, 6.949774040278203, 6.9112, 77.32836881548697, 1119245.058864666, 1106717.014888654, 246891.7547943144], 
processed observation next is [1.0, 0.34782608695652173, 0.6818181818181818, 0.7166666666666667, 1.0, 1.0, 0.3764523762528778, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9153286229619418, 0.003857404027820266, 0.0, 0.508428190748338, 0.4145352069869133, 0.4098951906995015, 0.6021750116934498], 
reward next is 0.2050, 
noisyNet noise sample is [array([0.20091408], dtype=float32), 0.13067053]. 
=============================================
[2019-03-23 20:10:39,388] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3543645e-01 5.2702067e-08 8.4265357e-01 8.4117615e-05 2.1825878e-02], sum to 1.0000
[2019-03-23 20:10:39,397] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9738
[2019-03-23 20:10:39,401] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.83333333333333, 69.0, 1.0, 2.0, 0.4403193414169613, 0.0, 2.0, 0.0, 1.0, 2.0, 0.883873710551846, 6.911199999999999, 6.9112, 77.32846344353835, 1004506.97239922, 1004506.97239922, 233354.9541896282], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3750600.0000, 
sim time next is 3751200.0000, 
raw observation next is [24.0, 69.0, 1.0, 2.0, 0.4975687626854517, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9424365080975996, 6.951540693546419, 6.9112, 77.32836404379695, 1115980.474703561, 1102878.659390946, 249128.3603455688], 
processed observation next is [1.0, 0.43478260869565216, 0.7272727272727273, 0.69, 1.0, 1.0, 0.37196095335681456, 0.0, 1.0, -0.25, 1.0, 1.0, 0.917766440139428, 0.0040340693546419, 0.0, 0.5084281593748362, 0.41332610174205964, 0.4084735775522022, 0.6076301471843142], 
reward next is 0.1907, 
noisyNet noise sample is [array([1.188442], dtype=float32), -0.8436076]. 
=============================================
[2019-03-23 20:10:50,905] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.0488130e-02 7.9262857e-10 9.6400195e-01 8.3375735e-06 5.5016084e-03], sum to 1.0000
[2019-03-23 20:10:50,913] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3434
[2019-03-23 20:10:50,918] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.5, 78.0, 1.0, 2.0, 0.3182547821072448, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6318962652697409, 6.9112, 6.9112, 77.32846344354104, 722215.3846505503, 722215.3846505503, 188280.4570264492], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4098600.0000, 
sim time next is 4099200.0000, 
raw observation next is [21.66666666666667, 78.0, 1.0, 2.0, 0.3361485602358276, 0.0, 2.0, 0.0, 1.0, 2.0, 0.668769080526483, 6.911199999999999, 6.9112, 77.32846344354104, 763683.6854255034, 763683.6854255038, 193951.5690705979], 
processed observation next is [1.0, 0.43478260869565216, 0.6212121212121214, 0.78, 1.0, 1.0, 0.1701857002947845, 0.0, 1.0, -0.25, 1.0, 1.0, 0.52681297218069, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2828458094168531, 0.2828458094168532, 0.4730526074892632], 
reward next is 0.5269, 
noisyNet noise sample is [array([-1.3907888], dtype=float32), -0.040434755]. 
=============================================
[2019-03-23 20:10:51,707] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.8301596e-02 1.8628959e-10 9.3094432e-01 2.6320024e-06 7.5137720e-04], sum to 1.0000
[2019-03-23 20:10:51,712] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1933
[2019-03-23 20:10:51,716] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 87.16666666666667, 1.0, 2.0, 0.2296337864794901, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4380696572468373, 6.9112, 6.9112, 77.32846344354104, 506872.1901580922, 506872.1901580922, 159857.9602046614], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4006200.0000, 
sim time next is 4006800.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.2210257327956141, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4224701946242018, 6.9112, 6.9112, 77.32846344354104, 488587.7082887352, 488587.7082887352, 158730.2624299978], 
processed observation next is [1.0, 0.391304347826087, 0.45454545454545453, 0.88, 1.0, 1.0, 0.026282165994517617, 0.0, 1.0, -0.25, 1.0, 1.0, 0.17495742089171692, 0.0, 0.0, 0.5084288129206541, 0.18095841047730932, 0.18095841047730932, 0.38714698153658], 
reward next is 0.6129, 
noisyNet noise sample is [array([-1.5721889], dtype=float32), -1.2204446]. 
=============================================
[2019-03-23 20:10:54,068] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.5422835e-05 1.6026012e-09 9.9993384e-01 1.4472788e-07 5.4356997e-07], sum to 1.0000
[2019-03-23 20:10:54,074] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2579
[2019-03-23 20:10:54,080] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3261917646121899, 6.911200000000001, 6.9112, 77.32846344354104, 376721.9603114771, 376721.9603114768, 149204.9836045967], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4048800.0000, 
sim time next is 4049400.0000, 
raw observation next is [17.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.32692027651107, 6.911200000000001, 6.9112, 77.32846344354104, 377563.3064602307, 377563.3064602304, 149289.5587976185], 
processed observation next is [1.0, 0.8695652173913043, 0.4090909090909091, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.03845753787295712, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1398382616519373, 0.1398382616519372, 0.36412087511614266], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.8529998], dtype=float32), -0.14179355]. 
=============================================
[2019-03-23 20:10:55,767] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.6245511e-04 7.7193624e-10 9.9973434e-01 1.0768331e-06 2.2023357e-06], sum to 1.0000
[2019-03-23 20:10:55,773] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8218
[2019-03-23 20:10:55,787] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [15.96666666666667, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 329644.1561145856, 329644.1561145856, 141367.1242028781], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4075800.0000, 
sim time next is 4076400.0000, 
raw observation next is [15.93333333333333, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 326799.4602401032, 326799.460240103, 140853.0020779799], 
processed observation next is [1.0, 0.17391304347826086, 0.36060606060606043, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12103683712596415, 0.12103683712596408, 0.34354390750726804], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7265371], dtype=float32), -1.0156205]. 
=============================================
[2019-03-23 20:10:56,853] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.05319604e-01 9.64892735e-08 8.79981816e-01 7.75877154e-04
 1.39225693e-02], sum to 1.0000
[2019-03-23 20:10:56,858] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6840
[2019-03-23 20:10:56,866] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 73.0, 1.0, 2.0, 0.3423198192232634, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6853066770789353, 6.911200000000001, 6.9112, 77.32846344354104, 780002.188463287, 780002.1884632866, 198223.5518398901], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4104000.0000, 
sim time next is 4104600.0000, 
raw observation next is [22.83333333333334, 73.0, 1.0, 2.0, 0.3859285691356985, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7722078228171068, 6.911199999999999, 6.9112, 77.32846344354104, 879270.9935216518, 879270.9935216522, 211848.8329323659], 
processed observation next is [1.0, 0.5217391304347826, 0.6742424242424245, 0.73, 1.0, 1.0, 0.2324107114196231, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6745826040244383, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3256559235265377, 0.3256559235265378, 0.5167044705667462], 
reward next is 0.4833, 
noisyNet noise sample is [array([0.2416962], dtype=float32), 0.0206049]. 
=============================================
[2019-03-23 20:10:56,922] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.9382149e-02 1.1740315e-07 8.9840108e-01 7.2919496e-04 1.1487415e-02], sum to 1.0000
[2019-03-23 20:10:56,930] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9777
[2019-03-23 20:10:56,937] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.5, 73.0, 1.0, 2.0, 0.3008066793567168, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5995845932833243, 6.911199999999999, 6.9112, 77.32846344354104, 683994.5051547574, 683994.5051547576, 184970.7952525672], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4105800.0000, 
sim time next is 4106400.0000, 
raw observation next is [22.33333333333334, 73.0, 1.0, 2.0, 0.2649171628588551, 0.0, 2.0, 0.0, 1.0, 2.0, 0.52682293645439, 6.911199999999999, 6.9112, 77.32846344354104, 601615.8264852272, 601615.8264852274, 175535.6972030674], 
processed observation next is [1.0, 0.5217391304347826, 0.6515151515151518, 0.73, 1.0, 1.0, 0.08114645357356884, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3240327663634144, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2228206764760101, 0.22282067647601017, 0.42813584683674977], 
reward next is 0.5719, 
noisyNet noise sample is [array([0.2416962], dtype=float32), 0.0206049]. 
=============================================
[2019-03-23 20:11:07,406] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.2075322e-04 3.2699576e-09 9.9976116e-01 2.0145058e-06 1.6092205e-05], sum to 1.0000
[2019-03-23 20:11:07,416] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4596
[2019-03-23 20:11:07,424] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 78.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3855140170011572, 6.9112, 6.9112, 77.32846344354104, 441921.7606203331, 441921.7606203331, 159410.2236851717], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4312800.0000, 
sim time next is 4313400.0000, 
raw observation next is [21.0, 78.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3829032426433193, 6.911199999999999, 6.9112, 77.32846344354104, 438990.649427808, 438990.6494278083, 159011.2714744763], 
processed observation next is [1.0, 0.9565217391304348, 0.5909090909090909, 0.78, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.11843320377617048, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16258912941770667, 0.16258912941770678, 0.38783236944994215], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8003397], dtype=float32), -0.278165]. 
=============================================
[2019-03-23 20:11:07,735] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 20:11:07,736] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:11:07,736] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:11:07,738] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:11:07,740] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:11:07,743] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:11:07,744] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:11:07,744] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:11:07,745] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:11:07,746] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:11:07,748] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:11:07,770] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run82
[2019-03-23 20:11:07,794] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run82
[2019-03-23 20:11:07,796] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run82
[2019-03-23 20:11:07,839] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run82
[2019-03-23 20:11:07,839] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run82
[2019-03-23 20:11:14,074] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00267751], dtype=float32), 0.015172265]
[2019-03-23 20:11:14,075] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.01666666666667, 65.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 258165.8769887459, 258165.8769887459, 103511.5134839778]
[2019-03-23 20:11:14,075] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:11:14,078] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.0483241e-04 1.1361348e-08 9.9979228e-01 7.6723052e-07 2.0839266e-06], sampled 0.7469955741613015
[2019-03-23 20:11:29,494] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00267751], dtype=float32), 0.015172265]
[2019-03-23 20:11:29,496] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.68766911333334, 49.18798455333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 228798.19221839, 228798.1922183896, 94606.20820508948]
[2019-03-23 20:11:29,498] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:11:29,502] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.3702254e-04 2.5841716e-08 9.9975926e-01 1.2068371e-06 2.4560213e-06], sampled 0.552753136322391
[2019-03-23 20:11:36,143] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00267751], dtype=float32), 0.015172265]
[2019-03-23 20:11:36,146] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.86666666666667, 56.33333333333333, 1.0, 2.0, 0.2324311855859647, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4338981033908266, 6.9112, 6.9112, 95.55338769695034, 504814.8179556925, 504814.8179556925, 138947.7302466254]
[2019-03-23 20:11:36,148] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:11:36,153] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.2757838e-03 7.9253222e-11 9.9065620e-01 5.8757206e-07 6.7451554e-05], sampled 0.482636203065
[2019-03-23 20:11:42,275] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00267751], dtype=float32), 0.015172265]
[2019-03-23 20:11:42,276] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.01268359, 54.63449144, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3709018920375907, 6.9112, 6.9112, 95.55338769695034, 426217.6759467594, 426217.6759467594, 161140.047559054]
[2019-03-23 20:11:42,277] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:11:42,281] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.8836315e-04 3.3017901e-11 9.9951077e-01 3.2850856e-08 8.5710963e-07], sampled 0.20267734070323273
[2019-03-23 20:11:44,841] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00267751], dtype=float32), 0.015172265]
[2019-03-23 20:11:44,841] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.50741442333334, 90.33396776000001, 1.0, 2.0, 0.2546272478456402, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5149057458926061, 6.9112, 6.9112, 95.55338769695034, 580670.3660775184, 580670.3660775184, 184372.7130184212]
[2019-03-23 20:11:44,845] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:11:44,847] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.3340025e-03 4.1086926e-12 9.9162221e-01 1.6414158e-07 4.3696353e-05], sampled 0.12273913153836935
[2019-03-23 20:11:58,681] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00267751], dtype=float32), 0.015172265]
[2019-03-23 20:11:58,682] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.87638566333334, 81.23463891333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3352362881831463, 6.911200000000001, 6.9112, 95.55338769695034, 387214.296651063, 387214.2966510626, 154758.3742202364]
[2019-03-23 20:11:58,683] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:11:58,687] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.3935128e-03 1.9283124e-11 9.9860317e-01 5.4864220e-08 3.2818773e-06], sampled 0.7604117126402418
[2019-03-23 20:12:02,448] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00267751], dtype=float32), 0.015172265]
[2019-03-23 20:12:02,449] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.95, 87.0, 1.0, 2.0, 0.2606375296457235, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5274288584851093, 6.911200000000001, 6.9112, 95.55338769695034, 594029.4724475151, 594029.4724475148, 186391.3317738942]
[2019-03-23 20:12:02,450] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:12:02,455] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.9184351e-03 2.0922016e-12 9.9507314e-01 4.3026912e-08 8.3839304e-06], sampled 0.031172253780267556
[2019-03-23 20:12:15,246] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00267751], dtype=float32), 0.015172265]
[2019-03-23 20:12:15,247] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.66117879166667, 87.8017295, 1.0, 2.0, 0.3039300410891654, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6156663782250258, 6.911200000000001, 6.9112, 95.55338769695034, 690099.454790305, 690099.4547903046, 200101.9973763824]
[2019-03-23 20:12:15,248] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:12:15,251] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.01519935e-02 5.27955154e-12 9.89798784e-01 1.93446098e-07
 4.89983977e-05], sampled 0.9192374226610109
[2019-03-23 20:12:26,587] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00267751], dtype=float32), 0.015172265]
[2019-03-23 20:12:26,588] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.90067745666667, 70.21267360666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3540973079550111, 6.911199999999999, 6.9112, 95.55338769695034, 409796.5528562966, 409796.5528562969, 156259.0638653206]
[2019-03-23 20:12:26,590] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:12:26,593] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.3213683e-04 4.5197266e-11 9.9926585e-01 6.0673088e-08 1.9158247e-06], sampled 0.577279753579753
[2019-03-23 20:12:28,096] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00267751], dtype=float32), 0.015172265]
[2019-03-23 20:12:28,099] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.581822, 49.77128268666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3083933341116704, 6.9112, 6.9112, 95.55338769695034, 357966.0190164223, 357966.0190164223, 149826.0974815771]
[2019-03-23 20:12:28,100] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:12:28,104] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.8500070e-04 8.1612184e-10 9.9981397e-01 1.4957234e-07 9.6001168e-07], sampled 0.7632768703802176
[2019-03-23 20:12:38,999] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00267751], dtype=float32), 0.015172265]
[2019-03-23 20:12:39,001] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.75, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3622175347747628, 6.9112, 6.9112, 95.55338769695034, 416052.8758263348, 416052.8758263348, 160192.6018954089]
[2019-03-23 20:12:39,002] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:12:39,006] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.0342189e-04 7.7616961e-11 9.9919420e-01 7.6817201e-08 2.2155366e-06], sampled 0.20921231254901307
[2019-03-23 20:12:51,404] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3331.6293 2096334335.6979 187.0000
[2019-03-23 20:12:51,636] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2745.4578 2122820953.5189 754.0000
[2019-03-23 20:12:51,704] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3574.0543 2173602990.5292 251.0000
[2019-03-23 20:12:51,818] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3499.0787 2102488423.6114 190.0000
[2019-03-23 20:12:51,911] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3099.4962 2107334099.8268 378.0000
[2019-03-23 20:12:52,928] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 2025000, evaluation results [2025000.0, 3574.054323340804, 2173602990.529241, 251.0, 3331.6293475289303, 2096334335.6978738, 187.0, 3499.0787176153103, 2102488423.6114154, 190.0, 2745.4577579894785, 2122820953.5188568, 754.0, 3099.496218064969, 2107334099.8268101, 378.0]
[2019-03-23 20:12:53,587] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0655209e-02 1.2681421e-10 9.8915839e-01 7.0179226e-07 1.8568948e-04], sum to 1.0000
[2019-03-23 20:12:53,592] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3974
[2019-03-23 20:12:53,596] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.2244157002609537, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4458282060573615, 6.911199999999999, 6.9112, 77.32846344354104, 509311.836121767, 509311.8361217673, 166788.2148582519], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4348800.0000, 
sim time next is 4349400.0000, 
raw observation next is [21.33333333333333, 82.16666666666667, 1.0, 2.0, 0.2512371876867784, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5002860822269142, 6.911200000000001, 6.9112, 77.32846344354104, 570929.4156325171, 570929.4156325167, 172884.8296858017], 
processed observation next is [1.0, 0.34782608695652173, 0.6060606060606059, 0.8216666666666668, 1.0, 1.0, 0.06404648460847297, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2861229746098774, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21145533912315448, 0.21145533912315434, 0.42167031630683344], 
reward next is 0.5783, 
noisyNet noise sample is [array([-0.37943742], dtype=float32), -0.12353531]. 
=============================================
[2019-03-23 20:12:54,919] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2066141e-02 8.7115426e-11 9.8787349e-01 7.9747900e-07 5.9424568e-05], sum to 1.0000
[2019-03-23 20:12:54,927] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8952
[2019-03-23 20:12:54,933] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.83333333333334, 95.0, 1.0, 2.0, 0.2468634126190998, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4993328346393501, 6.9112, 6.9112, 77.32846344354104, 562918.5160797215, 562918.5160797215, 178005.3662187436], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4524600.0000, 
sim time next is 4525200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.2481034773875651, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5019153083068367, 6.9112, 6.9112, 77.32846344354104, 565679.1683825849, 565679.1683825849, 178406.4096049374], 
processed observation next is [0.0, 0.391304347826087, 0.6363636363636364, 0.94, 1.0, 1.0, 0.06012934673445637, 0.0, 1.0, -0.25, 1.0, 1.0, 0.28845044043833823, 0.0, 0.0, 0.5084288129206541, 0.20951080310466108, 0.20951080310466108, 0.43513758440228634], 
reward next is 0.5649, 
noisyNet noise sample is [array([2.2330334], dtype=float32), 1.2415036]. 
=============================================
[2019-03-23 20:12:57,334] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.6062885e-02 5.3203329e-14 9.4391030e-01 3.6675569e-08 2.6908110e-05], sum to 1.0000
[2019-03-23 20:12:57,349] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3113
[2019-03-23 20:12:57,354] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.43333333333334, 67.33333333333334, 1.0, 2.0, 0.2436482193974615, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4922276629250188, 6.9112, 6.9112, 77.32846344354104, 555923.6936237278, 555923.6936237278, 176478.2842892272], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4393200.0000, 
sim time next is 4393800.0000, 
raw observation next is [25.15, 68.5, 1.0, 2.0, 0.2421845403100256, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4890880835266509, 6.911199999999999, 6.9112, 77.32846344354104, 552635.2829253053, 552635.2829253055, 175941.2790207625], 
processed observation next is [1.0, 0.8695652173913043, 0.7795454545454544, 0.685, 1.0, 1.0, 0.052730675387531976, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2701258336095013, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20467973441677975, 0.20467973441677983, 0.4291250707823476], 
reward next is 0.5709, 
noisyNet noise sample is [array([0.7472803], dtype=float32), 2.3956885]. 
=============================================
[2019-03-23 20:13:07,515] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.0897336e-03 2.0340278e-09 9.8195779e-01 2.1140020e-05 1.0931257e-02], sum to 1.0000
[2019-03-23 20:13:07,523] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4852
[2019-03-23 20:13:07,528] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.33333333333334, 59.0, 1.0, 2.0, 0.3742276616929543, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7226596199173188, 6.911199999999999, 6.9112, 77.32846344354104, 833882.9064955274, 833882.9064955277, 195389.7602533074], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4705800.0000, 
sim time next is 4706400.0000, 
raw observation next is [22.66666666666667, 58.00000000000001, 1.0, 2.0, 0.3371398790298157, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6527434042793349, 6.9112, 6.9112, 77.32846344354104, 752603.1461683096, 752603.1461683096, 185985.5711427747], 
processed observation next is [1.0, 0.4782608695652174, 0.6666666666666669, 0.5800000000000001, 1.0, 1.0, 0.17142484878726957, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5039191489704784, 0.0, 0.0, 0.5084288129206541, 0.2787419059882628, 0.2787419059882628, 0.45362334425066997], 
reward next is 0.5464, 
noisyNet noise sample is [array([0.34795287], dtype=float32), -1.2446188]. 
=============================================
[2019-03-23 20:13:12,185] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.2127353e-04 9.5572640e-11 9.9976164e-01 3.9231296e-08 1.7037302e-05], sum to 1.0000
[2019-03-23 20:13:12,193] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2116
[2019-03-23 20:13:12,204] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3535199114340437, 6.9112, 6.9112, 77.32846344354104, 406846.2051921151, 406846.2051921151, 153804.7042903286], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4757400.0000, 
sim time next is 4758000.0000, 
raw observation next is [19.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3526393340377703, 6.9112, 6.9112, 77.32846344354104, 405833.5393905484, 405833.5393905484, 153695.2776286236], 
processed observation next is [1.0, 0.043478260869565216, 0.5, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.07519904862538618, 0.0, 0.0, 0.5084288129206541, 0.1503087182927957, 0.1503087182927957, 0.37486653080152094], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.292709], dtype=float32), -0.1850458]. 
=============================================
[2019-03-23 20:13:12,214] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[31.024088]
 [30.309437]
 [30.669344]
 [30.245962]
 [30.324883]], R is [[30.56360435]
 [30.2579689 ]
 [29.95538902]
 [29.65583611]
 [29.35927773]].
[2019-03-23 20:13:14,213] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.5141023e-02 3.8953687e-11 9.8481500e-01 1.0408257e-06 4.2837339e-05], sum to 1.0000
[2019-03-23 20:13:14,222] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8204
[2019-03-23 20:13:14,226] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.16666666666667, 72.33333333333333, 1.0, 2.0, 0.2155408316653971, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4312292943965495, 6.911199999999999, 6.9112, 77.32846344354104, 490853.2381596874, 490853.2381596877, 166947.4630558525], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4737000.0000, 
sim time next is 4737600.0000, 
raw observation next is [23.0, 73.0, 1.0, 2.0, 0.2140119652124283, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4279078659038032, 6.911200000000001, 6.9112, 77.32846344354104, 487242.2545782462, 487242.2545782459, 166485.1726367779], 
processed observation next is [1.0, 0.8695652173913043, 0.6818181818181818, 0.73, 1.0, 1.0, 0.017514956515535356, 0.0, 1.0, -0.25, 1.0, 1.0, 0.18272552271971887, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18046009428823934, 0.18046009428823923, 0.406061396675068], 
reward next is 0.5939, 
noisyNet noise sample is [array([0.15250623], dtype=float32), -3.0145855]. 
=============================================
[2019-03-23 20:13:16,969] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.5610105e-04 9.6564423e-11 9.9886322e-01 2.3524726e-06 1.7838206e-04], sum to 1.0000
[2019-03-23 20:13:16,976] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4830
[2019-03-23 20:13:16,980] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3673803976714791, 6.9112, 6.9112, 77.32846344354104, 422758.8616420119, 422758.8616420119, 155569.7532221294], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4761600.0000, 
sim time next is 4762200.0000, 
raw observation next is [19.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.362581317664547, 6.911200000000001, 6.9112, 77.32846344354104, 417253.5642220341, 417253.5642220338, 154950.8781385413], 
processed observation next is [1.0, 0.08695652173913043, 0.5, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.08940188237792429, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15453835711927189, 0.15453835711927177, 0.37792897106961293], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1151462], dtype=float32), 0.48172563]. 
=============================================
[2019-03-23 20:13:20,609] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.4485505e-03 1.0149495e-09 9.9142003e-01 5.2343821e-06 1.2623875e-04], sum to 1.0000
[2019-03-23 20:13:20,619] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9254
[2019-03-23 20:13:20,625] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.83333333333333, 95.0, 1.0, 2.0, 0.2286667650532031, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4601357117360886, 6.9112, 6.9112, 77.32846344354104, 521727.0803027492, 521727.0803027492, 171430.7319746658], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4835400.0000, 
sim time next is 4836000.0000, 
raw observation next is [20.66666666666667, 96.0, 1.0, 2.0, 0.2279384707806305, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4585141654197319, 6.911200000000001, 6.9112, 77.32846344354104, 520029.2869963585, 520029.2869963582, 171152.6821663023], 
processed observation next is [1.0, 1.0, 0.575757575757576, 0.96, 1.0, 1.0, 0.03492308847578812, 0.0, 1.0, -0.25, 1.0, 1.0, 0.22644880774247417, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19260343962828091, 0.1926034396282808, 0.41744556625927387], 
reward next is 0.5826, 
noisyNet noise sample is [array([-0.22344153], dtype=float32), -1.1424481]. 
=============================================
[2019-03-23 20:13:20,649] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[26.005259]
 [26.364077]
 [26.89556 ]
 [27.346392]
 [27.7405  ]], R is [[25.85554314]
 [26.17886543]
 [26.49858665]
 [26.81521988]
 [27.12845802]].
[2019-03-23 20:13:23,177] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.3163226e-02 1.9356311e-10 9.2107970e-01 1.5432912e-05 5.7415632e-03], sum to 1.0000
[2019-03-23 20:13:23,183] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7292
[2019-03-23 20:13:23,186] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.2438147280730489, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4847583420514698, 6.9112, 6.9112, 77.32846344354104, 553605.0396298222, 553605.0396298222, 170884.2429105871], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4884000.0000, 
sim time next is 4884600.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.2314116216177666, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4599290559498579, 6.9112, 6.9112, 77.32846344354104, 525323.444834123, 525323.444834123, 168263.8064759861], 
processed observation next is [1.0, 0.5217391304347826, 0.5909090909090909, 0.83, 1.0, 1.0, 0.039264527022208236, 0.0, 1.0, -0.25, 1.0, 1.0, 0.22847007992836846, 0.0, 0.0, 0.5084288129206541, 0.19456423882745297, 0.19456423882745297, 0.41039952799020996], 
reward next is 0.5896, 
noisyNet noise sample is [array([-0.61958474], dtype=float32), 0.7248482]. 
=============================================
[2019-03-23 20:13:24,435] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4754749e-04 1.7122319e-10 9.9984467e-01 7.4078862e-08 7.5994662e-06], sum to 1.0000
[2019-03-23 20:13:24,441] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7819
[2019-03-23 20:13:24,445] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.2049236510123113, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4071717174128658, 6.9112, 6.9112, 77.32846344354104, 465095.0130534375, 465095.0130534375, 163238.8144490414], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4910400.0000, 
sim time next is 4911000.0000, 
raw observation next is [21.0, 83.83333333333334, 1.0, 2.0, 0.2054012610837236, 0.0, 2.0, 0.0, 1.0, 2.0, 0.408379802621785, 6.9112, 6.9112, 77.32846344354104, 466339.2739269445, 466339.2739269445, 163471.918604945], 
processed observation next is [1.0, 0.8695652173913043, 0.5909090909090909, 0.8383333333333334, 1.0, 1.0, 0.006751576354654502, 0.0, 1.0, -0.25, 1.0, 1.0, 0.15482828945969293, 0.0, 0.0, 0.5084288129206541, 0.17271824960257204, 0.17271824960257204, 0.39871199659742684], 
reward next is 0.6013, 
noisyNet noise sample is [array([-0.27033278], dtype=float32), -1.1999859]. 
=============================================
[2019-03-23 20:13:24,470] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[18.231546]
 [18.592573]
 [19.082401]
 [19.314594]
 [20.105606]], R is [[18.76359749]
 [19.1778183 ]
 [19.58657455]
 [19.98991013]
 [20.38780975]].
[2019-03-23 20:13:27,263] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.8228342e-05 1.4239578e-15 9.9998176e-01 7.2296766e-11 4.7188351e-08], sum to 1.0000
[2019-03-23 20:13:27,269] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4183
[2019-03-23 20:13:27,275] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.0, 96.0, 1.0, 2.0, 0.2143898777133559, 0.0, 2.0, 0.0, 1.0, 2.0, 0.428680810079994, 6.911200000000001, 6.9112, 77.32846344354104, 488111.6327151711, 488111.6327151709, 166567.8416345585], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5621400.0000, 
sim time next is 5622000.0000, 
raw observation next is [20.0, 96.0, 1.0, 2.0, 0.214369643940534, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4286408823582446, 6.911199999999999, 6.9112, 77.32846344354104, 488065.8039275325, 488065.8039275327, 166564.3625981954], 
processed observation next is [0.0, 0.043478260869565216, 0.5454545454545454, 0.96, 1.0, 1.0, 0.0179620549256675, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1837726890832066, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18076511256575278, 0.18076511256575284, 0.40625454292242785], 
reward next is 0.5937, 
noisyNet noise sample is [array([0.05974086], dtype=float32), -1.0507414]. 
=============================================
[2019-03-23 20:13:27,295] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[37.58549 ]
 [36.977097]
 [35.62881 ]
 [33.185085]
 [32.927773]], R is [[38.95904922]
 [39.16319656]
 [39.36534882]
 [39.56570435]
 [39.76498795]].
[2019-03-23 20:13:27,466] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.9875452e-03 2.1264533e-12 9.9688858e-01 5.5747580e-07 1.2325624e-04], sum to 1.0000
[2019-03-23 20:13:27,477] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3424
[2019-03-23 20:13:27,482] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.66666666666666, 69.66666666666666, 1.0, 2.0, 0.2947254449589736, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5571940668834906, 6.9112, 6.9112, 77.32846344354104, 646106.1351975348, 646106.1351975348, 170674.1128509316], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4977600.0000, 
sim time next is 4978200.0000, 
raw observation next is [19.83333333333334, 68.83333333333334, 1.0, 2.0, 0.2972518356935687, 0.0, 2.0, 0.0, 1.0, 2.0, 0.562625452731147, 6.9112, 6.9112, 77.32846344354104, 652244.0640067147, 652244.0640067147, 171436.2010492585], 
processed observation next is [1.0, 0.6086956521739131, 0.5378787878787882, 0.6883333333333335, 1.0, 1.0, 0.12156479461696089, 0.0, 1.0, -0.25, 1.0, 1.0, 0.37517921818735284, 0.0, 0.0, 0.5084288129206541, 0.2415718755580425, 0.2415718755580425, 0.4181370757298988], 
reward next is 0.5819, 
noisyNet noise sample is [array([1.3394636], dtype=float32), -0.3893283]. 
=============================================
[2019-03-23 20:13:27,598] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.1734493e-04 1.4943250e-13 9.9928242e-01 5.8102803e-09 2.9409426e-07], sum to 1.0000
[2019-03-23 20:13:27,607] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9928
[2019-03-23 20:13:27,617] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 54.0, 1.0, 2.0, 0.2024425074988933, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4036226486299774, 6.9112, 6.9112, 77.32846344354104, 460279.5831706339, 460279.5831706339, 163624.3563847094], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5061600.0000, 
sim time next is 5062200.0000, 
raw observation next is [26.16666666666667, 53.5, 1.0, 2.0, 0.2029188489462353, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4047636604436417, 6.911200000000001, 6.9112, 77.32846344354104, 461469.5246357154, 461469.5246357151, 163826.9852660439], 
processed observation next is [0.0, 0.6086956521739131, 0.825757575757576, 0.535, 1.0, 1.0, 0.003648561182794108, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1496623720623453, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17091463875396867, 0.17091463875396856, 0.3995780128440095], 
reward next is 0.6004, 
noisyNet noise sample is [array([0.03002063], dtype=float32), 0.2855768]. 
=============================================
[2019-03-23 20:13:33,937] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.4986930e-03 9.1042796e-10 9.8319215e-01 2.5533489e-05 7.2836648e-03], sum to 1.0000
[2019-03-23 20:13:33,942] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8220
[2019-03-23 20:13:33,948] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.83333333333334, 95.0, 1.0, 2.0, 0.448000378402509, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9067985502449638, 6.911199999999999, 6.9112, 77.32846344354104, 1021304.297092761, 1021304.297092761, 243898.0634389652], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5226600.0000, 
sim time next is 5227200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.4550544531813267, 0.0, 2.0, 0.0, 1.0, 2.0, 0.921180528077772, 6.911199999999999, 6.9112, 77.32846344354104, 1037220.365322555, 1037220.365322556, 247067.207284747], 
processed observation next is [1.0, 0.5217391304347826, 0.6363636363636364, 0.94, 1.0, 1.0, 0.31881806647665833, 0.0, 1.0, -0.25, 1.0, 1.0, 0.8874007543968172, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3841556908602055, 0.3841556908602059, 0.602602944596944], 
reward next is 0.3974, 
noisyNet noise sample is [array([1.3233833], dtype=float32), 0.22590466]. 
=============================================
[2019-03-23 20:13:36,077] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.1445449e-04 1.9134317e-13 9.9958247e-01 3.0698761e-08 3.0983088e-06], sum to 1.0000
[2019-03-23 20:13:36,082] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5923
[2019-03-23 20:13:36,088] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.76666666666667, 100.0, 1.0, 2.0, 0.2387934228921163, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4820999420838858, 6.9112, 6.9112, 77.32846344354104, 544922.5783010528, 544922.5783010528, 175034.2726114537], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5269200.0000, 
sim time next is 5269800.0000, 
raw observation next is [20.68333333333333, 100.0, 1.0, 2.0, 0.2369384094816608, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4781403657255532, 6.9112, 6.9112, 77.32846344354104, 540717.0154934778, 540717.0154934778, 174402.7092555389], 
processed observation next is [1.0, 1.0, 0.5765151515151513, 1.0, 1.0, 1.0, 0.046173011852076, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2544862367507903, 0.0, 0.0, 0.5084288129206541, 0.20026556129388068, 0.20026556129388068, 0.4253724615988754], 
reward next is 0.5746, 
noisyNet noise sample is [array([-1.0257168], dtype=float32), 0.8360318]. 
=============================================
[2019-03-23 20:13:41,596] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 20:13:41,598] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:13:41,600] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:13:41,600] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:13:41,601] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:13:41,604] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:13:41,604] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:13:41,607] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:13:41,607] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:13:41,607] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:13:41,611] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:13:41,625] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run83
[2019-03-23 20:13:41,651] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run83
[2019-03-23 20:13:41,652] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run83
[2019-03-23 20:13:41,653] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run83
[2019-03-23 20:13:41,675] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run83
[2019-03-23 20:13:51,906] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00259504], dtype=float32), 0.01536909]
[2019-03-23 20:13:51,909] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.16666666666666, 61.33333333333334, 1.0, 2.0, 0.2563145387103886, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5188797906044528, 6.911199999999999, 6.9112, 77.32846344354104, 583929.4797424765, 583929.4797424768, 180981.2897239077]
[2019-03-23 20:13:51,911] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:13:51,916] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.0081320e-04 1.0784638e-17 9.9919921e-01 2.1433239e-11 2.6504850e-08], sampled 0.44303058704571585
[2019-03-23 20:14:01,372] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00259504], dtype=float32), 0.01536909]
[2019-03-23 20:14:01,373] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.1, 58.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 293054.5819444722, 293054.5819444722, 124982.0527583429]
[2019-03-23 20:14:01,374] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:14:01,377] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.3398783e-05 4.5319366e-13 9.9990642e-01 2.5387896e-09 1.1131450e-07], sampled 0.1616792833169124
[2019-03-23 20:14:01,648] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00259504], dtype=float32), 0.01536909]
[2019-03-23 20:14:01,650] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.99829529333334, 90.01653998666667, 1.0, 2.0, 0.2574703036944568, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5125667749313321, 6.9112, 6.9112, 95.55338769695034, 584958.277386944, 584958.277386944, 178957.8934586546]
[2019-03-23 20:14:01,652] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:14:01,655] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.6181480e-03 5.6442300e-16 9.9738044e-01 1.2103726e-09 1.4860312e-06], sampled 0.0789260015880866
[2019-03-23 20:14:14,744] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00259504], dtype=float32), 0.01536909]
[2019-03-23 20:14:14,744] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.65882261833333, 81.70079563666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 244721.5245161635, 244721.5245161635, 106277.0132049453]
[2019-03-23 20:14:14,746] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:14:14,748] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.8687805e-05 3.0863108e-13 9.9996126e-01 1.3149047e-09 3.9812306e-08], sampled 0.9653090002971612
[2019-03-23 20:14:16,201] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00259504], dtype=float32), 0.01536909]
[2019-03-23 20:14:16,203] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.41205139333334, 65.35143248333334, 1.0, 2.0, 0.2259328101271578, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4524077724721848, 6.9112, 6.9112, 95.55338769695034, 514659.2736154178, 514659.2736154178, 173919.494599074]
[2019-03-23 20:14:16,206] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:14:16,209] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.4186394e-03 4.9211503e-17 9.9858129e-01 1.2128305e-10 1.6761479e-07], sampled 0.8263418676105526
[2019-03-23 20:14:19,985] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00259504], dtype=float32), 0.01536909]
[2019-03-23 20:14:19,987] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 82.16666666666667, 1.0, 2.0, 0.2554578914092394, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5123664575887803, 6.911199999999999, 6.9112, 77.32846344354104, 582367.8865146019, 582367.8865146021, 176066.2542978953]
[2019-03-23 20:14:19,987] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:14:19,990] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.9558354e-03 1.4089759e-16 9.9804366e-01 3.5764458e-10 4.8126640e-07], sampled 0.5249950771934293
[2019-03-23 20:14:30,035] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00259504], dtype=float32), 0.01536909]
[2019-03-23 20:14:30,037] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.96666666666667, 53.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3888555991796107, 6.9112, 6.9112, 95.55338769695034, 445785.4997587367, 445785.4997587367, 164427.8986599937]
[2019-03-23 20:14:30,037] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:14:30,041] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.5092130e-04 2.0380849e-16 9.9984908e-01 2.4550416e-11 7.4356046e-09], sampled 0.26292617824416165
[2019-03-23 20:14:34,518] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00259504], dtype=float32), 0.01536909]
[2019-03-23 20:14:34,521] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.0, 61.0, 1.0, 2.0, 0.4182666115210618, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8312017729231306, 6.9112, 6.9112, 77.32846344354104, 949852.2137695564, 949852.2137695564, 219770.8638422689]
[2019-03-23 20:14:34,522] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:14:34,525] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.3601493e-03 8.2503275e-12 9.9118793e-01 1.3967581e-06 4.5042628e-04], sampled 0.4935007881206279
[2019-03-23 20:15:00,075] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00259504], dtype=float32), 0.01536909]
[2019-03-23 20:15:00,077] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.40638743, 88.14789510666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3161138042115452, 6.911200000000001, 6.9112, 95.55338769695034, 366457.4170684505, 366457.4170684502, 151170.5730600169]
[2019-03-23 20:15:00,079] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:15:00,081] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.8607297e-05 5.3928030e-14 9.9994135e-01 4.5087706e-10 2.2307201e-08], sampled 0.3947558942545428
[2019-03-23 20:15:25,048] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3357.0460 2097576191.2380 181.0000
[2019-03-23 20:15:25,278] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3606.4089 2174764039.9760 243.0000
[2019-03-23 20:15:25,349] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2757.3422 2123722724.2314 754.0000
[2019-03-23 20:15:25,410] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3117.0501 2108545999.1897 370.0000
[2019-03-23 20:15:25,567] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3514.5609 2103728294.7860 179.0000
[2019-03-23 20:15:26,588] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 2050000, evaluation results [2050000.0, 3606.408940588577, 2174764039.975981, 243.0, 3357.045966192874, 2097576191.2380438, 181.0, 3514.560913555274, 2103728294.7859972, 179.0, 2757.342241337887, 2123722724.2313702, 754.0, 3117.0500649945275, 2108545999.1897151, 370.0]
[2019-03-23 20:15:26,768] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.1645624e-03 1.3939022e-15 9.9383509e-01 1.1633114e-09 4.0304610e-07], sum to 1.0000
[2019-03-23 20:15:26,779] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3979
[2019-03-23 20:15:26,787] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.249409347134152, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5045800094594849, 6.9112, 6.9112, 77.32846344354104, 568635.3628136634, 568635.3628136634, 178747.0072162131], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5259000.0000, 
sim time next is 5259600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.2498096544131257, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5053903863362932, 6.9112, 6.9112, 77.32846344354104, 569548.0433155935, 569548.0433155935, 178841.5183634444], 
processed observation next is [1.0, 0.9130434782608695, 0.6363636363636364, 0.94, 1.0, 1.0, 0.0622620680164071, 0.0, 1.0, -0.25, 1.0, 1.0, 0.293414837623276, 0.0, 0.0, 0.5084288129206541, 0.2109437197465161, 0.2109437197465161, 0.4361988252766936], 
reward next is 0.5638, 
noisyNet noise sample is [array([0.81400114], dtype=float32), 0.99903667]. 
=============================================
[2019-03-23 20:15:29,545] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.6165991e-03 3.6821813e-11 9.9147475e-01 6.8853619e-06 9.0177607e-04], sum to 1.0000
[2019-03-23 20:15:29,554] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8700
[2019-03-23 20:15:29,559] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.6, 87.0, 1.0, 2.0, 0.2307911917360103, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4634684086486893, 6.911200000000001, 6.9112, 77.32846344354104, 526314.3510119852, 526314.3510119849, 171141.4184177366], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5385600.0000, 
sim time next is 5386200.0000, 
raw observation next is [21.96666666666667, 85.66666666666667, 1.0, 2.0, 0.2470123591436245, 0.0, 2.0, 0.0, 1.0, 2.0, 0.496764204446376, 6.9112, 6.9112, 77.32846344354104, 563541.470032144, 563541.470032144, 175156.6811086548], 
processed observation next is [1.0, 0.34782608695652173, 0.6348484848484849, 0.8566666666666667, 1.0, 1.0, 0.058765448929530596, 0.0, 1.0, -0.25, 1.0, 1.0, 0.28109172063768, 0.0, 0.0, 0.5084288129206541, 0.20871906297486814, 0.20871906297486814, 0.4272114173381824], 
reward next is 0.5728, 
noisyNet noise sample is [array([1.9021287], dtype=float32), -1.6337138]. 
=============================================
[2019-03-23 20:15:29,626] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4024197e-03 2.2124802e-07 8.9779025e-01 8.5135293e-04 9.8955758e-02], sum to 1.0000
[2019-03-23 20:15:29,635] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7459
[2019-03-23 20:15:29,642] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.3, 55.0, 1.0, 2.0, 0.5678595500743668, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9742742587960637, 6.9112, 6.9112, 77.32843692244955, 1195134.969563457, 1195134.969563457, 270355.0973950801], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5313600.0000, 
sim time next is 5314200.0000, 
raw observation next is [28.48333333333333, 54.66666666666667, 1.0, 2.0, 0.7942396590323623, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9754413116333084, 6.911200000000001, 6.9112, 79.72385510643586, 1452494.924611094, 1452494.924611094, 306015.138384593], 
processed observation next is [1.0, 0.5217391304347826, 0.9310606060606059, 0.5466666666666667, 1.0, 1.0, 0.7427995737904527, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9649161594761549, 8.881784197001253e-17, 0.0, 0.5241783323784518, 0.537961083189294, 0.537961083189294, 0.7463783863038854], 
reward next is 0.2536, 
noisyNet noise sample is [array([0.3421337], dtype=float32), 0.7804603]. 
=============================================
[2019-03-23 20:15:32,499] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3394695e-02 8.9592229e-11 9.8584855e-01 1.1179498e-05 7.4551883e-04], sum to 1.0000
[2019-03-23 20:15:32,506] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6756
[2019-03-23 20:15:32,510] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.41666666666667, 87.0, 1.0, 2.0, 0.2566416057456328, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5150765176914848, 6.911199999999999, 6.9112, 77.32846344354104, 585194.8504175214, 585194.8504175217, 176568.4615779484], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5368200.0000, 
sim time next is 5368800.0000, 
raw observation next is [21.23333333333333, 87.0, 1.0, 2.0, 0.2485082216585245, 0.0, 2.0, 0.0, 1.0, 2.0, 0.498001352044648, 6.911199999999999, 6.9112, 77.32846344354104, 566341.5905240111, 566341.5905240114, 174219.1546466043], 
processed observation next is [1.0, 0.13043478260869565, 0.6015151515151514, 0.87, 1.0, 1.0, 0.060635277073155594, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2828590743494972, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2097561446385226, 0.20975614463852274, 0.4249247674307422], 
reward next is 0.5751, 
noisyNet noise sample is [array([0.2728487], dtype=float32), 1.2550129]. 
=============================================
[2019-03-23 20:15:34,258] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.5748632e-02 2.7452316e-07 5.7281613e-01 2.2381765e-03 3.7919676e-01], sum to 1.0000
[2019-03-23 20:15:34,265] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7554
[2019-03-23 20:15:34,270] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.36666666666667, 61.66666666666667, 1.0, 2.0, 0.6534925723465073, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9769291163319349, 6.9112, 6.9112, 77.32846344335043, 1291101.440259993, 1291101.440259993, 284917.8125701105], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5574000.0000, 
sim time next is 5574600.0000, 
raw observation next is [27.45, 61.5, 1.0, 2.0, 0.3517503051608727, 1.0, 1.0, 0.3517503051608727, 1.0, 2.0, 0.7117649716132375, 6.9112, 6.9112, 77.3421103, 1192418.193234024, 1192418.193234024, 283031.8802070268], 
processed observation next is [1.0, 0.5217391304347826, 0.884090909090909, 0.615, 1.0, 1.0, 0.18968788145109083, 1.0, 0.5, 0.18968788145109083, 1.0, 1.0, 0.5882356737331964, 0.0, 0.0, 0.5085185399722538, 0.44163636786445337, 0.44163636786445337, 0.6903216590415288], 
reward next is 0.3097, 
noisyNet noise sample is [array([0.01189476], dtype=float32), -1.1891745]. 
=============================================
[2019-03-23 20:15:41,270] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.9366102e-01 1.6293601e-08 7.6813316e-01 3.0035933e-04 3.7905451e-02], sum to 1.0000
[2019-03-23 20:15:41,279] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8584
[2019-03-23 20:15:41,284] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.7, 51.0, 1.0, 2.0, 0.2114175345788083, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3979568665140654, 6.911199999999999, 6.9112, 77.32846344354104, 461796.1179709876, 461796.1179709879, 154916.6663080479], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5828400.0000, 
sim time next is 5829000.0000, 
raw observation next is [22.98333333333333, 51.16666666666666, 1.0, 2.0, 0.2753999408701091, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5218891038731108, 6.9112, 6.9112, 77.32846344354104, 604831.3214859593, 604831.3214859593, 167157.2402240126], 
processed observation next is [1.0, 0.4782608695652174, 0.6810606060606059, 0.5116666666666666, 1.0, 1.0, 0.09424992608763637, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3169844341044441, 0.0, 0.0, 0.5084288129206541, 0.22401160055035532, 0.22401160055035532, 0.40770058591222585], 
reward next is 0.5923, 
noisyNet noise sample is [array([0.08010421], dtype=float32), 0.6930058]. 
=============================================
[2019-03-23 20:15:41,299] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[30.593437]
 [29.730583]
 [29.645256]
 [29.308586]
 [28.078571]], R is [[32.01125336]
 [32.31329727]
 [31.9901638 ]
 [31.67026329]
 [31.98003197]].
[2019-03-23 20:15:47,234] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4197846e-03 9.3691488e-06 9.9719489e-01 2.0301995e-04 1.1727666e-03], sum to 1.0000
[2019-03-23 20:15:47,243] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8302
[2019-03-23 20:15:47,247] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.23333333333333, 66.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 221505.0019345734, 221505.0019345734, 92981.74800647116], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5817000.0000, 
sim time next is 5817600.0000, 
raw observation next is [16.6, 65.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 225913.7314234788, 225913.7314234791, 94185.55426391847], 
processed observation next is [1.0, 0.34782608695652173, 0.390909090909091, 0.65, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08367175237906622, 0.08367175237906634, 0.22972086405833775], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.04634222], dtype=float32), 1.1696543]. 
=============================================
[2019-03-23 20:15:49,058] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.6739909e-04 2.6445051e-07 9.9920207e-01 7.4723907e-06 1.2283996e-04], sum to 1.0000
[2019-03-23 20:15:49,064] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8887
[2019-03-23 20:15:49,068] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [15.5, 76.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 230279.1923342041, 230279.1923342044, 95846.76535677677], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5676000.0000, 
sim time next is 5676600.0000, 
raw observation next is [15.5, 75.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 229313.5412468121, 229313.5412468121, 95483.9879819664], 
processed observation next is [0.0, 0.6956521739130435, 0.3409090909090909, 0.755, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.084930941202523, 0.084930941202523, 0.23288777556577173], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2101189], dtype=float32), -0.1192179]. 
=============================================
[2019-03-23 20:15:49,925] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.5406668e-03 2.4446974e-06 9.9662185e-01 5.6179375e-05 7.7889522e-04], sum to 1.0000
[2019-03-23 20:15:49,932] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4086
[2019-03-23 20:15:49,940] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.9, 61.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3153565895602847, 6.911199999999999, 6.9112, 77.32846344354104, 364379.8245524464, 364379.8245524467, 147786.4503964762], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5866200.0000, 
sim time next is 5866800.0000, 
raw observation next is [21.63333333333333, 63.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.315902133045965, 6.911199999999999, 6.9112, 77.32846344354104, 365047.6499773367, 365047.649977337, 147810.9121353193], 
processed observation next is [1.0, 0.9130434782608695, 0.6196969696969695, 0.63, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.022717332922807136, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13520283332493951, 0.13520283332493963, 0.3605144198422422], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.58848673], dtype=float32), -0.46255174]. 
=============================================
[2019-03-23 20:15:57,400] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.0385608e-02 1.6767405e-07 8.8826221e-01 7.4004231e-04 2.0612100e-02], sum to 1.0000
[2019-03-23 20:15:57,407] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4462
[2019-03-23 20:15:57,410] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.66666666666666, 72.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 312814.7870272351, 312814.7870272354, 135049.1404223903], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6136800.0000, 
sim time next is 6137400.0000, 
raw observation next is [18.48333333333333, 73.83333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 312644.3365806378, 312644.3365806378, 134428.5096477151], 
processed observation next is [1.0, 0.0, 0.4765151515151514, 0.7383333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.11579419873356955, 0.11579419873356955, 0.3278744137749149], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8778842], dtype=float32), -0.9469598]. 
=============================================
[2019-03-23 20:15:57,667] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.5167861e-01 1.7850802e-07 1.0722128e-01 6.2654115e-04 7.4047339e-01], sum to 1.0000
[2019-03-23 20:15:57,676] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7639
[2019-03-23 20:15:57,682] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.7, 43.33333333333334, 1.0, 2.0, 0.2022400761921128, 1.0, 2.0, 0.2022400761921128, 1.0, 2.0, 0.3966629212397863, 6.9112, 6.9112, 77.3421103, 683245.6968194437, 683245.6968194437, 213046.609863389], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5844000.0000, 
sim time next is 5844600.0000, 
raw observation next is [25.8, 42.5, 1.0, 2.0, 0.2155380262665279, 1.0, 2.0, 0.2155380262665279, 1.0, 2.0, 0.422605130371109, 6.9112, 6.9112, 77.3421103, 728046.0148383295, 728046.0148383295, 215892.4763270295], 
processed observation next is [1.0, 0.6521739130434783, 0.8090909090909091, 0.425, 1.0, 1.0, 0.019422532833159867, 1.0, 1.0, 0.019422532833159867, 1.0, 1.0, 0.17515018624444142, 0.0, 0.0, 0.5085185399722538, 0.2696466721623443, 0.2696466721623443, 0.5265670154317793], 
reward next is 0.4734, 
noisyNet noise sample is [array([0.5089994], dtype=float32), -1.3793224]. 
=============================================
[2019-03-23 20:15:59,032] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.0297644e-03 1.6442738e-05 9.8966938e-01 4.2853906e-04 6.8557491e-03], sum to 1.0000
[2019-03-23 20:15:59,048] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4535
[2019-03-23 20:15:59,052] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.03333333333333, 49.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3107542736234848, 6.9112, 6.9112, 77.32846344354104, 359223.7457779839, 359223.7457779839, 147101.2520694906], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5858400.0000, 
sim time next is 5859000.0000, 
raw observation next is [23.85, 49.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3102989219214607, 6.9112, 6.9112, 77.32846344354104, 358824.7777768279, 358824.7777768279, 146920.6368934016], 
processed observation next is [1.0, 0.8260869565217391, 0.7204545454545456, 0.495, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.014712745602086718, 0.0, 0.0, 0.5084288129206541, 0.1328980658432696, 0.1328980658432696, 0.3583430168131746], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5696566], dtype=float32), 0.121262796]. 
=============================================
[2019-03-23 20:15:59,067] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[3.1435046]
 [3.2120967]
 [3.4589179]
 [2.820004 ]
 [1.4248086]], R is [[3.55548477]
 [3.51992989]
 [3.48473072]
 [3.44988346]
 [3.41538477]].
[2019-03-23 20:16:00,387] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.5172258e-02 2.1305230e-08 7.5763866e-02 2.5990370e-04 8.9880395e-01], sum to 1.0000
[2019-03-23 20:16:00,399] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4292
[2019-03-23 20:16:00,407] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [19.2, 83.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 456132.6060169282, 456132.6060169285, 184227.8670202151], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5970000.0000, 
sim time next is 5970600.0000, 
raw observation next is [19.1, 84.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 417183.0903163224, 417183.0903163224, 178066.1224165718], 
processed observation next is [1.0, 0.08695652173913043, 0.5045454545454546, 0.84, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5085185399722538, 0.154512255672712, 0.154512255672712, 0.4343076156501751], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5777718], dtype=float32), 0.603461]. 
=============================================
[2019-03-23 20:16:15,349] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.4156153e-03 2.3860053e-07 1.8428586e-03 6.8880362e-04 9.9405247e-01], sum to 1.0000
[2019-03-23 20:16:15,359] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8722
[2019-03-23 20:16:15,363] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [20.18333333333333, 78.5, 1.0, 2.0, 0.2004317320894877, 1.0, 2.0, 0.2004317320894877, 1.0, 2.0, 0.3951534820684727, 6.911199999999999, 6.9112, 77.3421103, 679384.627985542, 679384.6279855424, 214261.314626342], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6173400.0000, 
sim time next is 6174000.0000, 
raw observation next is [20.0, 81.0, 1.0, 2.0, 0.2117208724715384, 1.0, 2.0, 0.2117208724715384, 1.0, 2.0, 0.4183174362456594, 6.911199999999999, 6.9112, 77.3421103, 718637.117072105, 718637.1170721052, 217517.9208558799], 
processed observation next is [1.0, 0.4782608695652174, 0.5454545454545454, 0.81, 1.0, 1.0, 0.014651090589422981, 1.0, 1.0, 0.014651090589422981, 1.0, 1.0, 0.16902490892237063, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.2661618952118907, 0.2661618952118908, 0.5305315142826339], 
reward next is 0.4695, 
noisyNet noise sample is [array([-1.7518414], dtype=float32), 0.023900738]. 
=============================================
[2019-03-23 20:16:15,373] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[19.484898]
 [19.577211]
 [19.585728]
 [19.250763]
 [18.994003]], R is [[20.06992722]
 [20.34663963]
 [20.62014961]
 [20.88788414]
 [21.15948105]].
[2019-03-23 20:16:15,489] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 20:16:15,491] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:16:15,492] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:16:15,492] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:16:15,494] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:16:15,496] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:16:15,497] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:16:15,498] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:16:15,499] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:16:15,499] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:16:15,500] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:16:15,523] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run84
[2019-03-23 20:16:15,547] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run84
[2019-03-23 20:16:15,575] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run84
[2019-03-23 20:16:15,606] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run84
[2019-03-23 20:16:15,634] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run84
[2019-03-23 20:16:35,554] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00298893], dtype=float32), 0.015060943]
[2019-03-23 20:16:35,554] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.33333333333334, 39.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 368596.312873518, 368596.312873518, 170728.2501758989]
[2019-03-23 20:16:35,555] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:16:35,556] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.9244928e-02 1.7018511e-04 1.9818938e-01 5.7105836e-03 7.7668494e-01], sampled 0.508171037097632
[2019-03-23 20:16:42,891] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00298893], dtype=float32), 0.015060943]
[2019-03-23 20:16:42,892] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.47607754333334, 59.21353154666667, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 356890.6364509844, 356890.6364509844, 168994.5189447993]
[2019-03-23 20:16:42,893] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:16:42,894] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.57951470e-02 1.05639985e-04 1.30333543e-01 4.78107482e-03
 8.48984599e-01], sampled 0.6746995078354181
[2019-03-23 20:16:42,937] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00298893], dtype=float32), 0.015060943]
[2019-03-23 20:16:42,937] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.0, 52.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 251943.6908511904, 251943.6908511904, 120508.8793515534]
[2019-03-23 20:16:42,939] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:16:42,942] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.4673322e-02 1.4753762e-04 1.2145259e-01 6.0697380e-03 8.4765679e-01], sampled 0.31369084862973706
[2019-03-23 20:16:43,616] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00298893], dtype=float32), 0.015060943]
[2019-03-23 20:16:43,617] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.5, 45.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3716835411608336, 6.911199999999999, 6.9112, 77.3421103, 647540.4843219293, 647540.4843219295, 200884.7909407207]
[2019-03-23 20:16:43,622] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:16:43,626] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.7860531e-03 6.8420486e-06 2.3619397e-02 1.2190067e-03 9.6836871e-01], sampled 0.7709182393129688
[2019-03-23 20:16:51,812] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00298893], dtype=float32), 0.015060943]
[2019-03-23 20:16:51,813] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [28.0, 58.66666666666667, 1.0, 2.0, 0.4265466781974693, 1.0, 2.0, 0.4265466781974693, 1.0, 2.0, 0.8623050250204637, 6.9112, 6.9112, 77.3421103, 1442463.960865927, 1442463.960865927, 318747.5629861361]
[2019-03-23 20:16:51,814] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:16:51,817] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.0095489e-03 1.9886901e-08 1.2072611e-03 1.0037791e-04 9.9568284e-01], sampled 0.2519661466573009
[2019-03-23 20:16:55,665] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00298893], dtype=float32), 0.015060943]
[2019-03-23 20:16:55,668] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.0, 68.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3011817914060047, 6.911200000000001, 6.9112, 77.32846344354104, 349278.001675284, 349278.0016752837, 144866.4858288487]
[2019-03-23 20:16:55,670] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:16:55,672] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.2756664e-02 1.6627536e-04 3.0300000e-01 4.9704225e-03 6.6910666e-01], sampled 0.5496436845115948
[2019-03-23 20:17:14,828] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00298893], dtype=float32), 0.015060943]
[2019-03-23 20:17:14,830] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.2, 70.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 271344.1512402247, 271344.1512402247, 134961.8252905444]
[2019-03-23 20:17:14,831] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:17:14,834] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.2731454e-02 5.9272181e-05 1.2214986e-01 3.5781511e-03 8.6148125e-01], sampled 0.816133380855667
[2019-03-23 20:17:45,830] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00298893], dtype=float32), 0.015060943]
[2019-03-23 20:17:45,830] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.05, 93.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 266409.8107606103, 266409.8107606103, 136954.4429444309]
[2019-03-23 20:17:45,832] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:17:45,836] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.6179601e-03 2.3720999e-05 8.9626685e-02 2.1874765e-03 8.9854419e-01], sampled 0.9362485109186812
[2019-03-23 20:17:58,975] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 1053.7707 2486439551.4315 28.0000
[2019-03-23 20:17:59,186] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 720.6260 2428362632.8891 35.0000
[2019-03-23 20:17:59,212] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 676.4119 2421122935.8947 45.0000
[2019-03-23 20:17:59,218] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 639.2930 2432902072.7926 46.0000
[2019-03-23 20:17:59,361] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 804.8674 2429634434.5593 45.0000
[2019-03-23 20:18:00,379] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 2075000, evaluation results [2075000.0, 1053.7707298332173, 2486439551.431549, 28.0, 676.4119269818007, 2421122935.8946958, 45.0, 639.2929862496909, 2432902072.7925863, 46.0, 804.8674148524492, 2429634434.559313, 45.0, 720.6259869126726, 2428362632.8890867, 35.0]
[2019-03-23 20:18:02,741] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.6551992e-02 5.9634249e-04 1.9992432e-01 1.5887018e-02 7.5704032e-01], sum to 1.0000
[2019-03-23 20:18:02,750] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0129
[2019-03-23 20:18:02,761] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.33333333333334, 49.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 432530.8672878596, 432530.8672878596, 170055.957115751], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6541800.0000, 
sim time next is 6542400.0000, 
raw observation next is [21.06666666666667, 50.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5667184408449645, 6.911200000000001, 6.9112, 77.32846344354104, 329644.9878674371, 329644.9878674368, 87067.44750550017], 
processed observation next is [1.0, 0.7391304347826086, 0.5939393939393941, 0.5, 0.0, 0.5, -0.25, 0.0, 0.5, -0.25, 1.0, 1.0, 0.381026344064235, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12209073624719893, 0.12209073624719881, 0.21235962806219552], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7158294], dtype=float32), -1.3948269]. 
=============================================
[2019-03-23 20:18:04,515] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.2052723e-03 8.5356733e-06 9.4276622e-02 2.0597032e-03 8.9544982e-01], sum to 1.0000
[2019-03-23 20:18:04,521] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1741
[2019-03-23 20:18:04,526] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.43333333333333, 59.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3590293227950937, 6.9112, 6.9112, 77.3421103, 601904.6525330025, 601904.6525330025, 219839.9373104241], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6267000.0000, 
sim time next is 6267600.0000, 
raw observation next is [28.8, 57.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3583124776569275, 6.911199999999999, 6.9112, 77.3421103, 600463.3880819243, 600463.3880819245, 219846.0986355605], 
processed observation next is [0.0, 0.5652173913043478, 0.9454545454545454, 0.57, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.08330353950989641, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.22239384743774973, 0.22239384743774981, 0.5362099966720988], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.64071685], dtype=float32), 1.7457314]. 
=============================================
[2019-03-23 20:18:08,165] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.7739265e-03 3.8467971e-07 3.2484406e-01 5.4114533e-04 6.6984051e-01], sum to 1.0000
[2019-03-23 20:18:08,176] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5010
[2019-03-23 20:18:08,184] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.28333333333333, 87.0, 1.0, 2.0, 0.2350807693987655, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4742883488678979, 6.9112, 6.9112, 77.32846344354104, 536483.7813497391, 536483.7813497391, 173894.7873401746], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6329400.0000, 
sim time next is 6330000.0000, 
raw observation next is [22.36666666666667, 87.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.318796258366533, 6.9112, 6.9112, 77.3421103, 539419.5770969683, 539419.5770969683, 206768.4002916506], 
processed observation next is [0.0, 0.2608695652173913, 0.6530303030303032, 0.87, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.026851797666475767, 0.0, 0.0, 0.5085185399722538, 0.1997850285544327, 0.1997850285544327, 0.5043131714430503], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.675178], dtype=float32), -0.65602845]. 
=============================================
[2019-03-23 20:18:08,209] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[18.098034]
 [18.129   ]
 [18.464973]
 [17.284567]
 [18.387247]], R is [[18.26713181]
 [18.66032791]
 [19.05052185]
 [18.86001587]
 [18.67141533]].
[2019-03-23 20:18:23,998] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.1448326e-03 1.1574643e-08 9.9619377e-01 1.1452709e-06 6.6021667e-04], sum to 1.0000
[2019-03-23 20:18:24,006] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4809
[2019-03-23 20:18:24,010] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.8, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3370646954267572, 6.9112, 6.9112, 77.32846344354104, 388577.2600851679, 388577.2600851679, 151157.7825147856], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6651600.0000, 
sim time next is 6652200.0000, 
raw observation next is [18.8, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3362233527108923, 6.911199999999999, 6.9112, 77.32846344354104, 387608.4884325836, 387608.4884325839, 151056.344443895], 
processed observation next is [1.0, 1.0, 0.49090909090909096, 0.87, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.05174764672984619, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1435586994194754, 0.14355869941947552, 0.36843010839974394], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.060153], dtype=float32), -0.80765057]. 
=============================================
[2019-03-23 20:18:35,031] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.7260108e-03 2.3812608e-15 9.9527341e-01 7.2735436e-11 6.4249741e-07], sum to 1.0000
[2019-03-23 20:18:35,039] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0395
[2019-03-23 20:18:35,045] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.45, 94.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3218718288383178, 6.9112, 6.9112, 77.32846344354104, 371991.5701259376, 371991.5701259376, 148447.6644551306], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6845400.0000, 
sim time next is 6846000.0000, 
raw observation next is [17.36666666666667, 95.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3204547650040788, 6.9112, 6.9112, 77.32846344354104, 370409.5381403485, 370409.5381403485, 148229.5122340715], 
processed observation next is [0.0, 0.21739130434782608, 0.42575757575757595, 0.95, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.029221092862969766, 0.0, 0.0, 0.5084288129206541, 0.1371887178297587, 0.1371887178297587, 0.3615353956928573], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7340776], dtype=float32), -1.518188]. 
=============================================
[2019-03-23 20:18:35,063] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[33.260017]
 [34.95552 ]
 [33.132366]
 [32.87078 ]
 [35.443214]], R is [[33.54005814]
 [33.20465851]
 [32.872612  ]
 [32.54388809]
 [32.21844864]].
[2019-03-23 20:18:35,314] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.7578733e-04 1.2359550e-16 9.9932408e-01 1.0334536e-12 1.1206363e-07], sum to 1.0000
[2019-03-23 20:18:35,326] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6536
[2019-03-23 20:18:35,329] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.71666666666667, 74.33333333333334, 1.0, 2.0, 0.2292179193766042, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4615620277751231, 6.9112, 6.9112, 77.32846344354104, 523044.6012892884, 523044.6012892884, 171811.5220132867], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7510200.0000, 
sim time next is 7510800.0000, 
raw observation next is [23.63333333333334, 74.66666666666667, 1.0, 2.0, 0.2288624492008535, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4607537697598321, 6.9112, 6.9112, 77.32846344354104, 522217.5449067486, 522217.5449067486, 171658.5289949471], 
processed observation next is [0.0, 0.9565217391304348, 0.7106060606060609, 0.7466666666666667, 1.0, 1.0, 0.036078061501066856, 0.0, 1.0, -0.25, 1.0, 1.0, 0.22964824251404592, 0.0, 0.0, 0.5084288129206541, 0.193413905521018, 0.193413905521018, 0.41867933901206605], 
reward next is 0.5813, 
noisyNet noise sample is [array([0.622065], dtype=float32), -0.6518269]. 
=============================================
[2019-03-23 20:18:35,920] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.8107100e-02 6.6637533e-16 9.4188958e-01 1.1595533e-09 3.4055229e-06], sum to 1.0000
[2019-03-23 20:18:35,927] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7733
[2019-03-23 20:18:35,934] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.58333333333334, 70.16666666666667, 1.0, 2.0, 0.2096114079421846, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4193640130284819, 6.911199999999999, 6.9112, 77.32846344354104, 477342.3427918786, 477342.3427918789, 165831.9461686689], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6862200.0000, 
sim time next is 6862800.0000, 
raw observation next is [23.86666666666667, 69.33333333333334, 1.0, 2.0, 0.2121249392920754, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4249599195347323, 6.9112, 6.9112, 77.32846344354104, 483328.0352529646, 483328.0352529646, 166685.0798242865], 
processed observation next is [0.0, 0.43478260869565216, 0.7212121212121214, 0.6933333333333335, 1.0, 1.0, 0.015156174115094241, 0.0, 1.0, -0.25, 1.0, 1.0, 0.17851417076390327, 0.0, 0.0, 0.5084288129206541, 0.1790103834270239, 0.1790103834270239, 0.4065489751811866], 
reward next is 0.5935, 
noisyNet noise sample is [array([-0.13250878], dtype=float32), 0.22223514]. 
=============================================
[2019-03-23 20:18:49,331] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 20:18:49,333] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:18:49,334] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:18:49,334] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:18:49,336] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:18:49,337] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:18:49,338] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:18:49,339] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:18:49,340] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:18:49,335] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:18:49,342] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:18:49,362] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run85
[2019-03-23 20:18:49,385] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run85
[2019-03-23 20:18:49,411] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run85
[2019-03-23 20:18:49,436] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run85
[2019-03-23 20:18:49,464] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run85
[2019-03-23 20:19:03,097] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0031876], dtype=float32), 0.01525927]
[2019-03-23 20:19:03,098] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.90860347833333, 79.97976921666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 255216.8773213704, 255216.8773213704, 108585.8002554142]
[2019-03-23 20:19:03,099] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:19:03,101] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.0191598e-04 3.9178603e-09 9.9957973e-01 2.3072475e-07 1.8113957e-05], sampled 0.3050774001172175
[2019-03-23 20:19:23,457] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0031876], dtype=float32), 0.01525927]
[2019-03-23 20:19:23,458] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [28.80576131666666, 54.218144665, 1.0, 2.0, 0.2667290726100544, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5402215334614333, 6.9112, 6.9112, 95.55338769695034, 606847.6787067642, 606847.6787067642, 189001.7807715082]
[2019-03-23 20:19:23,459] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:19:23,463] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.1107391e-04 2.2349403e-12 9.9988794e-01 1.2868520e-09 9.2246984e-07], sampled 0.780876508516309
[2019-03-23 20:19:39,391] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0031876], dtype=float32), 0.01525927]
[2019-03-23 20:19:39,392] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.73333333333333, 52.66666666666667, 1.0, 2.0, 0.5115207364700154, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8880763056212627, 7.031822860792979, 6.9112, 95.55294740334318, 1130718.515978599, 1082309.862512031, 254478.9833591598]
[2019-03-23 20:19:39,393] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:19:39,397] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.4487539e-03 2.4682117e-07 9.7225565e-01 5.7631267e-05 2.2237776e-02], sampled 0.2072581951752761
[2019-03-23 20:19:44,245] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0031876], dtype=float32), 0.01525927]
[2019-03-23 20:19:44,248] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.30263051, 74.79771123666667, 1.0, 2.0, 0.2089508378172936, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4101962101088223, 6.9112, 6.9112, 95.55338769695034, 470744.9843360639, 470744.9843360639, 166052.0092028619]
[2019-03-23 20:19:44,248] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:19:44,250] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.1418896e-04 4.8473150e-13 9.9938357e-01 9.3545671e-10 2.3038872e-06], sampled 0.7309359990924699
[2019-03-23 20:19:50,985] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0031876], dtype=float32), 0.01525927]
[2019-03-23 20:19:50,986] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.1, 59.0, 1.0, 2.0, 0.3454057336453587, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6985013168377355, 6.911200000000001, 6.9112, 95.55338769695034, 787806.6486611004, 787806.6486611001, 209967.1431254231]
[2019-03-23 20:19:50,988] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:19:50,991] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.5566188e-03 1.0746236e-10 9.9715048e-01 1.6168045e-07 2.9274190e-04], sampled 0.5452374275195492
[2019-03-23 20:19:53,397] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0031876], dtype=float32), 0.01525927]
[2019-03-23 20:19:53,398] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.33333333333333, 96.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 318509.2727118356, 318509.2727118356, 139394.9345307758]
[2019-03-23 20:19:53,398] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:19:53,405] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.4867309e-04 1.5593102e-10 9.9964380e-01 2.7466811e-08 7.4670156e-06], sampled 0.6504861811057997
[2019-03-23 20:20:22,122] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0031876], dtype=float32), 0.01525927]
[2019-03-23 20:20:22,123] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.60594541, 56.401070275, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 275798.4152798903, 275798.4152798903, 107633.2710400565]
[2019-03-23 20:20:22,123] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:20:22,127] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5895280e-04 1.0165573e-09 9.9983811e-01 5.5357411e-08 2.8086833e-06], sampled 0.6546356719380959
[2019-03-23 20:20:23,384] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0031876], dtype=float32), 0.01525927]
[2019-03-23 20:20:23,386] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.54627717, 67.209773955, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 95.55338769695034, 292286.9074778208, 292286.9074778211, 138424.5358018236]
[2019-03-23 20:20:23,387] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:20:23,390] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.3338289e-04 2.0913153e-09 9.9976069e-01 1.0761731e-07 5.8145224e-06], sampled 0.12262983562401897
[2019-03-23 20:20:31,969] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2757.5060 2123948393.4440 749.0000
[2019-03-23 20:20:32,248] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3358.8493 2097592257.2725 180.0000
[2019-03-23 20:20:32,473] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3597.2130 2175668609.8807 237.0000
[2019-03-23 20:20:32,510] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3121.3516 2108762964.7987 353.0000
[2019-03-23 20:20:32,561] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3510.6215 2103894705.6827 180.0000
[2019-03-23 20:20:33,576] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 2100000, evaluation results [2100000.0, 3597.2130401568347, 2175668609.8806953, 237.0, 3358.849251913464, 2097592257.2724867, 180.0, 3510.62153494786, 2103894705.682665, 180.0, 2757.5060243207836, 2123948393.444019, 749.0, 3121.351599295963, 2108762964.7987373, 353.0]
[2019-03-23 20:20:42,273] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.4814353e-03 3.7891451e-10 9.9201149e-01 7.1608247e-07 5.0641672e-04], sum to 1.0000
[2019-03-23 20:20:42,280] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6285
[2019-03-23 20:20:42,290] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.8, 86.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3124641615837088, 6.9112, 6.9112, 77.32846344354104, 362186.8581043536, 362186.8581043536, 146282.7594999365], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7366200.0000, 
sim time next is 7366800.0000, 
raw observation next is [17.9, 86.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3014222260777421, 6.9112, 6.9112, 77.32846344354104, 349320.7243585705, 349320.7243585705, 145141.4317484192], 
processed observation next is [1.0, 0.2608695652173913, 0.44999999999999996, 0.86, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.002031751539631596, 0.0, 0.0, 0.5084288129206541, 0.1293780460587298, 0.1293780460587298, 0.35400349206931514], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8264628], dtype=float32), 0.082443774]. 
=============================================
[2019-03-23 20:20:42,699] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.3584282e-03 8.0523636e-15 9.9450809e-01 6.2243938e-10 1.3354633e-04], sum to 1.0000
[2019-03-23 20:20:42,703] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5041
[2019-03-23 20:20:42,707] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.55, 54.0, 1.0, 2.0, 0.2510738514725612, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5081469252105131, 6.911199999999999, 6.9112, 77.32846344354104, 572189.3441229427, 572189.344122943, 179479.4964419504], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7486200.0000, 
sim time next is 7486800.0000, 
raw observation next is [28.63333333333333, 53.66666666666666, 1.0, 2.0, 0.2511456647797428, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5083060949757474, 6.911199999999999, 6.9112, 77.32846344354104, 572332.6611986354, 572332.6611986356, 179522.454172452], 
processed observation next is [0.0, 0.6521739130434783, 0.9378787878787876, 0.5366666666666666, 1.0, 1.0, 0.0639320809746785, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2975801356796392, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21197505970319827, 0.21197505970319835, 0.4378596443230537], 
reward next is 0.5621, 
noisyNet noise sample is [array([0.29228622], dtype=float32), 1.1845981]. 
=============================================
[2019-03-23 20:20:43,221] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:20:43,221] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:20:43,283] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run11
[2019-03-23 20:20:43,641] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.0323726e-03 4.3461714e-07 9.9343985e-01 8.4064523e-05 3.4433191e-03], sum to 1.0000
[2019-03-23 20:20:43,648] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2312
[2019-03-23 20:20:43,651] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.9, 46.66666666666667, 1.0, 2.0, 0.2485021942776591, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4801183900887349, 6.9112, 6.9112, 77.32846344354104, 553776.990907285, 553776.990907285, 165500.8522335024], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7303800.0000, 
sim time next is 7304400.0000, 
raw observation next is [25.0, 46.0, 1.0, 2.0, 0.2314129579413916, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4467440434485537, 6.9112, 6.9112, 77.32846344354104, 515373.3937662491, 515373.3937662491, 162193.0564313269], 
processed observation next is [1.0, 0.5652173913043478, 0.7727272727272727, 0.46, 1.0, 1.0, 0.039266197426739494, 0.0, 1.0, -0.25, 1.0, 1.0, 0.20963434778364815, 0.0, 0.0, 0.5084288129206541, 0.19087903472824042, 0.19087903472824042, 0.39559282056421197], 
reward next is 0.6044, 
noisyNet noise sample is [array([1.7113187], dtype=float32), -0.0678217]. 
=============================================
[2019-03-23 20:20:45,024] A3C_AGENT_WORKER-Thread-22 INFO:Local step 132500, global step 2105751: loss 11.1444
[2019-03-23 20:20:45,026] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 132500, global step 2105751: learning rate 0.0000
[2019-03-23 20:20:48,937] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.9723521e-02 1.5992589e-09 9.6567887e-01 3.3068961e-06 4.5942832e-03], sum to 1.0000
[2019-03-23 20:20:48,948] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9668
[2019-03-23 20:20:48,960] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.8, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3671231224021509, 6.9112, 6.9112, 77.32846344354104, 422394.8926022501, 422394.8926022501, 155599.9775843264], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7423800.0000, 
sim time next is 7424400.0000, 
raw observation next is [18.8, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3678367134635201, 6.911199999999999, 6.9112, 77.32846344354104, 423226.7126908849, 423226.7126908852, 155680.1102312491], 
processed observation next is [1.0, 0.9565217391304348, 0.49090909090909096, 0.9, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.09690959066217159, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15675063432995737, 0.15675063432995748, 0.37970758592987586], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2091099], dtype=float32), 0.9873959]. 
=============================================
[2019-03-23 20:20:57,160] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.3048954e-02 1.3776221e-14 9.6694183e-01 4.2244923e-11 9.2721339e-06], sum to 1.0000
[2019-03-23 20:20:57,173] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8093
[2019-03-23 20:20:57,180] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.73333333333333, 54.33333333333333, 1.0, 2.0, 0.2404008045187368, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4853983420542087, 6.9112, 6.9112, 77.32846344354104, 548582.3700444466, 548582.3700444466, 175447.2379146788], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7576800.0000, 
sim time next is 7577400.0000, 
raw observation next is [27.46666666666667, 55.16666666666667, 1.0, 2.0, 0.2387047959397229, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4817688765550518, 6.9112, 6.9112, 77.32846344354104, 544743.2645176438, 544743.2645176438, 174855.1151144109], 
processed observation next is [0.0, 0.6956521739130435, 0.8848484848484849, 0.5516666666666667, 1.0, 1.0, 0.04838099492465362, 0.0, 1.0, -0.25, 1.0, 1.0, 0.259669823650074, 0.0, 0.0, 0.5084288129206541, 0.20175676463616438, 0.20175676463616438, 0.4264758905229534], 
reward next is 0.5735, 
noisyNet noise sample is [array([-0.77363724], dtype=float32), -0.6569335]. 
=============================================
[2019-03-23 20:20:59,153] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1994273e-03 6.8065079e-13 9.9875820e-01 8.9542089e-09 4.2344396e-05], sum to 1.0000
[2019-03-23 20:20:59,161] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1655
[2019-03-23 20:20:59,164] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.9, 92.5, 1.0, 2.0, 0.2066109504273633, 0.0, 2.0, 0.0, 1.0, 2.0, 0.410576020882062, 6.9112, 6.9112, 77.32846344354104, 468958.4614103183, 468958.4614103183, 163566.909101322], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7591800.0000, 
sim time next is 7592400.0000, 
raw observation next is [20.0, 93.0, 1.0, 2.0, 0.2092737293061747, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4166586247467693, 6.911200000000001, 6.9112, 77.32846344354104, 475483.2649874498, 475483.2649874495, 164500.4457593039], 
processed observation next is [0.0, 0.9130434782608695, 0.5454545454545454, 0.93, 1.0, 1.0, 0.011592161632718347, 0.0, 1.0, -0.25, 1.0, 1.0, 0.16665517820967043, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17610491295831474, 0.17610491295831462, 0.4012205994129363], 
reward next is 0.5988, 
noisyNet noise sample is [array([0.22412701], dtype=float32), -0.294354]. 
=============================================
[2019-03-23 20:21:01,012] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133000, global step 2113709: loss 0.4067
[2019-03-23 20:21:01,013] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133000, global step 2113709: learning rate 0.0000
[2019-03-23 20:21:01,013] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0615058e-02 1.2337842e-06 9.8808426e-01 3.7387956e-05 1.2620777e-03], sum to 1.0000
[2019-03-23 20:21:01,022] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8518
[2019-03-23 20:21:01,024] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.15, 66.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 266230.7744710351, 266230.7744710353, 104327.5248728629], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7770600.0000, 
sim time next is 7771200.0000, 
raw observation next is [16.96666666666667, 67.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 262349.0840993041, 262349.0840993044, 103485.7350402358], 
processed observation next is [1.0, 0.9565217391304348, 0.40757575757575765, 0.6766666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09716632744418671, 0.09716632744418681, 0.2524042318054532], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2474508], dtype=float32), 0.06434745]. 
=============================================
[2019-03-23 20:21:01,801] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:21:01,802] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:21:01,838] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run11
[2019-03-23 20:21:03,692] A3C_AGENT_WORKER-Thread-17 INFO:Local step 132500, global step 2115132: loss 21.8327
[2019-03-23 20:21:03,694] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 132500, global step 2115134: learning rate 0.0000
[2019-03-23 20:21:07,769] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:21:07,771] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:21:07,833] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run11
[2019-03-23 20:21:08,662] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.8661694e-03 2.3862235e-08 8.4508032e-02 9.2217255e-05 9.1253358e-01], sum to 1.0000
[2019-03-23 20:21:08,677] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5367
[2019-03-23 20:21:08,682] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [14.86666666666667, 90.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 273975.3839539838, 273975.3839539838, 129678.3222124394], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7801800.0000, 
sim time next is 7802400.0000, 
raw observation next is [15.33333333333333, 87.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 275939.6054942867, 275939.605494287, 131219.8558479841], 
processed observation next is [1.0, 0.30434782608695654, 0.3333333333333332, 0.87, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.10219985388677284, 0.10219985388677295, 0.32004842889752216], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.20759316], dtype=float32), 1.9287044]. 
=============================================
[2019-03-23 20:21:09,607] A3C_AGENT_WORKER-Thread-16 INFO:Local step 132500, global step 2118271: loss 24.7337
[2019-03-23 20:21:09,616] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 132500, global step 2118272: learning rate 0.0000
[2019-03-23 20:21:10,733] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:21:10,733] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:21:10,798] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run11
[2019-03-23 20:21:12,550] A3C_AGENT_WORKER-Thread-11 INFO:Local step 132500, global step 2119831: loss 7.3582
[2019-03-23 20:21:12,553] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 132500, global step 2119831: learning rate 0.0000
[2019-03-23 20:21:13,062] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:21:13,062] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:21:13,100] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run11
[2019-03-23 20:21:14,863] A3C_AGENT_WORKER-Thread-19 INFO:Local step 132500, global step 2121063: loss 4.1295
[2019-03-23 20:21:14,864] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 132500, global step 2121064: learning rate 0.0000
[2019-03-23 20:21:14,878] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.7558163e-03 1.3425086e-05 6.5191023e-02 4.4102888e-04 9.2759871e-01], sum to 1.0000
[2019-03-23 20:21:14,883] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0713
[2019-03-23 20:21:14,889] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.7, 92.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 501927.84219295, 501927.84219295, 199094.6829303138], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7936800.0000, 
sim time next is 7937400.0000, 
raw observation next is [20.6, 92.5, 1.0, 2.0, 0.2191648682832333, 0.0, 1.0, 0.0, 1.0, 2.0, 0.4394445969457143, 6.9112, 6.9112, 77.32846344354104, 499536.5809118227, 499536.5809118227, 168298.7592315662], 
processed observation next is [1.0, 0.8695652173913043, 0.5727272727272728, 0.925, 1.0, 1.0, 0.023956085354041624, 0.0, 0.5, -0.25, 1.0, 1.0, 0.19920656706530618, 0.0, 0.0, 0.5084288129206541, 0.18501354848586024, 0.18501354848586024, 0.4104847786135761], 
reward next is 0.5895, 
noisyNet noise sample is [array([-0.37091607], dtype=float32), -0.4763657]. 
=============================================
[2019-03-23 20:21:15,166] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133500, global step 2121221: loss 0.1148
[2019-03-23 20:21:15,169] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133500, global step 2121222: learning rate 0.0000
[2019-03-23 20:21:15,515] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:21:15,515] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:21:15,560] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run11
[2019-03-23 20:21:16,104] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:21:16,105] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:21:16,140] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run11
[2019-03-23 20:21:16,418] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:21:16,419] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:21:16,434] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run11
[2019-03-23 20:21:16,484] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:21:16,485] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:21:16,517] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run11
[2019-03-23 20:21:16,637] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:21:16,638] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:21:16,647] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run11
[2019-03-23 20:21:16,754] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:21:16,754] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:21:16,756] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133000, global step 2121954: loss -1.6899
[2019-03-23 20:21:16,758] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133000, global step 2121956: learning rate 0.0000
[2019-03-23 20:21:16,770] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run11
[2019-03-23 20:21:17,035] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:21:17,035] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:21:17,042] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:21:17,042] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:21:17,049] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run11
[2019-03-23 20:21:17,071] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:21:17,073] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:21:17,073] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:21:17,074] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:21:17,085] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run11
[2019-03-23 20:21:17,125] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:21:17,146] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:21:17,148] A3C_AGENT_WORKER-Thread-15 INFO:Local step 132500, global step 2122070: loss 0.9518
[2019-03-23 20:21:17,150] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run11
[2019-03-23 20:21:17,150] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run11
[2019-03-23 20:21:17,187] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 132500, global step 2122074: learning rate 0.0000
[2019-03-23 20:21:17,238] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run11
[2019-03-23 20:21:18,276] A3C_AGENT_WORKER-Thread-2 INFO:Local step 132500, global step 2122307: loss 1.9138
[2019-03-23 20:21:18,277] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 132500, global step 2122307: learning rate 0.0000
[2019-03-23 20:21:18,307] A3C_AGENT_WORKER-Thread-18 INFO:Local step 132500, global step 2122321: loss 0.4434
[2019-03-23 20:21:18,312] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 132500, global step 2122323: learning rate 0.0000
[2019-03-23 20:21:18,420] A3C_AGENT_WORKER-Thread-12 INFO:Local step 132500, global step 2122380: loss 0.6680
[2019-03-23 20:21:18,422] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 132500, global step 2122380: learning rate 0.0000
[2019-03-23 20:21:18,538] A3C_AGENT_WORKER-Thread-9 INFO:Local step 132500, global step 2122435: loss 0.6018
[2019-03-23 20:21:18,541] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 132500, global step 2122437: learning rate 0.0000
[2019-03-23 20:21:18,717] A3C_AGENT_WORKER-Thread-21 INFO:Local step 132500, global step 2122533: loss 1.5552
[2019-03-23 20:21:18,719] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 132500, global step 2122534: learning rate 0.0000
[2019-03-23 20:21:18,971] A3C_AGENT_WORKER-Thread-14 INFO:Local step 132500, global step 2122683: loss 10.9178
[2019-03-23 20:21:18,973] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 132500, global step 2122683: learning rate 0.0000
[2019-03-23 20:21:19,061] A3C_AGENT_WORKER-Thread-13 INFO:Local step 132500, global step 2122729: loss 1.1769
[2019-03-23 20:21:19,064] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 132500, global step 2122730: learning rate 0.0000
[2019-03-23 20:21:19,115] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.1644944e-03 2.4463508e-05 6.5847501e-02 1.8401438e-03 9.2612338e-01], sum to 1.0000
[2019-03-23 20:21:19,129] A3C_AGENT_WORKER-Thread-10 INFO:Local step 132500, global step 2122773: loss 0.5426
[2019-03-23 20:21:19,132] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1404
[2019-03-23 20:21:19,132] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 132500, global step 2122773: learning rate 0.0000
[2019-03-23 20:21:19,137] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [17.5, 97.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 391346.9939153584, 391346.9939153584, 173757.0405413012], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 19800.0000, 
sim time next is 20400.0000, 
raw observation next is [17.33333333333333, 98.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 389291.3479593839, 389291.3479593839, 173288.2239582014], 
processed observation next is [1.0, 0.21739130434782608, 0.42424242424242403, 0.98, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5085185399722538, 0.14418198072569774, 0.14418198072569774, 0.42265420477610094], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1828661], dtype=float32), -0.18414094]. 
=============================================
[2019-03-23 20:21:19,165] A3C_AGENT_WORKER-Thread-3 INFO:Local step 132500, global step 2122791: loss 0.7512
[2019-03-23 20:21:19,167] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 132500, global step 2122791: learning rate 0.0000
[2019-03-23 20:21:19,198] A3C_AGENT_WORKER-Thread-20 INFO:Local step 132500, global step 2122808: loss 0.3871
[2019-03-23 20:21:19,203] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 132500, global step 2122809: learning rate 0.0000
[2019-03-23 20:21:21,427] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.91104685e-02 1.89150363e-04 1.19626455e-01 3.90202296e-03
 8.27171862e-01], sum to 1.0000
[2019-03-23 20:21:21,430] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6440
[2019-03-23 20:21:21,439] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.2, 0.0, 1.0, 0.0, 1.0, 2.0, 0.3032012529050468, 6.911199999999999, 6.9112, 77.32846344354104, 351952.2260088047, 351952.226008805, 144732.8859966507], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 75600.0000, 
sim time next is 76200.0000, 
raw observation next is [18.5, 73.66666666666667, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 341503.8238366607, 341503.8238366609, 162397.4713319154], 
processed observation next is [1.0, 0.9130434782608695, 0.4772727272727273, 0.7366666666666667, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.12648289771728174, 0.1264828977172818, 0.39609139349247663], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.121727], dtype=float32), 1.0980413]. 
=============================================
[2019-03-23 20:21:21,872] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.0898141e-02 3.3000528e-04 8.4312961e-02 4.9349847e-03 8.8952392e-01], sum to 1.0000
[2019-03-23 20:21:21,882] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1959
[2019-03-23 20:21:21,888] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [16.0, 77.0, 1.0, 2.0, 0.2, 0.0, 1.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 255223.3665631418, 255223.3665631415, 102044.0955288034], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 84000.0000, 
sim time next is 84600.0000, 
raw observation next is [16.0, 77.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 254160.507253334, 254160.5072533342, 125240.5783444638], 
processed observation next is [1.0, 1.0, 0.36363636363636365, 0.77, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.09413352120493852, 0.09413352120493859, 0.3054648252303995], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.4278977], dtype=float32), 0.5743087]. 
=============================================
[2019-03-23 20:21:22,712] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133000, global step 2124658: loss 1.0139
[2019-03-23 20:21:22,716] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133000, global step 2124658: learning rate 0.0000
[2019-03-23 20:21:23,379] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 20:21:23,380] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:21:23,381] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:21:23,383] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:21:23,383] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:21:23,384] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:21:23,385] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:21:23,386] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:21:23,387] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:21:23,387] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:21:23,387] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:21:23,408] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run86
[2019-03-23 20:21:23,435] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run86
[2019-03-23 20:21:23,436] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run86
[2019-03-23 20:21:23,485] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run86
[2019-03-23 20:21:23,510] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run86
[2019-03-23 20:21:26,382] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00319553], dtype=float32), 0.0154328905]
[2019-03-23 20:21:26,383] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.702382925, 36.61455458333333, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 302777.0456930145, 302777.0456930145, 130645.7628084541]
[2019-03-23 20:21:26,384] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:21:26,386] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0795790e-02 2.9349421e-05 8.5262708e-02 6.4801297e-04 9.0326416e-01], sampled 0.6889001588918873
[2019-03-23 20:21:34,583] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00319553], dtype=float32), 0.0154328905]
[2019-03-23 20:21:34,584] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.5, 76.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3105586416539712, 6.911199999999999, 6.9112, 77.3421103, 526309.72670091, 526309.7267009104, 204311.4336676098]
[2019-03-23 20:21:34,584] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:21:34,587] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.5855475e-03 6.3815019e-06 4.3770317e-02 2.9744432e-04 9.5034027e-01], sampled 0.6030326039881452
[2019-03-23 20:21:44,258] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00319553], dtype=float32), 0.0154328905]
[2019-03-23 20:21:44,259] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [8.960463656, 85.55981188166666, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 410742.0308768894, 410742.0308768894, 143462.8939868513]
[2019-03-23 20:21:44,260] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:21:44,262] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.1788691e-03 2.9938821e-05 2.9745912e-02 9.8528038e-04 9.6205997e-01], sampled 0.9322759840444789
[2019-03-23 20:22:21,828] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00319553], dtype=float32), 0.0154328905]
[2019-03-23 20:22:21,828] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.48685846833333, 90.36151727499998, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 308677.1367454982, 308677.1367454982, 147245.8405716786]
[2019-03-23 20:22:21,830] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:22:21,835] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.3226426e-03 9.5253690e-06 3.4623548e-02 4.0024729e-04 9.5964402e-01], sampled 0.4028214675205678
[2019-03-23 20:22:30,766] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00319553], dtype=float32), 0.0154328905]
[2019-03-23 20:22:30,770] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [29.03333333333333, 53.66666666666666, 1.0, 2.0, 0.357112657556194, 1.0, 2.0, 0.357112657556194, 1.0, 2.0, 0.7224440148739762, 6.9112, 6.9112, 77.3421103, 1209739.2591666, 1209739.2591666, 285605.6479401349]
[2019-03-23 20:22:30,771] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:22:30,775] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.1455206e-03 4.2045238e-07 1.3168857e-03 1.0434987e-04 9.9743289e-01], sampled 0.2571225863723394
[2019-03-23 20:22:31,319] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00319553], dtype=float32), 0.0154328905]
[2019-03-23 20:22:31,320] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.8, 70.66666666666667, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 502578.2679598016, 502578.2679598019, 199478.5523990424]
[2019-03-23 20:22:31,322] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:22:31,327] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.4239207e-03 1.8242135e-05 6.0403667e-02 5.3585926e-04 9.3061829e-01], sampled 0.2703536620399356
[2019-03-23 20:22:52,234] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00319553], dtype=float32), 0.0154328905]
[2019-03-23 20:22:52,235] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.76322651666667, 93.32092718999999, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 381720.0213745511, 381720.0213745511, 176921.0670607369]
[2019-03-23 20:22:52,236] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:22:52,240] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.9775299e-03 7.1357540e-06 2.9825455e-02 3.6339802e-04 9.6482652e-01], sampled 0.8357477841131448
[2019-03-23 20:23:06,555] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 1014.5909 2498677575.0511 15.0000
[2019-03-23 20:23:06,923] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 758.4008 2443797806.4584 38.0000
[2019-03-23 20:23:07,054] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 635.4839 2434131660.6794 40.0000
[2019-03-23 20:23:07,141] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 680.7652 2442293078.6566 17.0000
[2019-03-23 20:23:07,155] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 578.1134 2445261780.2849 38.0000
[2019-03-23 20:23:08,169] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 2125000, evaluation results [2125000.0, 1014.5908731943401, 2498677575.0510554, 15.0, 635.4838743509221, 2434131660.679419, 40.0, 578.1134255092534, 2445261780.284937, 38.0, 758.4007585180092, 2443797806.458376, 38.0, 680.7652288548832, 2442293078.656643, 17.0]
[2019-03-23 20:23:11,348] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133000, global step 2126594: loss -0.1940
[2019-03-23 20:23:11,350] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133000, global step 2126594: learning rate 0.0000
[2019-03-23 20:23:14,000] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133000, global step 2127917: loss 0.0002
[2019-03-23 20:23:14,002] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133000, global step 2127917: learning rate 0.0000
[2019-03-23 20:23:14,027] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134000, global step 2127929: loss 0.1772
[2019-03-23 20:23:14,030] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134000, global step 2127930: learning rate 0.0000
[2019-03-23 20:23:17,103] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133500, global step 2129456: loss 0.0714
[2019-03-23 20:23:17,109] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133500, global step 2129457: learning rate 0.0000
[2019-03-23 20:23:17,613] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133000, global step 2129704: loss 0.0069
[2019-03-23 20:23:17,614] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133000, global step 2129704: learning rate 0.0000
[2019-03-23 20:23:18,667] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133000, global step 2130234: loss 0.1589
[2019-03-23 20:23:18,669] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133000, global step 2130234: learning rate 0.0000
[2019-03-23 20:23:18,672] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133000, global step 2130235: loss 0.0222
[2019-03-23 20:23:18,675] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133000, global step 2130237: learning rate 0.0000
[2019-03-23 20:23:18,832] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133000, global step 2130316: loss 0.0124
[2019-03-23 20:23:18,833] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133000, global step 2130316: learning rate 0.0000
[2019-03-23 20:23:19,175] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133000, global step 2130487: loss 0.9446
[2019-03-23 20:23:19,176] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133000, global step 2130487: learning rate 0.0000
[2019-03-23 20:23:19,221] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133000, global step 2130511: loss 0.0038
[2019-03-23 20:23:19,223] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133000, global step 2130512: learning rate 0.0000
[2019-03-23 20:23:19,402] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133000, global step 2130600: loss -0.0012
[2019-03-23 20:23:19,405] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133000, global step 2130602: learning rate 0.0000
[2019-03-23 20:23:19,590] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133000, global step 2130696: loss 0.2409
[2019-03-23 20:23:19,591] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133000, global step 2130696: learning rate 0.0000
[2019-03-23 20:23:19,753] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133000, global step 2130776: loss 0.0393
[2019-03-23 20:23:19,755] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133000, global step 2130776: learning rate 0.0000
[2019-03-23 20:23:19,872] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133000, global step 2130830: loss -1.5546
[2019-03-23 20:23:19,875] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133000, global step 2130830: learning rate 0.0000
[2019-03-23 20:23:20,070] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133000, global step 2130933: loss -0.0045
[2019-03-23 20:23:20,078] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133000, global step 2130934: learning rate 0.0000
[2019-03-23 20:23:21,365] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.0897385e-02 6.0223130e-04 2.6053816e-02 4.5240312e-03 8.9792258e-01], sum to 1.0000
[2019-03-23 20:23:21,373] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9635
[2019-03-23 20:23:21,378] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [19.66666666666667, 79.66666666666666, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 391583.5227854929, 391583.5227854932, 174116.2703696346], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 690000.0000, 
sim time next is 690600.0000, 
raw observation next is [19.33333333333333, 81.33333333333334, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 387445.3759725403, 387445.3759725403, 173199.1293522853], 
processed observation next is [1.0, 1.0, 0.5151515151515149, 0.8133333333333335, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5085185399722538, 0.14349828739723713, 0.14349828739723713, 0.4224369008592324], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.64426196], dtype=float32), 0.42882416]. 
=============================================
[2019-03-23 20:23:22,420] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.7878797e-02 2.0587457e-04 1.2677700e-02 2.9000288e-03 9.6633762e-01], sum to 1.0000
[2019-03-23 20:23:22,428] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7022
[2019-03-23 20:23:22,434] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [12.66666666666667, 70.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 436658.3104905861, 436658.3104905864, 144902.3857907026], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 354000.0000, 
sim time next is 354600.0000, 
raw observation next is [12.5, 71.5, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 438946.5037168881, 438946.5037168881, 145417.8070026037], 
processed observation next is [1.0, 0.08695652173913043, 0.20454545454545456, 0.715, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5085185399722538, 0.162572779154403, 0.162572779154403, 0.35467757805513095], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.35593984], dtype=float32), 0.9475099]. 
=============================================
[2019-03-23 20:23:23,354] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133500, global step 2132551: loss -1.5156
[2019-03-23 20:23:23,356] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133500, global step 2132551: learning rate 0.0000
[2019-03-23 20:23:27,087] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.0278383e-02 2.7592716e-04 1.4042317e-02 4.5002140e-03 9.4090319e-01], sum to 1.0000
[2019-03-23 20:23:27,097] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3217
[2019-03-23 20:23:27,106] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [16.33333333333334, 88.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 460582.244230064, 460582.2442300643, 178840.4490828059], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 552000.0000, 
sim time next is 552600.0000, 
raw observation next is [16.5, 88.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 466911.0153634992, 466911.0153634995, 179854.6786312033], 
processed observation next is [1.0, 0.391304347826087, 0.38636363636363635, 0.88, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.17293000569018488, 0.17293000569018502, 0.4386699478809837], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1396836], dtype=float32), -0.34341288]. 
=============================================
[2019-03-23 20:23:27,415] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133500, global step 2134582: loss 2.0123
[2019-03-23 20:23:27,418] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133500, global step 2134583: learning rate 0.0000
[2019-03-23 20:23:28,930] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.1080877e-02 5.2994164e-04 1.6726810e-01 5.9645940e-03 7.6515651e-01], sum to 1.0000
[2019-03-23 20:23:28,938] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5493
[2019-03-23 20:23:28,942] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.66666666666667, 71.33333333333334, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3504528890587808, 6.911199999999999, 6.9112, 77.3421103, 588899.186306433, 588899.1863064333, 216832.2527729677], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1192800.0000, 
sim time next is 1193400.0000, 
raw observation next is [25.5, 72.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3496876672498166, 6.911199999999999, 6.9112, 77.3421103, 587803.4753366625, 587803.4753366627, 216514.1820824789], 
processed observation next is [1.0, 0.8260869565217391, 0.7954545454545454, 0.72, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0709823817854523, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.21770499086543055, 0.21770499086543063, 0.5280833709328754], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.50030196], dtype=float32), 0.48821792]. 
=============================================
[2019-03-23 20:23:29,963] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134500, global step 2135851: loss -0.0640
[2019-03-23 20:23:29,965] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134500, global step 2135852: learning rate 0.0000
[2019-03-23 20:23:30,264] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133500, global step 2136004: loss 3.2215
[2019-03-23 20:23:30,266] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133500, global step 2136005: learning rate 0.0000
[2019-03-23 20:23:33,214] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134000, global step 2137448: loss 7.2992
[2019-03-23 20:23:33,216] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134000, global step 2137448: learning rate 0.0000
[2019-03-23 20:23:33,890] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133500, global step 2137764: loss -0.4971
[2019-03-23 20:23:33,892] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133500, global step 2137764: learning rate 0.0000
[2019-03-23 20:23:34,669] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133500, global step 2138172: loss -3.4238
[2019-03-23 20:23:34,670] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133500, global step 2138172: learning rate 0.0000
[2019-03-23 20:23:34,908] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133500, global step 2138303: loss -0.7598
[2019-03-23 20:23:34,910] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133500, global step 2138303: learning rate 0.0000
[2019-03-23 20:23:34,921] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133500, global step 2138311: loss -1.0951
[2019-03-23 20:23:34,924] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133500, global step 2138311: learning rate 0.0000
[2019-03-23 20:23:35,207] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133500, global step 2138457: loss 1.2601
[2019-03-23 20:23:35,209] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133500, global step 2138457: learning rate 0.0000
[2019-03-23 20:23:35,248] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.64855754e-01 2.52659927e-04 1.01292424e-01 5.67395939e-03
 3.27925235e-01], sum to 1.0000
[2019-03-23 20:23:35,259] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4652
[2019-03-23 20:23:35,268] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.16666666666667, 93.0, 1.0, 1.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 271102.5555380441, 271102.5555380441, 141800.2585057719], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 618600.0000, 
sim time next is 619200.0000, 
raw observation next is [15.0, 94.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.4623391756460847, 6.911199999999999, 6.9112, 77.32846344354104, 268913.5698256282, 268913.5698256285, 74859.87265397077], 
processed observation next is [1.0, 0.17391304347826086, 0.3181818181818182, 0.94, 0.0, 0.5, -0.25, 0.0, 0.5, -0.25, 1.0, 1.0, 0.2319131080658353, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09959761845393637, 0.09959761845393647, 0.18258505525358726], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.4955292], dtype=float32), -1.5254707]. 
=============================================
[2019-03-23 20:23:35,304] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133500, global step 2138505: loss 0.3156
[2019-03-23 20:23:35,305] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133500, global step 2138506: learning rate 0.0000
[2019-03-23 20:23:35,376] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133500, global step 2138547: loss 0.2814
[2019-03-23 20:23:35,378] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133500, global step 2138547: learning rate 0.0000
[2019-03-23 20:23:35,775] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133500, global step 2138755: loss -0.3225
[2019-03-23 20:23:35,777] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133500, global step 2138755: learning rate 0.0000
[2019-03-23 20:23:35,802] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133500, global step 2138770: loss 0.4904
[2019-03-23 20:23:35,804] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133500, global step 2138771: learning rate 0.0000
[2019-03-23 20:23:35,911] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133500, global step 2138823: loss -0.5880
[2019-03-23 20:23:35,912] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133500, global step 2138823: learning rate 0.0000
[2019-03-23 20:23:36,109] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133500, global step 2138932: loss -1.2390
[2019-03-23 20:23:36,110] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133500, global step 2138932: learning rate 0.0000
[2019-03-23 20:23:38,012] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.3431230e-01 6.4923256e-07 1.9636180e-03 1.3140662e-04 2.6359200e-01], sum to 1.0000
[2019-03-23 20:23:38,018] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5956
[2019-03-23 20:23:38,025] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1003633.942707959 W.
[2019-03-23 20:23:38,029] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 50.5, 1.0, 2.0, 0.8851555214374931, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1003633.942707959, 1003633.942707959, 187575.6975465562], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 663000.0000, 
sim time next is 663600.0000, 
raw observation next is [26.0, 50.00000000000001, 1.0, 2.0, 0.4394966325003477, 1.0, 1.0, 0.4394966325003477, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1000944.401962832, 1000944.401962832, 207165.1364312239], 
processed observation next is [1.0, 0.6956521739130435, 0.8181818181818182, 0.5000000000000001, 1.0, 1.0, 0.2993707906254346, 1.0, 0.5, 0.2993707906254346, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.37072014887512295, 0.37072014887512295, 0.5052808205639607], 
reward next is 0.4947, 
noisyNet noise sample is [array([-0.44662842], dtype=float32), 0.5994808]. 
=============================================
[2019-03-23 20:23:39,428] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134000, global step 2140660: loss 81.6348
[2019-03-23 20:23:39,430] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134000, global step 2140662: learning rate 0.0000
[2019-03-23 20:23:39,585] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.1056273e-01 2.7273362e-08 2.0649971e-03 1.4875033e-05 1.8735737e-01], sum to 1.0000
[2019-03-23 20:23:39,596] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1185
[2019-03-23 20:23:39,602] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 861376.0689024541 W.
[2019-03-23 20:23:39,607] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 69.0, 1.0, 2.0, 0.7566915649291951, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 861376.0689024541, 861376.0689024538, 170991.8459559737], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 724800.0000, 
sim time next is 725400.0000, 
raw observation next is [23.5, 69.0, 1.0, 2.0, 0.749286976773591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 852538.5878746429, 852538.5878746429, 169542.3947644994], 
processed observation next is [1.0, 0.391304347826087, 0.7045454545454546, 0.69, 1.0, 1.0, 0.6866087209669888, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.31575503254616405, 0.31575503254616405, 0.41351803601097414], 
reward next is 0.5865, 
noisyNet noise sample is [array([-0.7615439], dtype=float32), -1.8682979]. 
=============================================
[2019-03-23 20:23:41,635] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.3415891e-01 6.6934152e-09 1.9593153e-03 4.6143186e-06 3.6387724e-01], sum to 1.0000
[2019-03-23 20:23:41,641] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6806
[2019-03-23 20:23:41,651] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.66666666666666, 56.0, 1.0, 2.0, 0.7969621453697432, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846338445904, 908976.9845656077, 908976.9845656075, 183747.3406406624], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 736800.0000, 
sim time next is 737400.0000, 
raw observation next is [27.83333333333334, 55.5, 1.0, 2.0, 0.2563843005372528, 1.0, 1.0, 0.2563843005372528, 1.0, 1.0, 0.519293710973026, 6.9112, 6.9112, 77.3421103, 875121.9956930858, 875121.9956930858, 244161.8463360924], 
processed observation next is [1.0, 0.5217391304347826, 0.9015151515151518, 0.555, 1.0, 1.0, 0.070480375671566, 1.0, 0.5, 0.070480375671566, 1.0, 0.5, 0.31327672996146577, 0.0, 0.0, 0.5085185399722538, 0.3241192576641059, 0.3241192576641059, 0.5955166983807132], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.55570155], dtype=float32), -0.7140925]. 
=============================================
[2019-03-23 20:23:43,478] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134000, global step 2142773: loss -92.2974
[2019-03-23 20:23:43,479] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134000, global step 2142773: learning rate 0.0000
[2019-03-23 20:23:44,624] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.9897313e-01 5.3327927e-14 1.0219536e-03 6.3952857e-11 4.8781726e-06], sum to 1.0000
[2019-03-23 20:23:44,631] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4773
[2019-03-23 20:23:44,636] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.0, 94.00000000000001, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7364963289002249, 7.081937149131742, 6.9112, 77.32800847480047, 478065.9834653842, 422614.3758622894, 130458.2753722997], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 796200.0000, 
sim time next is 796800.0000, 
raw observation next is [19.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7442667543399946, 7.151291970181157, 6.9112, 77.32773644068516, 505410.1705347365, 427433.9424496244, 131066.282411539], 
processed observation next is [0.0, 0.21739130434782608, 0.5, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.634666791914278, 0.024009197018115724, 0.0, 0.5084240329317271, 0.1871889520499024, 0.15830886757393497, 0.319673859540339], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3854107], dtype=float32), -0.42288214]. 
=============================================
[2019-03-23 20:23:45,928] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135000, global step 2144044: loss 22.4971
[2019-03-23 20:23:45,932] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135000, global step 2144044: learning rate 0.0000
[2019-03-23 20:23:45,950] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134000, global step 2144058: loss -69.8673
[2019-03-23 20:23:45,956] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134000, global step 2144058: learning rate 0.0000
[2019-03-23 20:23:48,336] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134500, global step 2145289: loss -91.1525
[2019-03-23 20:23:48,338] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134500, global step 2145290: learning rate 0.0000
[2019-03-23 20:23:49,319] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134000, global step 2145800: loss 10.6514
[2019-03-23 20:23:49,321] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134000, global step 2145800: learning rate 0.0000
[2019-03-23 20:23:49,536] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.7195865e-01 2.9604769e-05 5.2117523e-02 3.6286068e-04 1.7553142e-01], sum to 1.0000
[2019-03-23 20:23:49,549] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7953
[2019-03-23 20:23:49,553] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.16666666666667, 94.00000000000001, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7970703087144068, 7.505950246222959, 6.9112, 77.32705880854344, 645238.0853101427, 452078.8787926134, 141296.8349419105], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1235400.0000, 
sim time next is 1236000.0000, 
raw observation next is [21.33333333333334, 94.0, 1.0, 1.0, 0.268032360048273, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5406954325709433, 6.9112, 6.9112, 77.32810605178445, 611734.7731397835, 611734.7731397835, 181436.4327079578], 
processed observation next is [1.0, 0.30434782608695654, 0.6060606060606063, 0.94, 1.0, 0.5, 0.08504045006034126, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3438506179584905, 0.0, 0.0, 0.5084264630968187, 0.2265684344962161, 0.2265684344962161, 0.44252788465355564], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7017984], dtype=float32), -0.12692358]. 
=============================================
[2019-03-23 20:23:49,570] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[10.356814 ]
 [11.321035 ]
 [10.654484 ]
 [11.4416275]
 [10.634243 ]], R is [[10.69843674]
 [10.5914526 ]
 [10.48553848]
 [10.38068295]
 [10.27687645]].
[2019-03-23 20:23:49,959] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134000, global step 2146138: loss -6.5282
[2019-03-23 20:23:49,959] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134000, global step 2146138: learning rate 0.0000
[2019-03-23 20:23:50,326] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134000, global step 2146332: loss -33.2343
[2019-03-23 20:23:50,327] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134000, global step 2146332: learning rate 0.0000
[2019-03-23 20:23:50,465] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134000, global step 2146402: loss 10.2824
[2019-03-23 20:23:50,467] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134000, global step 2146402: learning rate 0.0000
[2019-03-23 20:23:50,579] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134000, global step 2146456: loss 6.7400
[2019-03-23 20:23:50,583] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134000, global step 2146456: learning rate 0.0000
[2019-03-23 20:23:50,679] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134000, global step 2146513: loss 5.8435
[2019-03-23 20:23:50,681] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134000, global step 2146513: learning rate 0.0000
[2019-03-23 20:23:50,857] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134000, global step 2146606: loss 36.7038
[2019-03-23 20:23:50,858] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134000, global step 2146606: learning rate 0.0000
[2019-03-23 20:23:51,011] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134000, global step 2146688: loss -17.1893
[2019-03-23 20:23:51,012] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134000, global step 2146688: learning rate 0.0000
[2019-03-23 20:23:51,132] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134000, global step 2146748: loss 0.0705
[2019-03-23 20:23:51,134] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134000, global step 2146750: learning rate 0.0000
[2019-03-23 20:23:51,222] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134000, global step 2146795: loss -17.1964
[2019-03-23 20:23:51,223] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134000, global step 2146795: learning rate 0.0000
[2019-03-23 20:23:51,245] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134000, global step 2146805: loss -22.1203
[2019-03-23 20:23:51,247] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134000, global step 2146806: learning rate 0.0000
[2019-03-23 20:23:52,372] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.3411012e-01 4.1610515e-06 2.9888174e-02 2.1486037e-04 2.3578270e-01], sum to 1.0000
[2019-03-23 20:23:52,377] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3464
[2019-03-23 20:23:52,386] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 726028.0444952834 W.
[2019-03-23 20:23:52,390] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.66666666666666, 69.66666666666667, 1.0, 2.0, 0.3186412660359114, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6450525287864042, 6.911200000000001, 6.9112, 77.32846344277988, 726028.0444952834, 726028.044495283, 197827.3230214336], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1168800.0000, 
sim time next is 1169400.0000, 
raw observation next is [25.83333333333334, 69.83333333333333, 1.0, 2.0, 0.2105652015020618, 1.0, 1.0, 0.2105652015020618, 1.0, 2.0, 0.4265396955039693, 6.911199999999999, 6.9112, 77.3421103, 717321.7537712075, 717321.7537712078, 231925.9568308724], 
processed observation next is [1.0, 0.5217391304347826, 0.8106060606060609, 0.6983333333333333, 1.0, 1.0, 0.013206501877577222, 1.0, 0.5, 0.013206501877577222, 1.0, 1.0, 0.18077099357709903, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.26567472361896577, 0.2656747236189658, 0.5656730654411521], 
reward next is 0.4343, 
noisyNet noise sample is [array([-1.4508932], dtype=float32), 1.5249348]. 
=============================================
[2019-03-23 20:23:53,255] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.3528811e-01 1.3395882e-07 1.6210262e-01 6.3058269e-06 2.6027334e-03], sum to 1.0000
[2019-03-23 20:23:53,263] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5459
[2019-03-23 20:23:53,273] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.0, 94.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7393470131008653, 7.098232873873702, 6.9112, 77.3279653914789, 484490.8249203627, 423746.7642088701, 131139.0181848615], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 954000.0000, 
sim time next is 954600.0000, 
raw observation next is [19.0, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7473166754174884, 7.172554005737179, 6.9112, 77.32767622590893, 513793.0172529434, 428911.4459217897, 131608.7130829591], 
processed observation next is [1.0, 0.043478260869565216, 0.5, 0.95, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6390238220249834, 0.02613540057371786, 0.0, 0.5084236370241164, 0.19029371009368276, 0.15885609108214432, 0.320996861177949], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.30948755], dtype=float32), -0.74944276]. 
=============================================
[2019-03-23 20:23:54,625] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134500, global step 2148580: loss -1.9759
[2019-03-23 20:23:54,626] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134500, global step 2148580: learning rate 0.0000
[2019-03-23 20:23:56,471] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.7716242e-01 4.5320020e-10 2.1544106e-02 1.1077414e-07 1.2933420e-03], sum to 1.0000
[2019-03-23 20:23:56,476] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5645
[2019-03-23 20:23:56,481] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 553820.3119622133 W.
[2019-03-23 20:23:56,488] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [13.0, 94.0, 1.0, 1.0, 0.2549566346034385, 1.0, 1.0, 0.2549566346034385, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.3281899894954, 553820.3119622133, 553820.3119622133, 145344.2824536457], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1056600.0000, 
sim time next is 1057200.0000, 
raw observation next is [13.0, 94.0, 1.0, 2.0, 0.2223028694189073, 1.0, 2.0, 0.2223028694189073, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846175081312, 482854.1246429014, 482854.1246429014, 132651.8420288365], 
processed observation next is [1.0, 0.21739130434782608, 0.22727272727272727, 0.94, 1.0, 1.0, 0.027878586773634126, 1.0, 1.0, 0.027878586773634126, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288017910957, 0.17883486097885237, 0.17883486097885237, 0.32354107811911337], 
reward next is 0.6765, 
noisyNet noise sample is [array([-0.8226887], dtype=float32), -0.48886514]. 
=============================================
[2019-03-23 20:23:57,337] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 20:23:57,338] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:23:57,339] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:23:57,340] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:23:57,343] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:23:57,346] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:23:57,347] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:23:57,347] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:23:57,348] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:23:57,346] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:23:57,348] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:23:57,369] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run87
[2019-03-23 20:23:57,394] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run87
[2019-03-23 20:23:57,419] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run87
[2019-03-23 20:23:57,446] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run87
[2019-03-23 20:23:57,474] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run87
[2019-03-23 20:24:52,129] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00241373], dtype=float32), 0.016277153]
[2019-03-23 20:24:52,130] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.131824915, 80.502883005, 1.0, 2.0, 0.4943091013338866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 563998.2283934937, 563998.2283934933, 144591.9634723945]
[2019-03-23 20:24:52,132] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:24:52,135] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.9342752e-01 4.3891770e-13 6.5555177e-03 6.3900019e-10 1.7079672e-05], sampled 0.1775614191072319
[2019-03-23 20:24:52,136] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 563998.2283934937 W.
[2019-03-23 20:25:10,216] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00241373], dtype=float32), 0.016277153]
[2019-03-23 20:25:10,218] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [12.63747798666667, 65.88829159666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 173925.3308743736, 173925.3308743736, 62277.48470878098]
[2019-03-23 20:25:10,219] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:25:10,222] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.9998796e-01 4.2161237e-27 1.2008308e-05 4.1313887e-21 1.6701178e-13], sampled 0.2676070181099147
[2019-03-23 20:25:10,268] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00241373], dtype=float32), 0.016277153]
[2019-03-23 20:25:10,269] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.76666666666667, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.335608872913764, 6.9112, 6.9112, 77.32846344354104, 195627.5671527833, 195627.5671527833, 59407.92374674703]
[2019-03-23 20:25:10,270] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:25:10,274] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.9998271e-01 2.4918677e-26 1.7236469e-05 1.5940428e-20 3.8828974e-13], sampled 0.8232046933634588
[2019-03-23 20:25:29,072] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00241373], dtype=float32), 0.016277153]
[2019-03-23 20:25:29,072] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.55, 88.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8281873798292138, 7.890737270126231, 6.9112, 77.32600718377157, 796941.528029463, 478817.9628859406, 138652.9252972325]
[2019-03-23 20:25:29,074] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:25:29,077] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.9973971e-01 6.0959734e-21 2.6030306e-04 2.6832291e-16 3.9513431e-10], sampled 0.5905448556004497
[2019-03-23 20:25:29,078] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 796941.528029463 W.
[2019-03-23 20:25:40,050] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6540.0303 1700598206.4686 2933.0000
[2019-03-23 20:25:40,244] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6271.1380 1687324188.6368 3214.0000
[2019-03-23 20:25:40,246] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6761.9834 1799593041.9901 2398.0000
[2019-03-23 20:25:40,363] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6444.8531 1681554520.4727 3057.0000
[2019-03-23 20:25:40,405] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6301.5632 1726259486.1742 3372.0000
[2019-03-23 20:25:41,424] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 2150000, evaluation results [2150000.0, 6761.983396747254, 1799593041.9900565, 2398.0, 6444.853061853167, 1681554520.4726741, 3057.0, 6271.137956445159, 1687324188.636763, 3214.0, 6301.563179844554, 1726259486.17425, 3372.0, 6540.030295093976, 1700598206.4685726, 2933.0]
[2019-03-23 20:25:42,960] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134500, global step 2150764: loss -16.1730
[2019-03-23 20:25:42,962] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134500, global step 2150765: learning rate 0.0000
[2019-03-23 20:25:45,446] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135500, global step 2152000: loss 0.7537
[2019-03-23 20:25:45,450] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135500, global step 2152001: learning rate 0.0000
[2019-03-23 20:25:45,490] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134500, global step 2152022: loss -157.2729
[2019-03-23 20:25:45,491] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134500, global step 2152022: learning rate 0.0000
[2019-03-23 20:25:48,911] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134500, global step 2153711: loss -94.8727
[2019-03-23 20:25:48,913] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134500, global step 2153711: learning rate 0.0000
[2019-03-23 20:25:48,990] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135000, global step 2153746: loss -19.1151
[2019-03-23 20:25:48,993] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135000, global step 2153747: learning rate 0.0000
[2019-03-23 20:25:49,859] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134500, global step 2154179: loss -123.1263
[2019-03-23 20:25:49,861] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134500, global step 2154179: learning rate 0.0000
[2019-03-23 20:25:50,171] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134500, global step 2154331: loss -51.5182
[2019-03-23 20:25:50,173] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134500, global step 2154331: learning rate 0.0000
[2019-03-23 20:25:50,304] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134500, global step 2154397: loss -21.9871
[2019-03-23 20:25:50,309] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134500, global step 2154398: learning rate 0.0000
[2019-03-23 20:25:50,329] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134500, global step 2154406: loss -146.2220
[2019-03-23 20:25:50,333] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134500, global step 2154407: learning rate 0.0000
[2019-03-23 20:25:50,384] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.6393383e-01 1.6535219e-08 2.2402195e-02 2.5335925e-05 1.3638600e-02], sum to 1.0000
[2019-03-23 20:25:50,392] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9034
[2019-03-23 20:25:50,400] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 589164.1731357528 W.
[2019-03-23 20:25:50,406] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.13333333333333, 88.33333333333334, 1.0, 2.0, 0.5175410671677652, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 589164.1731357528, 589164.1731357524, 145265.091561555], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1207200.0000, 
sim time next is 1207800.0000, 
raw observation next is [23.2, 88.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 1.0, 0.3506370780780121, 6.9112, 6.9112, 77.3421103, 589753.0338504035, 589753.0338504035, 216466.233903573], 
processed observation next is [1.0, 1.0, 0.6909090909090909, 0.88, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.5, 0.07233868296858871, 0.0, 0.0, 0.5085185399722538, 0.21842704957422351, 0.21842704957422351, 0.5279664241550561], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8767119], dtype=float32), 1.7571894]. 
=============================================
[2019-03-23 20:25:50,553] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134500, global step 2154514: loss -58.1546
[2019-03-23 20:25:50,555] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134500, global step 2154515: learning rate 0.0000
[2019-03-23 20:25:50,627] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134500, global step 2154556: loss -43.2037
[2019-03-23 20:25:50,631] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134500, global step 2154559: learning rate 0.0000
[2019-03-23 20:25:50,650] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134500, global step 2154567: loss -117.9317
[2019-03-23 20:25:50,651] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134500, global step 2154567: learning rate 0.0000
[2019-03-23 20:25:50,833] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134500, global step 2154651: loss -101.5196
[2019-03-23 20:25:50,836] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134500, global step 2154653: learning rate 0.0000
[2019-03-23 20:25:50,933] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134500, global step 2154707: loss -56.1869
[2019-03-23 20:25:50,935] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134500, global step 2154708: learning rate 0.0000
[2019-03-23 20:25:50,965] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134500, global step 2154721: loss 20.0138
[2019-03-23 20:25:50,967] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134500, global step 2154721: learning rate 0.0000
[2019-03-23 20:25:53,978] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.6966454e-01 1.2167440e-08 4.2669785e-01 3.8453302e-07 3.6372053e-03], sum to 1.0000
[2019-03-23 20:25:53,986] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4324
[2019-03-23 20:25:53,993] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 573593.0566203081 W.
[2019-03-23 20:25:54,002] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.83333333333333, 63.33333333333334, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3406535567617289, 6.9112, 6.9112, 77.3421103, 573593.0566203081, 573593.0566203081, 213727.5549852956], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1275000.0000, 
sim time next is 1275600.0000, 
raw observation next is [26.66666666666667, 64.66666666666667, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.344977721644939, 6.911199999999999, 6.9112, 77.3421103, 580322.6167142008, 580322.616714201, 215116.1665308624], 
processed observation next is [1.0, 0.782608695652174, 0.8484848484848487, 0.6466666666666667, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0642538880641986, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.21493430248674106, 0.21493430248674114, 0.5246735769045424], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9421362], dtype=float32), -0.23464717]. 
=============================================
[2019-03-23 20:25:55,294] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135000, global step 2156869: loss 23.3384
[2019-03-23 20:25:55,298] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135000, global step 2156869: learning rate 0.0000
[2019-03-23 20:25:57,833] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.8395431e-01 2.0029942e-08 1.2618520e-02 1.3912072e-06 3.4257607e-03], sum to 1.0000
[2019-03-23 20:25:57,840] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8924
[2019-03-23 20:25:57,846] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 678061.5553235636 W.
[2019-03-23 20:25:57,851] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.0, 88.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8095454388140687, 7.589204434116832, 6.9112, 77.32681913177115, 678061.5553235636, 457864.265084101, 143795.687558071], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1377000.0000, 
sim time next is 1377600.0000, 
raw observation next is [22.0, 88.0, 1.0, 1.0, 0.2661730469245522, 1.0, 1.0, 0.2661730469245522, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32805602324095, 606969.2524470607, 606969.2524470607, 181602.7791252344], 
processed observation next is [1.0, 0.9565217391304348, 0.6363636363636364, 0.88, 1.0, 0.5, 0.08271630865569021, 1.0, 0.5, 0.08271630865569021, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084261341629197, 0.2248034268322447, 0.2248034268322447, 0.44293360762252293], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2445649], dtype=float32), 0.067955926]. 
=============================================
[2019-03-23 20:25:58,128] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.7208362e-01 1.5456357e-07 1.8614173e-01 2.4982710e-05 1.4174956e-01], sum to 1.0000
[2019-03-23 20:25:58,139] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3469
[2019-03-23 20:25:58,150] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1276155.851406775 W.
[2019-03-23 20:25:58,152] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.0, 84.83333333333334, 1.0, 2.0, 0.5592581680728258, 1.0, 2.0, 0.5592581680728258, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1276155.851406775, 1276155.851406775, 242910.918256471], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1354200.0000, 
sim time next is 1354800.0000, 
raw observation next is [22.0, 86.66666666666667, 1.0, 2.0, 0.3417180297253555, 1.0, 2.0, 0.3417180297253555, 1.0, 1.0, 0.6918760708387794, 6.9112, 6.9112, 77.3421103, 1168074.993975969, 1168074.993975969, 273434.6119179527], 
processed observation next is [1.0, 0.6956521739130435, 0.6363636363636364, 0.8666666666666667, 1.0, 1.0, 0.17714753715669432, 1.0, 1.0, 0.17714753715669432, 1.0, 0.5, 0.5598229583411135, 0.0, 0.0, 0.5085185399722538, 0.4326203681392478, 0.4326203681392478, 0.6669136876047628], 
reward next is 0.3331, 
noisyNet noise sample is [array([-0.05342529], dtype=float32), -1.0600699]. 
=============================================
[2019-03-23 20:25:59,422] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135000, global step 2158910: loss 26.6831
[2019-03-23 20:25:59,426] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135000, global step 2158911: learning rate 0.0000
[2019-03-23 20:26:00,696] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136000, global step 2159539: loss 3.8744
[2019-03-23 20:26:00,699] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136000, global step 2159539: learning rate 0.0000
[2019-03-23 20:26:01,960] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135000, global step 2160147: loss 40.8923
[2019-03-23 20:26:01,964] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135000, global step 2160147: learning rate 0.0000
[2019-03-23 20:26:04,719] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135500, global step 2161518: loss 2.9713
[2019-03-23 20:26:04,720] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135500, global step 2161518: learning rate 0.0000
[2019-03-23 20:26:05,272] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135000, global step 2161796: loss -97.3711
[2019-03-23 20:26:05,274] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135000, global step 2161796: learning rate 0.0000
[2019-03-23 20:26:06,372] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135000, global step 2162330: loss 24.5880
[2019-03-23 20:26:06,374] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135000, global step 2162330: learning rate 0.0000
[2019-03-23 20:26:06,520] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135000, global step 2162404: loss -15.9438
[2019-03-23 20:26:06,523] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135000, global step 2162406: learning rate 0.0000
[2019-03-23 20:26:06,559] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135000, global step 2162422: loss 4.7332
[2019-03-23 20:26:06,561] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135000, global step 2162422: learning rate 0.0000
[2019-03-23 20:26:06,603] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135000, global step 2162441: loss -26.5450
[2019-03-23 20:26:06,606] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135000, global step 2162441: learning rate 0.0000
[2019-03-23 20:26:06,630] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135000, global step 2162452: loss -0.3935
[2019-03-23 20:26:06,631] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135000, global step 2162452: learning rate 0.0000
[2019-03-23 20:26:06,777] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135000, global step 2162530: loss -1.9714
[2019-03-23 20:26:06,779] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135000, global step 2162530: learning rate 0.0000
[2019-03-23 20:26:06,843] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135000, global step 2162567: loss 0.3657
[2019-03-23 20:26:06,845] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135000, global step 2162567: learning rate 0.0000
[2019-03-23 20:26:07,059] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135000, global step 2162674: loss -1.7919
[2019-03-23 20:26:07,060] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135000, global step 2162674: learning rate 0.0000
[2019-03-23 20:26:07,090] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135000, global step 2162686: loss 0.5934
[2019-03-23 20:26:07,095] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135000, global step 2162687: learning rate 0.0000
[2019-03-23 20:26:07,262] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135000, global step 2162765: loss -84.0032
[2019-03-23 20:26:07,269] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135000, global step 2162765: learning rate 0.0000
[2019-03-23 20:26:11,108] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135500, global step 2164709: loss 91.0502
[2019-03-23 20:26:11,112] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135500, global step 2164710: learning rate 0.0000
[2019-03-23 20:26:12,850] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.3720119e-02 4.7780658e-11 9.7626716e-01 1.8808484e-09 1.2635683e-05], sum to 1.0000
[2019-03-23 20:26:12,865] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1137
[2019-03-23 20:26:12,875] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.33333333333334, 81.33333333333333, 1.0, 2.0, 0.2051950365172971, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4082144708928046, 6.911199999999999, 6.9112, 77.32846344354104, 466019.2832181829, 466019.2832181831, 163577.4145854033], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1629600.0000, 
sim time next is 1630200.0000, 
raw observation next is [21.16666666666666, 82.16666666666667, 1.0, 2.0, 0.2042200323996111, 0.0, 2.0, 0.0, 1.0, 2.0, 0.406011761180143, 6.911200000000001, 6.9112, 77.32846344354104, 463644.2118670251, 463644.2118670248, 163252.0310714132], 
processed observation next is [1.0, 0.8695652173913043, 0.5984848484848482, 0.8216666666666668, 1.0, 1.0, 0.005275040499513849, 0.0, 1.0, -0.25, 1.0, 1.0, 0.15144537311449, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17172007846926857, 0.17172007846926843, 0.3981756855400322], 
reward next is 0.6018, 
noisyNet noise sample is [array([-0.13378592], dtype=float32), -0.41890985]. 
=============================================
[2019-03-23 20:26:14,844] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135500, global step 2166673: loss 18.3575
[2019-03-23 20:26:14,849] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135500, global step 2166673: learning rate 0.0000
[2019-03-23 20:26:16,292] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136500, global step 2167432: loss 1.1337
[2019-03-23 20:26:16,295] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136500, global step 2167433: learning rate 0.0000
[2019-03-23 20:26:16,803] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.4489850e-01 5.2727944e-07 1.0105389e-01 4.9488655e-05 1.5399764e-01], sum to 1.0000
[2019-03-23 20:26:16,811] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0824
[2019-03-23 20:26:16,816] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.83333333333333, 54.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7376149359385564, 7.175738457180371, 6.9112, 77.32769943275018, 515048.5272067675, 429132.6959247295, 104117.5212552229], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1849800.0000, 
sim time next is 1850400.0000, 
raw observation next is [19.0, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7495076289526342, 7.27555930207857, 6.9112, 77.32737862332905, 554404.109197342, 436069.3204289434, 106654.4980845461], 
processed observation next is [1.0, 0.43478260869565216, 0.5, 0.52, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6421537556466204, 0.03643593020785696, 0.0, 0.508421680309607, 0.2053348552582748, 0.16150715571442348, 0.2601329221574295], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.717786], dtype=float32), -0.77421606]. 
=============================================
[2019-03-23 20:26:17,791] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135500, global step 2168225: loss 4.4715
[2019-03-23 20:26:17,793] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135500, global step 2168226: learning rate 0.0000
[2019-03-23 20:26:18,439] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.7155511e-01 1.6001938e-14 2.8443137e-02 8.2132582e-12 1.7551780e-06], sum to 1.0000
[2019-03-23 20:26:18,440] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9162
[2019-03-23 20:26:18,446] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.83333333333334, 46.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5808534191098187, 6.911200000000001, 6.9112, 77.32846344354104, 337868.7667345246, 337868.7667345243, 106258.9596136888], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1879800.0000, 
sim time next is 1880400.0000, 
raw observation next is [22.66666666666667, 46.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5813022640782772, 6.911199999999999, 6.9112, 77.32846344354104, 338130.6163639894, 338130.6163639897, 104706.5829824927], 
processed observation next is [1.0, 0.782608695652174, 0.6666666666666669, 0.46666666666666673, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4018603772546818, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12523356161629237, 0.12523356161629248, 0.25538190971339686], 
reward next is 0.7446, 
noisyNet noise sample is [array([1.5700071], dtype=float32), -0.44530496]. 
=============================================
[2019-03-23 20:26:20,108] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136000, global step 2169423: loss 0.7744
[2019-03-23 20:26:20,115] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136000, global step 2169423: learning rate 0.0000
[2019-03-23 20:26:20,842] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135500, global step 2169802: loss 0.4964
[2019-03-23 20:26:20,844] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135500, global step 2169802: learning rate 0.0000
[2019-03-23 20:26:21,912] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135500, global step 2170367: loss 0.3539
[2019-03-23 20:26:21,913] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135500, global step 2170368: learning rate 0.0000
[2019-03-23 20:26:22,009] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135500, global step 2170423: loss 0.3614
[2019-03-23 20:26:22,013] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135500, global step 2170423: learning rate 0.0000
[2019-03-23 20:26:22,040] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135500, global step 2170436: loss 0.2897
[2019-03-23 20:26:22,043] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135500, global step 2170437: learning rate 0.0000
[2019-03-23 20:26:22,050] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135500, global step 2170442: loss 0.2525
[2019-03-23 20:26:22,054] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135500, global step 2170443: learning rate 0.0000
[2019-03-23 20:26:22,094] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135500, global step 2170465: loss 0.1885
[2019-03-23 20:26:22,098] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135500, global step 2170466: learning rate 0.0000
[2019-03-23 20:26:22,115] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135500, global step 2170475: loss 0.1489
[2019-03-23 20:26:22,117] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135500, global step 2170475: learning rate 0.0000
[2019-03-23 20:26:22,310] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135500, global step 2170577: loss 0.0683
[2019-03-23 20:26:22,312] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135500, global step 2170577: learning rate 0.0000
[2019-03-23 20:26:22,421] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135500, global step 2170635: loss 0.1181
[2019-03-23 20:26:22,423] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135500, global step 2170637: learning rate 0.0000
[2019-03-23 20:26:22,752] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135500, global step 2170808: loss 0.1736
[2019-03-23 20:26:22,754] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135500, global step 2170808: learning rate 0.0000
[2019-03-23 20:26:22,756] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135500, global step 2170809: loss 0.2398
[2019-03-23 20:26:22,759] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135500, global step 2170810: learning rate 0.0000
[2019-03-23 20:26:22,918] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9957258e-01 7.7446889e-17 4.2318951e-04 9.0500610e-12 4.2601937e-06], sum to 1.0000
[2019-03-23 20:26:22,927] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7888
[2019-03-23 20:26:22,933] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.0, 53.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7301052641509319, 7.012364525955011, 6.9112, 77.32818322108777, 450635.8444196226, 417779.7946258236, 130585.6452601822], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1963800.0000, 
sim time next is 1964400.0000, 
raw observation next is [25.0, 52.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7336226992358222, 7.059623338929264, 6.9112, 77.32799773583852, 469268.4474026449, 421063.8730126406, 130067.9443190629], 
processed observation next is [1.0, 0.7391304347826086, 0.7727272727272727, 0.5233333333333333, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6194609989083175, 0.01484233389292644, 0.0, 0.5084257509276464, 0.17380312866764627, 0.1559495825972743, 0.31723888858308025], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3737218], dtype=float32), -0.6608534]. 
=============================================
[2019-03-23 20:26:26,037] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136000, global step 2172526: loss 1.7785
[2019-03-23 20:26:26,039] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136000, global step 2172526: learning rate 0.0000
[2019-03-23 20:26:29,996] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136000, global step 2174578: loss 2.2770
[2019-03-23 20:26:29,997] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136000, global step 2174578: learning rate 0.0000
[2019-03-23 20:26:30,800] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 20:26:30,801] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:26:30,802] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:26:30,803] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:26:30,803] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:26:30,804] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:26:30,804] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:26:30,806] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:26:30,804] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:26:30,808] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:26:30,811] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:26:30,824] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run88
[2019-03-23 20:26:30,850] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run88
[2019-03-23 20:26:30,873] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run88
[2019-03-23 20:26:30,875] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run88
[2019-03-23 20:26:30,898] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run88
[2019-03-23 20:26:43,589] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.001087], dtype=float32), 0.01660022]
[2019-03-23 20:26:43,590] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.53662556, 97.146867055, 1.0, 1.0, 0.490651268346695, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 95.55301021572443, 557959.9973626811, 557959.9973626811, 141118.1493091602]
[2019-03-23 20:26:43,591] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:26:43,593] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.9999714e-01 8.4997388e-21 2.9046546e-06 1.3085672e-16 6.8719436e-12], sampled 0.3015415156973045
[2019-03-23 20:26:43,594] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 557959.9973626811 W.
[2019-03-23 20:26:50,351] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.001087], dtype=float32), 0.01660022]
[2019-03-23 20:26:50,352] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.93169093, 75.68074876, 1.0, 2.0, 0.4481993311562812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.5533869121282, 510660.0389498188, 510660.0389498188, 137710.575873067]
[2019-03-23 20:26:50,354] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:26:50,357] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.9998140e-01 3.0581093e-18 1.8583356e-05 1.3574239e-14 2.5303054e-10], sampled 0.47093049260099273
[2019-03-23 20:27:01,016] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.001087], dtype=float32), 0.01660022]
[2019-03-23 20:27:01,018] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.01666666666667, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6958141521546987, 7.01763227619516, 6.9112, 95.5528690522844, 444465.2973757648, 401751.6781048715, 128572.9176269691]
[2019-03-23 20:27:01,018] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:27:01,020] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.9999857e-01 9.3225430e-23 1.4691485e-06 1.7889822e-18 2.6022950e-13], sampled 0.10612096970061313
[2019-03-23 20:27:18,736] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.001087], dtype=float32), 0.01660022]
[2019-03-23 20:27:18,738] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.76467578166667, 67.15781676166667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6537031095491305, 6.9112, 6.9112, 95.55338769695034, 377790.9228238536, 377790.9228238536, 124223.4549507802]
[2019-03-23 20:27:18,740] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:27:18,744] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.9999976e-01 9.8557712e-26 1.9599152e-07 6.5329230e-21 3.0175182e-15], sampled 0.7303260945016434
[2019-03-23 20:27:24,246] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.001087], dtype=float32), 0.01660022]
[2019-03-23 20:27:24,247] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.90948932, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6022640958124511, 6.911199999999999, 6.9112, 95.55338769685254, 349831.6047275502, 349831.6047275506, 117352.7270851166]
[2019-03-23 20:27:24,250] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:27:24,254] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.9999678e-01 2.2501704e-21 3.1690604e-06 2.6997723e-17 1.7471260e-12], sampled 0.4081721635090937
[2019-03-23 20:27:42,532] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.001087], dtype=float32), 0.01660022]
[2019-03-23 20:27:42,536] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.7, 65.66666666666667, 1.0, 2.0, 0.464038255140033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338689819544, 528911.5472113763, 528911.5472113763, 139654.9689360515]
[2019-03-23 20:27:42,538] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:27:42,541] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.9999833e-01 1.3661695e-21 1.7248077e-06 3.5860903e-17 4.0889679e-12], sampled 0.9671784409132667
[2019-03-23 20:28:05,970] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.001087], dtype=float32), 0.01660022]
[2019-03-23 20:28:05,972] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.46666666666667, 82.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5057689879231669, 6.911199999999999, 6.9112, 95.55338769695034, 294164.6269579896, 294164.62695799, 95404.82765442527]
[2019-03-23 20:28:05,973] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:28:05,976] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 4.7607088e-33 9.6856723e-10 8.6481249e-27 8.8796902e-20], sampled 0.915749815599944
[2019-03-23 20:28:14,035] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6294.2855 1685690679.1826 3226.0000
[2019-03-23 20:28:14,179] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6553.3607 1698655049.1410 2956.0000
[2019-03-23 20:28:14,217] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6329.1626 1723357495.3779 3422.0000
[2019-03-23 20:28:14,262] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6481.9150 1678916345.5939 3055.0000
[2019-03-23 20:28:14,301] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6853.9557 1793448211.1675 2407.0000
[2019-03-23 20:28:15,320] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 2175000, evaluation results [2175000.0, 6853.955682892126, 1793448211.167498, 2407.0, 6481.914993490591, 1678916345.5938516, 3055.0, 6294.285486950552, 1685690679.18262, 3226.0, 6329.162589453947, 1723357495.377943, 3422.0, 6553.360677416896, 1698655049.1409822, 2956.0]
[2019-03-23 20:28:16,048] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137000, global step 2175364: loss 84.8734
[2019-03-23 20:28:16,051] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137000, global step 2175364: learning rate 0.0000
[2019-03-23 20:28:16,931] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.00000000e+00 1.13733935e-32 2.26767771e-11 4.36968106e-29
 3.44702479e-21], sum to 1.0000
[2019-03-23 20:28:16,947] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9007
[2019-03-23 20:28:16,951] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.0, 67.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4695469376967146, 6.9112, 6.9112, 77.32846344354104, 273107.0479683332, 273107.0479683332, 85242.86011018066], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1997400.0000, 
sim time next is 1998000.0000, 
raw observation next is [18.0, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4702334254705177, 6.911199999999999, 6.9112, 77.32846344354104, 273506.4486488107, 273506.448648811, 85937.22011254224], 
processed observation next is [0.0, 0.13043478260869565, 0.45454545454545453, 0.68, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.24319060781502536, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10129868468474469, 0.10129868468474483, 0.20960297588424937], 
reward next is 0.7904, 
noisyNet noise sample is [array([-0.9809306], dtype=float32), 0.36536703]. 
=============================================
[2019-03-23 20:28:16,971] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[81.761475]
 [83.52272 ]
 [82.29985 ]
 [83.33273 ]
 [84.59824 ]], R is [[80.65956116]
 [80.64505768]
 [80.63238525]
 [80.62142181]
 [80.61196136]].
[2019-03-23 20:28:17,630] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136000, global step 2176149: loss 1.9850
[2019-03-23 20:28:17,632] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136000, global step 2176151: learning rate 0.0000
[2019-03-23 20:28:20,334] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136500, global step 2177497: loss 0.1636
[2019-03-23 20:28:20,335] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136500, global step 2177497: learning rate 0.0000
[2019-03-23 20:28:20,982] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136000, global step 2177822: loss 1.7179
[2019-03-23 20:28:20,988] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136000, global step 2177822: learning rate 0.0000
[2019-03-23 20:28:22,008] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136000, global step 2178320: loss 1.1165
[2019-03-23 20:28:22,011] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136000, global step 2178320: learning rate 0.0000
[2019-03-23 20:28:22,137] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.9999654e-01 2.9074859e-28 3.4103614e-06 5.7627968e-23 2.4635867e-17], sum to 1.0000
[2019-03-23 20:28:22,143] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3777
[2019-03-23 20:28:22,151] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.0, 85.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4160564480442401, 6.911200000000001, 6.9112, 77.32846344354104, 241987.1263540163, 241987.126354016, 75525.070744336], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2097000.0000, 
sim time next is 2097600.0000, 
raw observation next is [15.33333333333333, 82.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4190855817277522, 6.911200000000001, 6.9112, 77.32846344354104, 243749.375278796, 243749.3752787957, 75923.6190520416], 
processed observation next is [0.0, 0.2608695652173913, 0.3333333333333332, 0.8266666666666665, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.17012225961107458, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09027754639955408, 0.09027754639955396, 0.1851795586635161], 
reward next is 0.8148, 
noisyNet noise sample is [array([-1.048313], dtype=float32), -0.760059]. 
=============================================
[2019-03-23 20:28:22,234] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136000, global step 2178434: loss 1.0799
[2019-03-23 20:28:22,235] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136000, global step 2178434: learning rate 0.0000
[2019-03-23 20:28:22,283] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136000, global step 2178456: loss 1.2253
[2019-03-23 20:28:22,284] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136000, global step 2178456: learning rate 0.0000
[2019-03-23 20:28:22,286] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136000, global step 2178457: loss 1.3033
[2019-03-23 20:28:22,289] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136000, global step 2178457: learning rate 0.0000
[2019-03-23 20:28:22,361] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136000, global step 2178492: loss 1.2067
[2019-03-23 20:28:22,362] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136000, global step 2178492: learning rate 0.0000
[2019-03-23 20:28:22,431] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136000, global step 2178528: loss 1.1786
[2019-03-23 20:28:22,439] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136000, global step 2178529: learning rate 0.0000
[2019-03-23 20:28:22,473] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136000, global step 2178545: loss 1.0432
[2019-03-23 20:28:22,475] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136000, global step 2178546: learning rate 0.0000
[2019-03-23 20:28:22,529] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136000, global step 2178576: loss 1.0257
[2019-03-23 20:28:22,530] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136000, global step 2178576: learning rate 0.0000
[2019-03-23 20:28:22,919] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136000, global step 2178767: loss 0.3543
[2019-03-23 20:28:22,921] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136000, global step 2178767: learning rate 0.0000
[2019-03-23 20:28:23,046] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136000, global step 2178833: loss 0.2850
[2019-03-23 20:28:23,048] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136000, global step 2178833: learning rate 0.0000
[2019-03-23 20:28:25,770] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9998260e-01 2.1030857e-12 1.1116332e-05 2.9042200e-09 6.3610569e-06], sum to 1.0000
[2019-03-23 20:28:25,781] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0405
[2019-03-23 20:28:25,785] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.83333333333333, 73.66666666666667, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3028749744461385, 6.9112, 6.9112, 77.3421103, 526229.6361391919, 526229.6361391919, 190208.1835174956], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2199000.0000, 
sim time next is 2199600.0000, 
raw observation next is [19.0, 73.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8286609572449337, 7.921068369929103, 6.9112, 77.32606497481437, 808899.9270414426, 480925.5088470222, 135015.3987730258], 
processed observation next is [1.0, 0.4782608695652174, 0.5, 0.73, 0.0, 0.5, -0.25, 0.0, 0.5, -0.25, 1.0, 1.0, 0.7552299389213338, 0.10098683699291033, 0.0, 0.5084130431697341, 0.2995925655709047, 0.17812055883223044, 0.3293058506659166], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.687449], dtype=float32), 1.0951939]. 
=============================================
[2019-03-23 20:28:26,141] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 5.1075831e-29 3.9894613e-10 4.2445854e-23 1.2460342e-17], sum to 1.0000
[2019-03-23 20:28:26,150] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1147
[2019-03-23 20:28:26,156] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.43333333333333, 92.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4330806525306105, 6.9112, 6.9112, 77.32846344354104, 251891.3234914352, 251891.3234914352, 78446.99295745124], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2182800.0000, 
sim time next is 2183400.0000, 
raw observation next is [14.55, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4322445233263421, 6.911200000000001, 6.9112, 77.32846344354104, 251404.8826328927, 251404.8826328925, 78581.48141811491], 
processed observation next is [1.0, 0.2608695652173913, 0.2977272727272728, 0.92, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1889207476090602, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09311291949366396, 0.09311291949366389, 0.19166214980028026], 
reward next is 0.8083, 
noisyNet noise sample is [array([-0.2805851], dtype=float32), 0.43841723]. 
=============================================
[2019-03-23 20:28:26,541] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136500, global step 2180564: loss 0.0199
[2019-03-23 20:28:26,542] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136500, global step 2180564: learning rate 0.0000
[2019-03-23 20:28:27,796] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9744642e-01 3.1243211e-10 6.2303276e-05 6.9546098e-07 2.4905358e-03], sum to 1.0000
[2019-03-23 20:28:27,803] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4464
[2019-03-23 20:28:27,810] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 718446.5527321374 W.
[2019-03-23 20:28:27,813] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 78.0, 1.0, 2.0, 0.2126966013712172, 1.0, 1.0, 0.2126966013712172, 1.0, 2.0, 0.4170387061483259, 6.9112, 6.9112, 77.3421103, 718446.5527321374, 718446.5527321374, 215259.700423359], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2210400.0000, 
sim time next is 2211000.0000, 
raw observation next is [20.33333333333334, 76.5, 1.0, 2.0, 0.8830995581020086, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 80.5999473675816, 990679.3600776121, 990679.3600776121, 182615.4399869651], 
processed observation next is [1.0, 0.6086956521739131, 0.5606060606060609, 0.765, 1.0, 1.0, 0.8538744476275106, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5299385728967251, 0.3669182815102267, 0.3669182815102267, 0.4454035121633295], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.76916724], dtype=float32), 0.51471245]. 
=============================================
[2019-03-23 20:28:27,830] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[30.786465]
 [32.028793]
 [34.054688]
 [37.484364]
 [37.418476]], R is [[29.01412964]
 [28.72398949]
 [28.43675041]
 [28.1523838 ]
 [27.87086105]].
[2019-03-23 20:28:28,633] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9996209e-01 1.0695409e-17 3.7883325e-05 3.3530555e-14 1.8112892e-10], sum to 1.0000
[2019-03-23 20:28:28,640] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8391
[2019-03-23 20:28:28,643] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.16666666666666, 77.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7535450424203614, 7.219295604050653, 6.9112, 77.32753897349977, 532221.4915978697, 432159.5373127482, 132553.2767102703], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2227800.0000, 
sim time next is 2228400.0000, 
raw observation next is [21.0, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7595331061265167, 7.276204159667627, 6.9112, 77.32733589990711, 554658.3380428584, 436114.1811530342, 132863.3138017154], 
processed observation next is [1.0, 0.8260869565217391, 0.5909090909090909, 0.78, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6564758658950239, 0.03650041596676266, 0.0, 0.5084213994063311, 0.20542901408994757, 0.16152377079742009, 0.3240568629310132], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6110757], dtype=float32), -0.3989626]. 
=============================================
[2019-03-23 20:28:30,919] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136500, global step 2182740: loss 0.0146
[2019-03-23 20:28:30,922] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136500, global step 2182741: learning rate 0.0000
[2019-03-23 20:28:33,501] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.3611411e-29 8.4472196e-10 3.3838701e-24 2.8348733e-20], sum to 1.0000
[2019-03-23 20:28:33,509] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8299
[2019-03-23 20:28:33,517] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.0, 45.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.755354492541353, 7.237654189742011, 6.9112, 77.32744409589837, 539459.5782513651, 433435.3322013469, 132588.1392033779], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2656800.0000, 
sim time next is 2657400.0000, 
raw observation next is [26.83333333333333, 45.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7592275584070429, 7.270956377921635, 6.9112, 77.32733160405245, 552589.3371464219, 435749.5340711017, 132966.3392726502], 
processed observation next is [0.0, 0.782608695652174, 0.8560606060606059, 0.455, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6560393691529185, 0.03597563779216353, 0.0, 0.5084213711614108, 0.20466271746163775, 0.16138871632263024, 0.3243081445674395], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.37050286], dtype=float32), 0.2953003]. 
=============================================
[2019-03-23 20:28:33,566] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137500, global step 2184055: loss -156.7513
[2019-03-23 20:28:33,569] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137500, global step 2184057: learning rate 0.0000
[2019-03-23 20:28:33,702] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136500, global step 2184123: loss 0.1196
[2019-03-23 20:28:33,704] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136500, global step 2184123: learning rate 0.0000
[2019-03-23 20:28:36,370] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137000, global step 2185452: loss -38.8296
[2019-03-23 20:28:36,373] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137000, global step 2185453: learning rate 0.0000
[2019-03-23 20:28:37,062] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136500, global step 2185797: loss 2.3478
[2019-03-23 20:28:37,067] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136500, global step 2185800: learning rate 0.0000
[2019-03-23 20:28:38,135] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136500, global step 2186335: loss 1.8015
[2019-03-23 20:28:38,139] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136500, global step 2186337: learning rate 0.0000
[2019-03-23 20:28:38,198] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136500, global step 2186369: loss 1.6622
[2019-03-23 20:28:38,201] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136500, global step 2186371: learning rate 0.0000
[2019-03-23 20:28:38,335] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136500, global step 2186432: loss 1.1180
[2019-03-23 20:28:38,336] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136500, global step 2186432: learning rate 0.0000
[2019-03-23 20:28:38,395] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136500, global step 2186465: loss 0.9961
[2019-03-23 20:28:38,397] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136500, global step 2186466: learning rate 0.0000
[2019-03-23 20:28:38,437] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136500, global step 2186483: loss 0.8141
[2019-03-23 20:28:38,439] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136500, global step 2186483: learning rate 0.0000
[2019-03-23 20:28:38,467] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136500, global step 2186496: loss 0.6407
[2019-03-23 20:28:38,468] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136500, global step 2186497: learning rate 0.0000
[2019-03-23 20:28:38,530] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136500, global step 2186528: loss 0.2202
[2019-03-23 20:28:38,533] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136500, global step 2186529: learning rate 0.0000
[2019-03-23 20:28:38,546] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136500, global step 2186538: loss 0.2964
[2019-03-23 20:28:38,548] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136500, global step 2186539: learning rate 0.0000
[2019-03-23 20:28:38,562] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136500, global step 2186542: loss 0.1363
[2019-03-23 20:28:38,563] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136500, global step 2186542: learning rate 0.0000
[2019-03-23 20:28:38,631] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.00000000e+00 5.70312105e-28 1.01865086e-10 4.04340787e-21
 2.23061958e-17], sum to 1.0000
[2019-03-23 20:28:38,640] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4453
[2019-03-23 20:28:38,645] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.0, 53.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5417291676033935, 6.9112, 6.9112, 77.32846344354104, 315104.6855160657, 315104.6855160657, 97100.12152357958], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2400000.0000, 
sim time next is 2400600.0000, 
raw observation next is [21.0, 53.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5397256278873692, 6.911199999999999, 6.9112, 77.32846344354104, 313938.9212085546, 313938.9212085549, 96909.9128347519], 
processed observation next is [1.0, 0.782608695652174, 0.5909090909090909, 0.53, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.34246518269624177, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11627367452168688, 0.11627367452168699, 0.23636564106037047], 
reward next is 0.7636, 
noisyNet noise sample is [array([0.6115693], dtype=float32), 0.6045752]. 
=============================================
[2019-03-23 20:28:39,200] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136500, global step 2186859: loss 0.5268
[2019-03-23 20:28:39,201] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136500, global step 2186859: learning rate 0.0000
[2019-03-23 20:28:40,248] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9999797e-01 6.8196106e-21 1.9995502e-06 1.3815174e-16 1.4921158e-13], sum to 1.0000
[2019-03-23 20:28:40,253] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2785
[2019-03-23 20:28:40,258] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4315392338828734, 6.9112, 6.9112, 77.32846344354104, 250994.5617346748, 250994.5617346748, 78495.22295702875], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2444400.0000, 
sim time next is 2445000.0000, 
raw observation next is [15.0, 88.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4656902006164033, 6.911199999999999, 6.9112, 77.32846344354104, 270863.1926702723, 270863.1926702725, 80917.97034827058], 
processed observation next is [1.0, 0.30434782608695654, 0.3181818181818182, 0.8800000000000001, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.23670028659486192, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10031970098898975, 0.1003197009889898, 0.19736090328846484], 
reward next is 0.8026, 
noisyNet noise sample is [array([-0.22684076], dtype=float32), 0.24388525]. 
=============================================
[2019-03-23 20:28:40,280] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[57.408222]
 [57.614697]
 [57.894318]
 [58.117428]
 [58.41082 ]], R is [[56.74356461]
 [56.98467636]
 [57.22514343]
 [57.46460342]
 [57.70318222]].
[2019-03-23 20:28:40,774] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.9979490e-01 1.0200559e-09 1.0524247e-04 3.1495810e-07 9.9548291e-05], sum to 1.0000
[2019-03-23 20:28:40,783] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5739
[2019-03-23 20:28:40,787] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 547912.2146081234 W.
[2019-03-23 20:28:40,790] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [15.33333333333334, 90.0, 1.0, 1.0, 0.2522383157613056, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4708736761610177, 6.9112, 6.9112, 77.32812869344332, 547912.2146081234, 547912.2146081234, 151566.0640292449], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2452800.0000, 
sim time next is 2453400.0000, 
raw observation next is [15.5, 88.0, 1.0, 2.0, 0.227992105242466, 1.0, 1.0, 0.227992105242466, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846137137317, 495217.7535091712, 495217.7535091712, 146642.6879061169], 
processed observation next is [1.0, 0.391304347826087, 0.3409090909090909, 0.88, 1.0, 1.0, 0.034990131553082476, 1.0, 0.5, 0.034990131553082476, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084287992963067, 0.18341398278117452, 0.18341398278117452, 0.3576650924539436], 
reward next is 0.6423, 
noisyNet noise sample is [array([0.96468693], dtype=float32), -1.8698453]. 
=============================================
[2019-03-23 20:28:42,321] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137000, global step 2188389: loss 69.8928
[2019-03-23 20:28:42,325] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137000, global step 2188390: learning rate 0.0000
[2019-03-23 20:28:46,862] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137000, global step 2190660: loss 18.2091
[2019-03-23 20:28:46,863] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137000, global step 2190660: learning rate 0.0000
[2019-03-23 20:28:49,398] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137000, global step 2192000: loss 54.0262
[2019-03-23 20:28:49,400] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137000, global step 2192000: learning rate 0.0000
[2019-03-23 20:28:49,890] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9935049e-01 1.0921399e-08 2.7764658e-04 6.4382666e-06 3.6533701e-04], sum to 1.0000
[2019-03-23 20:28:49,899] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4007
[2019-03-23 20:28:49,907] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 545210.7750137387 W.
[2019-03-23 20:28:49,911] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 80.5, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3221121340697043, 6.9112, 6.9112, 77.3421103, 545210.7750137387, 545210.7750137387, 207324.3472717289], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2849400.0000, 
sim time next is 2850000.0000, 
raw observation next is [23.0, 79.66666666666667, 1.0, 2.0, 0.2365201599508842, 1.0, 2.0, 0.2365201599508842, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 539692.3487539439, 539692.3487539439, 175890.1455889631], 
processed observation next is [1.0, 1.0, 0.6818181818181818, 0.7966666666666667, 1.0, 1.0, 0.04565019993860525, 1.0, 1.0, 0.04565019993860525, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1998860550940533, 0.1998860550940533, 0.4290003550950319], 
reward next is 0.5710, 
noisyNet noise sample is [array([-0.7448687], dtype=float32), 0.008989469]. 
=============================================
[2019-03-23 20:28:49,928] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9998701e-01 3.9708227e-15 1.3048191e-05 6.1570383e-13 9.0810741e-11], sum to 1.0000
[2019-03-23 20:28:49,930] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[27.463852]
 [27.96182 ]
 [27.554192]
 [26.776451]
 [25.967674]], R is [[29.0536747 ]
 [28.76313782]
 [28.47550583]
 [28.75728035]
 [28.46970749]].
[2019-03-23 20:28:49,937] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3503
[2019-03-23 20:28:49,950] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.33333333333334, 42.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6530258276875291, 6.9112, 6.9112, 77.32846344354104, 377139.4371374561, 377139.4371374561, 120067.3755387492], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2636400.0000, 
sim time next is 2637000.0000, 
raw observation next is [26.5, 42.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6599101562646343, 6.911199999999999, 6.9112, 77.32846344354104, 380868.6618862815, 380868.6618862817, 120894.7511906886], 
processed observation next is [0.0, 0.5217391304347826, 0.8409090909090909, 0.42, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5141573660923349, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14106246736528943, 0.14106246736528952, 0.29486524680655757], 
reward next is 0.7051, 
noisyNet noise sample is [array([-1.8299359], dtype=float32), 1.1178796]. 
=============================================
[2019-03-23 20:28:49,966] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[25.13503 ]
 [25.343256]
 [25.400007]
 [25.030172]
 [23.93735 ]], R is [[28.94371033]
 [29.36142731]
 [29.77657318]
 [30.18852425]
 [30.59625053]].
[2019-03-23 20:28:49,985] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138000, global step 2192303: loss 0.0358
[2019-03-23 20:28:49,986] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138000, global step 2192303: learning rate 0.0000
[2019-03-23 20:28:52,683] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137000, global step 2193723: loss 61.0375
[2019-03-23 20:28:52,686] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137000, global step 2193723: learning rate 0.0000
[2019-03-23 20:28:53,233] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137500, global step 2194013: loss 184.5455
[2019-03-23 20:28:53,235] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137500, global step 2194013: learning rate 0.0000
[2019-03-23 20:28:53,659] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137000, global step 2194235: loss -6.8877
[2019-03-23 20:28:53,665] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137000, global step 2194236: learning rate 0.0000
[2019-03-23 20:28:53,786] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137000, global step 2194298: loss 20.7691
[2019-03-23 20:28:53,789] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137000, global step 2194298: learning rate 0.0000
[2019-03-23 20:28:53,800] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137000, global step 2194307: loss 38.3588
[2019-03-23 20:28:53,803] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137000, global step 2194307: learning rate 0.0000
[2019-03-23 20:28:53,874] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137000, global step 2194339: loss 37.7488
[2019-03-23 20:28:53,875] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137000, global step 2194339: learning rate 0.0000
[2019-03-23 20:28:54,012] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137000, global step 2194414: loss 7.5185
[2019-03-23 20:28:54,017] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137000, global step 2194415: learning rate 0.0000
[2019-03-23 20:28:54,022] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137000, global step 2194417: loss 21.6409
[2019-03-23 20:28:54,023] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137000, global step 2194417: learning rate 0.0000
[2019-03-23 20:28:54,091] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137000, global step 2194457: loss 63.9890
[2019-03-23 20:28:54,092] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137000, global step 2194457: learning rate 0.0000
[2019-03-23 20:28:54,093] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137000, global step 2194458: loss 54.0387
[2019-03-23 20:28:54,096] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137000, global step 2194458: learning rate 0.0000
[2019-03-23 20:28:54,108] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137000, global step 2194467: loss 28.9542
[2019-03-23 20:28:54,109] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137000, global step 2194467: learning rate 0.0000
[2019-03-23 20:28:54,694] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137000, global step 2194769: loss 9.0920
[2019-03-23 20:28:54,696] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137000, global step 2194770: learning rate 0.0000
[2019-03-23 20:28:56,232] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0388534e-01 1.6607700e-06 8.1819983e-04 6.6656724e-04 8.9462829e-01], sum to 1.0000
[2019-03-23 20:28:56,233] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6230
[2019-03-23 20:28:56,236] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.66666666666666, 80.0, 1.0, 2.0, 0.4724681237744819, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9408189528982006, 6.939250988120333, 6.9112, 77.32839607536536, 1073239.22904997, 1064128.849787337, 254814.3540917894], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2967600.0000, 
sim time next is 2968200.0000, 
raw observation next is [25.0, 78.5, 1.0, 2.0, 0.37653821999538, 1.0, 1.0, 0.37653821999538, 1.0, 2.0, 0.7611648192929834, 6.9112, 6.9112, 77.3421103, 1272972.32158476, 1272972.32158476, 294939.1863962035], 
processed observation next is [1.0, 0.34782608695652173, 0.7727272727272727, 0.785, 1.0, 1.0, 0.220672774994225, 1.0, 0.5, 0.220672774994225, 1.0, 1.0, 0.6588068847042621, 0.0, 0.0, 0.5085185399722538, 0.4714712302165778, 0.4714712302165778, 0.719363869259033], 
reward next is 0.2806, 
noisyNet noise sample is [array([-0.96337694], dtype=float32), -0.6157102]. 
=============================================
[2019-03-23 20:28:56,622] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9398106e-01 1.2627778e-08 6.0141333e-03 1.1299331e-06 3.4955742e-06], sum to 1.0000
[2019-03-23 20:28:56,631] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4845
[2019-03-23 20:28:56,640] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 553934.4303384051 W.
[2019-03-23 20:28:56,644] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 78.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7637850463228827, 7.274367867278151, 6.9112, 77.32756203606108, 553934.4303384051, 435986.310035293, 135202.1259887797], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2761200.0000, 
sim time next is 2761800.0000, 
raw observation next is [21.83333333333334, 78.0, 1.0, 1.0, 0.2226363757606973, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4435866352602841, 6.9112, 6.9112, 77.32824520335836, 506047.7771922991, 506047.7771922991, 167184.7572462898], 
processed observation next is [0.0, 1.0, 0.628787878787879, 0.78, 1.0, 0.5, 0.02829546970087162, 0.0, 1.0, -0.25, 1.0, 1.0, 0.20512376465754872, 0.0, 0.0, 0.5084273780079186, 0.18742510266381449, 0.18742510266381449, 0.40776770060070683], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7959346], dtype=float32), 1.0656132]. 
=============================================
[2019-03-23 20:28:58,611] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137500, global step 2196807: loss -89.4931
[2019-03-23 20:28:58,614] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137500, global step 2196808: learning rate 0.0000
[2019-03-23 20:28:59,145] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.1345053e-01 2.4210843e-08 4.8371361e-04 9.6972901e-05 3.8596877e-01], sum to 1.0000
[2019-03-23 20:28:59,150] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3725
[2019-03-23 20:28:59,158] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1169893.565060124 W.
[2019-03-23 20:28:59,163] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.16666666666667, 93.16666666666667, 1.0, 2.0, 0.5459700874092831, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9684195970246039, 6.922365230855471, 6.9112, 77.32843484124035, 1169893.565060124, 1166267.327788006, 266835.3869744043], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3489000.0000, 
sim time next is 3489600.0000, 
raw observation next is [22.33333333333334, 92.33333333333334, 1.0, 2.0, 0.4963736614227923, 1.0, 1.0, 0.4963736614227923, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32845673425895, 1126939.102337889, 1126939.102337889, 231398.9008820546], 
processed observation next is [1.0, 0.391304347826087, 0.6515151515151518, 0.9233333333333335, 1.0, 1.0, 0.3704670767784904, 1.0, 0.5, 0.3704670767784904, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084287688076305, 0.4173848527177366, 0.4173848527177366, 0.5643875631269624], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7279847], dtype=float32), -0.7912368]. 
=============================================
[2019-03-23 20:29:02,290] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137500, global step 2198723: loss -7.3374
[2019-03-23 20:29:02,292] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137500, global step 2198725: learning rate 0.0000
[2019-03-23 20:29:04,734] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 20:29:04,735] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:29:04,735] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:29:04,736] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:29:04,736] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:29:04,736] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:29:04,738] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:29:04,737] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:29:04,738] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:29:04,741] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:29:04,742] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:29:04,764] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run89
[2019-03-23 20:29:04,788] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run89
[2019-03-23 20:29:04,810] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run89
[2019-03-23 20:29:04,810] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run89
[2019-03-23 20:29:04,874] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run89
[2019-03-23 20:30:29,133] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00071026], dtype=float32), 0.016802762]
[2019-03-23 20:30:29,135] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.16666666666667, 59.0, 1.0, 2.0, 0.2112703208311667, 1.0, 1.0, 0.2112703208311667, 1.0, 1.0, 0.4092960409049147, 6.911199999999999, 6.9112, 77.3421103, 707713.467672473, 707713.4676724734, 211467.8206539229]
[2019-03-23 20:30:29,137] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:30:29,140] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.3505423e-01 8.2393839e-05 1.1919924e-02 4.0163174e-03 3.4892708e-01], sampled 0.19899183816227828
[2019-03-23 20:30:29,141] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 707713.467672473 W.
[2019-03-23 20:30:31,947] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00071026], dtype=float32), 0.016802762]
[2019-03-23 20:30:31,949] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.41666666666667, 79.33333333333334, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7089788623533272, 7.105365623432127, 6.9112, 95.55271656482664, 485531.8983555934, 407609.0766693332, 131201.9533772529]
[2019-03-23 20:30:31,950] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:30:31,953] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.9844033e-01 4.2587875e-09 1.5464699e-03 2.6427207e-07 1.2938847e-05], sampled 0.03557013245770013
[2019-03-23 20:30:40,562] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00071026], dtype=float32), 0.016802762]
[2019-03-23 20:30:40,565] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.01216151166667, 83.30572461166666, 1.0, 1.0, 0.5200429009374467, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 95.55296811531154, 592893.212171642, 592893.212171642, 146045.4411096196]
[2019-03-23 20:30:40,566] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:30:40,569] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.9162173e-01 1.0203638e-06 6.6958340e-03 3.4530138e-05 1.6468726e-03], sampled 0.001996073574835222
[2019-03-23 20:30:40,572] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 592893.212171642 W.
[2019-03-23 20:30:46,308] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6268.6168 1702035145.9179 2998.0000
[2019-03-23 20:30:46,563] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6071.5425 1712308825.3344 3126.0000
[2019-03-23 20:30:46,906] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6160.1719 1764284915.2334 3078.0000
[2019-03-23 20:30:46,934] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6452.7195 1852904087.1483 2272.0000
[2019-03-23 20:30:47,097] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6322.2398 1733665271.3646 2797.0000
[2019-03-23 20:30:48,115] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 2200000, evaluation results [2200000.0, 6452.719536178086, 1852904087.1482563, 2272.0, 6268.616758996057, 1702035145.917918, 2998.0, 6071.542496867304, 1712308825.3343744, 3126.0, 6160.1718915199135, 1764284915.2333698, 3078.0, 6322.2398463094305, 1733665271.3646116, 2797.0]
[2019-03-23 20:30:48,207] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137500, global step 2200043: loss 16.2248
[2019-03-23 20:30:48,209] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137500, global step 2200043: learning rate 0.0000
[2019-03-23 20:30:48,823] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138500, global step 2200346: loss -13.3722
[2019-03-23 20:30:48,825] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138500, global step 2200347: learning rate 0.0000
[2019-03-23 20:30:50,678] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.4943449e-01 1.4245115e-05 5.8323122e-03 4.6482176e-04 7.4425411e-01], sum to 1.0000
[2019-03-23 20:30:50,687] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4152
[2019-03-23 20:30:50,696] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3340032564253946, 6.9112, 6.9112, 77.3421103, 564199.4016463183, 564199.4016463183, 210817.074623493], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3642600.0000, 
sim time next is 3643200.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3342798840527688, 6.9112, 6.9112, 77.3421103, 564341.1424416661, 564341.1424416661, 211134.534559112], 
processed observation next is [1.0, 0.17391304347826086, 0.5909090909090909, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0489712629325269, 0.0, 0.0, 0.5085185399722538, 0.20901523794135782, 0.20901523794135782, 0.5149622794124683], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.63359034], dtype=float32), -1.3136265]. 
=============================================
[2019-03-23 20:30:51,113] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8345803e-01 3.4690852e-06 5.6034973e-04 5.2213104e-04 8.1545609e-01], sum to 1.0000
[2019-03-23 20:30:51,121] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5212
[2019-03-23 20:30:51,127] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.16666666666667, 68.66666666666667, 1.0, 2.0, 0.3989851605787259, 1.0, 2.0, 0.3989851605787259, 1.0, 2.0, 0.8066597364370904, 6.9112, 6.9112, 79.22590883987648, 1349427.243328625, 1349427.243328625, 306195.1872130114], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2974200.0000, 
sim time next is 2974800.0000, 
raw observation next is [26.33333333333334, 67.33333333333334, 1.0, 2.0, 0.4236064200810741, 1.0, 2.0, 0.4236064200810741, 1.0, 2.0, 0.8562527379133579, 6.9112, 6.9112, 77.3421103, 1432043.783027674, 1432043.783027674, 317402.161812886], 
processed observation next is [1.0, 0.43478260869565216, 0.8333333333333336, 0.6733333333333335, 1.0, 1.0, 0.27950802510134254, 1.0, 1.0, 0.27950802510134254, 1.0, 1.0, 0.7946467684476543, 0.0, 0.0, 0.5085185399722538, 0.530386586306546, 0.530386586306546, 0.7741516141777708], 
reward next is 0.2258, 
noisyNet noise sample is [array([0.2850253], dtype=float32), -0.53024536]. 
=============================================
[2019-03-23 20:30:51,756] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137500, global step 2201798: loss -132.9634
[2019-03-23 20:30:51,760] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137500, global step 2201800: learning rate 0.0000
[2019-03-23 20:30:51,806] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138000, global step 2201822: loss 0.7904
[2019-03-23 20:30:51,807] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138000, global step 2201823: learning rate 0.0000
[2019-03-23 20:30:52,720] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137500, global step 2202279: loss -35.1657
[2019-03-23 20:30:52,724] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137500, global step 2202279: loss -83.1456
[2019-03-23 20:30:52,725] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137500, global step 2202279: learning rate 0.0000
[2019-03-23 20:30:52,726] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137500, global step 2202280: learning rate 0.0000
[2019-03-23 20:30:52,948] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137500, global step 2202390: loss -73.2395
[2019-03-23 20:30:52,950] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137500, global step 2202391: learning rate 0.0000
[2019-03-23 20:30:52,994] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137500, global step 2202413: loss -92.5740
[2019-03-23 20:30:52,997] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137500, global step 2202415: learning rate 0.0000
[2019-03-23 20:30:53,030] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137500, global step 2202432: loss -21.4843
[2019-03-23 20:30:53,034] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137500, global step 2202432: learning rate 0.0000
[2019-03-23 20:30:53,058] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137500, global step 2202445: loss -107.9021
[2019-03-23 20:30:53,061] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137500, global step 2202446: learning rate 0.0000
[2019-03-23 20:30:53,108] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137500, global step 2202471: loss -85.0943
[2019-03-23 20:30:53,111] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137500, global step 2202471: learning rate 0.0000
[2019-03-23 20:30:53,183] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137500, global step 2202506: loss 15.8366
[2019-03-23 20:30:53,185] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137500, global step 2202506: learning rate 0.0000
[2019-03-23 20:30:53,295] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137500, global step 2202565: loss -68.3922
[2019-03-23 20:30:53,300] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137500, global step 2202565: learning rate 0.0000
[2019-03-23 20:30:53,597] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137500, global step 2202715: loss -208.9560
[2019-03-23 20:30:53,600] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137500, global step 2202716: learning rate 0.0000
[2019-03-23 20:30:54,242] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.9999511e-01 2.9513842e-15 4.8569177e-06 1.3958163e-12 3.7906453e-10], sum to 1.0000
[2019-03-23 20:30:54,250] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2159
[2019-03-23 20:30:54,254] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.16666666666667, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7168686998447479, 6.98542064731441, 6.9112, 77.32812226245204, 440012.8634762258, 415907.6216585324, 124919.6134491986], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3034200.0000, 
sim time next is 3034800.0000, 
raw observation next is [17.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7019159511210102, 6.9112, 6.9112, 77.32836329625509, 407403.6417108959, 407403.6417108959, 123282.6870210155], 
processed observation next is [1.0, 0.13043478260869565, 0.4090909090909091, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5741656444585861, 0.0, 0.0, 0.5084281544598048, 0.1508902376707022, 0.1508902376707022, 0.3006894805390622], 
reward next is 0.6993, 
noisyNet noise sample is [array([0.9979614], dtype=float32), 0.6803291]. 
=============================================
[2019-03-23 20:30:57,294] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138000, global step 2204555: loss 0.7337
[2019-03-23 20:30:57,296] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138000, global step 2204555: learning rate 0.0000
[2019-03-23 20:31:01,245] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.1593608e-01 6.4686705e-09 9.5525480e-05 1.9225252e-05 4.8394915e-01], sum to 1.0000
[2019-03-23 20:31:01,251] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0835
[2019-03-23 20:31:01,258] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1306543.014304131 W.
[2019-03-23 20:31:01,263] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.66666666666666, 73.66666666666667, 1.0, 2.0, 0.6656467601365837, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9745049150641408, 6.9112, 6.9112, 77.32846340801015, 1306543.014304131, 1306543.014304131, 284342.166340231], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3159600.0000, 
sim time next is 3160200.0000, 
raw observation next is [24.83333333333334, 71.33333333333333, 1.0, 2.0, 0.5684278551089653, 1.0, 1.0, 0.5684278551089653, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.3284634433211, 1292567.2642358, 1292567.2642358, 248795.8093621136], 
processed observation next is [1.0, 0.5652173913043478, 0.7651515151515155, 0.7133333333333333, 1.0, 1.0, 0.4605348188862066, 1.0, 0.5, 0.4605348188862066, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.508428812919208, 0.47872861638362957, 0.47872861638362957, 0.6068190472246673], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5121225], dtype=float32), -0.076844476]. 
=============================================
[2019-03-23 20:31:01,361] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138000, global step 2206565: loss 0.9953
[2019-03-23 20:31:01,363] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138000, global step 2206565: learning rate 0.0000
[2019-03-23 20:31:03,911] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138000, global step 2207803: loss 0.5031
[2019-03-23 20:31:03,917] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138000, global step 2207804: learning rate 0.0000
[2019-03-23 20:31:04,903] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139000, global step 2208293: loss 0.0434
[2019-03-23 20:31:04,905] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139000, global step 2208294: learning rate 0.0000
[2019-03-23 20:31:07,142] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 8.0243907e-29 6.7992961e-14 1.6627543e-24 3.3306126e-21], sum to 1.0000
[2019-03-23 20:31:07,150] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3259
[2019-03-23 20:31:07,155] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 58.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6146132527913647, 6.911199999999999, 6.9112, 77.32846344354104, 356713.1134390366, 356713.1134390369, 115296.8160955064], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3270000.0000, 
sim time next is 3270600.0000, 
raw observation next is [22.0, 58.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6187931166530511, 6.9112, 6.9112, 77.32846344354104, 359008.2444202445, 359008.2444202445, 115751.0701778307], 
processed observation next is [0.0, 0.8695652173913043, 0.6363636363636364, 0.585, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4554187380757874, 0.0, 0.0, 0.5084288129206541, 0.1329660164519424, 0.1329660164519424, 0.2823196833605627], 
reward next is 0.7177, 
noisyNet noise sample is [array([-0.10342544], dtype=float32), -0.52386284]. 
=============================================
[2019-03-23 20:31:08,125] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138000, global step 2209891: loss 0.8080
[2019-03-23 20:31:08,128] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138000, global step 2209893: learning rate 0.0000
[2019-03-23 20:31:08,271] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138500, global step 2209969: loss -80.8869
[2019-03-23 20:31:08,275] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138500, global step 2209971: learning rate 0.0000
[2019-03-23 20:31:08,941] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138000, global step 2210302: loss 0.3021
[2019-03-23 20:31:08,942] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138000, global step 2210302: learning rate 0.0000
[2019-03-23 20:31:08,989] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138000, global step 2210326: loss 0.2933
[2019-03-23 20:31:08,990] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138000, global step 2210327: learning rate 0.0000
[2019-03-23 20:31:09,006] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138000, global step 2210332: loss 0.3402
[2019-03-23 20:31:09,008] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138000, global step 2210333: learning rate 0.0000
[2019-03-23 20:31:09,030] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138000, global step 2210341: loss 0.2525
[2019-03-23 20:31:09,035] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138000, global step 2210344: learning rate 0.0000
[2019-03-23 20:31:09,224] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138000, global step 2210438: loss 0.2669
[2019-03-23 20:31:09,225] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138000, global step 2210438: learning rate 0.0000
[2019-03-23 20:31:09,330] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138000, global step 2210497: loss 0.1805
[2019-03-23 20:31:09,333] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138000, global step 2210497: learning rate 0.0000
[2019-03-23 20:31:09,349] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138000, global step 2210502: loss 0.1374
[2019-03-23 20:31:09,351] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138000, global step 2210502: learning rate 0.0000
[2019-03-23 20:31:09,373] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138000, global step 2210513: loss 0.1243
[2019-03-23 20:31:09,375] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138000, global step 2210513: learning rate 0.0000
[2019-03-23 20:31:09,505] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138000, global step 2210579: loss 0.1073
[2019-03-23 20:31:09,508] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138000, global step 2210580: learning rate 0.0000
[2019-03-23 20:31:09,843] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138000, global step 2210747: loss 0.2189
[2019-03-23 20:31:09,845] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138000, global step 2210747: learning rate 0.0000
[2019-03-23 20:31:14,127] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138500, global step 2212873: loss 38.7120
[2019-03-23 20:31:14,130] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138500, global step 2212875: learning rate 0.0000
[2019-03-23 20:31:18,250] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138500, global step 2214876: loss 9.3730
[2019-03-23 20:31:18,251] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138500, global step 2214876: learning rate 0.0000
[2019-03-23 20:31:19,647] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.7451639e-02 2.2395211e-06 3.3451294e-04 7.4263645e-04 9.4146895e-01], sum to 1.0000
[2019-03-23 20:31:19,651] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7379
[2019-03-23 20:31:19,656] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 70.0, 1.0, 2.0, 0.3374750085110941, 1.0, 2.0, 0.3374750085110941, 1.0, 2.0, 0.682839991559951, 6.911199999999999, 6.9112, 77.3421103, 1138211.225105445, 1138211.225105445, 279408.4456426867], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3501000.0000, 
sim time next is 3501600.0000, 
raw observation next is [27.0, 70.0, 1.0, 2.0, 0.3332270489980478, 1.0, 2.0, 0.3332270489980478, 1.0, 2.0, 0.6742447576466812, 6.911199999999999, 6.9112, 77.3421103, 1123869.806626523, 1123869.806626524, 277662.7010942094], 
processed observation next is [1.0, 0.5217391304347826, 0.8636363636363636, 0.7, 1.0, 1.0, 0.1665338112475597, 1.0, 1.0, 0.1665338112475597, 1.0, 1.0, 0.5346353680666875, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.41624807652834184, 0.4162480765283422, 0.677226100229779], 
reward next is 0.3228, 
noisyNet noise sample is [array([0.6031015], dtype=float32), -0.44435745]. 
=============================================
[2019-03-23 20:31:20,328] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138500, global step 2215949: loss -118.7856
[2019-03-23 20:31:20,330] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138500, global step 2215949: learning rate 0.0000
[2019-03-23 20:31:20,618] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139500, global step 2216096: loss 31.6420
[2019-03-23 20:31:20,622] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139500, global step 2216096: learning rate 0.0000
[2019-03-23 20:31:24,048] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.6975899e-02 7.0783436e-08 3.1641750e-05 1.0009138e-05 9.3298239e-01], sum to 1.0000
[2019-03-23 20:31:24,054] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7154
[2019-03-23 20:31:24,062] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 54.5, 1.0, 2.0, 0.4164593881343494, 1.0, 2.0, 0.4164593881343494, 1.0, 2.0, 0.8414016740597069, 6.911199999999999, 6.9112, 77.3421103, 1404934.354576882, 1404934.354576882, 314772.6394577341], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3683400.0000, 
sim time next is 3684000.0000, 
raw observation next is [29.0, 54.0, 1.0, 2.0, 0.4398527894184956, 1.0, 2.0, 0.4398527894184956, 1.0, 2.0, 0.888414685408728, 6.9112, 6.9112, 77.3421103, 1484288.524532091, 1484288.524532091, 326401.2404036924], 
processed observation next is [1.0, 0.6521739130434783, 0.9545454545454546, 0.54, 1.0, 1.0, 0.29981598677311944, 1.0, 1.0, 0.29981598677311944, 1.0, 1.0, 0.8405924077267544, 0.0, 0.0, 0.5085185399722538, 0.5497364905674411, 0.5497364905674411, 0.7961005863504693], 
reward next is 0.2039, 
noisyNet noise sample is [array([-0.11786323], dtype=float32), 0.56504524]. 
=============================================
[2019-03-23 20:31:24,076] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[23.732786]
 [23.327993]
 [23.41833 ]
 [23.338793]
 [23.559023]], R is [[23.7339344 ]
 [23.72885704]
 [23.68701744]
 [23.59363174]
 [23.50997925]].
[2019-03-23 20:31:24,149] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138500, global step 2217948: loss -83.7406
[2019-03-23 20:31:24,151] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138500, global step 2217948: learning rate 0.0000
[2019-03-23 20:31:24,282] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139000, global step 2218017: loss 0.0513
[2019-03-23 20:31:24,284] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139000, global step 2218018: learning rate 0.0000
[2019-03-23 20:31:24,567] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138500, global step 2218164: loss -317.2353
[2019-03-23 20:31:24,569] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138500, global step 2218164: learning rate 0.0000
[2019-03-23 20:31:24,728] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138500, global step 2218251: loss -75.0780
[2019-03-23 20:31:24,737] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138500, global step 2218255: learning rate 0.0000
[2019-03-23 20:31:24,800] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138500, global step 2218283: loss -109.0676
[2019-03-23 20:31:24,803] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138500, global step 2218283: learning rate 0.0000
[2019-03-23 20:31:25,047] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138500, global step 2218411: loss -134.0199
[2019-03-23 20:31:25,048] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138500, global step 2218412: learning rate 0.0000
[2019-03-23 20:31:25,051] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138500, global step 2218413: loss 3.7270
[2019-03-23 20:31:25,052] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138500, global step 2218413: learning rate 0.0000
[2019-03-23 20:31:25,078] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138500, global step 2218422: loss -64.1206
[2019-03-23 20:31:25,080] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138500, global step 2218422: learning rate 0.0000
[2019-03-23 20:31:25,187] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138500, global step 2218483: loss -194.6479
[2019-03-23 20:31:25,189] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138500, global step 2218483: learning rate 0.0000
[2019-03-23 20:31:25,206] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138500, global step 2218492: loss -129.9494
[2019-03-23 20:31:25,207] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138500, global step 2218492: learning rate 0.0000
[2019-03-23 20:31:25,235] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138500, global step 2218504: loss -275.6054
[2019-03-23 20:31:25,238] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138500, global step 2218504: learning rate 0.0000
[2019-03-23 20:31:25,517] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138500, global step 2218652: loss -169.3608
[2019-03-23 20:31:25,519] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138500, global step 2218653: learning rate 0.0000
[2019-03-23 20:31:29,387] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139000, global step 2220674: loss 0.1262
[2019-03-23 20:31:29,389] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139000, global step 2220674: learning rate 0.0000
[2019-03-23 20:31:33,166] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139000, global step 2222653: loss 0.1273
[2019-03-23 20:31:33,168] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139000, global step 2222653: learning rate 0.0000
[2019-03-23 20:31:33,809] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9996853e-01 2.0453317e-15 3.1491192e-05 1.9992775e-12 7.1936048e-09], sum to 1.0000
[2019-03-23 20:31:33,813] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8876
[2019-03-23 20:31:33,826] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 569370.4053124496 W.
[2019-03-23 20:31:33,830] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 78.0, 1.0, 2.0, 0.2498715583330372, 1.0, 1.0, 0.2498715583330372, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 569370.4053124496, 569370.4053124493, 179563.9417117666], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4470600.0000, 
sim time next is 4471200.0000, 
raw observation next is [24.0, 78.0, 1.0, 2.0, 0.4998141636247607, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 570049.753666441, 570049.753666441, 141990.1408672196], 
processed observation next is [0.0, 0.782608695652174, 0.7272727272727273, 0.78, 1.0, 1.0, 0.3747677045309509, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21112953839497814, 0.21112953839497814, 0.3463174167493161], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6950881], dtype=float32), -1.1084327]. 
=============================================
[2019-03-23 20:31:34,473] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.00000000e+00 1.07225311e-32 1.09042075e-14 5.01815345e-26
 8.15551697e-21], sum to 1.0000
[2019-03-23 20:31:34,482] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3150
[2019-03-23 20:31:34,490] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.66666666666667, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.637669625633842, 6.911199999999999, 6.9112, 77.32846344354104, 369740.0342850531, 369740.0342850534, 117559.2205581274], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3795600.0000, 
sim time next is 3796200.0000, 
raw observation next is [17.5, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6336364604582579, 6.9112, 6.9112, 77.32846344354104, 367491.3285960814, 367491.3285960814, 117134.5313967938], 
processed observation next is [1.0, 0.9565217391304348, 0.4318181818181818, 0.91, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.47662351494036853, 0.0, 0.0, 0.5084288129206541, 0.13610789948003016, 0.13610789948003016, 0.28569397901657023], 
reward next is 0.7143, 
noisyNet noise sample is [array([-0.27514964], dtype=float32), 0.20674658]. 
=============================================
[2019-03-23 20:31:34,610] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 2.4785442e-33 5.7980611e-13 1.7378301e-26 1.6956490e-21], sum to 1.0000
[2019-03-23 20:31:34,619] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0436
[2019-03-23 20:31:34,623] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6102860696585183, 6.9112, 6.9112, 77.32846344354104, 354329.0688004657, 354329.0688004657, 114835.3884395363], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3808800.0000, 
sim time next is 3809400.0000, 
raw observation next is [17.0, 94.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6095813015298688, 6.9112, 6.9112, 77.32846344354104, 353919.7351028773, 353919.7351028773, 114776.5294831783], 
processed observation next is [0.0, 0.08695652173913043, 0.4090909090909091, 0.9400000000000002, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4422590021855269, 0.0, 0.0, 0.5084288129206541, 0.13108138337143604, 0.13108138337143604, 0.27994275483702025], 
reward next is 0.7201, 
noisyNet noise sample is [array([-0.0313371], dtype=float32), 0.2281863]. 
=============================================
[2019-03-23 20:31:35,512] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139000, global step 2223876: loss 0.2769
[2019-03-23 20:31:35,514] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139000, global step 2223878: learning rate 0.0000
[2019-03-23 20:31:36,038] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140000, global step 2224147: loss 37.6816
[2019-03-23 20:31:36,041] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140000, global step 2224147: learning rate 0.0000
[2019-03-23 20:31:37,639] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 20:31:37,640] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:31:37,640] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:31:37,641] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:31:37,642] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:31:37,642] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:31:37,643] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:31:37,643] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:31:37,644] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:31:37,643] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:31:37,645] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:31:37,667] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run90
[2019-03-23 20:31:37,695] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run90
[2019-03-23 20:31:37,719] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run90
[2019-03-23 20:31:37,742] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run90
[2019-03-23 20:31:37,778] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run90
[2019-03-23 20:31:40,491] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00070027], dtype=float32), 0.017104266]
[2019-03-23 20:31:40,493] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.16666666666667, 76.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.414367192435226, 6.9112, 6.9112, 77.32846344354104, 241004.3765676401, 241004.3765676401, 71063.5762282249]
[2019-03-23 20:31:40,494] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:31:40,497] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 1.4745254e-30 1.1892130e-12 4.4056902e-26 3.4541459e-21], sampled 0.4993198875100281
[2019-03-23 20:32:42,264] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00070027], dtype=float32), 0.017104266]
[2019-03-23 20:32:42,265] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.13201007333334, 80.24805643666667, 1.0, 2.0, 0.4598601477716702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338692529602, 524660.748720195, 524660.7487201954, 140494.9801050111]
[2019-03-23 20:32:42,266] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:32:42,269] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.999974e-01 3.486395e-15 2.650569e-06 9.260587e-13 2.165452e-09], sampled 0.9744753253084877
[2019-03-23 20:33:19,327] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6552.5474 1699858721.0391 2923.0000
[2019-03-23 20:33:19,363] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6481.8421 1679392174.5419 3046.0000
[2019-03-23 20:33:19,452] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6297.2008 1685875306.5022 3216.0000
[2019-03-23 20:33:19,493] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6799.9867 1800666047.3175 2381.0000
[2019-03-23 20:33:19,533] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6337.2281 1724626510.0758 3355.0000
[2019-03-23 20:33:20,550] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 2225000, evaluation results [2225000.0, 6799.986656905027, 1800666047.3174934, 2381.0, 6481.842059693447, 1679392174.5419354, 3046.0, 6297.200798817226, 1685875306.5022264, 3216.0, 6337.228144683318, 1724626510.0757873, 3355.0, 6552.547442926336, 1699858721.0391376, 2923.0]
[2019-03-23 20:33:22,332] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139000, global step 2225880: loss 0.1044
[2019-03-23 20:33:22,335] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139000, global step 2225880: learning rate 0.0000
[2019-03-23 20:33:22,685] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139500, global step 2226053: loss 325.3924
[2019-03-23 20:33:22,686] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139500, global step 2226053: learning rate 0.0000
[2019-03-23 20:33:22,864] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139000, global step 2226141: loss 0.2403
[2019-03-23 20:33:22,867] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139000, global step 2226141: learning rate 0.0000
[2019-03-23 20:33:23,085] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139000, global step 2226248: loss 0.1105
[2019-03-23 20:33:23,087] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139000, global step 2226248: learning rate 0.0000
[2019-03-23 20:33:23,202] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139000, global step 2226306: loss 0.0828
[2019-03-23 20:33:23,204] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139000, global step 2226306: learning rate 0.0000
[2019-03-23 20:33:23,377] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139000, global step 2226396: loss 0.0185
[2019-03-23 20:33:23,379] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139000, global step 2226397: learning rate 0.0000
[2019-03-23 20:33:23,547] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139000, global step 2226480: loss 0.0060
[2019-03-23 20:33:23,550] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139000, global step 2226480: learning rate 0.0000
[2019-03-23 20:33:23,619] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139000, global step 2226513: loss 0.0217
[2019-03-23 20:33:23,628] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139000, global step 2226516: learning rate 0.0000
[2019-03-23 20:33:23,647] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139000, global step 2226524: loss 0.0144
[2019-03-23 20:33:23,648] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139000, global step 2226526: learning rate 0.0000
[2019-03-23 20:33:23,666] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139000, global step 2226535: loss 0.0411
[2019-03-23 20:33:23,668] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139000, global step 2226535: learning rate 0.0000
[2019-03-23 20:33:23,698] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139000, global step 2226551: loss 0.0268
[2019-03-23 20:33:23,702] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139000, global step 2226551: learning rate 0.0000
[2019-03-23 20:33:23,909] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139000, global step 2226657: loss 0.0170
[2019-03-23 20:33:23,911] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139000, global step 2226657: learning rate 0.0000
[2019-03-23 20:33:24,418] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 6.1639712e-31 7.2720303e-15 8.2185779e-27 3.0817675e-23], sum to 1.0000
[2019-03-23 20:33:24,426] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5394
[2019-03-23 20:33:24,434] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.0, 45.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6727738021371028, 6.9112, 6.9112, 77.32846344354104, 387822.8478432925, 387822.8478432925, 122471.3410149311], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3936000.0000, 
sim time next is 3936600.0000, 
raw observation next is [26.0, 45.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6750151616113583, 6.911199999999999, 6.9112, 77.32846344354104, 389105.3852025127, 389105.385202513, 122696.8938312065], 
processed observation next is [0.0, 0.5652173913043478, 0.8181818181818182, 0.45, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5357359451590834, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14411310563056026, 0.14411310563056037, 0.29926071666147924], 
reward next is 0.7007, 
noisyNet noise sample is [array([0.63341475], dtype=float32), 0.57289904]. 
=============================================
[2019-03-23 20:33:25,296] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 3.1341299e-33 1.2039565e-12 1.0878620e-28 3.2515698e-23], sum to 1.0000
[2019-03-23 20:33:25,304] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6843
[2019-03-23 20:33:25,311] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.0, 45.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6782277636790167, 6.9112, 6.9112, 77.32846344354104, 390955.2990311214, 390955.2990311214, 123013.14522682], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3937200.0000, 
sim time next is 3937800.0000, 
raw observation next is [26.0, 45.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6791061341791765, 6.9112, 6.9112, 77.32846344354104, 391461.5976313567, 391461.5976313567, 123099.5429646331], 
processed observation next is [0.0, 0.5652173913043478, 0.8181818181818182, 0.45, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.541580191684538, 0.0, 0.0, 0.5084288129206541, 0.14498577690050246, 0.14498577690050246, 0.30024278771861734], 
reward next is 0.6998, 
noisyNet noise sample is [array([-0.5247644], dtype=float32), -1.2683709]. 
=============================================
[2019-03-23 20:33:28,396] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139500, global step 2228889: loss -1.5515
[2019-03-23 20:33:28,398] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139500, global step 2228890: learning rate 0.0000
[2019-03-23 20:33:32,309] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139500, global step 2230827: loss 170.6155
[2019-03-23 20:33:32,311] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139500, global step 2230829: learning rate 0.0000
[2019-03-23 20:33:32,367] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9788672e-01 1.7422288e-09 2.0732571e-04 2.7729791e-07 1.9057409e-03], sum to 1.0000
[2019-03-23 20:33:32,377] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9729
[2019-03-23 20:33:32,386] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 722191.9633646281 W.
[2019-03-23 20:33:32,388] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.5, 78.0, 1.0, 2.0, 0.3172615288502242, 1.0, 2.0, 0.3172615288502242, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 722191.9633646281, 722191.9633646281, 184216.25109301], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4098600.0000, 
sim time next is 4099200.0000, 
raw observation next is [21.66666666666667, 78.0, 1.0, 2.0, 0.2234196839596259, 1.0, 2.0, 0.2234196839596259, 1.0, 1.0, 0.4474354353769971, 6.9112, 6.9112, 77.3421103, 763714.5789249496, 763714.5789249496, 225726.5000137233], 
processed observation next is [1.0, 0.43478260869565216, 0.6212121212121214, 0.78, 1.0, 1.0, 0.029274604949532344, 1.0, 1.0, 0.029274604949532344, 1.0, 0.5, 0.2106220505385673, 0.0, 0.0, 0.5085185399722538, 0.28285725145368507, 0.28285725145368507, 0.5505524390578617], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.67115605], dtype=float32), -1.3133065]. 
=============================================
[2019-03-23 20:33:34,687] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139500, global step 2231985: loss 130.6073
[2019-03-23 20:33:34,694] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139500, global step 2231988: learning rate 0.0000
[2019-03-23 20:33:35,385] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140500, global step 2232336: loss 2.4343
[2019-03-23 20:33:35,386] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140500, global step 2232336: learning rate 0.0000
[2019-03-23 20:33:35,513] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9999321e-01 3.9898881e-15 6.7792839e-06 3.3489448e-12 2.9617032e-08], sum to 1.0000
[2019-03-23 20:33:35,525] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1140
[2019-03-23 20:33:35,529] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7530159798817317, 7.235928906042332, 6.9112, 77.32740811173987, 538779.3582071959, 433315.490705696, 131425.2202213782], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4136400.0000, 
sim time next is 4137000.0000, 
raw observation next is [18.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7518903667812576, 7.227866489332316, 6.9112, 77.32742696831953, 535600.6558994794, 432755.2356254126, 131233.8511991842], 
processed observation next is [1.0, 0.9130434782608695, 0.45454545454545453, 1.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6455576668303681, 0.03166664893323157, 0.0, 0.5084219981742719, 0.19837061329610348, 0.16027971689830098, 0.32008256390044926], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.23971394], dtype=float32), 2.0039482]. 
=============================================
[2019-03-23 20:33:35,548] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[32.81241 ]
 [31.5088  ]
 [30.648695]
 [30.71189 ]
 [30.476227]], R is [[32.88615036]
 [32.55728912]
 [32.23171616]
 [31.90939903]
 [31.59030533]].
[2019-03-23 20:33:38,335] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139500, global step 2233794: loss 2.7493
[2019-03-23 20:33:38,339] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139500, global step 2233796: learning rate 0.0000
[2019-03-23 20:33:39,001] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139500, global step 2234123: loss -24.2968
[2019-03-23 20:33:39,005] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139500, global step 2234123: learning rate 0.0000
[2019-03-23 20:33:39,249] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139500, global step 2234243: loss 9.1589
[2019-03-23 20:33:39,250] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139500, global step 2234243: learning rate 0.0000
[2019-03-23 20:33:39,287] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139500, global step 2234262: loss -21.9205
[2019-03-23 20:33:39,289] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139500, global step 2234263: learning rate 0.0000
[2019-03-23 20:33:39,408] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140000, global step 2234322: loss -25.0476
[2019-03-23 20:33:39,411] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140000, global step 2234322: learning rate 0.0000
[2019-03-23 20:33:39,472] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139500, global step 2234355: loss -22.2634
[2019-03-23 20:33:39,475] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139500, global step 2234356: learning rate 0.0000
[2019-03-23 20:33:39,567] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139500, global step 2234398: loss -21.0245
[2019-03-23 20:33:39,570] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139500, global step 2234403: learning rate 0.0000
[2019-03-23 20:33:39,605] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139500, global step 2234417: loss -17.1131
[2019-03-23 20:33:39,607] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139500, global step 2234418: learning rate 0.0000
[2019-03-23 20:33:39,678] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139500, global step 2234455: loss -14.0219
[2019-03-23 20:33:39,679] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139500, global step 2234455: loss -23.4400
[2019-03-23 20:33:39,680] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139500, global step 2234455: learning rate 0.0000
[2019-03-23 20:33:39,681] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139500, global step 2234456: learning rate 0.0000
[2019-03-23 20:33:39,746] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139500, global step 2234488: loss -2.4852
[2019-03-23 20:33:39,747] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139500, global step 2234488: learning rate 0.0000
[2019-03-23 20:33:39,852] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139500, global step 2234539: loss 0.2260
[2019-03-23 20:33:39,853] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139500, global step 2234539: learning rate 0.0000
[2019-03-23 20:33:43,619] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9999666e-01 1.6338522e-15 3.3057070e-06 2.5714378e-13 2.9993643e-08], sum to 1.0000
[2019-03-23 20:33:43,622] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9300
[2019-03-23 20:33:43,625] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 545779.611698525 W.
[2019-03-23 20:33:43,634] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.0, 83.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7601413009547731, 7.25368411913722, 6.9112, 77.32760746620046, 545779.611698525, 434549.0060807135, 134314.7629688976], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4420800.0000, 
sim time next is 4421400.0000, 
raw observation next is [20.83333333333333, 83.83333333333334, 1.0, 1.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 499444.8283990297, 499444.8283990297, 196265.6229735239], 
processed observation next is [0.0, 0.17391304347826086, 0.5833333333333331, 0.8383333333333334, 1.0, 0.5, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5085185399722538, 0.18497956607371469, 0.18497956607371469, 0.4786966413988388], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.47078547], dtype=float32), -0.9721923]. 
=============================================
[2019-03-23 20:33:44,940] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140000, global step 2237070: loss 36.6014
[2019-03-23 20:33:44,946] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140000, global step 2237073: learning rate 0.0000
[2019-03-23 20:33:46,765] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9997807e-01 3.7564573e-14 2.1985903e-05 1.7391041e-12 4.0810786e-08], sum to 1.0000
[2019-03-23 20:33:46,774] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0536
[2019-03-23 20:33:46,778] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.16666666666667, 94.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7289403970155895, 7.057447565620879, 6.9112, 77.3281287840941, 468410.5453301384, 420912.5328576338, 127686.3400248068], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4342200.0000, 
sim time next is 4342800.0000, 
raw observation next is [18.33333333333334, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7367952664809694, 7.118533752542158, 6.9112, 77.32781581462025, 492494.7816712756, 425157.5835105926, 128747.949100001], 
processed observation next is [1.0, 0.2608695652173913, 0.46969696969696995, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6239932378299563, 0.02073337525421577, 0.0, 0.5084245548093618, 0.18240547469306503, 0.15746577167058984, 0.31401938804878293], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.24039796], dtype=float32), 0.98754925]. 
=============================================
[2019-03-23 20:33:48,905] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140000, global step 2239031: loss -9.8449
[2019-03-23 20:33:48,910] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140000, global step 2239031: learning rate 0.0000
[2019-03-23 20:33:50,933] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140000, global step 2240045: loss 11.0518
[2019-03-23 20:33:50,936] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140000, global step 2240045: learning rate 0.0000
[2019-03-23 20:33:51,672] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141000, global step 2240367: loss -18.1516
[2019-03-23 20:33:51,673] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141000, global step 2240367: learning rate 0.0000
[2019-03-23 20:33:51,939] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9996805e-01 3.2797715e-14 3.1928939e-05 5.9890672e-13 2.0003512e-09], sum to 1.0000
[2019-03-23 20:33:51,944] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6217
[2019-03-23 20:33:51,948] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 560013.2671190546 W.
[2019-03-23 20:33:51,953] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.66666666666666, 79.66666666666667, 1.0, 1.0, 0.2454697414679792, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4936352089996954, 6.9112, 6.9112, 77.32816072776849, 560013.2671190546, 560013.2671190546, 174793.2444338224], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4437600.0000, 
sim time next is 4438200.0000, 
raw observation next is [22.83333333333334, 78.83333333333333, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3053778843718722, 6.9112, 6.9112, 77.3421103, 518480.3426782588, 518480.3426782588, 202410.9867331421], 
processed observation next is [0.0, 0.34782608695652173, 0.6742424242424245, 0.7883333333333333, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.007682691959817428, 0.0, 0.0, 0.5085185399722538, 0.19202975654750326, 0.19202975654750326, 0.49368533349546856], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.34697744], dtype=float32), -0.15752305]. 
=============================================
[2019-03-23 20:33:53,583] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9999595e-01 1.6678310e-15 4.0402847e-06 3.5694250e-13 4.2941223e-10], sum to 1.0000
[2019-03-23 20:33:53,590] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6005
[2019-03-23 20:33:53,598] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 589836.1136568447 W.
[2019-03-23 20:33:53,605] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 1.0, 0.2584772376682777, 1.0, 1.0, 0.2584772376682777, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32809300213098, 589836.1136568447, 589836.1136568447, 179272.8790039259], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4496400.0000, 
sim time next is 4497000.0000, 
raw observation next is [20.83333333333333, 94.00000000000001, 1.0, 2.0, 0.4669245812761773, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846115043267, 532625.4049119258, 532625.4049119261, 136351.8524808449], 
processed observation next is [0.0, 0.043478260869565216, 0.5833333333333331, 0.9400000000000002, 1.0, 1.0, 0.3336557265952216, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084287978436396, 0.19726866848589844, 0.19726866848589858, 0.3325654938557192], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.19261356], dtype=float32), 0.3234289]. 
=============================================
[2019-03-23 20:33:53,620] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[18.599913]
 [17.426989]
 [16.875908]
 [17.230444]
 [17.648863]], R is [[16.35928345]
 [16.19569016]
 [16.03373337]
 [16.44670486]
 [16.28223801]].
[2019-03-23 20:33:54,414] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140000, global step 2241771: loss -8.6667
[2019-03-23 20:33:54,418] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140000, global step 2241771: learning rate 0.0000
[2019-03-23 20:33:55,068] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140000, global step 2242115: loss 0.2499
[2019-03-23 20:33:55,070] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140000, global step 2242116: learning rate 0.0000
[2019-03-23 20:33:55,198] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140500, global step 2242179: loss -34.5462
[2019-03-23 20:33:55,200] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140500, global step 2242179: learning rate 0.0000
[2019-03-23 20:33:55,258] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140000, global step 2242206: loss 17.3307
[2019-03-23 20:33:55,260] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140000, global step 2242206: learning rate 0.0000
[2019-03-23 20:33:55,369] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140000, global step 2242264: loss 36.5935
[2019-03-23 20:33:55,371] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140000, global step 2242265: learning rate 0.0000
[2019-03-23 20:33:55,423] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140000, global step 2242289: loss 31.4410
[2019-03-23 20:33:55,424] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140000, global step 2242289: learning rate 0.0000
[2019-03-23 20:33:55,528] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140000, global step 2242341: loss -1.9890
[2019-03-23 20:33:55,533] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140000, global step 2242346: learning rate 0.0000
[2019-03-23 20:33:55,534] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140000, global step 2242346: loss -23.2622
[2019-03-23 20:33:55,541] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140000, global step 2242347: learning rate 0.0000
[2019-03-23 20:33:55,593] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140000, global step 2242370: loss 20.4502
[2019-03-23 20:33:55,593] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140000, global step 2242370: learning rate 0.0000
[2019-03-23 20:33:55,785] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140000, global step 2242470: loss 32.9717
[2019-03-23 20:33:55,786] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140000, global step 2242470: learning rate 0.0000
[2019-03-23 20:33:55,866] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140000, global step 2242514: loss 29.1086
[2019-03-23 20:33:55,867] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140000, global step 2242514: learning rate 0.0000
[2019-03-23 20:33:55,987] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140000, global step 2242576: loss 11.9873
[2019-03-23 20:33:55,991] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140000, global step 2242577: learning rate 0.0000
[2019-03-23 20:34:00,398] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140500, global step 2244885: loss 0.1212
[2019-03-23 20:34:00,399] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140500, global step 2244885: learning rate 0.0000
[2019-03-23 20:34:00,602] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.3660630e-01 6.2112299e-08 1.3407812e-03 6.1781889e-06 2.6204672e-01], sum to 1.0000
[2019-03-23 20:34:00,612] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8243
[2019-03-23 20:34:00,617] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.0, 56.0, 1.0, 2.0, 0.5215708686457895, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 566489.0879697194, 566489.0879697194, 125448.1104583211], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4618800.0000, 
sim time next is 4619400.0000, 
raw observation next is [21.33333333333333, 55.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 1.0, 0.3057888704539004, 6.9112, 6.9112, 77.3421103, 532335.8579038916, 532335.8579038916, 189575.9138072835], 
processed observation next is [1.0, 0.4782608695652174, 0.6060606060606059, 0.55, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.5, 0.008269814934143456, 0.0, 0.0, 0.5085185399722538, 0.19716142885329319, 0.19716142885329319, 0.46238027757874023], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.22144017], dtype=float32), -0.2504187]. 
=============================================
[2019-03-23 20:34:04,166] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140500, global step 2246825: loss 0.1888
[2019-03-23 20:34:04,170] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140500, global step 2246825: learning rate 0.0000
[2019-03-23 20:34:06,237] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140500, global step 2247911: loss 0.1364
[2019-03-23 20:34:06,239] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140500, global step 2247911: learning rate 0.0000
[2019-03-23 20:34:07,226] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141500, global step 2248433: loss 0.0716
[2019-03-23 20:34:07,228] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141500, global step 2248433: learning rate 0.0000
[2019-03-23 20:34:08,450] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.3267123e-01 3.0204637e-07 1.9576561e-02 9.1920001e-06 1.4774269e-01], sum to 1.0000
[2019-03-23 20:34:08,458] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9787
[2019-03-23 20:34:08,462] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [18.0, 100.0, 1.0, 1.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 489523.5087745723, 489523.5087745726, 191951.6681512034], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4767600.0000, 
sim time next is 4768200.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 440141.0327351018, 440141.0327351021, 183926.5601832876], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.16301519730929698, 0.1630151973092971, 0.44860136630070147], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3224745], dtype=float32), -0.10760148]. 
=============================================
[2019-03-23 20:34:08,575] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9779332e-01 1.6174101e-09 2.1962321e-03 1.5091148e-08 1.0514096e-05], sum to 1.0000
[2019-03-23 20:34:08,580] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8240
[2019-03-23 20:34:08,587] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.38333333333334, 96.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7388123273649208, 7.121541910339689, 6.9112, 77.327796669005, 493680.7946162939, 425366.6334266803, 129676.5950324374], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5436600.0000, 
sim time next is 5437200.0000, 
raw observation next is [18.46666666666667, 96.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7425582600163942, 7.151041113850404, 6.9112, 77.32769934061933, 505311.2735795873, 427416.5551059455, 130168.6163352744], 
processed observation next is [1.0, 0.9565217391304348, 0.4757575757575758, 0.9633333333333333, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6322260857377061, 0.023984111385040398, 0.0, 0.5084237890015934, 0.1871523235479953, 0.15830242781701687, 0.3174844300860351], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.36393335], dtype=float32), -2.2197368]. 
=============================================
[2019-03-23 20:34:09,849] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140500, global step 2249814: loss 0.1599
[2019-03-23 20:34:09,852] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140500, global step 2249814: learning rate 0.0000
[2019-03-23 20:34:10,204] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 20:34:10,206] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:34:10,207] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:34:10,210] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:34:10,214] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:34:10,215] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:34:10,216] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:34:10,217] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:34:10,218] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:34:10,219] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:34:10,220] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:34:10,240] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run91
[2019-03-23 20:34:10,241] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run91
[2019-03-23 20:34:10,286] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run91
[2019-03-23 20:34:10,287] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run91
[2019-03-23 20:34:10,289] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run91
[2019-03-23 20:35:09,396] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00089268], dtype=float32), 0.01728437]
[2019-03-23 20:35:09,397] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.14044582833333, 98.94732638333335, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7096358956770034, 7.119847529126973, 6.9112, 95.55270227540744, 492310.6420949004, 408575.9341239902, 130842.0161022919]
[2019-03-23 20:35:09,398] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:35:09,399] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.9941206e-01 1.4412412e-11 5.2629836e-04 9.5086972e-10 6.1608640e-05], sampled 0.11164498059406835
[2019-03-23 20:35:47,360] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00089268], dtype=float32), 0.01728437]
[2019-03-23 20:35:47,360] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.84888986, 81.75740931, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6993812067804263, 7.066212503376939, 6.9112, 95.55264294115761, 467204.9593649395, 404995.1709412544, 128046.8597967533]
[2019-03-23 20:35:47,362] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:35:47,367] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.998498e-01 9.104098e-13 1.492687e-04 5.787485e-11 9.992577e-07], sampled 0.5965322047782974
[2019-03-23 20:35:51,868] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 5973.9133 1978835930.5281 2054.0000
[2019-03-23 20:35:51,884] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 5279.0559 1864327151.1434 2783.0000
[2019-03-23 20:35:51,966] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 5857.4776 1871698566.1870 2795.0000
[2019-03-23 20:35:52,037] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 5693.6287 1870703395.9629 2468.0000
[2019-03-23 20:35:52,056] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 5641.3047 1838877729.9396 2790.0000
[2019-03-23 20:35:53,070] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 2250000, evaluation results [2250000.0, 5973.91331849969, 1978835930.5281155, 2054.0, 5641.304673127796, 1838877729.9395752, 2790.0, 5279.055884117522, 1864327151.1434348, 2783.0, 5857.477639890605, 1871698566.186953, 2795.0, 5693.628681844001, 1870703395.9628565, 2468.0]
[2019-03-23 20:35:53,175] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140500, global step 2250061: loss 0.2122
[2019-03-23 20:35:53,179] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140500, global step 2250063: learning rate 0.0000
[2019-03-23 20:35:53,493] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140500, global step 2250208: loss 0.0508
[2019-03-23 20:35:53,494] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140500, global step 2250208: learning rate 0.0000
[2019-03-23 20:35:53,528] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140500, global step 2250226: loss 0.0593
[2019-03-23 20:35:53,529] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140500, global step 2250226: loss 0.0875
[2019-03-23 20:35:53,530] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140500, global step 2250227: learning rate 0.0000
[2019-03-23 20:35:53,534] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140500, global step 2250227: learning rate 0.0000
[2019-03-23 20:35:53,535] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140500, global step 2250227: loss 0.0793
[2019-03-23 20:35:53,540] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140500, global step 2250228: learning rate 0.0000
[2019-03-23 20:35:53,573] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141000, global step 2250241: loss -6.9913
[2019-03-23 20:35:53,576] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141000, global step 2250242: learning rate 0.0000
[2019-03-23 20:35:53,607] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140500, global step 2250260: loss 0.0517
[2019-03-23 20:35:53,610] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140500, global step 2250260: learning rate 0.0000
[2019-03-23 20:35:53,924] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140500, global step 2250421: loss 0.2401
[2019-03-23 20:35:53,926] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140500, global step 2250421: learning rate 0.0000
[2019-03-23 20:35:54,022] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140500, global step 2250472: loss 0.0129
[2019-03-23 20:35:54,024] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140500, global step 2250472: learning rate 0.0000
[2019-03-23 20:35:54,275] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140500, global step 2250594: loss 0.0129
[2019-03-23 20:35:54,277] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140500, global step 2250594: learning rate 0.0000
[2019-03-23 20:35:54,452] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140500, global step 2250680: loss 0.0112
[2019-03-23 20:35:54,453] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140500, global step 2250680: learning rate 0.0000
[2019-03-23 20:35:59,256] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.0260020e-01 5.3060794e-06 5.7912376e-02 1.5739314e-04 1.3932480e-01], sum to 1.0000
[2019-03-23 20:35:59,265] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6227
[2019-03-23 20:35:59,271] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.0, 86.33333333333334, 1.0, 1.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3128909804894919, 6.9112, 6.9112, 77.3421103, 533232.1894232228, 533232.1894232228, 202240.3697392752], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4912800.0000, 
sim time next is 4913400.0000, 
raw observation next is [21.0, 87.16666666666667, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7734957122043913, 7.330693879329158, 6.9112, 77.32743235894644, 576141.6025068646, 439900.3872758311, 137507.0219884892], 
processed observation next is [1.0, 0.8695652173913043, 0.5909090909090909, 0.8716666666666667, 0.0, 0.5, -0.25, 0.0, 0.5, -0.25, 1.0, 1.0, 0.6764224460062733, 0.041949387932915805, 0.0, 0.5084220336172371, 0.21338577870624614, 0.16292606936141893, 0.33538298045972975], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.1898205], dtype=float32), 2.2905874]. 
=============================================
[2019-03-23 20:35:59,309] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141000, global step 2253103: loss -41.9160
[2019-03-23 20:35:59,312] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141000, global step 2253104: learning rate 0.0000
[2019-03-23 20:36:02,748] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141000, global step 2254806: loss -58.9025
[2019-03-23 20:36:02,756] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141000, global step 2254807: learning rate 0.0000
[2019-03-23 20:36:05,058] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141000, global step 2255963: loss 93.0617
[2019-03-23 20:36:05,061] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141000, global step 2255963: learning rate 0.0000
[2019-03-23 20:36:06,166] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142000, global step 2256519: loss 15.1651
[2019-03-23 20:36:06,168] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142000, global step 2256519: learning rate 0.0000
[2019-03-23 20:36:08,627] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141000, global step 2257740: loss -9.6282
[2019-03-23 20:36:08,630] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141000, global step 2257741: learning rate 0.0000
[2019-03-23 20:36:09,315] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141000, global step 2258083: loss 7.0820
[2019-03-23 20:36:09,316] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141000, global step 2258084: loss 1.0736
[2019-03-23 20:36:09,318] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141000, global step 2258084: learning rate 0.0000
[2019-03-23 20:36:09,319] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141000, global step 2258085: learning rate 0.0000
[2019-03-23 20:36:09,426] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141000, global step 2258138: loss -6.1512
[2019-03-23 20:36:09,428] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141000, global step 2258139: learning rate 0.0000
[2019-03-23 20:36:09,488] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141000, global step 2258171: loss -9.2187
[2019-03-23 20:36:09,494] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141000, global step 2258172: learning rate 0.0000
[2019-03-23 20:36:09,520] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141000, global step 2258181: loss -62.8948
[2019-03-23 20:36:09,521] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141000, global step 2258182: loss -4.3539
[2019-03-23 20:36:09,522] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141000, global step 2258182: learning rate 0.0000
[2019-03-23 20:36:09,522] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141000, global step 2258182: learning rate 0.0000
[2019-03-23 20:36:09,863] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141000, global step 2258355: loss -15.1699
[2019-03-23 20:36:09,867] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141000, global step 2258355: learning rate 0.0000
[2019-03-23 20:36:09,968] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141500, global step 2258409: loss 0.0254
[2019-03-23 20:36:09,971] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141500, global step 2258409: learning rate 0.0000
[2019-03-23 20:36:10,212] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141000, global step 2258531: loss -30.4062
[2019-03-23 20:36:10,216] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141000, global step 2258532: learning rate 0.0000
[2019-03-23 20:36:10,226] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141000, global step 2258538: loss 0.3908
[2019-03-23 20:36:10,228] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141000, global step 2258538: learning rate 0.0000
[2019-03-23 20:36:10,418] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141000, global step 2258633: loss 12.9024
[2019-03-23 20:36:10,420] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141000, global step 2258633: learning rate 0.0000
[2019-03-23 20:36:13,106] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.3063926e-02 1.3736619e-06 6.9538895e-03 5.8468053e-05 9.6992230e-01], sum to 1.0000
[2019-03-23 20:36:13,113] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7853
[2019-03-23 20:36:13,118] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.8, 85.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3487071977116264, 6.911199999999999, 6.9112, 77.3421103, 592063.9339416284, 592063.9339416288, 211569.2496494754], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5366400.0000, 
sim time next is 5367000.0000, 
raw observation next is [21.7, 86.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3489969880025204, 6.9112, 6.9112, 77.3421103, 592491.3124057999, 592491.3124057999, 211686.2512656727], 
processed observation next is [1.0, 0.08695652173913043, 0.6227272727272727, 0.86, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0699956971464577, 0.0, 0.0, 0.5085185399722538, 0.2194412268169629, 0.2194412268169629, 0.5163079299162749], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.659818], dtype=float32), 0.698917]. 
=============================================
[2019-03-23 20:36:13,136] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[17.293467]
 [16.91585 ]
 [15.790495]
 [16.580437]
 [16.409714]], R is [[16.99265099]
 [16.8227253 ]
 [16.65449905]
 [16.48795509]
 [16.75407219]].
[2019-03-23 20:36:13,793] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.9522600e-02 7.5937118e-07 2.2292456e-02 2.4212355e-05 8.8815999e-01], sum to 1.0000
[2019-03-23 20:36:13,804] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6810
[2019-03-23 20:36:13,814] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.0, 83.0, 1.0, 1.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3091977710313861, 6.9112, 6.9112, 77.3421103, 525107.0748131446, 525107.0748131446, 203087.5290299702], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5204400.0000, 
sim time next is 5205000.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 489340.0148907587, 489340.0148907587, 197541.1710842094], 
processed observation next is [1.0, 0.21739130434782608, 0.6363636363636364, 0.83, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5085185399722538, 0.18123704255213285, 0.18123704255213285, 0.48180773435173024], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6082816], dtype=float32), -0.0023471199]. 
=============================================
[2019-03-23 20:36:13,829] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[19.02644 ]
 [18.835402]
 [18.957941]
 [18.971554]
 [19.066605]], R is [[18.43394089]
 [18.24960136]
 [18.06710625]
 [17.88643456]
 [17.70757103]].
[2019-03-23 20:36:15,458] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141500, global step 2261143: loss 0.4050
[2019-03-23 20:36:15,458] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141500, global step 2261144: learning rate 0.0000
[2019-03-23 20:36:19,009] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141500, global step 2262920: loss 1.3665
[2019-03-23 20:36:19,010] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141500, global step 2262920: learning rate 0.0000
[2019-03-23 20:36:21,089] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141500, global step 2263957: loss 0.7059
[2019-03-23 20:36:21,090] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141500, global step 2263958: learning rate 0.0000
[2019-03-23 20:36:21,127] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5909848e-03 1.3941135e-06 1.0347563e-03 1.9919795e-05 9.9735296e-01], sum to 1.0000
[2019-03-23 20:36:21,134] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0387
[2019-03-23 20:36:21,139] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.8, 51.66666666666666, 1.0, 2.0, 0.3204998879591555, 1.0, 2.0, 0.3204998879591555, 1.0, 2.0, 0.6488709391631395, 6.911199999999999, 6.9112, 77.3421103, 1095626.842217904, 1095626.842217905, 265060.4489278839], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5310600.0000, 
sim time next is 5311200.0000, 
raw observation next is [27.9, 52.33333333333334, 1.0, 2.0, 0.323894921959859, 1.0, 2.0, 0.323894921959859, 1.0, 2.0, 0.6559281834348241, 6.9112, 6.9112, 77.3421103, 1106500.753574169, 1106500.753574169, 267062.0070473888], 
processed observation next is [1.0, 0.4782608695652174, 0.9045454545454544, 0.5233333333333334, 1.0, 1.0, 0.1548686524498237, 1.0, 1.0, 0.1548686524498237, 1.0, 1.0, 0.5084688334783202, 0.0, 0.0, 0.5085185399722538, 0.4098150939163589, 0.4098150939163589, 0.6513707488960703], 
reward next is 0.3486, 
noisyNet noise sample is [array([-0.5795008], dtype=float32), 0.99204654]. 
=============================================
[2019-03-23 20:36:21,653] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142500, global step 2264238: loss 0.3495
[2019-03-23 20:36:21,660] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142500, global step 2264239: learning rate 0.0000
[2019-03-23 20:36:25,142] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141500, global step 2265926: loss 1.9362
[2019-03-23 20:36:25,145] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141500, global step 2265927: learning rate 0.0000
[2019-03-23 20:36:25,526] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141500, global step 2266096: loss 1.5760
[2019-03-23 20:36:25,527] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141500, global step 2266096: learning rate 0.0000
[2019-03-23 20:36:25,588] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141500, global step 2266120: loss 1.4880
[2019-03-23 20:36:25,590] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141500, global step 2266120: learning rate 0.0000
[2019-03-23 20:36:25,647] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141500, global step 2266144: loss 1.6636
[2019-03-23 20:36:25,650] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141500, global step 2266145: learning rate 0.0000
[2019-03-23 20:36:25,751] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141500, global step 2266190: loss 1.9685
[2019-03-23 20:36:25,753] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141500, global step 2266191: learning rate 0.0000
[2019-03-23 20:36:25,773] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141500, global step 2266202: loss 2.4024
[2019-03-23 20:36:25,776] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141500, global step 2266203: learning rate 0.0000
[2019-03-23 20:36:25,838] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141500, global step 2266234: loss 2.3592
[2019-03-23 20:36:25,841] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141500, global step 2266236: learning rate 0.0000
[2019-03-23 20:36:26,040] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142000, global step 2266344: loss 18.1300
[2019-03-23 20:36:26,044] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142000, global step 2266344: learning rate 0.0000
[2019-03-23 20:36:26,253] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141500, global step 2266453: loss 3.2416
[2019-03-23 20:36:26,254] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141500, global step 2266453: learning rate 0.0000
[2019-03-23 20:36:26,468] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141500, global step 2266570: loss 4.7012
[2019-03-23 20:36:26,473] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141500, global step 2266573: learning rate 0.0000
[2019-03-23 20:36:26,621] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141500, global step 2266650: loss 3.0309
[2019-03-23 20:36:26,625] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141500, global step 2266651: learning rate 0.0000
[2019-03-23 20:36:26,653] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141500, global step 2266666: loss -1.3356
[2019-03-23 20:36:26,654] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141500, global step 2266666: learning rate 0.0000
[2019-03-23 20:36:28,537] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.9647731e-01 6.9953418e-13 3.5226734e-03 3.2571736e-12 4.4570117e-10], sum to 1.0000
[2019-03-23 20:36:28,545] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1027
[2019-03-23 20:36:28,548] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.56666666666667, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6506927871651232, 6.911199999999999, 6.9112, 77.32846344354104, 376582.669593591, 376582.6695935913, 119262.59986787], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5469600.0000, 
sim time next is 5470200.0000, 
raw observation next is [17.75, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6742694289906187, 6.911199999999999, 6.9112, 77.32846344354104, 390246.9791499604, 390246.9791499607, 121457.763435279], 
processed observation next is [1.0, 0.30434782608695654, 0.4431818181818182, 0.93, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5346706128437411, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14453591820368902, 0.14453591820368913, 0.2962384474031195], 
reward next is 0.7038, 
noisyNet noise sample is [array([1.3092781], dtype=float32), -0.48034477]. 
=============================================
[2019-03-23 20:36:30,466] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.0791746e-03 4.6455077e-07 3.0759126e-03 1.6618443e-06 9.9484283e-01], sum to 1.0000
[2019-03-23 20:36:30,474] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3232
[2019-03-23 20:36:30,482] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.78333333333333, 67.0, 1.0, 2.0, 0.2680782322712036, 1.0, 2.0, 0.2680782322712036, 1.0, 2.0, 0.5415712247885124, 6.911199999999999, 6.9112, 77.3421103, 904576.983003114, 904576.9830031144, 252721.846244745], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5505000.0000, 
sim time next is 5505600.0000, 
raw observation next is [26.96666666666667, 65.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3635531861599466, 6.9112, 6.9112, 77.3421103, 609309.6183952389, 609309.6183952389, 221009.0994393351], 
processed observation next is [1.0, 0.7391304347826086, 0.8621212121212122, 0.65, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.09079026594278086, 0.0, 0.0, 0.5085185399722538, 0.22567022903527367, 0.22567022903527367, 0.5390465839983783], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.9601716], dtype=float32), 0.66602653]. 
=============================================
[2019-03-23 20:36:31,456] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142000, global step 2269191: loss 20.3815
[2019-03-23 20:36:31,459] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142000, global step 2269191: learning rate 0.0000
[2019-03-23 20:36:31,888] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9988115e-01 3.5453799e-19 1.1879589e-04 2.6919931e-18 5.0436259e-15], sum to 1.0000
[2019-03-23 20:36:31,895] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4787
[2019-03-23 20:36:31,904] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.41666666666667, 76.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6949901406661448, 6.911199999999999, 6.9112, 77.32846344354104, 400840.7435987371, 400840.7435987373, 124519.4232504503], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6210600.0000, 
sim time next is 6211200.0000, 
raw observation next is [20.33333333333334, 77.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6988639303358353, 6.911199999999999, 6.9112, 77.32846344354104, 403026.554714811, 403026.5547148113, 124946.9603580712], 
processed observation next is [1.0, 0.9130434782608695, 0.5606060606060609, 0.7766666666666667, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.569805614765479, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14926909433881888, 0.14926909433881902, 0.30474868380017367], 
reward next is 0.6953, 
noisyNet noise sample is [array([-1.1604221], dtype=float32), -0.20563337]. 
=============================================
[2019-03-23 20:36:34,667] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142000, global step 2270876: loss 22.8172
[2019-03-23 20:36:34,669] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142000, global step 2270876: learning rate 0.0000
[2019-03-23 20:36:36,707] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142000, global step 2271944: loss 24.5343
[2019-03-23 20:36:36,708] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142000, global step 2271945: learning rate 0.0000
[2019-03-23 20:36:37,004] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143000, global step 2272101: loss 4.4729
[2019-03-23 20:36:37,009] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143000, global step 2272101: learning rate 0.0000
[2019-03-23 20:36:38,570] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.00000000e+00 0.00000000e+00 7.98866355e-12 1.04648575e-36
 2.83375336e-32], sum to 1.0000
[2019-03-23 20:36:38,577] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6185
[2019-03-23 20:36:38,583] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.26666666666667, 96.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.576971939703419, 6.911199999999999, 6.9112, 77.32846344354104, 335561.5271174671, 335561.5271174674, 110335.6296950513], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5647200.0000, 
sim time next is 5647800.0000, 
raw observation next is [16.18333333333333, 96.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5693759455319288, 6.9112, 6.9112, 77.32846344354104, 331174.8649201381, 331174.8649201381, 108517.0783060897], 
processed observation next is [0.0, 0.34782608695652173, 0.37196969696969684, 0.9616666666666666, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3848227793313269, 0.0, 0.0, 0.5084288129206541, 0.12265735737782892, 0.12265735737782892, 0.2646758007465602], 
reward next is 0.7353, 
noisyNet noise sample is [array([-0.02282484], dtype=float32), -1.645833]. 
=============================================
[2019-03-23 20:36:38,716] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9999321e-01 1.3023067e-32 6.7838369e-06 2.0282450e-27 1.7268570e-24], sum to 1.0000
[2019-03-23 20:36:38,726] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2740
[2019-03-23 20:36:38,730] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.6, 86.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4611570703520015, 6.911199999999999, 6.9112, 77.32846344354104, 268225.8240589416, 268225.8240589419, 84573.80356074702], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5665800.0000, 
sim time next is 5666400.0000, 
raw observation next is [15.5, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4558724149874231, 6.911199999999999, 6.9112, 77.32846344354104, 265151.2372891356, 265151.2372891359, 83531.64670827074], 
processed observation next is [0.0, 0.6086956521739131, 0.3409090909090909, 0.87, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2226748785534616, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0982041619589391, 0.09820416195893923, 0.20373572367870912], 
reward next is 0.7963, 
noisyNet noise sample is [array([0.68966216], dtype=float32), -0.38010317]. 
=============================================
[2019-03-23 20:36:40,469] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142000, global step 2273887: loss 3.0484
[2019-03-23 20:36:40,470] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142000, global step 2273887: learning rate 0.0000
[2019-03-23 20:36:40,689] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142000, global step 2273999: loss 5.1126
[2019-03-23 20:36:40,690] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142000, global step 2274000: learning rate 0.0000
[2019-03-23 20:36:41,071] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142000, global step 2274201: loss 12.5423
[2019-03-23 20:36:41,076] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142000, global step 2274201: learning rate 0.0000
[2019-03-23 20:36:41,083] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142000, global step 2274205: loss 0.1106
[2019-03-23 20:36:41,086] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142000, global step 2274205: learning rate 0.0000
[2019-03-23 20:36:41,128] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142000, global step 2274227: loss 1.9566
[2019-03-23 20:36:41,130] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142000, global step 2274228: learning rate 0.0000
[2019-03-23 20:36:41,142] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142000, global step 2274236: loss 2.2428
[2019-03-23 20:36:41,144] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142000, global step 2274237: learning rate 0.0000
[2019-03-23 20:36:41,153] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142500, global step 2274241: loss 3.3615
[2019-03-23 20:36:41,155] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142500, global step 2274242: learning rate 0.0000
[2019-03-23 20:36:41,276] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142000, global step 2274307: loss 5.3853
[2019-03-23 20:36:41,277] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142000, global step 2274308: learning rate 0.0000
[2019-03-23 20:36:41,600] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142000, global step 2274477: loss -0.6301
[2019-03-23 20:36:41,601] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142000, global step 2274478: learning rate 0.0000
[2019-03-23 20:36:41,642] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142000, global step 2274499: loss 0.2783
[2019-03-23 20:36:41,644] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142000, global step 2274499: learning rate 0.0000
[2019-03-23 20:36:41,803] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142000, global step 2274583: loss 0.1354
[2019-03-23 20:36:41,804] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142000, global step 2274583: learning rate 0.0000
[2019-03-23 20:36:42,146] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142000, global step 2274766: loss 0.0359
[2019-03-23 20:36:42,148] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142000, global step 2274766: learning rate 0.0000
[2019-03-23 20:36:42,591] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 20:36:42,593] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:36:42,594] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:36:42,595] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:36:42,596] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:36:42,596] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:36:42,597] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:36:42,601] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:36:42,603] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:36:42,603] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:36:42,605] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:36:42,623] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run92
[2019-03-23 20:36:42,651] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run92
[2019-03-23 20:36:42,676] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run92
[2019-03-23 20:36:42,702] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run92
[2019-03-23 20:36:42,726] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run92
[2019-03-23 20:36:58,536] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00125384], dtype=float32), 0.0172605]
[2019-03-23 20:36:58,537] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.33333333333334, 98.0, 1.0, 2.0, 0.2080842218353932, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4140146849845132, 6.911200000000001, 6.9112, 77.32846344354104, 472615.6318123002, 472615.6318123, 164123.5571831574]
[2019-03-23 20:36:58,539] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:36:58,542] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.9098923e-03 6.1154082e-11 9.9809009e-01 9.7685561e-11 5.4912797e-10], sampled 0.9564903303880932
[2019-03-23 20:37:02,854] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00125384], dtype=float32), 0.0172605]
[2019-03-23 20:37:02,856] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.5, 49.0, 1.0, 2.0, 0.2115938366175185, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4146646532655724, 6.911200000000001, 6.9112, 95.55338769695034, 476156.8141559502, 476156.8141559498, 166175.7492758741]
[2019-03-23 20:37:02,857] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:37:02,862] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.84891645e-03 4.73538656e-12 9.97151077e-01 5.11911867e-12
 1.19126185e-11], sampled 0.5385875592684438
[2019-03-23 20:37:30,055] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00125384], dtype=float32), 0.0172605]
[2019-03-23 20:37:30,057] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.70985634333334, 69.77584146, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 95.55338769695034, 327693.5597152052, 327693.5597152056, 145765.5038392394]
[2019-03-23 20:37:30,058] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:37:30,061] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.7489776e-03 9.7438536e-11 9.9825102e-01 9.9600932e-11 2.0495496e-10], sampled 0.7218526034102194
[2019-03-23 20:37:36,290] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00125384], dtype=float32), 0.0172605]
[2019-03-23 20:37:36,290] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [28.521138805, 46.08660537833333, 1.0, 2.0, 0.3168682927321664, 1.0, 1.0, 0.3168682927321664, 1.0, 2.0, 0.6408904464899036, 6.911199999999999, 6.9112, 95.55333058427092, 1084228.171509956, 1084228.171509956, 268179.2251742065]
[2019-03-23 20:37:36,294] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:37:36,299] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.5639322e-03 3.0308283e-06 4.6546984e-01 6.0580340e-05 5.2790260e-01], sampled 0.02672444299557697
[2019-03-23 20:37:48,977] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00125384], dtype=float32), 0.0172605]
[2019-03-23 20:37:48,979] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.1, 54.0, 1.0, 2.0, 0.211496508654703, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4220498942168807, 6.911199999999999, 6.9112, 77.32846344354104, 481082.5325723201, 481082.5325723204, 165487.3387170761]
[2019-03-23 20:37:48,980] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:37:48,983] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.1417700e-03 3.3080379e-12 9.9785823e-01 3.1411406e-12 4.1311095e-12], sampled 0.31914141847180477
[2019-03-23 20:37:57,977] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00125384], dtype=float32), 0.0172605]
[2019-03-23 20:37:57,978] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.63081094, 88.06593735, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 95.55338769695034, 318040.4501705606, 318040.4501705609, 137907.8648383953]
[2019-03-23 20:37:57,981] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:37:57,984] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.7324637e-03 1.1764918e-10 9.9826753e-01 1.3976971e-10 3.9305473e-10], sampled 0.016996275301078945
[2019-03-23 20:38:10,359] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00125384], dtype=float32), 0.0172605]
[2019-03-23 20:38:10,361] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.16666666666667, 63.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3779897030417523, 6.9112, 6.9112, 95.55338769695034, 433252.3292849524, 433252.3292849524, 163045.6694926524]
[2019-03-23 20:38:10,365] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:38:10,368] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.7510136e-03 3.8369832e-12 9.9824905e-01 3.2208806e-12 3.5532215e-12], sampled 0.7947458069428516
[2019-03-23 20:38:10,581] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00125384], dtype=float32), 0.0172605]
[2019-03-23 20:38:10,581] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.42669175666667, 66.04847632, 1.0, 2.0, 0.2253048452720066, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4522294784567564, 6.9112, 6.9112, 95.55338769695034, 513667.5794311919, 513667.5794311919, 174539.6672579091]
[2019-03-23 20:38:10,584] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:38:10,587] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.0290597e-03 1.6611323e-12 9.9797088e-01 1.6237606e-12 2.4751741e-12], sampled 0.48899491978900267
[2019-03-23 20:38:23,419] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3364.6015 2097556892.4468 141.0000
[2019-03-23 20:38:23,903] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3540.1064 2187250078.9760 156.0000
[2019-03-23 20:38:24,004] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3538.2591 2103776480.6532 120.0000
[2019-03-23 20:38:24,153] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2812.0871 2128315513.0123 500.0000
[2019-03-23 20:38:24,213] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3139.2317 2110696641.8449 238.0000
[2019-03-23 20:38:25,232] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 2275000, evaluation results [2275000.0, 3540.106377962017, 2187250078.9760427, 156.0, 3364.601506351973, 2097556892.4467747, 141.0, 3538.2590736791094, 2103776480.6532376, 120.0, 2812.087141292041, 2128315513.0123498, 500.0, 3139.231720045319, 2110696641.8448758, 238.0]
[2019-03-23 20:38:29,613] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142500, global step 2277185: loss 0.4290
[2019-03-23 20:38:29,618] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142500, global step 2277185: learning rate 0.0000
[2019-03-23 20:38:30,646] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.5152391e-01 6.2757344e-10 7.4839056e-01 1.9128029e-08 8.5476371e-05], sum to 1.0000
[2019-03-23 20:38:30,653] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8838
[2019-03-23 20:38:30,657] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.9, 45.83333333333333, 1.0, 2.0, 0.2871212598486768, 0.0, 2.0, 0.0, 1.0, 1.0, 0.553796189609059, 6.9112, 6.9112, 77.32846344354094, 639104.3899071787, 639104.3899071787, 173096.1671230024], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5838600.0000, 
sim time next is 5839200.0000, 
raw observation next is [25.0, 45.0, 1.0, 2.0, 0.2986536119215136, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5758711692721517, 6.9112, 6.9112, 77.32846344354104, 664648.931562071, 664648.931562071, 175610.5618675467], 
processed observation next is [1.0, 0.6086956521739131, 0.7727272727272727, 0.45, 1.0, 1.0, 0.12331701490189195, 0.0, 1.0, -0.25, 1.0, 1.0, 0.39410167038878813, 0.0, 0.0, 0.5084288129206541, 0.24616627094891516, 0.24616627094891516, 0.4283184435793822], 
reward next is 0.5717, 
noisyNet noise sample is [array([-1.680901], dtype=float32), -0.013044793]. 
=============================================
[2019-03-23 20:38:33,106] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142500, global step 2278915: loss -4.9771
[2019-03-23 20:38:33,114] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142500, global step 2278915: learning rate 0.0000
[2019-03-23 20:38:35,147] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142500, global step 2279943: loss -49.6088
[2019-03-23 20:38:35,148] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142500, global step 2279943: learning rate 0.0000
[2019-03-23 20:38:35,669] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143500, global step 2280201: loss 19.0945
[2019-03-23 20:38:35,672] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143500, global step 2280201: learning rate 0.0000
[2019-03-23 20:38:39,054] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142500, global step 2281879: loss 14.9568
[2019-03-23 20:38:39,056] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142500, global step 2281880: learning rate 0.0000
[2019-03-23 20:38:39,345] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142500, global step 2282026: loss 41.3658
[2019-03-23 20:38:39,351] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142500, global step 2282026: learning rate 0.0000
[2019-03-23 20:38:39,688] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142500, global step 2282201: loss 30.5447
[2019-03-23 20:38:39,691] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142500, global step 2282201: learning rate 0.0000
[2019-03-23 20:38:39,696] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142500, global step 2282202: loss 1.3228
[2019-03-23 20:38:39,698] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142500, global step 2282202: learning rate 0.0000
[2019-03-23 20:38:39,724] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142500, global step 2282217: loss -22.1114
[2019-03-23 20:38:39,730] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142500, global step 2282218: learning rate 0.0000
[2019-03-23 20:38:39,732] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142500, global step 2282220: loss 13.4835
[2019-03-23 20:38:39,735] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142500, global step 2282221: learning rate 0.0000
[2019-03-23 20:38:39,920] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142500, global step 2282312: loss 17.9567
[2019-03-23 20:38:39,922] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142500, global step 2282313: learning rate 0.0000
[2019-03-23 20:38:40,122] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143000, global step 2282415: loss 214.3981
[2019-03-23 20:38:40,125] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143000, global step 2282415: learning rate 0.0000
[2019-03-23 20:38:40,284] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142500, global step 2282473: loss 34.6331
[2019-03-23 20:38:40,285] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142500, global step 2282473: learning rate 0.0000
[2019-03-23 20:38:40,348] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142500, global step 2282509: loss -26.9039
[2019-03-23 20:38:40,351] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142500, global step 2282510: learning rate 0.0000
[2019-03-23 20:38:40,409] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142500, global step 2282534: loss 144.1346
[2019-03-23 20:38:40,411] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142500, global step 2282534: learning rate 0.0000
[2019-03-23 20:38:40,597] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142500, global step 2282629: loss 22.9254
[2019-03-23 20:38:40,600] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142500, global step 2282630: learning rate 0.0000
[2019-03-23 20:38:42,068] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.6851706e-28 4.0239080e-08 1.9658119e-26 4.2385524e-22], sum to 1.0000
[2019-03-23 20:38:42,076] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1954
[2019-03-23 20:38:42,081] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.0, 79.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5070316390372303, 6.9112, 6.9112, 77.32846344354104, 294916.2415608171, 294916.2415608171, 84933.07058017876], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6055800.0000, 
sim time next is 6056400.0000, 
raw observation next is [15.9, 79.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4707508318705108, 6.911199999999999, 6.9112, 77.32846344354104, 273807.4774870933, 273807.4774870936, 81934.11472985263], 
processed observation next is [1.0, 0.08695652173913043, 0.3590909090909091, 0.7933333333333334, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.24392975981501547, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1014101768470716, 0.1014101768470717, 0.19983930421915277], 
reward next is 0.8002, 
noisyNet noise sample is [array([0.35046515], dtype=float32), -0.87058026]. 
=============================================
[2019-03-23 20:38:46,034] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143000, global step 2285344: loss 14.1658
[2019-03-23 20:38:46,036] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143000, global step 2285345: learning rate 0.0000
[2019-03-23 20:38:49,427] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143000, global step 2287029: loss 87.4313
[2019-03-23 20:38:49,433] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143000, global step 2287029: learning rate 0.0000
[2019-03-23 20:38:51,527] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143000, global step 2288074: loss -1.1599
[2019-03-23 20:38:51,529] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143000, global step 2288074: learning rate 0.0000
[2019-03-23 20:38:51,661] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144000, global step 2288143: loss -4.5135
[2019-03-23 20:38:51,664] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144000, global step 2288144: learning rate 0.0000
[2019-03-23 20:38:51,898] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.2710103e-01 5.3144815e-13 7.7289897e-01 7.3275603e-13 4.9631066e-10], sum to 1.0000
[2019-03-23 20:38:51,905] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7191
[2019-03-23 20:38:51,910] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.03333333333333, 89.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.351184254231582, 6.9112, 6.9112, 77.32846344354104, 403893.6751028196, 403893.6751028196, 153763.203823881], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6244800.0000, 
sim time next is 6245400.0000, 
raw observation next is [19.21666666666667, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3526463032340554, 6.9112, 6.9112, 77.32846344354104, 405438.4012196095, 405438.4012196095, 154070.8626857996], 
processed observation next is [0.0, 0.2608695652173913, 0.5098484848484849, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.07520900462007914, 0.0, 0.0, 0.5084288129206541, 0.1501623708220776, 0.1501623708220776, 0.37578259191658436], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1973305], dtype=float32), -1.0382907]. 
=============================================
[2019-03-23 20:38:54,959] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143000, global step 2289783: loss 45.4725
[2019-03-23 20:38:54,962] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143000, global step 2289783: learning rate 0.0000
[2019-03-23 20:38:55,297] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143000, global step 2289951: loss -69.4857
[2019-03-23 20:38:55,299] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143000, global step 2289952: learning rate 0.0000
[2019-03-23 20:38:55,566] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143000, global step 2290080: loss 47.8286
[2019-03-23 20:38:55,571] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143000, global step 2290080: learning rate 0.0000
[2019-03-23 20:38:55,681] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143000, global step 2290119: loss -102.7163
[2019-03-23 20:38:55,684] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143000, global step 2290119: learning rate 0.0000
[2019-03-23 20:38:55,715] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143000, global step 2290135: loss 123.0832
[2019-03-23 20:38:55,717] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143000, global step 2290135: learning rate 0.0000
[2019-03-23 20:38:55,774] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143000, global step 2290167: loss 19.3199
[2019-03-23 20:38:55,776] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143000, global step 2290168: learning rate 0.0000
[2019-03-23 20:38:55,957] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143000, global step 2290257: loss 16.4626
[2019-03-23 20:38:55,961] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143000, global step 2290258: learning rate 0.0000
[2019-03-23 20:38:56,203] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143000, global step 2290373: loss 71.7604
[2019-03-23 20:38:56,205] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143000, global step 2290373: learning rate 0.0000
[2019-03-23 20:38:56,309] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143000, global step 2290428: loss 3.8978
[2019-03-23 20:38:56,313] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143000, global step 2290431: learning rate 0.0000
[2019-03-23 20:38:56,489] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143000, global step 2290517: loss 5.1326
[2019-03-23 20:38:56,492] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143000, global step 2290517: learning rate 0.0000
[2019-03-23 20:38:56,594] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143500, global step 2290569: loss -1.6522
[2019-03-23 20:38:56,598] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143500, global step 2290570: learning rate 0.0000
[2019-03-23 20:38:56,601] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143000, global step 2290571: loss 3.6304
[2019-03-23 20:38:56,603] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143000, global step 2290572: learning rate 0.0000
[2019-03-23 20:39:01,264] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.1600442e-01 2.9926210e-15 8.3989583e-02 7.9082807e-13 6.0507909e-06], sum to 1.0000
[2019-03-23 20:39:01,274] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2742
[2019-03-23 20:39:01,275] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 643502.7400136221 W.
[2019-03-23 20:39:01,279] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.4, 74.0, 1.0, 2.0, 0.5639446575572044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 643502.7400136221, 643502.7400136221, 149153.5477000428], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6404400.0000, 
sim time next is 6405000.0000, 
raw observation next is [24.5, 73.0, 1.0, 2.0, 0.3084619433522891, 0.0, 2.0, 0.0, 1.0, 1.0, 0.6232024681998585, 6.9112, 6.9112, 77.32846344354104, 703901.6255805556, 703901.6255805556, 193053.1674494653], 
processed observation next is [1.0, 0.13043478260869565, 0.75, 0.73, 1.0, 1.0, 0.13557742919036136, 0.0, 1.0, -0.25, 1.0, 0.5, 0.4617178117140836, 0.0, 0.0, 0.5084288129206541, 0.2607043057705762, 0.2607043057705762, 0.47086138402308614], 
reward next is 0.5291, 
noisyNet noise sample is [array([0.05405214], dtype=float32), 0.84306836]. 
=============================================
[2019-03-23 20:39:01,293] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[51.250786]
 [51.378498]
 [51.7549  ]
 [51.84485 ]
 [51.462387]], R is [[51.59246063]
 [51.71274948]
 [51.19562149]
 [51.22525024]
 [51.2362709 ]].
[2019-03-23 20:39:02,164] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143500, global step 2293356: loss 42.1473
[2019-03-23 20:39:02,165] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143500, global step 2293356: learning rate 0.0000
[2019-03-23 20:39:05,188] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9998999e-01 1.1408525e-31 9.9828567e-06 9.2303902e-30 2.7031099e-27], sum to 1.0000
[2019-03-23 20:39:05,199] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1848
[2019-03-23 20:39:05,203] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.5, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4077830437484433, 6.911199999999999, 6.9112, 77.32846344354104, 237173.9682709924, 237173.9682709927, 71291.90941153748], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6474600.0000, 
sim time next is 6475200.0000, 
raw observation next is [15.5, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4077743493490437, 6.911199999999999, 6.9112, 77.32846344354104, 237168.910218711, 237168.9102187113, 71276.46334344674], 
processed observation next is [1.0, 0.9565217391304348, 0.3409090909090909, 0.75, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.15396335621291962, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08784033711804111, 0.08784033711804122, 0.17384503254499203], 
reward next is 0.8262, 
noisyNet noise sample is [array([-0.44527492], dtype=float32), 1.7551495]. 
=============================================
[2019-03-23 20:39:05,486] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143500, global step 2295099: loss -40.6409
[2019-03-23 20:39:05,488] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143500, global step 2295099: learning rate 0.0000
[2019-03-23 20:39:07,306] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143500, global step 2296050: loss -6.5066
[2019-03-23 20:39:07,309] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143500, global step 2296050: learning rate 0.0000
[2019-03-23 20:39:07,378] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144500, global step 2296087: loss 3.6403
[2019-03-23 20:39:07,382] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144500, global step 2296088: learning rate 0.0000
[2019-03-23 20:39:08,930] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9963737e-01 1.4205652e-30 3.6261597e-04 1.6266953e-27 1.3164553e-25], sum to 1.0000
[2019-03-23 20:39:08,939] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6363
[2019-03-23 20:39:08,942] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.8, 60.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4634131936911782, 6.9112, 6.9112, 77.32846344354104, 269538.4315569062, 269538.4315569062, 78031.48070175761], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6558600.0000, 
sim time next is 6559200.0000, 
raw observation next is [17.7, 61.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4626845629956407, 6.911199999999999, 6.9112, 77.32846344354104, 269114.5154653548, 269114.5154653551, 77826.90931592752], 
processed observation next is [1.0, 0.9565217391304348, 0.44090909090909086, 0.61, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.23240651856520103, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09967204276494622, 0.09967204276494634, 0.1898217300388476], 
reward next is 0.8102, 
noisyNet noise sample is [array([1.5859793], dtype=float32), -1.9876943]. 
=============================================
[2019-03-23 20:39:10,563] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143500, global step 2297766: loss -53.1073
[2019-03-23 20:39:10,568] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143500, global step 2297767: learning rate 0.0000
[2019-03-23 20:39:10,731] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143500, global step 2297848: loss 0.7008
[2019-03-23 20:39:10,734] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143500, global step 2297848: learning rate 0.0000
[2019-03-23 20:39:11,222] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143500, global step 2298083: loss -4.4439
[2019-03-23 20:39:11,225] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143500, global step 2298083: learning rate 0.0000
[2019-03-23 20:39:11,373] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143500, global step 2298163: loss -68.3430
[2019-03-23 20:39:11,374] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143500, global step 2298163: learning rate 0.0000
[2019-03-23 20:39:11,381] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143500, global step 2298166: loss 0.1328
[2019-03-23 20:39:11,381] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143500, global step 2298166: learning rate 0.0000
[2019-03-23 20:39:11,601] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143500, global step 2298280: loss -11.4298
[2019-03-23 20:39:11,605] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143500, global step 2298281: learning rate 0.0000
[2019-03-23 20:39:11,699] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143500, global step 2298329: loss 1.1224
[2019-03-23 20:39:11,702] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143500, global step 2298331: learning rate 0.0000
[2019-03-23 20:39:11,766] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143500, global step 2298369: loss 1.2284
[2019-03-23 20:39:11,768] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143500, global step 2298369: learning rate 0.0000
[2019-03-23 20:39:12,002] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143500, global step 2298491: loss 1.4131
[2019-03-23 20:39:12,005] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143500, global step 2298491: learning rate 0.0000
[2019-03-23 20:39:12,229] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143500, global step 2298614: loss 0.2840
[2019-03-23 20:39:12,233] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143500, global step 2298616: learning rate 0.0000
[2019-03-23 20:39:12,267] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143500, global step 2298631: loss -106.3232
[2019-03-23 20:39:12,271] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143500, global step 2298632: learning rate 0.0000
[2019-03-23 20:39:12,271] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144000, global step 2298633: loss 94.7327
[2019-03-23 20:39:12,278] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144000, global step 2298636: learning rate 0.0000
[2019-03-23 20:39:13,471] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.7501603e-01 1.3971572e-15 1.2498395e-01 5.0246244e-15 4.5178281e-11], sum to 1.0000
[2019-03-23 20:39:13,477] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1314
[2019-03-23 20:39:13,481] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.8, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3399815244420763, 6.9112, 6.9112, 77.32846344354104, 391934.4890670407, 391934.4890670407, 151511.7200311602], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6648000.0000, 
sim time next is 6648600.0000, 
raw observation next is [18.8, 87.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6763493786430554, 6.911199999999999, 6.9112, 77.32846344354104, 390179.9906920817, 390179.990692082, 122602.728158386], 
processed observation next is [1.0, 0.9565217391304348, 0.49090909090909096, 0.87, 0.0, 0.5, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5376419694900793, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14451110766373396, 0.14451110766373407, 0.29903104428874633], 
reward next is 0.7010, 
noisyNet noise sample is [array([1.3792745], dtype=float32), -1.338765]. 
=============================================
[2019-03-23 20:39:14,898] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 20:39:14,901] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:39:14,905] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:39:14,905] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:39:14,906] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:39:14,908] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:39:14,908] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:39:14,906] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:39:14,910] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:39:14,910] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:39:14,911] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:39:14,938] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run93
[2019-03-23 20:39:14,965] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run93
[2019-03-23 20:39:14,988] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run93
[2019-03-23 20:39:14,989] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run93
[2019-03-23 20:39:15,014] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run93
[2019-03-23 20:40:22,727] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00159737], dtype=float32), 0.017548032]
[2019-03-23 20:40:22,729] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.92816165, 88.18446138333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 279464.0673265736, 279464.0673265732, 113180.769405045]
[2019-03-23 20:40:22,729] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:40:22,732] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.6912640e-03 1.7186561e-18 9.9630874e-01 8.4592597e-19 8.2399489e-18], sampled 0.8458143663214738
[2019-03-23 20:40:23,743] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00159737], dtype=float32), 0.017548032]
[2019-03-23 20:40:23,745] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.4, 63.5, 1.0, 2.0, 0.3048700440704644, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6138954902180205, 6.911199999999999, 6.9112, 95.55338769695034, 695700.7950985812, 695700.7950985816, 195010.9167479452]
[2019-03-23 20:40:23,746] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:40:23,749] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.0250087e-03 7.8092118e-15 9.9797505e-01 2.7495611e-14 2.1140638e-11], sampled 0.5943171063003476
[2019-03-23 20:40:42,130] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00159737], dtype=float32), 0.017548032]
[2019-03-23 20:40:42,131] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.86666666666667, 55.33333333333334, 1.0, 2.0, 0.2303621317254826, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4634261880472906, 6.911200000000001, 6.9112, 95.55338769695034, 525516.1599325989, 525516.1599325986, 176378.1720737834]
[2019-03-23 20:40:42,132] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:40:42,134] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.5833131e-03 2.4464251e-18 9.9541664e-01 1.7258512e-18 3.2400863e-17], sampled 0.5502247939033249
[2019-03-23 20:40:55,618] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3618.6566 2173734236.4702 264.0000
[2019-03-23 20:40:55,786] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3532.0404 2101149441.0687 207.0000
[2019-03-23 20:40:56,050] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2800.5769 2120589658.5239 784.0000
[2019-03-23 20:40:56,069] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3156.4575 2106359961.7992 384.0000
[2019-03-23 20:40:56,176] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3392.3468 2094167916.1901 222.0000
[2019-03-23 20:40:57,193] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2300000, evaluation results [2300000.0, 3618.6566287971555, 2173734236.4701657, 264.0, 3392.3468349126424, 2094167916.190069, 222.0, 3532.040434322756, 2101149441.068739, 207.0, 2800.5769264322053, 2120589658.523908, 784.0, 3156.4574566372257, 2106359961.7992392, 384.0]
[2019-03-23 20:40:57,953] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.8270532e-05 1.2223965e-13 9.9994171e-01 1.6758926e-13 7.0559708e-10], sum to 1.0000
[2019-03-23 20:40:57,961] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9983
[2019-03-23 20:40:57,968] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.4, 85.5, 1.0, 2.0, 0.2635646390268545, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5147519338746577, 6.911200000000001, 6.9112, 77.32846344354104, 591870.8707937099, 591870.8707937095, 170745.6440475016], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6683400.0000, 
sim time next is 6684000.0000, 
raw observation next is [19.6, 84.0, 1.0, 2.0, 0.2905121648230048, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5679516571126031, 6.9112, 6.9112, 77.32846344354104, 652872.170784082, 652872.170784082, 176949.4926144722], 
processed observation next is [1.0, 0.34782608695652173, 0.5272727272727273, 0.84, 1.0, 1.0, 0.11314020602875598, 0.0, 1.0, -0.25, 1.0, 1.0, 0.382788081589433, 0.0, 0.0, 0.5084288129206541, 0.24180450769780815, 0.24180450769780815, 0.431584128327981], 
reward next is 0.5684, 
noisyNet noise sample is [array([-0.6094087], dtype=float32), 0.10229935]. 
=============================================
[2019-03-23 20:40:57,993] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[22.07746 ]
 [20.165209]
 [18.897116]
 [18.115702]
 [18.16596 ]], R is [[24.42053604]
 [24.75987816]
 [25.10982132]
 [25.46683502]
 [25.21216774]].
[2019-03-23 20:40:59,926] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144000, global step 2301366: loss 0.0981
[2019-03-23 20:40:59,931] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144000, global step 2301366: learning rate 0.0000
[2019-03-23 20:41:00,561] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.4355408e-03 5.6817221e-18 9.9456441e-01 6.9742029e-18 1.7170951e-17], sum to 1.0000
[2019-03-23 20:41:00,570] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0642
[2019-03-23 20:41:00,575] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.71666666666667, 66.83333333333333, 1.0, 2.0, 0.2200759133399955, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4424221384807523, 6.911199999999999, 6.9112, 77.32846344354104, 502010.8422707381, 502010.8422707384, 169335.4320087167], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6864600.0000, 
sim time next is 6865200.0000, 
raw observation next is [25.0, 66.0, 1.0, 2.0, 0.2225506414364119, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4478346397685298, 6.911199999999999, 6.9112, 77.32846344354104, 507766.5232200219, 507766.5232200222, 170183.8178468283], 
processed observation next is [0.0, 0.4782608695652174, 0.7727272727272727, 0.66, 1.0, 1.0, 0.02818830179551486, 0.0, 1.0, -0.25, 1.0, 1.0, 0.21119234252647112, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18806167526667478, 0.1880616752666749, 0.4150824825532397], 
reward next is 0.5849, 
noisyNet noise sample is [array([-0.2593257], dtype=float32), 0.39571485]. 
=============================================
[2019-03-23 20:41:03,059] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144000, global step 2302932: loss 0.5724
[2019-03-23 20:41:03,061] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144000, global step 2302932: learning rate 0.0000
[2019-03-23 20:41:05,153] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145000, global step 2303955: loss -1.2594
[2019-03-23 20:41:05,155] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145000, global step 2303956: learning rate 0.0000
[2019-03-23 20:41:05,394] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144000, global step 2304077: loss 0.3213
[2019-03-23 20:41:05,396] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144000, global step 2304077: learning rate 0.0000
[2019-03-23 20:41:08,538] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144000, global step 2305639: loss 2.1473
[2019-03-23 20:41:08,543] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144000, global step 2305639: learning rate 0.0000
[2019-03-23 20:41:09,058] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144000, global step 2305896: loss 4.4267
[2019-03-23 20:41:09,061] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144000, global step 2305897: learning rate 0.0000
[2019-03-23 20:41:09,419] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144000, global step 2306075: loss 3.1026
[2019-03-23 20:41:09,425] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144000, global step 2306078: learning rate 0.0000
[2019-03-23 20:41:09,702] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144000, global step 2306216: loss 4.8107
[2019-03-23 20:41:09,704] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144000, global step 2306216: learning rate 0.0000
[2019-03-23 20:41:09,737] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144000, global step 2306235: loss 3.7201
[2019-03-23 20:41:09,739] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144000, global step 2306236: learning rate 0.0000
[2019-03-23 20:41:09,763] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144000, global step 2306245: loss 2.6762
[2019-03-23 20:41:09,766] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144000, global step 2306245: learning rate 0.0000
[2019-03-23 20:41:09,955] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144000, global step 2306341: loss 3.9811
[2019-03-23 20:41:09,957] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144000, global step 2306343: learning rate 0.0000
[2019-03-23 20:41:10,207] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144000, global step 2306469: loss 3.5254
[2019-03-23 20:41:10,209] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144000, global step 2306469: learning rate 0.0000
[2019-03-23 20:41:10,268] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144000, global step 2306499: loss 3.4174
[2019-03-23 20:41:10,270] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144000, global step 2306500: learning rate 0.0000
[2019-03-23 20:41:10,347] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144000, global step 2306541: loss 3.2692
[2019-03-23 20:41:10,351] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144000, global step 2306543: learning rate 0.0000
[2019-03-23 20:41:10,542] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144500, global step 2306634: loss 0.5352
[2019-03-23 20:41:10,545] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144500, global step 2306635: learning rate 0.0000
[2019-03-23 20:41:10,581] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144000, global step 2306656: loss 2.3381
[2019-03-23 20:41:10,586] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144000, global step 2306656: learning rate 0.0000
[2019-03-23 20:41:13,001] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.8907640e-02 2.7682486e-18 9.7109228e-01 2.6103626e-15 2.1471012e-09], sum to 1.0000
[2019-03-23 20:41:13,009] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9230
[2019-03-23 20:41:13,016] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.65, 63.5, 1.0, 2.0, 0.250723885411994, 0.0, 2.0, 0.0, 1.0, 2.0, 0.507382755469927, 6.911200000000001, 6.9112, 77.32846344354104, 571468.5111008195, 571468.5111008191, 179295.2621591041], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6978600.0000, 
sim time next is 6979200.0000, 
raw observation next is [26.46666666666667, 64.66666666666667, 1.0, 2.0, 0.2516826175436699, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5093575033961699, 6.9112, 6.9112, 77.32846344354104, 573608.2145826642, 573608.2145826642, 179583.8732211676], 
processed observation next is [0.0, 0.782608695652174, 0.8393939393939395, 0.6466666666666667, 1.0, 1.0, 0.06460327192958734, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2990821477088142, 0.0, 0.0, 0.5084288129206541, 0.21244748688246823, 0.21244748688246823, 0.4380094468808966], 
reward next is 0.5620, 
noisyNet noise sample is [array([-0.7970464], dtype=float32), -1.1829565]. 
=============================================
[2019-03-23 20:41:16,042] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144500, global step 2309385: loss 0.2899
[2019-03-23 20:41:16,044] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144500, global step 2309385: learning rate 0.0000
[2019-03-23 20:41:17,006] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.5901877e-04 2.4576909e-13 9.9904090e-01 4.1722632e-12 1.6275617e-08], sum to 1.0000
[2019-03-23 20:41:17,014] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1854
[2019-03-23 20:41:17,021] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.2, 86.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3575601101367117, 6.911199999999999, 6.9112, 77.32846344354104, 411601.8235565195, 411601.8235565198, 154206.6320192008], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7068000.0000, 
sim time next is 7068600.0000, 
raw observation next is [19.1, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3565012162458352, 6.9112, 6.9112, 77.32846344354104, 410338.2200919918, 410338.2200919918, 154117.0341375276], 
processed observation next is [1.0, 0.8260869565217391, 0.5045454545454546, 0.87, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.08071602320833601, 0.0, 0.0, 0.5084288129206541, 0.15197711855258955, 0.15197711855258955, 0.37589520521348196], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.50862634], dtype=float32), -0.8696537]. 
=============================================
[2019-03-23 20:41:19,163] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144500, global step 2310919: loss 0.9145
[2019-03-23 20:41:19,165] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144500, global step 2310920: learning rate 0.0000
[2019-03-23 20:41:21,269] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145500, global step 2311966: loss 0.4708
[2019-03-23 20:41:21,270] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145500, global step 2311966: learning rate 0.0000
[2019-03-23 20:41:21,469] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144500, global step 2312065: loss -2.6872
[2019-03-23 20:41:21,472] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144500, global step 2312067: learning rate 0.0000
[2019-03-23 20:41:24,379] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.8164073e-06 1.4256952e-12 9.9999416e-01 2.2387576e-12 5.7872943e-11], sum to 1.0000
[2019-03-23 20:41:24,386] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1356
[2019-03-23 20:41:24,391] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.8, 69.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 300781.3607968719, 300781.3607968719, 127638.3829384851], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7869000.0000, 
sim time next is 7869600.0000, 
raw observation next is [18.8, 70.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 301589.8141356527, 301589.8141356524, 128547.1695239117], 
processed observation next is [1.0, 0.08695652173913043, 0.49090909090909096, 0.7, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11169993116135284, 0.11169993116135274, 0.3135296817656383], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5461216], dtype=float32), -1.0018767]. 
=============================================
[2019-03-23 20:41:24,722] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144500, global step 2313699: loss -0.1232
[2019-03-23 20:41:24,723] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144500, global step 2313699: learning rate 0.0000
[2019-03-23 20:41:25,131] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144500, global step 2313903: loss -0.6667
[2019-03-23 20:41:25,132] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144500, global step 2313903: learning rate 0.0000
[2019-03-23 20:41:25,425] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144500, global step 2314049: loss -1.7729
[2019-03-23 20:41:25,427] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144500, global step 2314050: learning rate 0.0000
[2019-03-23 20:41:25,722] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144500, global step 2314201: loss 0.0334
[2019-03-23 20:41:25,723] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144500, global step 2314201: learning rate 0.0000
[2019-03-23 20:41:25,745] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144500, global step 2314211: loss -0.3827
[2019-03-23 20:41:25,746] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144500, global step 2314212: learning rate 0.0000
[2019-03-23 20:41:25,851] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144500, global step 2314265: loss -0.2276
[2019-03-23 20:41:25,860] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144500, global step 2314265: learning rate 0.0000
[2019-03-23 20:41:25,943] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144500, global step 2314312: loss 0.1311
[2019-03-23 20:41:25,944] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144500, global step 2314312: learning rate 0.0000
[2019-03-23 20:41:26,143] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144500, global step 2314415: loss -3.5176
[2019-03-23 20:41:26,145] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144500, global step 2314415: learning rate 0.0000
[2019-03-23 20:41:26,346] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144500, global step 2314517: loss -0.6188
[2019-03-23 20:41:26,349] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144500, global step 2314518: learning rate 0.0000
[2019-03-23 20:41:26,555] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144500, global step 2314622: loss -0.4564
[2019-03-23 20:41:26,556] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144500, global step 2314622: learning rate 0.0000
[2019-03-23 20:41:26,610] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144500, global step 2314648: loss -0.0097
[2019-03-23 20:41:26,613] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144500, global step 2314648: learning rate 0.0000
[2019-03-23 20:41:26,624] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145000, global step 2314654: loss 0.5243
[2019-03-23 20:41:26,626] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145000, global step 2314655: learning rate 0.0000
[2019-03-23 20:41:28,722] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.6464602e-04 8.1784018e-10 9.9973530e-01 5.0905469e-10 2.5270428e-08], sum to 1.0000
[2019-03-23 20:41:28,727] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5407
[2019-03-23 20:41:28,731] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 71.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 288151.1806368668, 288151.1806368671, 118107.0365190645], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7255800.0000, 
sim time next is 7256400.0000, 
raw observation next is [17.9, 72.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 289176.0419766118, 289176.0419766121, 118863.3903401145], 
processed observation next is [1.0, 1.0, 0.44999999999999996, 0.7266666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1071022377691155, 0.1071022377691156, 0.28991070814662073], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9026271], dtype=float32), -0.07950683]. 
=============================================
[2019-03-23 20:41:29,602] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:41:29,602] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:41:29,675] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run12
[2019-03-23 20:41:31,857] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.3600029e-04 7.1943467e-12 9.9956399e-01 5.5096750e-11 6.5590759e-09], sum to 1.0000
[2019-03-23 20:41:31,864] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4883
[2019-03-23 20:41:31,871] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.25, 52.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3177040616702103, 6.911199999999999, 6.9112, 77.32846344354104, 367440.421778662, 367440.4217786622, 147703.5744473062], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7327800.0000, 
sim time next is 7328400.0000, 
raw observation next is [23.06666666666667, 53.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3162317493903247, 6.9112, 6.9112, 77.32846344354104, 365784.8711838225, 365784.8711838225, 147488.9276071163], 
processed observation next is [1.0, 0.8260869565217391, 0.684848484848485, 0.5333333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.023188213414749623, 0.0, 0.0, 0.5084288129206541, 0.13547587821623056, 0.13547587821623056, 0.3597290917246739], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.8115706], dtype=float32), 0.078442246]. 
=============================================
[2019-03-23 20:41:31,885] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145000, global step 2317267: loss 1.9308
[2019-03-23 20:41:31,889] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145000, global step 2317267: learning rate 0.0000
[2019-03-23 20:41:34,085] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5941405e-04 1.6020876e-09 9.9978501e-01 2.8629689e-08 5.5545937e-05], sum to 1.0000
[2019-03-23 20:41:34,092] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1326
[2019-03-23 20:41:34,095] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.7, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3038637972534539, 6.911199999999999, 6.9112, 77.32846344354104, 352277.3672893281, 352277.3672893284, 145274.6785533094], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7365600.0000, 
sim time next is 7366200.0000, 
raw observation next is [17.8, 86.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3124628214731132, 6.911199999999999, 6.9112, 77.32846344354104, 362186.8585258073, 362186.8585258076, 146280.9997182422], 
processed observation next is [1.0, 0.2608695652173913, 0.4454545454545455, 0.865, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.01780403067587604, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1341432809354842, 0.1341432809354843, 0.35678292614205415], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.2685016], dtype=float32), -0.8921544]. 
=============================================
[2019-03-23 20:41:34,302] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5672851e-05 1.9650480e-08 7.4439365e-03 1.7874213e-06 9.9253863e-01], sum to 1.0000
[2019-03-23 20:41:34,309] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6003
[2019-03-23 20:41:34,318] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.36666666666667, 58.83333333333333, 1.0, 2.0, 0.3174260352678253, 1.0, 2.0, 0.3174260352678253, 1.0, 2.0, 0.6426133739586312, 6.9112, 6.9112, 77.3421103, 1085215.091964278, 1085215.091964278, 263795.6563491212], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7384200.0000, 
sim time next is 7384800.0000, 
raw observation next is [26.63333333333333, 57.66666666666667, 1.0, 2.0, 0.3525509011873545, 1.0, 2.0, 0.3525509011873545, 1.0, 2.0, 0.7138992443460815, 6.9112, 6.9112, 77.3421103, 1204791.06508254, 1204791.06508254, 278147.9963362078], 
processed observation next is [1.0, 0.4782608695652174, 0.8469696969696968, 0.5766666666666667, 1.0, 1.0, 0.1906886264841931, 1.0, 1.0, 0.1906886264841931, 1.0, 1.0, 0.5912846347801165, 0.0, 0.0, 0.5085185399722538, 0.44621891299353333, 0.44621891299353333, 0.6784097471614824], 
reward next is 0.3216, 
noisyNet noise sample is [array([0.12289667], dtype=float32), 0.6452337]. 
=============================================
[2019-03-23 20:41:34,883] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145000, global step 2318831: loss 0.9892
[2019-03-23 20:41:34,885] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145000, global step 2318831: learning rate 0.0000
[2019-03-23 20:41:36,892] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145000, global step 2319893: loss -1.9364
[2019-03-23 20:41:36,894] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145000, global step 2319893: learning rate 0.0000
[2019-03-23 20:41:40,093] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145000, global step 2321576: loss 0.4811
[2019-03-23 20:41:40,096] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145000, global step 2321577: learning rate 0.0000
[2019-03-23 20:41:40,571] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145000, global step 2321828: loss -2.1923
[2019-03-23 20:41:40,572] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145000, global step 2321828: learning rate 0.0000
[2019-03-23 20:41:40,648] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2452240e-01 2.2933960e-17 8.7547767e-01 2.9678779e-15 1.8548550e-10], sum to 1.0000
[2019-03-23 20:41:40,656] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0179
[2019-03-23 20:41:40,662] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.9, 60.0, 1.0, 2.0, 0.2299818540878081, 0.0, 2.0, 0.0, 1.0, 2.0, 0.462683131323233, 6.911199999999999, 6.9112, 77.32846344354104, 524707.3317076287, 524707.3317076289, 171623.2751911877], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7496400.0000, 
sim time next is 7497000.0000, 
raw observation next is [25.8, 59.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7900271293760318, 7.458980160773097, 6.9112, 77.32712646443896, 626719.701289858, 448814.9850692479, 139894.091231204], 
processed observation next is [0.0, 0.782608695652174, 0.8090909090909091, 0.59, 0.0, 0.5, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.700038756251474, 0.05477801607730966, 0.0, 0.5084200223839294, 0.23211840788513258, 0.16622777224786958, 0.3412051005639122], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.05813947], dtype=float32), -0.5973403]. 
=============================================
[2019-03-23 20:41:40,674] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[50.97496 ]
 [51.466026]
 [51.02156 ]
 [52.113937]
 [51.94304 ]], R is [[49.77085114]
 [49.85454941]
 [49.93352509]
 [50.00857544]
 [50.0813942 ]].
[2019-03-23 20:41:40,780] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145000, global step 2321935: loss -3.2570
[2019-03-23 20:41:40,784] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145000, global step 2321936: learning rate 0.0000
[2019-03-23 20:41:41,113] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145000, global step 2322110: loss 10.8531
[2019-03-23 20:41:41,115] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145000, global step 2322110: learning rate 0.0000
[2019-03-23 20:41:41,206] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145000, global step 2322160: loss -127.4783
[2019-03-23 20:41:41,206] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145000, global step 2322160: learning rate 0.0000
[2019-03-23 20:41:41,431] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145000, global step 2322278: loss 0.0837
[2019-03-23 20:41:41,434] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145000, global step 2322278: learning rate 0.0000
[2019-03-23 20:41:41,503] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145000, global step 2322317: loss 2.6757
[2019-03-23 20:41:41,510] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145000, global step 2322319: learning rate 0.0000
[2019-03-23 20:41:41,541] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145000, global step 2322337: loss 2.9593
[2019-03-23 20:41:41,543] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145000, global step 2322338: learning rate 0.0000
[2019-03-23 20:41:41,834] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145000, global step 2322491: loss -2.9885
[2019-03-23 20:41:41,836] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145000, global step 2322491: learning rate 0.0000
[2019-03-23 20:41:41,915] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145000, global step 2322530: loss 0.6158
[2019-03-23 20:41:41,919] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145000, global step 2322530: learning rate 0.0000
[2019-03-23 20:41:41,967] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145500, global step 2322554: loss 4.5175
[2019-03-23 20:41:41,969] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145500, global step 2322555: learning rate 0.0000
[2019-03-23 20:41:42,194] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145000, global step 2322673: loss 1.2034
[2019-03-23 20:41:42,196] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145000, global step 2322673: learning rate 0.0000
[2019-03-23 20:41:43,651] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.45681803e-06 1.26189970e-09 9.17426776e-03 1.05894884e-07
 9.90819156e-01], sum to 1.0000
[2019-03-23 20:41:43,658] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1781
[2019-03-23 20:41:43,664] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.23333333333333, 67.33333333333333, 1.0, 2.0, 0.3770056329928056, 1.0, 2.0, 0.3770056329928056, 1.0, 2.0, 0.7626557105930722, 6.9112, 6.9112, 77.3421103, 1277045.903134842, 1277045.903134842, 294386.4833818178], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7645200.0000, 
sim time next is 7645800.0000, 
raw observation next is [26.41666666666667, 66.16666666666667, 1.0, 2.0, 0.3773437282622951, 1.0, 2.0, 0.3773437282622951, 1.0, 2.0, 0.7633748318552834, 6.9112, 6.9112, 77.3421103, 1278365.681062255, 1278365.681062255, 294481.4123681711], 
processed observation next is [1.0, 0.4782608695652174, 0.8371212121212124, 0.6616666666666667, 1.0, 1.0, 0.22167966032786887, 1.0, 1.0, 0.22167966032786887, 1.0, 1.0, 0.6619640455075478, 0.0, 0.0, 0.5085185399722538, 0.4734687707637982, 0.4734687707637982, 0.7182473472394417], 
reward next is 0.2818, 
noisyNet noise sample is [array([-0.6512999], dtype=float32), -0.8859438]. 
=============================================
[2019-03-23 20:41:46,626] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 20:41:46,627] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:41:46,627] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:41:46,628] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:41:46,628] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:41:46,628] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:41:46,631] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:41:46,633] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:41:46,633] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:41:46,635] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:41:46,635] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:41:46,654] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run94
[2019-03-23 20:41:46,679] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run94
[2019-03-23 20:41:46,707] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run94
[2019-03-23 20:41:46,735] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run94
[2019-03-23 20:41:46,736] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run94
[2019-03-23 20:41:58,251] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00138739], dtype=float32), 0.017430801]
[2019-03-23 20:41:58,252] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.7, 41.83333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3913855173060771, 6.911200000000001, 6.9112, 95.55338769695034, 448183.6814680649, 448183.6814680645, 165202.5552600629]
[2019-03-23 20:41:58,253] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:41:58,257] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.3768638e-03 5.3087961e-20 9.9462318e-01 5.0476579e-18 1.5387832e-13], sampled 0.9886513934034932
[2019-03-23 20:42:49,899] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00138739], dtype=float32), 0.017430801]
[2019-03-23 20:42:49,900] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 83.0, 1.0, 2.0, 0.21510212792882, 0.0, 2.0, 0.0, 1.0, 2.0, 0.431579059648056, 6.9112, 6.9112, 77.32846344346305, 490381.2084808989, 490381.2084808989, 167714.382173387]
[2019-03-23 20:42:49,901] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:42:49,903] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.4655030e-02 9.5683631e-19 9.8534495e-01 9.1405951e-16 1.2359056e-09], sampled 0.22637397217661237
[2019-03-23 20:43:13,991] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00138739], dtype=float32), 0.017430801]
[2019-03-23 20:43:13,994] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.93333333333334, 45.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3869067349434567, 6.911200000000001, 6.9112, 95.55338769695034, 442840.9289661163, 442840.9289661159, 164780.8715030914]
[2019-03-23 20:43:13,996] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:43:14,000] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.4461413e-03 5.1527294e-20 9.9355388e-01 6.0470658e-18 2.4984352e-13], sampled 0.4386599215481103
[2019-03-23 20:43:26,953] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3119.9374 2113588981.7820 167.0000
[2019-03-23 20:43:27,024] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3479.8598 2104123073.7135 102.0000
[2019-03-23 20:43:27,036] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3333.1980 2098728081.0963 117.0000
[2019-03-23 20:43:27,104] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3486.4871 2193534866.3747 105.0000
[2019-03-23 20:43:27,118] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2808.2723 2133874874.5700 294.0000
[2019-03-23 20:43:28,137] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2325000, evaluation results [2325000.0, 3486.4871420466375, 2193534866.374746, 105.0, 3333.197998168364, 2098728081.0962586, 117.0, 3479.8598391925857, 2104123073.713538, 102.0, 2808.272256680081, 2133874874.5699754, 294.0, 3119.9373504730975, 2113588981.7820148, 167.0]
[2019-03-23 20:43:28,433] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145500, global step 2325149: loss 3.3688
[2019-03-23 20:43:28,434] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145500, global step 2325149: learning rate 0.0000
[2019-03-23 20:43:31,620] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:43:31,621] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:43:31,627] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145500, global step 2326743: loss 29.3128
[2019-03-23 20:43:31,631] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145500, global step 2326743: learning rate 0.0000
[2019-03-23 20:43:31,680] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run12
[2019-03-23 20:43:32,884] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.3578223e-05 5.0778180e-13 9.9992645e-01 1.1065281e-12 6.4093730e-09], sum to 1.0000
[2019-03-23 20:43:32,889] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7655
[2019-03-23 20:43:32,893] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.45, 98.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.334805760847017, 6.9112, 6.9112, 77.32846344354104, 386082.7523834651, 386082.7523834651, 150782.888476762], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7709400.0000, 
sim time next is 7710000.0000, 
raw observation next is [17.53333333333333, 98.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3372783067874438, 6.911199999999999, 6.9112, 77.32846344354104, 388875.1636323118, 388875.1636323121, 151133.614193898], 
processed observation next is [1.0, 0.21739130434782608, 0.43333333333333324, 0.98, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.053254723982062595, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1440278383823377, 0.14402783838233782, 0.3686185712046293], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.8143209], dtype=float32), 0.5476395]. 
=============================================
[2019-03-23 20:43:32,904] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[20.048124]
 [20.524654]
 [21.687027]
 [22.380133]
 [23.759417]], R is [[20.20866203]
 [20.00657654]
 [19.80651093]
 [19.60844612]
 [19.41236115]].
[2019-03-23 20:43:33,675] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145500, global step 2327809: loss 3.2505
[2019-03-23 20:43:33,679] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145500, global step 2327810: learning rate 0.0000
[2019-03-23 20:43:36,486] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:43:36,488] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:43:36,551] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run12
[2019-03-23 20:43:37,230] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145500, global step 2329592: loss 2.5316
[2019-03-23 20:43:37,231] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145500, global step 2329593: learning rate 0.0000
[2019-03-23 20:43:37,385] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145500, global step 2329679: loss 1.2465
[2019-03-23 20:43:37,386] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145500, global step 2329679: learning rate 0.0000
[2019-03-23 20:43:37,604] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145500, global step 2329804: loss 2.7675
[2019-03-23 20:43:37,605] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145500, global step 2329804: learning rate 0.0000
[2019-03-23 20:43:37,861] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145500, global step 2329953: loss 0.3539
[2019-03-23 20:43:37,865] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145500, global step 2329953: learning rate 0.0000
[2019-03-23 20:43:38,037] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145500, global step 2330039: loss 5.9685
[2019-03-23 20:43:38,039] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145500, global step 2330039: learning rate 0.0000
[2019-03-23 20:43:38,071] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145500, global step 2330056: loss -0.9156
[2019-03-23 20:43:38,073] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145500, global step 2330056: learning rate 0.0000
[2019-03-23 20:43:38,278] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145500, global step 2330156: loss -1.7447
[2019-03-23 20:43:38,280] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145500, global step 2330156: learning rate 0.0000
[2019-03-23 20:43:38,370] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145500, global step 2330201: loss 3.8194
[2019-03-23 20:43:38,372] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145500, global step 2330201: learning rate 0.0000
[2019-03-23 20:43:38,631] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145500, global step 2330329: loss 3.9246
[2019-03-23 20:43:38,634] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145500, global step 2330330: learning rate 0.0000
[2019-03-23 20:43:38,773] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145500, global step 2330401: loss -2.0017
[2019-03-23 20:43:38,775] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145500, global step 2330402: learning rate 0.0000
[2019-03-23 20:43:38,967] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145500, global step 2330495: loss -0.6235
[2019-03-23 20:43:38,968] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145500, global step 2330495: learning rate 0.0000
[2019-03-23 20:43:39,540] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4736535e-05 1.2182738e-13 9.9998522e-01 9.9688259e-13 4.0944517e-10], sum to 1.0000
[2019-03-23 20:43:39,551] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5834
[2019-03-23 20:43:39,557] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.46666666666667, 49.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 318891.8861271057, 318891.886127106, 124948.6574203173], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7843200.0000, 
sim time next is 7843800.0000, 
raw observation next is [21.28333333333333, 49.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 315363.3402851298, 315363.3402851301, 122078.4472637739], 
processed observation next is [1.0, 0.782608695652174, 0.6037878787878787, 0.4933333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11680123714264067, 0.11680123714264078, 0.29775231039944855], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.6525142], dtype=float32), -1.2806894]. 
=============================================
[2019-03-23 20:43:39,596] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:43:39,596] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:43:39,668] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run12
[2019-03-23 20:43:41,706] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:43:41,706] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:43:41,785] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run12
[2019-03-23 20:43:44,893] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:43:44,893] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:43:44,925] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run12
[2019-03-23 20:43:45,065] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:43:45,065] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:43:45,116] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run12
[2019-03-23 20:43:45,333] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:43:45,333] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:43:45,364] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run12
[2019-03-23 20:43:45,591] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:43:45,592] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:43:45,616] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run12
[2019-03-23 20:43:45,726] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:43:45,730] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:43:45,761] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run12
[2019-03-23 20:43:45,808] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:43:45,808] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:43:45,820] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run12
[2019-03-23 20:43:45,859] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:43:45,860] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:43:45,889] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run12
[2019-03-23 20:43:46,011] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:43:46,012] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:43:46,015] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run12
[2019-03-23 20:43:46,056] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:43:46,056] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:43:46,059] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run12
[2019-03-23 20:43:46,152] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:43:46,153] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:43:46,157] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run12
[2019-03-23 20:43:46,261] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:43:46,261] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:43:46,266] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run12
[2019-03-23 20:43:47,511] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.5143355e-04 6.7297039e-09 9.9914742e-01 5.7751470e-09 1.2442559e-06], sum to 1.0000
[2019-03-23 20:43:47,518] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5552
[2019-03-23 20:43:47,521] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [13.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 215040.7329289477, 215040.7329289474, 90158.25741675291], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 172800.0000, 
sim time next is 173400.0000, 
raw observation next is [13.16666666666667, 88.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 213208.9295714408, 213208.9295714411, 90105.09165111929], 
processed observation next is [0.0, 0.0, 0.23484848484848497, 0.8800000000000001, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07896627021164473, 0.07896627021164486, 0.21976851622224217], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.08225851], dtype=float32), -0.85196984]. 
=============================================
[2019-03-23 20:43:50,609] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.0509669e-04 2.1610033e-08 9.9978656e-01 2.1797598e-08 8.3945088e-06], sum to 1.0000
[2019-03-23 20:43:50,625] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0903
[2019-03-23 20:43:50,630] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.0, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 254147.3734654437, 254147.3734654434, 102734.6878118166], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 84600.0000, 
sim time next is 85200.0000, 
raw observation next is [16.0, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 252762.4387278546, 252762.4387278543, 102467.2775187799], 
processed observation next is [1.0, 1.0, 0.36363636363636365, 0.77, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09361571804735355, 0.09361571804735346, 0.24992018907019486], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.13724983], dtype=float32), 1.0274199]. 
=============================================
[2019-03-23 20:43:56,442] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.1380468e-04 5.5504486e-08 9.9927205e-01 5.7323653e-08 1.4069976e-05], sum to 1.0000
[2019-03-23 20:43:56,450] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0026
[2019-03-23 20:43:56,454] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.33333333333333, 69.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 257688.3627707406, 257688.3627707408, 101037.0177875189], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 164400.0000, 
sim time next is 165000.0000, 
raw observation next is [16.16666666666667, 70.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 254761.1055761047, 254761.1055761047, 100552.4495084125], 
processed observation next is [1.0, 0.9130434782608695, 0.37121212121212144, 0.705, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.09435596502818692, 0.09435596502818692, 0.24524987684978658], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5749126], dtype=float32), -1.3318391]. 
=============================================
[2019-03-23 20:43:56,467] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[5.153586 ]
 [5.0890446]
 [5.029993 ]
 [4.949207 ]
 [4.9140987]], R is [[5.16785669]
 [5.11617804]
 [5.06501627]
 [5.01436615]
 [4.96422243]].
[2019-03-23 20:43:57,583] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1118331e-05 9.8618648e-12 9.9998891e-01 3.1480173e-11 9.6091695e-09], sum to 1.0000
[2019-03-23 20:43:57,590] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8176
[2019-03-23 20:43:57,596] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [13.33333333333333, 92.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 208176.3252267966, 208176.3252267966, 90351.24731699463], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 184800.0000, 
sim time next is 185400.0000, 
raw observation next is [13.5, 91.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 209490.0626140104, 209490.0626140106, 90771.2001939905], 
processed observation next is [0.0, 0.13043478260869565, 0.25, 0.91, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07758891207926312, 0.07758891207926318, 0.22139317120485488], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.911176], dtype=float32), -2.1207545]. 
=============================================
[2019-03-23 20:44:00,559] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.9375693e-05 2.7635119e-09 9.9996066e-01 1.6402328e-10 3.1239185e-08], sum to 1.0000
[2019-03-23 20:44:00,572] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1713
[2019-03-23 20:44:00,576] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [15.0, 94.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 264613.45203162, 264613.4520316203, 110069.8874086325], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 252600.0000, 
sim time next is 253200.0000, 
raw observation next is [15.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 262973.3582305756, 262973.3582305759, 109734.1041336731], 
processed observation next is [0.0, 0.9565217391304348, 0.3181818181818182, 0.94, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09739754008539839, 0.09739754008539848, 0.2676441564235929], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.04935633], dtype=float32), -0.31675297]. 
=============================================
[2019-03-23 20:44:03,037] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.5806571e-04 2.8099365e-09 9.9954200e-01 2.3143509e-09 4.0586393e-08], sum to 1.0000
[2019-03-23 20:44:03,046] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3653
[2019-03-23 20:44:03,056] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 43.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 278780.1913732873, 278780.191373287, 107115.4912400068], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 321600.0000, 
sim time next is 322200.0000, 
raw observation next is [21.0, 43.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 278533.2722701731, 278533.2722701728, 107061.708815196], 
processed observation next is [0.0, 0.7391304347826086, 0.5909090909090909, 0.43, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10316047121117523, 0.10316047121117511, 0.26112611906145367], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0526023], dtype=float32), 0.27839127]. 
=============================================
[2019-03-23 20:44:06,657] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.7073972e-04 5.5839555e-09 9.9971396e-01 2.3374749e-08 1.5234055e-05], sum to 1.0000
[2019-03-23 20:44:06,667] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6718
[2019-03-23 20:44:06,676] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [12.83333333333333, 76.83333333333334, 1.0, 2.0, 0.2020161624534798, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3771199184045766, 6.9112, 6.9112, 77.32846344354104, 438770.3912951782, 438770.3912951782, 122800.7805044744], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 370200.0000, 
sim time next is 370800.0000, 
raw observation next is [13.0, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3705247364351621, 6.911200000000001, 6.9112, 77.32846344354104, 431093.6461881892, 431093.6461881889, 122387.9093341682], 
processed observation next is [1.0, 0.30434782608695654, 0.22727272727272727, 0.77, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.10074962347880301, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15966431340303305, 0.15966431340303294, 0.2985070959369956], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.35646394], dtype=float32), -0.016572207]. 
=============================================
[2019-03-23 20:44:06,935] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.8584930e-05 7.8977811e-09 9.9992836e-01 3.7897436e-09 3.0398623e-06], sum to 1.0000
[2019-03-23 20:44:06,942] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0592
[2019-03-23 20:44:06,946] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.83333333333333, 54.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 335597.1812884035, 335597.1812884032, 114185.9081827601], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 384600.0000, 
sim time next is 385200.0000, 
raw observation next is [18.0, 52.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 330571.1875753457, 330571.1875753457, 112699.5201035414], 
processed observation next is [1.0, 0.4782608695652174, 0.45454545454545453, 0.52, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.12243377317605396, 0.12243377317605396, 0.2748768783013205], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7971829], dtype=float32), 1.1146232]. 
=============================================
[2019-03-23 20:44:10,007] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.8761643e-04 1.5515331e-09 9.9981219e-01 6.8090378e-10 1.8979277e-07], sum to 1.0000
[2019-03-23 20:44:10,014] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3209
[2019-03-23 20:44:10,016] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 83.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 335923.9249730486, 335923.9249730483, 142629.1323107412], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 595800.0000, 
sim time next is 596400.0000, 
raw observation next is [18.0, 83.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 335961.9516013134, 335961.9516013134, 142635.3190897657], 
processed observation next is [1.0, 0.9130434782608695, 0.45454545454545453, 0.83, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.1244303524449309, 0.1244303524449309, 0.3478910221701602], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7113156], dtype=float32), 1.7629374]. 
=============================================
[2019-03-23 20:44:13,293] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.4963325e-04 1.3346098e-10 9.9974936e-01 9.5285883e-11 1.0128226e-06], sum to 1.0000
[2019-03-23 20:44:13,303] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6019
[2019-03-23 20:44:13,306] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.2085182970601194, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4143787963823304, 6.911199999999999, 6.9112, 77.32846344354104, 473297.5456650748, 473297.5456650751, 163914.0318391532], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1224600.0000, 
sim time next is 1225200.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.2054371758945687, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4082587910952396, 6.9112, 6.9112, 77.32846344354104, 466302.4580982625, 466302.4580982625, 163367.5894128757], 
processed observation next is [1.0, 0.17391304347826086, 0.5, 1.0, 1.0, 1.0, 0.006796469868210857, 0.0, 1.0, -0.25, 1.0, 1.0, 0.15465541585034231, 0.0, 0.0, 0.5084288129206541, 0.17270461411046759, 0.17270461411046759, 0.39845753515335536], 
reward next is 0.6015, 
noisyNet noise sample is [array([-1.5509747], dtype=float32), -0.40624306]. 
=============================================
[2019-03-23 20:44:17,932] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 20:44:17,933] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:44:17,934] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:44:17,935] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:44:17,935] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:44:17,937] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:44:17,936] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:44:17,939] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:44:17,937] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:44:17,939] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:44:17,940] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:44:17,961] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run95
[2019-03-23 20:44:17,986] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run95
[2019-03-23 20:44:18,012] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run95
[2019-03-23 20:44:18,013] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run95
[2019-03-23 20:44:18,038] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run95
[2019-03-23 20:44:52,970] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00105406], dtype=float32), 0.017488394]
[2019-03-23 20:44:52,971] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.0, 88.5, 1.0, 2.0, 0.297461010902875, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5703419603765507, 6.9112, 6.9112, 77.32846344354104, 659216.9347269076, 659216.9347269076, 174113.7475624864]
[2019-03-23 20:44:52,971] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:44:52,974] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.7355228e-03 1.9633211e-13 9.9326283e-01 1.2382902e-11 1.6597336e-06], sampled 0.7196908256126959
[2019-03-23 20:44:55,299] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00105406], dtype=float32), 0.017488394]
[2019-03-23 20:44:55,302] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.33333333333334, 54.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3010554618436112, 6.911199999999999, 6.9112, 77.32846344354104, 349019.0790641577, 349019.079064158, 144971.7044753215]
[2019-03-23 20:44:55,304] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:44:55,306] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.7288563e-04 8.6533322e-11 9.9982709e-01 9.9204318e-11 3.2569891e-09], sampled 0.6707188455465115
[2019-03-23 20:45:08,325] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00105406], dtype=float32), 0.017488394]
[2019-03-23 20:45:08,326] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.48333333333333, 71.16666666666666, 1.0, 2.0, 0.2444051156650409, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4930900012211077, 6.9112, 6.9112, 95.55338769695034, 557714.9622005629, 557714.9622005629, 180658.4460018966]
[2019-03-23 20:45:08,327] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:45:08,330] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.2774100e-03 8.2413087e-14 9.9572253e-01 2.1140440e-12 5.3312654e-08], sampled 0.033042636119951285
[2019-03-23 20:45:15,087] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00105406], dtype=float32), 0.017488394]
[2019-03-23 20:45:15,090] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.62246215666667, 76.28837504, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 254884.2071123071, 254884.2071123071, 105750.919801247]
[2019-03-23 20:45:15,092] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:45:15,094] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.7539150e-04 2.9944255e-11 9.9982458e-01 4.2325497e-11 1.5851263e-09], sampled 0.1873279661523244
[2019-03-23 20:45:34,650] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00105406], dtype=float32), 0.017488394]
[2019-03-23 20:45:34,652] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.43333333333333, 47.0, 1.0, 2.0, 0.2620075543256329, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5175240774244323, 6.9112, 6.9112, 95.55338769695034, 592632.8841995653, 592632.8841995653, 177878.707434744]
[2019-03-23 20:45:34,653] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:45:34,655] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.2904248e-03 2.5140197e-11 9.9869639e-01 3.7853828e-10 1.3162759e-05], sampled 0.49713840265298814
[2019-03-23 20:45:44,258] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00105406], dtype=float32), 0.017488394]
[2019-03-23 20:45:44,259] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [28.55, 49.5, 1.0, 2.0, 0.229589745472399, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4629463067927501, 6.911199999999999, 6.9112, 77.32846344354104, 523951.8991916077, 523951.899191608, 172462.5540477614]
[2019-03-23 20:45:44,260] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:45:44,264] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.1134433e-03 1.6341644e-13 9.9888653e-01 1.2244983e-12 5.5846257e-09], sampled 0.671828827404046
[2019-03-23 20:45:58,504] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3525.4280 2108403518.5658 45.0000
[2019-03-23 20:45:58,525] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3358.8922 2103002940.0961 58.0000
[2019-03-23 20:45:58,706] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3506.2870 2199783221.7649 48.0000
[2019-03-23 20:45:58,728] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2854.7200 2140375147.2379 161.0000
[2019-03-23 20:45:58,860] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3134.5551 2117905734.7454 90.0000
[2019-03-23 20:45:59,877] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 2350000, evaluation results [2350000.0, 3506.286958354499, 2199783221.7648582, 48.0, 3358.8922034024727, 2103002940.09614, 58.0, 3525.4279771931415, 2108403518.565848, 45.0, 2854.7200313519775, 2140375147.2378907, 161.0, 3134.5551122501565, 2117905734.7453928, 90.0]
[2019-03-23 20:46:00,913] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.5750019e-03 1.8721798e-13 9.9742508e-01 3.8688318e-13 1.8653861e-09], sum to 1.0000
[2019-03-23 20:46:00,919] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8531
[2019-03-23 20:46:00,927] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.16666666666666, 86.33333333333334, 1.0, 2.0, 0.2145923065567426, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4290042444787543, 6.9112, 6.9112, 77.32846344354104, 488532.4373909666, 488532.4373909666, 166553.4735203911], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 928200.0000, 
sim time next is 928800.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.2157875086917509, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4315900313496202, 6.911200000000001, 6.9112, 77.32846344354104, 491351.3759890615, 491351.3759890613, 166907.4301992801], 
processed observation next is [0.0, 0.782608695652174, 0.5909090909090909, 0.88, 1.0, 1.0, 0.019734385864688606, 0.0, 1.0, -0.25, 1.0, 1.0, 0.18798575907088605, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18198199110705982, 0.18198199110705976, 0.40709129316897585], 
reward next is 0.5929, 
noisyNet noise sample is [array([-0.75328076], dtype=float32), 0.28309366]. 
=============================================
[2019-03-23 20:46:01,592] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.7488926e-03 2.4629385e-11 9.9725074e-01 4.2422388e-10 4.1073199e-07], sum to 1.0000
[2019-03-23 20:46:01,598] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5106
[2019-03-23 20:46:01,606] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.33333333333333, 98.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 272832.1344458011, 272832.1344458011, 109891.1222473781], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 624000.0000, 
sim time next is 624600.0000, 
raw observation next is [14.5, 97.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 262190.0019095475, 262190.0019095475, 108139.1941870296], 
processed observation next is [1.0, 0.21739130434782608, 0.29545454545454547, 0.97, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.09710740811464721, 0.09710740811464721, 0.2637541321634868], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.19389927], dtype=float32), 0.32566896]. 
=============================================
[2019-03-23 20:46:03,226] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.6332128e-03 2.5502761e-08 2.7668011e-01 2.2552645e-06 7.1968436e-01], sum to 1.0000
[2019-03-23 20:46:03,237] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0188
[2019-03-23 20:46:03,240] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 424680.2857495436, 424680.2857495436, 181704.0255618062], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 970800.0000, 
sim time next is 971400.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.2, 0.0, 1.0, 0.0, 1.0, 2.0, 0.3746003490863939, 6.9112, 6.9112, 77.32846344354104, 429298.4946698803, 429298.4946698803, 158076.3043723343], 
processed observation next is [1.0, 0.21739130434782608, 0.5, 0.94, 1.0, 1.0, 0.0, 0.0, 0.5, -0.25, 1.0, 1.0, 0.10657192726627701, 0.0, 0.0, 0.5084288129206541, 0.15899944247032605, 0.15899944247032605, 0.3855519618837422], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.34991077], dtype=float32), 0.6212619]. 
=============================================
[2019-03-23 20:46:03,414] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.0915594e-04 1.0229072e-08 1.0710102e-01 1.2908324e-06 8.9248854e-01], sum to 1.0000
[2019-03-23 20:46:03,422] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3778
[2019-03-23 20:46:03,428] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.33333333333334, 65.0, 1.0, 2.0, 0.2195409349098665, 1.0, 2.0, 0.2195409349098665, 1.0, 2.0, 0.435084948244676, 6.9112, 6.9112, 77.3421103, 746536.4610373395, 746536.4610373395, 220431.8845527939], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 642000.0000, 
sim time next is 642600.0000, 
raw observation next is [22.5, 63.0, 1.0, 2.0, 0.2229896601769485, 1.0, 2.0, 0.2229896601769485, 1.0, 2.0, 0.4411474974222033, 6.9112, 6.9112, 77.3421103, 757498.1134159964, 757498.1134159964, 220630.7344591336], 
processed observation next is [1.0, 0.43478260869565216, 0.6590909090909091, 0.63, 1.0, 1.0, 0.0287370752211856, 1.0, 1.0, 0.0287370752211856, 1.0, 1.0, 0.20163928203171907, 0.0, 0.0, 0.5085185399722538, 0.28055485682073944, 0.28055485682073944, 0.5381237425832527], 
reward next is 0.4619, 
noisyNet noise sample is [array([-2.1508253], dtype=float32), 0.7748576]. 
=============================================
[2019-03-23 20:46:05,732] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.5607456e-03 1.8099008e-10 9.9636567e-01 5.9467753e-10 7.3552357e-05], sum to 1.0000
[2019-03-23 20:46:05,742] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9246
[2019-03-23 20:46:05,748] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.0, 96.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 262877.9154920749, 262877.9154920749, 104709.8142192371], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1017600.0000, 
sim time next is 1018200.0000, 
raw observation next is [14.0, 95.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 259218.7354437677, 259218.7354437677, 103540.9733359345], 
processed observation next is [1.0, 0.782608695652174, 0.2727272727272727, 0.95, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.0960069390532473, 0.0960069390532473, 0.2525389593559378], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5731279], dtype=float32), 0.8242716]. 
=============================================
[2019-03-23 20:46:10,241] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.1868816e-03 2.4527853e-16 9.9781311e-01 1.4371806e-14 2.8314520e-10], sum to 1.0000
[2019-03-23 20:46:10,253] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5425
[2019-03-23 20:46:10,259] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 69.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3675905259683111, 6.9112, 6.9112, 77.32846344354104, 422050.6597547665, 422050.6597547665, 156463.3343510705], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1101600.0000, 
sim time next is 1102200.0000, 
raw observation next is [22.0, 69.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3667691072839699, 6.9112, 6.9112, 77.32846344354104, 421141.4493728039, 421141.4493728039, 156327.7949052296], 
processed observation next is [1.0, 0.782608695652174, 0.6363636363636364, 0.69, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.09538443897709986, 0.0, 0.0, 0.5084288129206541, 0.15597831458251996, 0.15597831458251996, 0.3812873046469014], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2001704], dtype=float32), -0.6073322]. 
=============================================
[2019-03-23 20:46:10,545] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.1712947e-02 3.1884275e-14 9.5824891e-01 2.8211279e-11 3.8117192e-05], sum to 1.0000
[2019-03-23 20:46:10,554] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4925
[2019-03-23 20:46:10,556] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.83333333333333, 69.66666666666667, 1.0, 2.0, 0.2200526969452677, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4412064254504741, 6.9112, 6.9112, 77.32846344354104, 501553.8227665671, 501553.8227665671, 168460.5142837427], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 774600.0000, 
sim time next is 775200.0000, 
raw observation next is [23.66666666666666, 70.33333333333334, 1.0, 2.0, 0.2188378048958942, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4385502719411099, 6.911200000000001, 6.9112, 77.32846344354104, 498692.1694187069, 498692.1694187066, 168068.6485944101], 
processed observation next is [1.0, 1.0, 0.7121212121212118, 0.7033333333333335, 1.0, 1.0, 0.023547256119867722, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1979289599158713, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18470080348840998, 0.18470080348840986, 0.4099235331570978], 
reward next is 0.5901, 
noisyNet noise sample is [array([1.2574463], dtype=float32), 1.5145829]. 
=============================================
[2019-03-23 20:46:20,375] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.8045540e-03 4.8477089e-09 9.9062437e-01 1.5848399e-07 5.5710291e-03], sum to 1.0000
[2019-03-23 20:46:20,382] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2435
[2019-03-23 20:46:20,387] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 94.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3514818232009889, 6.911199999999999, 6.9112, 77.32846344354104, 405132.3000985034, 405132.3000985037, 152958.3126356958], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1293000.0000, 
sim time next is 1293600.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3492887333502082, 6.911200000000001, 6.9112, 77.32846344354104, 402615.1485912853, 402615.148591285, 152681.095894746], 
processed observation next is [1.0, 1.0, 0.45454545454545453, 0.94, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.07041247621458319, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14911672170047602, 0.14911672170047593, 0.37239291681645365], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0517013], dtype=float32), 0.5563925]. 
=============================================
[2019-03-23 20:46:24,184] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.52857886e-05 6.78336249e-08 9.99903321e-01 1.02691466e-07
 2.12365467e-05], sum to 1.0000
[2019-03-23 20:46:24,193] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3369
[2019-03-23 20:46:24,198] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.0, 48.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3504338855125904, 6.9112, 6.9112, 77.32846344354104, 407708.7849930892, 407708.7849930892, 119934.0323613829], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1771200.0000, 
sim time next is 1771800.0000, 
raw observation next is [17.16666666666667, 47.5, 1.0, 2.0, 0.2076996718631509, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3877297853518333, 6.9112, 6.9112, 77.32846344354104, 451120.4556420702, 451120.4556420702, 124620.1666140478], 
processed observation next is [1.0, 0.5217391304347826, 0.4166666666666669, 0.475, 1.0, 1.0, 0.009624589828938594, 0.0, 1.0, -0.25, 1.0, 1.0, 0.12532826478833328, 0.0, 0.0, 0.5084288129206541, 0.16708165023780377, 0.16708165023780377, 0.30395162588792146], 
reward next is 0.6960, 
noisyNet noise sample is [array([1.0124167], dtype=float32), 1.1884284]. 
=============================================
[2019-03-23 20:46:36,321] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4200131e-02 8.0126862e-17 9.8579967e-01 5.9370227e-14 2.3124086e-07], sum to 1.0000
[2019-03-23 20:46:36,333] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5935
[2019-03-23 20:46:36,338] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 71.0, 1.0, 2.0, 0.2655207812202551, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5378603674275715, 6.911199999999999, 6.9112, 77.32846344354104, 603445.0426020123, 603445.0426020126, 184483.2316248851], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1436400.0000, 
sim time next is 1437000.0000, 
raw observation next is [25.5, 73.0, 1.0, 2.0, 0.2630234532802703, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5327529320262648, 6.911200000000001, 6.9112, 77.32846344354104, 598278.037743388, 598278.0377433877, 183486.7593166116], 
processed observation next is [0.0, 0.6521739130434783, 0.7954545454545454, 0.73, 1.0, 1.0, 0.07877931660033789, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3325041886089498, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22158445842347702, 0.22158445842347693, 0.4475286812600283], 
reward next is 0.5525, 
noisyNet noise sample is [array([-0.24959175], dtype=float32), -0.024330536]. 
=============================================
[2019-03-23 20:46:36,354] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[50.1486  ]
 [50.161392]
 [50.154007]
 [50.166725]
 [49.843735]], R is [[50.17889023]
 [50.22714233]
 [50.27283096]
 [50.31581116]
 [50.35590363]].
[2019-03-23 20:46:36,955] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.4338505e-04 2.2603278e-17 9.9935657e-01 1.0585350e-15 1.8279496e-10], sum to 1.0000
[2019-03-23 20:46:36,961] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5003
[2019-03-23 20:46:36,967] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.33333333333333, 90.0, 1.0, 2.0, 0.2079885798411511, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4102449019251476, 6.911199999999999, 6.9112, 77.32846344354104, 470035.9016039293, 470035.9016039296, 162168.8345776187], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1281000.0000, 
sim time next is 1281600.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3812513057481692, 6.9112, 6.9112, 77.32846344354104, 438820.1043140037, 438820.1043140037, 157243.1083399626], 
processed observation next is [1.0, 0.8695652173913043, 0.45454545454545453, 0.94, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.11607329392595599, 0.0, 0.0, 0.5084288129206541, 0.16252596456074211, 0.16252596456074211, 0.3835197764389332], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5176554], dtype=float32), 1.308746]. 
=============================================
[2019-03-23 20:46:37,312] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.5357307e-05 1.2112907e-14 9.9997842e-01 1.5910050e-12 6.2510921e-06], sum to 1.0000
[2019-03-23 20:46:37,319] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5566
[2019-03-23 20:46:37,323] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3664616219494886, 6.9112, 6.9112, 77.32846344354104, 420916.3839985394, 420916.3839985394, 156172.6428640614], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1308000.0000, 
sim time next is 1308600.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3667039327559382, 6.911200000000001, 6.9112, 77.32846344354104, 421202.104405626, 421202.1044056257, 156196.8062833324], 
processed observation next is [1.0, 0.13043478260869565, 0.45454545454545453, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.09529133250848318, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1560007794094911, 0.156000779409491, 0.38096782020324976], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.506782], dtype=float32), -0.8877744]. 
=============================================
[2019-03-23 20:46:43,251] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.8097600e-03 3.6791469e-20 9.9219018e-01 9.9160602e-19 8.9746105e-15], sum to 1.0000
[2019-03-23 20:46:43,258] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1264
[2019-03-23 20:46:43,260] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 54.0, 1.0, 2.0, 0.206171280891101, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4110987537447398, 6.9112, 6.9112, 77.32846344354104, 468784.9417319118, 468784.9417319118, 164314.0129458988], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2134800.0000, 
sim time next is 2135400.0000, 
raw observation next is [26.0, 54.0, 1.0, 2.0, 0.2060961339126255, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4108835979586902, 6.9112, 6.9112, 77.32846344354104, 468577.3740381853, 468577.3740381853, 164260.5928538914], 
processed observation next is [0.0, 0.7391304347826086, 0.8181818181818182, 0.54, 1.0, 1.0, 0.0076201673907818485, 0.0, 1.0, -0.25, 1.0, 1.0, 0.15840513994098607, 0.0, 0.0, 0.5084288129206541, 0.17354717556969826, 0.17354717556969826, 0.40063559232656437], 
reward next is 0.5994, 
noisyNet noise sample is [array([-2.6829956], dtype=float32), -0.980923]. 
=============================================
[2019-03-23 20:46:47,341] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.7105847e-03 9.0980093e-14 1.0757403e-02 6.7729677e-10 9.8253202e-01], sum to 1.0000
[2019-03-23 20:46:47,348] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5023
[2019-03-23 20:46:47,351] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.93333333333333, 62.16666666666667, 1.0, 2.0, 0.3327292332734601, 1.0, 2.0, 0.3327292332734601, 1.0, 2.0, 0.6737006521678004, 6.9112, 6.9112, 77.3421103, 1130438.713423815, 1130438.713423815, 274189.4184332641], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1605000.0000, 
sim time next is 1605600.0000, 
raw observation next is [27.0, 62.0, 1.0, 2.0, 0.3368691593462783, 1.0, 2.0, 0.3368691593462783, 1.0, 2.0, 0.6819988025239142, 6.9112, 6.9112, 77.3421103, 1143938.448562886, 1143938.448562886, 276093.8719742554], 
processed observation next is [1.0, 0.6086956521739131, 0.8636363636363636, 0.62, 1.0, 1.0, 0.17108644918284788, 1.0, 1.0, 0.17108644918284788, 1.0, 1.0, 0.5457125750341631, 0.0, 0.0, 0.5085185399722538, 0.423680906875143, 0.423680906875143, 0.6733996877420864], 
reward next is 0.3266, 
noisyNet noise sample is [array([-1.7102678], dtype=float32), 1.4051116]. 
=============================================
[2019-03-23 20:46:49,552] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 20:46:49,552] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:46:49,553] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:46:49,554] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:46:49,556] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:46:49,560] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:46:49,560] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:46:49,563] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:46:49,563] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:46:49,562] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:46:49,566] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:46:49,589] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run96
[2019-03-23 20:46:49,611] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run96
[2019-03-23 20:46:49,637] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run96
[2019-03-23 20:46:49,663] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run96
[2019-03-23 20:46:49,687] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run96
[2019-03-23 20:47:16,884] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00111543], dtype=float32), 0.017605979]
[2019-03-23 20:47:16,885] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.5, 60.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 247563.8331610175, 247563.8331610178, 96626.47090038136]
[2019-03-23 20:47:16,886] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:47:16,888] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.4847639e-05 3.9438505e-13 9.9998510e-01 2.7153526e-13 2.6162759e-12], sampled 0.26744721804464044
[2019-03-23 20:47:46,258] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00111543], dtype=float32), 0.017605979]
[2019-03-23 20:47:46,259] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.06666666666667, 71.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 285129.2725160553, 285129.2725160549, 122563.9142832824]
[2019-03-23 20:47:46,259] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:47:46,262] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.2906876e-05 1.2871691e-15 9.9997711e-01 1.6894364e-15 1.6663259e-13], sampled 0.6616846238630263
[2019-03-23 20:47:47,590] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00111543], dtype=float32), 0.017605979]
[2019-03-23 20:47:47,591] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.117579285, 94.421215115, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3324936235287057, 6.9112, 6.9112, 95.55338769695034, 383158.9165930895, 383158.9165930895, 155292.714033343]
[2019-03-23 20:47:47,593] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:47:47,597] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.1980304e-05 3.4389412e-17 9.9995804e-01 1.7748478e-16 2.6299023e-13], sampled 0.9137072573592646
[2019-03-23 20:48:05,427] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00111543], dtype=float32), 0.017605979]
[2019-03-23 20:48:05,430] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.5, 90.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3700896980620307, 6.911199999999999, 6.9112, 95.55338769695034, 426240.8021892064, 426240.8021892067, 160163.1192605176]
[2019-03-23 20:48:05,431] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:48:05,434] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.9446961e-04 5.0708037e-18 9.9980551e-01 1.2643060e-16 2.3370689e-12], sampled 0.6777538395573085
[2019-03-23 20:48:20,722] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00111543], dtype=float32), 0.017605979]
[2019-03-23 20:48:20,723] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.918244105, 63.549646775, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 278656.6333719149, 278656.6333719145, 131954.9507341335]
[2019-03-23 20:48:20,726] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:48:20,727] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.9990208e-05 1.9561555e-15 9.9993002e-01 6.8109788e-15 3.8412238e-12], sampled 0.7560040703950287
[2019-03-23 20:48:29,570] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00111543], dtype=float32), 0.017605979]
[2019-03-23 20:48:29,573] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.01978090166667, 60.509996695, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3256580423980394, 6.911200000000001, 6.9112, 95.55338769695034, 376153.8707712938, 376153.8707712934, 153625.3165806623]
[2019-03-23 20:48:29,574] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:48:29,580] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.3357791e-06 4.7135482e-15 9.9999166e-01 3.5193126e-15 6.2329218e-14], sampled 0.10506491644980442
[2019-03-23 20:48:29,640] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3368.0580 2099143141.6580 130.0000
[2019-03-23 20:48:30,215] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2814.9314 2129539863.6251 469.0000
[2019-03-23 20:48:30,464] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3138.1349 2112477282.5004 216.0000
[2019-03-23 20:48:30,469] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3528.0926 2104942009.5826 111.0000
[2019-03-23 20:48:30,530] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3519.4065 2188889659.0028 147.0000
[2019-03-23 20:48:31,549] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 2375000, evaluation results [2375000.0, 3519.406452573511, 2188889659.0027704, 147.0, 3368.058040673246, 2099143141.6580436, 130.0, 3528.0925586544795, 2104942009.5826306, 111.0, 2814.931407382214, 2129539863.6251254, 469.0, 3138.1349302411722, 2112477282.5004141, 216.0]
[2019-03-23 20:48:38,679] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.1999324e-04 2.2470811e-08 1.1806839e-01 3.8072628e-07 8.8161117e-01], sum to 1.0000
[2019-03-23 20:48:38,687] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6566
[2019-03-23 20:48:38,693] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [19.0, 77.16666666666667, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3829620924256964, 6.911199999999999, 6.9112, 77.3421103, 662583.1608452278, 662583.1608452281, 207783.1148103264], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1681800.0000, 
sim time next is 1682400.0000, 
raw observation next is [19.0, 76.33333333333334, 1.0, 2.0, 0.2084994128488186, 1.0, 2.0, 0.2084994128488186, 1.0, 2.0, 0.4026087710176915, 6.911199999999999, 6.9112, 77.3421103, 696770.4945714386, 696770.4945714389, 209996.2932731458], 
processed observation next is [1.0, 0.4782608695652174, 0.5, 0.7633333333333334, 1.0, 1.0, 0.010624266061023228, 1.0, 1.0, 0.010624266061023228, 1.0, 1.0, 0.14658395859670215, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.25806314613756987, 0.25806314613757, 0.5121860811540141], 
reward next is 0.4878, 
noisyNet noise sample is [array([0.80140644], dtype=float32), 0.019616477]. 
=============================================
[2019-03-23 20:48:42,089] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.4517611e-04 1.1352170e-06 9.9921978e-01 2.5552665e-06 6.3125894e-04], sum to 1.0000
[2019-03-23 20:48:42,100] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1141
[2019-03-23 20:48:42,109] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [12.0, 76.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 194454.7327812598, 194454.7327812601, 83632.93484728233], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1720800.0000, 
sim time next is 1721400.0000, 
raw observation next is [12.0, 75.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 194117.1335824329, 194117.1335824326, 83496.12464429876], 
processed observation next is [1.0, 0.9565217391304348, 0.18181818181818182, 0.7516666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07189523466016033, 0.07189523466016022, 0.20364908449828967], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7611429], dtype=float32), 0.05924227]. 
=============================================
[2019-03-23 20:48:46,347] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0601687e-03 1.5974237e-04 3.4970120e-01 5.2340027e-05 6.4902657e-01], sum to 1.0000
[2019-03-23 20:48:46,354] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6889
[2019-03-23 20:48:46,360] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [19.5, 40.0, 1.0, 2.0, 0.2206174183494174, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4118443880732549, 6.911199999999999, 6.9112, 77.32846344354104, 479191.4274563874, 479191.4274563877, 129253.3426380536], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1783800.0000, 
sim time next is 1784400.0000, 
raw observation next is [19.33333333333334, 40.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 471833.5792456821, 471833.5792456824, 156167.8630178338], 
processed observation next is [1.0, 0.6521739130434783, 0.5151515151515155, 0.4, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.17475317749840077, 0.17475317749840089, 0.38089722687276534], 
reward next is 0.0000, 
noisyNet noise sample is [array([3.4302614], dtype=float32), 0.40460807]. 
=============================================
[2019-03-23 20:48:50,010] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0433376e-03 4.7498732e-05 5.0059557e-01 1.7831070e-04 4.9813530e-01], sum to 1.0000
[2019-03-23 20:48:50,018] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5776
[2019-03-23 20:48:50,021] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [16.06666666666667, 98.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 322181.5986524933, 322181.5986524933, 159890.7504995863], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2605800.0000, 
sim time next is 2606400.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 326949.0202715615, 326949.0202715617, 161020.8824262103], 
processed observation next is [0.0, 0.17391304347826086, 0.36363636363636365, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.12109222973020797, 0.12109222973020803, 0.39273385957612267], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.49065572], dtype=float32), -1.1754858]. 
=============================================
[2019-03-23 20:48:58,401] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.8791733e-03 3.6399317e-05 1.9996852e-01 8.8089757e-05 7.9702783e-01], sum to 1.0000
[2019-03-23 20:48:58,410] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1440
[2019-03-23 20:48:58,413] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 53.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999998, 6.9112, 77.3421103, 345092.7021637586, 345092.7021637592, 165035.340057888], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2037600.0000, 
sim time next is 2038200.0000, 
raw observation next is [23.16666666666667, 52.00000000000001, 1.0, 2.0, 0.2, 0.0, 1.0, 0.0, 1.0, 2.0, 0.3020811649920691, 6.911199999999999, 6.9112, 77.32846344354104, 349533.8576299465, 349533.8576299468, 145785.5720666248], 
processed observation next is [0.0, 0.6086956521739131, 0.6893939393939396, 0.52, 1.0, 1.0, 0.0, 0.0, 0.5, -0.25, 1.0, 1.0, 0.0029730928458130256, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12945698430738758, 0.1294569843073877, 0.35557456601615806], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0447086], dtype=float32), 2.536966]. 
=============================================
[2019-03-23 20:49:07,569] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6758252e-03 1.3863596e-05 4.3861517e-01 5.9466132e-05 5.5963570e-01], sum to 1.0000
[2019-03-23 20:49:07,575] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0080
[2019-03-23 20:49:07,584] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.83333333333334, 78.0, 1.0, 2.0, 0.2973736762397153, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5762200885988397, 6.911200000000001, 6.9112, 77.32846344354104, 664160.7128461725, 664160.7128461722, 176427.7667659393], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2209800.0000, 
sim time next is 2210400.0000, 
raw observation next is [20.0, 78.0, 1.0, 2.0, 0.3209147852246687, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6238357183846102, 6.9112, 6.9112, 77.32846344354104, 718417.107822061, 718417.107822061, 182880.8580362397], 
processed observation next is [1.0, 0.6086956521739131, 0.5454545454545454, 0.78, 1.0, 1.0, 0.15114348153083587, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4626224548351574, 0.0, 0.0, 0.5084288129206541, 0.26608041030446705, 0.26608041030446705, 0.4460508732591212], 
reward next is 0.5539, 
noisyNet noise sample is [array([-0.42264304], dtype=float32), -1.1214792]. 
=============================================
[2019-03-23 20:49:11,276] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2112199e-03 6.9060143e-06 9.9010032e-01 8.5948859e-06 8.6730272e-03], sum to 1.0000
[2019-03-23 20:49:11,281] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3821
[2019-03-23 20:49:11,288] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 56.0, 1.0, 2.0, 0.2121759155861498, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3960859517450299, 6.9112, 6.9112, 77.32846344354104, 460847.3953198079, 460847.3953198079, 130659.6449251621], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2286000.0000, 
sim time next is 2286600.0000, 
raw observation next is [18.0, 55.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3722918428080718, 6.9112, 6.9112, 77.32846344354104, 433150.5336043517, 433150.5336043517, 127928.4523584664], 
processed observation next is [1.0, 0.4782608695652174, 0.45454545454545453, 0.5533333333333335, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.10327406115438834, 0.0, 0.0, 0.5084288129206541, 0.1604261235571673, 0.1604261235571673, 0.3120206155084546], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.14856951], dtype=float32), -0.3046976]. 
=============================================
[2019-03-23 20:49:18,056] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.0823104e-04 1.1476065e-10 9.9979180e-01 1.1126129e-09 1.1737406e-08], sum to 1.0000
[2019-03-23 20:49:18,068] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7109
[2019-03-23 20:49:18,074] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.5, 54.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 321963.2464294387, 321963.2464294384, 138416.2383283491], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2572200.0000, 
sim time next is 2572800.0000, 
raw observation next is [21.33333333333334, 55.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 319324.7690543201, 319324.7690543203, 136215.247876103], 
processed observation next is [1.0, 0.782608695652174, 0.6060606060606063, 0.55, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11826843298308153, 0.1182684329830816, 0.3322323118929342], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.62576115], dtype=float32), 0.2513003]. 
=============================================
[2019-03-23 20:49:18,211] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.8971999e-04 4.5060629e-11 8.3389789e-02 2.9905973e-08 9.1572052e-01], sum to 1.0000
[2019-03-23 20:49:18,217] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5690
[2019-03-23 20:49:18,227] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.0, 73.0, 1.0, 2.0, 0.5206895459404148, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9490722412498723, 6.937451055231944, 6.9112, 77.32837682663747, 1142016.268857578, 1133490.472595073, 251725.0429690572], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3141600.0000, 
sim time next is 3142200.0000, 
raw observation next is [23.0, 73.0, 1.0, 2.0, 0.3373688272572548, 1.0, 1.0, 0.3373688272572548, 1.0, 2.0, 0.6805777849004427, 6.9112, 6.9112, 77.3421103, 1155593.146609352, 1155593.146609352, 266788.1967750256], 
processed observation next is [1.0, 0.34782608695652173, 0.6818181818181818, 0.73, 1.0, 1.0, 0.17171103407156849, 1.0, 0.5, 0.17171103407156849, 1.0, 1.0, 0.5436825498577754, 0.0, 0.0, 0.5085185399722538, 0.4279974617071674, 0.4279974617071674, 0.650702918963477], 
reward next is 0.3493, 
noisyNet noise sample is [array([-0.51119024], dtype=float32), -0.9226194]. 
=============================================
[2019-03-23 20:49:21,249] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 20:49:21,252] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:49:21,253] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:49:21,254] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:49:21,256] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:49:21,260] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:49:21,262] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:49:21,265] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:49:21,265] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:49:21,266] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:49:21,266] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:49:21,286] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run97
[2019-03-23 20:49:21,310] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run97
[2019-03-23 20:49:21,335] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run97
[2019-03-23 20:49:21,361] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run97
[2019-03-23 20:49:21,384] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run97
[2019-03-23 20:49:24,963] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00105929], dtype=float32), 0.017644055]
[2019-03-23 20:49:24,966] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.0, 29.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3111753309499948, 6.9112, 6.9112, 95.55338769695034, 361991.1121920058, 361991.1121920058, 130130.5157184498]
[2019-03-23 20:49:24,967] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:49:24,969] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.4165659e-05 2.0163709e-14 9.9998581e-01 2.0066260e-14 1.4555254e-12], sampled 0.009445585653613198
[2019-03-23 20:49:25,040] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00105929], dtype=float32), 0.017644055]
[2019-03-23 20:49:25,041] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.16666666666667, 98.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 285663.5719191591, 285663.5719191591, 120241.0279204536]
[2019-03-23 20:49:25,041] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:49:25,043] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.2801412e-05 1.7371093e-13 9.9997723e-01 2.3521877e-13 3.7599295e-11], sampled 0.8798156012150923
[2019-03-23 20:49:26,430] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00105929], dtype=float32), 0.017644055]
[2019-03-23 20:49:26,432] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.206153508, 74.71361565666666, 1.0, 2.0, 0.2133792341554923, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3983322838957541, 6.911199999999999, 6.9112, 81.90383549307435, 463449.9164386428, 463449.9164386431, 126947.0408653099]
[2019-03-23 20:49:26,435] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:49:26,439] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.1725967e-04 2.8669270e-14 9.9958271e-01 6.9925321e-13 1.1115939e-08], sampled 0.3543401482921683
[2019-03-23 20:49:33,244] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00105929], dtype=float32), 0.017644055]
[2019-03-23 20:49:33,245] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.16666666666666, 99.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3890528793645305, 6.9112, 6.9112, 77.32846344354104, 446652.7668385925, 446652.7668385925, 159284.0153307163]
[2019-03-23 20:49:33,247] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:49:33,249] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.8428770e-04 3.8401604e-18 9.9901569e-01 3.4709539e-16 2.9743014e-11], sampled 0.9071474321657109
[2019-03-23 20:49:40,280] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00105929], dtype=float32), 0.017644055]
[2019-03-23 20:49:40,281] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.7, 73.0, 1.0, 2.0, 0.2659476869286592, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5244006917438964, 6.9112, 6.9112, 95.55338769695034, 600911.0492213328, 600911.0492213328, 178321.7088549268]
[2019-03-23 20:49:40,282] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:49:40,283] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.1895733e-03 6.1790164e-19 9.9281043e-01 4.5526015e-16 5.7365462e-10], sampled 0.21406899783229827
[2019-03-23 20:49:50,306] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00105929], dtype=float32), 0.017644055]
[2019-03-23 20:49:50,307] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.25943696666667, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 278191.4274573138, 278191.4274573138, 115969.2266660149]
[2019-03-23 20:49:50,308] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:49:50,310] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.3475360e-05 4.2535577e-13 9.9996650e-01 7.1693855e-13 1.7851963e-10], sampled 0.16591368724775313
[2019-03-23 20:49:52,552] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00105929], dtype=float32), 0.017644055]
[2019-03-23 20:49:52,554] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.21666666666667, 87.5, 1.0, 2.0, 0.2141391503267262, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4288330737306033, 6.9112, 6.9112, 77.32846344354104, 487848.2743191046, 487848.2743191046, 166955.6222963378]
[2019-03-23 20:49:52,554] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:49:52,557] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.1267891e-03 4.6170353e-19 9.9687320e-01 1.2878562e-16 4.0323540e-11], sampled 0.9123754020087768
[2019-03-23 20:49:55,171] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00105929], dtype=float32), 0.017644055]
[2019-03-23 20:49:55,172] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.21666666666667, 71.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 340604.3078081546, 340604.3078081546, 147380.9985210006]
[2019-03-23 20:49:55,174] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:49:55,176] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.8021335e-05 5.9736147e-15 9.9997199e-01 1.4591981e-14 1.1065073e-11], sampled 0.06871832624900776
[2019-03-23 20:50:07,263] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00105929], dtype=float32), 0.017644055]
[2019-03-23 20:50:07,264] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.0, 53.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3098324640651306, 6.9112, 6.9112, 77.32846344354104, 358608.5451938103, 358608.5451938103, 146538.0435884677]
[2019-03-23 20:50:07,265] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:50:07,267] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.2691170e-05 1.3503384e-14 9.9998736e-01 1.2862551e-14 7.8516382e-13], sampled 0.22685272894360642
[2019-03-23 20:50:32,580] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00105929], dtype=float32), 0.017644055]
[2019-03-23 20:50:32,583] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [10.52075818166667, 74.84200772, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3282178858684147, 6.911199999999999, 6.9112, 95.55338769695034, 381823.0611951288, 381823.0611951292, 117800.9705539068]
[2019-03-23 20:50:32,584] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:50:32,587] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.1188293e-05 3.6900119e-13 9.9991882e-01 1.4094200e-12 1.8233225e-09], sampled 0.2662149466946292
[2019-03-23 20:51:01,222] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3565.8591 2177279509.7321 236.0000
[2019-03-23 20:51:01,560] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3522.3670 2103387321.8526 164.0000
[2019-03-23 20:51:01,593] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3108.7632 2108704682.3812 346.0000
[2019-03-23 20:51:01,634] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3356.3953 2097404835.9144 172.0000
[2019-03-23 20:51:01,680] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2759.0726 2123839051.1835 733.0000
[2019-03-23 20:51:02,695] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 2400000, evaluation results [2400000.0, 3565.8591473124106, 2177279509.732113, 236.0, 3356.395333880231, 2097404835.914355, 172.0, 3522.3670010111828, 2103387321.8525605, 164.0, 2759.072590184163, 2123839051.1834567, 733.0, 3108.7631572245887, 2108704682.381233, 346.0]
[2019-03-23 20:51:05,461] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.1438958e-05 2.5159597e-10 9.9995852e-01 3.0468383e-10 8.3871043e-09], sum to 1.0000
[2019-03-23 20:51:05,466] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7894
[2019-03-23 20:51:05,472] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.83333333333334, 42.83333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3226980276740776, 6.911199999999999, 6.9112, 77.32846344354104, 372220.5069471597, 372220.5069471599, 149260.6480421744], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2634600.0000, 
sim time next is 2635200.0000, 
raw observation next is [26.0, 42.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3226004905165509, 6.9112, 6.9112, 77.32846344354104, 372142.7993548064, 372142.7993548064, 149215.1820511311], 
processed observation next is [0.0, 0.5217391304347826, 0.8181818181818182, 0.42, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.03228641502364413, 0.0, 0.0, 0.5084288129206541, 0.13783066642770608, 0.13783066642770608, 0.3639394684173929], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.04578521], dtype=float32), 0.21698004]. 
=============================================
[2019-03-23 20:51:07,986] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.3664984e-04 6.2123497e-08 9.9975723e-01 2.2546894e-08 5.9094591e-06], sum to 1.0000
[2019-03-23 20:51:07,993] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9240
[2019-03-23 20:51:07,997] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.5, 58.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 308036.6987981489, 308036.6987981491, 128446.6347962244], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2575800.0000, 
sim time next is 2576400.0000, 
raw observation next is [20.33333333333333, 58.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 306102.730687203, 306102.730687203, 127224.9382983128], 
processed observation next is [1.0, 0.8260869565217391, 0.5606060606060604, 0.5866666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.11337138173600111, 0.11337138173600111, 0.3103047275568605], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.3883886], dtype=float32), 1.1462266]. 
=============================================
[2019-03-23 20:51:15,264] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.2555995e-05 3.1773036e-14 9.9992740e-01 3.3448735e-13 9.0509943e-12], sum to 1.0000
[2019-03-23 20:51:15,273] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1812
[2019-03-23 20:51:15,279] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.05, 79.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3466803527839113, 6.9112, 6.9112, 77.32846344354104, 399143.5646982844, 399143.5646982844, 152805.2806377678], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2681400.0000, 
sim time next is 2682000.0000, 
raw observation next is [20.0, 80.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3481736002806793, 6.911200000000001, 6.9112, 77.32846344354104, 400740.2721214349, 400740.2721214346, 153102.7981029513], 
processed observation next is [0.0, 0.043478260869565216, 0.5454545454545454, 0.8, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.068819428972399, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14842232300793887, 0.14842232300793876, 0.37342145878768607], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.18090019], dtype=float32), 0.3483766]. 
=============================================
[2019-03-23 20:51:15,295] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[24.942362]
 [24.49243 ]
 [23.77169 ]
 [23.351753]
 [23.926111]], R is [[26.11746025]
 [25.8562851 ]
 [25.59772301]
 [25.34174538]
 [25.08832741]].
[2019-03-23 20:51:20,350] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8858442e-04 3.5749219e-09 9.9904031e-01 6.3630793e-08 7.7107392e-04], sum to 1.0000
[2019-03-23 20:51:20,358] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7752
[2019-03-23 20:51:20,368] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3084148996300138, 6.911200000000001, 6.9112, 77.32846344354104, 356804.8206368309, 356804.8206368307, 146547.4767805451], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2778000.0000, 
sim time next is 2778600.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.308422407783241, 6.9112, 6.9112, 77.32846344354104, 356815.0092823989, 356815.0092823989, 146546.779157124], 
processed observation next is [1.0, 0.13043478260869565, 0.45454545454545453, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.012032011118915704, 0.0, 0.0, 0.5084288129206541, 0.13215370714162922, 0.13215370714162922, 0.3574311686759122], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4072357], dtype=float32), -2.471998]. 
=============================================
[2019-03-23 20:51:21,731] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.3690013e-02 1.0806687e-15 9.6630991e-01 3.4624749e-12 6.8259816e-09], sum to 1.0000
[2019-03-23 20:51:21,740] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1314
[2019-03-23 20:51:21,749] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 54.0, 1.0, 2.0, 0.2244395728013784, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4511231494199753, 6.9112, 6.9112, 77.32846344354104, 511949.8166195824, 511949.8166195824, 170155.5975986147], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2835600.0000, 
sim time next is 2836200.0000, 
raw observation next is [27.0, 54.0, 1.0, 2.0, 0.2236370066535883, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4495057730654382, 6.911199999999999, 6.9112, 77.32846344354104, 510116.9799946865, 510116.9799946868, 169990.0549506842], 
processed observation next is [1.0, 0.8260869565217391, 0.8636363636363636, 0.54, 1.0, 1.0, 0.029546258316985353, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2135796758077689, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18893221481284686, 0.18893221481284697, 0.41460989012362], 
reward next is 0.5854, 
noisyNet noise sample is [array([-0.49641228], dtype=float32), 0.68249816]. 
=============================================
[2019-03-23 20:51:23,112] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.1208594e-02 2.2980754e-12 9.8863912e-01 3.2735739e-10 1.5232612e-04], sum to 1.0000
[2019-03-23 20:51:23,122] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0913
[2019-03-23 20:51:23,128] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.2413839403795783, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4844806306713196, 6.9112, 6.9112, 77.32846344354104, 550394.0224676426, 550394.0224676426, 173195.996384735], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2862000.0000, 
sim time next is 2862600.0000, 
raw observation next is [21.83333333333334, 83.83333333333334, 1.0, 2.0, 0.2833202028911168, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5685899783594615, 6.911199999999999, 6.9112, 77.32846344354104, 646056.894854254, 646056.8948542542, 182962.1950059682], 
processed observation next is [1.0, 0.13043478260869565, 0.628787878787879, 0.8383333333333334, 1.0, 1.0, 0.104150253613896, 0.0, 1.0, -0.25, 1.0, 1.0, 0.38369996908494497, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23928033142750146, 0.23928033142750155, 0.4462492561121176], 
reward next is 0.5538, 
noisyNet noise sample is [array([0.5262291], dtype=float32), -0.5453093]. 
=============================================
[2019-03-23 20:51:24,506] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.6268845e-04 6.4788717e-14 9.9943596e-01 8.0176699e-12 1.3507092e-06], sum to 1.0000
[2019-03-23 20:51:24,517] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6272
[2019-03-23 20:51:24,520] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.16666666666667, 82.16666666666667, 1.0, 2.0, 0.2249131641756651, 0.0, 2.0, 0.0, 1.0, 2.0, 0.451548971984941, 6.9112, 6.9112, 77.32846344354104, 512863.1398612499, 512863.1398612499, 169853.2796128352], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2854200.0000, 
sim time next is 2854800.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.2252081003268005, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4519502790570634, 6.9112, 6.9112, 77.32846344354104, 513467.7725995056, 513467.7725995056, 169773.4245211284], 
processed observation next is [1.0, 0.043478260869565216, 0.6363636363636364, 0.83, 1.0, 1.0, 0.03151012540850061, 0.0, 1.0, -0.25, 1.0, 1.0, 0.21707182722437635, 0.0, 0.0, 0.5084288129206541, 0.190173249110928, 0.190173249110928, 0.41408152322226444], 
reward next is 0.5859, 
noisyNet noise sample is [array([-1.0833198], dtype=float32), 0.29673064]. 
=============================================
[2019-03-23 20:51:27,163] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3636060e-03 1.8370453e-13 9.9842888e-01 1.3619109e-11 2.0743697e-04], sum to 1.0000
[2019-03-23 20:51:27,176] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5314
[2019-03-23 20:51:27,179] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.2685886666380466, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5440741998177577, 6.911199999999999, 6.9112, 77.32846344354104, 610437.6413062186, 610437.6413062189, 185255.0080822666], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2942400.0000, 
sim time next is 2943000.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.268287564645886, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5434642018192171, 6.9112, 6.9112, 77.32846344354104, 609754.200936164, 609754.200936164, 185176.9863028363], 
processed observation next is [1.0, 0.043478260869565216, 0.6363636363636364, 1.0, 1.0, 1.0, 0.08535945580735747, 0.0, 1.0, -0.25, 1.0, 1.0, 0.34780600259888156, 0.0, 0.0, 0.5084288129206541, 0.2258348892356163, 0.2258348892356163, 0.4516511861044788], 
reward next is 0.5483, 
noisyNet noise sample is [array([0.2603835], dtype=float32), -0.20775338]. 
=============================================
[2019-03-23 20:51:27,195] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[44.073086]
 [44.05843 ]
 [44.37627 ]
 [44.194984]
 [44.769726]], R is [[44.5792923 ]
 [44.68165588]
 [44.78279877]
 [44.88284683]
 [44.98197937]].
[2019-03-23 20:51:27,403] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.7048719e-04 1.6074981e-12 4.4548656e-03 7.8118498e-09 9.9527466e-01], sum to 1.0000
[2019-03-23 20:51:27,409] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5958
[2019-03-23 20:51:27,412] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 73.33333333333333, 1.0, 2.0, 0.5168722260234542, 1.0, 2.0, 0.5022245499533344, 1.0, 2.0, 0.9865530188920543, 6.911199999999999, 6.9112, 77.3421103, 1694697.901015318, 1694697.901015318, 358740.5213898192], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2907600.0000, 
sim time next is 2908200.0000, 
raw observation next is [26.5, 76.16666666666667, 1.0, 2.0, 0.5090711614248332, 1.0, 2.0, 0.4983240176540239, 1.0, 2.0, 0.9865530188920543, 6.911199999999999, 6.9112, 77.3421103, 1681516.462666981, 1681516.462666981, 357331.212075408], 
processed observation next is [1.0, 0.6521739130434783, 0.8409090909090909, 0.7616666666666667, 1.0, 1.0, 0.3863389517810415, 1.0, 1.0, 0.37290502206752985, 1.0, 1.0, 0.9807900269886491, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.6227838750618447, 0.6227838750618447, 0.8715395416473366], 
reward next is 0.1285, 
noisyNet noise sample is [array([0.41025737], dtype=float32), -1.7155833]. 
=============================================
[2019-03-23 20:51:35,123] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.7752894e-03 1.1043079e-08 3.5514455e-02 5.1848730e-07 9.6170968e-01], sum to 1.0000
[2019-03-23 20:51:35,130] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7112
[2019-03-23 20:51:35,134] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [18.66666666666667, 84.83333333333333, 1.0, 2.0, 0.2212491328894046, 1.0, 1.0, 0.2212491328894046, 1.0, 2.0, 0.431052542714926, 6.9112, 6.9112, 77.3421103, 744129.879149667, 744129.879149667, 215265.5485101147], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3055800.0000, 
sim time next is 3056400.0000, 
raw observation next is [19.0, 83.0, 1.0, 2.0, 0.2098989968641927, 1.0, 2.0, 0.2098989968641927, 1.0, 2.0, 0.410671795189577, 6.911199999999999, 6.9112, 77.3421103, 707975.1413239522, 707975.1413239526, 213978.6225900462], 
processed observation next is [1.0, 0.391304347826087, 0.5, 0.83, 1.0, 1.0, 0.012373746080240854, 1.0, 1.0, 0.012373746080240854, 1.0, 1.0, 0.15810256455653865, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.2622130153051675, 0.2622130153051676, 0.5218990794879176], 
reward next is 0.4781, 
noisyNet noise sample is [array([1.1046538], dtype=float32), 0.096116975]. 
=============================================
[2019-03-23 20:51:40,987] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4257688e-03 3.1893516e-11 1.7275307e-02 1.5368570e-08 9.8129886e-01], sum to 1.0000
[2019-03-23 20:51:40,998] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6471
[2019-03-23 20:51:41,001] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.0, 65.0, 1.0, 2.0, 0.3429224437451114, 1.0, 2.0, 0.3429224437451114, 1.0, 2.0, 0.6941161896591034, 6.911199999999999, 6.9112, 77.3421103, 1172779.392670528, 1172779.392670528, 273279.5431819785], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3412800.0000, 
sim time next is 3413400.0000, 
raw observation next is [25.33333333333334, 64.5, 1.0, 2.0, 0.3011518267986157, 1.0, 2.0, 0.3011518267986157, 1.0, 2.0, 0.60967323388346, 6.911199999999999, 6.9112, 77.3421103, 1029507.73701593, 1029507.73701593, 257887.3844991509], 
processed observation next is [1.0, 0.5217391304347826, 0.7878787878787882, 0.645, 1.0, 1.0, 0.1264397834982696, 1.0, 1.0, 0.1264397834982696, 1.0, 1.0, 0.44239033411922857, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.38129916185775187, 0.38129916185775187, 0.6289936207296364], 
reward next is 0.3710, 
noisyNet noise sample is [array([-0.30797383], dtype=float32), -0.043470394]. 
=============================================
[2019-03-23 20:51:41,250] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.3582920e-05 1.6171583e-11 9.9993646e-01 5.6184651e-11 3.8249020e-08], sum to 1.0000
[2019-03-23 20:51:41,256] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1455
[2019-03-23 20:51:41,260] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.66666666666667, 69.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3368911083810359, 6.911199999999999, 6.9112, 77.32846344354104, 387472.9961180944, 387472.9961180947, 151997.2493905099], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3919800.0000, 
sim time next is 3920400.0000, 
raw observation next is [22.0, 69.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3446965803658902, 6.911200000000001, 6.9112, 77.32846344354104, 395988.5984968066, 395988.5984968063, 153376.8140711992], 
processed observation next is [0.0, 0.391304347826087, 0.6363636363636364, 0.69, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.06385225766555742, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14666244388770613, 0.14666244388770602, 0.374089790417559], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1991154], dtype=float32), -1.3484925]. 
=============================================
[2019-03-23 20:51:43,944] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3153979e-01 3.3233516e-12 6.9298416e-01 2.8834654e-08 1.7547601e-01], sum to 1.0000
[2019-03-23 20:51:43,953] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7416
[2019-03-23 20:51:43,959] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.3459916835437646, 0.0, 1.0, 0.0, 1.0, 2.0, 0.69245921090267, 6.9112, 6.9112, 77.32846344354104, 788283.8814260594, 788283.8814260594, 199203.341974456], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3405600.0000, 
sim time next is 3406200.0000, 
raw observation next is [22.5, 75.83333333333333, 1.0, 2.0, 0.3783432760249195, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7571777294095685, 6.911199999999999, 6.9112, 77.32846344354104, 862043.3110582113, 862043.3110582115, 209416.4853969823], 
processed observation next is [1.0, 0.43478260869565216, 0.6590909090909091, 0.7583333333333333, 1.0, 1.0, 0.22292909503114938, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6531110420136693, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3192753003919301, 0.3192753003919302, 0.5107719156023959], 
reward next is 0.4892, 
noisyNet noise sample is [array([1.4927382], dtype=float32), 0.3000063]. 
=============================================
[2019-03-23 20:51:46,130] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.8808238e-04 1.4475254e-10 9.9961191e-01 3.4743593e-11 3.4954819e-08], sum to 1.0000
[2019-03-23 20:51:46,137] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4261
[2019-03-23 20:51:46,140] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.5, 70.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 343517.5914223178, 343517.5914223181, 143685.8495870462], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3277800.0000, 
sim time next is 3278400.0000, 
raw observation next is [19.0, 72.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 337340.6700351484, 337340.6700351482, 142342.2903111183], 
processed observation next is [0.0, 0.9565217391304348, 0.5, 0.7266666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12494098890190682, 0.12494098890190675, 0.3471763178319959], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7987472], dtype=float32), 0.37673977]. 
=============================================
[2019-03-23 20:51:52,383] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 20:51:52,384] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:51:52,385] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:51:52,386] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:51:52,388] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:51:52,388] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:51:52,389] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:51:52,391] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:51:52,391] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:51:52,392] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:51:52,393] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:51:52,408] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run98
[2019-03-23 20:51:52,437] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run98
[2019-03-23 20:51:52,461] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run98
[2019-03-23 20:51:52,488] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run98
[2019-03-23 20:51:52,515] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run98
[2019-03-23 20:51:55,842] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00081579], dtype=float32), 0.017486323]
[2019-03-23 20:51:55,842] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.33333333333333, 64.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 322310.3345658108, 322310.3345658108, 140152.2095257329]
[2019-03-23 20:51:55,843] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:51:55,846] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.3438863e-05 9.0474850e-10 9.9991620e-01 1.3390943e-09 3.8385440e-07], sampled 0.8727173525998221
[2019-03-23 20:52:03,647] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00081579], dtype=float32), 0.017486323]
[2019-03-23 20:52:03,647] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.40283153666667, 90.53201414666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3918197414348766, 6.911200000000001, 6.9112, 95.55338769695034, 448867.9923631935, 448867.9923631931, 165099.8815215573]
[2019-03-23 20:52:03,648] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:52:03,653] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.8710269e-04 3.9756623e-14 9.9951279e-01 9.3895150e-13 1.2508779e-07], sampled 0.6985140492589024
[2019-03-23 20:52:16,444] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00081579], dtype=float32), 0.017486323]
[2019-03-23 20:52:16,445] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.5, 54.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 309284.0800290594, 309284.0800290597, 121981.0286697054]
[2019-03-23 20:52:16,446] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:52:16,448] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.3978422e-05 4.8320997e-10 9.9990594e-01 5.3173482e-10 7.9350087e-08], sampled 0.03741826695872952
[2019-03-23 20:52:23,768] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00081579], dtype=float32), 0.017486323]
[2019-03-23 20:52:23,768] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.42884125666667, 76.00406324666668, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3895081062043694, 6.9112, 6.9112, 95.55338769695034, 446075.6829639928, 446075.6829639928, 164912.0027985206]
[2019-03-23 20:52:23,769] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:52:23,771] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.5319502e-04 1.7501278e-14 9.9944669e-01 4.6509693e-13 6.6055122e-08], sampled 0.9697282448060892
[2019-03-23 20:52:27,977] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00081579], dtype=float32), 0.017486323]
[2019-03-23 20:52:27,978] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.06993727, 99.57554998666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 326782.1299122914, 326782.1299122914, 145299.091647568]
[2019-03-23 20:52:27,979] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:52:27,981] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.5255750e-05 6.3667523e-11 9.9991405e-01 1.8619432e-10 7.2121372e-07], sampled 0.2149734270700292
[2019-03-23 20:52:57,101] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00081579], dtype=float32), 0.017486323]
[2019-03-23 20:52:57,103] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [29.9, 51.0, 1.0, 2.0, 0.4667282817521082, 1.0, 2.0, 0.4667282817521082, 1.0, 2.0, 0.9440647339651155, 6.9112, 6.9112, 77.3421103, 1574753.310074459, 1574753.310074459, 341615.9642299878]
[2019-03-23 20:52:57,104] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:52:57,106] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.8919199e-05 1.1650645e-12 1.0848180e-03 1.1588343e-09 9.9885631e-01], sampled 0.8186730857049722
[2019-03-23 20:53:01,388] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00081579], dtype=float32), 0.017486323]
[2019-03-23 20:53:01,390] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.73725904166666, 93.83925595, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3700340069807497, 6.9112, 6.9112, 95.55338769695034, 425158.6192596799, 425158.6192596799, 161084.9811189721]
[2019-03-23 20:53:01,391] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:53:01,394] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.4389619e-04 5.0291341e-13 9.9985600e-01 3.8200003e-12 1.3105102e-07], sampled 0.8451250281014134
[2019-03-23 20:53:21,243] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00081579], dtype=float32), 0.017486323]
[2019-03-23 20:53:21,244] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.6, 78.0, 1.0, 2.0, 0.2306693102953194, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4655134189392463, 6.911200000000001, 6.9112, 95.55338769695034, 526345.7150181999, 526345.7150181995, 177761.0894250372]
[2019-03-23 20:53:21,245] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:53:21,247] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.4248961e-03 1.6115317e-16 9.9257505e-01 4.2739863e-14 9.9198481e-08], sampled 0.12402351426961866
[2019-03-23 20:53:31,860] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2849.8922 2138970743.1040 161.0000
[2019-03-23 20:53:32,483] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3341.9866 2101030175.9256 69.0000
[2019-03-23 20:53:32,503] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3503.6188 2199489058.8534 45.0000
[2019-03-23 20:53:32,584] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3500.6154 2107139184.8050 54.0000
[2019-03-23 20:53:32,618] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3146.8579 2116308165.9892 86.0000
[2019-03-23 20:53:33,633] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 2425000, evaluation results [2425000.0, 3503.6187610721613, 2199489058.8533955, 45.0, 3341.986564364189, 2101030175.9255924, 69.0, 3500.615352663761, 2107139184.8049705, 54.0, 2849.8921505200683, 2138970743.1039615, 161.0, 3146.8579218214127, 2116308165.9892056, 86.0]
[2019-03-23 20:53:34,747] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.0449727e-06 5.6618685e-13 2.5549869e-04 6.4333845e-09 9.9974042e-01], sum to 1.0000
[2019-03-23 20:53:34,757] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7373
[2019-03-23 20:53:34,763] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.5, 58.0, 1.0, 2.0, 0.4156528481215787, 1.0, 2.0, 0.4156528481215787, 1.0, 2.0, 0.8413217678011308, 6.9112, 6.9112, 77.3421103, 1410708.290590541, 1410708.290590541, 311647.1316978656], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3420000.0000, 
sim time next is 3420600.0000, 
raw observation next is [27.55, 57.66666666666667, 1.0, 2.0, 0.3988681983009354, 1.0, 2.0, 0.3988681983009354, 1.0, 2.0, 0.8074194853475982, 6.911199999999999, 6.9112, 77.3421103, 1354104.416819036, 1354104.416819036, 303435.7850678798], 
processed observation next is [1.0, 0.6086956521739131, 0.8886363636363637, 0.5766666666666667, 1.0, 1.0, 0.24858524787616923, 1.0, 1.0, 0.24858524787616923, 1.0, 1.0, 0.7248849790679974, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5015201543774207, 0.5015201543774207, 0.7400872806533655], 
reward next is 0.2599, 
noisyNet noise sample is [array([-1.743423], dtype=float32), -0.3528931]. 
=============================================
[2019-03-23 20:53:35,735] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0631545e-01 6.1189308e-13 8.9307690e-01 5.6292394e-11 6.0753635e-04], sum to 1.0000
[2019-03-23 20:53:35,745] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4095
[2019-03-23 20:53:35,751] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.2592104515367967, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5248799368090831, 6.9112, 6.9112, 77.32846344354104, 590213.3560913217, 590213.3560913217, 182013.5375105054], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3450600.0000, 
sim time next is 3451200.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.2586291938818914, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5237022642526913, 6.911200000000001, 6.9112, 77.32846344354104, 588890.9458383044, 588890.9458383041, 181869.2695875031], 
processed observation next is [1.0, 0.9565217391304348, 0.6818181818181818, 0.89, 1.0, 1.0, 0.0732864923523642, 0.0, 1.0, -0.25, 1.0, 1.0, 0.31957466321813044, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2181077577178905, 0.21810775771789043, 0.4435835843597637], 
reward next is 0.5564, 
noisyNet noise sample is [array([-0.28580442], dtype=float32), -0.4467973]. 
=============================================
[2019-03-23 20:53:35,831] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.5288263e-04 3.7560905e-15 9.9903834e-01 3.5324181e-12 8.7600220e-06], sum to 1.0000
[2019-03-23 20:53:35,840] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2914
[2019-03-23 20:53:35,849] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 81.5, 1.0, 2.0, 0.2781957594763164, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5632883393306899, 6.9112, 6.9112, 77.32846344354104, 629822.5587676015, 629822.5587676015, 189052.6326265501], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3439800.0000, 
sim time next is 3440400.0000, 
raw observation next is [24.66666666666667, 84.0, 1.0, 2.0, 0.2791782612701215, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5652461973197919, 6.9112, 6.9112, 77.32846344354104, 631899.2616776883, 631899.2616776883, 189379.7581271119], 
processed observation next is [1.0, 0.8260869565217391, 0.7575757575757578, 0.84, 1.0, 1.0, 0.09897282658765189, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3789231390282741, 0.0, 0.0, 0.5084288129206541, 0.234036763584329, 0.234036763584329, 0.46190184909051685], 
reward next is 0.5381, 
noisyNet noise sample is [array([0.56219715], dtype=float32), 1.0893236]. 
=============================================
[2019-03-23 20:53:37,329] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.4024671e-01 3.9941314e-11 5.9353644e-01 4.9358446e-09 6.6216864e-02], sum to 1.0000
[2019-03-23 20:53:37,338] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0950
[2019-03-23 20:53:37,347] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 637514.9136649912 W.
[2019-03-23 20:53:37,350] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3776505477312105, 6.911199999999999, 6.9112, 77.3421103, 637514.9136649912, 637514.9136649914, 220856.6005306034], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3638400.0000, 
sim time next is 3639000.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.551832444417612, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 629493.5430944902, 629493.5430944902, 148124.2513705583], 
processed observation next is [1.0, 0.08695652173913043, 0.5909090909090909, 1.0, 1.0, 1.0, 0.439790555522015, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23314575670166304, 0.23314575670166304, 0.3612786618794105], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.84740406], dtype=float32), 0.670361]. 
=============================================
[2019-03-23 20:53:37,364] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[41.76276 ]
 [41.194298]
 [41.43144 ]
 [41.402985]
 [42.88218 ]], R is [[41.22512436]
 [40.81287384]
 [40.40474701]
 [40.43393326]
 [40.48561859]].
[2019-03-23 20:53:38,396] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.8446602e-05 4.8765512e-09 9.9990153e-01 6.6291743e-11 3.7085262e-09], sum to 1.0000
[2019-03-23 20:53:38,402] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0032
[2019-03-23 20:53:38,409] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.0, 92.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 347652.2570987027, 347652.2570987024, 144616.1308495564], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3813600.0000, 
sim time next is 3814200.0000, 
raw observation next is [17.0, 91.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 342988.0075399734, 342988.0075399734, 143653.2971562574], 
processed observation next is [0.0, 0.13043478260869565, 0.4090909090909091, 0.91, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.12703259538517533, 0.12703259538517533, 0.35037389550306686], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.72061616], dtype=float32), -0.09890748]. 
=============================================
[2019-03-23 20:53:45,706] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.9475503e-01 2.1143453e-17 8.0524498e-01 2.0317529e-13 3.1660655e-08], sum to 1.0000
[2019-03-23 20:53:45,719] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6210
[2019-03-23 20:53:45,722] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.2452255511297005, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4955882006486106, 6.911199999999999, 6.9112, 77.32846344354104, 559456.3815732728, 559456.3815732731, 177044.015344278], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3636000.0000, 
sim time next is 3636600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.393117675672269, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7948099774168482, 6.9112, 6.9112, 82.24921059666127, 896938.412029117, 896938.412029117, 223029.4399645081], 
processed observation next is [1.0, 0.08695652173913043, 0.5909090909090909, 1.0, 1.0, 1.0, 0.24139709459033626, 0.0, 1.0, -0.25, 1.0, 1.0, 0.7068713963097832, 0.0, 0.0, 0.5407823541955336, 0.3321994118626359, 0.3321994118626359, 0.5439742438158734], 
reward next is 0.4560, 
noisyNet noise sample is [array([-0.06699287], dtype=float32), 0.7460482]. 
=============================================
[2019-03-23 20:53:47,811] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.1027077e-03 1.0932916e-15 9.9089557e-01 2.6086636e-13 1.6546508e-06], sum to 1.0000
[2019-03-23 20:53:47,820] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2315
[2019-03-23 20:53:47,824] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.16666666666667, 99.00000000000001, 1.0, 2.0, 0.2608633203930756, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5273072180056704, 6.911199999999999, 6.9112, 77.32846344354104, 595097.4480396542, 595097.4480396545, 180863.0364704692], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3658200.0000, 
sim time next is 3658800.0000, 
raw observation next is [21.33333333333334, 98.0, 1.0, 2.0, 0.3750879939417204, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7585831265225199, 6.9112, 6.9112, 77.32846344354104, 855655.5905566341, 855655.5905566341, 214948.7778597798], 
processed observation next is [1.0, 0.34782608695652173, 0.6060606060606063, 0.98, 1.0, 1.0, 0.21885999242715046, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6551187521750285, 0.0, 0.0, 0.5084288129206541, 0.3169094779839386, 0.3169094779839386, 0.5242653118531214], 
reward next is 0.4757, 
noisyNet noise sample is [array([1.0471673], dtype=float32), 1.7262977]. 
=============================================
[2019-03-23 20:53:48,912] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.7757099e-02 2.2114916e-18 9.6224284e-01 2.4530069e-14 6.3882166e-09], sum to 1.0000
[2019-03-23 20:53:48,920] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0486
[2019-03-23 20:53:48,926] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.33333333333334, 72.66666666666667, 1.0, 2.0, 0.2616989166397118, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5299080326532858, 6.911200000000001, 6.9112, 77.32846344354104, 595912.9772340612, 595912.9772340609, 182597.8060911031], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3702000.0000, 
sim time next is 3702600.0000, 
raw observation next is [25.0, 74.0, 1.0, 2.0, 0.260123082792445, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5265992160847165, 6.911200000000001, 6.9112, 77.32846344354104, 592593.0254578677, 592593.0254578674, 181928.9700646756], 
processed observation next is [1.0, 0.8695652173913043, 0.7727272727272727, 0.74, 1.0, 1.0, 0.07515385349055624, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3237131658353093, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21947889831772877, 0.21947889831772868, 0.4437291952796966], 
reward next is 0.5563, 
noisyNet noise sample is [array([0.7866861], dtype=float32), 1.058191]. 
=============================================
[2019-03-23 20:53:59,517] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.9474280e-05 2.3615751e-10 9.9997044e-01 2.4041330e-10 9.9961220e-08], sum to 1.0000
[2019-03-23 20:53:59,522] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3827
[2019-03-23 20:53:59,525] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.66666666666667, 65.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 308400.7842698295, 308400.7842698297, 133447.2448276503], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3882000.0000, 
sim time next is 3882600.0000, 
raw observation next is [19.5, 66.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 305575.5055704109, 305575.5055704106, 131576.9731943994], 
processed observation next is [0.0, 0.9565217391304348, 0.5227272727272727, 0.66, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11317611317422627, 0.11317611317422614, 0.3209194468156083], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2405697], dtype=float32), -0.6586387]. 
=============================================
[2019-03-23 20:54:06,523] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3485438e-02 6.6662088e-12 9.6148413e-01 3.1008720e-09 2.5030363e-02], sum to 1.0000
[2019-03-23 20:54:06,531] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4498
[2019-03-23 20:54:06,534] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.0, 100.0, 1.0, 2.0, 0.2090847077558484, 0.0, 1.0, 0.0, 1.0, 2.0, 0.4032520271554884, 6.911199999999999, 6.9112, 77.32846344354104, 465295.5037187117, 465295.503718712, 158240.147090919], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4021200.0000, 
sim time next is 4021800.0000, 
raw observation next is [17.16666666666667, 100.0, 1.0, 2.0, 0.2422876292450358, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4677346885109264, 6.911200000000001, 6.9112, 77.32846344354104, 539603.0089823186, 539603.0089823183, 164175.1595092076], 
processed observation next is [1.0, 0.5652173913043478, 0.4166666666666669, 1.0, 1.0, 1.0, 0.05285953655629474, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2396209835870378, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1998529662897476, 0.19985296628974752, 0.40042721831514044], 
reward next is 0.5996, 
noisyNet noise sample is [array([-0.54904467], dtype=float32), 1.3803713]. 
=============================================
[2019-03-23 20:54:12,644] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.2650877e-03 6.4060951e-11 9.9565828e-01 1.3736497e-09 7.6717515e-05], sum to 1.0000
[2019-03-23 20:54:12,654] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3737
[2019-03-23 20:54:12,658] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.370049297540778, 6.9112, 6.9112, 77.32846344354104, 425043.9682034132, 425043.9682034132, 156624.5909229986], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4141200.0000, 
sim time next is 4141800.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3691688101943368, 6.9112, 6.9112, 77.32846344354104, 424033.3624393536, 424033.3624393536, 156511.3018022346], 
processed observation next is [1.0, 0.9565217391304348, 0.45454545454545453, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.09881258599190972, 0.0, 0.0, 0.5084288129206541, 0.1570493934960569, 0.1570493934960569, 0.3817348824444747], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.3238437], dtype=float32), 1.8637613]. 
=============================================
[2019-03-23 20:54:19,753] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.3601911e-04 1.0169876e-11 9.4869250e-04 6.5771175e-09 9.9881530e-01], sum to 1.0000
[2019-03-23 20:54:19,761] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0224
[2019-03-23 20:54:19,776] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.83333333333334, 51.83333333333334, 1.0, 2.0, 0.4449297034691916, 1.0, 2.0, 0.4449297034691916, 1.0, 2.0, 0.9001683322130374, 6.911199999999999, 6.9112, 81.36248861880586, 1507866.903985722, 1507866.903985722, 329390.2230752886], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4378200.0000, 
sim time next is 4378800.0000, 
raw observation next is [28.66666666666667, 51.66666666666667, 1.0, 2.0, 0.4579568155636671, 1.0, 2.0, 0.4579568155636671, 1.0, 2.0, 0.9268266890717465, 6.911199999999999, 6.9112, 77.3421103, 1553780.419540529, 1553780.419540529, 333499.1049020516], 
processed observation next is [1.0, 0.6956521739130435, 0.9393939393939396, 0.5166666666666667, 1.0, 1.0, 0.3224460194545838, 1.0, 1.0, 0.3224460194545838, 1.0, 1.0, 0.8954666986739236, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5754742294594551, 0.5754742294594551, 0.8134124509806138], 
reward next is 0.1866, 
noisyNet noise sample is [array([0.61858857], dtype=float32), 0.3161913]. 
=============================================
[2019-03-23 20:54:20,724] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4975713e-01 1.9484414e-13 8.5013926e-01 1.0194869e-10 1.0355704e-04], sum to 1.0000
[2019-03-23 20:54:20,730] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2114
[2019-03-23 20:54:20,736] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.66666666666667, 90.50000000000001, 1.0, 2.0, 0.2241044071604253, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4359184110040888, 6.911199999999999, 6.9112, 77.32846344354104, 501803.3501851574, 501803.3501851577, 162272.42486907], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4263000.0000, 
sim time next is 4263600.0000, 
raw observation next is [19.33333333333334, 87.0, 1.0, 2.0, 0.3042822681134168, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5950982273737524, 6.9112, 6.9112, 77.32846344354104, 684015.616971484, 684015.616971484, 180322.9428903951], 
processed observation next is [1.0, 0.34782608695652173, 0.5151515151515155, 0.87, 1.0, 1.0, 0.13035283514177098, 0.0, 1.0, -0.25, 1.0, 1.0, 0.42156889624821775, 0.0, 0.0, 0.5084288129206541, 0.25333911739684595, 0.25333911739684595, 0.4398120558302319], 
reward next is 0.5602, 
noisyNet noise sample is [array([0.50110924], dtype=float32), -2.3327916]. 
=============================================
[2019-03-23 20:54:23,613] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.6298260e-01 2.7738640e-09 8.3364284e-01 2.6142088e-08 3.3744299e-03], sum to 1.0000
[2019-03-23 20:54:23,618] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3452
[2019-03-23 20:54:23,622] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 99.00000000000001, 1.0, 2.0, 0.2506099331118761, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4906567954617046, 6.9112, 6.9112, 77.3284634410171, 563700.5401358835, 563700.5401358835, 168610.5270060747], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4327800.0000, 
sim time next is 4328400.0000, 
raw observation next is [18.0, 98.0, 1.0, 2.0, 0.2197136107729269, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4294800034366925, 6.911199999999999, 6.9112, 77.32846344352542, 493637.6691103821, 493637.6691103824, 162424.0361826114], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 0.98, 1.0, 1.0, 0.024642013466158602, 0.0, 1.0, -0.25, 1.0, 1.0, 0.18497143348098932, -8.881784197001253e-17, 0.0, 0.5084288129205514, 0.18282876633717857, 0.18282876633717865, 0.3961561858112473], 
reward next is 0.6038, 
noisyNet noise sample is [array([0.70816875], dtype=float32), 0.92239416]. 
=============================================
[2019-03-23 20:54:23,636] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 20:54:23,643] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:54:23,644] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:54:23,647] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:54:23,649] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:54:23,649] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:54:23,650] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:54:23,651] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:54:23,653] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:54:23,654] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:54:23,655] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:54:23,675] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run99
[2019-03-23 20:54:23,700] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run99
[2019-03-23 20:54:23,701] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run99
[2019-03-23 20:54:23,701] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run99
[2019-03-23 20:54:23,701] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run99
[2019-03-23 20:54:29,689] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00071377], dtype=float32), 0.017526673]
[2019-03-23 20:54:29,690] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.16666666666667, 92.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 221707.0125621013, 221707.0125621013, 95580.3646849756]
[2019-03-23 20:54:29,691] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:54:29,694] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.0735388e-04 1.3015616e-08 9.9919158e-01 9.0198515e-09 1.0969733e-06], sampled 0.5974128049155121
[2019-03-23 20:54:30,949] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00071377], dtype=float32), 0.017526673]
[2019-03-23 20:54:30,949] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [11.1, 86.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 95.55338769695034, 348348.3416765927, 348348.3416765931, 115880.6079177948]
[2019-03-23 20:54:30,949] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:54:30,952] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0970202e-03 1.7083844e-09 9.9889600e-01 3.0269178e-09 6.8916320e-06], sampled 0.9916558798067509
[2019-03-23 20:54:56,167] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00071377], dtype=float32), 0.017526673]
[2019-03-23 20:54:56,168] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.8977757, 47.59589421, 1.0, 2.0, 0.210292057551786, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4180714293942661, 6.9112, 6.9112, 95.55338769695034, 477384.2354961711, 477384.2354961711, 168991.2415476128]
[2019-03-23 20:54:56,169] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:54:56,171] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.0463273e-04 4.1251555e-12 9.9979538e-01 3.4676259e-12 2.2530804e-09], sampled 0.9246502246926928
[2019-03-23 20:54:57,010] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00071377], dtype=float32), 0.017526673]
[2019-03-23 20:54:57,010] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.26293414666667, 80.89626859, 1.0, 2.0, 0.2560207108846947, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5184741758878579, 6.9112, 6.9112, 95.55338769695034, 582713.2679367595, 582713.2679367595, 186112.7164015287]
[2019-03-23 20:54:57,011] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:54:57,015] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.0732517e-03 2.1425503e-13 9.9492657e-01 1.7906605e-12 1.3840750e-07], sampled 0.2390258568541126
[2019-03-23 20:55:03,957] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00071377], dtype=float32), 0.017526673]
[2019-03-23 20:55:03,958] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.85355486, 84.44753397666666, 1.0, 2.0, 0.2225100199041073, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4437305415594698, 6.911200000000001, 6.9112, 95.55338769695034, 505934.0022128588, 505934.0022128584, 172082.7416489755]
[2019-03-23 20:55:03,961] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:55:03,965] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5617671e-03 4.7247763e-13 9.9843818e-01 1.3160088e-12 1.5194827e-08], sampled 0.4017564951502035
[2019-03-23 20:55:05,015] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00071377], dtype=float32), 0.017526673]
[2019-03-23 20:55:05,017] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.15679162, 67.68496399333333, 1.0, 2.0, 0.251982648014077, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5084920737871641, 6.9112, 6.9112, 95.55338769695034, 575005.6363097997, 575005.6363097997, 182517.2510011578]
[2019-03-23 20:55:05,017] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:55:05,019] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.1273405e-03 4.1433649e-12 9.9787164e-01 1.9178981e-11 1.1205202e-06], sampled 0.5704765919757124
[2019-03-23 20:55:10,474] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00071377], dtype=float32), 0.017526673]
[2019-03-23 20:55:10,477] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.08959943, 95.68403028333333, 1.0, 2.0, 0.207490633371395, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4117512926048679, 6.9112, 6.9112, 95.55338769695034, 470551.8052958632, 470551.8052958632, 168058.0213673132]
[2019-03-23 20:55:10,478] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:55:10,484] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.3715695e-03 7.3371369e-14 9.9262834e-01 9.6593642e-13 1.3612805e-07], sampled 0.05569542366356017
[2019-03-23 20:55:30,003] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00071377], dtype=float32), 0.017526673]
[2019-03-23 20:55:30,004] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.81154935, 65.70054480333334, 1.0, 2.0, 0.3909817474243069, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7902922391099998, 6.911200000000001, 6.9112, 95.55338769695034, 892066.4113418574, 892066.4113418569, 225175.6214485845]
[2019-03-23 20:55:30,007] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:55:30,010] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0484149e-02 8.9517110e-10 6.8256086e-01 2.5538348e-08 3.0695501e-01], sampled 0.8052798626999104
[2019-03-23 20:55:43,527] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00071377], dtype=float32), 0.017526673]
[2019-03-23 20:55:43,528] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [10.65934636, 91.89479221, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3609637329582113, 6.9112, 6.9112, 95.55338769695034, 419930.3332765427, 419930.3332765427, 124184.91386831]
[2019-03-23 20:55:43,529] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:55:43,532] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.6194729e-03 2.8933617e-10 9.9837661e-01 6.8311340e-10 3.9576094e-06], sampled 0.1456461304043134
[2019-03-23 20:55:55,245] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00071377], dtype=float32), 0.017526673]
[2019-03-23 20:55:55,247] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.73660413, 93.83919522333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3290168775020245, 6.9112, 6.9112, 95.55338769695034, 379748.2294900888, 379748.2294900888, 154299.1987088266]
[2019-03-23 20:55:55,248] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:55:55,252] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.3979706e-03 7.4810089e-12 9.9860173e-01 2.2145022e-11 3.1188569e-07], sampled 0.07679203923585298
[2019-03-23 20:55:56,933] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00071377], dtype=float32), 0.017526673]
[2019-03-23 20:55:56,935] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.76666666666667, 78.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 227306.7780089716, 227306.7780089712, 101449.5151383162]
[2019-03-23 20:55:56,936] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:55:56,939] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.2664895e-04 5.0996651e-09 9.9947232e-01 4.6958908e-09 1.0325106e-06], sampled 0.6447047042952736
[2019-03-23 20:56:03,293] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3122.9648 2119566591.0112 79.0000
[2019-03-23 20:56:03,347] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3321.1803 2104191341.8041 59.0000
[2019-03-23 20:56:03,381] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3497.7793 2108945629.9029 43.0000
[2019-03-23 20:56:03,396] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2857.7997 2143260755.4188 106.0000
[2019-03-23 20:56:03,644] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3499.4453 2203315333.7360 24.0000
[2019-03-23 20:56:04,663] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 2450000, evaluation results [2450000.0, 3499.4452923451026, 2203315333.7360134, 24.0, 3321.1802773366076, 2104191341.8040519, 59.0, 3497.7793316280267, 2108945629.902943, 43.0, 2857.799729497256, 2143260755.4188118, 106.0, 3122.964779095587, 2119566591.0112343, 79.0]
[2019-03-23 20:56:06,522] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4733970e-03 1.4117208e-13 9.9852657e-01 4.8717681e-13 4.7271427e-09], sum to 1.0000
[2019-03-23 20:56:06,530] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9977
[2019-03-23 20:56:06,534] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.66666666666667, 69.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3832674391508128, 6.9112, 6.9112, 77.32846344354104, 438551.6346627735, 438551.6346627735, 159806.9540157652], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4546200.0000, 
sim time next is 4546800.0000, 
raw observation next is [23.0, 69.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3926340963558103, 6.9112, 6.9112, 77.32846344354104, 448737.5953562265, 448737.5953562265, 161517.5780868644], 
processed observation next is [0.0, 0.6521739130434783, 0.6818181818181818, 0.69, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.13233442336544332, 0.0, 0.0, 0.5084288129206541, 0.166199109391195, 0.166199109391195, 0.3939453124069864], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.2699954], dtype=float32), 0.50022423]. 
=============================================
[2019-03-23 20:56:10,577] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3908289e-03 2.8862448e-14 9.9860877e-01 1.5368267e-12 4.2553367e-07], sum to 1.0000
[2019-03-23 20:56:10,588] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3249
[2019-03-23 20:56:10,593] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [15.0, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 223748.5294962382, 223748.5294962382, 93544.06959010512], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4690800.0000, 
sim time next is 4691400.0000, 
raw observation next is [15.33333333333333, 76.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 229491.2004075262, 229491.2004075265, 95257.2396700082], 
processed observation next is [1.0, 0.30434782608695654, 0.3333333333333332, 0.7616666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08499674089167637, 0.08499674089167648, 0.23233473090245904], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3982753], dtype=float32), -0.62543845]. 
=============================================
[2019-03-23 20:56:18,308] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.4722960e-05 1.1209413e-09 9.9990988e-01 9.6880557e-09 5.3331746e-06], sum to 1.0000
[2019-03-23 20:56:18,315] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1141
[2019-03-23 20:56:18,319] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 285483.3747169706, 285483.3747169703, 117600.4143124139], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4584000.0000, 
sim time next is 4584600.0000, 
raw observation next is [16.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 285314.1905234528, 285314.1905234528, 117560.5992930113], 
processed observation next is [1.0, 0.043478260869565216, 0.36363636363636365, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.10567192241609363, 0.10567192241609363, 0.28673316900734463], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.02813747], dtype=float32), 1.9665517]. 
=============================================
[2019-03-23 20:56:22,923] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.0619704e-04 5.2509497e-11 9.9959356e-01 6.8388090e-10 2.5874061e-07], sum to 1.0000
[2019-03-23 20:56:22,933] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7072
[2019-03-23 20:56:22,938] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.0, 82.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 264002.4425163615, 264002.4425163615, 107779.0921807346], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4672200.0000, 
sim time next is 4672800.0000, 
raw observation next is [16.0, 82.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 263223.9488120929, 263223.9488120926, 107625.086510811], 
processed observation next is [1.0, 0.08695652173913043, 0.36363636363636365, 0.82, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09749035141188625, 0.09749035141188615, 0.26250021100197807], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6375189], dtype=float32), -0.5720281]. 
=============================================
[2019-03-23 20:56:26,176] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.4921034e-05 7.3211923e-13 9.9993503e-01 1.9079183e-12 3.0511721e-08], sum to 1.0000
[2019-03-23 20:56:26,181] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4244
[2019-03-23 20:56:26,190] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.5, 80.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3798219577817724, 6.911200000000001, 6.9112, 77.32846344354104, 435785.3221180676, 435785.3221180674, 158316.2150085811], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4746600.0000, 
sim time next is 4747200.0000, 
raw observation next is [20.33333333333333, 81.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3752770985277887, 6.9112, 6.9112, 77.32846344354104, 430702.0739668212, 430702.0739668212, 157607.3232319324], 
processed observation next is [1.0, 0.9565217391304348, 0.5606060606060604, 0.8133333333333332, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.10753871218255527, 0.0, 0.0, 0.5084288129206541, 0.15951928665437823, 0.15951928665437823, 0.38440810544373755], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.39125186], dtype=float32), -0.019624216]. 
=============================================
[2019-03-23 20:56:28,303] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.9535793e-04 6.6495425e-12 9.9972159e-01 1.3545269e-10 8.3033381e-05], sum to 1.0000
[2019-03-23 20:56:28,311] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0512
[2019-03-23 20:56:28,317] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3287226929723988, 6.9112, 6.9112, 77.32846344354104, 380854.8171019695, 380854.8171019695, 148286.2237805625], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4952400.0000, 
sim time next is 4953000.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3090563969240534, 6.9112, 6.9112, 77.32846344354104, 358105.303235538, 358105.303235538, 146043.3901851104], 
processed observation next is [1.0, 0.30434782608695654, 0.4090909090909091, 0.94, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.012937709891504874, 0.0, 0.0, 0.5084288129206541, 0.13263159379094, 0.13263159379094, 0.3562033906953912], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9723706], dtype=float32), 2.1442232]. 
=============================================
[2019-03-23 20:56:28,343] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[35.50061 ]
 [35.544453]
 [34.312862]
 [33.137207]
 [32.362545]], R is [[34.66007233]
 [34.31347275]
 [33.97033691]
 [33.63063431]
 [33.29432678]].
[2019-03-23 20:56:33,678] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.2619771e-04 1.9710342e-15 9.9937844e-01 5.3092491e-12 3.9529949e-04], sum to 1.0000
[2019-03-23 20:56:33,687] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9075
[2019-03-23 20:56:33,690] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.2153077361562127, 0.0, 2.0, 0.0, 1.0, 2.0, 0.43198896759647, 6.9112, 6.9112, 77.32846344354104, 490849.1951359101, 490849.1951359101, 167752.101222896], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5202000.0000, 
sim time next is 5202600.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.2330641115731412, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4676724558456675, 6.9112, 6.9112, 77.32846344354104, 531373.0217937328, 531373.0217937328, 171352.7775057601], 
processed observation next is [1.0, 0.21739130434782608, 0.6363636363636364, 0.83, 1.0, 1.0, 0.041330139466426476, 0.0, 1.0, -0.25, 1.0, 1.0, 0.23953207977952506, 0.0, 0.0, 0.5084288129206541, 0.1968048228865677, 0.1968048228865677, 0.41793360367258564], 
reward next is 0.5821, 
noisyNet noise sample is [array([-1.2811594], dtype=float32), 2.9393013]. 
=============================================
[2019-03-23 20:56:39,760] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.2597759e-04 9.0844339e-11 2.7018782e-02 1.4284504e-08 9.7225517e-01], sum to 1.0000
[2019-03-23 20:56:39,768] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1647
[2019-03-23 20:56:39,774] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.48333333333333, 54.66666666666667, 1.0, 2.0, 0.4281817964229783, 1.0, 2.0, 0.4281817964229783, 1.0, 2.0, 0.8664400323363677, 6.911200000000001, 6.9112, 79.72385527075286, 1451880.582548117, 1451880.582548116, 319667.548145617], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5314200.0000, 
sim time next is 5314800.0000, 
raw observation next is [28.66666666666667, 54.33333333333334, 1.0, 2.0, 0.3562145360385321, 1.0, 2.0, 0.3562145360385321, 1.0, 2.0, 0.7206557877187042, 6.9112, 6.9112, 77.3421103, 1206836.192269205, 1206836.192269205, 285169.0093836171], 
processed observation next is [1.0, 0.5217391304347826, 0.9393939393939396, 0.5433333333333334, 1.0, 1.0, 0.1952681700481651, 1.0, 1.0, 0.1952681700481651, 1.0, 1.0, 0.6009368395981489, 0.0, 0.0, 0.5085185399722538, 0.446976367507113, 0.446976367507113, 0.6955341692283343], 
reward next is 0.3045, 
noisyNet noise sample is [array([0.7142648], dtype=float32), -0.7483025]. 
=============================================
[2019-03-23 20:56:41,968] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.6269045e-03 6.1733408e-16 9.9037313e-01 1.3367444e-13 3.8983279e-09], sum to 1.0000
[2019-03-23 20:56:41,983] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9622
[2019-03-23 20:56:41,991] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.7, 73.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3046138403762377, 6.9112, 6.9112, 77.32846344354104, 352720.414511594, 352720.414511594, 145801.4026068556], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5277600.0000, 
sim time next is 5278200.0000, 
raw observation next is [19.63333333333333, 73.83333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.378252465200918, 6.9112, 6.9112, 77.32846344354104, 437909.4764870738, 437909.4764870738, 154456.6314881517], 
processed observation next is [1.0, 0.08695652173913043, 0.5287878787878786, 0.7383333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.11178923600131144, 0.0, 0.0, 0.5084288129206541, 0.16218869499521252, 0.16218869499521252, 0.37672349143451633], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5670227], dtype=float32), -0.23954466]. 
=============================================
[2019-03-23 20:56:45,850] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.7320441e-04 5.6523443e-19 9.9972683e-01 1.8228894e-16 6.2705091e-10], sum to 1.0000
[2019-03-23 20:56:45,858] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7446
[2019-03-23 20:56:45,861] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.2001938264790531, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3975999340398113, 6.9112, 6.9112, 77.32846344354104, 454246.5317526616, 454246.5317526616, 162315.6660786452], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5115000.0000, 
sim time next is 5115600.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.2002408377050359, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3976948406299047, 6.9112, 6.9112, 77.32846344354104, 454354.2180964559, 454354.2180964559, 162324.624637052], 
processed observation next is [0.0, 0.21739130434782608, 0.5909090909090909, 0.83, 1.0, 1.0, 0.00030104713129485566, 0.0, 1.0, -0.25, 1.0, 1.0, 0.13956405804272098, 0.0, 0.0, 0.5084288129206541, 0.16827934003572442, 0.16827934003572442, 0.3959137186269561], 
reward next is 0.6041, 
noisyNet noise sample is [array([0.51155156], dtype=float32), 1.8582534]. 
=============================================
[2019-03-23 20:56:46,751] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0604352e-03 5.3458723e-18 9.9893957e-01 9.8558992e-15 8.9896179e-09], sum to 1.0000
[2019-03-23 20:56:46,758] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7254
[2019-03-23 20:56:46,768] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.5, 80.5, 1.0, 2.0, 0.2208431082207553, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4436327890909839, 6.9112, 6.9112, 77.32846344354104, 503662.6630114675, 503662.6630114675, 169231.1804758173], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5128200.0000, 
sim time next is 5128800.0000, 
raw observation next is [22.66666666666666, 79.66666666666667, 1.0, 2.0, 0.2211148642469216, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4443481942224112, 6.911200000000001, 6.9112, 77.32846344354104, 504335.1532131841, 504335.1532131838, 169415.3253867032], 
processed observation next is [0.0, 0.34782608695652173, 0.6666666666666664, 0.7966666666666667, 1.0, 1.0, 0.026393580308651972, 0.0, 1.0, -0.25, 1.0, 1.0, 0.206211706032016, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18679079748636448, 0.18679079748636437, 0.41320811069927604], 
reward next is 0.5868, 
noisyNet noise sample is [array([-0.84283835], dtype=float32), -1.6564627]. 
=============================================
[2019-03-23 20:56:48,794] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.8184878e-03 4.3635437e-10 1.9081376e-01 1.2654300e-07 8.0636758e-01], sum to 1.0000
[2019-03-23 20:56:48,801] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5041
[2019-03-23 20:56:48,804] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.93333333333333, 67.16666666666666, 1.0, 2.0, 0.2446148301491187, 1.0, 2.0, 0.2446148301491187, 1.0, 2.0, 0.4891538143702746, 6.911199999999999, 6.9112, 77.3421103, 835715.160588784, 835715.1605887843, 230641.8487552471], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5910600.0000, 
sim time next is 5911200.0000, 
raw observation next is [23.3, 66.0, 1.0, 2.0, 0.2515663526988006, 1.0, 2.0, 0.2515663526988006, 1.0, 2.0, 0.5039700095334263, 6.911200000000001, 6.9112, 77.3421103, 860123.2492336349, 860123.2492336347, 233492.0070263713], 
processed observation next is [1.0, 0.43478260869565216, 0.6954545454545454, 0.66, 1.0, 1.0, 0.06445794087350076, 1.0, 1.0, 0.06445794087350076, 1.0, 1.0, 0.29138572790489475, 8.881784197001253e-17, 0.0, 0.5085185399722538, 0.31856416638282775, 0.31856416638282764, 0.5694927000643203], 
reward next is 0.4305, 
noisyNet noise sample is [array([-1.0501086], dtype=float32), 0.2225686]. 
=============================================
[2019-03-23 20:56:49,697] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.9191088e-04 9.2400392e-18 9.9980813e-01 3.2697660e-14 8.3535641e-09], sum to 1.0000
[2019-03-23 20:56:49,709] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1040
[2019-03-23 20:56:49,714] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.2200883563523202, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4416113843190523, 6.9112, 6.9112, 77.32846344354104, 501764.9781219977, 501764.9781219977, 168705.9093241838], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5185200.0000, 
sim time next is 5185800.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.2196503239747877, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4407286633345993, 6.9112, 6.9112, 77.32846344354104, 500764.4016974586, 500764.4016974586, 168616.942922011], 
processed observation next is [1.0, 0.0, 0.6363636363636364, 0.83, 1.0, 1.0, 0.024562904968484615, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2010409476208562, 0.0, 0.0, 0.5084288129206541, 0.18546829692498465, 0.18546829692498465, 0.41126083639514877], 
reward next is 0.5887, 
noisyNet noise sample is [array([-0.63800615], dtype=float32), -0.8516672]. 
=============================================
[2019-03-23 20:56:54,705] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 20:56:54,706] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:56:54,706] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:56:54,707] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:56:54,707] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:56:54,708] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:56:54,709] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:56:54,709] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:56:54,711] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:56:54,708] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:56:54,714] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:56:54,742] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run100
[2019-03-23 20:56:54,742] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run100
[2019-03-23 20:56:54,791] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run100
[2019-03-23 20:56:54,823] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run100
[2019-03-23 20:56:54,851] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run100
[2019-03-23 20:57:10,948] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00076463], dtype=float32), 0.017654853]
[2019-03-23 20:57:10,949] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.84889617, 94.98928552, 1.0, 2.0, 0.3263869709079535, 1.0, 2.0, 0.3263869709079535, 1.0, 2.0, 0.6604046843152784, 6.9112, 6.9112, 95.55338769695034, 1100556.061526688, 1100556.061526688, 280853.8660270143]
[2019-03-23 20:57:10,950] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:57:10,951] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.0768535e-03 1.4819146e-12 8.4438109e-01 4.7137705e-10 1.5254208e-01], sampled 0.16490995126855412
[2019-03-23 20:57:12,713] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00076463], dtype=float32), 0.017654853]
[2019-03-23 20:57:12,715] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.0, 79.0, 1.0, 2.0, 0.2949764108094703, 0.0, 2.0, 0.0, 1.0, 2.0, 0.596069022624255, 6.9112, 6.9112, 77.32846344354104, 663819.4925777031, 663819.4925777031, 195041.2647636657]
[2019-03-23 20:57:12,716] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:57:12,718] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.08616415e-03 1.63999475e-17 9.98913765e-01 5.62780040e-15
 1.01137154e-07], sampled 0.20273628525998422
[2019-03-23 20:57:29,104] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00076463], dtype=float32), 0.017654853]
[2019-03-23 20:57:29,106] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [28.61644619333333, 42.71416215333333, 1.0, 2.0, 0.2353438830393033, 0.0, 2.0, 0.0, 1.0, 2.0, 0.470283155478234, 6.9112, 6.9112, 95.55338769695034, 535640.1879337279, 535640.1879337279, 175246.808700457]
[2019-03-23 20:57:29,107] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:57:29,109] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.0712830e-04 9.7072757e-19 9.9959284e-01 1.1715654e-16 2.2994893e-10], sampled 0.8383485080470232
[2019-03-23 20:57:35,269] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00076463], dtype=float32), 0.017654853]
[2019-03-23 20:57:35,269] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.6, 88.0, 1.0, 2.0, 0.2126233594850149, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4236006548934279, 6.9112, 6.9112, 95.55338769695034, 483210.7054860496, 483210.7054860496, 169939.4958037407]
[2019-03-23 20:57:35,270] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:57:35,273] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.2148106e-04 1.7552414e-17 9.9987853e-01 4.0570324e-16 3.5797334e-11], sampled 0.2164284065981853
[2019-03-23 20:58:16,725] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00076463], dtype=float32), 0.017654853]
[2019-03-23 20:58:16,726] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.316785755, 86.336354135, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3796280120823173, 6.911199999999999, 6.9112, 95.55338769695034, 434666.075370204, 434666.0753702043, 163667.4038690353]
[2019-03-23 20:58:16,727] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:58:16,730] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.3419888e-05 2.8494318e-16 9.9996662e-01 2.9546572e-15 1.2719809e-10], sampled 0.692151573528183
[2019-03-23 20:58:17,791] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00076463], dtype=float32), 0.017654853]
[2019-03-23 20:58:17,793] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.87805847333333, 99.08157127666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3920351501236204, 6.9112, 6.9112, 95.55338769695034, 448298.0170746, 448298.0170746, 165828.2021465581]
[2019-03-23 20:58:17,796] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:58:17,799] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.3782837e-05 1.7400404e-15 9.9997616e-01 7.1837381e-15 4.9463648e-11], sampled 0.9238667809458907
[2019-03-23 20:58:19,014] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00076463], dtype=float32), 0.017654853]
[2019-03-23 20:58:19,015] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.36666666666667, 57.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3957150616549038, 6.911199999999999, 6.9112, 77.328463443541, 451335.6102686804, 451335.6102686807, 162712.2160535029]
[2019-03-23 20:58:19,016] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:58:19,019] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.9018338e-05 1.6905036e-14 9.9997103e-01 5.9433815e-14 3.4365194e-10], sampled 0.13534371911381293
[2019-03-23 20:58:33,497] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00076463], dtype=float32), 0.017654853]
[2019-03-23 20:58:33,498] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.8, 68.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 297423.4878119642, 297423.4878119639, 124234.8911886325]
[2019-03-23 20:58:33,499] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:58:33,501] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.1925103e-05 9.4724489e-12 9.9998808e-01 8.0435181e-12 1.3770179e-09], sampled 0.6905401073933273
[2019-03-23 20:58:33,892] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00076463], dtype=float32), 0.017654853]
[2019-03-23 20:58:33,892] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.96666666666667, 60.0, 1.0, 2.0, 0.2356649276986263, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4522079507687555, 6.9112, 6.9112, 95.55338769695034, 522446.0924171197, 522446.0924171197, 166633.4591841825]
[2019-03-23 20:58:33,894] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:58:33,897] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.8402147e-04 6.4913468e-17 9.9981600e-01 1.8060045e-15 2.6583677e-10], sampled 0.6766514257692139
[2019-03-23 20:58:34,213] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3537.4274 2105911852.6505 85.0000
[2019-03-23 20:58:34,241] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2838.4850 2132514824.8165 353.0000
[2019-03-23 20:58:34,265] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3364.4620 2099578314.6606 122.0000
[2019-03-23 20:58:34,305] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3152.4180 2114006640.7787 170.0000
[2019-03-23 20:58:34,345] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3543.9014 2192880512.2861 89.0000
[2019-03-23 20:58:35,365] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 2475000, evaluation results [2475000.0, 3543.901375371467, 2192880512.2860518, 89.0, 3364.4620032751154, 2099578314.6606317, 122.0, 3537.4273783884814, 2105911852.6504705, 85.0, 2838.4849600508783, 2132514824.8165076, 353.0, 3152.4180226245853, 2114006640.778709, 170.0]
[2019-03-23 20:58:38,935] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.6858879e-05 3.2714851e-08 9.9989581e-01 2.7207157e-08 7.1158970e-06], sum to 1.0000
[2019-03-23 20:58:38,942] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8006
[2019-03-23 20:58:38,946] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.1, 54.0, 1.0, 2.0, 0.2100690995221481, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4191960161542492, 6.911199999999999, 6.9112, 77.32846344354104, 477831.1249717733, 477831.1249717736, 165220.9595765139], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5343000.0000, 
sim time next is 5343600.0000, 
raw observation next is [26.1, 54.00000000000001, 1.0, 2.0, 0.2120529853065844, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4231569529371591, 6.9112, 6.9112, 77.32846344354104, 482347.1044834981, 482347.1044834981, 165588.2316512693], 
processed observation next is [1.0, 0.8695652173913043, 0.8227272727272728, 0.54, 1.0, 1.0, 0.015066231633230481, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1759385041959416, 0.0, 0.0, 0.5084288129206541, 0.17864707573462893, 0.17864707573462893, 0.4038737357348032], 
reward next is 0.5961, 
noisyNet noise sample is [array([-2.1926062], dtype=float32), -1.3167309]. 
=============================================
[2019-03-23 20:58:42,191] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.2344902e-05 1.8559672e-10 9.9993801e-01 8.8529395e-10 2.9694120e-05], sum to 1.0000
[2019-03-23 20:58:42,202] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3396
[2019-03-23 20:58:42,209] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.2, 84.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 304511.8600008488, 304511.8600008491, 132581.0560012164], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6154200.0000, 
sim time next is 6154800.0000, 
raw observation next is [17.2, 84.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 304936.9441614789, 304936.9441614786, 132655.9140872905], 
processed observation next is [1.0, 0.21739130434782608, 0.41818181818181815, 0.84, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11293960894869588, 0.11293960894869579, 0.3235510099690012], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.7364295], dtype=float32), 1.5386097]. 
=============================================
[2019-03-23 20:58:49,705] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.0216578e-04 4.3775007e-13 9.9959785e-01 3.3997870e-12 2.4657366e-08], sum to 1.0000
[2019-03-23 20:58:49,710] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7924
[2019-03-23 20:58:49,719] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.5, 87.0, 1.0, 2.0, 0.205995359430281, 0.0, 2.0, 0.0, 1.0, 2.0, 0.409352896060693, 6.9112, 6.9112, 77.32846344354104, 467560.6498604667, 467560.6498604667, 163457.5300834427], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5536800.0000, 
sim time next is 5537400.0000, 
raw observation next is [20.5, 87.0, 1.0, 2.0, 0.3181150758873227, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6327163290966041, 6.911199999999999, 6.9112, 81.63991234897068, 722549.5976202184, 722549.5976202186, 190543.6275959137], 
processed observation next is [1.0, 0.08695652173913043, 0.5681818181818182, 0.87, 1.0, 1.0, 0.14764384485915333, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4753090415665774, -8.881784197001253e-17, 0.0, 0.5367762641868508, 0.2676109620815624, 0.2676109620815625, 0.46474055511198464], 
reward next is 0.5353, 
noisyNet noise sample is [array([0.01850388], dtype=float32), -1.3461176]. 
=============================================
[2019-03-23 20:58:55,138] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3725047e-06 1.8077037e-10 9.9999857e-01 9.4405863e-12 3.9424748e-09], sum to 1.0000
[2019-03-23 20:58:55,147] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5091
[2019-03-23 20:58:55,150] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.06666666666667, 97.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3622845752585802, 6.9112, 6.9112, 77.32846344354104, 416590.861662794, 416590.861662794, 155210.0570321369], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5636400.0000, 
sim time next is 5637000.0000, 
raw observation next is [17.88333333333333, 97.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3545669765901392, 6.911200000000001, 6.9112, 77.32846344354104, 408122.5503120237, 408122.5503120234, 153867.3564995293], 
processed observation next is [0.0, 0.21739130434782608, 0.44924242424242405, 0.97, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.07795282370019886, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15115650011556434, 0.15115650011556422, 0.3752862353647056], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6741822], dtype=float32), 1.5597767]. 
=============================================
[2019-03-23 20:58:55,176] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[-3.5191114]
 [-3.3234935]
 [-3.104399 ]
 [-2.9773796]
 [-2.9669304]], R is [[-3.64470553]
 [-3.60825849]
 [-3.57217598]
 [-3.5364542 ]
 [-3.50108981]].
[2019-03-23 20:58:58,687] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.9984166e-05 1.2198620e-08 9.9993885e-01 1.0068859e-08 1.2058986e-06], sum to 1.0000
[2019-03-23 20:58:58,696] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2059
[2019-03-23 20:58:58,702] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [8.8, 93.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 129693.8606671258, 129693.8606671256, 72277.73151695525], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5722200.0000, 
sim time next is 5722800.0000, 
raw observation next is [8.8, 94.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 128447.73756379, 128447.73756379, 72088.5260098949], 
processed observation next is [0.0, 0.21739130434782608, 0.0363636363636364, 0.9466666666666665, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.04757323613473704, 0.04757323613473704, 0.17582567319486558], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.25883344], dtype=float32), 0.015440464]. 
=============================================
[2019-03-23 20:59:08,469] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.5064461e-03 4.3172181e-06 9.5680207e-01 1.4848515e-05 4.0672280e-02], sum to 1.0000
[2019-03-23 20:59:08,476] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8520
[2019-03-23 20:59:08,481] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.1, 83.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 341354.3634783118, 341354.3634783118, 143774.4988865401], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5880000.0000, 
sim time next is 5880600.0000, 
raw observation next is [18.0, 82.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 335957.432911986, 335957.4329119863, 142607.4248748214], 
processed observation next is [1.0, 0.043478260869565216, 0.45454545454545453, 0.825, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12442867885629112, 0.12442867885629122, 0.34782298749956436], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5032279], dtype=float32), 1.7007095]. 
=============================================
[2019-03-23 20:59:10,375] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.3805446e-06 6.1555535e-12 1.0550605e-04 8.1647367e-10 9.9989212e-01], sum to 1.0000
[2019-03-23 20:59:10,386] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5297
[2019-03-23 20:59:10,390] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.43333333333334, 53.33333333333334, 1.0, 2.0, 0.209295702031877, 1.0, 2.0, 0.209295702031877, 1.0, 2.0, 0.4217142117815876, 6.911199999999999, 6.9112, 77.3421103, 716571.9126162694, 716571.9126162698, 225397.7034117146], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5919600.0000, 
sim time next is 5920200.0000, 
raw observation next is [26.35, 53.5, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.380124802589885, 6.911199999999999, 6.9112, 77.3421103, 646619.5879901138, 646619.587990114, 217410.8448068761], 
processed observation next is [1.0, 0.5217391304347826, 0.8340909090909091, 0.535, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.11446400369983575, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.23948873629263473, 0.2394887362926348, 0.5302703531875027], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.2841287], dtype=float32), 1.1834157]. 
=============================================
[2019-03-23 20:59:12,759] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.6907878e-04 6.9532252e-06 1.5799189e-01 3.2980010e-05 8.4129912e-01], sum to 1.0000
[2019-03-23 20:59:12,767] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2210
[2019-03-23 20:59:12,772] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.23333333333333, 71.33333333333334, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 403003.8204587239, 403003.8204587242, 176660.2850933736], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5962800.0000, 
sim time next is 5963400.0000, 
raw observation next is [21.05, 73.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 404382.1366075732, 404382.1366075735, 177037.3538490286], 
processed observation next is [1.0, 0.0, 0.5931818181818183, 0.73, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.1497711617065086, 0.1497711617065087, 0.43179842402202095], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7207096], dtype=float32), 1.6031296]. 
=============================================
[2019-03-23 20:59:16,525] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4519315e-04 1.6717860e-06 1.0013321e-02 1.4406563e-05 9.8982543e-01], sum to 1.0000
[2019-03-23 20:59:16,532] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7679
[2019-03-23 20:59:16,538] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.9, 54.66666666666667, 1.0, 2.0, 0.2902624629723092, 1.0, 2.0, 0.2902624629723092, 1.0, 2.0, 0.5845159665037986, 6.9112, 6.9112, 77.3421103, 993998.7669405305, 993998.7669405305, 248552.1726368122], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6795600.0000, 
sim time next is 6796200.0000, 
raw observation next is [26.0, 53.33333333333334, 1.0, 2.0, 0.3209176188087602, 1.0, 2.0, 0.3209176188087602, 1.0, 2.0, 0.6465226619168677, 6.911199999999999, 6.9112, 77.3421103, 1099135.803534991, 1099135.803534991, 259478.4340110549], 
processed observation next is [1.0, 0.6521739130434783, 0.8181818181818182, 0.5333333333333334, 1.0, 1.0, 0.15114702351095022, 1.0, 1.0, 0.15114702351095022, 1.0, 1.0, 0.4950323741669539, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4070873346425893, 0.4070873346425893, 0.6328742292952558], 
reward next is 0.3671, 
noisyNet noise sample is [array([-0.29445016], dtype=float32), -1.3203759]. 
=============================================
[2019-03-23 20:59:19,987] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.8162737e-03 2.9279630e-05 7.9948986e-01 1.5731592e-04 1.9550726e-01], sum to 1.0000
[2019-03-23 20:59:19,998] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2897
[2019-03-23 20:59:20,001] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.8, 57.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 310849.8109011759, 310849.8109011756, 130995.5474737169], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6118200.0000, 
sim time next is 6118800.0000, 
raw observation next is [20.53333333333333, 58.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 308832.9038913923, 308832.9038913926, 129827.4986817323], 
processed observation next is [1.0, 0.8260869565217391, 0.5696969696969696, 0.5833333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11438255699681196, 0.11438255699681206, 0.3166524358091031], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.15134767], dtype=float32), 0.15207498]. 
=============================================
[2019-03-23 20:59:22,415] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8717970e-03 1.6771712e-05 2.4340044e-01 4.5331541e-05 7.5466561e-01], sum to 1.0000
[2019-03-23 20:59:22,421] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6130
[2019-03-23 20:59:22,425] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [17.28333333333333, 83.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.99976149914694, 480724.0931766671, 480724.0931766674, 182348.7270736028], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6142200.0000, 
sim time next is 6142800.0000, 
raw observation next is [17.36666666666667, 82.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 390734.1027892129, 390734.1027892132, 169431.9140108188], 
processed observation next is [1.0, 0.08695652173913043, 0.42575757575757595, 0.82, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.14471633436637515, 0.14471633436637527, 0.4132485707580946], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1646904], dtype=float32), 1.5225843]. 
=============================================
[2019-03-23 20:59:23,644] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.3913174e-06 4.6123266e-10 5.9268036e-04 1.0944372e-07 9.9939883e-01], sum to 1.0000
[2019-03-23 20:59:23,650] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1538
[2019-03-23 20:59:23,657] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.0, 62.0, 1.0, 2.0, 0.2454978087556378, 1.0, 2.0, 0.2454978087556378, 1.0, 2.0, 0.4879252411721719, 6.9112, 6.9112, 77.3421103, 836217.4954223649, 836217.4954223649, 228156.4707717884], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6190200.0000, 
sim time next is 6190800.0000, 
raw observation next is [22.9, 62.66666666666667, 1.0, 2.0, 0.2640562318414882, 1.0, 2.0, 0.2640562318414882, 1.0, 2.0, 0.5250436254818471, 6.911199999999999, 6.9112, 77.3421103, 899705.2078964061, 899705.2078964064, 233484.7401585717], 
processed observation next is [1.0, 0.6521739130434783, 0.6772727272727272, 0.6266666666666667, 1.0, 1.0, 0.08007028980186022, 1.0, 1.0, 0.08007028980186022, 1.0, 1.0, 0.3214908935454959, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.333224151072743, 0.3332241510727431, 0.5694749759965163], 
reward next is 0.4305, 
noisyNet noise sample is [array([-0.4413645], dtype=float32), -0.22741865]. 
=============================================
[2019-03-23 20:59:24,256] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.29651084e-04 1.41369485e-08 9.86487329e-01 1.14849364e-07
 1.31828757e-02], sum to 1.0000
[2019-03-23 20:59:24,262] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3931
[2019-03-23 20:59:24,270] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.15, 62.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.332158823590211, 6.9112, 6.9112, 77.32846344354104, 383115.7638313965, 383115.7638313965, 150386.6355788636], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6201000.0000, 
sim time next is 6201600.0000, 
raw observation next is [21.96666666666667, 64.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.333992155773596, 6.911200000000001, 6.9112, 77.32846344354104, 385024.981814187, 385024.9818141867, 150801.9192093748], 
processed observation next is [1.0, 0.782608695652174, 0.6348484848484849, 0.6433333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.04856022253370856, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14260184511636556, 0.14260184511636545, 0.36780955904725565], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.10996742], dtype=float32), -1.3807148]. 
=============================================
[2019-03-23 20:59:24,694] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.9677687e-03 2.5448074e-07 3.7023526e-01 6.0937867e-07 6.2479609e-01], sum to 1.0000
[2019-03-23 20:59:24,696] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3663
[2019-03-23 20:59:24,706] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.51666666666667, 58.83333333333333, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 377775.8594955964, 377775.8594955967, 171186.9195212472], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6199800.0000, 
sim time next is 6200400.0000, 
raw observation next is [22.33333333333334, 60.66666666666667, 1.0, 2.0, 0.2, 0.0, 1.0, 0.0, 1.0, 2.0, 0.3307345036639385, 6.911199999999999, 6.9112, 77.32846344354104, 381434.1635997529, 381434.1635997532, 150255.5514680462], 
processed observation next is [1.0, 0.782608695652174, 0.6515151515151518, 0.6066666666666667, 1.0, 1.0, 0.0, 0.0, 0.5, -0.25, 1.0, 1.0, 0.04390643380562641, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14127191244435292, 0.14127191244435305, 0.3664769548001127], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7957239], dtype=float32), -0.12690748]. 
=============================================
[2019-03-23 20:59:25,509] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 20:59:25,510] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:59:25,513] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:59:25,514] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:59:25,515] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:59:25,517] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:59:25,517] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:59:25,520] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:59:25,520] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:59:25,521] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:59:25,521] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:59:25,553] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run101
[2019-03-23 20:59:25,554] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run101
[2019-03-23 20:59:25,577] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run101
[2019-03-23 20:59:25,632] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run101
[2019-03-23 20:59:25,659] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/42/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run101
[2019-03-23 20:59:58,670] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00066907], dtype=float32), 0.017518098]
[2019-03-23 20:59:58,671] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.07385572666666, 53.627935155, 1.0, 2.0, 0.2076433379871577, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4138365092431028, 6.9112, 6.9112, 95.55338769695034, 471978.6310638193, 471978.6310638193, 169113.9041472708]
[2019-03-23 20:59:58,672] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:59:58,675] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.9725222e-04 1.7782622e-14 9.9930227e-01 9.7586826e-13 5.1912031e-07], sampled 0.6730246250205419
[2019-03-23 20:59:59,089] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00066907], dtype=float32), 0.017518098]
[2019-03-23 20:59:59,089] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.6, 83.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3917216445342766, 6.9112, 6.9112, 95.55338769695034, 448439.0042818584, 448439.0042818584, 165359.5686376996]
[2019-03-23 20:59:59,090] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:59:59,094] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.5784220e-03 3.4271034e-15 9.9741626e-01 8.3366788e-13 5.3597787e-06], sampled 0.5145045655728746
[2019-03-23 21:00:34,355] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00066907], dtype=float32), 0.017518098]
[2019-03-23 21:00:34,357] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [28.91208905333333, 58.75172336166667, 1.0, 2.0, 0.6136675092816865, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 694429.0385786457, 694429.0385786453, 163890.0697131673]
[2019-03-23 21:00:34,358] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:00:34,361] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.1373907e-02 5.3312636e-12 6.7570198e-01 3.3417717e-09 2.9292417e-01], sampled 0.041864900748427525
[2019-03-23 21:00:39,392] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00066907], dtype=float32), 0.017518098]
[2019-03-23 21:00:39,394] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.5, 42.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3112160816374134, 6.9112, 6.9112, 77.32846344354104, 359812.1231146614, 359812.1231146614, 147098.064665408]
[2019-03-23 21:00:39,396] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:00:39,399] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.7177806e-04 4.2000747e-11 9.9971372e-01 3.4781167e-10 1.4523256e-05], sampled 0.6631146372980484
[2019-03-23 21:00:44,498] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00066907], dtype=float32), 0.017518098]
[2019-03-23 21:00:44,499] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.8, 93.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3666565798397475, 6.9112, 6.9112, 77.32846344354104, 421099.5364276621, 421099.5364276621, 156234.4365591859]
[2019-03-23 21:00:44,500] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:00:44,505] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.8351348e-04 7.4524788e-13 9.9908185e-01 3.6051689e-11 3.4665914e-05], sampled 0.20498093615837165
[2019-03-23 21:01:06,623] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00066907], dtype=float32), 0.017518098]
[2019-03-23 21:01:06,626] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.86666666666667, 86.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3019801546726687, 6.911200000000001, 6.9112, 95.55338769695034, 349829.3020777132, 349829.3020777129, 149850.8834099631]
[2019-03-23 21:01:06,627] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:01:06,630] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.0725999e-04 6.7055153e-11 9.9943846e-01 9.4648145e-10 2.5424646e-04], sampled 0.8748600681937946
[2019-03-23 21:01:07,133] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3292.2871 2108053795.2428 43.0000
[2019-03-23 21:01:07,340] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3106.4945 2124799428.3771 41.0000
[2019-03-23 21:01:07,420] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3450.6830 2111654087.8271 41.0000
[2019-03-23 21:01:07,447] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2854.8745 2149197540.8218 41.0000
[2019-03-23 21:01:07,513] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3440.7646 2210491913.9223 28.0000
[2019-03-23 21:01:08,533] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2500000, evaluation results [2500000.0, 3440.764640417405, 2210491913.9223204, 28.0, 3292.2870595137692, 2108053795.2428405, 43.0, 3450.6829931959214, 2111654087.8270738, 41.0, 2854.8744532485202, 2149197540.8217807, 41.0, 3106.494494313086, 2124799428.377103, 41.0]
