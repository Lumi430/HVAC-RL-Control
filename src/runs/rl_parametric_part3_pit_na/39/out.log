Using TensorFlow backend.
[2019-03-23 11:34:16,820] A3C_AGENT_MAIN INFO:Namespace(action_repeat_n=1, action_space='part3_v1', activation='relu', agent_num=5, check_args_only=False, clip_norm=5.0, debug_log_prob=0.0005, decay_steps=1000000, dropout_prob=0.0, end_e=0.0, env='Part3-NA-Pit-Train-v1', eval_act_func='part3_pit_det_v1', eval_env_res_max_keep=50, eval_epi_num=1, eval_freq=25000, forecast_dim=0, gamma=0.99, h_decay_bounds=[], h_regu_frac=[0.0], init_e=0.0, isNoisyNet=True, isNoisyNetEval_rmNoise=True, is_greedy_policy=False, is_learning_rate_decay_staircase=False, is_warm_start=False, job_mode='Train', learning_rate=0.0001, learning_rate_decay_rate=1.0, learning_rate_decay_steps=100000, max_interactions=2500000, metric_func='part3_v1', model_dir='None', model_param=[256, 8], model_type='nn', num_threads=16, output='./Part3-NA-Pit-Train-v1-res1', p_loss_frac=1.0, raw_state_prcs_func='cslDx_1', reward_func='part3_v3', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=1.0, rwd_p_para=1.0, save_freq=500000, save_max_to_keep=5, save_scope='all', sharedNet_type='Dense', state_dim=17, test_env=['Part3-NA-Pit-Test-v1', 'Part3-NA-Pit-Test-v2', 'Part3-NA-Pit-Test-v3', 'Part3-NA-Pit-Test-v4'], test_mode='Multiple', train_act_func='part3_pit_sto_v1', train_freq=5, v_loss_frac=0.5, violation_penalty_scl=50.0, weight_initer='glorot_uniform', window_len=21)
[2019-03-23 11:34:16,820] A3C_AGENT_MAIN INFO:Start compiling...
2019-03-23 11:34:16.901590: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[2019-03-23 11:34:45,918] A3C_AGENT_MAIN INFO:Start the learning...
[2019-03-23 11:34:45,918] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['Part3-NA-Pit-Train-v1', 'Part3-NA-Pit-Test-v1', 'Part3-NA-Pit-Test-v2', 'Part3-NA-Pit-Test-v3', 'Part3-NA-Pit-Test-v4'] ...
[2019-03-23 11:34:45,929] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation worker starts!
[2019-03-23 11:34:45,932] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation worker starts!
[2019-03-23 11:34:45,934] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation worker starts!
[2019-03-23 11:34:45,939] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation worker starts!
[2019-03-23 11:34:45,943] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation worker starts!
[2019-03-23 11:34:45,943] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 11:34:45,943] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2019-03-23 11:34:46,030] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:34:46,031] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run1
[2019-03-23 11:34:46,944] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 11:34:46,947] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2019-03-23 11:34:47,097] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:34:47,097] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run1
[2019-03-23 11:34:47,481] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 11:34:47,482] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:34:47,483] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:34:47,483] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:34:47,483] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:34:47,484] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:34:47,483] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:34:47,484] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:34:47,484] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:34:47,485] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:34:47,485] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:34:47,488] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run1
[2019-03-23 11:34:47,490] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run1
[2019-03-23 11:34:47,490] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run1
[2019-03-23 11:34:47,514] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run1
[2019-03-23 11:34:47,539] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run1
[2019-03-23 11:34:47,948] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 11:34:47,949] A3C_AGENT_WORKER-Thread-9 INFO:Local worker starts!
[2019-03-23 11:34:48,064] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:34:48,065] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run1
[2019-03-23 11:34:48,949] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 11:34:48,952] A3C_AGENT_WORKER-Thread-10 INFO:Local worker starts!
[2019-03-23 11:34:49,096] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:34:49,096] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run1
[2019-03-23 11:34:49,951] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 11:34:49,956] A3C_AGENT_WORKER-Thread-11 INFO:Local worker starts!
[2019-03-23 11:34:50,044] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:34:50,045] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run1
[2019-03-23 11:34:50,954] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 11:34:50,959] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2019-03-23 11:34:51,055] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:34:51,056] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run1
[2019-03-23 11:34:51,958] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 11:34:51,964] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2019-03-23 11:34:52,055] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:34:52,055] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run1
[2019-03-23 11:34:52,962] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 11:34:52,966] A3C_AGENT_WORKER-Thread-14 INFO:Local worker starts!
[2019-03-23 11:34:53,056] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:34:53,057] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run1
[2019-03-23 11:34:53,966] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 11:34:53,969] A3C_AGENT_WORKER-Thread-15 INFO:Local worker starts!
[2019-03-23 11:34:54,065] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:34:54,066] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run1
[2019-03-23 11:34:54,970] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 11:34:54,974] A3C_AGENT_WORKER-Thread-16 INFO:Local worker starts!
[2019-03-23 11:34:55,067] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:34:55,068] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run1
[2019-03-23 11:34:55,974] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 11:34:55,978] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2019-03-23 11:34:56,070] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:34:56,071] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run1
[2019-03-23 11:34:56,979] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 11:34:56,981] A3C_AGENT_WORKER-Thread-18 INFO:Local worker starts!
[2019-03-23 11:34:57,072] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:34:57,073] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run1
[2019-03-23 11:34:57,982] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 11:34:57,986] A3C_AGENT_WORKER-Thread-19 INFO:Local worker starts!
[2019-03-23 11:34:58,077] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:34:58,078] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run1
[2019-03-23 11:34:58,987] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 11:34:58,992] A3C_AGENT_WORKER-Thread-20 INFO:Local worker starts!
[2019-03-23 11:34:59,084] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:34:59,085] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run1
[2019-03-23 11:34:59,992] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 11:34:59,995] A3C_AGENT_WORKER-Thread-21 INFO:Local worker starts!
[2019-03-23 11:35:00,090] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:35:00,091] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run1
[2019-03-23 11:35:00,996] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 11:35:01,000] A3C_AGENT_WORKER-Thread-22 INFO:Local worker starts!
[2019-03-23 11:35:01,096] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:35:01,097] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run1
[2019-03-23 11:35:11,918] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 11:35:11,920] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.7, 62.0, 1.0, 2.0, 0.8210634041687647, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 935863.462129791, 935863.4621297907, 192550.8062177256]
[2019-03-23 11:35:11,921] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:35:11,923] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.22321308 0.19304885 0.19537301 0.19955628 0.18880887], sampled 0.7191514963285546
[2019-03-23 11:35:42,481] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 11:35:42,485] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.16666666666666, 70.0, 1.0, 2.0, 0.7777879758042269, 1.0, 2.0, 0.7777879758042269, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1749788.427657088, 1749788.427657088, 317295.9643774289]
[2019-03-23 11:35:42,488] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:35:42,492] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.22200276 0.19194706 0.1965503  0.20277768 0.18672222], sampled 0.06524314688409105
[2019-03-23 11:35:42,494] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 1749788.427657088 W.
[2019-03-23 11:35:51,562] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 11:35:51,564] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.26666666666667, 65.66666666666667, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3440226337698162, 6.9112, 6.9112, 95.55338769695034, 579619.8688991305, 579619.8688991305, 219091.5714824873]
[2019-03-23 11:35:51,565] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:35:51,568] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.22107866 0.19272007 0.19419812 0.2023454  0.1896578 ], sampled 0.6007404816332681
[2019-03-23 11:36:02,122] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 11:36:02,122] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.83333333333334, 66.66666666666666, 1.0, 2.0, 0.2846263726538147, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5757518850569685, 6.9112, 6.9112, 77.32846344354104, 642269.2685259467, 642269.2685259467, 191589.0349097613]
[2019-03-23 11:36:02,123] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:36:02,128] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.22488678 0.19061065 0.1926803  0.20109451 0.19072773], sampled 0.535138021119732
[2019-03-23 11:36:32,452] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 2622.6987 2073617126.3605 779.0000
[2019-03-23 11:36:32,929] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 2495.6373 1992140060.6405 984.0000
[2019-03-23 11:36:32,970] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2281.0299 2019963942.2479 1266.0000
[2019-03-23 11:36:33,111] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 2349.9035 2005693073.3837 944.0000
[2019-03-23 11:36:33,248] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 2525.4001 1987554877.8003 985.0000
[2019-03-23 11:36:34,262] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 0, evaluation results [0.0, 2622.6987417619684, 2073617126.360488, 779.0, 2525.4000538833993, 1987554877.800294, 985.0, 2495.6372764058337, 1992140060.6405272, 984.0, 2281.0298874449527, 2019963942.247897, 1266.0, 2349.903538992018, 2005693073.383719, 944.0]
[2019-03-23 11:36:39,521] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.22286108 0.19934644 0.19778092 0.1988514  0.18116014], sum to 1.0000
[2019-03-23 11:36:39,531] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4226
[2019-03-23 11:36:39,702] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.83333333333334, 90.5, 1.0, 2.0, 0.3653010049478176, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7256566193961581, 6.911199999999999, 6.9112, 77.32846344354104, 829288.5967406679, 829288.5967406682, 202056.4201422655], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 33000.0000, 
sim time next is 33600.0000, 
raw observation next is [20.06666666666667, 89.0, 1.0, 2.0, 0.3918939628307851, 0.0, 2.0, 0.0, 1.0, 2.0, 0.779254335852197, 6.911200000000001, 6.9112, 77.32846344354104, 890190.975992793, 890190.9759927926, 210989.1292218782], 
processed observation next is [1.0, 0.391304347826087, 0.5484848484848487, 0.89, 1.0, 1.0, 0.23986745353848135, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6846490512174245, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3297003614788122, 0.3297003614788121, 0.5146076322484834], 
reward next is 0.4854, 
noisyNet noise sample is [array([-1.2299008], dtype=float32), 0.27396753]. 
=============================================
[2019-03-23 11:36:40,991] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.20697306 0.20675792 0.20169221 0.20037268 0.18420418], sum to 1.0000
[2019-03-23 11:36:41,000] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2623
[2019-03-23 11:36:41,006] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1083566.070150525 W.
[2019-03-23 11:36:41,177] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.3165477135370432, 1.0, 1.0, 0.3165477135370432, 1.0, 2.0, 0.6359659605186379, 6.9112, 6.9112, 77.3421103, 1083566.070150525, 1083566.070150525, 255844.0264883002], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 59400.0000, 
sim time next is 60000.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.3088490233845348, 1.0, 2.0, 0.3088490233845348, 1.0, 2.0, 0.6212600004741031, 6.911199999999999, 6.9112, 77.3421103, 1057505.135546578, 1057505.135546578, 254025.8490806301], 
processed observation next is [1.0, 0.6956521739130435, 0.5909090909090909, 0.83, 1.0, 1.0, 0.13606127923066846, 1.0, 1.0, 0.13606127923066846, 1.0, 1.0, 0.4589428578201474, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.39166856872095485, 0.39166856872095485, 0.6195752416600735], 
reward next is 0.3804, 
noisyNet noise sample is [array([-0.0825354], dtype=float32), -0.7429786]. 
=============================================
[2019-03-23 11:36:41,200] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[0.2492017 ]
 [0.2653811 ]
 [0.26392907]
 [0.24670137]
 [0.25380933]], R is [[0.63461298]
 [1.00425708]
 [1.16347933]
 [1.1518445 ]
 [1.14032602]].
[2019-03-23 11:36:49,102] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9999177e-01 8.2604729e-06 6.8457362e-10 2.1873776e-10 3.7808031e-11], sum to 1.0000
[2019-03-23 11:36:49,109] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9365
[2019-03-23 11:36:49,258] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.25, 76.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4647551044508767, 6.9112, 6.9112, 77.32846344354104, 270319.1539068859, 270319.1539068859, 87812.47586975555], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 226200.0000, 
sim time next is 226800.0000, 
raw observation next is [17.5, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4722664693592973, 6.911199999999999, 6.9112, 77.32846344354104, 274689.2817076963, 274689.2817076966, 89267.05434918126], 
processed observation next is [0.0, 0.6521739130434783, 0.4318181818181818, 0.75, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.24609495622756758, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10173677100285049, 0.1017367710028506, 0.21772452280288113], 
reward next is 0.7823, 
noisyNet noise sample is [array([1.0928941], dtype=float32), 0.026032805]. 
=============================================
[2019-03-23 11:36:49,406] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9998999e-01 1.0062074e-05 9.2037616e-10 5.3291850e-11 3.1206107e-11], sum to 1.0000
[2019-03-23 11:36:49,414] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3817
[2019-03-23 11:36:49,559] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.73333333333333, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4771517038694991, 6.9112, 6.9112, 77.32846344354104, 277531.5424294111, 277531.5424294111, 90591.59158536514], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 227400.0000, 
sim time next is 228000.0000, 
raw observation next is [17.96666666666667, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.480100759549238, 6.911199999999998, 6.9112, 77.32846344354104, 279247.3299489315, 279247.3299489321, 91765.23515644681], 
processed observation next is [0.0, 0.6521739130434783, 0.4530303030303031, 0.73, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2572867993560543, -1.7763568394002506e-16, 0.0, 0.5084288129206541, 0.10342493701812279, 0.103424937018123, 0.223817646723041], 
reward next is 0.7762, 
noisyNet noise sample is [array([0.92473704], dtype=float32), -0.09598398]. 
=============================================
[2019-03-23 11:36:49,578] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[55.428276]
 [55.36218 ]
 [55.25016 ]
 [55.24444 ]
 [55.21323 ]], R is [[55.68091583]
 [55.90315247]
 [56.12639618]
 [56.35095596]
 [56.57661057]].
[2019-03-23 11:36:53,080] A3C_AGENT_WORKER-Thread-21 INFO:Local step 500, global step 7910: loss 1.2260
[2019-03-23 11:36:53,162] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 500, global step 7910: learning rate 0.0001
[2019-03-23 11:36:53,174] A3C_AGENT_WORKER-Thread-12 INFO:Local step 500, global step 7922: loss 1.1696
[2019-03-23 11:36:53,175] A3C_AGENT_WORKER-Thread-11 INFO:Local step 500, global step 7922: loss 0.9484
[2019-03-23 11:36:53,178] A3C_AGENT_WORKER-Thread-16 INFO:Local step 500, global step 7922: loss 0.4638
[2019-03-23 11:36:53,179] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 500, global step 7922: learning rate 0.0001
[2019-03-23 11:36:53,179] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 500, global step 7922: learning rate 0.0001
[2019-03-23 11:36:53,182] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 500, global step 7923: learning rate 0.0001
[2019-03-23 11:36:53,221] A3C_AGENT_WORKER-Thread-17 INFO:Local step 500, global step 7943: loss 0.2269
[2019-03-23 11:36:53,226] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 500, global step 7943: learning rate 0.0001
[2019-03-23 11:36:53,226] A3C_AGENT_WORKER-Thread-19 INFO:Local step 500, global step 7944: loss 0.0111
[2019-03-23 11:36:53,230] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 500, global step 7944: learning rate 0.0001
[2019-03-23 11:36:53,252] A3C_AGENT_WORKER-Thread-2 INFO:Local step 500, global step 7959: loss 0.0055
[2019-03-23 11:36:53,255] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 500, global step 7959: learning rate 0.0001
[2019-03-23 11:36:53,259] A3C_AGENT_WORKER-Thread-10 INFO:Local step 500, global step 7962: loss 0.0238
[2019-03-23 11:36:53,262] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 500, global step 7963: learning rate 0.0001
[2019-03-23 11:36:53,297] A3C_AGENT_WORKER-Thread-3 INFO:Local step 500, global step 7982: loss 0.2444
[2019-03-23 11:36:53,299] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 500, global step 7983: learning rate 0.0001
[2019-03-23 11:36:53,332] A3C_AGENT_WORKER-Thread-15 INFO:Local step 500, global step 8001: loss 0.8491
[2019-03-23 11:36:53,335] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 500, global step 8001: learning rate 0.0001
[2019-03-23 11:36:53,354] A3C_AGENT_WORKER-Thread-14 INFO:Local step 500, global step 8010: loss 2.4700
[2019-03-23 11:36:53,355] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 500, global step 8010: learning rate 0.0001
[2019-03-23 11:36:53,400] A3C_AGENT_WORKER-Thread-9 INFO:Local step 500, global step 8028: loss 5.2558
[2019-03-23 11:36:53,401] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 500, global step 8028: learning rate 0.0001
[2019-03-23 11:36:53,453] A3C_AGENT_WORKER-Thread-20 INFO:Local step 500, global step 8056: loss 6.2250
[2019-03-23 11:36:53,454] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 500, global step 8056: learning rate 0.0001
[2019-03-23 11:36:53,475] A3C_AGENT_WORKER-Thread-18 INFO:Local step 500, global step 8065: loss 4.2055
[2019-03-23 11:36:53,478] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 500, global step 8067: learning rate 0.0001
[2019-03-23 11:36:53,500] A3C_AGENT_WORKER-Thread-22 INFO:Local step 500, global step 8078: loss 1.6893
[2019-03-23 11:36:53,502] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 500, global step 8079: learning rate 0.0001
[2019-03-23 11:36:53,539] A3C_AGENT_WORKER-Thread-13 INFO:Local step 500, global step 8098: loss 0.4730
[2019-03-23 11:36:53,541] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 500, global step 8098: learning rate 0.0001
[2019-03-23 11:36:56,230] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.8956827e-09 2.5073996e-16 1.2328806e-17 2.1092776e-15], sum to 1.0000
[2019-03-23 11:36:56,239] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8405
[2019-03-23 11:36:56,399] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [12.5, 71.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7337956210176505, 7.151000520316103, 6.9112, 77.32776079319395, 505295.2582628144, 427413.6617158488, 91329.8103765077], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 354600.0000, 
sim time next is 355200.0000, 
raw observation next is [12.33333333333333, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7411087604565672, 7.207547222614398, 6.9112, 77.32754788651843, 527589.5451349206, 431343.1681343639, 93834.6537694147], 
processed observation next is [1.0, 0.08695652173913043, 0.19696969696969682, 0.73, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6301553720808103, 0.029634722261439796, 0.0, 0.5084227932023068, 0.1954035352351558, 0.15975672893865328, 0.22886500919369437], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5650755], dtype=float32), -0.21888839]. 
=============================================
[2019-03-23 11:36:58,370] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 5.2203879e-13 2.6761870e-17 1.5719299e-24 6.7588553e-24], sum to 1.0000
[2019-03-23 11:36:58,380] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1734
[2019-03-23 11:36:58,536] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.0, 51.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6378062775417921, 6.9112, 6.9112, 77.32846344354104, 371010.6589083572, 371010.6589083572, 97583.03129794775], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 394200.0000, 
sim time next is 394800.0000, 
raw observation next is [20.0, 51.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6892516586428096, 6.9112, 6.9112, 77.32846344354104, 400948.6742319452, 400948.6742319452, 103872.26639167], 
processed observation next is [1.0, 0.5652173913043478, 0.5454545454545454, 0.5166666666666666, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5560737980611565, 0.0, 0.0, 0.5084288129206541, 0.14849950897479453, 0.14849950897479453, 0.2533469911991951], 
reward next is 0.7467, 
noisyNet noise sample is [array([-1.9204997], dtype=float32), 3.478698]. 
=============================================
[2019-03-23 11:36:59,345] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9993861e-01 5.4787404e-05 6.5119912e-06 7.1968205e-09 2.2687348e-09], sum to 1.0000
[2019-03-23 11:36:59,351] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6345
[2019-03-23 11:36:59,514] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.33333333333333, 66.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.450611559333565, 6.911200000000001, 6.9112, 77.32846344352846, 262090.5163802867, 262090.5163802864, 79569.57106195283], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 409200.0000, 
sim time next is 409800.0000, 
raw observation next is [17.16666666666667, 67.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4460763320773166, 6.9112, 6.9112, 77.32846344354097, 259451.9753380285, 259451.9753380285, 78461.35268445472], 
processed observation next is [1.0, 0.7391304347826086, 0.4166666666666669, 0.6733333333333335, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.20868047439616663, 0.0, 0.0, 0.5084288129206537, 0.09609332419926982, 0.09609332419926982, 0.19136915288891393], 
reward next is 0.8086, 
noisyNet noise sample is [array([-0.8423584], dtype=float32), 0.5720216]. 
=============================================
[2019-03-23 11:37:01,050] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 9.8437791e-09 1.9292326e-10 1.0566901e-15 6.2859077e-15], sum to 1.0000
[2019-03-23 11:37:01,061] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2735
[2019-03-23 11:37:01,217] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [13.0, 99.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3543806145220113, 6.9112, 6.9112, 77.32846344354104, 206107.5723036366, 206107.5723036366, 67204.3105278244], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 437400.0000, 
sim time next is 438000.0000, 
raw observation next is [13.0, 99.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3541382846242345, 6.911199999999999, 6.9112, 77.32846344354104, 205966.6035280477, 205966.603528048, 67265.02599033627], 
processed observation next is [1.0, 0.043478260869565216, 0.22727272727272727, 0.9966666666666666, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.07734040660604934, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07628392723261027, 0.07628392723261038, 0.16406103900082017], 
reward next is 0.8359, 
noisyNet noise sample is [array([0.11578661], dtype=float32), -0.39191976]. 
=============================================
[2019-03-23 11:37:01,238] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[56.706097]
 [56.76038 ]
 [57.19306 ]
 [57.4152  ]
 [57.571926]], R is [[57.04020691]
 [57.30589294]
 [57.56907272]
 [57.82967758]
 [58.08746338]].
[2019-03-23 11:37:06,458] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 5.5546093e-19 2.5839228e-18 1.1433226e-21 9.5025064e-24], sum to 1.0000
[2019-03-23 11:37:06,466] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3607
[2019-03-23 11:37:06,629] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.66666666666667, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4378460491793433, 6.911199999999999, 6.9112, 77.32846344354104, 254663.7316207033, 254663.7316207036, 79577.64161468118], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 544800.0000, 
sim time next is 545400.0000, 
raw observation next is [15.0, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4460007097199774, 6.9112, 6.9112, 77.32846344354104, 259407.9792752028, 259407.9792752028, 81875.22795175923], 
processed observation next is [1.0, 0.30434782608695654, 0.3181818181818182, 0.91, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2085724424571106, 0.0, 0.0, 0.5084288129206541, 0.09607702936118621, 0.09607702936118621, 0.19969567793112006], 
reward next is 0.8003, 
noisyNet noise sample is [array([-0.35184196], dtype=float32), 0.8948019]. 
=============================================
[2019-03-23 11:37:09,444] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1000, global step 15866: loss 0.3214
[2019-03-23 11:37:09,450] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1000, global step 15866: learning rate 0.0001
[2019-03-23 11:37:09,450] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1000, global step 15866: loss 0.3673
[2019-03-23 11:37:09,453] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1000, global step 15867: learning rate 0.0001
[2019-03-23 11:37:09,501] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1000, global step 15887: loss 0.1379
[2019-03-23 11:37:09,503] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1000, global step 15887: learning rate 0.0001
[2019-03-23 11:37:09,556] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1000, global step 15915: loss 0.0262
[2019-03-23 11:37:09,557] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1000, global step 15915: learning rate 0.0001
[2019-03-23 11:37:09,654] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1000, global step 15968: loss 1.6239
[2019-03-23 11:37:09,655] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1000, global step 15969: learning rate 0.0001
[2019-03-23 11:37:09,658] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1000, global step 15969: loss 2.2665
[2019-03-23 11:37:09,660] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1000, global step 15969: learning rate 0.0001
[2019-03-23 11:37:09,672] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1000, global step 15973: loss 3.5306
[2019-03-23 11:37:09,674] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1000, global step 15973: learning rate 0.0001
[2019-03-23 11:37:09,687] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1000, global step 15980: loss 3.8127
[2019-03-23 11:37:09,688] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1000, global step 15980: learning rate 0.0001
[2019-03-23 11:37:09,695] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1000, global step 15982: loss 6.4741
[2019-03-23 11:37:09,696] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1000, global step 15982: learning rate 0.0001
[2019-03-23 11:37:09,757] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1000, global step 16021: loss 4.9382
[2019-03-23 11:37:09,758] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1000, global step 16022: learning rate 0.0001
[2019-03-23 11:37:09,774] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1000, global step 16029: loss 3.0372
[2019-03-23 11:37:09,779] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1000, global step 16029: loss 3.2714
[2019-03-23 11:37:09,779] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1000, global step 16029: learning rate 0.0001
[2019-03-23 11:37:09,780] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1000, global step 16031: learning rate 0.0001
[2019-03-23 11:37:09,805] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1000, global step 16044: loss 2.6930
[2019-03-23 11:37:09,809] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1000, global step 16044: learning rate 0.0001
[2019-03-23 11:37:09,832] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1000, global step 16052: loss 0.3107
[2019-03-23 11:37:09,832] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1000, global step 16052: learning rate 0.0001
[2019-03-23 11:37:09,965] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1000, global step 16127: loss 0.2812
[2019-03-23 11:37:09,969] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1000, global step 16127: learning rate 0.0001
[2019-03-23 11:37:09,975] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1000, global step 16129: loss 0.6227
[2019-03-23 11:37:09,979] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1000, global step 16130: learning rate 0.0001
[2019-03-23 11:37:16,465] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9999988e-01 7.0597328e-10 1.5675720e-07 8.6564410e-12 3.4946164e-09], sum to 1.0000
[2019-03-23 11:37:16,473] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0074
[2019-03-23 11:37:16,479] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1216867.463545367 W.
[2019-03-23 11:37:16,483] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.5, 59.5, 1.0, 2.0, 0.5343509442525339, 1.0, 2.0, 0.5343509442525339, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354019, 1216867.463545367, 1216867.463545367, 238875.9762789654], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 732600.0000, 
sim time next is 733200.0000, 
raw observation next is [26.66666666666667, 59.0, 1.0, 2.0, 0.3742792313956391, 1.0, 2.0, 0.3742792313956391, 1.0, 1.0, 0.7581576240342788, 6.911199999999999, 6.9112, 77.3421103, 1277086.776083135, 1277086.776083136, 288904.1128682811], 
processed observation next is [1.0, 0.4782608695652174, 0.8484848484848487, 0.59, 1.0, 1.0, 0.21784903924454888, 1.0, 1.0, 0.21784903924454888, 1.0, 0.5, 0.6545108914775412, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.472995102253013, 0.47299510225301333, 0.7046441777275149], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.6719775], dtype=float32), -0.24399014]. 
=============================================
[2019-03-23 11:37:18,620] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.7477626  0.05288645 0.08585002 0.04514478 0.06835625], sum to 1.0000
[2019-03-23 11:37:18,622] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5273
[2019-03-23 11:37:18,629] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.66666666666666, 70.33333333333334, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 504943.8274972289, 504943.8274972292, 199409.4727726026], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 775200.0000, 
sim time next is 775800.0000, 
raw observation next is [23.5, 71.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7771954779796392, 7.355789011174599, 6.9112, 77.3273943615783, 586035.6381428513, 441644.2169999775, 138211.0521328903], 
processed observation next is [1.0, 1.0, 0.7045454545454546, 0.71, 0.0, 0.5, -0.25, 0.0, 0.5, -0.25, 1.0, 1.0, 0.6817078256851988, 0.04445890111745987, 0.0, 0.5084217837874084, 0.21705023634920417, 0.1635719322222139, 0.337100127153391], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4916533], dtype=float32), 1.3021096]. 
=============================================
[2019-03-23 11:37:24,493] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.13887155 0.21351115 0.52010983 0.02610396 0.10140347], sum to 1.0000
[2019-03-23 11:37:24,500] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6296
[2019-03-23 11:37:24,507] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 1.0, 0.39010544549941, 6.9112, 6.9112, 77.32846343899831, 447299.0468496719, 447299.0468496719, 159919.7748843646], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 879600.0000, 
sim time next is 880200.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3890235676799043, 6.9112, 6.9112, 77.32846344351292, 445996.8896804263, 445996.8896804263, 159830.0501782795], 
processed observation next is [0.0, 0.17391304347826086, 0.5, 0.94, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.12717652525700618, 0.0, 0.0, 0.5084288129204692, 0.1651840332149727, 0.1651840332149727, 0.38982939067873046], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.49073088], dtype=float32), 0.23915473]. 
=============================================
[2019-03-23 11:37:25,123] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1500, global step 23836: loss 3.5997
[2019-03-23 11:37:25,126] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1500, global step 23836: learning rate 0.0001
[2019-03-23 11:37:25,210] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1500, global step 23885: loss 2.9564
[2019-03-23 11:37:25,214] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1500, global step 23886: learning rate 0.0001
[2019-03-23 11:37:25,231] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1500, global step 23893: loss 3.8689
[2019-03-23 11:37:25,236] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1500, global step 23893: learning rate 0.0001
[2019-03-23 11:37:25,267] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1500, global step 23908: loss 0.4590
[2019-03-23 11:37:25,270] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1500, global step 23910: learning rate 0.0001
[2019-03-23 11:37:25,354] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1500, global step 23955: loss 1.5982
[2019-03-23 11:37:25,361] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1500, global step 23955: learning rate 0.0001
[2019-03-23 11:37:25,383] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1500, global step 23966: loss 0.0244
[2019-03-23 11:37:25,389] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1500, global step 23966: learning rate 0.0001
[2019-03-23 11:37:25,425] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1500, global step 23984: loss 0.0763
[2019-03-23 11:37:25,428] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1500, global step 23985: learning rate 0.0001
[2019-03-23 11:37:25,432] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1500, global step 23987: loss 2.0577
[2019-03-23 11:37:25,435] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1500, global step 23988: learning rate 0.0001
[2019-03-23 11:37:25,436] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1500, global step 23990: loss -4.1843
[2019-03-23 11:37:25,439] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1500, global step 23990: learning rate 0.0001
[2019-03-23 11:37:25,488] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1500, global step 24014: loss 0.3657
[2019-03-23 11:37:25,490] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1500, global step 24016: learning rate 0.0001
[2019-03-23 11:37:25,500] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1500, global step 24023: loss 0.5783
[2019-03-23 11:37:25,504] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1500, global step 24023: learning rate 0.0001
[2019-03-23 11:37:25,519] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1500, global step 24030: loss 0.4020
[2019-03-23 11:37:25,523] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1500, global step 24031: learning rate 0.0001
[2019-03-23 11:37:25,531] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1500, global step 24031: loss 0.0685
[2019-03-23 11:37:25,533] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1500, global step 24032: learning rate 0.0001
[2019-03-23 11:37:25,590] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1500, global step 24068: loss 0.1116
[2019-03-23 11:37:25,594] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1500, global step 24069: learning rate 0.0001
[2019-03-23 11:37:25,656] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1500, global step 24099: loss 0.3162
[2019-03-23 11:37:25,659] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1500, global step 24099: learning rate 0.0001
[2019-03-23 11:37:25,807] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1500, global step 24173: loss 0.5043
[2019-03-23 11:37:25,807] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1500, global step 24173: learning rate 0.0001
[2019-03-23 11:37:27,441] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 11:37:27,442] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:37:27,443] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:37:27,443] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:37:27,444] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:37:27,444] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:37:27,445] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:37:27,446] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:37:27,446] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:37:27,446] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:37:27,447] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:37:27,459] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run2
[2019-03-23 11:37:27,490] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run2
[2019-03-23 11:37:27,512] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run2
[2019-03-23 11:37:27,513] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run2
[2019-03-23 11:37:27,513] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run2
[2019-03-23 11:38:31,127] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00687034], dtype=float32), 0.04375527]
[2019-03-23 11:38:31,130] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.60779795, 62.69046557333333, 1.0, 2.0, 0.5969897056866671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 678976.5237640318, 678976.5237640314, 153424.3932583572]
[2019-03-23 11:38:31,130] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:38:31,134] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.2008450e-10 9.9998093e-01 1.9066576e-05 6.4083670e-16 2.0896444e-11], sampled 0.6253047575333012
[2019-03-23 11:38:35,491] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00687034], dtype=float32), 0.04375527]
[2019-03-23 11:38:35,493] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.2, 52.0, 1.0, 2.0, 0.3695388693581049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 416173.7180069215, 416173.7180069212, 126355.5567283965]
[2019-03-23 11:38:35,494] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:38:35,496] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.9284370e-10 9.9997890e-01 2.1045662e-05 8.8040027e-16 2.6122670e-11], sampled 0.5996550297069049
[2019-03-23 11:38:40,639] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00687034], dtype=float32), 0.04375527]
[2019-03-23 11:38:40,642] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.38614752833333, 71.49437540833333, 1.0, 2.0, 0.7694175805698259, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769693884, 873037.3558614793, 873037.3558614796, 186647.7879438529]
[2019-03-23 11:38:40,643] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:38:40,647] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.2591193e-10 9.9999273e-01 7.2607013e-06 2.8620545e-17 2.3659674e-12], sampled 0.6794046648763551
[2019-03-23 11:39:05,722] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:39:05,744] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8853.5131 1663852527.9379 105.0000
[2019-03-23 11:39:05,868] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8510.6796 1773282006.9086 173.0000
[2019-03-23 11:39:06,004] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.2975 1656204760.6478 80.0000
[2019-03-23 11:39:06,033] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:39:07,046] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 25000, evaluation results [25000.0, 8510.679577500932, 1773282006.9086075, 173.0, 9060.297531699427, 1656204760.6478498, 80.0, 8853.513140842784, 1663852527.9379442, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:39:07,753] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.5306102e-09 9.9998355e-01 1.6496935e-05 2.1937603e-14 3.3012350e-11], sum to 1.0000
[2019-03-23 11:39:07,761] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8448
[2019-03-23 11:39:07,766] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4071803691327499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 461576.0187912537, 461576.0187912534, 127129.2421964145], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 950400.0000, 
sim time next is 951000.0000, 
raw observation next is [19.0, 99.00000000000001, 1.0, 2.0, 0.4056689998008565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 459576.9255194446, 459576.9255194446, 126794.1254401531], 
processed observation next is [1.0, 0.0, 0.5, 0.9900000000000001, 1.0, 1.0, 0.25708624975107064, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1702136761183128, 0.1702136761183128, 0.3092539644881783], 
reward next is 0.6907, 
noisyNet noise sample is [array([-1.5699447], dtype=float32), -0.96202487]. 
=============================================
[2019-03-23 11:39:07,788] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[53.58771 ]
 [53.933765]
 [53.919464]
 [53.903336]
 [53.878933]], R is [[53.62086105]
 [53.77458191]
 [53.92662811]
 [54.07691193]
 [54.22541809]].
[2019-03-23 11:39:08,775] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.9973816e-10 9.9998200e-01 1.8043180e-05 6.4861089e-18 1.4118006e-13], sum to 1.0000
[2019-03-23 11:39:08,782] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9589
[2019-03-23 11:39:08,789] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.3768881323050115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 424661.2762237174, 424661.2762237177, 122778.2135130817], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 970800.0000, 
sim time next is 971400.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.3810076056144583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 429312.0051400454, 429312.0051400451, 123142.5418028495], 
processed observation next is [1.0, 0.21739130434782608, 0.5, 0.94, 1.0, 1.0, 0.22625950701807285, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15900444634816496, 0.15900444634816485, 0.3003476629337793], 
reward next is 0.6997, 
noisyNet noise sample is [array([-0.8609066], dtype=float32), -0.8268231]. 
=============================================
[2019-03-23 11:39:12,035] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.0888367e-04 9.9744874e-01 2.2285038e-03 9.1774012e-07 1.2866667e-05], sum to 1.0000
[2019-03-23 11:39:12,041] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6293
[2019-03-23 11:39:12,046] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 96.0, 1.0, 2.0, 0.2331403962920159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 253137.1385556061, 253137.1385556058, 76114.36011376113], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1045200.0000, 
sim time next is 1045800.0000, 
raw observation next is [13.0, 97.0, 1.0, 2.0, 0.2012026232631298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 218452.2356983842, 218452.2356983845, 73232.14949444661], 
processed observation next is [1.0, 0.08695652173913043, 0.22727272727272727, 0.97, 1.0, 1.0, 0.0015032790789122272, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.080908235443846, 0.08090823544384611, 0.17861499876694295], 
reward next is 0.8214, 
noisyNet noise sample is [array([2.3206918], dtype=float32), 0.5749691]. 
=============================================
[2019-03-23 11:39:13,338] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.5300629e-05 9.9996471e-01 2.2713410e-08 2.4700551e-19 1.3086105e-11], sum to 1.0000
[2019-03-23 11:39:13,345] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9522
[2019-03-23 11:39:13,540] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.5, 77.0, 1.0, 2.0, 0.3534146249946202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 383778.9665277968, 383778.9665277968, 94094.37026729199], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1067400.0000, 
sim time next is 1068000.0000, 
raw observation next is [16.66666666666666, 77.0, 1.0, 2.0, 0.3526856106255759, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 382987.0056267598, 382987.0056267595, 95616.84493501695], 
processed observation next is [1.0, 0.34782608695652173, 0.39393939393939365, 0.77, 1.0, 1.0, 0.19085701328196986, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14184703912102214, 0.14184703912102203, 0.2332118169146755], 
reward next is 0.7668, 
noisyNet noise sample is [array([-2.7515042], dtype=float32), 0.02027169]. 
=============================================
[2019-03-23 11:39:13,574] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[81.16784 ]
 [81.1431  ]
 [81.47351 ]
 [81.977646]
 [82.44548 ]], R is [[81.12477875]
 [81.08403015]
 [81.06519318]
 [81.06032562]
 [81.05976105]].
[2019-03-23 11:39:16,951] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.9522914e-07 9.9999976e-01 4.7100307e-10 3.3546569e-23 6.5712337e-15], sum to 1.0000
[2019-03-23 11:39:16,961] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9048
[2019-03-23 11:39:16,966] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.3455424176505399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 384502.208079229, 384502.208079229, 117794.9896252893], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1140000.0000, 
sim time next is 1140600.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.3422080924567411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 380780.5437010573, 380780.5437010573, 117529.040144386], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 0.94, 1.0, 1.0, 0.17776011557092636, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1410298310003916, 0.1410298310003916, 0.2866561954741122], 
reward next is 0.7133, 
noisyNet noise sample is [array([-0.17212725], dtype=float32), -0.2762046]. 
=============================================
[2019-03-23 11:39:17,479] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.0531750e-10 1.0000000e+00 6.3588881e-15 3.7924871e-32 3.2425202e-20], sum to 1.0000
[2019-03-23 11:39:17,486] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7726
[2019-03-23 11:39:17,644] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.3430358853876961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 381699.1013899249, 381699.1013899252, 117592.6440204725], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1143600.0000, 
sim time next is 1144200.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.3426527449931661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 381271.7499714233, 381271.749971423, 117562.258273542], 
processed observation next is [1.0, 0.21739130434782608, 0.45454545454545453, 0.94, 1.0, 1.0, 0.17831593124145761, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1412117592486753, 0.14121175924867518, 0.28673721530132196], 
reward next is 0.7133, 
noisyNet noise sample is [array([-0.6783369], dtype=float32), -1.1132023]. 
=============================================
[2019-03-23 11:39:18,158] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.115913e-08 9.999999e-01 8.351378e-12 1.362034e-22 5.090594e-17], sum to 1.0000
[2019-03-23 11:39:18,165] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8738
[2019-03-23 11:39:18,173] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.16666666666667, 99.00000000000001, 1.0, 2.0, 0.3883763871834714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 436223.3015135696, 436223.3015135693, 123079.7632894129], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1149000.0000, 
sim time next is 1149600.0000, 
raw observation next is [18.33333333333334, 98.0, 1.0, 2.0, 0.3766361475388366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 423317.1169221533, 423317.1169221533, 122204.7936632113], 
processed observation next is [1.0, 0.30434782608695654, 0.46969696969696995, 0.98, 1.0, 1.0, 0.22079518442354576, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15678411737857528, 0.15678411737857528, 0.29806047234929584], 
reward next is 0.7019, 
noisyNet noise sample is [array([0.22137389], dtype=float32), -0.8057023]. 
=============================================
[2019-03-23 11:39:18,277] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0043412e-04 9.9988592e-01 1.3610388e-05 2.8479969e-15 6.7829786e-10], sum to 1.0000
[2019-03-23 11:39:18,291] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3931
[2019-03-23 11:39:18,294] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.3951872031516076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 445249.3766291615, 445249.3766291615, 124375.7798014731], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1152000.0000, 
sim time next is 1152600.0000, 
raw observation next is [19.33333333333334, 92.16666666666667, 1.0, 2.0, 0.3906693443356448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 440600.5132053933, 440600.5132053933, 124212.5023157498], 
processed observation next is [1.0, 0.34782608695652173, 0.5151515151515155, 0.9216666666666667, 1.0, 1.0, 0.238336680419556, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16318537526125676, 0.16318537526125676, 0.302957322721341], 
reward next is 0.6970, 
noisyNet noise sample is [array([-0.92841834], dtype=float32), -1.2955647]. 
=============================================
[2019-03-23 11:39:19,925] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2000, global step 31829: loss 0.6966
[2019-03-23 11:39:19,927] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2000, global step 31830: learning rate 0.0001
[2019-03-23 11:39:19,938] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2000, global step 31832: loss 0.6962
[2019-03-23 11:39:19,947] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2000, global step 31834: learning rate 0.0001
[2019-03-23 11:39:19,973] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2000, global step 31848: loss 1.1156
[2019-03-23 11:39:19,977] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2000, global step 31848: learning rate 0.0001
[2019-03-23 11:39:19,990] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2000, global step 31857: loss 1.0036
[2019-03-23 11:39:19,990] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2000, global step 31857: learning rate 0.0001
[2019-03-23 11:39:20,094] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2000, global step 31912: loss 1.6489
[2019-03-23 11:39:20,096] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2000, global step 31912: learning rate 0.0001
[2019-03-23 11:39:20,119] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2000, global step 31923: loss 1.4498
[2019-03-23 11:39:20,120] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2000, global step 31923: learning rate 0.0001
[2019-03-23 11:39:20,130] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2000, global step 31927: loss 1.5272
[2019-03-23 11:39:20,133] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2000, global step 31928: learning rate 0.0001
[2019-03-23 11:39:20,223] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2000, global step 31978: loss 1.3631
[2019-03-23 11:39:20,233] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2000, global step 31979: learning rate 0.0001
[2019-03-23 11:39:20,234] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2000, global step 31979: loss 1.2168
[2019-03-23 11:39:20,242] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2000, global step 31984: learning rate 0.0001
[2019-03-23 11:39:20,248] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2000, global step 31985: loss 1.0936
[2019-03-23 11:39:20,250] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2000, global step 31986: learning rate 0.0001
[2019-03-23 11:39:20,303] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2000, global step 32011: loss 0.4321
[2019-03-23 11:39:20,304] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2000, global step 32011: learning rate 0.0001
[2019-03-23 11:39:20,358] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2000, global step 32039: loss 0.2172
[2019-03-23 11:39:20,362] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2000, global step 32039: learning rate 0.0001
[2019-03-23 11:39:20,403] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2000, global step 32063: loss 0.0355
[2019-03-23 11:39:20,412] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2000, global step 32064: learning rate 0.0001
[2019-03-23 11:39:20,647] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2000, global step 32184: loss 0.1680
[2019-03-23 11:39:20,648] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2000, global step 32184: learning rate 0.0001
[2019-03-23 11:39:20,651] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2000, global step 32185: loss 0.2049
[2019-03-23 11:39:20,655] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2000, global step 32185: learning rate 0.0001
[2019-03-23 11:39:20,757] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2000, global step 32240: loss 0.9858
[2019-03-23 11:39:20,761] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2000, global step 32240: learning rate 0.0001
[2019-03-23 11:39:29,161] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.8033967e-10 1.0000000e+00 9.0217797e-16 3.0531172e-19 2.0394269e-16], sum to 1.0000
[2019-03-23 11:39:29,174] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2012
[2019-03-23 11:39:29,338] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 90.0, 1.0, 2.0, 0.4909934833898805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 560267.674004439, 560267.6740044394, 140074.1397530704], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1374000.0000, 
sim time next is 1374600.0000, 
raw observation next is [22.0, 89.0, 1.0, 2.0, 0.4850465775000777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 553482.6949173936, 553482.694917394, 139126.0846820287], 
processed observation next is [1.0, 0.9130434782608695, 0.6363636363636364, 0.89, 1.0, 1.0, 0.3563082218750971, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20499359071014578, 0.20499359071014592, 0.3393319138586066], 
reward next is 0.6607, 
noisyNet noise sample is [array([-1.1353401], dtype=float32), -0.535475]. 
=============================================
[2019-03-23 11:39:30,572] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.5316930e-10 1.0000000e+00 3.0936899e-14 1.1537117e-19 2.9181396e-14], sum to 1.0000
[2019-03-23 11:39:30,581] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5080
[2019-03-23 11:39:30,587] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4874472112715648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 556152.3421743932, 556152.3421743932, 140043.361983108], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1399800.0000, 
sim time next is 1400400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4876606587295418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 556396.0121164975, 556396.0121164975, 140067.7214107649], 
processed observation next is [0.0, 0.21739130434782608, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3595758234119272, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20607259708018427, 0.20607259708018427, 0.3416285888067437], 
reward next is 0.6584, 
noisyNet noise sample is [array([-1.0587285], dtype=float32), 0.45864138]. 
=============================================
[2019-03-23 11:39:35,620] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2500, global step 39753: loss 0.8721
[2019-03-23 11:39:35,623] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2500, global step 39755: learning rate 0.0001
[2019-03-23 11:39:35,741] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2500, global step 39813: loss 0.0101
[2019-03-23 11:39:35,744] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2500, global step 39813: learning rate 0.0001
[2019-03-23 11:39:35,759] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 39823: loss 0.0503
[2019-03-23 11:39:35,761] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2500, global step 39824: learning rate 0.0001
[2019-03-23 11:39:35,842] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2500, global step 39869: loss 0.1151
[2019-03-23 11:39:35,846] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2500, global step 39870: learning rate 0.0001
[2019-03-23 11:39:35,861] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2500, global step 39879: loss 0.6627
[2019-03-23 11:39:35,863] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2500, global step 39879: learning rate 0.0001
[2019-03-23 11:39:35,891] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 39888: loss 0.4723
[2019-03-23 11:39:35,892] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2500, global step 39888: learning rate 0.0001
[2019-03-23 11:39:35,903] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2500, global step 39894: loss 0.6530
[2019-03-23 11:39:35,906] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2500, global step 39894: learning rate 0.0001
[2019-03-23 11:39:36,015] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2500, global step 39957: loss 0.1346
[2019-03-23 11:39:36,018] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2500, global step 39957: learning rate 0.0001
[2019-03-23 11:39:36,129] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 40011: loss 0.1431
[2019-03-23 11:39:36,131] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2500, global step 40011: learning rate 0.0001
[2019-03-23 11:39:36,187] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 40041: loss 0.6417
[2019-03-23 11:39:36,197] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2500, global step 40042: loss 1.2559
[2019-03-23 11:39:36,197] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2500, global step 40042: learning rate 0.0001
[2019-03-23 11:39:36,199] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2500, global step 40043: learning rate 0.0001
[2019-03-23 11:39:36,297] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2500, global step 40094: loss 0.0580
[2019-03-23 11:39:36,298] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2500, global step 40094: learning rate 0.0001
[2019-03-23 11:39:36,357] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2500, global step 40122: loss 0.0008
[2019-03-23 11:39:36,361] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2500, global step 40122: learning rate 0.0001
[2019-03-23 11:39:36,472] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2500, global step 40185: loss 0.2869
[2019-03-23 11:39:36,474] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2500, global step 40186: learning rate 0.0001
[2019-03-23 11:39:36,503] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2500, global step 40200: loss 0.4193
[2019-03-23 11:39:36,506] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2500, global step 40200: learning rate 0.0001
[2019-03-23 11:39:36,587] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 40236: loss 0.5206
[2019-03-23 11:39:36,589] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2500, global step 40237: learning rate 0.0001
[2019-03-23 11:39:43,160] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.6126516e-13 1.0000000e+00 3.0170854e-20 5.5348157e-25 5.2059641e-19], sum to 1.0000
[2019-03-23 11:39:43,165] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1854
[2019-03-23 11:39:43,168] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 83.0, 1.0, 2.0, 0.3769445189538893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 423346.7199875486, 423346.7199875486, 122073.2616177351], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1638000.0000, 
sim time next is 1638600.0000, 
raw observation next is [19.83333333333334, 83.83333333333334, 1.0, 2.0, 0.3745982793768203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 420423.3870315793, 420423.3870315796, 121731.3571362308], 
processed observation next is [1.0, 1.0, 0.5378787878787882, 0.8383333333333334, 1.0, 1.0, 0.21824784922102533, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15571236556725157, 0.1557123655672517, 0.296905749112758], 
reward next is 0.7031, 
noisyNet noise sample is [array([0.9228376], dtype=float32), -0.90087885]. 
=============================================
[2019-03-23 11:39:43,174] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.6386970e-12 1.0000000e+00 2.1689356e-19 3.7627308e-24 7.4458859e-19], sum to 1.0000
[2019-03-23 11:39:43,182] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4481
[2019-03-23 11:39:43,186] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 84.66666666666666, 1.0, 2.0, 0.3498163297516194, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 388963.8857445595, 388963.8857445595, 118007.5944691281], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1644000.0000, 
sim time next is 1644600.0000, 
raw observation next is [19.0, 83.83333333333334, 1.0, 2.0, 0.3462584859310582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 384426.6015171986, 384426.6015171983, 117486.3584218899], 
processed observation next is [1.0, 0.0, 0.5, 0.8383333333333334, 1.0, 1.0, 0.1828231074138227, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14238022278414764, 0.14238022278414753, 0.2865520937119266], 
reward next is 0.7134, 
noisyNet noise sample is [array([-0.7800268], dtype=float32), 1.2194986]. 
=============================================
[2019-03-23 11:39:47,498] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.5977972e-08 9.9999988e-01 3.2720137e-15 4.4798357e-18 6.9790842e-13], sum to 1.0000
[2019-03-23 11:39:47,505] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9002
[2019-03-23 11:39:47,513] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 57.5, 1.0, 2.0, 0.2254228707224281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 244755.5628411933, 244755.5628411935, 71815.77111115107], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1711800.0000, 
sim time next is 1712400.0000, 
raw observation next is [15.0, 59.33333333333334, 1.0, 2.0, 0.2188923870762505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 237663.2802231181, 237663.2802231178, 70911.46701467507], 
processed observation next is [1.0, 0.8260869565217391, 0.3181818181818182, 0.5933333333333334, 1.0, 1.0, 0.02361548384531311, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08802343711967338, 0.08802343711967325, 0.17295479759676846], 
reward next is 0.8270, 
noisyNet noise sample is [array([0.7564858], dtype=float32), -1.1174687]. 
=============================================
[2019-03-23 11:39:48,981] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6362717e-02 9.8359668e-01 1.2819743e-05 8.2687592e-07 2.6993939e-05], sum to 1.0000
[2019-03-23 11:39:48,995] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6846
[2019-03-23 11:39:49,000] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [8.0, 84.0, 1.0, 2.0, 0.3240475756518315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 351877.2484505494, 351877.2484505497, 76929.96476346148], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1744200.0000, 
sim time next is 1744800.0000, 
raw observation next is [8.0, 85.0, 1.0, 2.0, 0.3223862193010212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 350072.5630547138, 350072.5630547135, 76824.79621750215], 
processed observation next is [1.0, 0.17391304347826086, 0.0, 0.85, 1.0, 1.0, 0.15298277412627645, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1296565048350792, 0.12965650483507907, 0.18737755175000526], 
reward next is 0.8126, 
noisyNet noise sample is [array([-0.03358078], dtype=float32), 0.24761477]. 
=============================================
[2019-03-23 11:39:49,915] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.6415833e-06 9.9999738e-01 1.2470783e-15 7.7542916e-21 3.1417858e-16], sum to 1.0000
[2019-03-23 11:39:49,920] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2327
[2019-03-23 11:39:49,925] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.83333333333333, 67.66666666666667, 1.0, 2.0, 0.3498293371033401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 379884.1204316977, 379884.1204316977, 80894.25596262216], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1756200.0000, 
sim time next is 1756800.0000, 
raw observation next is [12.0, 67.0, 1.0, 2.0, 0.3198090102308421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 347273.0254660732, 347273.0254660735, 78390.37939883879], 
processed observation next is [1.0, 0.34782608695652173, 0.18181818181818182, 0.67, 1.0, 1.0, 0.14976126278855256, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12861963906150858, 0.1286196390615087, 0.19119604731424095], 
reward next is 0.8088, 
noisyNet noise sample is [array([0.06238636], dtype=float32), 0.04037723]. 
=============================================
[2019-03-23 11:39:51,326] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3000, global step 47745: loss 0.0067
[2019-03-23 11:39:51,331] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3000, global step 47745: learning rate 0.0001
[2019-03-23 11:39:51,413] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3000, global step 47792: loss 1.4527
[2019-03-23 11:39:51,415] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3000, global step 47792: learning rate 0.0001
[2019-03-23 11:39:51,475] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3000, global step 47821: loss 1.3714
[2019-03-23 11:39:51,478] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3000, global step 47823: learning rate 0.0001
[2019-03-23 11:39:51,517] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3000, global step 47845: loss 0.3162
[2019-03-23 11:39:51,520] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3000, global step 47847: learning rate 0.0001
[2019-03-23 11:39:51,537] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3000, global step 47855: loss 0.3826
[2019-03-23 11:39:51,539] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3000, global step 47856: learning rate 0.0001
[2019-03-23 11:39:51,584] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3000, global step 47878: loss 0.0004
[2019-03-23 11:39:51,585] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3000, global step 47878: learning rate 0.0001
[2019-03-23 11:39:51,676] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3000, global step 47924: loss 0.4860
[2019-03-23 11:39:51,677] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3000, global step 47924: learning rate 0.0001
[2019-03-23 11:39:51,897] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3000, global step 48038: loss 0.1554
[2019-03-23 11:39:51,899] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3000, global step 48038: learning rate 0.0001
[2019-03-23 11:39:51,899] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3000, global step 48039: loss 0.0338
[2019-03-23 11:39:51,902] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3000, global step 48039: learning rate 0.0001
[2019-03-23 11:39:51,938] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3000, global step 48054: loss 0.0033
[2019-03-23 11:39:51,940] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3000, global step 48054: learning rate 0.0001
[2019-03-23 11:39:51,995] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3000, global step 48082: loss 0.2421
[2019-03-23 11:39:51,997] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3000, global step 48084: learning rate 0.0001
[2019-03-23 11:39:52,048] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3000, global step 48114: loss 0.9829
[2019-03-23 11:39:52,049] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3000, global step 48114: learning rate 0.0001
[2019-03-23 11:39:52,081] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3000, global step 48125: loss 1.9604
[2019-03-23 11:39:52,084] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3000, global step 48128: learning rate 0.0001
[2019-03-23 11:39:52,097] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3000, global step 48134: loss 1.1174
[2019-03-23 11:39:52,100] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3000, global step 48134: learning rate 0.0001
[2019-03-23 11:39:52,189] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3000, global step 48182: loss 0.3549
[2019-03-23 11:39:52,190] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3000, global step 48182: learning rate 0.0001
[2019-03-23 11:39:52,228] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3000, global step 48206: loss 0.0003
[2019-03-23 11:39:52,233] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3000, global step 48206: learning rate 0.0001
[2019-03-23 11:39:55,718] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 11:39:55,721] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:39:55,722] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:39:55,723] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:39:55,723] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:39:55,723] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:39:55,724] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:39:55,726] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:39:55,728] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:39:55,724] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:39:55,731] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:39:55,740] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run3
[2019-03-23 11:39:55,763] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run3
[2019-03-23 11:39:55,764] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run3
[2019-03-23 11:39:55,811] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run3
[2019-03-23 11:39:55,834] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run3
[2019-03-23 11:40:32,327] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00917178], dtype=float32), 0.09387867]
[2019-03-23 11:40:32,331] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.40000000000001, 56.0, 1.0, 2.0, 0.4505180205971588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 513314.0937976877, 513314.0937976873, 137968.236174137]
[2019-03-23 11:40:32,332] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:40:32,335] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.6856740e-07 9.9999988e-01 5.4588608e-20 2.4618845e-25 2.7203091e-19], sampled 0.3241977604749614
[2019-03-23 11:41:00,565] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00917178], dtype=float32), 0.09387867]
[2019-03-23 11:41:00,565] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.56666666666667, 72.0, 1.0, 2.0, 0.3862852000999877, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 434056.8553817124, 434056.8553817124, 127312.093953674]
[2019-03-23 11:41:00,567] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:41:00,569] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.7450294e-07 9.9999988e-01 6.0096966e-20 2.7845454e-25 2.9840644e-19], sampled 0.7008526998388862
[2019-03-23 11:41:29,904] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00917178], dtype=float32), 0.09387867]
[2019-03-23 11:41:29,904] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.758706845, 69.20688927, 1.0, 2.0, 0.3514321272828941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 387811.8483154363, 387811.8483154363, 121281.2443394255]
[2019-03-23 11:41:29,906] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:41:29,907] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.2532564e-07 9.9999988e-01 2.3713464e-20 8.4867480e-26 1.2192550e-19], sampled 0.7051142927853962
[2019-03-23 11:41:34,126] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:41:34,200] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:41:34,296] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:41:34,371] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:41:34,398] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:41:35,408] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 50000, evaluation results [50000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:41:38,086] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.0926014e-09 1.0000000e+00 1.2561356e-20 4.7331989e-27 5.8222852e-21], sum to 1.0000
[2019-03-23 11:41:38,093] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2858
[2019-03-23 11:41:38,098] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.16666666666667, 99.00000000000001, 1.0, 2.0, 0.4435507882451643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 503016.7546871224, 503016.7546871224, 130780.1234679877], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1926600.0000, 
sim time next is 1927200.0000, 
raw observation next is [19.33333333333334, 98.0, 1.0, 2.0, 0.4300520705438852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 487891.8753773416, 487891.8753773419, 129584.1027250919], 
processed observation next is [1.0, 0.30434782608695654, 0.5151515151515155, 0.98, 1.0, 1.0, 0.2875650881798565, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18070069458420057, 0.18070069458420068, 0.31605878713437047], 
reward next is 0.6839, 
noisyNet noise sample is [array([-0.47506845], dtype=float32), -0.9113582]. 
=============================================
[2019-03-23 11:41:45,810] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3500, global step 55593: loss 0.0389
[2019-03-23 11:41:45,814] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3500, global step 55593: learning rate 0.0001
[2019-03-23 11:41:45,931] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3500, global step 55658: loss 0.0022
[2019-03-23 11:41:45,935] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3500, global step 55658: learning rate 0.0001
[2019-03-23 11:41:46,181] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3500, global step 55798: loss 0.3737
[2019-03-23 11:41:46,184] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3500, global step 55798: learning rate 0.0001
[2019-03-23 11:41:46,226] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3500, global step 55825: loss 0.1123
[2019-03-23 11:41:46,229] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3500, global step 55825: learning rate 0.0001
[2019-03-23 11:41:46,299] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3500, global step 55868: loss 0.1069
[2019-03-23 11:41:46,300] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3500, global step 55868: learning rate 0.0001
[2019-03-23 11:41:46,374] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3500, global step 55909: loss 0.3405
[2019-03-23 11:41:46,376] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3500, global step 55909: learning rate 0.0001
[2019-03-23 11:41:46,479] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3500, global step 55969: loss 0.0320
[2019-03-23 11:41:46,480] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3500, global step 55970: learning rate 0.0001
[2019-03-23 11:41:46,505] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3500, global step 55984: loss 0.0054
[2019-03-23 11:41:46,507] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3500, global step 55985: learning rate 0.0001
[2019-03-23 11:41:46,599] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3500, global step 56039: loss 0.0553
[2019-03-23 11:41:46,602] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3500, global step 56040: learning rate 0.0001
[2019-03-23 11:41:46,624] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3500, global step 56052: loss 0.6088
[2019-03-23 11:41:46,625] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3500, global step 56052: learning rate 0.0001
[2019-03-23 11:41:46,706] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3500, global step 56107: loss 0.6260
[2019-03-23 11:41:46,707] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3500, global step 56108: learning rate 0.0001
[2019-03-23 11:41:46,718] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3500, global step 56115: loss 0.1321
[2019-03-23 11:41:46,720] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3500, global step 56115: learning rate 0.0001
[2019-03-23 11:41:46,797] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3500, global step 56159: loss 0.0454
[2019-03-23 11:41:46,798] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3500, global step 56160: learning rate 0.0001
[2019-03-23 11:41:46,847] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3500, global step 56197: loss 0.3930
[2019-03-23 11:41:46,848] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3500, global step 56198: learning rate 0.0001
[2019-03-23 11:41:46,937] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3500, global step 56245: loss 0.6700
[2019-03-23 11:41:46,939] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3500, global step 56247: learning rate 0.0001
[2019-03-23 11:41:47,016] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3500, global step 56298: loss 0.0848
[2019-03-23 11:41:47,017] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3500, global step 56298: learning rate 0.0001
[2019-03-23 11:41:56,522] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.6804966e-10 1.0000000e+00 7.7427424e-24 2.0829776e-31 4.1322181e-25], sum to 1.0000
[2019-03-23 11:41:56,533] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4782
[2019-03-23 11:41:56,537] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 56.0, 1.0, 2.0, 0.4487807166029232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 487390.5388122255, 487390.5388122255, 99217.21162536815], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2284200.0000, 
sim time next is 2284800.0000, 
raw observation next is [18.0, 56.0, 1.0, 2.0, 0.4288957900087293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 465784.5125564045, 465784.5125564045, 97119.44651303478], 
processed observation next is [1.0, 0.43478260869565216, 0.45454545454545453, 0.56, 1.0, 1.0, 0.2861197375109116, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17251278242829796, 0.17251278242829796, 0.23687669881227996], 
reward next is 0.7631, 
noisyNet noise sample is [array([1.3440955], dtype=float32), 0.8101136]. 
=============================================
[2019-03-23 11:42:01,100] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4000, global step 63521: loss 0.3098
[2019-03-23 11:42:01,103] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4000, global step 63522: learning rate 0.0001
[2019-03-23 11:42:01,355] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4000, global step 63653: loss 1.6303
[2019-03-23 11:42:01,358] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4000, global step 63655: learning rate 0.0001
[2019-03-23 11:42:01,593] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4000, global step 63785: loss 0.0855
[2019-03-23 11:42:01,595] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4000, global step 63786: learning rate 0.0001
[2019-03-23 11:42:01,657] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4000, global step 63822: loss 0.2951
[2019-03-23 11:42:01,659] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4000, global step 63822: loss 0.2136
[2019-03-23 11:42:01,659] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4000, global step 63822: learning rate 0.0001
[2019-03-23 11:42:01,662] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4000, global step 63823: learning rate 0.0001
[2019-03-23 11:42:01,879] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4000, global step 63949: loss 1.8600
[2019-03-23 11:42:01,880] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4000, global step 63949: learning rate 0.0001
[2019-03-23 11:42:01,898] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4000, global step 63959: loss 1.8201
[2019-03-23 11:42:01,901] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4000, global step 63961: learning rate 0.0001
[2019-03-23 11:42:01,933] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4000, global step 63980: loss 1.7853
[2019-03-23 11:42:01,935] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4000, global step 63983: learning rate 0.0001
[2019-03-23 11:42:02,002] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4000, global step 64018: loss 0.9302
[2019-03-23 11:42:02,007] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4000, global step 64018: learning rate 0.0001
[2019-03-23 11:42:02,140] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4000, global step 64098: loss 0.1561
[2019-03-23 11:42:02,141] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4000, global step 64099: learning rate 0.0001
[2019-03-23 11:42:02,148] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4000, global step 64102: loss 0.1125
[2019-03-23 11:42:02,154] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4000, global step 64105: learning rate 0.0001
[2019-03-23 11:42:02,214] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4000, global step 64140: loss 0.4581
[2019-03-23 11:42:02,215] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4000, global step 64140: learning rate 0.0001
[2019-03-23 11:42:02,270] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4000, global step 64172: loss 0.1462
[2019-03-23 11:42:02,272] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4000, global step 64172: learning rate 0.0001
[2019-03-23 11:42:02,327] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4000, global step 64206: loss 0.0044
[2019-03-23 11:42:02,329] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4000, global step 64206: learning rate 0.0001
[2019-03-23 11:42:02,392] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4000, global step 64246: loss 0.3321
[2019-03-23 11:42:02,394] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4000, global step 64246: learning rate 0.0001
[2019-03-23 11:42:02,501] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4000, global step 64313: loss 1.7321
[2019-03-23 11:42:02,502] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4000, global step 64313: learning rate 0.0001
[2019-03-23 11:42:12,338] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.0303647e-09 1.0000000e+00 5.8656982e-18 1.0610077e-23 2.3001871e-19], sum to 1.0000
[2019-03-23 11:42:12,348] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2912
[2019-03-23 11:42:12,355] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.3, 88.0, 1.0, 2.0, 0.2996883917528385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 325417.2123549432, 325417.2123549429, 111172.2756192271], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2595600.0000, 
sim time next is 2596200.0000, 
raw observation next is [17.23333333333333, 89.00000000000001, 1.0, 2.0, 0.3046946669001047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 331066.084637569, 331066.084637569, 111582.0363303281], 
processed observation next is [0.0, 0.043478260869565216, 0.41969696969696957, 0.8900000000000001, 1.0, 1.0, 0.13086833362513087, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12261706838428481, 0.12261706838428481, 0.27215130812275146], 
reward next is 0.7278, 
noisyNet noise sample is [array([1.0444285], dtype=float32), 1.4478729]. 
=============================================
[2019-03-23 11:42:12,552] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2616767e-10 1.0000000e+00 9.6163997e-22 1.9604221e-24 3.1182879e-21], sum to 1.0000
[2019-03-23 11:42:12,561] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6178
[2019-03-23 11:42:12,737] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.83333333333333, 100.0, 1.0, 2.0, 0.2946804621724605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 319977.553459277, 319977.553459277, 110837.0343761914], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2613000.0000, 
sim time next is 2613600.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.3002906268287293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 326071.369698946, 326071.369698946, 111212.5464421749], 
processed observation next is [0.0, 0.2608695652173913, 0.36363636363636365, 1.0, 1.0, 1.0, 0.1253632835359116, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1207671739625726, 0.1207671739625726, 0.2712501132735973], 
reward next is 0.7287, 
noisyNet noise sample is [array([0.35984987], dtype=float32), -0.020953383]. 
=============================================
[2019-03-23 11:42:13,745] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.7502085e-06 9.9999130e-01 7.9917525e-15 3.4430537e-20 3.5278334e-15], sum to 1.0000
[2019-03-23 11:42:13,753] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0602
[2019-03-23 11:42:13,756] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 88.5, 1.0, 2.0, 0.3338938955737646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 370318.3907756082, 370318.3907756082, 116375.8580819256], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2619000.0000, 
sim time next is 2619600.0000, 
raw observation next is [19.0, 86.66666666666666, 1.0, 2.0, 0.3428297752092589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 381828.784877916, 381828.784877916, 117731.3007562408], 
processed observation next is [0.0, 0.30434782608695654, 0.5, 0.8666666666666666, 1.0, 1.0, 0.1785372190115736, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1414180684733022, 0.1414180684733022, 0.2871495140396117], 
reward next is 0.7129, 
noisyNet noise sample is [array([1.0810664], dtype=float32), -1.386992]. 
=============================================
[2019-03-23 11:42:16,554] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4500, global step 71493: loss 0.0039
[2019-03-23 11:42:16,561] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4500, global step 71493: learning rate 0.0001
[2019-03-23 11:42:16,708] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4500, global step 71568: loss 0.0003
[2019-03-23 11:42:16,710] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4500, global step 71569: learning rate 0.0001
[2019-03-23 11:42:17,195] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4500, global step 71827: loss 0.0654
[2019-03-23 11:42:17,197] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4500, global step 71827: learning rate 0.0001
[2019-03-23 11:42:17,202] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4500, global step 71829: loss 0.0867
[2019-03-23 11:42:17,207] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4500, global step 71832: learning rate 0.0001
[2019-03-23 11:42:17,256] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.26392985e-10 1.00000000e+00 1.24471634e-20 4.33621408e-25
 3.67366622e-21], sum to 1.0000
[2019-03-23 11:42:17,263] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1533
[2019-03-23 11:42:17,267] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.13333333333333, 86.5, 1.0, 2.0, 0.3337410210009448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 367219.0439096661, 367219.0439096658, 115215.2644516828], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2688600.0000, 
sim time next is 2689200.0000, 
raw observation next is [18.0, 87.0, 1.0, 2.0, 0.3313946150528904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 364161.6539481933, 364161.6539481935, 114864.6702881015], 
processed observation next is [0.0, 0.13043478260869565, 0.45454545454545453, 0.87, 1.0, 1.0, 0.164243268816113, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.134874686647479, 0.13487468664747906, 0.28015773241000363], 
reward next is 0.7198, 
noisyNet noise sample is [array([0.4593735], dtype=float32), 1.4427218]. 
=============================================
[2019-03-23 11:42:17,287] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4500, global step 71869: loss 0.1073
[2019-03-23 11:42:17,291] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4500, global step 71869: learning rate 0.0001
[2019-03-23 11:42:17,314] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4500, global step 71882: loss 0.0130
[2019-03-23 11:42:17,316] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4500, global step 71882: learning rate 0.0001
[2019-03-23 11:42:17,409] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4500, global step 71932: loss 0.2652
[2019-03-23 11:42:17,411] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4500, global step 71932: learning rate 0.0001
[2019-03-23 11:42:17,545] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4500, global step 72003: loss 0.3745
[2019-03-23 11:42:17,548] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4500, global step 72003: learning rate 0.0001
[2019-03-23 11:42:17,616] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4500, global step 72039: loss 0.1449
[2019-03-23 11:42:17,618] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4500, global step 72039: learning rate 0.0001
[2019-03-23 11:42:17,708] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4500, global step 72087: loss 0.0440
[2019-03-23 11:42:17,711] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4500, global step 72087: learning rate 0.0001
[2019-03-23 11:42:17,749] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4500, global step 72104: loss 0.1050
[2019-03-23 11:42:17,754] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4500, global step 72105: learning rate 0.0001
[2019-03-23 11:42:17,851] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4500, global step 72160: loss 0.2485
[2019-03-23 11:42:17,852] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4500, global step 72160: learning rate 0.0001
[2019-03-23 11:42:17,859] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4500, global step 72166: loss 0.1444
[2019-03-23 11:42:17,861] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4500, global step 72167: learning rate 0.0001
[2019-03-23 11:42:17,998] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4500, global step 72241: loss 0.0259
[2019-03-23 11:42:18,002] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4500, global step 72243: learning rate 0.0001
[2019-03-23 11:42:18,146] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4500, global step 72317: loss 0.6701
[2019-03-23 11:42:18,150] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4500, global step 72318: learning rate 0.0001
[2019-03-23 11:42:18,175] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4500, global step 72330: loss 0.3851
[2019-03-23 11:42:18,182] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4500, global step 72330: learning rate 0.0001
[2019-03-23 11:42:19,180] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.7089444e-09 1.0000000e+00 2.6717092e-17 5.5537958e-22 7.4670560e-17], sum to 1.0000
[2019-03-23 11:42:19,188] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6344
[2019-03-23 11:42:19,195] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666666, 63.16666666666667, 1.0, 2.0, 0.4938002040726102, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 563013.4716598659, 563013.4716598659, 141558.3792844982], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2725800.0000, 
sim time next is 2726400.0000, 
raw observation next is [26.33333333333334, 64.33333333333334, 1.0, 2.0, 0.4918740299583916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560958.8820090033, 560958.8820090033, 141119.5003766785], 
processed observation next is [0.0, 0.5652173913043478, 0.8333333333333336, 0.6433333333333334, 1.0, 1.0, 0.36484253744798945, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20776254889222345, 0.20776254889222345, 0.34419390335775246], 
reward next is 0.6558, 
noisyNet noise sample is [array([0.2521958], dtype=float32), -1.160906]. 
=============================================
[2019-03-23 11:42:19,369] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.2414395e-08 1.0000000e+00 5.1651383e-18 4.0365477e-22 2.5616444e-18], sum to 1.0000
[2019-03-23 11:42:19,375] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2637
[2019-03-23 11:42:19,536] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 57.66666666666667, 1.0, 2.0, 0.4511995276312597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 514515.0188324074, 514515.0188324074, 134310.0878085838], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2737200.0000, 
sim time next is 2737800.0000, 
raw observation next is [26.5, 56.0, 1.0, 2.0, 0.4470117758204592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 509563.6637642221, 509563.6637642221, 133574.9505439058], 
processed observation next is [0.0, 0.6956521739130435, 0.8409090909090909, 0.56, 1.0, 1.0, 0.30876471977557396, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1887272828756378, 0.1887272828756378, 0.3257925623022093], 
reward next is 0.6742, 
noisyNet noise sample is [array([-0.23143657], dtype=float32), -0.54528373]. 
=============================================
[2019-03-23 11:42:19,975] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.7289663e-07 9.9999988e-01 1.6811856e-14 2.1970150e-19 1.8084577e-14], sum to 1.0000
[2019-03-23 11:42:19,983] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3283
[2019-03-23 11:42:19,990] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 54.33333333333334, 1.0, 2.0, 0.4421034195596192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 503747.2401522909, 503747.2401522909, 132754.2429366854], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2738400.0000, 
sim time next is 2739000.0000, 
raw observation next is [26.83333333333333, 52.66666666666666, 1.0, 2.0, 0.4366209719422482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 497230.5490192752, 497230.5490192752, 131865.859725251], 
processed observation next is [0.0, 0.6956521739130435, 0.8560606060606059, 0.5266666666666666, 1.0, 1.0, 0.2957762149278102, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18415946259973154, 0.18415946259973154, 0.3216240481103683], 
reward next is 0.6784, 
noisyNet noise sample is [array([-0.6544758], dtype=float32), 0.95652366]. 
=============================================
[2019-03-23 11:42:20,000] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[52.19006 ]
 [52.226067]
 [52.25395 ]
 [52.275356]
 [52.282814]], R is [[52.30595016]
 [52.45909882]
 [52.60871506]
 [52.75504303]
 [52.89837265]].
[2019-03-23 11:42:23,541] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 11:42:23,546] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:42:23,547] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:42:23,548] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:42:23,550] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:42:23,551] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:42:23,548] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:42:23,551] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:42:23,553] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:42:23,558] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:42:23,560] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:42:23,566] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run4
[2019-03-23 11:42:23,589] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run4
[2019-03-23 11:42:23,622] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run4
[2019-03-23 11:42:23,624] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run4
[2019-03-23 11:42:23,668] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run4
[2019-03-23 11:42:24,889] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01356092], dtype=float32), 0.14485206]
[2019-03-23 11:42:24,891] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.20224488, 91.47489445333333, 1.0, 2.0, 0.3368337204867839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 374098.3053185896, 374098.3053185889, 121132.2335611914]
[2019-03-23 11:42:24,892] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:42:24,894] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.0274262e-05 9.9993968e-01 3.1449252e-09 8.9855574e-11 1.7801477e-09], sampled 0.6571287527404092
[2019-03-23 11:42:29,666] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01356092], dtype=float32), 0.14485206]
[2019-03-23 11:42:29,667] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.8, 65.33333333333334, 1.0, 2.0, 0.4246812829604188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 478267.972517081, 478267.972517081, 131287.5434233325]
[2019-03-23 11:42:29,668] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:42:29,673] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.7707618e-05 9.9998224e-01 2.7981736e-10 5.1377088e-12 1.4863653e-10], sampled 0.27036822699482166
[2019-03-23 11:43:22,799] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01356092], dtype=float32), 0.14485206]
[2019-03-23 11:43:22,800] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.775539235, 43.920447275, 1.0, 2.0, 0.6142707099144412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 697343.7773248536, 697343.7773248531, 154541.0989864987]
[2019-03-23 11:43:22,804] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:43:22,808] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.2419717e-05 9.9997759e-01 4.4577805e-10 8.9057494e-12 2.3953894e-10], sampled 0.3715870351997449
[2019-03-23 11:43:40,976] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01356092], dtype=float32), 0.14485206]
[2019-03-23 11:43:40,977] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.92791107, 87.02123695, 1.0, 2.0, 0.2910809883705526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 316048.2220405211, 316048.2220405211, 109472.1067890873]
[2019-03-23 11:43:40,977] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:43:40,979] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.7600509e-05 9.9998236e-01 2.7679647e-10 5.0709428e-12 1.4698476e-10], sampled 0.3139262185236791
[2019-03-23 11:43:41,928] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01356092], dtype=float32), 0.14485206]
[2019-03-23 11:43:41,929] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.4, 50.66666666666666, 1.0, 2.0, 0.4746993608453785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 529367.115973865, 529367.115973865, 133757.4988520108]
[2019-03-23 11:43:41,930] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:43:41,932] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.1386253e-05 9.9997866e-01 4.0612913e-10 7.9824931e-12 2.1783560e-10], sampled 0.34994521330174333
[2019-03-23 11:43:51,903] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01356092], dtype=float32), 0.14485206]
[2019-03-23 11:43:51,904] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.45155936, 61.90096264, 1.0, 2.0, 0.5066058828112988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 577887.7622193892, 577887.7622193889, 146774.2736524161]
[2019-03-23 11:43:51,905] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:43:51,908] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.7431597e-05 9.9998260e-01 2.7119701e-10 4.9506037e-12 1.4392729e-10], sampled 0.6300090861672207
[2019-03-23 11:44:01,750] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:44:01,781] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:44:01,927] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:44:01,946] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8594.4970 1705928113.8738 465.0000
[2019-03-23 11:44:02,125] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:44:03,137] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 75000, evaluation results [75000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8594.497035745262, 1705928113.8737924, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:44:03,696] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.1591309e-05 9.9993837e-01 1.1114970e-09 5.8019575e-11 6.3960004e-10], sum to 1.0000
[2019-03-23 11:44:03,704] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2914
[2019-03-23 11:44:03,707] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333333, 51.33333333333334, 1.0, 2.0, 0.4550417819890058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 519225.6154864492, 519225.6154864492, 136015.0958072608], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2828400.0000, 
sim time next is 2829000.0000, 
raw observation next is [28.16666666666667, 51.16666666666666, 1.0, 2.0, 0.4541453532474587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518189.8476602717, 518189.8476602717, 135564.4301949794], 
processed observation next is [1.0, 0.7391304347826086, 0.9166666666666669, 0.5116666666666666, 1.0, 1.0, 0.31768169155932335, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19192216580010063, 0.19192216580010063, 0.3306449516950717], 
reward next is 0.6694, 
noisyNet noise sample is [array([0.23681135], dtype=float32), 1.6651149]. 
=============================================
[2019-03-23 11:44:03,719] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[24.72866 ]
 [24.84446 ]
 [24.729286]
 [24.408028]
 [24.427502]], R is [[25.53600883]
 [25.94890594]
 [26.35637665]
 [26.09281349]
 [25.83188629]].
[2019-03-23 11:44:07,069] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2625381e-06 9.9999869e-01 8.6112226e-13 8.1522842e-14 1.7445221e-12], sum to 1.0000
[2019-03-23 11:44:07,074] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5215
[2019-03-23 11:44:07,078] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1362419.387759687 W.
[2019-03-23 11:44:07,083] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 74.0, 1.0, 2.0, 0.4038719768244992, 1.0, 1.0, 0.4038719768244992, 1.0, 2.0, 0.8170752202640902, 6.911199999999999, 6.9112, 77.3421103, 1362419.387759687, 1362419.387759688, 309158.29582403], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2884800.0000, 
sim time next is 2885400.0000, 
raw observation next is [26.0, 74.0, 1.0, 2.0, 0.4161413962098702, 1.0, 2.0, 0.4161413962098702, 1.0, 2.0, 0.842011942541673, 6.9112, 6.9112, 77.3421103, 1403860.272669924, 1403860.272669924, 315237.1191297704], 
processed observation next is [1.0, 0.391304347826087, 0.8181818181818182, 0.74, 1.0, 1.0, 0.2701767452623377, 1.0, 1.0, 0.2701767452623377, 1.0, 1.0, 0.7743027750595328, 0.0, 0.0, 0.5085185399722538, 0.5199482491370089, 0.5199482491370089, 0.7688710222677326], 
reward next is 0.2311, 
noisyNet noise sample is [array([1.4344782], dtype=float32), 1.495431]. 
=============================================
[2019-03-23 11:44:08,633] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.5661117e-14 1.0000000e+00 7.3084315e-23 6.4953257e-29 1.0684825e-28], sum to 1.0000
[2019-03-23 11:44:08,640] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3207
[2019-03-23 11:44:08,646] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5227978844806144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 595584.5439143927, 595584.543914393, 145556.294714573], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2923200.0000, 
sim time next is 2923800.0000, 
raw observation next is [22.83333333333334, 89.83333333333334, 1.0, 2.0, 0.5231594874231991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 596105.3683108569, 596105.3683108569, 145498.3814270613], 
processed observation next is [1.0, 0.8695652173913043, 0.6742424242424245, 0.8983333333333334, 1.0, 1.0, 0.4039493592789988, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2207797660410581, 0.2207797660410581, 0.35487410104161293], 
reward next is 0.6451, 
noisyNet noise sample is [array([0.6732388], dtype=float32), 0.31070197]. 
=============================================
[2019-03-23 11:44:10,188] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.3111653e-14 1.0000000e+00 6.8596934e-23 5.5785793e-28 3.7109908e-29], sum to 1.0000
[2019-03-23 11:44:10,194] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0492
[2019-03-23 11:44:10,196] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.4948815147059971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564380.2545456504, 564380.2545456504, 141486.0040034096], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2959200.0000, 
sim time next is 2959800.0000, 
raw observation next is [22.16666666666667, 93.16666666666667, 1.0, 2.0, 0.553414492677452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 631092.9695532785, 631092.9695532788, 148673.4256125627], 
processed observation next is [1.0, 0.2608695652173913, 0.6439393939393941, 0.9316666666666668, 1.0, 1.0, 0.44176811584681497, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23373813687158465, 0.23373813687158473, 0.362618111250153], 
reward next is 0.6374, 
noisyNet noise sample is [array([-1.504787], dtype=float32), -0.7475209]. 
=============================================
[2019-03-23 11:44:11,311] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.63074556e-09 1.00000000e+00 1.19364315e-14 1.80336756e-17
 1.41507458e-17], sum to 1.0000
[2019-03-23 11:44:11,318] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1282
[2019-03-23 11:44:11,323] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1201541.06025136 W.
[2019-03-23 11:44:11,332] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 70.0, 1.0, 2.0, 0.5312671503003652, 1.0, 1.0, 0.5312671503003652, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1201541.06025136, 1201541.060251359, 241716.6122137976], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2973600.0000, 
sim time next is 2974200.0000, 
raw observation next is [26.16666666666667, 68.66666666666667, 1.0, 2.0, 0.5971572382945074, 1.0, 2.0, 0.5971572382945074, 0.0, 2.0, 0.0, 6.9112, 6.9112, 79.22590883987648, 1349467.484366437, 1349467.484366437, 260782.8413004655], 
processed observation next is [1.0, 0.43478260869565216, 0.825757575757576, 0.6866666666666668, 1.0, 1.0, 0.4964465478681342, 1.0, 1.0, 0.4964465478681342, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5209043732445049, 0.4998027719875692, 0.4998027719875692, 0.6360557104889402], 
reward next is 0.3639, 
noisyNet noise sample is [array([-0.81370693], dtype=float32), 2.2589757]. 
=============================================
[2019-03-23 11:44:11,704] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5000, global step 79598: loss 97.2277
[2019-03-23 11:44:11,708] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5000, global step 79598: learning rate 0.0001
[2019-03-23 11:44:11,909] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5000, global step 79635: loss 72.9921
[2019-03-23 11:44:11,910] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5000, global step 79635: learning rate 0.0001
[2019-03-23 11:44:12,413] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5000, global step 79831: loss 148.3407
[2019-03-23 11:44:12,415] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5000, global step 79833: learning rate 0.0001
[2019-03-23 11:44:12,583] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5000, global step 79852: loss -31.4576
[2019-03-23 11:44:12,584] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5000, global step 79852: learning rate 0.0001
[2019-03-23 11:44:12,590] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5000, global step 79855: loss 66.0531
[2019-03-23 11:44:12,723] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5000, global step 79855: learning rate 0.0001
[2019-03-23 11:44:12,867] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.4212207e-07 9.9999940e-01 3.3129128e-11 4.9953032e-13 1.5690979e-13], sum to 1.0000
[2019-03-23 11:44:12,878] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5692
[2019-03-23 11:44:12,887] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1442409.168598977 W.
[2019-03-23 11:44:13,066] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 58.66666666666667, 1.0, 2.0, 0.7873457476398753, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9780268300348404, 6.9112, 6.9112, 77.32846344354104, 1442409.168598977, 1442409.168598977, 306634.6086523666], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2992800.0000, 
sim time next is 2993400.0000, 
raw observation next is [28.0, 60.5, 1.0, 2.0, 0.6764340914586892, 1.0, 1.0, 0.6764340914586892, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1524562.39336158, 1524562.39336158, 283804.6904155512], 
processed observation next is [1.0, 0.6521739130434783, 0.9090909090909091, 0.605, 1.0, 1.0, 0.5955426143233614, 1.0, 0.5, 0.5955426143233614, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5646527382820667, 0.5646527382820667, 0.6922065619891492], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.6326568], dtype=float32), 0.7872403]. 
=============================================
[2019-03-23 11:44:13,094] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5000, global step 79903: loss 10.0594
[2019-03-23 11:44:13,099] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5000, global step 79903: learning rate 0.0001
[2019-03-23 11:44:13,316] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5000, global step 79949: loss 65.8928
[2019-03-23 11:44:13,317] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5000, global step 79949: learning rate 0.0001
[2019-03-23 11:44:13,516] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5000, global step 79988: loss 44.8343
[2019-03-23 11:44:13,518] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5000, global step 79988: learning rate 0.0001
[2019-03-23 11:44:13,823] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5000, global step 80083: loss 19.1310
[2019-03-23 11:44:13,824] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5000, global step 80083: learning rate 0.0001
[2019-03-23 11:44:13,834] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5000, global step 80092: loss -7.4390
[2019-03-23 11:44:13,995] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5000, global step 80092: learning rate 0.0001
[2019-03-23 11:44:14,117] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5000, global step 80100: loss 11.7576
[2019-03-23 11:44:14,118] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5000, global step 80101: loss 155.6321
[2019-03-23 11:44:14,120] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5000, global step 80101: learning rate 0.0001
[2019-03-23 11:44:14,259] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5000, global step 80101: learning rate 0.0001
[2019-03-23 11:44:14,451] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5000, global step 80136: loss 218.1265
[2019-03-23 11:44:14,453] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5000, global step 80138: learning rate 0.0001
[2019-03-23 11:44:14,654] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5000, global step 80201: loss -11.2624
[2019-03-23 11:44:14,654] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5000, global step 80201: learning rate 0.0001
[2019-03-23 11:44:14,859] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5000, global step 80245: loss 140.8214
[2019-03-23 11:44:14,860] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5000, global step 80245: learning rate 0.0001
[2019-03-23 11:44:15,057] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5000, global step 80301: loss 29.1719
[2019-03-23 11:44:15,059] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5000, global step 80301: learning rate 0.0001
[2019-03-23 11:44:25,958] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.9487522e-19 1.0000000e+00 1.0366433e-30 7.5518293e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 11:44:25,969] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2671
[2019-03-23 11:44:25,972] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.83333333333333, 83.83333333333334, 1.0, 2.0, 0.3378319273697006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 373749.7364881614, 373749.7364881614, 116298.8853814041], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3221400.0000, 
sim time next is 3222000.0000, 
raw observation next is [19.0, 83.0, 1.0, 2.0, 0.3396689218083329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 376159.0003668476, 376159.0003668473, 116588.5074654703], 
processed observation next is [0.0, 0.30434782608695654, 0.5, 0.83, 1.0, 1.0, 0.17458615226041613, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13931814828401765, 0.13931814828401753, 0.2843622133304154], 
reward next is 0.7156, 
noisyNet noise sample is [array([-0.405021], dtype=float32), 1.1972473]. 
=============================================
[2019-03-23 11:44:25,985] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[88.44713 ]
 [88.502655]
 [88.55204 ]
 [88.59251 ]
 [88.62766 ]], R is [[88.25376892]
 [88.08757782]
 [87.92373657]
 [87.76216888]
 [87.60283661]].
[2019-03-23 11:44:29,398] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5500, global step 87544: loss 0.7449
[2019-03-23 11:44:29,402] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5500, global step 87544: learning rate 0.0001
[2019-03-23 11:44:29,473] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5500, global step 87581: loss 0.7930
[2019-03-23 11:44:29,475] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5500, global step 87581: learning rate 0.0001
[2019-03-23 11:44:29,853] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5500, global step 87777: loss 0.1324
[2019-03-23 11:44:29,854] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5500, global step 87777: learning rate 0.0001
[2019-03-23 11:44:30,009] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5500, global step 87853: loss 0.4271
[2019-03-23 11:44:30,011] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5500, global step 87855: learning rate 0.0001
[2019-03-23 11:44:30,088] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5500, global step 87894: loss 0.4725
[2019-03-23 11:44:30,089] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5500, global step 87894: learning rate 0.0001
[2019-03-23 11:44:30,132] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5500, global step 87915: loss 0.3613
[2019-03-23 11:44:30,136] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5500, global step 87915: learning rate 0.0001
[2019-03-23 11:44:30,163] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5500, global step 87928: loss 0.3725
[2019-03-23 11:44:30,166] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5500, global step 87929: learning rate 0.0001
[2019-03-23 11:44:30,381] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5500, global step 88041: loss 0.0012
[2019-03-23 11:44:30,383] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5500, global step 88042: learning rate 0.0001
[2019-03-23 11:44:30,393] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5500, global step 88047: loss 0.0018
[2019-03-23 11:44:30,395] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5500, global step 88047: learning rate 0.0001
[2019-03-23 11:44:30,410] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5500, global step 88056: loss 0.0159
[2019-03-23 11:44:30,414] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5500, global step 88058: loss 0.0043
[2019-03-23 11:44:30,415] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5500, global step 88057: learning rate 0.0001
[2019-03-23 11:44:30,425] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5500, global step 88059: learning rate 0.0001
[2019-03-23 11:44:30,435] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5500, global step 88064: loss 0.0514
[2019-03-23 11:44:30,438] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5500, global step 88066: learning rate 0.0001
[2019-03-23 11:44:30,730] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5500, global step 88215: loss 0.3333
[2019-03-23 11:44:30,732] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5500, global step 88216: learning rate 0.0001
[2019-03-23 11:44:30,764] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5500, global step 88228: loss 0.1004
[2019-03-23 11:44:30,768] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5500, global step 88229: learning rate 0.0001
[2019-03-23 11:44:30,874] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5500, global step 88286: loss 0.0009
[2019-03-23 11:44:30,877] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5500, global step 88287: learning rate 0.0001
[2019-03-23 11:44:30,959] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5500, global step 88323: loss 0.4047
[2019-03-23 11:44:30,960] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5500, global step 88323: learning rate 0.0001
[2019-03-23 11:44:36,700] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.7436596e-08 1.0000000e+00 1.4854597e-13 1.0213773e-16 1.1805633e-17], sum to 1.0000
[2019-03-23 11:44:36,705] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7887
[2019-03-23 11:44:36,711] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1320757.23574468 W.
[2019-03-23 11:44:36,715] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.83333333333334, 56.16666666666667, 1.0, 2.0, 0.6782397185308294, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9747586185739925, 6.911199999999999, 6.9112, 77.32846344354104, 1320757.23574468, 1320757.23574468, 286418.9426243399], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3427800.0000, 
sim time next is 3428400.0000, 
raw observation next is [27.66666666666667, 57.33333333333334, 1.0, 2.0, 0.3906725380393334, 1.0, 1.0, 0.3906725380393334, 1.0, 2.0, 0.7911519959178732, 6.911199999999999, 6.9112, 77.3421103, 1328540.812609952, 1328540.812609952, 298676.9904142765], 
processed observation next is [1.0, 0.6956521739130435, 0.8939393939393941, 0.5733333333333335, 1.0, 1.0, 0.23834067254916672, 1.0, 0.5, 0.23834067254916672, 1.0, 1.0, 0.7016457084541047, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.49205215281850073, 0.49205215281850073, 0.7284804644250646], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5689576], dtype=float32), -0.16335051]. 
=============================================
[2019-03-23 11:44:45,355] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6000, global step 95655: loss 46.1922
[2019-03-23 11:44:45,357] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6000, global step 95655: learning rate 0.0001
[2019-03-23 11:44:45,491] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6000, global step 95725: loss -13.5774
[2019-03-23 11:44:45,494] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6000, global step 95725: learning rate 0.0001
[2019-03-23 11:44:45,587] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.8618373e-08 1.0000000e+00 9.0535809e-13 1.6989180e-14 1.9160406e-15], sum to 1.0000
[2019-03-23 11:44:45,594] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3183
[2019-03-23 11:44:45,602] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1424439.258289308 W.
[2019-03-23 11:44:45,606] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.6333506962918664, 1.0, 1.0, 0.6333506962918664, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846340689707, 1424439.258289308, 1424439.258289307, 271570.1324316963], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3589200.0000, 
sim time next is 3589800.0000, 
raw observation next is [26.16666666666667, 82.33333333333333, 1.0, 2.0, 0.7545455870126218, 1.0, 2.0, 0.7545455870126218, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 85.675424731087, 1697173.721907816, 1697173.721907816, 313335.317435132], 
processed observation next is [1.0, 0.5652173913043478, 0.825757575757576, 0.8233333333333333, 1.0, 1.0, 0.6931819837657771, 1.0, 1.0, 0.6931819837657771, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5633094536309167, 0.6285828599658577, 0.6285828599658577, 0.7642324815491024], 
reward next is 0.2358, 
noisyNet noise sample is [array([-0.15649411], dtype=float32), 1.4378922]. 
=============================================
[2019-03-23 11:44:45,660] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6000, global step 95807: loss -24.4641
[2019-03-23 11:44:45,661] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6000, global step 95808: learning rate 0.0001
[2019-03-23 11:44:45,721] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6000, global step 95837: loss -60.3936
[2019-03-23 11:44:45,722] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6000, global step 95837: learning rate 0.0001
[2019-03-23 11:44:45,834] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6000, global step 95895: loss 15.3298
[2019-03-23 11:44:45,839] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6000, global step 95896: learning rate 0.0001
[2019-03-23 11:44:45,899] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6000, global step 95927: loss -61.4160
[2019-03-23 11:44:45,900] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6000, global step 95927: learning rate 0.0001
[2019-03-23 11:44:45,952] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6000, global step 95952: loss 2.1132
[2019-03-23 11:44:45,954] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6000, global step 95953: learning rate 0.0001
[2019-03-23 11:44:46,091] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.0708926e-07 9.9999976e-01 9.3118369e-12 1.9175815e-13 1.0151747e-14], sum to 1.0000
[2019-03-23 11:44:46,096] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6401
[2019-03-23 11:44:46,101] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 81.33333333333334, 1.0, 2.0, 0.513613286609984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 585183.8992926861, 585183.8992926861, 144380.2401501382], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3608400.0000, 
sim time next is 3609000.0000, 
raw observation next is [24.0, 80.5, 1.0, 2.0, 0.511056624601659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 582492.4566197668, 582492.4566197668, 143844.4607388041], 
processed observation next is [1.0, 0.782608695652174, 0.7272727272727273, 0.805, 1.0, 1.0, 0.3888207807520737, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21573794689620993, 0.21573794689620993, 0.3508401481434246], 
reward next is 0.6492, 
noisyNet noise sample is [array([-1.0349066], dtype=float32), -0.4477901]. 
=============================================
[2019-03-23 11:44:46,115] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6000, global step 96032: loss -49.5354
[2019-03-23 11:44:46,120] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6000, global step 96033: learning rate 0.0001
[2019-03-23 11:44:46,122] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[32.407997]
 [32.491745]
 [32.48685 ]
 [32.175087]
 [31.99092 ]], R is [[32.67115402]
 [32.99229813]
 [33.30834198]
 [33.61907578]
 [33.92623138]].
[2019-03-23 11:44:46,141] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6000, global step 96046: loss -72.1445
[2019-03-23 11:44:46,143] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6000, global step 96046: learning rate 0.0001
[2019-03-23 11:44:46,179] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6000, global step 96063: loss -27.1197
[2019-03-23 11:44:46,182] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6000, global step 96065: learning rate 0.0001
[2019-03-23 11:44:46,202] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6000, global step 96075: loss -101.2595
[2019-03-23 11:44:46,206] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6000, global step 96076: learning rate 0.0001
[2019-03-23 11:44:46,209] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6000, global step 96078: loss 14.2607
[2019-03-23 11:44:46,212] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6000, global step 96080: learning rate 0.0001
[2019-03-23 11:44:46,416] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6000, global step 96183: loss -4.7912
[2019-03-23 11:44:46,418] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6000, global step 96183: learning rate 0.0001
[2019-03-23 11:44:46,424] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6000, global step 96185: loss 68.3808
[2019-03-23 11:44:46,425] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6000, global step 96185: learning rate 0.0001
[2019-03-23 11:44:46,471] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6000, global step 96212: loss -4.1964
[2019-03-23 11:44:46,474] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6000, global step 96212: learning rate 0.0001
[2019-03-23 11:44:46,699] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6000, global step 96326: loss -73.3687
[2019-03-23 11:44:46,700] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6000, global step 96326: learning rate 0.0001
[2019-03-23 11:44:53,950] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 11:44:53,951] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:44:53,954] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:44:53,954] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:44:53,955] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:44:53,956] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:44:53,957] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:44:53,958] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:44:53,955] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:44:53,959] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:44:53,958] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:44:53,973] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run5
[2019-03-23 11:44:53,997] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run5
[2019-03-23 11:44:54,018] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run5
[2019-03-23 11:44:54,019] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run5
[2019-03-23 11:44:54,019] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run5
[2019-03-23 11:45:58,025] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00936088], dtype=float32), 0.15935113]
[2019-03-23 11:45:58,026] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.38333333333333, 61.5, 1.0, 2.0, 0.3862627269003036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 434596.0135661759, 434596.0135661763, 127595.7108376782]
[2019-03-23 11:45:58,026] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:45:58,030] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.3575491e-12 1.0000000e+00 1.1492608e-21 4.9941563e-23 1.1972670e-24], sampled 0.6257073638493009
[2019-03-23 11:46:09,020] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00936088], dtype=float32), 0.15935113]
[2019-03-23 11:46:09,021] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.36666666666667, 92.5, 1.0, 2.0, 0.2890624873897104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 313856.013528958, 313856.013528958, 110262.9698206058]
[2019-03-23 11:46:09,022] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:46:09,026] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.2324511e-12 1.0000000e+00 9.7044745e-22 4.1684145e-23 9.8692850e-25], sampled 0.9478118187128715
[2019-03-23 11:46:13,399] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00936088], dtype=float32), 0.15935113]
[2019-03-23 11:46:13,401] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.23333333333333, 86.33333333333334, 1.0, 2.0, 0.3652294828525456, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 408228.0259709266, 408228.0259709266, 124473.2781107269]
[2019-03-23 11:46:13,402] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:46:13,404] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.8022443e-12 1.0000000e+00 1.8897218e-21 8.4734996e-23 2.1109423e-24], sampled 0.31959321954986786
[2019-03-23 11:46:31,890] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.3054 1656177539.0774 80.0000
[2019-03-23 11:46:31,951] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:46:32,037] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:46:32,041] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:46:32,129] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:46:33,144] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 100000, evaluation results [100000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9060.305424413044, 1656177539.0773692, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:46:33,939] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.6637610e-09 1.0000000e+00 9.8383519e-17 3.4155128e-17 5.3488502e-19], sum to 1.0000
[2019-03-23 11:46:33,945] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7301
[2019-03-23 11:46:33,950] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 54.0, 1.0, 2.0, 0.6583121702646182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 748368.3572888878, 748368.3572888878, 156495.0823749755], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3762000.0000, 
sim time next is 3762600.0000, 
raw observation next is [25.16666666666667, 58.83333333333333, 1.0, 2.0, 0.7130743068991011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 810870.5004485506, 810870.5004485508, 164032.2808489854], 
processed observation next is [1.0, 0.5652173913043478, 0.7803030303030305, 0.5883333333333333, 1.0, 1.0, 0.6413428836238763, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.30032240757353723, 0.30032240757353734, 0.4000787337780132], 
reward next is 0.5999, 
noisyNet noise sample is [array([-1.1321858], dtype=float32), 0.80862725]. 
=============================================
[2019-03-23 11:46:39,722] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6500, global step 103501: loss 0.3009
[2019-03-23 11:46:39,723] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6500, global step 103501: learning rate 0.0001
[2019-03-23 11:46:39,997] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6500, global step 103653: loss 0.1736
[2019-03-23 11:46:40,001] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6500, global step 103653: learning rate 0.0001
[2019-03-23 11:46:40,258] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6500, global step 103788: loss 0.0557
[2019-03-23 11:46:40,263] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6500, global step 103788: learning rate 0.0001
[2019-03-23 11:46:40,326] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6500, global step 103824: loss 0.0506
[2019-03-23 11:46:40,328] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6500, global step 103824: learning rate 0.0001
[2019-03-23 11:46:40,364] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6500, global step 103841: loss 0.1649
[2019-03-23 11:46:40,365] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6500, global step 103841: learning rate 0.0001
[2019-03-23 11:46:40,583] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6500, global step 103960: loss 0.0925
[2019-03-23 11:46:40,588] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6500, global step 103963: loss 0.0851
[2019-03-23 11:46:40,591] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6500, global step 103963: learning rate 0.0001
[2019-03-23 11:46:40,591] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6500, global step 103963: learning rate 0.0001
[2019-03-23 11:46:40,595] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6500, global step 103964: loss 0.1332
[2019-03-23 11:46:40,598] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6500, global step 103966: learning rate 0.0001
[2019-03-23 11:46:40,770] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6500, global step 104058: loss 0.0106
[2019-03-23 11:46:40,773] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6500, global step 104059: learning rate 0.0001
[2019-03-23 11:46:40,798] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6500, global step 104075: loss 0.0782
[2019-03-23 11:46:40,800] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6500, global step 104075: learning rate 0.0001
[2019-03-23 11:46:40,841] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6500, global step 104096: loss 0.2384
[2019-03-23 11:46:40,845] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6500, global step 104096: learning rate 0.0001
[2019-03-23 11:46:40,899] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6500, global step 104127: loss 0.5323
[2019-03-23 11:46:40,905] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6500, global step 104129: learning rate 0.0001
[2019-03-23 11:46:40,960] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6500, global step 104159: loss 0.1666
[2019-03-23 11:46:40,964] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6500, global step 104159: learning rate 0.0001
[2019-03-23 11:46:40,992] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6500, global step 104176: loss 0.2047
[2019-03-23 11:46:40,992] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6500, global step 104176: learning rate 0.0001
[2019-03-23 11:46:41,253] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6500, global step 104314: loss 0.1811
[2019-03-23 11:46:41,258] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6500, global step 104316: learning rate 0.0001
[2019-03-23 11:46:41,272] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6500, global step 104323: loss 0.1647
[2019-03-23 11:46:41,274] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6500, global step 104323: learning rate 0.0001
[2019-03-23 11:46:48,957] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.6671092e-15 1.0000000e+00 6.8159400e-26 9.4329676e-27 6.4280825e-29], sum to 1.0000
[2019-03-23 11:46:48,966] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2792
[2019-03-23 11:46:48,975] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 100.0, 1.0, 2.0, 0.3041365905473509, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 330248.9375797978, 330248.9375797978, 111471.034827792], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4066200.0000, 
sim time next is 4066800.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.3042378045027081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 330358.87882311, 330358.87882311, 111477.8571030486], 
processed observation next is [1.0, 0.043478260869565216, 0.36363636363636365, 1.0, 1.0, 1.0, 0.1302972556283851, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12235514030485556, 0.12235514030485556, 0.27189721244646003], 
reward next is 0.7281, 
noisyNet noise sample is [array([0.5211991], dtype=float32), 0.33044067]. 
=============================================
[2019-03-23 11:46:51,866] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.1571334e-12 1.0000000e+00 5.7271918e-20 6.6024228e-21 1.4407586e-22], sum to 1.0000
[2019-03-23 11:46:51,876] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1156
[2019-03-23 11:46:51,880] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.8697955568366578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 989368.5760312235, 989368.5760312235, 187568.9011136238], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4120200.0000, 
sim time next is 4120800.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.8789356742713679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 999797.2242921592, 999797.2242921594, 189061.949737734], 
processed observation next is [1.0, 0.6956521739130435, 0.6363636363636364, 0.78, 1.0, 1.0, 0.8486695928392098, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3702952682563553, 0.37029526825635534, 0.46112670667739997], 
reward next is 0.5389, 
noisyNet noise sample is [array([-0.3465947], dtype=float32), -1.0763968]. 
=============================================
[2019-03-23 11:46:53,391] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7206475e-17 1.0000000e+00 1.3127471e-29 3.2508978e-32 7.8359445e-34], sum to 1.0000
[2019-03-23 11:46:53,398] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1223
[2019-03-23 11:46:53,403] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 100.0, 1.0, 2.0, 0.3314010326702816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 366728.5716894891, 366728.5716894894, 115850.7949666023], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4167600.0000, 
sim time next is 4168200.0000, 
raw observation next is [17.0, 100.0, 1.0, 2.0, 0.3314371944791977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 366768.5786116821, 366768.5786116818, 115853.5088023832], 
processed observation next is [1.0, 0.21739130434782608, 0.4090909090909091, 1.0, 1.0, 1.0, 0.16429649309899713, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.135840214300623, 0.1358402143006229, 0.2825695336643493], 
reward next is 0.7174, 
noisyNet noise sample is [array([2.0757601], dtype=float32), 0.4982436]. 
=============================================
[2019-03-23 11:46:54,694] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.8059689e-16 1.0000000e+00 1.8188183e-29 2.7275769e-31 3.5283278e-34], sum to 1.0000
[2019-03-23 11:46:54,703] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2163
[2019-03-23 11:46:54,710] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.3442650793531009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 383067.4905217611, 383067.4905217608, 117689.1246891393], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4175400.0000, 
sim time next is 4176000.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.3449769680634917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 383862.4040474932, 383862.4040474935, 117746.1115391035], 
processed observation next is [1.0, 0.34782608695652173, 0.45454545454545453, 0.94, 1.0, 1.0, 0.18122121007936462, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1421712607583308, 0.14217126075833092, 0.2871856379002524], 
reward next is 0.7128, 
noisyNet noise sample is [array([0.15684506], dtype=float32), -3.1061535]. 
=============================================
[2019-03-23 11:46:54,723] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[79.46    ]
 [79.470985]
 [79.483055]
 [79.497475]
 [79.520195]], R is [[79.39881897]
 [79.31777954]
 [79.23768616]
 [79.15838623]
 [79.0796814 ]].
[2019-03-23 11:46:54,985] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.5124514e-13 1.0000000e+00 4.8496533e-22 5.4546868e-24 1.0105482e-25], sum to 1.0000
[2019-03-23 11:46:54,992] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6009
[2019-03-23 11:46:54,995] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.3436081693543291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 382334.9903288567, 382334.990328857, 117637.0279435347], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4174800.0000, 
sim time next is 4175400.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.3442650793531009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 383067.4905217611, 383067.4905217608, 117689.1246891393], 
processed observation next is [1.0, 0.30434782608695654, 0.45454545454545453, 0.94, 1.0, 1.0, 0.1803313491913761, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.141876848341393, 0.14187684834139289, 0.2870466455832666], 
reward next is 0.7130, 
noisyNet noise sample is [array([1.659441], dtype=float32), -0.14675662]. 
=============================================
[2019-03-23 11:46:55,067] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7000, global step 111472: loss 0.0048
[2019-03-23 11:46:55,069] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7000, global step 111472: learning rate 0.0001
[2019-03-23 11:46:55,347] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7000, global step 111614: loss 0.2292
[2019-03-23 11:46:55,352] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7000, global step 111614: learning rate 0.0001
[2019-03-23 11:46:55,709] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7000, global step 111796: loss 0.0085
[2019-03-23 11:46:55,710] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7000, global step 111796: learning rate 0.0001
[2019-03-23 11:46:55,712] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7000, global step 111797: loss 0.0079
[2019-03-23 11:46:55,715] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7000, global step 111797: learning rate 0.0001
[2019-03-23 11:46:55,796] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7000, global step 111838: loss 0.0235
[2019-03-23 11:46:55,801] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7000, global step 111841: learning rate 0.0001
[2019-03-23 11:46:56,023] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7000, global step 111954: loss 0.0139
[2019-03-23 11:46:56,026] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7000, global step 111954: learning rate 0.0001
[2019-03-23 11:46:56,054] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7000, global step 111969: loss 0.0619
[2019-03-23 11:46:56,056] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7000, global step 111969: learning rate 0.0001
[2019-03-23 11:46:56,074] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7000, global step 111974: loss 0.0690
[2019-03-23 11:46:56,078] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7000, global step 111975: learning rate 0.0001
[2019-03-23 11:46:56,265] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7000, global step 112066: loss 0.0828
[2019-03-23 11:46:56,266] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7000, global step 112066: learning rate 0.0001
[2019-03-23 11:46:56,286] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7000, global step 112080: loss 0.0543
[2019-03-23 11:46:56,289] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7000, global step 112080: learning rate 0.0001
[2019-03-23 11:46:56,320] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7000, global step 112097: loss 0.0592
[2019-03-23 11:46:56,322] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7000, global step 112097: learning rate 0.0001
[2019-03-23 11:46:56,400] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7000, global step 112138: loss 0.1199
[2019-03-23 11:46:56,402] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7000, global step 112138: loss 0.0413
[2019-03-23 11:46:56,403] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7000, global step 112138: learning rate 0.0001
[2019-03-23 11:46:56,406] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7000, global step 112139: learning rate 0.0001
[2019-03-23 11:46:56,409] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7000, global step 112139: loss 0.0757
[2019-03-23 11:46:56,411] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7000, global step 112140: learning rate 0.0001
[2019-03-23 11:46:56,795] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7000, global step 112330: loss 0.2544
[2019-03-23 11:46:56,798] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7000, global step 112331: learning rate 0.0001
[2019-03-23 11:46:56,925] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7000, global step 112394: loss 0.4775
[2019-03-23 11:46:56,928] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7000, global step 112396: learning rate 0.0001
[2019-03-23 11:47:06,347] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.1798426e-14 1.0000000e+00 1.0982167e-25 8.5221482e-25 4.1285091e-28], sum to 1.0000
[2019-03-23 11:47:06,353] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0823
[2019-03-23 11:47:06,357] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 60.33333333333334, 1.0, 2.0, 0.4845356869596271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 552882.4393330797, 552882.4393330797, 139450.8267606012], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4389600.0000, 
sim time next is 4390200.0000, 
raw observation next is [26.5, 61.5, 1.0, 2.0, 0.4845025824972182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 552829.1257278018, 552829.1257278018, 139542.2160406107], 
processed observation next is [1.0, 0.8260869565217391, 0.8409090909090909, 0.615, 1.0, 1.0, 0.3556282281215227, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.204751528047334, 0.204751528047334, 0.34034686839173345], 
reward next is 0.6597, 
noisyNet noise sample is [array([-0.37530738], dtype=float32), 0.23415527]. 
=============================================
[2019-03-23 11:47:06,733] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.0714011e-16 1.0000000e+00 1.7069613e-28 8.1835941e-29 1.4174394e-34], sum to 1.0000
[2019-03-23 11:47:06,741] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8253
[2019-03-23 11:47:06,745] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.25, 87.0, 1.0, 2.0, 0.4405236770481539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 501494.2051504602, 501494.2051504602, 132065.0155441022], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4415400.0000, 
sim time next is 4416000.0000, 
raw observation next is [21.16666666666667, 87.33333333333334, 1.0, 2.0, 0.4383413519814903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 498919.9704351716, 498919.9704351713, 131751.0650106815], 
processed observation next is [0.0, 0.08695652173913043, 0.5984848484848487, 0.8733333333333334, 1.0, 1.0, 0.2979266899768629, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18478517423524876, 0.18478517423524862, 0.3213440610016622], 
reward next is 0.6787, 
noisyNet noise sample is [array([-0.30828178], dtype=float32), 0.79390234]. 
=============================================
[2019-03-23 11:47:06,764] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[74.6436 ]
 [74.66558]
 [74.42091]
 [74.4102 ]
 [74.29865]], R is [[74.52806091]
 [74.46067047]
 [74.39347076]
 [74.3267746 ]
 [74.26053619]].
[2019-03-23 11:47:06,856] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.3716044e-14 1.0000000e+00 1.9019564e-23 2.1523562e-23 9.3036067e-26], sum to 1.0000
[2019-03-23 11:47:06,866] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0803
[2019-03-23 11:47:06,879] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.4340993529323934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 493901.3240725614, 493901.3240725614, 131135.8426489297], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4417200.0000, 
sim time next is 4417800.0000, 
raw observation next is [21.0, 87.16666666666667, 1.0, 2.0, 0.4317958856564903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 491063.2627936656, 491063.2627936656, 130703.5078307502], 
processed observation next is [0.0, 0.13043478260869565, 0.5909090909090909, 0.8716666666666667, 1.0, 1.0, 0.2897448570706128, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18187528251617244, 0.18187528251617244, 0.3187890434896346], 
reward next is 0.6812, 
noisyNet noise sample is [array([1.2394464], dtype=float32), -0.89994115]. 
=============================================
[2019-03-23 11:47:07,813] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.7038453e-18 1.0000000e+00 1.5391760e-31 3.8720108e-32 2.1483964e-36], sum to 1.0000
[2019-03-23 11:47:07,822] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4189
[2019-03-23 11:47:07,826] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 81.66666666666667, 1.0, 2.0, 0.4544456249962053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 518032.8025996123, 518032.802599612, 134341.3759065451], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4407600.0000, 
sim time next is 4408200.0000, 
raw observation next is [22.25, 82.0, 1.0, 2.0, 0.4530928639284997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 516435.3146668026, 516435.3146668029, 134117.2385285512], 
processed observation next is [0.0, 0.0, 0.6477272727272727, 0.82, 1.0, 1.0, 0.31636607991062454, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19127233876548244, 0.19127233876548255, 0.3271152159232956], 
reward next is 0.6729, 
noisyNet noise sample is [array([-0.11676645], dtype=float32), -0.28859568]. 
=============================================
[2019-03-23 11:47:10,049] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.41707168e-16 1.00000000e+00 2.90509849e-30 1.25662355e-29
 1.32303594e-32], sum to 1.0000
[2019-03-23 11:47:10,060] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5153
[2019-03-23 11:47:10,063] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666666, 93.0, 1.0, 2.0, 0.4704352814619768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 536627.0455285223, 536627.0455285223, 136723.1388474938], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4485000.0000, 
sim time next is 4485600.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.4673550172585716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 533070.0422720443, 533070.0422720443, 136287.7890894525], 
processed observation next is [0.0, 0.9565217391304348, 0.5909090909090909, 0.94, 1.0, 1.0, 0.33419377157321445, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19743334898964604, 0.19743334898964604, 0.33240924168159147], 
reward next is 0.6676, 
noisyNet noise sample is [array([0.03409958], dtype=float32), 1.5504283]. 
=============================================
[2019-03-23 11:47:10,819] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7500, global step 119441: loss 0.2169
[2019-03-23 11:47:10,822] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7500, global step 119442: learning rate 0.0001
[2019-03-23 11:47:11,162] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7500, global step 119614: loss 0.4225
[2019-03-23 11:47:11,170] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7500, global step 119614: learning rate 0.0001
[2019-03-23 11:47:11,618] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7500, global step 119839: loss 0.0048
[2019-03-23 11:47:11,621] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7500, global step 119841: learning rate 0.0001
[2019-03-23 11:47:11,650] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7500, global step 119856: loss 0.0031
[2019-03-23 11:47:11,651] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7500, global step 119857: learning rate 0.0001
[2019-03-23 11:47:11,714] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7500, global step 119892: loss 0.0863
[2019-03-23 11:47:11,715] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7500, global step 119892: learning rate 0.0001
[2019-03-23 11:47:11,719] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7500, global step 119893: loss 0.1203
[2019-03-23 11:47:11,723] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7500, global step 119893: learning rate 0.0001
[2019-03-23 11:47:11,758] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7500, global step 119913: loss 0.2972
[2019-03-23 11:47:11,759] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7500, global step 119913: learning rate 0.0001
[2019-03-23 11:47:11,939] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7500, global step 120000: loss 0.0431
[2019-03-23 11:47:11,943] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7500, global step 120001: learning rate 0.0001
[2019-03-23 11:47:12,041] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7500, global step 120055: loss 0.0037
[2019-03-23 11:47:12,044] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7500, global step 120055: learning rate 0.0001
[2019-03-23 11:47:12,058] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7500, global step 120064: loss 0.0273
[2019-03-23 11:47:12,060] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7500, global step 120064: learning rate 0.0001
[2019-03-23 11:47:12,140] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7500, global step 120105: loss 0.0082
[2019-03-23 11:47:12,142] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7500, global step 120105: learning rate 0.0001
[2019-03-23 11:47:12,162] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7500, global step 120119: loss 0.0025
[2019-03-23 11:47:12,164] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7500, global step 120119: learning rate 0.0001
[2019-03-23 11:47:12,190] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7500, global step 120130: loss 0.0038
[2019-03-23 11:47:12,192] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7500, global step 120130: learning rate 0.0001
[2019-03-23 11:47:12,215] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7500, global step 120142: loss 0.0065
[2019-03-23 11:47:12,218] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7500, global step 120142: learning rate 0.0001
[2019-03-23 11:47:12,619] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7500, global step 120347: loss 0.0419
[2019-03-23 11:47:12,623] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7500, global step 120348: learning rate 0.0001
[2019-03-23 11:47:12,736] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7500, global step 120408: loss 0.1267
[2019-03-23 11:47:12,740] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7500, global step 120409: learning rate 0.0001
[2019-03-23 11:47:13,222] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.8788746e-14 1.0000000e+00 2.5586593e-23 5.8891037e-26 4.5301805e-29], sum to 1.0000
[2019-03-23 11:47:13,229] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5590
[2019-03-23 11:47:13,236] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666667, 100.0, 1.0, 2.0, 0.4449557909459974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 507284.966883476, 507284.966883476, 133467.11256976], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4518600.0000, 
sim time next is 4519200.0000, 
raw observation next is [20.33333333333334, 100.0, 1.0, 2.0, 0.4511348534099952, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 514532.581520561, 514532.581520561, 134488.909614847], 
processed observation next is [0.0, 0.30434782608695654, 0.5606060606060609, 1.0, 1.0, 1.0, 0.31391856676249397, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19056762278539296, 0.19056762278539296, 0.3280217307679195], 
reward next is 0.6720, 
noisyNet noise sample is [array([-0.47533917], dtype=float32), -0.2828683]. 
=============================================
[2019-03-23 11:47:21,725] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 11:47:21,733] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:47:21,734] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:47:21,734] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:47:21,735] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:47:21,735] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:47:21,735] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:47:21,736] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:47:21,737] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:47:21,737] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:47:21,737] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:47:21,752] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run6
[2019-03-23 11:47:21,775] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run6
[2019-03-23 11:47:21,776] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run6
[2019-03-23 11:47:21,776] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run6
[2019-03-23 11:47:21,776] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run6
[2019-03-23 11:47:32,130] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00707998], dtype=float32), 0.19370009]
[2019-03-23 11:47:32,130] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.4, 39.0, 1.0, 2.0, 0.35914517481011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 389974.5365941823, 389974.5365941823, 113896.4468124476]
[2019-03-23 11:47:32,132] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:47:32,136] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.5627683e-16 1.0000000e+00 6.8770206e-28 1.6732106e-29 4.9981550e-32], sampled 0.919672205681051
[2019-03-23 11:47:32,486] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00707998], dtype=float32), 0.19370009]
[2019-03-23 11:47:32,488] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.74136460333333, 59.25267791333334, 1.0, 2.0, 0.4498032662313232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 510654.4039363546, 510654.4039363543, 136138.0304645518]
[2019-03-23 11:47:32,490] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:47:32,494] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0268545e-16 1.0000000e+00 7.7906900e-29 1.6651423e-30 4.0733862e-33], sampled 0.5798453870995446
[2019-03-23 11:47:44,265] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00707998], dtype=float32), 0.19370009]
[2019-03-23 11:47:44,266] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.7273031, 76.68091170333334, 1.0, 2.0, 0.506161677703425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 576763.2209889152, 576763.2209889152, 147657.2814111022]
[2019-03-23 11:47:44,266] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:47:44,273] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.4493360e-17 1.0000000e+00 1.8019401e-29 3.5301238e-31 7.5501410e-34], sampled 0.00713238572492747
[2019-03-23 11:47:50,281] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00707998], dtype=float32), 0.19370009]
[2019-03-23 11:47:50,281] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.0, 47.0, 1.0, 2.0, 0.3242633875697808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 355450.8836410832, 355450.8836410832, 114022.2398691853]
[2019-03-23 11:47:50,284] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:47:50,289] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.9166539e-16 1.0000000e+00 8.1172805e-28 1.9945049e-29 6.0494754e-32], sampled 0.2600299709301356
[2019-03-23 11:47:51,421] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00707998], dtype=float32), 0.19370009]
[2019-03-23 11:47:51,425] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.94830657666667, 55.76465285666667, 1.0, 2.0, 0.280975910930619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 305073.6051694399, 305073.6051694399, 103839.4432486411]
[2019-03-23 11:47:51,427] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:47:51,429] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.7158314e-17 1.0000000e+00 5.8472124e-29 1.2285861e-30 2.9274210e-33], sampled 0.5339255087834003
[2019-03-23 11:48:06,221] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00707998], dtype=float32), 0.19370009]
[2019-03-23 11:48:06,223] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.93136987, 59.48596792, 1.0, 2.0, 0.4266898388696442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 486179.132057793, 486179.132057793, 135555.4782168752]
[2019-03-23 11:48:06,224] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:48:06,229] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.2993310e-16 1.0000000e+00 3.1949170e-28 7.4266401e-30 2.0679103e-32], sampled 0.13597614585746254
[2019-03-23 11:48:27,394] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00707998], dtype=float32), 0.19370009]
[2019-03-23 11:48:27,398] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.73565769666667, 86.53932366000001, 1.0, 2.0, 0.293903515830457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 319113.6631007245, 319113.6631007241, 105481.1419693577]
[2019-03-23 11:48:27,399] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:48:27,402] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.2510978e-16 1.0000000e+00 1.1009624e-28 2.4019704e-30 6.0656706e-33], sampled 0.48668638572659395
[2019-03-23 11:48:28,299] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00707998], dtype=float32), 0.19370009]
[2019-03-23 11:48:28,300] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [13.16666666666667, 83.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 202269.7912202446, 202269.7912202443, 72257.08849243847]
[2019-03-23 11:48:28,302] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:48:28,305] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.5607166e-16 1.0000000e+00 6.8707012e-28 1.6714243e-29 4.9930856e-32], sampled 0.24636335726833214
[2019-03-23 11:48:29,581] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00707998], dtype=float32), 0.19370009]
[2019-03-23 11:48:29,582] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 83.0, 1.0, 2.0, 0.4008717954692299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 454270.1694618324, 454270.1694618324, 126433.6641347211]
[2019-03-23 11:48:29,584] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:48:29,586] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.7534614e-16 1.0000000e+00 4.3804646e-28 1.0374785e-29 2.9739425e-32], sampled 0.5095383614470403
[2019-03-23 11:48:40,304] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00707998], dtype=float32), 0.19370009]
[2019-03-23 11:48:40,305] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.97383935666667, 48.47678751166667, 1.0, 2.0, 0.5463162842879307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 605436.9928922458, 605436.9928922454, 139460.8532235795]
[2019-03-23 11:48:40,306] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:48:40,308] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.9055338e-16 1.0000000e+00 1.6658628e-27 4.2719759e-29 1.3839993e-31], sampled 0.6421588351690709
[2019-03-23 11:48:43,990] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00707998], dtype=float32), 0.19370009]
[2019-03-23 11:48:43,993] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.6, 87.5, 1.0, 2.0, 0.3755366263106835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 422463.6666762095, 422463.6666762095, 126629.1009310414]
[2019-03-23 11:48:43,995] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:48:43,998] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.8283364e-17 1.0000000e+00 7.2157174e-29 1.5352186e-30 3.7293752e-33], sampled 0.7191025026219451
[2019-03-23 11:48:48,637] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00707998], dtype=float32), 0.19370009]
[2019-03-23 11:48:48,638] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.64814560333333, 58.47642702, 1.0, 2.0, 0.42754829432888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 486658.0367881517, 486658.0367881514, 135047.8422378886]
[2019-03-23 11:48:48,640] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:48:48,643] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.7117952e-17 1.0000000e+00 7.0663880e-29 1.5015558e-30 3.6407058e-33], sampled 0.0652305779430159
[2019-03-23 11:48:59,466] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:48:59,533] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:48:59,628] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:48:59,788] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:48:59,849] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:49:00,862] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 125000, evaluation results [125000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:49:05,885] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8000, global step 127397: loss 0.3490
[2019-03-23 11:49:05,889] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8000, global step 127399: learning rate 0.0001
[2019-03-23 11:49:06,190] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8000, global step 127560: loss 0.2384
[2019-03-23 11:49:06,192] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8000, global step 127561: learning rate 0.0001
[2019-03-23 11:49:06,552] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8000, global step 127752: loss 0.1897
[2019-03-23 11:49:06,554] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8000, global step 127752: learning rate 0.0001
[2019-03-23 11:49:06,619] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8000, global step 127790: loss 0.3468
[2019-03-23 11:49:06,621] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8000, global step 127790: learning rate 0.0001
[2019-03-23 11:49:06,790] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8000, global step 127881: loss 0.4385
[2019-03-23 11:49:06,793] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8000, global step 127881: learning rate 0.0001
[2019-03-23 11:49:06,830] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8000, global step 127899: loss 0.3842
[2019-03-23 11:49:06,833] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8000, global step 127900: learning rate 0.0001
[2019-03-23 11:49:06,908] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8000, global step 127940: loss 0.2735
[2019-03-23 11:49:06,910] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8000, global step 127940: learning rate 0.0001
[2019-03-23 11:49:06,944] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8000, global step 127959: loss 0.2419
[2019-03-23 11:49:06,950] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8000, global step 127959: learning rate 0.0001
[2019-03-23 11:49:07,013] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8000, global step 127995: loss 0.2921
[2019-03-23 11:49:07,014] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8000, global step 127995: learning rate 0.0001
[2019-03-23 11:49:07,197] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8000, global step 128090: loss 0.3367
[2019-03-23 11:49:07,201] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8000, global step 128090: learning rate 0.0001
[2019-03-23 11:49:07,290] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8000, global step 128146: loss 0.6601
[2019-03-23 11:49:07,291] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8000, global step 128146: learning rate 0.0001
[2019-03-23 11:49:07,317] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8000, global step 128156: loss 0.5552
[2019-03-23 11:49:07,319] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8000, global step 128157: learning rate 0.0001
[2019-03-23 11:49:07,372] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8000, global step 128188: loss 0.7024
[2019-03-23 11:49:07,374] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8000, global step 128188: learning rate 0.0001
[2019-03-23 11:49:07,379] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8000, global step 128189: loss 0.7076
[2019-03-23 11:49:07,382] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8000, global step 128189: learning rate 0.0001
[2019-03-23 11:49:07,526] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8000, global step 128268: loss 0.5227
[2019-03-23 11:49:07,531] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8000, global step 128269: learning rate 0.0001
[2019-03-23 11:49:07,894] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8000, global step 128459: loss 0.2281
[2019-03-23 11:49:07,896] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8000, global step 128459: learning rate 0.0001
[2019-03-23 11:49:08,945] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.0600931e-17 1.0000000e+00 7.0954452e-31 2.6294654e-32 2.3155586e-34], sum to 1.0000
[2019-03-23 11:49:08,959] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2657
[2019-03-23 11:49:08,963] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 98.0, 1.0, 2.0, 0.4113908412388902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 466765.4732648921, 466765.4732648921, 127820.1312528129], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4855200.0000, 
sim time next is 4855800.0000, 
raw observation next is [19.16666666666667, 99.0, 1.0, 2.0, 0.4087508347989057, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 463591.7428906097, 463591.7428906097, 127441.2571388826], 
processed observation next is [1.0, 0.17391304347826086, 0.5075757575757578, 0.99, 1.0, 1.0, 0.2609385434986321, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17170064551504063, 0.17170064551504063, 0.3108323344850795], 
reward next is 0.6892, 
noisyNet noise sample is [array([0.28446326], dtype=float32), 0.007611863]. 
=============================================
[2019-03-23 11:49:09,413] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6871895e-14 1.0000000e+00 7.1753827e-25 2.4343795e-27 6.8908788e-30], sum to 1.0000
[2019-03-23 11:49:09,420] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0578
[2019-03-23 11:49:09,427] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.4465983224959968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 508982.5113048792, 508982.5113048792, 133370.5940832774], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4839600.0000, 
sim time next is 4840200.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.4463494094944667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 508698.4964272336, 508698.4964272336, 133344.4221603242], 
processed observation next is [1.0, 0.0, 0.5454545454545454, 1.0, 1.0, 1.0, 0.3079367618680834, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18840685052860504, 0.18840685052860504, 0.32523029795201025], 
reward next is 0.6748, 
noisyNet noise sample is [array([2.105248], dtype=float32), -0.683377]. 
=============================================
[2019-03-23 11:49:21,122] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8500, global step 135406: loss 3.5041
[2019-03-23 11:49:21,124] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8500, global step 135406: learning rate 0.0001
[2019-03-23 11:49:21,548] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8500, global step 135621: loss 0.5969
[2019-03-23 11:49:21,549] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8500, global step 135621: learning rate 0.0001
[2019-03-23 11:49:21,802] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8500, global step 135756: loss 3.1095
[2019-03-23 11:49:21,804] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8500, global step 135757: learning rate 0.0001
[2019-03-23 11:49:21,996] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8500, global step 135855: loss 0.5789
[2019-03-23 11:49:22,001] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8500, global step 135857: learning rate 0.0001
[2019-03-23 11:49:22,028] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8500, global step 135870: loss 0.4491
[2019-03-23 11:49:22,032] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8500, global step 135870: learning rate 0.0001
[2019-03-23 11:49:22,085] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8500, global step 135896: loss 0.2241
[2019-03-23 11:49:22,087] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8500, global step 135897: learning rate 0.0001
[2019-03-23 11:49:22,159] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8500, global step 135935: loss 0.4419
[2019-03-23 11:49:22,161] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8500, global step 135935: learning rate 0.0001
[2019-03-23 11:49:22,165] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.7769295e-15 1.0000000e+00 1.6695280e-26 1.7885730e-28 3.0996893e-30], sum to 1.0000
[2019-03-23 11:49:22,166] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8500, global step 135938: loss 0.5904
[2019-03-23 11:49:22,169] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7454
[2019-03-23 11:49:22,175] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 81.33333333333334, 1.0, 2.0, 0.4103941334009406, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 465536.6970702289, 465536.6970702286, 127654.4986564508], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5102400.0000, 
sim time next is 5103000.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.4082475437943741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 462748.6425164032, 462748.6425164029, 127203.8899701548], 
processed observation next is [0.0, 0.043478260869565216, 0.5909090909090909, 0.83, 1.0, 1.0, 0.2603094297429676, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17138838611718638, 0.17138838611718626, 0.3102533901711093], 
reward next is 0.6897, 
noisyNet noise sample is [array([0.786863], dtype=float32), -1.2320398]. 
=============================================
[2019-03-23 11:49:22,177] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8500, global step 135942: learning rate 0.0001
[2019-03-23 11:49:22,210] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[63.893276]
 [63.926514]
 [63.930264]
 [63.913742]
 [63.89685 ]], R is [[64.01434326]
 [64.06284332]
 [64.10932159]
 [64.15441895]
 [64.19952393]].
[2019-03-23 11:49:22,282] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8500, global step 135995: loss 1.4879
[2019-03-23 11:49:22,284] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8500, global step 135995: learning rate 0.0001
[2019-03-23 11:49:22,541] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8500, global step 136126: loss 2.4028
[2019-03-23 11:49:22,543] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8500, global step 136127: learning rate 0.0001
[2019-03-23 11:49:22,560] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8500, global step 136134: loss 2.0770
[2019-03-23 11:49:22,562] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8500, global step 136135: learning rate 0.0001
[2019-03-23 11:49:22,590] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8500, global step 136149: loss 1.5164
[2019-03-23 11:49:22,592] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8500, global step 136151: learning rate 0.0001
[2019-03-23 11:49:22,684] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8500, global step 136200: loss 0.5829
[2019-03-23 11:49:22,688] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8500, global step 136202: learning rate 0.0001
[2019-03-23 11:49:22,708] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8500, global step 136210: loss 0.3406
[2019-03-23 11:49:22,712] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8500, global step 136212: learning rate 0.0001
[2019-03-23 11:49:22,831] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8500, global step 136277: loss 0.2969
[2019-03-23 11:49:22,833] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8500, global step 136277: learning rate 0.0001
[2019-03-23 11:49:23,268] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8500, global step 136494: loss 2.0159
[2019-03-23 11:49:23,269] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8500, global step 136495: learning rate 0.0001
[2019-03-23 11:49:30,346] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.3866077e-14 1.0000000e+00 1.4130696e-22 1.4406127e-26 1.2456381e-27], sum to 1.0000
[2019-03-23 11:49:30,351] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0206
[2019-03-23 11:49:30,356] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5070057466879804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 578208.8670959835, 578208.8670959832, 142916.7012955421], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5255400.0000, 
sim time next is 5256000.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5044632631784157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 575308.1216672318, 575308.1216672318, 142616.198997969], 
processed observation next is [1.0, 0.8695652173913043, 0.6363636363636364, 0.94, 1.0, 1.0, 0.3805790789730196, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21307708209897475, 0.21307708209897475, 0.34784438779992444], 
reward next is 0.6522, 
noisyNet noise sample is [array([-1.6544291], dtype=float32), 0.5102715]. 
=============================================
[2019-03-23 11:49:30,374] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[65.07378 ]
 [65.236694]
 [65.42186 ]
 [65.19153 ]
 [65.21834 ]], R is [[65.00708008]
 [65.00843048]
 [65.00959015]
 [65.0118103 ]
 [65.01478577]].
[2019-03-23 11:49:30,837] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.8766703e-15 1.0000000e+00 3.1603822e-28 4.6122777e-28 5.1150484e-30], sum to 1.0000
[2019-03-23 11:49:30,847] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5453
[2019-03-23 11:49:30,851] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.4983138278518979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 568293.8817134199, 568293.8817134203, 141890.6967340062], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5258400.0000, 
sim time next is 5259000.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.4986130123203537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 568635.3628136634, 568635.3628136634, 141925.4996756264], 
processed observation next is [1.0, 0.8695652173913043, 0.6363636363636364, 0.94, 1.0, 1.0, 0.3732662654004421, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21060568993098647, 0.21060568993098647, 0.34615975530640586], 
reward next is 0.6538, 
noisyNet noise sample is [array([-0.6540216], dtype=float32), 0.07142908]. 
=============================================
[2019-03-23 11:49:30,864] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[66.62386]
 [66.76034]
 [66.96928]
 [67.04966]
 [67.13462]], R is [[66.72679901]
 [66.7134552 ]
 [66.7000351 ]
 [66.68635559]
 [66.67223358]].
[2019-03-23 11:49:31,323] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3542826e-12 1.0000000e+00 3.1868702e-21 7.4160539e-22 1.3464362e-25], sum to 1.0000
[2019-03-23 11:49:31,330] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9644
[2019-03-23 11:49:31,335] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.91666666666667, 95.0, 1.0, 2.0, 0.499887806152467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 570051.3910742293, 570051.3910742295, 142135.8116814718], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5260200.0000, 
sim time next is 5260800.0000, 
raw observation next is [21.83333333333334, 96.0, 1.0, 2.0, 0.4998769642112281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 569987.0119567572, 569987.0119567572, 142211.7342958284], 
processed observation next is [1.0, 0.9130434782608695, 0.628787878787879, 0.96, 1.0, 1.0, 0.3748462052640351, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2111063007247249, 0.2111063007247249, 0.34685788852641075], 
reward next is 0.6531, 
noisyNet noise sample is [array([0.00022925], dtype=float32), -0.21837276]. 
=============================================
[2019-03-23 11:49:33,487] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4766443e-08 1.0000000e+00 3.6240956e-16 1.1708719e-16 3.0315789e-18], sum to 1.0000
[2019-03-23 11:49:33,490] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9754
[2019-03-23 11:49:33,498] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.78333333333333, 53.5, 1.0, 2.0, 0.896932698982629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1022702.505068204, 1022702.505068204, 194633.6948404275], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5307000.0000, 
sim time next is 5307600.0000, 
raw observation next is [26.96666666666667, 53.00000000000001, 1.0, 2.0, 0.8989371918350801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1025248.881073862, 1025248.881073862, 195359.4487894828], 
processed observation next is [1.0, 0.43478260869565216, 0.8621212121212122, 0.53, 1.0, 1.0, 0.8736714897938502, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.37972180780513404, 0.37972180780513404, 0.47648646046215315], 
reward next is 0.5235, 
noisyNet noise sample is [array([2.6924458], dtype=float32), -1.5367793]. 
=============================================
[2019-03-23 11:49:35,883] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3238819e-13 1.0000000e+00 4.4455369e-24 2.1672066e-27 8.1104704e-28], sum to 1.0000
[2019-03-23 11:49:35,884] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3206
[2019-03-23 11:49:35,889] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.73333333333333, 56.66666666666667, 1.0, 2.0, 0.4220159346560499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 479832.641665652, 479832.641665652, 129641.4642792418], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5347200.0000, 
sim time next is 5347800.0000, 
raw observation next is [25.55, 58.0, 1.0, 2.0, 0.4266002193183771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 485204.5014636535, 485204.5014636535, 130234.9462516586], 
processed observation next is [1.0, 0.9130434782608695, 0.7977272727272727, 0.58, 1.0, 1.0, 0.2832502741479713, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17970537091246427, 0.17970537091246427, 0.31764621036989904], 
reward next is 0.6824, 
noisyNet noise sample is [array([2.194403], dtype=float32), 0.5460652]. 
=============================================
[2019-03-23 11:49:36,438] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.5775814e-19 1.0000000e+00 4.5398487e-30 9.9679120e-35 4.6164462e-37], sum to 1.0000
[2019-03-23 11:49:36,446] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9930
[2019-03-23 11:49:36,449] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.63333333333334, 75.66666666666667, 1.0, 2.0, 0.4628868659906479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 528084.7556871596, 528084.7556871596, 136114.5039508115], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5358000.0000, 
sim time next is 5358600.0000, 
raw observation next is [23.55, 76.5, 1.0, 2.0, 0.464270119473538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 529687.6927173632, 529687.6927173632, 136349.0626534324], 
processed observation next is [1.0, 0.0, 0.7068181818181819, 0.765, 1.0, 1.0, 0.3303376493419225, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19618062693235674, 0.19618062693235674, 0.3325586893986156], 
reward next is 0.6674, 
noisyNet noise sample is [array([1.8894016], dtype=float32), 0.73215806]. 
=============================================
[2019-03-23 11:49:36,967] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9000, global step 143445: loss 58.5017
[2019-03-23 11:49:36,971] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9000, global step 143446: learning rate 0.0001
[2019-03-23 11:49:37,532] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9000, global step 143728: loss 16.4889
[2019-03-23 11:49:37,534] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9000, global step 143728: learning rate 0.0001
[2019-03-23 11:49:37,700] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9000, global step 143811: loss 10.8950
[2019-03-23 11:49:37,701] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9000, global step 143811: learning rate 0.0001
[2019-03-23 11:49:37,791] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9000, global step 143858: loss 13.9413
[2019-03-23 11:49:37,795] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9000, global step 143858: learning rate 0.0001
[2019-03-23 11:49:37,836] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9000, global step 143883: loss -0.0044
[2019-03-23 11:49:37,839] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9000, global step 143884: learning rate 0.0001
[2019-03-23 11:49:37,874] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9000, global step 143897: loss 50.6714
[2019-03-23 11:49:37,877] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9000, global step 143897: learning rate 0.0001
[2019-03-23 11:49:38,014] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9000, global step 143968: loss 28.6262
[2019-03-23 11:49:38,017] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9000, global step 143970: loss 112.5447
[2019-03-23 11:49:38,019] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9000, global step 143971: learning rate 0.0001
[2019-03-23 11:49:38,019] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9000, global step 143970: learning rate 0.0001
[2019-03-23 11:49:38,058] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9000, global step 143985: loss 83.4634
[2019-03-23 11:49:38,060] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9000, global step 143986: learning rate 0.0001
[2019-03-23 11:49:38,216] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9000, global step 144064: loss -21.4250
[2019-03-23 11:49:38,218] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9000, global step 144065: learning rate 0.0001
[2019-03-23 11:49:38,232] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9000, global step 144075: loss 48.2608
[2019-03-23 11:49:38,234] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9000, global step 144076: learning rate 0.0001
[2019-03-23 11:49:38,316] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9000, global step 144117: loss -2.5271
[2019-03-23 11:49:38,318] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9000, global step 144117: learning rate 0.0001
[2019-03-23 11:49:38,460] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9000, global step 144188: loss -1.4229
[2019-03-23 11:49:38,463] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9000, global step 144188: learning rate 0.0001
[2019-03-23 11:49:38,481] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9000, global step 144200: loss -17.5854
[2019-03-23 11:49:38,483] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9000, global step 144200: learning rate 0.0001
[2019-03-23 11:49:38,599] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9000, global step 144258: loss 33.6965
[2019-03-23 11:49:38,604] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9000, global step 144258: learning rate 0.0001
[2019-03-23 11:49:38,976] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9000, global step 144442: loss 77.1037
[2019-03-23 11:49:38,981] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9000, global step 144443: learning rate 0.0001
[2019-03-23 11:49:41,902] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.3713600e-16 1.0000000e+00 3.9649020e-27 5.1183393e-33 1.4851124e-34], sum to 1.0000
[2019-03-23 11:49:41,912] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8482
[2019-03-23 11:49:41,917] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.11666666666667, 91.0, 1.0, 2.0, 0.3498332119065929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 387883.0020734861, 387883.0020734858, 117557.9158269835], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5471400.0000, 
sim time next is 5472000.0000, 
raw observation next is [18.3, 90.0, 1.0, 2.0, 0.3518719904549857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 390549.6181792854, 390549.6181792854, 117881.4385890013], 
processed observation next is [1.0, 0.34782608695652173, 0.4681818181818182, 0.9, 1.0, 1.0, 0.1898399880687321, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14464800673306866, 0.14464800673306866, 0.2875157038756129], 
reward next is 0.7125, 
noisyNet noise sample is [array([1.6466357], dtype=float32), -0.46530056]. 
=============================================
[2019-03-23 11:49:41,930] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[82.87226 ]
 [82.912254]
 [82.96258 ]
 [83.03814 ]
 [83.07983 ]], R is [[82.75      ]
 [82.63577271]
 [82.52272034]
 [82.41105652]
 [82.3032074 ]].
[2019-03-23 11:49:49,970] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 11:49:49,975] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:49:49,975] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:49:49,976] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:49:49,977] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:49:49,977] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:49:49,978] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:49:49,978] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:49:49,978] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:49:49,979] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:49:49,980] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:49:49,989] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run7
[2019-03-23 11:49:50,013] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run7
[2019-03-23 11:49:50,014] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run7
[2019-03-23 11:49:50,014] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run7
[2019-03-23 11:49:50,102] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run7
[2019-03-23 11:50:04,100] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00758947], dtype=float32), 0.21266645]
[2019-03-23 11:50:04,101] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.4, 55.33333333333334, 1.0, 2.0, 0.4749951439852958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 541009.7589657119, 541009.7589657116, 140312.4315447479]
[2019-03-23 11:50:04,103] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:50:04,106] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.5956365e-17 1.0000000e+00 1.9096758e-32 1.0799412e-33 4.4315963e-34], sampled 0.662697915672278
[2019-03-23 11:50:31,969] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00758947], dtype=float32), 0.21266645]
[2019-03-23 11:50:31,970] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.1, 90.0, 1.0, 2.0, 0.4498767675670855, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 512528.3401119078, 512528.3401119078, 137829.7673547925]
[2019-03-23 11:50:31,972] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:50:31,977] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.9347670e-18 1.0000000e+00 3.5920759e-34 1.7340542e-35 6.8108892e-36], sampled 0.29379905215572966
[2019-03-23 11:50:53,865] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00758947], dtype=float32), 0.21266645]
[2019-03-23 11:50:53,866] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.13333333333333, 68.33333333333334, 1.0, 2.0, 0.3092249980302955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 337501.2568339973, 337501.2568339969, 116735.6391604913]
[2019-03-23 11:50:53,867] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:50:53,869] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0860643e-17 1.0000000e+00 9.2542659e-33 5.0844566e-34 2.0697707e-34], sampled 0.9164259350666892
[2019-03-23 11:51:28,232] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:51:28,329] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:51:28,503] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:51:28,619] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:51:28,781] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:51:29,793] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 150000, evaluation results [150000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:51:32,490] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9500, global step 151434: loss 5.5891
[2019-03-23 11:51:32,492] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9500, global step 151434: learning rate 0.0001
[2019-03-23 11:51:32,984] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9500, global step 151699: loss 7.1821
[2019-03-23 11:51:32,985] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9500, global step 151699: learning rate 0.0001
[2019-03-23 11:51:33,103] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9500, global step 151767: loss 5.1080
[2019-03-23 11:51:33,106] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9500, global step 151769: learning rate 0.0001
[2019-03-23 11:51:33,120] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9500, global step 151771: loss 4.5769
[2019-03-23 11:51:33,121] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9500, global step 151773: learning rate 0.0001
[2019-03-23 11:51:33,265] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9500, global step 151853: loss 4.2999
[2019-03-23 11:51:33,268] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9500, global step 151854: learning rate 0.0001
[2019-03-23 11:51:33,321] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9500, global step 151885: loss 4.2301
[2019-03-23 11:51:33,323] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9500, global step 151885: learning rate 0.0001
[2019-03-23 11:51:33,332] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9500, global step 151890: loss 4.5371
[2019-03-23 11:51:33,333] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9500, global step 151890: learning rate 0.0001
[2019-03-23 11:51:33,506] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9500, global step 151983: loss 3.2490
[2019-03-23 11:51:33,507] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9500, global step 151984: learning rate 0.0001
[2019-03-23 11:51:33,613] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9500, global step 152040: loss 2.6613
[2019-03-23 11:51:33,615] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9500, global step 152042: learning rate 0.0001
[2019-03-23 11:51:33,667] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9500, global step 152066: loss 2.0106
[2019-03-23 11:51:33,668] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9500, global step 152066: loss 2.1339
[2019-03-23 11:51:33,670] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9500, global step 152067: loss 1.9404
[2019-03-23 11:51:33,671] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9500, global step 152066: learning rate 0.0001
[2019-03-23 11:51:33,671] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9500, global step 152067: learning rate 0.0001
[2019-03-23 11:51:33,672] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9500, global step 152067: learning rate 0.0001
[2019-03-23 11:51:33,967] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9500, global step 152223: loss 0.8100
[2019-03-23 11:51:33,972] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9500, global step 152223: learning rate 0.0001
[2019-03-23 11:51:34,030] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9500, global step 152256: loss 0.5880
[2019-03-23 11:51:34,033] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9500, global step 152257: learning rate 0.0001
[2019-03-23 11:51:34,199] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9500, global step 152346: loss 0.2627
[2019-03-23 11:51:34,202] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9500, global step 152347: learning rate 0.0001
[2019-03-23 11:51:34,367] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9500, global step 152436: loss 0.0716
[2019-03-23 11:51:34,369] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9500, global step 152436: learning rate 0.0001
[2019-03-23 11:51:34,550] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.27537945 0.5813109  0.0598953  0.04157273 0.04184161], sum to 1.0000
[2019-03-23 11:51:34,559] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1302
[2019-03-23 11:51:34,567] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [9.3, 86.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 137354.0834759081, 137354.0834759079, 56202.38852093634], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5717400.0000, 
sim time next is 5718000.0000, 
raw observation next is [9.200000000000001, 87.33333333333334, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 135966.7805900245, 135966.7805900248, 51213.11188836491], 
processed observation next is [0.0, 0.17391304347826086, 0.05454545454545459, 0.8733333333333334, 0.0, 0.5, -0.25, 0.0, 1.0, -0.25, 1.0, 0.5, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.05035806688519425, 0.05035806688519437, 0.12491002899601197], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4501928], dtype=float32), 0.020207558]. 
=============================================
[2019-03-23 11:51:34,585] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[2.3909764]
 [2.3919716]
 [2.3823175]
 [2.3861258]
 [2.3814652]], R is [[2.37000585]
 [2.34630585]
 [2.32284284]
 [2.29961443]
 [2.27661824]].
[2019-03-23 11:51:34,924] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.31005415 0.20954826 0.17075947 0.18316281 0.1264753 ], sum to 1.0000
[2019-03-23 11:51:34,930] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2556
[2019-03-23 11:51:34,934] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [12.2, 80.0, 1.0, 2.0, 0.2, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 163820.7053053275, 163820.7053053272, 59662.60721634487], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5729400.0000, 
sim time next is 5730000.0000, 
raw observation next is [12.56666666666667, 78.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.3, 6.911199999999998, 6.9112, 77.32846344354104, 168400.6886329084, 168400.688632909, 56986.85721026514], 
processed observation next is [0.0, 0.30434782608695654, 0.20757575757575772, 0.78, 0.0, 0.5, -0.25, 0.0, 1.0, -0.25, 1.0, 0.5, 0.0, -1.7763568394002506e-16, 0.0, 0.5084288129206541, 0.062370625419595704, 0.062370625419595926, 0.13899233465918326], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4443575], dtype=float32), 0.14128242]. 
=============================================
[2019-03-23 11:51:34,958] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[0.3816656 ]
 [0.38392502]
 [0.37470132]
 [0.36916178]
 [0.37323183]], R is [[0.37636277]
 [0.37259915]
 [0.36887318]
 [0.36518446]
 [0.36153263]].
[2019-03-23 11:51:40,022] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.3778533e-06 9.9999261e-01 8.5455822e-34 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 11:51:40,031] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7287
[2019-03-23 11:51:40,038] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 48.33333333333334, 1.0, 2.0, 0.6032294596013342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 670963.5265534905, 670963.5265534905, 142041.4135312706], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5836800.0000, 
sim time next is 5837400.0000, 
raw observation next is [24.7, 47.5, 1.0, 2.0, 0.6520703537331443, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 725168.6660324025, 725168.6660324022, 147530.5443005158], 
processed observation next is [1.0, 0.5652173913043478, 0.759090909090909, 0.475, 1.0, 1.0, 0.5650879421664303, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.26858098741940833, 0.2685809874194082, 0.35983059585491656], 
reward next is 0.6402, 
noisyNet noise sample is [array([0.28693223], dtype=float32), 0.031755824]. 
=============================================
[2019-03-23 11:51:41,661] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.2376934e-06 9.9999273e-01 3.9078244e-29 8.3436773e-34 3.8065147e-34], sum to 1.0000
[2019-03-23 11:51:41,662] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4358
[2019-03-23 11:51:41,666] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 66.0, 1.0, 2.0, 0.3303556551985043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 364612.2633612806, 364612.2633612808, 115393.4737466515], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5868000.0000, 
sim time next is 5868600.0000, 
raw observation next is [20.91666666666667, 67.16666666666667, 1.0, 2.0, 0.3294337115545268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 363515.7680855169, 363515.7680855169, 115294.391266781], 
processed observation next is [1.0, 0.9565217391304348, 0.5871212121212124, 0.6716666666666667, 1.0, 1.0, 0.16179213944315846, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13463546966130255, 0.13463546966130255, 0.2812058323580024], 
reward next is 0.7188, 
noisyNet noise sample is [array([-0.56134415], dtype=float32), -0.43356094]. 
=============================================
[2019-03-23 11:51:44,069] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.6424162e-07 9.9999905e-01 2.8803088e-32 7.8330261e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 11:51:44,075] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5945
[2019-03-23 11:51:44,079] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 78.0, 1.0, 2.0, 0.2751438139095884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 298757.2491657132, 298757.2491657132, 103332.1416403499], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5902200.0000, 
sim time next is 5902800.0000, 
raw observation next is [18.26666666666667, 77.33333333333334, 1.0, 2.0, 0.2832275259413657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 307537.4981042835, 307537.4981042838, 108018.1155877664], 
processed observation next is [1.0, 0.30434782608695654, 0.4666666666666668, 0.7733333333333334, 1.0, 1.0, 0.1040344074267071, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11390277707566057, 0.11390277707566067, 0.2634588185067473], 
reward next is 0.7365, 
noisyNet noise sample is [array([-0.07594422], dtype=float32), -0.19141422]. 
=============================================
[2019-03-23 11:51:44,752] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.4728289e-06 9.9999654e-01 1.2908219e-24 9.5488579e-28 2.6450842e-29], sum to 1.0000
[2019-03-23 11:51:44,760] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9162
[2019-03-23 11:51:44,771] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1145000.812343945 W.
[2019-03-23 11:51:44,775] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.2, 47.0, 1.0, 2.0, 0.5237758563944857, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9485897608587345, 6.935836118183973, 6.9112, 77.32840300721818, 1145000.812343945, 1136999.511306998, 250747.3681206855], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5936400.0000, 
sim time next is 5937000.0000, 
raw observation next is [27.2, 47.00000000000001, 1.0, 2.0, 0.2939634012575515, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5863414208206904, 6.911199999999999, 6.9112, 77.32844863949063, 668645.3807451001, 668645.3807451004, 183443.6571766646], 
processed observation next is [1.0, 0.7391304347826086, 0.8727272727272727, 0.4700000000000001, 1.0, 1.0, 0.11745425157193935, 0.0, 1.0, -0.25, 1.0, 1.0, 0.40905917260098634, -8.881784197001253e-17, 0.0, 0.5084287155851396, 0.24764643731300004, 0.24764643731300015, 0.44742355408942586], 
reward next is 0.5526, 
noisyNet noise sample is [array([-0.9629156], dtype=float32), -0.7944119]. 
=============================================
[2019-03-23 11:51:44,795] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[62.399807]
 [62.240925]
 [61.814285]
 [61.248875]
 [61.30035 ]], R is [[64.26934052]
 [63.89188766]
 [63.69815826]
 [63.49722672]
 [63.29096222]].
[2019-03-23 11:51:44,817] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.6465303e-04 9.9923539e-01 1.0782121e-22 3.5836541e-25 4.1187836e-26], sum to 1.0000
[2019-03-23 11:51:44,824] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8655
[2019-03-23 11:51:44,997] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 46.0, 1.0, 2.0, 0.8593930902695491, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846332531416, 977991.4648832794, 977991.4648832794, 186328.4388725894], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5926800.0000, 
sim time next is 5927400.0000, 
raw observation next is [27.7, 46.0, 1.0, 2.0, 0.8668247177875152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344280921, 986058.7289425108, 986058.7289425108, 187156.807040511], 
processed observation next is [1.0, 0.6086956521739131, 0.8954545454545454, 0.46, 1.0, 1.0, 0.8335308972343941, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129158424, 0.36520693664537435, 0.36520693664537435, 0.456480017171978], 
reward next is 0.5435, 
noisyNet noise sample is [array([0.9607401], dtype=float32), -0.7352667]. 
=============================================
[2019-03-23 11:51:47,789] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10000, global step 159435: loss 0.1087
[2019-03-23 11:51:47,790] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10000, global step 159436: learning rate 0.0001
[2019-03-23 11:51:47,901] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5737012e-07 9.9999988e-01 1.1582906e-31 1.0866665e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 11:51:47,908] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7092
[2019-03-23 11:51:47,915] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.2, 90.0, 1.0, 2.0, 0.344855891585025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 382433.5273235979, 382433.5273235976, 117199.0718558518], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5976600.0000, 
sim time next is 5977200.0000, 
raw observation next is [18.1, 90.0, 1.0, 2.0, 0.3380333814256901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 374283.3604149817, 374283.3604149817, 116437.5761571157], 
processed observation next is [1.0, 0.17391304347826086, 0.45909090909090916, 0.9, 1.0, 1.0, 0.17254172678211263, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1386234668203636, 0.1386234668203636, 0.2839940881880871], 
reward next is 0.7160, 
noisyNet noise sample is [array([1.3306016], dtype=float32), -0.1204717]. 
=============================================
[2019-03-23 11:51:48,046] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10000, global step 159568: loss 1.1344
[2019-03-23 11:51:48,049] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10000, global step 159568: learning rate 0.0001
[2019-03-23 11:51:48,184] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10000, global step 159636: loss 0.1865
[2019-03-23 11:51:48,189] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10000, global step 159636: learning rate 0.0001
[2019-03-23 11:51:48,272] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10000, global step 159680: loss 0.0090
[2019-03-23 11:51:48,275] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10000, global step 159681: learning rate 0.0001
[2019-03-23 11:51:48,588] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10000, global step 159838: loss 1.0139
[2019-03-23 11:51:48,592] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10000, global step 159838: learning rate 0.0001
[2019-03-23 11:51:48,684] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10000, global step 159892: loss 1.0923
[2019-03-23 11:51:48,687] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10000, global step 159892: learning rate 0.0001
[2019-03-23 11:51:48,810] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10000, global step 159953: loss 0.6803
[2019-03-23 11:51:48,812] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10000, global step 159953: learning rate 0.0001
[2019-03-23 11:51:48,844] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10000, global step 159968: loss 0.4153
[2019-03-23 11:51:48,846] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10000, global step 159968: learning rate 0.0001
[2019-03-23 11:51:49,032] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10000, global step 160061: loss 0.0064
[2019-03-23 11:51:49,037] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10000, global step 160061: learning rate 0.0001
[2019-03-23 11:51:49,086] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10000, global step 160086: loss 0.0165
[2019-03-23 11:51:49,089] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10000, global step 160087: learning rate 0.0001
[2019-03-23 11:51:49,094] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10000, global step 160089: loss 0.0857
[2019-03-23 11:51:49,097] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10000, global step 160089: learning rate 0.0001
[2019-03-23 11:51:49,311] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10000, global step 160200: loss 0.0735
[2019-03-23 11:51:49,313] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10000, global step 160201: learning rate 0.0001
[2019-03-23 11:51:49,343] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10000, global step 160213: loss 0.1057
[2019-03-23 11:51:49,345] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10000, global step 160213: loss 0.1419
[2019-03-23 11:51:49,346] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10000, global step 160214: learning rate 0.0001
[2019-03-23 11:51:49,346] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10000, global step 160215: learning rate 0.0001
[2019-03-23 11:51:49,664] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10000, global step 160356: loss 0.0052
[2019-03-23 11:51:49,670] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10000, global step 160356: learning rate 0.0001
[2019-03-23 11:51:49,699] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10000, global step 160376: loss 0.0054
[2019-03-23 11:51:49,701] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10000, global step 160376: learning rate 0.0001
[2019-03-23 11:51:57,560] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.8302902e-10 1.0000000e+00 2.2515510e-29 6.0457318e-34 3.0735570e-33], sum to 1.0000
[2019-03-23 11:51:57,567] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3589
[2019-03-23 11:51:57,571] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.43333333333333, 79.66666666666667, 1.0, 2.0, 0.3043421872858151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 331052.3762670857, 331052.3762670854, 111687.477905269], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6162000.0000, 
sim time next is 6162600.0000, 
raw observation next is [18.61666666666667, 79.33333333333334, 1.0, 2.0, 0.3076302094736216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 335544.6193511536, 335544.6193511533, 112234.0386406384], 
processed observation next is [1.0, 0.30434782608695654, 0.48257575757575777, 0.7933333333333334, 1.0, 1.0, 0.13453776184202695, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12427578494487171, 0.1242757849448716, 0.27374155766009367], 
reward next is 0.7263, 
noisyNet noise sample is [array([0.693927], dtype=float32), 1.6186495]. 
=============================================
[2019-03-23 11:51:59,955] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.5538353e-13 1.0000000e+00 7.6807162e-35 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 11:51:59,962] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6110
[2019-03-23 11:51:59,966] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666666, 79.33333333333334, 1.0, 2.0, 0.3634318651821046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 406476.7195270731, 406476.7195270734, 120121.081355492], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6212400.0000, 
sim time next is 6213000.0000, 
raw observation next is [20.08333333333334, 80.16666666666666, 1.0, 2.0, 0.3656271909393284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 409072.3771126928, 409072.3771126931, 120366.3853666437], 
processed observation next is [1.0, 0.9130434782608695, 0.5492424242424245, 0.8016666666666665, 1.0, 1.0, 0.20703398867416045, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15150828781951586, 0.15150828781951597, 0.2935765496747407], 
reward next is 0.7064, 
noisyNet noise sample is [array([0.5548643], dtype=float32), 0.8758928]. 
=============================================
[2019-03-23 11:51:59,981] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[88.36419 ]
 [88.34331 ]
 [88.31868 ]
 [88.29205 ]
 [88.261505]], R is [[88.20261383]
 [88.02761078]
 [87.85476685]
 [87.68412781]
 [87.51573181]].
[2019-03-23 11:52:03,182] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.0944499e-07 9.9999952e-01 8.5263879e-21 1.4988471e-24 3.5672788e-25], sum to 1.0000
[2019-03-23 11:52:03,188] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5429
[2019-03-23 11:52:03,190] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 73.33333333333334, 1.0, 2.0, 0.5090535187018296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 579554.318755252, 579554.318755252, 144198.0988363451], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6262800.0000, 
sim time next is 6263400.0000, 
raw observation next is [26.05, 71.16666666666666, 1.0, 2.0, 0.5175608309904262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588722.0633337334, 588722.0633337334, 145582.7432708666], 
processed observation next is [0.0, 0.4782608695652174, 0.8204545454545454, 0.7116666666666666, 1.0, 1.0, 0.39695103873803267, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21804520864212346, 0.21804520864212346, 0.35507986163626], 
reward next is 0.6449, 
noisyNet noise sample is [array([-0.13338237], dtype=float32), 0.77381665]. 
=============================================
[2019-03-23 11:52:03,535] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.6304437e-08 9.9999988e-01 5.6514774e-25 6.6300066e-29 4.8493053e-28], sum to 1.0000
[2019-03-23 11:52:03,543] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2243
[2019-03-23 11:52:03,551] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.85, 79.83333333333334, 1.0, 2.0, 0.4811588961883357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 548839.576754952, 548839.5767549516, 139688.0058326068], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6261000.0000, 
sim time next is 6261600.0000, 
raw observation next is [24.4, 77.66666666666667, 1.0, 2.0, 0.4904776346311364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 559200.750838258, 559200.750838258, 141203.4317425451], 
processed observation next is [0.0, 0.4782608695652174, 0.7454545454545454, 0.7766666666666667, 1.0, 1.0, 0.3630970432889205, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2071113891993548, 0.2071113891993548, 0.3443986140062076], 
reward next is 0.6556, 
noisyNet noise sample is [array([-0.03753271], dtype=float32), -0.7750871]. 
=============================================
[2019-03-23 11:52:03,611] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10500, global step 167440: loss 0.0773
[2019-03-23 11:52:03,612] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10500, global step 167440: learning rate 0.0001
[2019-03-23 11:52:03,895] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10500, global step 167584: loss 0.2227
[2019-03-23 11:52:03,899] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10500, global step 167587: learning rate 0.0001
[2019-03-23 11:52:03,928] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10500, global step 167600: loss 0.0960
[2019-03-23 11:52:03,930] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10500, global step 167600: learning rate 0.0001
[2019-03-23 11:52:04,011] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10500, global step 167637: loss 0.0848
[2019-03-23 11:52:04,015] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10500, global step 167639: learning rate 0.0001
[2019-03-23 11:52:04,533] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10500, global step 167907: loss 0.0102
[2019-03-23 11:52:04,537] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10500, global step 167907: learning rate 0.0001
[2019-03-23 11:52:04,599] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10500, global step 167936: loss 0.3071
[2019-03-23 11:52:04,600] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10500, global step 167936: loss 0.2999
[2019-03-23 11:52:04,601] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10500, global step 167937: learning rate 0.0001
[2019-03-23 11:52:04,604] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10500, global step 167938: learning rate 0.0001
[2019-03-23 11:52:04,677] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10500, global step 167977: loss 0.6194
[2019-03-23 11:52:04,683] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10500, global step 167977: learning rate 0.0001
[2019-03-23 11:52:04,849] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10500, global step 168064: loss 0.1661
[2019-03-23 11:52:04,850] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10500, global step 168064: learning rate 0.0001
[2019-03-23 11:52:04,866] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10500, global step 168072: loss 0.1397
[2019-03-23 11:52:04,867] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10500, global step 168073: learning rate 0.0001
[2019-03-23 11:52:04,907] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10500, global step 168094: loss 0.3312
[2019-03-23 11:52:04,914] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10500, global step 168094: learning rate 0.0001
[2019-03-23 11:52:05,112] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10500, global step 168178: loss 0.0024
[2019-03-23 11:52:05,115] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10500, global step 168179: learning rate 0.0001
[2019-03-23 11:52:05,150] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10500, global step 168195: loss 0.0836
[2019-03-23 11:52:05,152] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10500, global step 168195: learning rate 0.0001
[2019-03-23 11:52:05,267] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10500, global step 168255: loss 0.4671
[2019-03-23 11:52:05,269] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10500, global step 168257: learning rate 0.0001
[2019-03-23 11:52:05,634] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10500, global step 168443: loss 0.0973
[2019-03-23 11:52:05,636] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10500, global step 168443: learning rate 0.0001
[2019-03-23 11:52:05,667] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10500, global step 168458: loss 0.0457
[2019-03-23 11:52:05,669] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10500, global step 168458: learning rate 0.0001
[2019-03-23 11:52:09,206] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.1884956e-09 1.0000000e+00 3.9416577e-22 2.6780553e-25 2.4825948e-25], sum to 1.0000
[2019-03-23 11:52:09,214] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3779
[2019-03-23 11:52:09,217] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.35, 74.0, 1.0, 2.0, 0.569171076500586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 644146.1763249307, 644146.176324931, 153532.962682373], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6377400.0000, 
sim time next is 6378000.0000, 
raw observation next is [26.06666666666667, 75.66666666666667, 1.0, 2.0, 0.5697039184289737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 644822.4344496748, 644822.4344496748, 153579.9039856922], 
processed observation next is [0.0, 0.8260869565217391, 0.8212121212121214, 0.7566666666666667, 1.0, 1.0, 0.4621298980362171, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23882312387024993, 0.23882312387024993, 0.37458513167241997], 
reward next is 0.6254, 
noisyNet noise sample is [array([0.7920101], dtype=float32), 0.4131909]. 
=============================================
[2019-03-23 11:52:09,227] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[52.26082 ]
 [52.22981 ]
 [52.203705]
 [52.18407 ]
 [52.152565]], R is [[52.39554596]
 [52.4971199 ]
 [52.59778976]
 [52.6975708 ]
 [52.79676819]].
[2019-03-23 11:52:14,639] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.6278996e-09 1.0000000e+00 5.4193752e-28 6.2875110e-31 7.9204950e-31], sum to 1.0000
[2019-03-23 11:52:14,649] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6163
[2019-03-23 11:52:14,657] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.3, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 211046.5767506244, 211046.5767506247, 70257.56040618251], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6490800.0000, 
sim time next is 6491400.0000, 
raw observation next is [13.2, 87.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 209353.0914853647, 209353.0914853647, 69848.1970238826], 
processed observation next is [1.0, 0.13043478260869565, 0.23636363636363633, 0.875, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07753818203161655, 0.07753818203161655, 0.17036145615581122], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.046728], dtype=float32), -0.13626447]. 
=============================================
[2019-03-23 11:52:15,370] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.5802509e-09 1.0000000e+00 4.0746792e-24 2.5571820e-26 2.5673668e-26], sum to 1.0000
[2019-03-23 11:52:15,378] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2286
[2019-03-23 11:52:15,383] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.53333333333333, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 198781.0933413665, 198781.0933413662, 66930.38142599553], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6499200.0000, 
sim time next is 6499800.0000, 
raw observation next is [12.45, 87.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 196906.5847526818, 196906.5847526821, 66551.69609715507], 
processed observation next is [1.0, 0.21739130434782608, 0.20227272727272724, 0.875, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07292836472321548, 0.0729283647232156, 0.16232120999306116], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3610725], dtype=float32), 0.79749906]. 
=============================================
[2019-03-23 11:52:15,602] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.6931583e-08 1.0000000e+00 1.5004690e-21 4.0976529e-25 6.2472212e-25], sum to 1.0000
[2019-03-23 11:52:15,611] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3516
[2019-03-23 11:52:15,616] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.7, 87.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 207153.0198002182, 207153.0198002182, 68610.605953748], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6496800.0000, 
sim time next is 6497400.0000, 
raw observation next is [12.7, 86.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 204954.198409153, 204954.1984091528, 68135.9823536559], 
processed observation next is [1.0, 0.17391304347826086, 0.2136363636363636, 0.8666666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07590896237376037, 0.0759089623737603, 0.16618532281379486], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.19622488], dtype=float32), -0.34534484]. 
=============================================
[2019-03-23 11:52:15,804] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8261376e-08 1.0000000e+00 9.4414060e-24 2.1613376e-26 2.2667294e-27], sum to 1.0000
[2019-03-23 11:52:15,815] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2088
[2019-03-23 11:52:15,824] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 54.0, 1.0, 2.0, 0.4472228466565689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 485697.7959105937, 485697.7959105937, 103055.8765280016], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6523200.0000, 
sim time next is 6523800.0000, 
raw observation next is [19.58333333333334, 53.16666666666666, 1.0, 2.0, 0.4879166613007444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 529916.6211473374, 529916.6211473374, 107649.7014498554], 
processed observation next is [1.0, 0.5217391304347826, 0.5265151515151518, 0.5316666666666666, 1.0, 1.0, 0.35989582662593045, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19626541523975458, 0.19626541523975458, 0.26256024743867173], 
reward next is 0.7374, 
noisyNet noise sample is [array([0.8869542], dtype=float32), -0.8172649]. 
=============================================
[2019-03-23 11:52:18,500] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 11:52:18,501] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:52:18,502] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:52:18,502] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:52:18,504] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:52:18,507] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:52:18,508] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:52:18,512] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:52:18,512] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:52:18,513] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:52:18,511] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:52:18,526] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run8
[2019-03-23 11:52:18,528] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run8
[2019-03-23 11:52:18,552] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run8
[2019-03-23 11:52:18,573] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run8
[2019-03-23 11:52:18,617] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run8
[2019-03-23 11:52:31,604] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01867063], dtype=float32), 0.23846012]
[2019-03-23 11:52:31,606] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.88333333333333, 39.83333333333334, 1.0, 2.0, 0.4052010561456996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 459452.4170678874, 459452.4170678874, 131362.2908816589]
[2019-03-23 11:52:31,608] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:52:31,611] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.3473020e-12 1.0000000e+00 6.5034512e-31 3.9299956e-35 3.0421294e-35], sampled 0.5241399894921468
[2019-03-23 11:52:45,378] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01867063], dtype=float32), 0.23846012]
[2019-03-23 11:52:45,379] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.2, 84.33333333333333, 1.0, 2.0, 0.8176880585053279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 933099.4188577821, 933099.4188577821, 188054.6337430877]
[2019-03-23 11:52:45,380] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:52:45,383] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.5225100e-12 1.0000000e+00 1.2369986e-31 5.8994621e-36 4.5401120e-36], sampled 0.23928224669155385
[2019-03-23 11:52:58,260] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01867063], dtype=float32), 0.23846012]
[2019-03-23 11:52:58,264] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.53333333333333, 58.66666666666667, 1.0, 2.0, 0.4929169979038718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 562343.8984378364, 562343.8984378361, 143890.9589058784]
[2019-03-23 11:52:58,264] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:52:58,268] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.9901199e-12 1.0000000e+00 4.0214828e-31 2.2692551e-35 1.7537318e-35], sampled 0.5996915201522024
[2019-03-23 11:53:07,411] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01867063], dtype=float32), 0.23846012]
[2019-03-23 11:53:07,412] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.14015396333333, 72.59005129666667, 1.0, 2.0, 0.5549632946025322, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 612084.648048223, 612084.648048223, 139306.3941898537]
[2019-03-23 11:53:07,415] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:53:07,417] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.2802450e-12 1.0000000e+00 1.8807228e-31 9.5276027e-36 7.3454170e-36], sampled 0.7965143408659359
[2019-03-23 11:53:19,613] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01867063], dtype=float32), 0.23846012]
[2019-03-23 11:53:19,613] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.86135353, 94.38573161, 1.0, 2.0, 0.5173135358406438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 589939.1884846285, 589939.1884846285, 148387.1001627322]
[2019-03-23 11:53:19,614] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:53:19,618] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.9319836e-12 1.0000000e+00 8.4622839e-32 3.8316259e-36 2.9473281e-36], sampled 0.8359778573997363
[2019-03-23 11:53:42,733] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01867063], dtype=float32), 0.23846012]
[2019-03-23 11:53:42,734] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [12.140605825, 98.95556058666668, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 204288.8746195058, 204288.8746195054, 73597.22048886123]
[2019-03-23 11:53:42,736] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:53:42,741] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.5947333e-11 1.0000000e+00 1.4028278e-29 1.3103329e-33 1.0243573e-33], sampled 0.8383825345758247
[2019-03-23 11:53:45,353] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01867063], dtype=float32), 0.23846012]
[2019-03-23 11:53:45,356] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.56666666666667, 61.33333333333334, 1.0, 2.0, 0.399750195066136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 450525.9120693092, 450525.9120693092, 129184.3669592449]
[2019-03-23 11:53:45,356] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:53:45,358] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.7821282e-12 1.0000000e+00 2.4053342e-31 1.2628379e-35 9.7460298e-36], sampled 0.3494420459888359
[2019-03-23 11:53:45,431] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01867063], dtype=float32), 0.23846012]
[2019-03-23 11:53:45,431] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.5, 67.0, 1.0, 2.0, 0.3937802303070445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 443212.9596025874, 443212.959602587, 128340.0723185277]
[2019-03-23 11:53:45,432] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:53:45,436] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.56119126e-12 1.00000000e+00 2.16440131e-31 1.11955534e-35
 8.63746921e-36], sampled 0.3018312803213268
[2019-03-23 11:53:46,793] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01867063], dtype=float32), 0.23846012]
[2019-03-23 11:53:46,795] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.03891436, 69.064031935, 1.0, 2.0, 0.522986418488144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 595322.5721460368, 595322.5721460363, 150217.720798468]
[2019-03-23 11:53:46,795] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:53:46,800] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.1462718e-11 1.0000000e+00 1.5356872e-30 1.0470618e-34 8.1235395e-35], sampled 0.5496372927100203
[2019-03-23 11:53:56,983] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:53:57,070] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:53:57,418] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:53:57,532] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:53:57,544] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:53:58,558] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 175000, evaluation results [175000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:53:59,313] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11000, global step 175404: loss 0.4925
[2019-03-23 11:53:59,314] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11000, global step 175405: learning rate 0.0001
[2019-03-23 11:53:59,662] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11000, global step 175594: loss 0.6137
[2019-03-23 11:53:59,663] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11000, global step 175595: learning rate 0.0001
[2019-03-23 11:53:59,677] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11000, global step 175602: loss 0.5592
[2019-03-23 11:53:59,680] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11000, global step 175604: learning rate 0.0001
[2019-03-23 11:53:59,822] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11000, global step 175678: loss 1.0977
[2019-03-23 11:53:59,827] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11000, global step 175680: learning rate 0.0001
[2019-03-23 11:54:00,174] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11000, global step 175865: loss 1.2405
[2019-03-23 11:54:00,175] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11000, global step 175866: learning rate 0.0001
[2019-03-23 11:54:00,262] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11000, global step 175911: loss 1.2866
[2019-03-23 11:54:00,265] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11000, global step 175913: loss 1.4225
[2019-03-23 11:54:00,266] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11000, global step 175913: learning rate 0.0001
[2019-03-23 11:54:00,269] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11000, global step 175913: learning rate 0.0001
[2019-03-23 11:54:00,331] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11000, global step 175946: loss 1.0092
[2019-03-23 11:54:00,338] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11000, global step 175947: learning rate 0.0001
[2019-03-23 11:54:00,585] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11000, global step 176083: loss 0.6430
[2019-03-23 11:54:00,587] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11000, global step 176084: learning rate 0.0001
[2019-03-23 11:54:00,644] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11000, global step 176116: loss 0.6128
[2019-03-23 11:54:00,645] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11000, global step 176116: learning rate 0.0001
[2019-03-23 11:54:00,698] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11000, global step 176143: loss 0.5066
[2019-03-23 11:54:00,701] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11000, global step 176143: learning rate 0.0001
[2019-03-23 11:54:00,803] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11000, global step 176199: loss 0.1441
[2019-03-23 11:54:00,805] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11000, global step 176200: learning rate 0.0001
[2019-03-23 11:54:00,817] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11000, global step 176207: loss 0.1476
[2019-03-23 11:54:00,819] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11000, global step 176208: learning rate 0.0001
[2019-03-23 11:54:00,942] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11000, global step 176276: loss 0.0286
[2019-03-23 11:54:00,942] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11000, global step 176276: learning rate 0.0001
[2019-03-23 11:54:01,257] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11000, global step 176442: loss 0.2146
[2019-03-23 11:54:01,258] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11000, global step 176442: learning rate 0.0001
[2019-03-23 11:54:01,303] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11000, global step 176463: loss 0.2729
[2019-03-23 11:54:01,307] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11000, global step 176466: learning rate 0.0001
[2019-03-23 11:54:02,877] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.1558499e-11 1.0000000e+00 8.1107535e-27 7.5328626e-31 3.5087771e-31], sum to 1.0000
[2019-03-23 11:54:02,888] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8453
[2019-03-23 11:54:02,893] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.379462604620267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 423437.2769897092, 423437.2769897092, 121031.8543239128], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6664200.0000, 
sim time next is 6664800.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.3620718187227515, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 404024.5367594988, 404024.5367594985, 119592.9662696375], 
processed observation next is [1.0, 0.13043478260869565, 0.4681818181818182, 0.93, 1.0, 1.0, 0.20258977340343937, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1496387173183329, 0.14963871731833275, 0.2916901616332622], 
reward next is 0.7083, 
noisyNet noise sample is [array([-0.33255452], dtype=float32), 0.28003773]. 
=============================================
[2019-03-23 11:54:04,199] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0859050e-13 1.0000000e+00 3.7793535e-35 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 11:54:04,205] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7668
[2019-03-23 11:54:04,214] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.3, 87.5, 1.0, 2.0, 0.3911485300882161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 438514.0001930743, 438514.0001930743, 122928.2098190829], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6678600.0000, 
sim time next is 6679200.0000, 
raw observation next is [19.2, 88.0, 1.0, 2.0, 0.3787567044704468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 424442.3541211619, 424442.3541211621, 121777.8712016514], 
processed observation next is [1.0, 0.30434782608695654, 0.509090909090909, 0.88, 1.0, 1.0, 0.22344588058805848, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15720087189672663, 0.1572008718967267, 0.2970191980528083], 
reward next is 0.7030, 
noisyNet noise sample is [array([-0.13225237], dtype=float32), 1.4807754]. 
=============================================
[2019-03-23 11:54:09,499] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9267246e-10 1.0000000e+00 5.5132266e-29 1.1297020e-34 2.4439560e-33], sum to 1.0000
[2019-03-23 11:54:09,501] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6223
[2019-03-23 11:54:09,509] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.63333333333334, 76.0, 1.0, 2.0, 0.7823581458502403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 891065.5563257491, 891065.5563257491, 175240.48274324], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6780000.0000, 
sim time next is 6780600.0000, 
raw observation next is [22.65, 76.0, 1.0, 2.0, 0.7893302928919123, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 899066.3824358608, 899066.3824358606, 176348.0790958938], 
processed observation next is [1.0, 0.4782608695652174, 0.6659090909090909, 0.76, 1.0, 1.0, 0.7366628661148902, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3329875490503188, 0.33298754905031874, 0.43011726608754586], 
reward next is 0.5699, 
noisyNet noise sample is [array([1.169934], dtype=float32), 0.503274]. 
=============================================
[2019-03-23 11:54:12,434] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1656107e-09 1.0000000e+00 2.4680048e-26 3.5408745e-30 8.5205614e-31], sum to 1.0000
[2019-03-23 11:54:12,442] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0671
[2019-03-23 11:54:12,449] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 90.0, 1.0, 2.0, 0.3645833174941722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 407635.7258040743, 407635.7258040743, 120157.5184335035], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6833400.0000, 
sim time next is 6834000.0000, 
raw observation next is [18.8, 90.0, 1.0, 2.0, 0.3648340927134845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 407914.5987686187, 407914.5987686187, 120177.5184817602], 
processed observation next is [0.0, 0.08695652173913043, 0.49090909090909096, 0.9, 1.0, 1.0, 0.2060426158918556, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15107948102541433, 0.15107948102541433, 0.29311589873600047], 
reward next is 0.7069, 
noisyNet noise sample is [array([-1.0016419], dtype=float32), 0.12084676]. 
=============================================
[2019-03-23 11:54:12,473] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[66.06946 ]
 [66.097244]
 [66.04091 ]
 [66.146225]
 [66.26323 ]], R is [[65.99245453]
 [66.03945923]
 [66.08602142]
 [66.1319809 ]
 [66.17728424]].
[2019-03-23 11:54:14,277] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11500, global step 183379: loss 0.0018
[2019-03-23 11:54:14,278] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11500, global step 183379: learning rate 0.0001
[2019-03-23 11:54:14,637] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11500, global step 183562: loss 0.0765
[2019-03-23 11:54:14,642] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11500, global step 183565: learning rate 0.0001
[2019-03-23 11:54:14,676] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11500, global step 183582: loss 0.0112
[2019-03-23 11:54:14,678] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11500, global step 183583: learning rate 0.0001
[2019-03-23 11:54:14,836] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11500, global step 183663: loss 0.2822
[2019-03-23 11:54:14,840] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11500, global step 183663: learning rate 0.0001
[2019-03-23 11:54:15,112] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11500, global step 183802: loss 0.4635
[2019-03-23 11:54:15,117] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11500, global step 183802: learning rate 0.0001
[2019-03-23 11:54:15,402] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11500, global step 183949: loss 0.3628
[2019-03-23 11:54:15,405] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11500, global step 183950: learning rate 0.0001
[2019-03-23 11:54:15,504] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11500, global step 184002: loss 0.1735
[2019-03-23 11:54:15,508] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11500, global step 184003: learning rate 0.0001
[2019-03-23 11:54:15,542] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11500, global step 184021: loss 0.0416
[2019-03-23 11:54:15,546] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11500, global step 184022: learning rate 0.0001
[2019-03-23 11:54:15,630] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11500, global step 184063: loss 0.0527
[2019-03-23 11:54:15,633] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11500, global step 184063: learning rate 0.0001
[2019-03-23 11:54:15,727] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11500, global step 184110: loss 0.3740
[2019-03-23 11:54:15,729] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11500, global step 184111: learning rate 0.0001
[2019-03-23 11:54:15,746] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11500, global step 184124: loss 0.3352
[2019-03-23 11:54:15,747] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11500, global step 184124: learning rate 0.0001
[2019-03-23 11:54:15,767] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4657901e-12 1.0000000e+00 5.8374448e-31 7.0673136e-34 1.7670491e-34], sum to 1.0000
[2019-03-23 11:54:15,773] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5393
[2019-03-23 11:54:15,777] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.8, 48.83333333333334, 1.0, 2.0, 0.4400106414368638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 501257.1646447848, 501257.1646447848, 132406.3559116265], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6886200.0000, 
sim time next is 6886800.0000, 
raw observation next is [27.7, 49.0, 1.0, 2.0, 0.437123252977678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 497867.450145021, 497867.4501450207, 131991.7858909797], 
processed observation next is [0.0, 0.7391304347826086, 0.8954545454545454, 0.49, 1.0, 1.0, 0.2964040662220975, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18439535190556333, 0.18439535190556322, 0.32193118509995045], 
reward next is 0.6781, 
noisyNet noise sample is [array([2.4167852], dtype=float32), 0.640756]. 
=============================================
[2019-03-23 11:54:15,871] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11500, global step 184185: loss 0.0059
[2019-03-23 11:54:15,877] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11500, global step 184186: learning rate 0.0001
[2019-03-23 11:54:15,956] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11500, global step 184228: loss 0.1491
[2019-03-23 11:54:15,957] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11500, global step 184228: learning rate 0.0001
[2019-03-23 11:54:15,996] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11500, global step 184246: loss 0.1761
[2019-03-23 11:54:15,999] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11500, global step 184247: learning rate 0.0001
[2019-03-23 11:54:16,261] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11500, global step 184382: loss 0.0718
[2019-03-23 11:54:16,266] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11500, global step 184382: learning rate 0.0001
[2019-03-23 11:54:16,453] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11500, global step 184475: loss 0.0115
[2019-03-23 11:54:16,457] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11500, global step 184478: learning rate 0.0001
[2019-03-23 11:54:17,272] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.4249271e-10 1.0000000e+00 1.4105116e-22 5.0724853e-26 6.0742101e-27], sum to 1.0000
[2019-03-23 11:54:17,280] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7836
[2019-03-23 11:54:17,284] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 88.5, 1.0, 2.0, 0.3630990770552519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 405124.4574515114, 405124.4574515111, 119656.3370494657], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6928200.0000, 
sim time next is 6928800.0000, 
raw observation next is [18.8, 88.0, 1.0, 2.0, 0.3603749863647621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 401752.8538482962, 401752.8538482962, 119290.2267775082], 
processed observation next is [0.0, 0.17391304347826086, 0.49090909090909096, 0.88, 1.0, 1.0, 0.20046873295595263, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14879735327714674, 0.14879735327714674, 0.29095177262806876], 
reward next is 0.7090, 
noisyNet noise sample is [array([1.7557354], dtype=float32), -0.1650782]. 
=============================================
[2019-03-23 11:54:17,697] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.5209943e-11 1.0000000e+00 4.3553880e-28 8.6438903e-30 2.9427505e-32], sum to 1.0000
[2019-03-23 11:54:17,704] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6877
[2019-03-23 11:54:17,710] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 69.0, 1.0, 2.0, 0.4413547675680303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 503238.5092441817, 503238.5092441817, 133196.8240824229], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6948000.0000, 
sim time next is 6948600.0000, 
raw observation next is [24.68333333333333, 68.16666666666667, 1.0, 2.0, 0.4477794886139899, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 510723.4504000444, 510723.4504000447, 134178.3923426718], 
processed observation next is [0.0, 0.43478260869565216, 0.7583333333333332, 0.6816666666666668, 1.0, 1.0, 0.3097243607674874, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18915683348149792, 0.18915683348149803, 0.3272643715674922], 
reward next is 0.6727, 
noisyNet noise sample is [array([-0.28339198], dtype=float32), -0.87755567]. 
=============================================
[2019-03-23 11:54:23,545] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.8865498e-13 1.0000000e+00 5.0698134e-27 2.6367692e-31 9.2550831e-32], sum to 1.0000
[2019-03-23 11:54:23,553] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9274
[2019-03-23 11:54:23,558] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333333, 79.83333333333334, 1.0, 2.0, 0.5619058837877648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 639130.1451530505, 639130.1451530508, 144885.3408025948], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7060200.0000, 
sim time next is 7060800.0000, 
raw observation next is [21.46666666666667, 80.66666666666667, 1.0, 2.0, 0.4311932652557001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 489519.6807084221, 489519.6807084218, 129939.0686849537], 
processed observation next is [1.0, 0.7391304347826086, 0.6121212121212122, 0.8066666666666668, 1.0, 1.0, 0.2889915815696251, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18130358544756373, 0.18130358544756364, 0.31692455776817974], 
reward next is 0.6831, 
noisyNet noise sample is [array([0.32302406], dtype=float32), -1.3311533]. 
=============================================
[2019-03-23 11:54:26,753] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.5894554e-10 1.0000000e+00 2.1325943e-23 2.1825478e-26 4.7374849e-25], sum to 1.0000
[2019-03-23 11:54:26,762] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5742
[2019-03-23 11:54:26,767] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 55.0, 1.0, 2.0, 0.4171048929156319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 463069.6991346429, 463069.6991346429, 123310.5148880431], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7131600.0000, 
sim time next is 7132200.0000, 
raw observation next is [23.38333333333333, 54.16666666666667, 1.0, 2.0, 0.5300495975566677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588506.6028793635, 588506.6028793635, 133896.876083063], 
processed observation next is [1.0, 0.5652173913043478, 0.6992424242424241, 0.5416666666666667, 1.0, 1.0, 0.41256199694583456, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21796540847383833, 0.21796540847383833, 0.3265777465440561], 
reward next is 0.6734, 
noisyNet noise sample is [array([-0.6155379], dtype=float32), 1.9260716]. 
=============================================
[2019-03-23 11:54:29,866] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12000, global step 191282: loss 0.7236
[2019-03-23 11:54:29,870] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12000, global step 191282: learning rate 0.0001
[2019-03-23 11:54:30,357] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12000, global step 191528: loss 0.7559
[2019-03-23 11:54:30,358] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12000, global step 191528: learning rate 0.0001
[2019-03-23 11:54:30,464] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12000, global step 191584: loss 0.8385
[2019-03-23 11:54:30,467] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12000, global step 191586: learning rate 0.0001
[2019-03-23 11:54:30,697] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12000, global step 191704: loss 0.6823
[2019-03-23 11:54:30,700] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12000, global step 191704: learning rate 0.0001
[2019-03-23 11:54:30,852] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12000, global step 191780: loss 0.7133
[2019-03-23 11:54:30,854] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12000, global step 191781: learning rate 0.0001
[2019-03-23 11:54:31,243] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12000, global step 191974: loss 1.3004
[2019-03-23 11:54:31,244] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12000, global step 191974: learning rate 0.0001
[2019-03-23 11:54:31,317] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12000, global step 192011: loss 1.4483
[2019-03-23 11:54:31,320] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12000, global step 192011: learning rate 0.0001
[2019-03-23 11:54:31,444] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12000, global step 192077: loss 1.6288
[2019-03-23 11:54:31,446] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12000, global step 192077: learning rate 0.0001
[2019-03-23 11:54:31,472] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12000, global step 192089: loss 1.4506
[2019-03-23 11:54:31,478] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12000, global step 192091: learning rate 0.0001
[2019-03-23 11:54:31,506] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12000, global step 192105: loss 1.5900
[2019-03-23 11:54:31,508] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12000, global step 192105: learning rate 0.0001
[2019-03-23 11:54:31,551] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12000, global step 192128: loss 1.7211
[2019-03-23 11:54:31,553] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12000, global step 192129: learning rate 0.0001
[2019-03-23 11:54:31,605] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12000, global step 192161: loss 1.8124
[2019-03-23 11:54:31,608] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12000, global step 192162: learning rate 0.0001
[2019-03-23 11:54:31,705] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12000, global step 192207: loss 1.3796
[2019-03-23 11:54:31,708] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12000, global step 192209: learning rate 0.0001
[2019-03-23 11:54:31,875] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12000, global step 192292: loss 0.5979
[2019-03-23 11:54:31,876] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12000, global step 192292: learning rate 0.0001
[2019-03-23 11:54:32,089] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12000, global step 192402: loss 0.1344
[2019-03-23 11:54:32,093] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12000, global step 192403: learning rate 0.0001
[2019-03-23 11:54:32,325] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12000, global step 192520: loss 0.0302
[2019-03-23 11:54:32,328] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12000, global step 192520: learning rate 0.0001
[2019-03-23 11:54:32,725] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.21042265e-11 1.00000000e+00 1.76019051e-30 3.95036402e-34
 6.99122209e-32], sum to 1.0000
[2019-03-23 11:54:32,732] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9843
[2019-03-23 11:54:32,738] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.55, 46.0, 1.0, 2.0, 0.322167368369545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 349834.8318477535, 349834.8318477538, 112704.4001406839], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7234200.0000, 
sim time next is 7234800.0000, 
raw observation next is [23.46666666666667, 46.0, 1.0, 2.0, 0.3232912783620852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 351055.7028183984, 351055.7028183987, 112781.8207239292], 
processed observation next is [1.0, 0.7391304347826086, 0.7030303030303031, 0.46, 1.0, 1.0, 0.1541140979526065, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1300206306734809, 0.130020630673481, 0.2750776115217785], 
reward next is 0.7249, 
noisyNet noise sample is [array([-0.40860865], dtype=float32), -0.94611]. 
=============================================
[2019-03-23 11:54:33,129] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.9762839e-13 1.0000000e+00 3.4428622e-34 3.5383100e-37 1.8392539e-37], sum to 1.0000
[2019-03-23 11:54:33,136] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3936
[2019-03-23 11:54:33,144] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 45.66666666666666, 1.0, 2.0, 0.609706502287902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 668500.9673483007, 668500.9673483011, 139360.6973992546], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7231200.0000, 
sim time next is 7231800.0000, 
raw observation next is [23.9, 45.83333333333334, 1.0, 2.0, 0.57556122679693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 630067.3170445508, 630067.317044551, 135507.1070635214], 
processed observation next is [1.0, 0.6956521739130435, 0.7227272727272727, 0.4583333333333334, 1.0, 1.0, 0.4694515334961625, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23335826557205586, 0.23335826557205594, 0.3305051391793205], 
reward next is 0.6695, 
noisyNet noise sample is [array([1.0156301], dtype=float32), -0.87081724]. 
=============================================
[2019-03-23 11:54:35,444] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.2324282e-13 1.0000000e+00 1.6035295e-28 2.1934334e-32 5.5458314e-31], sum to 1.0000
[2019-03-23 11:54:35,455] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5805
[2019-03-23 11:54:35,459] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.9, 82.83333333333333, 1.0, 2.0, 0.2032330390763043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 220657.224251111, 220657.2242511113, 71905.61605999315], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7275000.0000, 
sim time next is 7275600.0000, 
raw observation next is [13.8, 84.0, 1.0, 2.0, 0.2012130206503769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 218463.5270151731, 218463.5270151733, 71769.75174645339], 
processed observation next is [1.0, 0.21739130434782608, 0.26363636363636367, 0.84, 1.0, 1.0, 0.0015162758129711254, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08091241741302707, 0.08091241741302715, 0.17504817499134973], 
reward next is 0.8250, 
noisyNet noise sample is [array([-2.4005513], dtype=float32), 0.7114773]. 
=============================================
[2019-03-23 11:54:37,473] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1164121e-09 1.0000000e+00 2.6609650e-27 7.0912890e-28 1.5171607e-28], sum to 1.0000
[2019-03-23 11:54:37,479] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0795
[2019-03-23 11:54:37,482] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.73333333333333, 44.0, 1.0, 2.0, 0.946288603644319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1057946.324428792, 1057946.324428793, 189467.1445150287], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7306800.0000, 
sim time next is 7307400.0000, 
raw observation next is [25.91666666666667, 43.5, 1.0, 2.0, 0.9533343975935962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1066741.732274866, 1066741.732274866, 190982.4908020717], 
processed observation next is [1.0, 0.5652173913043478, 0.8143939393939396, 0.435, 1.0, 1.0, 0.9416679969919952, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3950895304721726, 0.3950895304721726, 0.46581095317578464], 
reward next is 0.5342, 
noisyNet noise sample is [array([2.6080623], dtype=float32), 1.2454239]. 
=============================================
[2019-03-23 11:54:39,307] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.9075258e-08 1.0000000e+00 3.9150693e-24 4.8048415e-26 1.5154797e-25], sum to 1.0000
[2019-03-23 11:54:39,313] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6144
[2019-03-23 11:54:39,317] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.06666666666666, 65.66666666666666, 1.0, 2.0, 0.8968239245796902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1020819.727163042, 1020819.727163042, 192591.4614016689], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7378800.0000, 
sim time next is 7379400.0000, 
raw observation next is [24.53333333333333, 63.83333333333334, 1.0, 2.0, 0.9464756134712792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1078187.179389735, 1078187.179389736, 201806.9925957061], 
processed observation next is [1.0, 0.391304347826087, 0.7515151515151515, 0.6383333333333334, 1.0, 1.0, 0.9330945168390988, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3993285849591611, 0.39932858495916146, 0.4922121770626978], 
reward next is 0.5078, 
noisyNet noise sample is [array([0.6543541], dtype=float32), 0.0351957]. 
=============================================
[2019-03-23 11:54:40,864] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.2203500e-09 1.0000000e+00 1.4103932e-22 1.9818735e-25 6.7317569e-25], sum to 1.0000
[2019-03-23 11:54:40,871] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0509
[2019-03-23 11:54:40,876] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 73.0, 1.0, 2.0, 0.8037104816267241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 910736.7144019614, 910736.7144019612, 174755.4926414057], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7376400.0000, 
sim time next is 7377000.0000, 
raw observation next is [22.66666666666666, 71.16666666666667, 1.0, 2.0, 0.8692718157800038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 986604.6346777448, 986604.6346777448, 185763.6218621689], 
processed observation next is [1.0, 0.391304347826087, 0.6666666666666664, 0.7116666666666667, 1.0, 1.0, 0.8365897697250047, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3654091239547203, 0.3654091239547203, 0.45308200454187536], 
reward next is 0.5469, 
noisyNet noise sample is [array([0.38987935], dtype=float32), -1.4953192]. 
=============================================
[2019-03-23 11:54:40,898] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[52.60959 ]
 [52.66975 ]
 [52.75917 ]
 [52.961895]
 [53.35574 ]], R is [[52.50702286]
 [52.55572128]
 [52.6205101 ]
 [52.69125366]
 [52.77102661]].
[2019-03-23 11:54:44,937] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.73132729e-12 1.00000000e+00 1.12988755e-26 5.05233340e-30
 8.29532558e-30], sum to 1.0000
[2019-03-23 11:54:44,947] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9575
[2019-03-23 11:54:44,952] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 63.66666666666667, 1.0, 2.0, 0.530969659239717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 603845.5365854681, 603845.5365854681, 147316.7683450024], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7476000.0000, 
sim time next is 7476600.0000, 
raw observation next is [27.51666666666667, 62.33333333333334, 1.0, 2.0, 0.5280904886860722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 600745.1867841142, 600745.1867841142, 146852.4504387899], 
processed observation next is [0.0, 0.5217391304347826, 0.8871212121212122, 0.6233333333333334, 1.0, 1.0, 0.4101131108575902, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2224982173274497, 0.2224982173274497, 0.35817670838729243], 
reward next is 0.6418, 
noisyNet noise sample is [array([-1.0543324], dtype=float32), 0.12479297]. 
=============================================
[2019-03-23 11:54:45,706] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12500, global step 199304: loss 0.2103
[2019-03-23 11:54:45,708] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12500, global step 199304: learning rate 0.0001
[2019-03-23 11:54:46,120] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12500, global step 199517: loss 0.0071
[2019-03-23 11:54:46,122] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12500, global step 199518: learning rate 0.0001
[2019-03-23 11:54:46,241] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12500, global step 199576: loss 0.1194
[2019-03-23 11:54:46,244] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12500, global step 199576: learning rate 0.0001
[2019-03-23 11:54:46,633] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12500, global step 199775: loss 0.9219
[2019-03-23 11:54:46,634] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12500, global step 199775: learning rate 0.0001
[2019-03-23 11:54:46,669] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12500, global step 199790: loss 0.3600
[2019-03-23 11:54:46,675] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12500, global step 199791: learning rate 0.0001
[2019-03-23 11:54:47,008] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12500, global step 199961: loss 0.1401
[2019-03-23 11:54:47,010] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12500, global step 199963: learning rate 0.0001
[2019-03-23 11:54:47,012] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12500, global step 199963: loss 0.1106
[2019-03-23 11:54:47,016] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12500, global step 199965: learning rate 0.0001
[2019-03-23 11:54:47,082] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 11:54:47,086] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:54:47,086] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:54:47,087] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:54:47,088] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:54:47,090] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:54:47,091] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:54:47,095] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:54:47,088] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:54:47,098] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:54:47,100] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:54:47,106] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run9
[2019-03-23 11:54:47,127] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run9
[2019-03-23 11:54:47,155] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run9
[2019-03-23 11:54:47,155] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run9
[2019-03-23 11:54:47,176] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run9
[2019-03-23 11:55:01,133] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01867063], dtype=float32), 0.22413556]
[2019-03-23 11:55:01,134] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.5, 97.0, 1.0, 2.0, 0.3964531142613621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 446100.8350175425, 446100.8350175425, 124189.575202827]
[2019-03-23 11:55:01,135] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:55:01,137] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.7795683e-13 1.0000000e+00 5.4461817e-32 9.3585895e-36 1.5812491e-35], sampled 0.9858712629912657
[2019-03-23 11:55:02,310] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01867063], dtype=float32), 0.22413556]
[2019-03-23 11:55:02,311] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.52991662, 72.47364285500001, 1.0, 2.0, 0.4199962356798799, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 456074.1852288506, 456074.1852288506, 103503.0569944801]
[2019-03-23 11:55:02,313] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:55:02,316] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.5191131e-12 1.0000000e+00 2.2404791e-31 4.5678921e-35 7.6246082e-35], sampled 0.17820318306644733
[2019-03-23 11:55:09,412] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01867063], dtype=float32), 0.22413556]
[2019-03-23 11:55:09,414] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.70352635666667, 74.86018355, 1.0, 2.0, 0.5688755330598627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 646028.6461254754, 646028.6461254754, 156905.8827488892]
[2019-03-23 11:55:09,415] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:55:09,418] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.82641943e-13 1.00000000e+00 6.39061251e-33 8.47554009e-37
 1.45826535e-36], sampled 0.9681795892287157
[2019-03-23 11:55:26,294] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01867063], dtype=float32), 0.22413556]
[2019-03-23 11:55:26,295] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.5, 87.16666666666666, 1.0, 2.0, 0.4141306504378265, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 469331.0836783571, 469331.0836783567, 132037.198574775]
[2019-03-23 11:55:26,295] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:55:26,299] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.6374198e-13 1.0000000e+00 1.7369366e-32 2.5995795e-36 4.4354816e-36], sampled 0.39254671960218057
[2019-03-23 11:55:33,303] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01867063], dtype=float32), 0.22413556]
[2019-03-23 11:55:33,306] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.403931365, 83.66877135666667, 1.0, 2.0, 0.4085777373559155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 464077.4034734014, 464077.4034734011, 132278.881090398]
[2019-03-23 11:55:33,307] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:55:33,310] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.3639071e-13 1.0000000e+00 3.4599818e-32 5.6282324e-36 9.5463020e-36], sampled 0.9091610828589985
[2019-03-23 11:55:35,562] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01867063], dtype=float32), 0.22413556]
[2019-03-23 11:55:35,563] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.672034295, 95.08757560500001, 1.0, 2.0, 0.3476863072303856, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 385411.1113601925, 385411.1113601925, 121672.2633379852]
[2019-03-23 11:55:35,563] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:55:35,566] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.87794267e-13 1.00000000e+00 1.19585634e-32 1.71082660e-36
 2.92849999e-36], sampled 0.2860862682939048
[2019-03-23 11:55:38,040] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01867063], dtype=float32), 0.22413556]
[2019-03-23 11:55:38,043] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.1, 55.66666666666667, 1.0, 2.0, 0.9962975854050643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.67503668133988, 6.9112, 95.55144232598418, 1442718.908963236, 1136178.983228458, 223849.7367931588]
[2019-03-23 11:55:38,043] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:55:38,047] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.4492187e-13 1.0000000e+00 3.5584741e-32 5.8100380e-36 9.8404712e-36], sampled 0.7011235035590829
[2019-03-23 11:55:38,048] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1442718.908963236 W.
[2019-03-23 11:55:42,012] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01867063], dtype=float32), 0.22413556]
[2019-03-23 11:55:42,013] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.9, 66.0, 1.0, 2.0, 0.4674025274647167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 532997.8038878143, 532997.8038878139, 140447.0938691401]
[2019-03-23 11:55:42,017] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:55:42,022] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.9973135e-13 1.0000000e+00 3.4034676e-33 4.1825930e-37 7.2351475e-37], sampled 0.4880859953553097
[2019-03-23 11:55:43,202] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01867063], dtype=float32), 0.22413556]
[2019-03-23 11:55:43,205] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.1, 58.0, 1.0, 2.0, 0.4916745493592389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 560967.9087162757, 560967.9087162757, 144591.7508609286]
[2019-03-23 11:55:43,207] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:55:43,208] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.9198670e-13 1.0000000e+00 3.1811544e-33 3.8775736e-37 6.7113573e-37], sampled 0.26983337984491684
[2019-03-23 11:55:45,383] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01867063], dtype=float32), 0.22413556]
[2019-03-23 11:55:45,384] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.95230852333333, 43.86282089666666, 1.0, 2.0, 0.3796181526596724, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 427466.413407308, 427466.413407308, 127197.0813922943]
[2019-03-23 11:55:45,386] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:55:45,389] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.0304243e-13 1.0000000e+00 1.2944898e-32 1.8697517e-36 3.1977816e-36], sampled 0.023257891406781472
[2019-03-23 11:55:47,379] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01867063], dtype=float32), 0.22413556]
[2019-03-23 11:55:47,382] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.3, 87.0, 1.0, 2.0, 0.4984035763426871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 568672.1660594037, 568672.1660594033, 145042.4378553849]
[2019-03-23 11:55:47,383] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:55:47,386] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.5111123e-13 1.0000000e+00 5.1187298e-33 6.6089711e-37 1.1393345e-36], sampled 0.6348641698454127
[2019-03-23 11:55:55,743] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01867063], dtype=float32), 0.22413556]
[2019-03-23 11:55:55,744] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.53189211666667, 76.89732554666666, 1.0, 2.0, 0.4198987429291552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 477373.1785076605, 477373.1785076601, 133735.3931333183]
[2019-03-23 11:55:55,746] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:55:55,749] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.9571717e-13 1.0000000e+00 3.2869463e-33 4.0225136e-37 6.9604687e-37], sampled 0.9898329916387111
[2019-03-23 11:56:25,439] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.1204 1705935497.0665 465.0000
[2019-03-23 11:56:25,738] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:56:25,805] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:56:25,895] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:56:25,972] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:56:26,986] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 200000, evaluation results [200000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.120377555595, 1705935497.0665214, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:56:27,115] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12500, global step 200067: loss 0.3734
[2019-03-23 11:56:27,117] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12500, global step 200067: learning rate 0.0001
[2019-03-23 11:56:27,141] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12500, global step 200079: loss 0.5691
[2019-03-23 11:56:27,145] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12500, global step 200080: learning rate 0.0001
[2019-03-23 11:56:27,249] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12500, global step 200141: loss 0.4533
[2019-03-23 11:56:27,250] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12500, global step 200141: learning rate 0.0001
[2019-03-23 11:56:27,255] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12500, global step 200141: loss 0.0590
[2019-03-23 11:56:27,258] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12500, global step 200142: learning rate 0.0001
[2019-03-23 11:56:27,301] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12500, global step 200161: loss 0.0149
[2019-03-23 11:56:27,303] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12500, global step 200163: learning rate 0.0001
[2019-03-23 11:56:27,305] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12500, global step 200163: loss 0.0062
[2019-03-23 11:56:27,308] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12500, global step 200164: learning rate 0.0001
[2019-03-23 11:56:27,540] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12500, global step 200294: loss 0.0759
[2019-03-23 11:56:27,542] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12500, global step 200294: learning rate 0.0001
[2019-03-23 11:56:27,653] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12500, global step 200355: loss 0.0132
[2019-03-23 11:56:27,656] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12500, global step 200355: learning rate 0.0001
[2019-03-23 11:56:27,893] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12500, global step 200485: loss 0.0767
[2019-03-23 11:56:27,895] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12500, global step 200485: learning rate 0.0001
[2019-03-23 11:56:29,346] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4751712e-13 1.0000000e+00 3.6722726e-32 1.9567874e-35 5.2201831e-34], sum to 1.0000
[2019-03-23 11:56:29,354] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2679
[2019-03-23 11:56:29,363] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 84.0, 1.0, 2.0, 0.4518674083026405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 515287.0565600228, 515287.0565600228, 134400.1957703291], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7549200.0000, 
sim time next is 7549800.0000, 
raw observation next is [22.56666666666667, 82.66666666666667, 1.0, 2.0, 0.4558990839251063, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 520034.6652802475, 520034.6652802475, 135149.133369795], 
processed observation next is [0.0, 0.391304347826087, 0.6621212121212122, 0.8266666666666667, 1.0, 1.0, 0.31987385490638287, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19260543158527685, 0.19260543158527685, 0.32963203260925605], 
reward next is 0.6704, 
noisyNet noise sample is [array([-1.1173768], dtype=float32), 0.83238167]. 
=============================================
[2019-03-23 11:56:32,263] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.4018860e-09 1.0000000e+00 1.7711690e-23 1.9710232e-26 7.2958017e-26], sum to 1.0000
[2019-03-23 11:56:32,273] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1871
[2019-03-23 11:56:32,278] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 93.5, 1.0, 2.0, 0.4230213821287263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 480336.8482734638, 480336.8482734638, 129214.9440404725], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7593000.0000, 
sim time next is 7593600.0000, 
raw observation next is [20.0, 94.0, 1.0, 2.0, 0.4260671260385807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 483981.3286240124, 483981.3286240124, 129656.836226231], 
processed observation next is [0.0, 0.9130434782608695, 0.5454545454545454, 0.94, 1.0, 1.0, 0.2825839075482259, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17925234393481942, 0.17925234393481942, 0.3162361859176366], 
reward next is 0.6838, 
noisyNet noise sample is [array([-0.85056746], dtype=float32), -0.25782338]. 
=============================================
[2019-03-23 11:56:33,167] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0226241e-10 1.0000000e+00 3.5274423e-25 3.2715949e-27 8.6414589e-28], sum to 1.0000
[2019-03-23 11:56:33,174] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7350
[2019-03-23 11:56:33,184] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 94.5, 1.0, 2.0, 0.4318154683578737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 490696.7239299174, 490696.7239299174, 130371.1750866841], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7615800.0000, 
sim time next is 7616400.0000, 
raw observation next is [20.0, 95.0, 1.0, 2.0, 0.4371515542969703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 496928.5729396286, 496928.5729396286, 131040.9995464398], 
processed observation next is [1.0, 0.13043478260869565, 0.5454545454545454, 0.95, 1.0, 1.0, 0.2964394428712128, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18404761960726987, 0.18404761960726987, 0.31961219401570684], 
reward next is 0.6804, 
noisyNet noise sample is [array([0.39639208], dtype=float32), -0.75243044]. 
=============================================
[2019-03-23 11:56:33,504] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.2739950e-10 1.0000000e+00 1.1200944e-26 1.3402751e-27 8.4427617e-28], sum to 1.0000
[2019-03-23 11:56:33,504] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4973
[2019-03-23 11:56:33,510] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 96.0, 1.0, 2.0, 0.4240610457940981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482368.5813880055, 482368.5813880055, 130032.7063656572], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7622400.0000, 
sim time next is 7623000.0000, 
raw observation next is [20.0, 96.0, 1.0, 2.0, 0.4216850355447413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 479658.8914842218, 479658.8914842221, 129792.5745921892], 
processed observation next is [1.0, 0.21739130434782608, 0.5454545454545454, 0.96, 1.0, 1.0, 0.2771062944309266, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17765144129045252, 0.17765144129045263, 0.31656725510290046], 
reward next is 0.6834, 
noisyNet noise sample is [array([-0.9047201], dtype=float32), -0.12368172]. 
=============================================
[2019-03-23 11:56:33,550] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[64.18132 ]
 [64.14542 ]
 [64.110146]
 [64.057884]
 [64.029175]], R is [[64.22917175]
 [64.26972961]
 [64.30741882]
 [64.34442139]
 [64.3790741 ]].
[2019-03-23 11:56:33,990] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.9232752e-08 1.0000000e+00 1.0749123e-22 1.1171165e-25 9.6409163e-26], sum to 1.0000
[2019-03-23 11:56:33,998] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2637
[2019-03-23 11:56:34,003] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1177266.669369559 W.
[2019-03-23 11:56:34,008] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.33333333333334, 72.66666666666667, 1.0, 2.0, 0.5532668211977966, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9724276908953929, 6.918375241232097, 6.9112, 77.32844584153982, 1177266.669369559, 1174936.298306891, 269727.8103490603], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7641600.0000, 
sim time next is 7642200.0000, 
raw observation next is [25.41666666666666, 72.33333333333333, 1.0, 2.0, 0.345091533613667, 1.0, 1.0, 0.345091533613667, 1.0, 2.0, 0.6985972669389308, 6.911200000000001, 6.9112, 77.3421103, 1171579.503299832, 1171579.503299832, 279586.5126663932], 
processed observation next is [1.0, 0.43478260869565216, 0.7916666666666664, 0.7233333333333333, 1.0, 1.0, 0.18136441701708375, 1.0, 0.5, 0.18136441701708375, 1.0, 1.0, 0.5694246670556155, 8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4339183345554934, 0.4339183345554934, 0.6819183235765688], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9294429], dtype=float32), 0.15553883]. 
=============================================
[2019-03-23 11:56:34,217] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.2890551e-07 9.9999964e-01 2.3708688e-18 6.8067859e-20 1.6284342e-19], sum to 1.0000
[2019-03-23 11:56:34,225] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7001
[2019-03-23 11:56:34,231] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1229062.99451231 W.
[2019-03-23 11:56:34,237] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.08333333333334, 73.66666666666667, 1.0, 2.0, 0.5419236408418017, 1.0, 1.0, 0.5419236408418017, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32845660745335, 1229062.99451231, 1229062.99451231, 243322.1064510644], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7639800.0000, 
sim time next is 7640400.0000, 
raw observation next is [25.16666666666667, 73.33333333333334, 1.0, 2.0, 0.3532477479283825, 1.0, 2.0, 0.3532477479283825, 1.0, 1.0, 0.7150191916041659, 6.911199999999999, 6.9112, 77.3421103, 1198751.463969036, 1198751.463969036, 283200.8732800389], 
processed observation next is [1.0, 0.43478260869565216, 0.7803030303030305, 0.7333333333333334, 1.0, 1.0, 0.1915596849104781, 1.0, 1.0, 0.1915596849104781, 1.0, 0.5, 0.5928845594345228, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.44398202369223555, 0.44398202369223555, 0.6907338372683876], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.60210234], dtype=float32), 0.82360035]. 
=============================================
[2019-03-23 11:56:34,315] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6000299e-06 9.9999845e-01 6.5141889e-17 1.8868044e-18 7.2371898e-19], sum to 1.0000
[2019-03-23 11:56:34,323] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3520
[2019-03-23 11:56:34,327] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1216072.333885675 W.
[2019-03-23 11:56:34,330] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.46666666666667, 54.33333333333334, 1.0, 2.0, 0.5365567505544053, 1.0, 2.0, 0.5365567505544053, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1216072.333885675, 1216072.333885675, 242239.3654699791], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7658400.0000, 
sim time next is 7659000.0000, 
raw observation next is [28.55, 54.0, 1.0, 2.0, 0.3494699274546344, 1.0, 2.0, 0.3494699274546344, 1.0, 1.0, 0.7075430695152096, 6.911199999999999, 6.9112, 77.3421103, 1186998.823343261, 1186998.823343261, 281183.3517548234], 
processed observation next is [1.0, 0.6521739130434783, 0.9340909090909091, 0.54, 1.0, 1.0, 0.18683740931829299, 1.0, 1.0, 0.18683740931829299, 1.0, 0.5, 0.5822043850217281, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4396291938308374, 0.4396291938308374, 0.6858130530605449], 
reward next is 0.3142, 
noisyNet noise sample is [array([-1.1443564], dtype=float32), 0.4489491]. 
=============================================
[2019-03-23 11:56:34,346] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[40.379726]
 [40.384087]
 [40.458965]
 [40.301914]
 [40.89568 ]], R is [[40.42944336]
 [40.43432236]
 [40.40042114]
 [39.996418  ]
 [39.91281891]].
[2019-03-23 11:56:40,498] A3C_AGENT_WORKER-Thread-11 INFO:Local step 13000, global step 207290: loss 0.0970
[2019-03-23 11:56:40,501] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 13000, global step 207290: learning rate 0.0001
[2019-03-23 11:56:40,619] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1530372e-10 1.0000000e+00 2.6033910e-28 1.1152561e-32 3.1578226e-31], sum to 1.0000
[2019-03-23 11:56:40,630] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2399
[2019-03-23 11:56:40,636] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.03333333333333, 85.0, 1.0, 2.0, 0.2120414031151464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 230223.0367097669, 230223.0367097666, 73722.67349463065], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7791600.0000, 
sim time next is 7792200.0000, 
raw observation next is [13.85, 87.0, 1.0, 2.0, 0.2044377948394141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221965.5682086248, 221965.5682086245, 72969.25750119155], 
processed observation next is [1.0, 0.17391304347826086, 0.2659090909090909, 0.87, 1.0, 1.0, 0.005547243549267611, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08220946970689808, 0.08220946970689796, 0.177973798783394], 
reward next is 0.8220, 
noisyNet noise sample is [array([-1.3417622], dtype=float32), -0.7291081]. 
=============================================
[2019-03-23 11:56:41,044] A3C_AGENT_WORKER-Thread-21 INFO:Local step 13000, global step 207562: loss 0.0123
[2019-03-23 11:56:41,050] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 13000, global step 207564: learning rate 0.0001
[2019-03-23 11:56:41,283] A3C_AGENT_WORKER-Thread-15 INFO:Local step 13000, global step 207687: loss 0.5214
[2019-03-23 11:56:41,284] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 13000, global step 207687: learning rate 0.0001
[2019-03-23 11:56:41,341] A3C_AGENT_WORKER-Thread-2 INFO:Local step 13000, global step 207711: loss 0.8716
[2019-03-23 11:56:41,345] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 13000, global step 207713: learning rate 0.0001
[2019-03-23 11:56:41,414] A3C_AGENT_WORKER-Thread-14 INFO:Local step 13000, global step 207751: loss 0.9092
[2019-03-23 11:56:41,419] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 13000, global step 207754: learning rate 0.0001
[2019-03-23 11:56:41,488] A3C_AGENT_WORKER-Thread-9 INFO:Local step 13000, global step 207788: loss 0.6547
[2019-03-23 11:56:41,488] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 13000, global step 207788: learning rate 0.0001
[2019-03-23 11:56:41,695] A3C_AGENT_WORKER-Thread-3 INFO:Local step 13000, global step 207886: loss 0.0472
[2019-03-23 11:56:41,697] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 13000, global step 207887: learning rate 0.0001
[2019-03-23 11:56:42,084] A3C_AGENT_WORKER-Thread-12 INFO:Local step 13000, global step 208083: loss 0.5113
[2019-03-23 11:56:42,085] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 13000, global step 208083: learning rate 0.0001
[2019-03-23 11:56:42,158] A3C_AGENT_WORKER-Thread-18 INFO:Local step 13000, global step 208123: loss 0.6453
[2019-03-23 11:56:42,163] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 13000, global step 208124: learning rate 0.0001
[2019-03-23 11:56:42,195] A3C_AGENT_WORKER-Thread-17 INFO:Local step 13000, global step 208139: loss 0.8375
[2019-03-23 11:56:42,198] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 13000, global step 208140: learning rate 0.0001
[2019-03-23 11:56:42,203] A3C_AGENT_WORKER-Thread-19 INFO:Local step 13000, global step 208143: loss 0.8421
[2019-03-23 11:56:42,206] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 13000, global step 208143: learning rate 0.0001
[2019-03-23 11:56:42,211] A3C_AGENT_WORKER-Thread-10 INFO:Local step 13000, global step 208145: loss 0.8933
[2019-03-23 11:56:42,212] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 13000, global step 208145: learning rate 0.0001
[2019-03-23 11:56:42,438] A3C_AGENT_WORKER-Thread-20 INFO:Local step 13000, global step 208259: loss 0.3284
[2019-03-23 11:56:42,439] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 13000, global step 208259: learning rate 0.0001
[2019-03-23 11:56:42,486] A3C_AGENT_WORKER-Thread-13 INFO:Local step 13000, global step 208282: loss 0.2723
[2019-03-23 11:56:42,490] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 13000, global step 208283: learning rate 0.0001
[2019-03-23 11:56:42,607] A3C_AGENT_WORKER-Thread-16 INFO:Local step 13000, global step 208341: loss 0.1161
[2019-03-23 11:56:42,609] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 13000, global step 208342: learning rate 0.0001
[2019-03-23 11:56:43,119] A3C_AGENT_WORKER-Thread-22 INFO:Local step 13000, global step 208599: loss 0.8798
[2019-03-23 11:56:43,122] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 13000, global step 208599: learning rate 0.0001
[2019-03-23 11:56:44,909] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7713622e-11 1.0000000e+00 1.3093245e-24 1.1352264e-28 9.9977544e-30], sum to 1.0000
[2019-03-23 11:56:44,914] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2905
[2019-03-23 11:56:44,921] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 68.33333333333334, 1.0, 2.0, 0.2739158470385495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 297423.4878119642, 297423.4878119639, 95807.72775943864], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7866600.0000, 
sim time next is 7867200.0000, 
raw observation next is [18.8, 68.66666666666667, 1.0, 2.0, 0.2764602041000775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 300187.0559402162, 300187.0559402165, 96651.76065446125], 
processed observation next is [1.0, 0.043478260869565216, 0.49090909090909096, 0.6866666666666668, 1.0, 1.0, 0.09557525512509685, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11118039108896895, 0.11118039108896909, 0.23573600159624694], 
reward next is 0.7643, 
noisyNet noise sample is [array([-0.534017], dtype=float32), 0.53038234]. 
=============================================
[2019-03-23 11:56:48,122] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.1460713e-11 1.0000000e+00 1.1663222e-28 1.4893690e-32 9.2826930e-33], sum to 1.0000
[2019-03-23 11:56:48,130] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3096
[2019-03-23 11:56:48,136] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.8, 93.0, 1.0, 2.0, 0.85570259865617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 975969.569644999, 975969.5696449992, 188306.8384008958], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7911000.0000, 
sim time next is 7911600.0000, 
raw observation next is [20.9, 93.0, 1.0, 2.0, 0.8741729395362463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 997348.673033981, 997348.673033981, 191859.0089857454], 
processed observation next is [1.0, 0.5652173913043478, 0.5863636363636363, 0.93, 1.0, 1.0, 0.8427161744203079, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.36938839741999296, 0.36938839741999296, 0.46794880240425707], 
reward next is 0.5321, 
noisyNet noise sample is [array([-0.8990907], dtype=float32), 0.77607965]. 
=============================================
[2019-03-23 11:56:49,459] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:56:49,461] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:56:49,483] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run2
[2019-03-23 11:56:50,020] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:56:50,020] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:56:50,022] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run2
[2019-03-23 11:56:50,090] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:56:50,090] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:56:50,092] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run2
[2019-03-23 11:56:50,235] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:56:50,235] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:56:50,237] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run2
[2019-03-23 11:56:50,300] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:56:50,301] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:56:50,302] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run2
[2019-03-23 11:56:50,322] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:56:50,323] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:56:50,324] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run2
[2019-03-23 11:56:50,384] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:56:50,384] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:56:50,385] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run2
[2019-03-23 11:56:50,587] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:56:50,587] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:56:50,588] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run2
[2019-03-23 11:56:50,676] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:56:50,676] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:56:50,677] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run2
[2019-03-23 11:56:50,704] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:56:50,704] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:56:50,705] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:56:50,705] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:56:50,706] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:56:50,706] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:56:50,708] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run2
[2019-03-23 11:56:50,733] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run2
[2019-03-23 11:56:50,763] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:56:50,764] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:56:50,767] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:56:50,764] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:56:50,770] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run2
[2019-03-23 11:56:50,767] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run2
[2019-03-23 11:56:50,769] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run2
[2019-03-23 11:56:50,862] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:56:50,862] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:56:50,863] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run2
[2019-03-23 11:56:50,915] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:56:50,916] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:56:50,925] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run2
[2019-03-23 11:56:52,366] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0044800e-13 1.0000000e+00 3.1387272e-31 5.9779751e-38 6.1724495e-36], sum to 1.0000
[2019-03-23 11:56:52,372] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9230
[2019-03-23 11:56:52,376] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 96.0, 1.0, 2.0, 0.3762663823024679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 418037.4442851447, 418037.4442851447, 119998.9193312236], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 16800.0000, 
sim time next is 17400.0000, 
raw observation next is [17.83333333333333, 95.0, 1.0, 2.0, 0.3719317731145442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 413550.0066918425, 413550.0066918425, 119779.3988300858], 
processed observation next is [1.0, 0.17391304347826086, 0.44696969696969674, 0.95, 1.0, 1.0, 0.2149147163931802, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15316666914512686, 0.15316666914512686, 0.2921448751953312], 
reward next is 0.7079, 
noisyNet noise sample is [array([1.4487641], dtype=float32), 1.3000578]. 
=============================================
[2019-03-23 11:56:53,966] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.2869820e-10 1.0000000e+00 1.8587166e-19 3.4527969e-24 9.6982894e-23], sum to 1.0000
[2019-03-23 11:56:53,972] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2321
[2019-03-23 11:56:53,975] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 78.0, 1.0, 2.0, 0.8597982769009191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 971353.5013658251, 971353.5013658251, 181421.8139209944], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 48600.0000, 
sim time next is 49200.0000, 
raw observation next is [21.0, 78.0, 1.0, 2.0, 0.863199695028125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 975334.7890800295, 975334.7890800295, 182018.7180024419], 
processed observation next is [1.0, 0.5652173913043478, 0.5909090909090909, 0.78, 1.0, 1.0, 0.8289996187851562, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3612351070666776, 0.3612351070666776, 0.4439480926888827], 
reward next is 0.5561, 
noisyNet noise sample is [array([0.20204881], dtype=float32), -2.4805799]. 
=============================================
[2019-03-23 11:56:56,766] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.9728802e-12 1.0000000e+00 1.7872839e-28 3.6086824e-33 3.3551125e-34], sum to 1.0000
[2019-03-23 11:56:56,774] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0252
[2019-03-23 11:56:56,779] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 43.0, 1.0, 2.0, 0.3012090195589224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 327068.9442233415, 327068.9442233415, 90462.14327483665], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 150000.0000, 
sim time next is 150600.0000, 
raw observation next is [22.0, 43.0, 1.0, 2.0, 0.3007543987416282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 326575.1267468068, 326575.1267468071, 90420.937106148], 
processed observation next is [1.0, 0.7391304347826086, 0.6363636363636364, 0.43, 1.0, 1.0, 0.1259429984270352, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12095375064696548, 0.12095375064696558, 0.2205388709906049], 
reward next is 0.7795, 
noisyNet noise sample is [array([-0.66403246], dtype=float32), -1.3219953]. 
=============================================
[2019-03-23 11:56:58,168] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.3927049e-12 1.0000000e+00 1.3728874e-25 3.9747866e-29 4.8383991e-30], sum to 1.0000
[2019-03-23 11:56:58,178] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8795
[2019-03-23 11:56:58,184] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 79.5, 1.0, 2.0, 0.2164002898243642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 234956.8221804311, 234956.8221804308, 72691.25004909304], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 109800.0000, 
sim time next is 110400.0000, 
raw observation next is [14.0, 80.33333333333333, 1.0, 2.0, 0.2121876760718933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 230381.8895516047, 230381.8895516044, 72480.35998054636], 
processed observation next is [1.0, 0.2608695652173913, 0.2727272727272727, 0.8033333333333332, 1.0, 1.0, 0.015234595089866597, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08532662575985359, 0.08532662575985347, 0.17678136580621062], 
reward next is 0.8232, 
noisyNet noise sample is [array([-0.08142877], dtype=float32), 0.18275264]. 
=============================================
[2019-03-23 11:57:01,448] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.4728853e-11 1.0000000e+00 1.2651457e-23 1.8399370e-27 8.1503207e-29], sum to 1.0000
[2019-03-23 11:57:01,457] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5605
[2019-03-23 11:57:01,464] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.66666666666667, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 211020.3423804344, 211020.3423804347, 71690.96046971813], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 186000.0000, 
sim time next is 186600.0000, 
raw observation next is [13.83333333333333, 89.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 212779.0505135553, 212779.050513555, 72165.63061804546], 
processed observation next is [0.0, 0.13043478260869565, 0.265151515151515, 0.89, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07880705574576122, 0.0788070557457611, 0.176013733214745], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.73527735], dtype=float32), 1.1423111]. 
=============================================
[2019-03-23 11:57:03,371] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3179886e-17 1.0000000e+00 1.2714032e-35 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 11:57:03,383] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5331
[2019-03-23 11:57:03,389] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 71.33333333333333, 1.0, 2.0, 0.2565219037470286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 278531.3763952542, 278531.3763952539, 89904.25207089241], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 222000.0000, 
sim time next is 222600.0000, 
raw observation next is [17.0, 76.66666666666667, 1.0, 2.0, 0.2502631652843804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 271733.7423242621, 271733.7423242621, 86592.91608199707], 
processed observation next is [0.0, 0.5652173913043478, 0.4090909090909091, 0.7666666666666667, 1.0, 1.0, 0.06282895660547551, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10064212678676374, 0.10064212678676374, 0.2112022343463343], 
reward next is 0.7888, 
noisyNet noise sample is [array([1.0828843], dtype=float32), 0.82524014]. 
=============================================
[2019-03-23 11:57:11,980] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.0777280e-16 1.0000000e+00 2.4273513e-34 0.0000000e+00 6.5315973e-38], sum to 1.0000
[2019-03-23 11:57:11,987] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9245
[2019-03-23 11:57:11,994] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333334, 62.66666666666667, 1.0, 2.0, 0.2955363642879061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 320907.2378513027, 320907.2378513027, 84091.03618055861], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 382800.0000, 
sim time next is 383400.0000, 
raw observation next is [17.5, 60.0, 1.0, 2.0, 0.3023002732548105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 328254.2860647654, 328254.2860647654, 84037.21170550282], 
processed observation next is [1.0, 0.43478260869565216, 0.4318181818181818, 0.6, 1.0, 1.0, 0.12787534156851313, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12157566150546867, 0.12157566150546867, 0.20496880903781176], 
reward next is 0.7950, 
noisyNet noise sample is [array([-1.644549], dtype=float32), -0.28546205]. 
=============================================
[2019-03-23 11:57:14,176] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.6675645e-15 1.0000000e+00 6.1468365e-29 2.5434736e-34 7.6726419e-33], sum to 1.0000
[2019-03-23 11:57:14,182] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3837
[2019-03-23 11:57:14,188] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 212313.4768847729, 212313.4768847729, 72810.04844572564], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 429600.0000, 
sim time next is 430200.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 210937.9063881089, 210937.9063881086, 72559.69190559353], 
processed observation next is [1.0, 1.0, 0.22727272727272727, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07812515051411441, 0.0781251505141143, 0.17697485830632567], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6925772], dtype=float32), 1.3673308]. 
=============================================
[2019-03-23 11:57:17,499] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 11:57:17,500] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:57:17,500] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:57:17,502] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:57:17,502] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:57:17,503] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:57:17,504] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:57:17,504] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:57:17,506] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:57:17,505] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:57:17,508] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:57:17,520] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run10
[2019-03-23 11:57:17,544] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run10
[2019-03-23 11:57:17,544] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run10
[2019-03-23 11:57:17,608] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run10
[2019-03-23 11:57:17,641] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run10
[2019-03-23 11:57:35,217] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02011629], dtype=float32), 0.19682099]
[2019-03-23 11:57:35,219] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.0, 65.0, 1.0, 2.0, 0.6637517414774275, 1.0, 1.0, 0.6637517414774275, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32712455748386, 1505789.173129563, 1505789.173129562, 277100.340806424]
[2019-03-23 11:57:35,221] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:57:35,225] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.2523293e-13 1.0000000e+00 4.6005420e-27 7.1498098e-32 3.6439885e-31], sampled 0.7287306204190488
[2019-03-23 11:57:35,227] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1505789.173129563 W.
[2019-03-23 11:57:53,899] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02011629], dtype=float32), 0.19682099]
[2019-03-23 11:57:53,900] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.750439, 45.266080335, 1.0, 2.0, 0.4113174970251703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 467159.5487201267, 467159.5487201264, 132515.1820048337]
[2019-03-23 11:57:53,900] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:57:53,902] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.5369730e-12 1.0000000e+00 6.9976467e-26 1.7920338e-30 8.4491322e-30], sampled 0.3797265073766297
[2019-03-23 11:57:57,829] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02011629], dtype=float32), 0.19682099]
[2019-03-23 11:57:57,831] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.9, 66.0, 1.0, 2.0, 0.3024518121772629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 328397.7420755603, 328397.7420755599, 115661.7294504767]
[2019-03-23 11:57:57,833] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:57:57,837] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.9924882e-12 1.0000000e+00 2.8721587e-25 9.5315574e-30 4.3165326e-29], sampled 0.06942061674255329
[2019-03-23 11:58:14,537] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02011629], dtype=float32), 0.19682099]
[2019-03-23 11:58:14,539] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [31.1, 47.0, 1.0, 2.0, 0.8934407621810478, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9804189669507677, 6.911199999999999, 6.9112, 95.55338769695034, 1559620.833213373, 1559620.833213374, 331811.777281737]
[2019-03-23 11:58:14,540] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:58:14,543] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.0661631e-14 1.0000000e+00 7.5909340e-30 3.6411744e-35 2.2301323e-34], sampled 0.41725582177444276
[2019-03-23 11:58:14,544] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1559620.833213373 W.
[2019-03-23 11:58:20,049] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02011629], dtype=float32), 0.19682099]
[2019-03-23 11:58:20,050] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.26666666666667, 68.33333333333333, 1.0, 2.0, 0.6734356691718936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 768453.7190727853, 768453.7190727853, 167931.2044334711]
[2019-03-23 11:58:20,051] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:58:20,053] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.5500776e-13 1.0000000e+00 1.5534015e-26 3.0186227e-31 1.4858521e-30], sampled 0.23069781014082236
[2019-03-23 11:58:56,263] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:58:56,708] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:58:56,746] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:58:56,815] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:58:56,893] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:58:57,907] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 225000, evaluation results [225000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:58:59,703] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.9061216e-13 1.0000000e+00 3.6825506e-27 9.9009303e-31 1.1317882e-29], sum to 1.0000
[2019-03-23 11:58:59,709] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8583
[2019-03-23 11:58:59,714] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2113531228743362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 229475.5631316004, 229475.5631316007, 76315.13108417443], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 525600.0000, 
sim time next is 526200.0000, 
raw observation next is [14.0, 94.00000000000001, 1.0, 2.0, 0.3173934474545601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 344649.0935711113, 344649.093571111, 86777.45854598637], 
processed observation next is [1.0, 0.08695652173913043, 0.2727272727272727, 0.9400000000000002, 1.0, 1.0, 0.1467418093182001, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12764781243374493, 0.12764781243374482, 0.21165233791703994], 
reward next is 0.7883, 
noisyNet noise sample is [array([0.20063643], dtype=float32), -1.4812522]. 
=============================================
[2019-03-23 11:59:12,947] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.9794603e-10 1.0000000e+00 1.4053509e-21 3.0338456e-26 2.8857659e-25], sum to 1.0000
[2019-03-23 11:59:12,956] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6528
[2019-03-23 11:59:12,961] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.16666666666666, 68.33333333333333, 1.0, 2.0, 0.4484341315880381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 510962.4249191852, 510962.4249191849, 133408.1172150331], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 769800.0000, 
sim time next is 770400.0000, 
raw observation next is [24.0, 69.0, 1.0, 2.0, 0.447266419868536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 509534.9790229174, 509534.9790229177, 133164.5828869649], 
processed observation next is [1.0, 0.9565217391304348, 0.7272727272727273, 0.69, 1.0, 1.0, 0.30908302483566996, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18871665889737682, 0.18871665889737693, 0.3247916655779632], 
reward next is 0.6752, 
noisyNet noise sample is [array([-0.10746843], dtype=float32), -0.61949986]. 
=============================================
[2019-03-23 11:59:14,403] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0553550e-13 1.0000000e+00 2.1699707e-26 5.0345124e-32 2.0298194e-30], sum to 1.0000
[2019-03-23 11:59:14,415] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3587
[2019-03-23 11:59:14,425] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.00000000000001, 1.0, 2.0, 0.3863486345789148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 435344.8144455772, 435344.8144455772, 123619.7698330344], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 796200.0000, 
sim time next is 796800.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.3857514582467097, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 434671.0595375159, 434671.0595375162, 123566.6399241136], 
processed observation next is [0.0, 0.21739130434782608, 0.5, 0.94, 1.0, 1.0, 0.2321893228083871, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16098928131019108, 0.1609892813101912, 0.301382048595399], 
reward next is 0.6986, 
noisyNet noise sample is [array([0.4367351], dtype=float32), 0.81321734]. 
=============================================
[2019-03-23 11:59:15,108] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3606954e-13 1.0000000e+00 1.1455730e-25 2.7197519e-32 1.7936145e-29], sum to 1.0000
[2019-03-23 11:59:15,119] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5597
[2019-03-23 11:59:15,128] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 64.66666666666667, 1.0, 2.0, 0.615723996910011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 691919.2786708378, 691919.2786708378, 161104.503073487], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 821400.0000, 
sim time next is 822000.0000, 
raw observation next is [29.0, 63.33333333333334, 1.0, 2.0, 0.6078150759707359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 683025.3898620945, 683025.3898620945, 159985.2932722404], 
processed observation next is [0.0, 0.5217391304347826, 0.9545454545454546, 0.6333333333333334, 1.0, 1.0, 0.5097688449634199, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2529723666155906, 0.2529723666155906, 0.39020803237131807], 
reward next is 0.6098, 
noisyNet noise sample is [array([-0.02820921], dtype=float32), -0.3416675]. 
=============================================
[2019-03-23 11:59:15,141] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[75.14566 ]
 [75.128235]
 [75.094   ]
 [75.07897 ]
 [75.066055]], R is [[75.01538086]
 [74.87229156]
 [74.72941589]
 [74.58937836]
 [74.452034  ]].
[2019-03-23 11:59:15,588] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.8913983e-13 1.0000000e+00 2.4516158e-23 2.2316966e-28 1.1341751e-27], sum to 1.0000
[2019-03-23 11:59:15,596] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4508
[2019-03-23 11:59:15,601] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 55.0, 1.0, 2.0, 0.5294879349153251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 602258.2946211068, 602258.2946211066, 147073.5223574445], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 838800.0000, 
sim time next is 839400.0000, 
raw observation next is [28.83333333333334, 55.5, 1.0, 2.0, 0.528347238282994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 601082.5276543102, 601082.5276543105, 146855.818852916], 
processed observation next is [0.0, 0.7391304347826086, 0.9469696969696972, 0.555, 1.0, 1.0, 0.4104340478537425, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22262315839048527, 0.22262315839048535, 0.3581849240315025], 
reward next is 0.6418, 
noisyNet noise sample is [array([0.777338], dtype=float32), 0.64261115]. 
=============================================
[2019-03-23 11:59:16,111] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.5933795e-12 1.0000000e+00 6.0377451e-23 2.5338964e-26 4.6008626e-25], sum to 1.0000
[2019-03-23 11:59:16,121] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6693
[2019-03-23 11:59:16,128] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 55.0, 1.0, 2.0, 0.5336345575523909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 606974.566482652, 606974.566482652, 147590.8509209655], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 834000.0000, 
sim time next is 834600.0000, 
raw observation next is [29.0, 55.0, 1.0, 2.0, 0.5336630479570863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 607006.2973237018, 607006.2973237014, 147594.8233085036], 
processed observation next is [0.0, 0.6521739130434783, 0.9545454545454546, 0.55, 1.0, 1.0, 0.4170788099463578, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22481714715692658, 0.22481714715692647, 0.35998737392317953], 
reward next is 0.6400, 
noisyNet noise sample is [array([-2.0134022], dtype=float32), -0.6577763]. 
=============================================
[2019-03-23 11:59:16,937] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1380605e-12 1.0000000e+00 7.7952584e-24 2.6859714e-27 3.2441666e-27], sum to 1.0000
[2019-03-23 11:59:16,945] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8420
[2019-03-23 11:59:16,952] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 91.0, 1.0, 2.0, 0.397842992404662, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 448927.8060381822, 448927.8060381825, 124986.4763372672], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 869400.0000, 
sim time next is 870000.0000, 
raw observation next is [19.66666666666666, 90.0, 1.0, 2.0, 0.398400083759033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 449757.1277672657, 449757.1277672654, 125149.6602856817], 
processed observation next is [0.0, 0.043478260869565216, 0.53030303030303, 0.9, 1.0, 1.0, 0.24800010469879125, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16657671398787618, 0.16657671398787607, 0.30524307386751637], 
reward next is 0.6948, 
noisyNet noise sample is [array([-1.0395789], dtype=float32), -0.25903463]. 
=============================================
[2019-03-23 11:59:16,975] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[57.70365 ]
 [57.70837 ]
 [57.652122]
 [57.566067]
 [57.444435]], R is [[57.88181305]
 [57.99814987]
 [58.11376572]
 [58.22864532]
 [58.34220505]].
[2019-03-23 11:59:18,683] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.6764732e-12 1.0000000e+00 6.4139728e-22 4.9238887e-27 5.6794652e-25], sum to 1.0000
[2019-03-23 11:59:18,691] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6057
[2019-03-23 11:59:18,697] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 71.0, 1.0, 2.0, 0.4880959851140848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 556854.3514279993, 556854.3514279993, 140242.4901415783], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 906000.0000, 
sim time next is 906600.0000, 
raw observation next is [25.5, 68.0, 1.0, 2.0, 0.4887756194992752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 557621.4801042372, 557621.4801042369, 140345.0468093229], 
processed observation next is [0.0, 0.4782608695652174, 0.7954545454545454, 0.68, 1.0, 1.0, 0.360969524374094, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20652647411268044, 0.20652647411268032, 0.3423049922178607], 
reward next is 0.6577, 
noisyNet noise sample is [array([-1.5353025], dtype=float32), 1.6551491]. 
=============================================
[2019-03-23 11:59:22,971] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.9631475e-12 1.0000000e+00 1.0848591e-25 1.4705098e-29 1.1812363e-29], sum to 1.0000
[2019-03-23 11:59:22,979] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0712
[2019-03-23 11:59:22,982] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4069752088150342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 461346.7336140961, 461346.7336140964, 127112.2223812859], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 963600.0000, 
sim time next is 964200.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4037840598119037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 457721.0301406559, 457721.0301406559, 126807.5164927755], 
processed observation next is [1.0, 0.13043478260869565, 0.5, 1.0, 1.0, 1.0, 0.2547300747648796, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16952630745950217, 0.16952630745950217, 0.3092866255921354], 
reward next is 0.6907, 
noisyNet noise sample is [array([-0.17221506], dtype=float32), 1.1250427]. 
=============================================
[2019-03-23 11:59:23,791] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.0160840e-14 1.0000000e+00 1.1813226e-28 9.5101102e-34 4.4160560e-33], sum to 1.0000
[2019-03-23 11:59:23,800] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7027
[2019-03-23 11:59:23,804] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.83333333333333, 100.0, 1.0, 2.0, 0.4780995532328934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 519248.7599334788, 519248.7599334788, 124929.4291440418], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 997800.0000, 
sim time next is 998400.0000, 
raw observation next is [15.66666666666667, 100.0, 1.0, 2.0, 0.5438121630107065, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 590660.5034606118, 590660.5034606118, 130914.7005745982], 
processed observation next is [1.0, 0.5652173913043478, 0.3484848484848486, 1.0, 1.0, 1.0, 0.429765203763383, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21876314942985622, 0.21876314942985622, 0.31930414774292243], 
reward next is 0.6807, 
noisyNet noise sample is [array([-0.6258629], dtype=float32), -0.23320125]. 
=============================================
[2019-03-23 11:59:28,766] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6853249e-13 1.0000000e+00 2.2141132e-25 2.3475439e-32 3.5710275e-31], sum to 1.0000
[2019-03-23 11:59:28,771] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3411
[2019-03-23 11:59:28,776] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 67.33333333333334, 1.0, 2.0, 0.4867346610174552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 538798.0574977217, 538798.0574977217, 129056.13834511], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1082400.0000, 
sim time next is 1083000.0000, 
raw observation next is [21.0, 68.16666666666666, 1.0, 2.0, 0.4720254834192782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 523328.1729899016, 523328.1729899019, 127984.8860436786], 
processed observation next is [1.0, 0.5217391304347826, 0.5909090909090909, 0.6816666666666665, 1.0, 1.0, 0.3400318542740977, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1938252492555191, 0.19382524925551922, 0.3121582586431185], 
reward next is 0.6878, 
noisyNet noise sample is [array([-0.4878633], dtype=float32), 0.077025615]. 
=============================================
[2019-03-23 11:59:28,788] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[73.31013]
 [73.17901]
 [73.07014]
 [72.84169]
 [73.00468]], R is [[73.35484314]
 [73.30651855]
 [73.25263977]
 [73.1967392 ]
 [73.11434937]].
[2019-03-23 11:59:30,142] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.6368823e-14 1.0000000e+00 1.2484531e-29 3.8600948e-32 2.4297809e-32], sum to 1.0000
[2019-03-23 11:59:30,149] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3360
[2019-03-23 11:59:30,152] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 83.83333333333334, 1.0, 2.0, 0.3083737709370564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 335329.7986994946, 335329.7986994943, 111923.1461851173], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1123800.0000, 
sim time next is 1124400.0000, 
raw observation next is [17.66666666666667, 84.66666666666667, 1.0, 2.0, 0.3064795361858933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 332816.4106354548, 332816.4106354548, 111636.9025371925], 
processed observation next is [1.0, 0.0, 0.4393939393939396, 0.8466666666666667, 1.0, 1.0, 0.1330994202323666, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12326533727239067, 0.12326533727239067, 0.2722851281394939], 
reward next is 0.7277, 
noisyNet noise sample is [array([-0.4876951], dtype=float32), 0.8872356]. 
=============================================
[2019-03-23 11:59:30,407] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.7117817e-11 1.0000000e+00 3.7883672e-24 9.8147557e-28 1.5232331e-27], sum to 1.0000
[2019-03-23 11:59:30,418] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0188
[2019-03-23 11:59:30,424] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 74.66666666666667, 1.0, 2.0, 0.3513190030692458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 390939.5533225648, 390939.5533225648, 118254.1040292983], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1110000.0000, 
sim time next is 1110600.0000, 
raw observation next is [20.0, 75.5, 1.0, 2.0, 0.3454476053062811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 383219.7862357486, 383219.7862357483, 117297.4686762034], 
processed observation next is [1.0, 0.8695652173913043, 0.5454545454545454, 0.755, 1.0, 1.0, 0.18180950663285136, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14193325416138838, 0.14193325416138827, 0.28609138701513026], 
reward next is 0.7139, 
noisyNet noise sample is [array([0.13342403], dtype=float32), -0.029393412]. 
=============================================
[2019-03-23 11:59:31,326] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8179417e-13 1.0000000e+00 1.4415884e-30 1.9008902e-38 1.0077785e-36], sum to 1.0000
[2019-03-23 11:59:31,334] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4328
[2019-03-23 11:59:31,344] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 78.0, 1.0, 2.0, 0.3238671174029363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 355007.906801542, 355007.9068015417, 113990.6572280562], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1118400.0000, 
sim time next is 1119000.0000, 
raw observation next is [19.0, 78.0, 1.0, 2.0, 0.3233538921989923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 354444.8312208211, 354444.8312208214, 113953.6611309192], 
processed observation next is [1.0, 0.9565217391304348, 0.5, 0.78, 1.0, 1.0, 0.15419236524874036, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13127586341511893, 0.13127586341511904, 0.2779357588559005], 
reward next is 0.7221, 
noisyNet noise sample is [array([-0.8364766], dtype=float32), -0.31806338]. 
=============================================
[2019-03-23 11:59:31,374] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[86.20765 ]
 [86.270744]
 [86.32058 ]
 [86.374794]
 [86.42543 ]], R is [[86.01699829]
 [85.87880707]
 [85.74219513]
 [85.60703278]
 [85.47312927]].
[2019-03-23 11:59:38,298] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.06737252e-09 1.00000000e+00 1.19456416e-20 1.37090015e-23
 2.50576630e-22], sum to 1.0000
[2019-03-23 11:59:38,305] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2518
[2019-03-23 11:59:38,311] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 62.0, 1.0, 2.0, 0.3670678233593638, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7435098616496821, 6.9112, 6.9112, 77.32846344354104, 835033.783914052, 835033.783914052, 214599.4467184828], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1271400.0000, 
sim time next is 1272000.0000, 
raw observation next is [27.0, 62.0, 1.0, 2.0, 0.506228185403316, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576880.79353641, 576880.79353641, 143381.1051263242], 
processed observation next is [1.0, 0.7391304347826086, 0.8636363636363636, 0.62, 1.0, 1.0, 0.38278523175414503, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21365955316163332, 0.21365955316163332, 0.34971001250322975], 
reward next is 0.6503, 
noisyNet noise sample is [array([-0.6854521], dtype=float32), -1.5798135]. 
=============================================
[2019-03-23 11:59:38,327] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[49.009052]
 [46.919163]
 [46.46841 ]
 [45.764294]
 [45.153805]], R is [[50.3952713 ]
 [50.36790466]
 [50.11004257]
 [49.86965942]
 [49.65442276]].
[2019-03-23 11:59:43,948] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.4056729e-12 1.0000000e+00 5.2661438e-27 1.0176171e-30 9.2644481e-31], sum to 1.0000
[2019-03-23 11:59:43,951] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0871
[2019-03-23 11:59:43,955] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 78.0, 1.0, 2.0, 0.4672593997828811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 532899.9019309432, 532899.9019309436, 136144.5434447809], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1360800.0000, 
sim time next is 1361400.0000, 
raw observation next is [22.83333333333334, 79.66666666666667, 1.0, 2.0, 0.4662778936307407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 531779.9529939516, 531779.952993952, 136039.3644523916], 
processed observation next is [1.0, 0.782608695652174, 0.6742424242424245, 0.7966666666666667, 1.0, 1.0, 0.3328473670384258, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19695553814590802, 0.19695553814590813, 0.33180332793266243], 
reward next is 0.6682, 
noisyNet noise sample is [array([-1.5225109], dtype=float32), 2.580532]. 
=============================================
[2019-03-23 11:59:44,191] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.8038891e-12 1.0000000e+00 5.4428130e-26 8.6083516e-30 5.3352105e-29], sum to 1.0000
[2019-03-23 11:59:44,198] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0061
[2019-03-23 11:59:44,201] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.4987212142577964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 568798.4877648776, 568798.4877648774, 141871.6343556794], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1368000.0000, 
sim time next is 1368600.0000, 
raw observation next is [22.0, 94.00000000000001, 1.0, 2.0, 0.5024129171736647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 572972.7818245542, 572972.7818245542, 142368.2242515494], 
processed observation next is [1.0, 0.8695652173913043, 0.6363636363636364, 0.9400000000000002, 1.0, 1.0, 0.37801614646708076, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21221214141650155, 0.21221214141650155, 0.3472395713452424], 
reward next is 0.6528, 
noisyNet noise sample is [array([0.72515386], dtype=float32), -0.4793909]. 
=============================================
[2019-03-23 11:59:46,576] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 11:59:46,578] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:59:46,578] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:59:46,579] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:59:46,580] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:59:46,580] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:59:46,583] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:59:46,584] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:59:46,579] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:59:46,580] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:59:46,586] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:59:46,598] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run11
[2019-03-23 11:59:46,599] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run11
[2019-03-23 11:59:46,599] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run11
[2019-03-23 11:59:46,599] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run11
[2019-03-23 11:59:46,623] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run11
[2019-03-23 12:00:28,369] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02011629], dtype=float32), 0.16655159]
[2019-03-23 12:00:28,370] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.17641833833333, 64.67222632666667, 1.0, 2.0, 0.5948412631518124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 678385.8428600853, 678385.842860085, 155362.4764993795]
[2019-03-23 12:00:28,371] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:00:28,373] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.8955259e-14 1.0000000e+00 3.9378111e-29 2.7492067e-34 4.3853690e-33], sampled 0.8678142662670654
[2019-03-23 12:00:49,870] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02011629], dtype=float32), 0.16655159]
[2019-03-23 12:00:49,871] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.03657034, 88.26152454666666, 1.0, 2.0, 0.4393527489175305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 477101.7806492965, 477101.7806492965, 99273.0416312617]
[2019-03-23 12:00:49,872] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:00:49,874] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.7588666e-14 1.0000000e+00 2.6163236e-28 2.5805639e-33 3.7881496e-32], sampled 0.853921551828625
[2019-03-23 12:01:13,031] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02011629], dtype=float32), 0.16655159]
[2019-03-23 12:01:13,032] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.19237922666667, 64.41368004333333, 1.0, 2.0, 0.3422343546621446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 371606.3981474848, 371606.3981474845, 118426.5190614012]
[2019-03-23 12:01:13,035] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:01:13,037] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.6270132e-14 1.0000000e+00 7.7060375e-29 6.0812598e-34 9.4187366e-33], sampled 0.10586630810391984
[2019-03-23 12:01:24,916] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 12:01:25,091] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 12:01:25,452] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 12:01:25,546] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 12:01:25,591] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 12:01:26,604] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 250000, evaluation results [250000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 12:01:30,134] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.46388604e-10 1.00000000e+00 6.23924921e-23 2.16759395e-28
 1.01457585e-27], sum to 1.0000
[2019-03-23 12:01:30,142] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5720
[2019-03-23 12:01:30,145] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 85.66666666666667, 1.0, 2.0, 0.5985415441717993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 672597.1504609854, 672597.1504609854, 158689.2184594903], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1502400.0000, 
sim time next is 1503000.0000, 
raw observation next is [25.5, 84.0, 1.0, 2.0, 0.5974324199609771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 671715.9862289042, 671715.9862289042, 158462.398007246], 
processed observation next is [0.0, 0.391304347826087, 0.7954545454545454, 0.84, 1.0, 1.0, 0.4967905249512213, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24878369860329785, 0.24878369860329785, 0.38649365367620975], 
reward next is 0.6135, 
noisyNet noise sample is [array([-0.1652542], dtype=float32), 0.8087023]. 
=============================================
[2019-03-23 12:01:30,159] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[68.89193]
 [68.88491]
 [68.86858]
 [68.83646]
 [68.82431]], R is [[68.82717896]
 [68.75186157]
 [68.67868805]
 [68.60851288]
 [68.54350281]].
[2019-03-23 12:01:33,426] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.3718768e-11 1.0000000e+00 3.2140940e-22 6.2706611e-27 5.0569713e-26], sum to 1.0000
[2019-03-23 12:01:33,433] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4017
[2019-03-23 12:01:33,439] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.3976391974216755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 450795.6747357529, 450795.6747357529, 126263.4612949874], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1566000.0000, 
sim time next is 1566600.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4568280846696164, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 517935.0064024731, 517935.0064024728, 132013.1476819555], 
processed observation next is [1.0, 0.13043478260869565, 0.5, 1.0, 1.0, 1.0, 0.32103510583702044, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1918277801490641, 0.191827780149064, 0.3219832870291598], 
reward next is 0.6780, 
noisyNet noise sample is [array([0.6071075], dtype=float32), -0.09194505]. 
=============================================
[2019-03-23 12:01:34,195] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0518239e-15 1.0000000e+00 1.7318324e-28 8.4911834e-34 1.3046967e-33], sum to 1.0000
[2019-03-23 12:01:34,201] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8285
[2019-03-23 12:01:34,204] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666667, 94.00000000000001, 1.0, 2.0, 0.4128079277421273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469285.8974811581, 469285.8974811581, 128678.3041916452], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1577400.0000, 
sim time next is 1578000.0000, 
raw observation next is [20.33333333333334, 94.0, 1.0, 2.0, 0.4128746363218472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469758.9252341168, 469758.9252341168, 129049.9719225623], 
processed observation next is [1.0, 0.2608695652173913, 0.5606060606060609, 0.94, 1.0, 1.0, 0.2660932954023089, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17398478712374696, 0.17398478712374696, 0.31475602907942024], 
reward next is 0.6852, 
noisyNet noise sample is [array([-0.30024257], dtype=float32), 0.14195447]. 
=============================================
[2019-03-23 12:01:34,215] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[73.17041 ]
 [73.20114 ]
 [73.209236]
 [73.2504  ]
 [73.27947 ]], R is [[73.11974335]
 [73.0746994 ]
 [73.03237915]
 [72.99131775]
 [72.95127869]].
[2019-03-23 12:01:43,416] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.4820337e-12 1.0000000e+00 3.2517667e-24 2.4053563e-28 1.6127805e-28], sum to 1.0000
[2019-03-23 12:01:43,424] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9140
[2019-03-23 12:01:43,428] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 46.0, 1.0, 2.0, 0.3161632201522498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 343312.7509416508, 343312.7509416505, 81191.23458548207], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1773600.0000, 
sim time next is 1774200.0000, 
raw observation next is [17.83333333333333, 45.5, 1.0, 2.0, 0.3202835550187206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 347788.506676555, 347788.5066765553, 81700.05929428608], 
processed observation next is [1.0, 0.5217391304347826, 0.44696969696969674, 0.455, 1.0, 1.0, 0.1503544437734007, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1288105580283537, 0.1288105580283538, 0.1992684373031368], 
reward next is 0.8007, 
noisyNet noise sample is [array([-0.7029562], dtype=float32), 0.8005123]. 
=============================================
[2019-03-23 12:01:44,155] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.6677023e-13 1.0000000e+00 7.9099129e-27 6.2371680e-34 2.0240887e-31], sum to 1.0000
[2019-03-23 12:01:44,162] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1486
[2019-03-23 12:01:44,167] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 57.0, 1.0, 2.0, 0.3014284720652834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 327307.3177433618, 327307.3177433618, 78422.92971330394], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1762200.0000, 
sim time next is 1762800.0000, 
raw observation next is [15.33333333333333, 55.0, 1.0, 2.0, 0.3266651877322944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 354720.701553631, 354720.7015536313, 80704.47209933786], 
processed observation next is [1.0, 0.391304347826087, 0.3333333333333332, 0.55, 1.0, 1.0, 0.158331484665368, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13137803761245592, 0.13137803761245603, 0.19684017585204355], 
reward next is 0.8032, 
noisyNet noise sample is [array([-0.4136379], dtype=float32), 1.7276406]. 
=============================================
[2019-03-23 12:01:45,981] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3235756e-14 1.0000000e+00 1.4485893e-30 9.3458574e-35 9.9810865e-33], sum to 1.0000
[2019-03-23 12:01:45,992] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6195
[2019-03-23 12:01:46,004] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 54.0, 1.0, 2.0, 0.229851560945313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 249565.2995614377, 249565.299561438, 73597.46194500846], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1806000.0000, 
sim time next is 1806600.0000, 
raw observation next is [17.0, 54.5, 1.0, 2.0, 0.2291176057988729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 248768.1912962368, 248768.1912962365, 73659.39853562112], 
processed observation next is [1.0, 0.9130434782608695, 0.4090909090909091, 0.545, 1.0, 1.0, 0.036397007248591094, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09213636714675437, 0.09213636714675426, 0.1796570695990759], 
reward next is 0.8203, 
noisyNet noise sample is [array([-0.40341422], dtype=float32), -3.4733596]. 
=============================================
[2019-03-23 12:01:46,685] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.3034793e-16 1.0000000e+00 1.5174899e-29 4.2988709e-35 9.0036777e-35], sum to 1.0000
[2019-03-23 12:01:46,694] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2769
[2019-03-23 12:01:46,702] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.5, 83.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 190742.175029058, 190742.1750290577, 65062.67148559804], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1819800.0000, 
sim time next is 1820400.0000, 
raw observation next is [12.0, 86.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 184359.2246924184, 184359.2246924187, 63858.58081102247], 
processed observation next is [1.0, 0.043478260869565216, 0.18181818181818182, 0.8666666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.06828119433052533, 0.06828119433052544, 0.15575263612444504], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7713037], dtype=float32), -0.18126959]. 
=============================================
[2019-03-23 12:01:57,638] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1129645e-11 1.0000000e+00 4.4743768e-23 1.0133492e-28 6.8717535e-27], sum to 1.0000
[2019-03-23 12:01:57,645] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0949
[2019-03-23 12:01:57,649] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 70.5, 1.0, 2.0, 0.2764166437683598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 300139.7425020227, 300139.742502023, 96144.80654042706], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2017800.0000, 
sim time next is 2018400.0000, 
raw observation next is [18.66666666666667, 69.66666666666666, 1.0, 2.0, 0.2780098103218072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 301870.1773890815, 301870.1773890815, 96983.50354558098], 
processed observation next is [0.0, 0.34782608695652173, 0.4848484848484851, 0.6966666666666665, 1.0, 1.0, 0.097512262902259, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11180376940336352, 0.11180376940336352, 0.236545130598978], 
reward next is 0.7635, 
noisyNet noise sample is [array([0.1407469], dtype=float32), -0.35124937]. 
=============================================
[2019-03-23 12:02:02,020] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.7189275e-13 1.0000000e+00 1.2457861e-26 4.6606969e-31 2.0355486e-31], sum to 1.0000
[2019-03-23 12:02:02,029] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5495
[2019-03-23 12:02:02,034] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 71.0, 1.0, 2.0, 0.2510262606431582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 272562.5373299517, 272562.5373299519, 88689.63269968626], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2101200.0000, 
sim time next is 2101800.0000, 
raw observation next is [18.5, 69.5, 1.0, 2.0, 0.2599900414217765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 282298.1717344709, 282298.1717344709, 92628.23472556702], 
processed observation next is [0.0, 0.30434782608695654, 0.4772727272727273, 0.695, 1.0, 1.0, 0.07498755177722062, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1045548784201744, 0.1045548784201744, 0.22592252372089516], 
reward next is 0.7741, 
noisyNet noise sample is [array([-0.09841411], dtype=float32), 0.7067191]. 
=============================================
[2019-03-23 12:02:04,179] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.0914078e-12 1.0000000e+00 7.0283355e-25 1.9309451e-28 2.4041281e-27], sum to 1.0000
[2019-03-23 12:02:04,185] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7107
[2019-03-23 12:02:04,194] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 58.66666666666667, 1.0, 2.0, 0.4034230153898311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 457021.5594731956, 457021.5594731959, 126577.4475576583], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2140800.0000, 
sim time next is 2141400.0000, 
raw observation next is [24.33333333333333, 59.83333333333334, 1.0, 2.0, 0.4009151288993168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 453794.759199612, 453794.759199612, 126094.090147187], 
processed observation next is [0.0, 0.782608695652174, 0.7424242424242422, 0.5983333333333334, 1.0, 1.0, 0.25114391112414597, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16807213303689333, 0.16807213303689333, 0.30754656133460245], 
reward next is 0.6925, 
noisyNet noise sample is [array([0.36067945], dtype=float32), 0.7608088]. 
=============================================
[2019-03-23 12:02:12,111] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1945951e-14 1.0000000e+00 7.2120063e-28 1.4924045e-34 3.5170820e-33], sum to 1.0000
[2019-03-23 12:02:12,117] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5795
[2019-03-23 12:02:12,123] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 56.0, 1.0, 2.0, 0.4593737111790753, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 498900.780675563, 498900.780675563, 99839.49895110798], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2283000.0000, 
sim time next is 2283600.0000, 
raw observation next is [18.0, 56.0, 1.0, 2.0, 0.4562885145535891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 495548.4087789578, 495548.4087789578, 100013.3322334163], 
processed observation next is [1.0, 0.43478260869565216, 0.45454545454545453, 0.56, 1.0, 1.0, 0.3203606431919863, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1835364476959103, 0.1835364476959103, 0.243934956666869], 
reward next is 0.7561, 
noisyNet noise sample is [array([0.46430603], dtype=float32), 1.1529918]. 
=============================================
[2019-03-23 12:02:13,689] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.4197244e-13 1.0000000e+00 1.0107289e-26 4.6433364e-33 6.4159742e-31], sum to 1.0000
[2019-03-23 12:02:13,698] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8440
[2019-03-23 12:02:13,703] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 49.0, 1.0, 2.0, 0.2687890378313754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 291855.0220606271, 291855.0220606268, 81345.55612023984], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2313000.0000, 
sim time next is 2313600.0000, 
raw observation next is [19.33333333333334, 49.0, 1.0, 2.0, 0.2681393201682136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 291149.3380626597, 291149.3380626597, 80774.03431886436], 
processed observation next is [1.0, 0.782608695652174, 0.5151515151515155, 0.49, 1.0, 1.0, 0.08517415021026702, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10783308817135545, 0.10783308817135545, 0.1970098398021082], 
reward next is 0.8030, 
noisyNet noise sample is [array([0.02675512], dtype=float32), 0.02741028]. 
=============================================
[2019-03-23 12:02:15,237] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 12:02:15,239] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:02:15,240] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:02:15,240] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:02:15,243] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:02:15,245] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:02:15,246] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:02:15,247] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:02:15,248] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:02:15,248] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:02:15,249] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:02:15,258] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run12
[2019-03-23 12:02:15,259] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run12
[2019-03-23 12:02:15,304] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run12
[2019-03-23 12:02:15,340] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run12
[2019-03-23 12:02:15,341] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run12
[2019-03-23 12:02:33,366] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02564909], dtype=float32), 0.1445436]
[2019-03-23 12:02:33,368] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.15, 92.0, 1.0, 2.0, 0.4019144055012237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 452514.276662729, 452514.2766627286, 129142.3346459944]
[2019-03-23 12:02:33,369] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:02:33,374] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.1701598e-12 1.0000000e+00 3.9969329e-25 2.4379909e-30 7.5846570e-29], sampled 0.678050023989017
[2019-03-23 12:03:07,787] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02564909], dtype=float32), 0.1445436]
[2019-03-23 12:03:07,789] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.7, 52.0, 1.0, 2.0, 0.3689496724051707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 413348.7966398995, 413348.7966398991, 125223.3254616904]
[2019-03-23 12:03:07,790] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:03:07,795] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.1327375e-12 1.0000000e+00 3.7416166e-25 2.2501503e-30 7.0293398e-29], sampled 0.38881808174736554
[2019-03-23 12:03:09,544] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02564909], dtype=float32), 0.1445436]
[2019-03-23 12:03:09,546] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.16666666666667, 82.66666666666667, 1.0, 2.0, 0.3416355152903106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 379187.4172678617, 379187.4172678613, 121401.6568576721]
[2019-03-23 12:03:09,548] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:03:09,552] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.4627403e-12 1.0000000e+00 6.2866189e-25 4.2267000e-30 1.2778893e-28], sampled 0.310227392490932
[2019-03-23 12:03:17,069] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02564909], dtype=float32), 0.1445436]
[2019-03-23 12:03:17,071] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.48333333333333, 79.0, 1.0, 2.0, 0.5316917202805748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 605426.3395514343, 605426.3395514339, 151143.1421181359]
[2019-03-23 12:03:17,071] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:03:17,077] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.6068092e-13 1.0000000e+00 6.0272880e-26 2.4481574e-31 8.5814661e-30], sampled 0.1424153800115785
[2019-03-23 12:03:24,517] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02564909], dtype=float32), 0.1445436]
[2019-03-23 12:03:24,518] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.61186574, 78.99145499, 1.0, 2.0, 0.5944835271087701, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 667946.360318078, 667946.3603180776, 162436.1639469815]
[2019-03-23 12:03:24,519] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:03:24,521] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.3963094e-13 1.0000000e+00 5.4815060e-26 2.1815266e-31 7.6927284e-30], sampled 0.7994563171133776
[2019-03-23 12:03:37,075] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02564909], dtype=float32), 0.1445436]
[2019-03-23 12:03:37,076] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.85, 69.0, 1.0, 2.0, 0.3356860375426159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 371433.8605068803, 371433.8605068803, 120476.714004496]
[2019-03-23 12:03:37,077] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:03:37,079] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.8614197e-12 1.0000000e+00 1.0252573e-24 7.6573613e-30 2.2447342e-28], sampled 0.6430072975554761
[2019-03-23 12:03:52,575] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02564909], dtype=float32), 0.1445436]
[2019-03-23 12:03:52,576] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.7, 49.0, 1.0, 2.0, 0.3027753437486467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 328749.123990317, 328749.123990317, 101293.4364917502]
[2019-03-23 12:03:52,577] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:03:52,580] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.5841525e-12 1.0000000e+00 1.9950655e-24 1.7192920e-29 4.8328328e-28], sampled 0.791442142902174
[2019-03-23 12:03:54,566] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 12:03:54,720] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 12:03:54,849] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 12:03:54,861] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 12:03:55,007] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 12:03:56,026] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 275000, evaluation results [275000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 12:03:56,031] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.1362397e-10 1.0000000e+00 1.3816846e-22 8.6110533e-28 7.1000085e-27], sum to 1.0000
[2019-03-23 12:03:56,034] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9139
[2019-03-23 12:03:56,040] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 60.0, 1.0, 2.0, 0.3923335092997586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 426060.163197749, 426060.1631977487, 99710.12918032902], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2365200.0000, 
sim time next is 2365800.0000, 
raw observation next is [19.16666666666667, 58.16666666666666, 1.0, 2.0, 0.4509213986393044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489716.5605112371, 489716.5605112371, 105302.76633101], 
processed observation next is [1.0, 0.391304347826087, 0.5075757575757578, 0.5816666666666666, 1.0, 1.0, 0.3136517482991305, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1813765038930508, 0.1813765038930508, 0.2568360154414878], 
reward next is 0.7432, 
noisyNet noise sample is [array([-1.0839466], dtype=float32), 0.25279042]. 
=============================================
[2019-03-23 12:03:58,191] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.7088583e-14 1.0000000e+00 4.8742207e-25 1.3631291e-32 1.5414053e-28], sum to 1.0000
[2019-03-23 12:03:58,198] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7183
[2019-03-23 12:03:58,206] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 75.33333333333334, 1.0, 2.0, 0.2540425226789548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 275838.5020329688, 275838.5020329691, 85707.86874591075], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2416800.0000, 
sim time next is 2417400.0000, 
raw observation next is [17.0, 74.5, 1.0, 2.0, 0.2501152400782953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 271573.0814764421, 271573.0814764421, 84603.72091446], 
processed observation next is [1.0, 1.0, 0.4090909090909091, 0.745, 1.0, 1.0, 0.06264405009786908, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10058262276905264, 0.10058262276905264, 0.2063505388157561], 
reward next is 0.7936, 
noisyNet noise sample is [array([-0.5178391], dtype=float32), 1.7731929]. 
=============================================
[2019-03-23 12:03:59,057] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.2761183e-16 1.0000000e+00 2.8096573e-29 1.7853005e-36 8.2059516e-35], sum to 1.0000
[2019-03-23 12:03:59,065] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8269
[2019-03-23 12:03:59,068] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 77.0, 1.0, 2.0, 0.259028703786805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 281254.0458667957, 281254.0458667957, 87685.01118951743], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2415600.0000, 
sim time next is 2416200.0000, 
raw observation next is [17.0, 76.16666666666667, 1.0, 2.0, 0.2576306340543195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 279735.5815171089, 279735.5815171092, 86801.78106687662], 
processed observation next is [1.0, 1.0, 0.4090909090909091, 0.7616666666666667, 1.0, 1.0, 0.07203829256789938, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10360577093226256, 0.10360577093226266, 0.21171166113872344], 
reward next is 0.7883, 
noisyNet noise sample is [array([0.6791272], dtype=float32), 0.032585192]. 
=============================================
[2019-03-23 12:04:23,387] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.5511009e-13 1.0000000e+00 1.7381262e-21 3.6635844e-24 3.0217243e-22], sum to 1.0000
[2019-03-23 12:04:23,394] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6337
[2019-03-23 12:04:23,403] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1515586.985161145 W.
[2019-03-23 12:04:23,409] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.5, 74.0, 1.0, 2.0, 0.6738236847212848, 1.0, 2.0, 0.6738236847212848, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1515586.985161145, 1515586.985161145, 283667.2838391718], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2889000.0000, 
sim time next is 2889600.0000, 
raw observation next is [26.66666666666667, 74.0, 1.0, 2.0, 0.8892394344336308, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9857172420832897, 6.911199999999999, 6.9112, 77.32846344354104, 1548435.728764462, 1548435.728764462, 331446.826582233], 
processed observation next is [1.0, 0.43478260869565216, 0.8484848484848487, 0.74, 1.0, 1.0, 0.8615492930420384, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9795960601189855, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5734947143572081, 0.5734947143572081, 0.8084068941030074], 
reward next is 0.1916, 
noisyNet noise sample is [array([0.883112], dtype=float32), -0.9079884]. 
=============================================
[2019-03-23 12:04:26,521] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.1446928e-14 1.0000000e+00 4.2946617e-26 3.9665940e-28 2.5717763e-27], sum to 1.0000
[2019-03-23 12:04:26,528] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1692
[2019-03-23 12:04:26,535] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.5395792826388845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 613717.0228376507, 613717.0228376505, 148348.5912502638], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2935200.0000, 
sim time next is 2935800.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.5399201955721918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 614104.9007367605, 614104.9007367601, 148391.4721814732], 
processed observation next is [1.0, 1.0, 0.6363636363636364, 1.0, 1.0, 1.0, 0.4249002444652398, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22744625953213352, 0.22744625953213338, 0.3619304199548127], 
reward next is 0.6381, 
noisyNet noise sample is [array([0.10075408], dtype=float32), -2.0128238]. 
=============================================
[2019-03-23 12:04:28,220] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.6587192e-08 1.0000000e+00 1.4844025e-14 2.9247563e-16 1.6597075e-15], sum to 1.0000
[2019-03-23 12:04:28,228] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6104
[2019-03-23 12:04:28,233] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.83333333333334, 95.0, 1.0, 2.0, 0.3234533230475204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 353395.3866288841, 353395.3866288844, 113543.6882272006], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3048600.0000, 
sim time next is 3049200.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3286730747995727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 359507.2312721538, 359507.2312721536, 114060.4149534753], 
processed observation next is [1.0, 0.30434782608695654, 0.4090909090909091, 0.94, 1.0, 1.0, 0.16084134349946586, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.133150826397094, 0.13315082639709394, 0.2781961340328666], 
reward next is 0.7218, 
noisyNet noise sample is [array([0.05328486], dtype=float32), -0.9991285]. 
=============================================
[2019-03-23 12:04:36,904] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2932450e-11 1.0000000e+00 5.0890114e-21 4.2662845e-25 3.9157733e-23], sum to 1.0000
[2019-03-23 12:04:36,912] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9500
[2019-03-23 12:04:36,917] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1080205.953645011 W.
[2019-03-23 12:04:36,923] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.4730948449573878, 1.0, 2.0, 0.4730948449573878, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1080205.953645011, 1080205.953645011, 220132.0344303326], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3153600.0000, 
sim time next is 3154200.0000, 
raw observation next is [21.5, 87.16666666666667, 1.0, 2.0, 0.3161744579804113, 1.0, 2.0, 0.3161744579804113, 1.0, 1.0, 0.6390345157487821, 6.911199999999999, 6.9112, 77.3421103, 1082504.083984831, 1082504.083984831, 260893.1999557747], 
processed observation next is [1.0, 0.5217391304347826, 0.6136363636363636, 0.8716666666666667, 1.0, 1.0, 0.14521807247551413, 1.0, 1.0, 0.14521807247551413, 1.0, 0.5, 0.4843350224982602, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4009274385129004, 0.4009274385129004, 0.6363248779409139], 
reward next is 0.3637, 
noisyNet noise sample is [array([-0.4964025], dtype=float32), 0.051267102]. 
=============================================
[2019-03-23 12:04:38,271] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.04206185e-10 1.00000000e+00 1.34554611e-20 4.72402490e-24
 9.88670411e-23], sum to 1.0000
[2019-03-23 12:04:38,279] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5395
[2019-03-23 12:04:38,284] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.9119691456846024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1038628.273782022, 1038628.273782022, 205033.0438968872], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3157200.0000, 
sim time next is 3157800.0000, 
raw observation next is [24.16666666666666, 80.66666666666667, 1.0, 2.0, 0.8643990999210155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 984559.8915892396, 984559.8915892392, 196449.9221869321], 
processed observation next is [1.0, 0.5652173913043478, 0.7348484848484845, 0.8066666666666668, 1.0, 1.0, 0.8304988749012693, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3646518116997184, 0.3646518116997182, 0.4791461516754441], 
reward next is 0.5209, 
noisyNet noise sample is [array([-0.23678073], dtype=float32), 0.8497497]. 
=============================================
[2019-03-23 12:04:39,181] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5808264e-13 1.0000000e+00 4.1596600e-24 2.0666459e-27 9.1415303e-26], sum to 1.0000
[2019-03-23 12:04:39,189] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4520
[2019-03-23 12:04:39,192] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 89.00000000000001, 1.0, 2.0, 0.4298641738717909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 488663.9759754949, 488663.9759754949, 130333.3025596372], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3197400.0000, 
sim time next is 3198000.0000, 
raw observation next is [20.33333333333334, 90.0, 1.0, 2.0, 0.424006547080066, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 481422.9450102983, 481422.9450102983, 129285.0708537163], 
processed observation next is [0.0, 0.0, 0.5606060606060609, 0.9, 1.0, 1.0, 0.28000818385008247, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1783047944482586, 0.1783047944482586, 0.31532944110662514], 
reward next is 0.6847, 
noisyNet noise sample is [array([0.682486], dtype=float32), 0.6615868]. 
=============================================
[2019-03-23 12:04:39,208] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[63.95226 ]
 [64.13662 ]
 [64.845116]
 [64.84596 ]
 [64.85201 ]], R is [[63.89770126]
 [63.94083786]
 [63.98171616]
 [64.02194214]
 [64.06134796]].
[2019-03-23 12:04:39,623] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.7915801e-14 1.0000000e+00 3.4890305e-27 2.4955695e-29 7.6166124e-28], sum to 1.0000
[2019-03-23 12:04:39,637] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0318
[2019-03-23 12:04:39,643] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.3926725303613477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 442476.807457871, 442476.8074578713, 124183.7120546314], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3201600.0000, 
sim time next is 3202200.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.3928430795389779, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 442665.9437215276, 442665.9437215279, 124197.2859482176], 
processed observation next is [0.0, 0.043478260869565216, 0.5, 0.94, 1.0, 1.0, 0.24105384942372235, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1639503495264917, 0.16395034952649182, 0.30292020962979904], 
reward next is 0.6971, 
noisyNet noise sample is [array([1.1131891], dtype=float32), 0.60779035]. 
=============================================
[2019-03-23 12:04:40,146] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.6321849e-13 1.0000000e+00 1.1466672e-23 2.2096873e-29 4.4111389e-26], sum to 1.0000
[2019-03-23 12:04:40,153] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2730
[2019-03-23 12:04:40,157] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.4365170948592785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 496626.5532275553, 496626.5532275553, 131353.8475336929], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3195600.0000, 
sim time next is 3196200.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.4348500198203665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 494727.1453261129, 494727.1453261129, 131184.1205712177], 
processed observation next is [1.0, 1.0, 0.5909090909090909, 0.88, 1.0, 1.0, 0.2935625247754581, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1832322760467085, 0.1832322760467085, 0.31996126968589683], 
reward next is 0.6800, 
noisyNet noise sample is [array([-1.0115045], dtype=float32), 0.6192061]. 
=============================================
[2019-03-23 12:04:40,182] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1950692e-14 1.0000000e+00 3.8731584e-27 1.3672120e-32 1.5387498e-28], sum to 1.0000
[2019-03-23 12:04:40,192] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8144
[2019-03-23 12:04:40,196] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3359906642890752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369809.5171659943, 369809.5171659943, 115425.0803969436], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3216000.0000, 
sim time next is 3216600.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3343387039520727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 367981.0360496757, 367981.0360496754, 115298.7596288699], 
processed observation next is [0.0, 0.21739130434782608, 0.45454545454545453, 0.88, 1.0, 1.0, 0.16792337994009088, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.136289272610991, 0.13628927261099089, 0.2812164868996827], 
reward next is 0.7188, 
noisyNet noise sample is [array([1.1754135], dtype=float32), -0.11048]. 
=============================================
[2019-03-23 12:04:42,331] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.9361221e-16 1.0000000e+00 2.3810972e-30 1.0479934e-33 1.0597055e-30], sum to 1.0000
[2019-03-23 12:04:42,339] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4919
[2019-03-23 12:04:42,348] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 62.33333333333334, 1.0, 2.0, 0.3541741490093308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 394441.8248444024, 394441.8248444021, 118619.4412687104], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3233400.0000, 
sim time next is 3234000.0000, 
raw observation next is [22.66666666666667, 60.66666666666667, 1.0, 2.0, 0.3569015039206597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 397754.1568018686, 397754.1568018689, 118955.4727513297], 
processed observation next is [0.0, 0.43478260869565216, 0.6666666666666669, 0.6066666666666667, 1.0, 1.0, 0.19612687990082464, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14731635437106244, 0.14731635437106258, 0.2901352993934871], 
reward next is 0.7099, 
noisyNet noise sample is [array([0.08127238], dtype=float32), -0.8974626]. 
=============================================
[2019-03-23 12:04:42,363] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[81.77784 ]
 [81.779594]
 [81.74601 ]
 [81.7288  ]
 [81.701416]], R is [[81.64855957]
 [81.54276276]
 [81.43817139]
 [81.33324432]
 [81.22793579]].
[2019-03-23 12:04:44,134] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.4555150e-18 1.0000000e+00 3.5085593e-33 0.0000000e+00 2.7832267e-34], sum to 1.0000
[2019-03-23 12:04:44,143] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5089
[2019-03-23 12:04:44,146] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 72.66666666666666, 1.0, 2.0, 0.310665324604692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 337340.6700351484, 337340.6700351482, 111911.7210422421], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3278400.0000, 
sim time next is 3279000.0000, 
raw observation next is [18.5, 74.83333333333334, 1.0, 2.0, 0.3047943133434248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 330963.3737130687, 330963.3737130687, 108374.6623884519], 
processed observation next is [0.0, 0.9565217391304348, 0.4772727272727273, 0.7483333333333334, 1.0, 1.0, 0.13099289167928102, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12257902730113657, 0.12257902730113657, 0.2643284448498827], 
reward next is 0.7357, 
noisyNet noise sample is [array([0.3671076], dtype=float32), -2.2955728]. 
=============================================
[2019-03-23 12:04:44,157] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[87.8207 ]
 [87.76865]
 [87.71455]
 [87.68016]
 [87.65974]], R is [[87.72977448]
 [87.57952118]
 [87.42957306]
 [87.2793808 ]
 [87.12910461]].
[2019-03-23 12:04:44,826] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 12:04:44,827] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:04:44,829] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:04:44,831] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:04:44,832] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:04:44,833] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:04:44,833] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:04:44,833] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:04:44,831] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:04:44,834] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:04:44,836] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:04:44,850] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run13
[2019-03-23 12:04:44,850] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run13
[2019-03-23 12:04:44,892] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run13
[2019-03-23 12:04:44,927] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run13
[2019-03-23 12:04:44,948] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run13
[2019-03-23 12:04:49,610] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01834309], dtype=float32), 0.12253927]
[2019-03-23 12:04:49,612] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.05, 36.0, 1.0, 2.0, 0.3477551711415108, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 383806.6234463708, 383806.6234463704, 121018.6180443458]
[2019-03-23 12:04:49,612] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:04:49,614] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.9239709e-14 1.0000000e+00 5.0135614e-26 1.5687861e-30 8.6887935e-28], sampled 0.3254544260663237
[2019-03-23 12:05:00,007] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01834309], dtype=float32), 0.12253927]
[2019-03-23 12:05:00,008] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.42118895666667, 72.08095610666666, 1.0, 2.0, 0.4328765003527641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 470066.3441200268, 470066.3441200268, 104136.0060250316]
[2019-03-23 12:05:00,010] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:05:00,013] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.8336331e-14 1.0000000e+00 1.0553554e-25 3.7739895e-30 1.9256058e-27], sampled 0.7694357524660066
[2019-03-23 12:05:03,391] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01834309], dtype=float32), 0.12253927]
[2019-03-23 12:05:03,393] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.46666666666667, 65.33333333333333, 1.0, 2.0, 0.7072819452546605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 806029.1747173788, 806029.1747173783, 174669.8803431816]
[2019-03-23 12:05:03,393] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:05:03,397] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.4497439e-14 1.0000000e+00 9.2876496e-26 3.2461177e-30 1.6796457e-27], sampled 0.35422267731053725
[2019-03-23 12:05:17,507] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01834309], dtype=float32), 0.12253927]
[2019-03-23 12:05:17,509] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.0, 82.66666666666667, 1.0, 2.0, 0.2003548227303798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 217531.5452411883, 217531.5452411886, 71858.72714617454]
[2019-03-23 12:05:17,511] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:05:17,514] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0680587e-13 1.0000000e+00 3.2841396e-25 1.4396931e-29 6.4816448e-27], sampled 0.700841391485979
[2019-03-23 12:05:18,604] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01834309], dtype=float32), 0.12253927]
[2019-03-23 12:05:18,604] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.74127414, 77.84588397833335, 1.0, 2.0, 0.3120770414040398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 338851.6210833227, 338851.6210833223, 106653.0963028888]
[2019-03-23 12:05:18,606] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:05:18,608] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.2308317e-14 1.0000000e+00 5.7746258e-26 1.8533254e-30 1.0106050e-27], sampled 0.3557237761085722
[2019-03-23 12:06:20,255] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01834309], dtype=float32), 0.12253927]
[2019-03-23 12:06:20,256] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.39219170333334, 98.003859025, 1.0, 2.0, 0.347092993642726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 384481.5599750142, 384481.5599750138, 121517.8072172114]
[2019-03-23 12:06:20,258] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:06:20,260] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.6271349e-14 1.0000000e+00 9.6057428e-27 2.2346919e-31 1.4849697e-28], sampled 0.9076242116586126
[2019-03-23 12:06:23,304] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 12:06:23,979] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 12:06:23,980] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 12:06:24,105] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 12:06:24,218] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 12:06:25,233] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 300000, evaluation results [300000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 12:06:27,897] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.6304891e-13 1.0000000e+00 1.4524955e-23 5.1929319e-27 5.4101147e-23], sum to 1.0000
[2019-03-23 12:06:27,905] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9137
[2019-03-23 12:06:27,908] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 50.0, 1.0, 2.0, 0.3581637623994932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 400989.7352657617, 400989.7352657617, 119875.923714155], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3336600.0000, 
sim time next is 3337200.0000, 
raw observation next is [25.0, 50.0, 1.0, 2.0, 0.3580789109308785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 400895.1163394272, 400895.1163394272, 119869.1333852391], 
processed observation next is [0.0, 0.6521739130434783, 0.7727272727272727, 0.5, 1.0, 1.0, 0.19759863866359811, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14847967271830637, 0.14847967271830637, 0.2923637399639978], 
reward next is 0.7076, 
noisyNet noise sample is [array([-0.43641174], dtype=float32), 0.11515515]. 
=============================================
[2019-03-23 12:06:36,324] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.57419779e-05 9.99974251e-01 7.78316040e-12 4.74574861e-13
 1.00946265e-10], sum to 1.0000
[2019-03-23 12:06:36,332] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9218
[2019-03-23 12:06:36,335] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 71.33333333333333, 1.0, 2.0, 0.5467502548504595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 620733.1625800604, 620733.1625800604, 149849.1179356955], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3526800.0000, 
sim time next is 3527400.0000, 
raw observation next is [26.16666666666667, 72.66666666666667, 1.0, 2.0, 0.5504870723077965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 624771.5419407645, 624771.5419407645, 150419.1179775714], 
processed observation next is [1.0, 0.8260869565217391, 0.825757575757576, 0.7266666666666667, 1.0, 1.0, 0.43810884038474557, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23139686738546833, 0.23139686738546833, 0.36687589750627175], 
reward next is 0.6331, 
noisyNet noise sample is [array([-0.3486365], dtype=float32), -1.6251338]. 
=============================================
[2019-03-23 12:06:37,951] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.5860607e-12 1.0000000e+00 2.4874603e-23 1.0134618e-27 5.7023991e-22], sum to 1.0000
[2019-03-23 12:06:37,958] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8231
[2019-03-23 12:06:37,961] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5217892879665988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 594446.6126932054, 594446.612693205, 145422.9480318171], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3544200.0000, 
sim time next is 3544800.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5215851694867957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 594214.2028345306, 594214.2028345306, 145397.8863337873], 
processed observation next is [1.0, 0.0, 0.6818181818181818, 0.89, 1.0, 1.0, 0.40198146185849454, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2200793343831595, 0.2200793343831595, 0.35462899105801776], 
reward next is 0.6454, 
noisyNet noise sample is [array([-1.6442219], dtype=float32), 0.6223328]. 
=============================================
[2019-03-23 12:06:47,520] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.1625135e-07 9.9999964e-01 4.9482640e-15 2.9387110e-17 6.1354352e-11], sum to 1.0000
[2019-03-23 12:06:47,530] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9379
[2019-03-23 12:06:47,535] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.510230907550195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 581894.2585644063, 581894.2585644063, 143289.9374919811], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3721800.0000, 
sim time next is 3722400.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5089935710144614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 580482.6410448605, 580482.6410448605, 143142.8333144495], 
processed observation next is [1.0, 0.08695652173913043, 0.6363636363636364, 0.94, 1.0, 1.0, 0.38624196376807673, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21499357075735573, 0.21499357075735573, 0.34912886174255975], 
reward next is 0.6509, 
noisyNet noise sample is [array([-1.6499144], dtype=float32), 0.82742345]. 
=============================================
[2019-03-23 12:06:49,124] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.4063498e-05 9.9995589e-01 5.6583873e-11 2.6541098e-13 2.1585183e-08], sum to 1.0000
[2019-03-23 12:06:49,130] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6217
[2019-03-23 12:06:49,137] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 73.33333333333333, 1.0, 2.0, 0.9215869316620598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1048406.341581432, 1048406.341581432, 196138.5933245096], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3764400.0000, 
sim time next is 3765000.0000, 
raw observation next is [21.83333333333333, 78.16666666666667, 1.0, 2.0, 0.9343486237865093, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1062363.665334082, 1062363.665334082, 197787.2983982481], 
processed observation next is [1.0, 0.5652173913043478, 0.6287878787878786, 0.7816666666666667, 1.0, 1.0, 0.9179357797331367, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.39346802419780813, 0.39346802419780813, 0.48240804487377587], 
reward next is 0.5176, 
noisyNet noise sample is [array([0.62859297], dtype=float32), -0.3993832]. 
=============================================
[2019-03-23 12:06:49,154] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[38.082848]
 [39.508102]
 [41.42252 ]
 [42.265182]
 [42.37983 ]], R is [[36.67788696]
 [36.83272171]
 [37.01126862]
 [37.20167923]
 [37.4295845 ]].
[2019-03-23 12:06:53,251] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.01430464e-09 1.00000000e+00 6.53094125e-18 1.06001464e-19
 2.50444468e-13], sum to 1.0000
[2019-03-23 12:06:53,271] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8736
[2019-03-23 12:06:53,276] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 59.66666666666667, 1.0, 2.0, 0.352023205077176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 393234.5185707462, 393234.5185707462, 118969.0530767615], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3860400.0000, 
sim time next is 3861000.0000, 
raw observation next is [23.0, 59.0, 1.0, 2.0, 0.3501464626843231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 390606.3700208063, 390606.3700208066, 118581.0603791776], 
processed observation next is [0.0, 0.6956521739130435, 0.6818181818181818, 0.59, 1.0, 1.0, 0.18768307835540385, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14466902593363198, 0.14466902593363207, 0.289222098485799], 
reward next is 0.7108, 
noisyNet noise sample is [array([1.640253], dtype=float32), 1.8258822]. 
=============================================
[2019-03-23 12:06:53,290] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[61.48067 ]
 [61.423035]
 [61.371056]
 [61.304188]
 [61.24965 ]], R is [[61.63715363]
 [61.73061371]
 [61.82222366]
 [61.91270065]
 [62.00349045]].
[2019-03-23 12:06:54,351] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.0489328e-08 1.0000000e+00 4.3900264e-16 7.4305318e-20 1.2084820e-12], sum to 1.0000
[2019-03-23 12:06:54,358] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4272
[2019-03-23 12:06:54,361] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 57.0, 1.0, 2.0, 0.3136099622800332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 342919.8289870513, 342919.8289870513, 112951.8282844786], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3870000.0000, 
sim time next is 3870600.0000, 
raw observation next is [21.83333333333334, 58.16666666666666, 1.0, 2.0, 0.3130759723292684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 342466.2747032593, 342466.2747032593, 112961.8277358105], 
processed observation next is [0.0, 0.8260869565217391, 0.628787878787879, 0.5816666666666666, 1.0, 1.0, 0.1413449654115855, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12683936100120716, 0.12683936100120716, 0.27551665301417194], 
reward next is 0.7245, 
noisyNet noise sample is [array([-0.33883977], dtype=float32), 0.30813766]. 
=============================================
[2019-03-23 12:06:54,435] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.1861452e-07 9.9999976e-01 3.9883775e-15 7.6679874e-18 8.8442621e-12], sum to 1.0000
[2019-03-23 12:06:54,442] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2062
[2019-03-23 12:06:54,450] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 57.0, 1.0, 2.0, 0.3306451448063228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 364728.5102100467, 364728.510210047, 115335.9579086701], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3864600.0000, 
sim time next is 3865200.0000, 
raw observation next is [22.33333333333334, 57.0, 1.0, 2.0, 0.3263903732071055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 359124.8409203329, 359124.8409203329, 114672.8464183704], 
processed observation next is [0.0, 0.7391304347826086, 0.6515151515151518, 0.57, 1.0, 1.0, 0.15798796650888186, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13300920034086403, 0.13300920034086403, 0.2796898693130985], 
reward next is 0.7203, 
noisyNet noise sample is [array([0.59585243], dtype=float32), 0.21088557]. 
=============================================
[2019-03-23 12:06:56,075] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.5012070e-10 1.0000000e+00 2.3310418e-19 1.0648505e-25 1.1676878e-15], sum to 1.0000
[2019-03-23 12:06:56,081] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1491
[2019-03-23 12:06:56,085] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 77.0, 1.0, 2.0, 0.281226297896304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 305363.8185248253, 305363.818524825, 101629.3232344219], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3895800.0000, 
sim time next is 3896400.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.2802719496107651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 304327.2347440493, 304327.2347440493, 101531.392387699], 
processed observation next is [0.0, 0.08695652173913043, 0.45454545454545453, 0.77, 1.0, 1.0, 0.10033993701345639, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1127137906459442, 0.1127137906459442, 0.24763754240902194], 
reward next is 0.7524, 
noisyNet noise sample is [array([0.47424662], dtype=float32), -0.3175878]. 
=============================================
[2019-03-23 12:06:56,360] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.0668196e-08 1.0000000e+00 1.3987492e-16 2.2716468e-19 8.1442535e-12], sum to 1.0000
[2019-03-23 12:06:56,367] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6036
[2019-03-23 12:06:56,375] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.83333333333334, 69.5, 1.0, 2.0, 0.2749894576857389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 298589.5943064849, 298589.5943064846, 98407.80215808265], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3885000.0000, 
sim time next is 3885600.0000, 
raw observation next is [18.66666666666667, 71.0, 1.0, 2.0, 0.2762123400048362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 299917.8362301589, 299917.8362301592, 99109.61966161139], 
processed observation next is [0.0, 1.0, 0.4848484848484851, 0.71, 1.0, 1.0, 0.09526542500604522, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11108068008524405, 0.11108068008524415, 0.2417307796624668], 
reward next is 0.7583, 
noisyNet noise sample is [array([-0.39933106], dtype=float32), 1.836955]. 
=============================================
[2019-03-23 12:06:57,387] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0447675e-06 9.9999893e-01 2.6564941e-16 3.7888604e-21 1.5434726e-12], sum to 1.0000
[2019-03-23 12:06:57,394] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1916
[2019-03-23 12:06:57,403] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333333, 49.0, 1.0, 2.0, 0.3263963829251046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 361296.1780651273, 361296.1780651273, 115519.1846385189], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3930000.0000, 
sim time next is 3930600.0000, 
raw observation next is [24.66666666666667, 48.0, 1.0, 2.0, 0.3293996194495492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 365257.0409152881, 365257.0409152881, 116003.0478077656], 
processed observation next is [0.0, 0.4782608695652174, 0.7575757575757578, 0.48, 1.0, 1.0, 0.16174952431193648, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13528038552418079, 0.13528038552418079, 0.28293426294576973], 
reward next is 0.7171, 
noisyNet noise sample is [array([-0.17982535], dtype=float32), -0.18188915]. 
=============================================
[2019-03-23 12:06:57,515] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8350796e-08 1.0000000e+00 3.3221066e-16 2.9679085e-20 4.9063206e-12], sum to 1.0000
[2019-03-23 12:06:57,523] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5611
[2019-03-23 12:06:57,528] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333334, 80.66666666666667, 1.0, 2.0, 0.2711254411958046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 294392.6904331248, 294392.6904331245, 97288.58006776505], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3903600.0000, 
sim time next is 3904200.0000, 
raw observation next is [17.25, 81.0, 1.0, 2.0, 0.2696518106823413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 292792.1152899305, 292792.1152899302, 96526.00521144077], 
processed observation next is [0.0, 0.17391304347826086, 0.42045454545454547, 0.81, 1.0, 1.0, 0.0870647633529266, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10844152418145574, 0.10844152418145563, 0.23542928100351407], 
reward next is 0.7646, 
noisyNet noise sample is [array([1.634744], dtype=float32), 0.34569743]. 
=============================================
[2019-03-23 12:07:09,050] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0555109e-09 1.0000000e+00 3.2039892e-18 1.7902842e-23 8.6030379e-14], sum to 1.0000
[2019-03-23 12:07:09,058] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0999
[2019-03-23 12:07:09,067] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3812734379983369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 428126.4457387502, 428126.4457387505, 122405.1077385702], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4136400.0000, 
sim time next is 4137000.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3797694622690682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 426357.2636851329, 426357.2636851329, 122236.5225615439], 
processed observation next is [1.0, 0.9130434782608695, 0.45454545454545453, 1.0, 1.0, 1.0, 0.22471182783633525, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15791009766116032, 0.15791009766116032, 0.2981378599062046], 
reward next is 0.7019, 
noisyNet noise sample is [array([1.1760744], dtype=float32), -0.08438338]. 
=============================================
[2019-03-23 12:07:09,085] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[72.409546]
 [72.3715  ]
 [72.3675  ]
 [72.419044]
 [72.5315  ]], R is [[72.4120636 ]
 [72.38939667]
 [72.36625671]
 [72.34282684]
 [72.31920624]].
[2019-03-23 12:07:12,800] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1891790e-05 9.9998593e-01 3.0413696e-11 6.5433058e-14 2.1498377e-06], sum to 1.0000
[2019-03-23 12:07:12,807] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0689
[2019-03-23 12:07:12,817] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1127155.220707635 W.
[2019-03-23 12:07:12,822] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.66666666666666, 63.66666666666667, 1.0, 2.0, 0.9936141379325735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1127155.220707635, 1127155.220707635, 205949.8823043957], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4206000.0000, 
sim time next is 4206600.0000, 
raw observation next is [23.5, 65.0, 1.0, 2.0, 0.5194260583917081, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9442336905487166, 6.939234791878874, 6.9112, 77.32839458165799, 1138720.429860753, 1129615.310977372, 247266.7837310977], 
processed observation next is [1.0, 0.6956521739130435, 0.7045454545454546, 0.65, 1.0, 1.0, 0.39928257298963504, 0.0, 1.0, -0.25, 1.0, 0.5, 0.9203338436410239, 0.0028034791878874367, 0.0, 0.5084283601589685, 0.42174830735583446, 0.4183760411027304, 0.6030897164173115], 
reward next is 0.2567, 
noisyNet noise sample is [array([-0.88066566], dtype=float32), 0.2716963]. 
=============================================
[2019-03-23 12:07:13,795] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 12:07:13,797] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:07:13,798] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:07:13,798] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:07:13,799] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:07:13,800] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:07:13,801] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:07:13,801] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:07:13,802] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:07:13,803] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:07:13,805] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:07:13,814] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run14
[2019-03-23 12:07:13,815] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run14
[2019-03-23 12:07:13,864] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run14
[2019-03-23 12:07:13,888] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run14
[2019-03-23 12:07:13,888] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run14
[2019-03-23 12:07:24,161] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01834309], dtype=float32), 0.10581809]
[2019-03-23 12:07:24,162] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.0, 94.0, 1.0, 2.0, 0.2931818287795568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 318349.7359950736, 318349.7359950733, 102484.5161960098]
[2019-03-23 12:07:24,164] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:07:24,170] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.2509054e-07 9.9999988e-01 1.7626437e-14 2.1869903e-18 5.3856901e-09], sampled 0.7489553982567404
[2019-03-23 12:07:30,504] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01834309], dtype=float32), 0.10581809]
[2019-03-23 12:07:30,505] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.71666666666667, 58.33333333333334, 1.0, 2.0, 0.7390603800650987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 842345.578839313, 842345.5788393127, 179409.2760433912]
[2019-03-23 12:07:30,506] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:07:30,510] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.3388004e-07 9.9999988e-01 2.0145925e-14 2.5969666e-18 5.8379324e-09], sampled 0.9630512771583782
[2019-03-23 12:07:49,300] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01834309], dtype=float32), 0.10581809]
[2019-03-23 12:07:49,301] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.63382213, 53.52592439, 1.0, 2.0, 0.4480166314727009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 510303.1829694497, 510303.1829694493, 137503.9196231193]
[2019-03-23 12:07:49,302] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:07:49,304] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0126199e-07 9.9999988e-01 1.1635396e-14 1.2821243e-18 4.1915964e-09], sampled 0.5423126485497693
[2019-03-23 12:07:52,529] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01834309], dtype=float32), 0.10581809]
[2019-03-23 12:07:52,530] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [33.75352876166667, 61.54660356833333, 1.0, 2.0, 0.9562145457226006, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9865530188920543, 6.911199999999999, 6.9112, 95.55338768172592, 1623423.256775113, 1623423.256775114, 348985.4723659047]
[2019-03-23 12:07:52,532] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:07:52,535] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.2565606e-07 9.9999964e-01 1.1561688e-13 2.4553007e-17 1.6756871e-08], sampled 0.4484099189112477
[2019-03-23 12:07:52,537] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 1623423.256775113 W.
[2019-03-23 12:07:55,375] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01834309], dtype=float32), 0.10581809]
[2019-03-23 12:07:55,376] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.84385833, 93.39748702333334, 1.0, 2.0, 0.3159064046765276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 343934.7776005491, 343934.7776005488, 116897.2917993511]
[2019-03-23 12:07:55,379] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:07:55,382] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.8339640e-08 9.9999988e-01 8.8962236e-15 9.0794229e-19 3.5648877e-09], sampled 0.7530197397733912
[2019-03-23 12:08:05,424] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01834309], dtype=float32), 0.10581809]
[2019-03-23 12:08:05,426] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.44569095, 68.024357585, 1.0, 2.0, 0.30813420246592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 336676.6214515318, 336676.6214515315, 116793.6732007827]
[2019-03-23 12:08:05,427] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:08:05,429] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0330668e-07 9.9999988e-01 1.2102082e-14 1.3486048e-18 4.2922581e-09], sampled 0.37989425705284896
[2019-03-23 12:08:06,994] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01834309], dtype=float32), 0.10581809]
[2019-03-23 12:08:06,996] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.83333333333333, 56.83333333333334, 1.0, 2.0, 0.3975131641132382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 449560.1960131216, 449560.1960131213, 129872.8143714363]
[2019-03-23 12:08:06,998] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:08:07,002] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.9911929e-08 9.9999988e-01 1.1332786e-14 1.2394108e-18 4.1254631e-09], sampled 0.9415082812560996
[2019-03-23 12:08:20,429] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01834309], dtype=float32), 0.10581809]
[2019-03-23 12:08:20,431] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.15, 72.5, 1.0, 2.0, 0.7688144748832403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 876556.6735979819, 876556.6735979816, 183739.9541709175]
[2019-03-23 12:08:20,432] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:08:20,435] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.4190452e-07 9.9999988e-01 2.2587770e-14 3.0083881e-18 6.2551764e-09], sampled 0.8236370350222328
[2019-03-23 12:08:33,075] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01834309], dtype=float32), 0.10581809]
[2019-03-23 12:08:33,076] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.9, 90.0, 1.0, 2.0, 0.3689741281689184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 413167.9178575227, 413167.9178575223, 125127.5938029643]
[2019-03-23 12:08:33,078] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:08:33,081] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.2540120e-08 9.9999988e-01 9.7474722e-15 1.0211229e-18 3.7670103e-09], sampled 0.5505074426893501
[2019-03-23 12:08:36,404] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01834309], dtype=float32), 0.10581809]
[2019-03-23 12:08:36,405] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.55402455666667, 76.79362580666668, 1.0, 2.0, 0.2382140492847939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 258634.3140011064, 258634.3140011061, 94705.73248666384]
[2019-03-23 12:08:36,406] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:08:36,408] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.7573009e-07 9.9999988e-01 3.4387098e-14 5.1639165e-18 8.0607654e-09], sampled 0.2838334025842234
[2019-03-23 12:08:52,300] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 12:08:52,583] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 12:08:52,688] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 12:08:52,738] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 12:08:52,744] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 12:08:53,759] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 325000, evaluation results [325000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 12:09:00,733] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4261636e-05 9.9995196e-01 3.1477015e-08 1.8663925e-12 3.3744851e-05], sum to 1.0000
[2019-03-23 12:09:00,741] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1480
[2019-03-23 12:09:00,746] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 51.66666666666666, 1.0, 2.0, 0.3692747509370855, 1.0, 1.0, 0.3692747509370855, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 841685.7975362298, 841685.7975362298, 200866.7242298363], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4381800.0000, 
sim time next is 4382400.0000, 
raw observation next is [28.0, 52.33333333333334, 1.0, 2.0, 0.4652692086951631, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 530883.8952009607, 530883.8952009607, 137311.6545606637], 
processed observation next is [1.0, 0.7391304347826086, 0.9090909090909091, 0.5233333333333334, 1.0, 1.0, 0.3315865108689538, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1966236648892447, 0.1966236648892447, 0.33490647453820416], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.98926234], dtype=float32), -2.1420534]. 
=============================================
[2019-03-23 12:09:02,490] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.2930516e-06 9.9997807e-01 1.4442635e-13 1.6227082e-17 1.4621624e-05], sum to 1.0000
[2019-03-23 12:09:02,498] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8755
[2019-03-23 12:09:02,503] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.4132752629070427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468444.6084590276, 468444.6084590276, 127676.4365039124], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4420800.0000, 
sim time next is 4421400.0000, 
raw observation next is [20.83333333333333, 83.83333333333334, 1.0, 2.0, 0.4100424767217192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 464536.064994645, 464536.0649946447, 127206.9684275269], 
processed observation next is [0.0, 0.17391304347826086, 0.5833333333333331, 0.8383333333333334, 1.0, 1.0, 0.2625530959021489, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17205039444246112, 0.172050394442461, 0.31026089860372413], 
reward next is 0.6897, 
noisyNet noise sample is [array([0.06217744], dtype=float32), -0.6099187]. 
=============================================
[2019-03-23 12:09:05,108] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8221731e-07 9.9999571e-01 7.4540153e-14 1.6989148e-17 4.0642867e-06], sum to 1.0000
[2019-03-23 12:09:05,118] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7710
[2019-03-23 12:09:05,121] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 81.33333333333334, 1.0, 2.0, 0.4812188917576605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 549107.309003255, 549107.309003255, 138617.868606542], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4476000.0000, 
sim time next is 4476600.0000, 
raw observation next is [23.0, 80.5, 1.0, 2.0, 0.4780033534584129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 545401.8148420979, 545401.8148420979, 138014.8854261381], 
processed observation next is [0.0, 0.8260869565217391, 0.6818181818181818, 0.805, 1.0, 1.0, 0.34750419182301606, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20200067216373999, 0.20200067216373999, 0.3366216717710685], 
reward next is 0.6634, 
noisyNet noise sample is [array([-0.50374985], dtype=float32), -0.9008817]. 
=============================================
[2019-03-23 12:09:06,243] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.9757228e-08 9.9999118e-01 8.2449332e-15 8.3245575e-19 8.7909420e-06], sum to 1.0000
[2019-03-23 12:09:06,253] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1182
[2019-03-23 12:09:06,256] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.4622335744862021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 527210.8604073273, 527210.8604073273, 135701.8450041212], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4495800.0000, 
sim time next is 4496400.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.4629136109970758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 527987.0674436156, 527987.0674436156, 135775.3963370891], 
processed observation next is [0.0, 0.043478260869565216, 0.5909090909090909, 0.94, 1.0, 1.0, 0.3286420137463447, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19555076571985763, 0.19555076571985763, 0.3311595032611929], 
reward next is 0.6688, 
noisyNet noise sample is [array([1.4541368], dtype=float32), -0.5511283]. 
=============================================
[2019-03-23 12:09:09,573] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.6579494e-07 9.9999952e-01 3.4681252e-14 1.3891762e-17 3.9801662e-07], sum to 1.0000
[2019-03-23 12:09:09,579] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4807
[2019-03-23 12:09:09,586] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 46.0, 1.0, 2.0, 0.6129047410863521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 668344.0201107907, 668344.0201107907, 138535.9444202582], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4628400.0000, 
sim time next is 4629000.0000, 
raw observation next is [23.83333333333333, 46.5, 1.0, 2.0, 0.6317883361924831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 692024.1951508492, 692024.1951508494, 141495.6057775584], 
processed observation next is [1.0, 0.5652173913043478, 0.7196969696969695, 0.465, 1.0, 1.0, 0.5397354202406038, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2563052574632775, 0.25630525746327754, 0.34511123360380097], 
reward next is 0.6549, 
noisyNet noise sample is [array([-0.02960036], dtype=float32), 0.09964007]. 
=============================================
[2019-03-23 12:09:09,609] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[67.06957 ]
 [67.44434 ]
 [67.91578 ]
 [68.242516]
 [68.02723 ]], R is [[66.72636414]
 [66.72121429]
 [66.72415161]
 [66.74716949]
 [66.80794525]].
[2019-03-23 12:09:16,992] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5781579e-07 9.9999166e-01 2.1826534e-12 9.1106857e-17 8.2477663e-06], sum to 1.0000
[2019-03-23 12:09:16,999] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8904
[2019-03-23 12:09:17,007] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.5, 79.5, 1.0, 2.0, 0.2518957185908784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 273506.8540657267, 273506.8540657265, 85645.39782466456], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4667400.0000, 
sim time next is 4668000.0000, 
raw observation next is [16.33333333333333, 80.33333333333333, 1.0, 2.0, 0.250527585085224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 272020.9275178294, 272020.9275178294, 85031.21121117147], 
processed observation next is [1.0, 0.0, 0.37878787878787856, 0.8033333333333332, 1.0, 1.0, 0.06315948135652998, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10074849167327014, 0.10074849167327014, 0.20739319807602796], 
reward next is 0.7926, 
noisyNet noise sample is [array([-0.06120289], dtype=float32), -0.772943]. 
=============================================
[2019-03-23 12:09:17,025] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[61.799877]
 [61.779007]
 [61.780693]
 [61.796974]
 [61.92845 ]], R is [[61.95387268]
 [62.1254425 ]
 [62.29365921]
 [62.45839691]
 [62.61967087]].
[2019-03-23 12:09:24,306] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.1895837e-06 9.6749854e-01 2.7441127e-12 3.9296374e-15 3.2497279e-02], sum to 1.0000
[2019-03-23 12:09:24,314] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0297
[2019-03-23 12:09:24,318] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.4579688779368812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 522344.1440196138, 522344.1440196141, 135244.4882970014], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4834800.0000, 
sim time next is 4835400.0000, 
raw observation next is [20.83333333333333, 95.0, 1.0, 2.0, 0.45745913649009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 521727.0803027492, 521727.0803027492, 135113.238727797], 
processed observation next is [1.0, 1.0, 0.5833333333333331, 0.95, 1.0, 1.0, 0.3218239206126125, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19323225196398117, 0.19323225196398117, 0.3295444847019439], 
reward next is 0.6705, 
noisyNet noise sample is [array([0.8245444], dtype=float32), 1.0055561]. 
=============================================
[2019-03-23 12:09:24,458] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.4854544e-05 9.5850152e-01 2.6161220e-09 7.8285543e-16 4.1463561e-02], sum to 1.0000
[2019-03-23 12:09:24,463] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6281
[2019-03-23 12:09:24,467] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 98.0, 1.0, 2.0, 0.4842551527551972, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 552578.4160205754, 552578.4160205754, 139249.9826603861], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4828800.0000, 
sim time next is 4829400.0000, 
raw observation next is [21.0, 97.0, 1.0, 2.0, 0.4794323607507651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 547070.2273493315, 547070.2273493315, 138452.7933235102], 
processed observation next is [1.0, 0.9130434782608695, 0.5909090909090909, 0.97, 1.0, 1.0, 0.34929045093845634, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20261860272197463, 0.20261860272197463, 0.3376897398134395], 
reward next is 0.6623, 
noisyNet noise sample is [array([1.1557399], dtype=float32), 0.5660134]. 
=============================================
[2019-03-23 12:09:25,865] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.8001872e-06 9.9980825e-01 1.5129675e-11 1.6409946e-16 1.8800024e-04], sum to 1.0000
[2019-03-23 12:09:25,872] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5145
[2019-03-23 12:09:25,874] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.4055220e-08 9.9999964e-01 2.8246166e-13 1.4435132e-16 3.4355321e-07], sum to 1.0000
[2019-03-23 12:09:25,877] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4480747105443938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 508007.2507688553, 508007.250768855, 131134.0359658178], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4864200.0000, 
sim time next is 4864800.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4568896393274866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 518029.3505497647, 518029.3505497644, 132035.9268510284], 
processed observation next is [1.0, 0.30434782608695654, 0.5, 1.0, 1.0, 1.0, 0.3211120491593582, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19186272242583877, 0.19186272242583868, 0.32203884597811805], 
reward next is 0.6780, 
noisyNet noise sample is [array([1.6703619], dtype=float32), 1.0433217]. 
=============================================
[2019-03-23 12:09:25,883] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1961
[2019-03-23 12:09:25,887] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.43010038985941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 487589.7338302037, 487589.7338302037, 129339.6793281695], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4863600.0000, 
sim time next is 4864200.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4480747105443938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 508007.2507688553, 508007.250768855, 131134.0359658178], 
processed observation next is [1.0, 0.30434782608695654, 0.5, 1.0, 1.0, 1.0, 0.3100933881804922, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18815083361809454, 0.18815083361809443, 0.31983911211175076], 
reward next is 0.6802, 
noisyNet noise sample is [array([0.9810004], dtype=float32), 0.6058688]. 
=============================================
[2019-03-23 12:09:33,083] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.9245644e-07 9.9999154e-01 3.8273304e-12 6.9324044e-21 8.2062925e-06], sum to 1.0000
[2019-03-23 12:09:33,089] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0853
[2019-03-23 12:09:33,095] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 79.5, 1.0, 2.0, 0.2857382479591615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 310264.5899475627, 310264.5899475624, 99348.35527307645], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5002200.0000, 
sim time next is 5002800.0000, 
raw observation next is [17.66666666666667, 78.66666666666666, 1.0, 2.0, 0.2875592666699215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 312242.5505742441, 312242.5505742441, 100484.0276908809], 
processed observation next is [1.0, 0.9130434782608695, 0.4393939393939396, 0.7866666666666666, 1.0, 1.0, 0.10944908333740185, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11564538910157189, 0.11564538910157189, 0.2450829943680022], 
reward next is 0.7549, 
noisyNet noise sample is [array([0.27291003], dtype=float32), -2.5202706]. 
=============================================
[2019-03-23 12:09:33,472] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.3710860e-09 9.9992740e-01 7.9950566e-14 1.1707952e-17 7.2649957e-05], sum to 1.0000
[2019-03-23 12:09:33,482] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7253
[2019-03-23 12:09:33,488] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.33333333333333, 92.0, 1.0, 2.0, 0.2632068878512662, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 285792.0620363351, 285792.0620363351, 88621.71087604815], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5016000.0000, 
sim time next is 5016600.0000, 
raw observation next is [15.0, 94.0, 1.0, 2.0, 0.258899403154971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 281113.6103266894, 281113.6103266897, 87151.00490283675], 
processed observation next is [0.0, 0.043478260869565216, 0.3181818181818182, 0.94, 1.0, 1.0, 0.07362425394371375, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10411615197284792, 0.10411615197284804, 0.21256342659228475], 
reward next is 0.7874, 
noisyNet noise sample is [array([-0.78990906], dtype=float32), 1.7070348]. 
=============================================
[2019-03-23 12:09:34,287] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7746966e-09 9.9998748e-01 2.0574394e-13 1.2964180e-21 1.2541269e-05], sum to 1.0000
[2019-03-23 12:09:34,296] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5870
[2019-03-23 12:09:34,301] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 80.5, 1.0, 2.0, 0.4283156138530803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 487389.0147424785, 487389.0147424788, 130625.6628451537], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5095800.0000, 
sim time next is 5096400.0000, 
raw observation next is [22.0, 79.66666666666667, 1.0, 2.0, 0.4249314496288941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 483273.9570742114, 483273.9570742114, 130040.1834164642], 
processed observation next is [0.0, 1.0, 0.6363636363636364, 0.7966666666666667, 1.0, 1.0, 0.28116431203611764, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17899035447193015, 0.17899035447193015, 0.31717117906454684], 
reward next is 0.6828, 
noisyNet noise sample is [array([1.0494895], dtype=float32), 0.5638492]. 
=============================================
[2019-03-23 12:09:36,392] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.1904254e-07 9.9946338e-01 5.7728149e-11 4.7277652e-15 5.3616083e-04], sum to 1.0000
[2019-03-23 12:09:36,401] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7356
[2019-03-23 12:09:36,408] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666666, 56.00000000000001, 1.0, 2.0, 0.369169287482543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416321.6267677371, 416321.6267677371, 122308.0835391602], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5055600.0000, 
sim time next is 5056200.0000, 
raw observation next is [25.0, 55.5, 1.0, 2.0, 0.3757208258897861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 424540.9147258562, 424540.9147258559, 123354.7472466461], 
processed observation next is [0.0, 0.5217391304347826, 0.7727272727272727, 0.555, 1.0, 1.0, 0.21965103236223263, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15723737582439118, 0.1572373758243911, 0.3008652371869417], 
reward next is 0.6991, 
noisyNet noise sample is [array([0.47555035], dtype=float32), 0.31306145]. 
=============================================
[2019-03-23 12:09:37,789] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.9826638e-10 1.0000000e+00 2.9348037e-16 5.3077084e-20 2.7642390e-08], sum to 1.0000
[2019-03-23 12:09:37,798] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9086
[2019-03-23 12:09:37,805] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 56.83333333333334, 1.0, 2.0, 0.4288532755612173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 488531.3779544732, 488531.3779544732, 131258.8522644864], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5079000.0000, 
sim time next is 5079600.0000, 
raw observation next is [26.0, 58.0, 1.0, 2.0, 0.4314489718346127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 491577.6041171407, 491577.6041171407, 131632.5897640944], 
processed observation next is [0.0, 0.8260869565217391, 0.8181818181818182, 0.58, 1.0, 1.0, 0.2893112147932659, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1820657793026447, 0.1820657793026447, 0.3210550969855961], 
reward next is 0.6789, 
noisyNet noise sample is [array([-0.4601157], dtype=float32), -1.087879]. 
=============================================
[2019-03-23 12:09:37,975] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6397678e-11 1.0000000e+00 1.9768021e-15 7.8735063e-22 1.3653472e-08], sum to 1.0000
[2019-03-23 12:09:37,979] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9645
[2019-03-23 12:09:37,985] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 79.66666666666666, 1.0, 2.0, 0.4301111044937329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489775.6586095421, 489775.6586095421, 131163.9476945642], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5092800.0000, 
sim time next is 5093400.0000, 
raw observation next is [22.16666666666667, 81.33333333333334, 1.0, 2.0, 0.4321557188523262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 492225.4812296815, 492225.4812296818, 131509.1027836364], 
processed observation next is [0.0, 0.9565217391304348, 0.6439393939393941, 0.8133333333333335, 1.0, 1.0, 0.29019464856540766, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18230573378877094, 0.18230573378877105, 0.32075390922838143], 
reward next is 0.6792, 
noisyNet noise sample is [array([-0.18078758], dtype=float32), -1.8996278]. 
=============================================
[2019-03-23 12:09:39,929] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.7995691e-09 9.9999428e-01 3.5984592e-12 1.3472508e-17 5.7445673e-06], sum to 1.0000
[2019-03-23 12:09:39,939] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3978
[2019-03-23 12:09:39,943] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4304247081187441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 490380.4218633093, 490380.4218633093, 131490.3690173766], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5201400.0000, 
sim time next is 5202000.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4308359050608702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 490849.1951359095, 490849.1951359095, 131532.1677195505], 
processed observation next is [1.0, 0.21739130434782608, 0.6363636363636364, 0.83, 1.0, 1.0, 0.28854488132608774, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.181795998198485, 0.181795998198485, 0.32081016516963534], 
reward next is 0.6792, 
noisyNet noise sample is [array([0.20160142], dtype=float32), -1.6097296]. 
=============================================
[2019-03-23 12:09:39,971] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[64.27338 ]
 [64.249626]
 [64.19844 ]
 [64.17866 ]
 [64.13501 ]], R is [[64.34225464]
 [64.37812805]
 [64.41339874]
 [64.44792175]
 [64.48065948]].
[2019-03-23 12:09:42,129] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 12:09:42,131] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:09:42,131] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:09:42,131] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:09:42,132] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:09:42,133] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:09:42,133] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:09:42,135] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:09:42,136] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:09:42,138] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:09:42,138] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:09:42,149] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run15
[2019-03-23 12:09:42,173] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run15
[2019-03-23 12:09:42,199] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run15
[2019-03-23 12:09:42,199] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run15
[2019-03-23 12:09:42,225] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run15
[2019-03-23 12:10:02,105] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01834309], dtype=float32), 0.08678981]
[2019-03-23 12:10:02,107] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.83333333333333, 95.0, 1.0, 2.0, 0.4580815146849653, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522440.4920216106, 522440.4920216106, 135186.4700455592]
[2019-03-23 12:10:02,108] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:10:02,112] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.8978339e-10 1.0000000e+00 1.2429693e-14 5.5333943e-20 1.7080371e-08], sampled 0.7223409798749428
[2019-03-23 12:10:20,325] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01834309], dtype=float32), 0.08678981]
[2019-03-23 12:10:20,325] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.93333333333333, 75.33333333333333, 1.0, 2.0, 0.3092771784447441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 336279.6783698978, 336279.6783698974, 116287.695021442]
[2019-03-23 12:10:20,326] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:10:20,328] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.1624917e-10 1.0000000e+00 1.4101568e-14 6.5908504e-20 1.8333408e-08], sampled 0.8748204249954104
[2019-03-23 12:10:32,688] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01834309], dtype=float32), 0.08678981]
[2019-03-23 12:10:32,689] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.98899481, 89.48133186333334, 1.0, 2.0, 0.5666519297482913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 642050.9136666701, 642050.9136666701, 157219.1752043033]
[2019-03-23 12:10:32,691] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:10:32,694] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.5741913e-10 1.0000000e+00 5.1494275e-15 1.6318915e-20 1.0419039e-08], sampled 0.3990584697925149
[2019-03-23 12:10:41,091] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01834309], dtype=float32), 0.08678981]
[2019-03-23 12:10:41,092] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.80272106, 85.17112225, 1.0, 2.0, 0.4605737889545803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 522946.4449111464, 522946.4449111461, 137279.9715824335]
[2019-03-23 12:10:41,096] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:10:41,099] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.8762209e-10 1.0000000e+00 1.2295854e-14 5.4510369e-20 1.6977021e-08], sampled 0.735323622461842
[2019-03-23 12:10:48,856] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01834309], dtype=float32), 0.08678981]
[2019-03-23 12:10:48,856] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.13271991333333, 72.59395474666667, 1.0, 2.0, 0.2978244038454229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 323372.0182516641, 323372.0182516637, 101812.2578531405]
[2019-03-23 12:10:48,859] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:10:48,862] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.7195089e-10 1.0000000e+00 1.7824421e-14 9.1186064e-20 2.0908157e-08], sampled 0.25478826048028846
[2019-03-23 12:11:05,558] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01834309], dtype=float32), 0.08678981]
[2019-03-23 12:11:05,559] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.2, 86.0, 1.0, 2.0, 0.4003455244790121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 452187.6929010075, 452187.6929010071, 129789.5353032414]
[2019-03-23 12:11:05,560] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:11:05,565] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.3421853e-10 1.0000000e+00 9.1400471e-15 3.6140238e-20 1.4374996e-08], sampled 0.6159413283206299
[2019-03-23 12:11:16,147] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01834309], dtype=float32), 0.08678981]
[2019-03-23 12:11:16,148] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [12.56666666666667, 87.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 194222.4771770516, 194222.4771770509, 70692.20691031856]
[2019-03-23 12:11:16,149] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:11:16,152] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.9757437e-10 1.0000000e+00 2.7133311e-14 1.6322970e-19 2.6465649e-08], sampled 0.511033310799529
[2019-03-23 12:11:21,339] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 12:11:21,486] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 12:11:21,523] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9310 1705987275.5940 465.0000
[2019-03-23 12:11:21,529] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 12:11:21,720] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01834309], dtype=float32), 0.08678981]
[2019-03-23 12:11:21,720] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.20835674, 90.13161008, 1.0, 2.0, 0.5598530499124288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 632808.4817757392, 632808.4817757392, 156830.6713148379]
[2019-03-23 12:11:21,720] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:11:21,721] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.7477723e-10 1.0000000e+00 1.1510946e-14 4.9749023e-20 1.6360339e-08], sampled 0.3607190281134566
[2019-03-23 12:11:21,762] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 12:11:22,780] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 350000, evaluation results [350000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.931041181726, 1705987275.594041, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 12:11:30,145] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.8934435e-05 9.9619883e-01 3.4093424e-07 2.5501770e-09 3.7518139e-03], sum to 1.0000
[2019-03-23 12:11:30,154] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2117
[2019-03-23 12:11:30,161] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1110311.221889808 W.
[2019-03-23 12:11:30,166] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.15, 52.5, 1.0, 2.0, 0.9732301065310323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1110311.221889808, 1110311.221889808, 208736.4801113695], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5308200.0000, 
sim time next is 5308800.0000, 
raw observation next is [27.33333333333334, 52.0, 1.0, 2.0, 0.498132589651147, 1.0, 1.0, 0.498132589651147, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1137242.739643379, 1137242.739643379, 226577.6442616415], 
processed observation next is [1.0, 0.43478260869565216, 0.878787878787879, 0.52, 1.0, 1.0, 0.3726657370639337, 1.0, 0.5, 0.3726657370639337, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.421201014682733, 0.421201014682733, 0.55262840063815], 
reward next is 0.4474, 
noisyNet noise sample is [array([-0.54431593], dtype=float32), 0.75961745]. 
=============================================
[2019-03-23 12:11:32,465] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.3733390e-08 9.9848121e-01 1.0868688e-13 6.7791160e-16 1.5188097e-03], sum to 1.0000
[2019-03-23 12:11:32,469] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0510
[2019-03-23 12:11:32,477] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.38333333333333, 78.16666666666667, 1.0, 2.0, 0.4665356686963179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 532310.8156102602, 532310.8156102602, 136756.6663323525], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5359800.0000, 
sim time next is 5360400.0000, 
raw observation next is [23.3, 79.0, 1.0, 2.0, 0.4677389748796388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 533698.0382902558, 533698.0382902558, 136965.1974531228], 
processed observation next is [1.0, 0.043478260869565216, 0.6954545454545454, 0.79, 1.0, 1.0, 0.3346737185995484, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19766594010750216, 0.19766594010750216, 0.3340614572027385], 
reward next is 0.6659, 
noisyNet noise sample is [array([-2.1129634], dtype=float32), 0.49003577]. 
=============================================
[2019-03-23 12:11:33,532] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.0166844e-07 9.9987102e-01 3.2893217e-09 1.7887380e-13 1.2802503e-04], sum to 1.0000
[2019-03-23 12:11:33,538] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5527
[2019-03-23 12:11:33,544] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1391886.166103469 W.
[2019-03-23 12:11:33,547] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.6, 72.0, 1.0, 2.0, 0.4125963099092561, 1.0, 2.0, 0.4125963099092561, 1.0, 1.0, 0.834838887830835, 6.9112, 6.9112, 77.3421103, 1391886.166103469, 1391886.166103469, 313479.7880759776], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5394600.0000, 
sim time next is 5395200.0000, 
raw observation next is [26.96666666666667, 70.33333333333333, 1.0, 2.0, 0.6624118667320105, 1.0, 2.0, 0.6624118667320105, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1489885.36463235, 1489885.36463235, 280195.0314277285], 
processed observation next is [1.0, 0.43478260869565216, 0.8621212121212122, 0.7033333333333333, 1.0, 1.0, 0.578014833415013, 1.0, 1.0, 0.578014833415013, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5518093943082778, 0.5518093943082778, 0.6834025156773865], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.61602765], dtype=float32), 0.5229655]. 
=============================================
[2019-03-23 12:11:33,602] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.5730665e-07 9.9983585e-01 3.9478039e-11 1.1022041e-13 1.6334833e-04], sum to 1.0000
[2019-03-23 12:11:33,605] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6287
[2019-03-23 12:11:33,611] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1123267.562553387 W.
[2019-03-23 12:11:33,619] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.06666666666667, 63.00000000000001, 1.0, 2.0, 0.4995729036504657, 1.0, 2.0, 0.4995729036504657, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1123267.562553387, 1123267.562553387, 235386.1446529593], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5401200.0000, 
sim time next is 5401800.0000, 
raw observation next is [28.25, 63.0, 1.0, 2.0, 0.4318964198233721, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8734900555276037, 6.9112, 6.9112, 77.32846344354104, 974401.832104213, 974401.832104213, 242676.8929059592], 
processed observation next is [1.0, 0.5217391304347826, 0.9204545454545454, 0.63, 1.0, 1.0, 0.2898705247792151, 0.0, 0.5, -0.25, 1.0, 0.5, 0.8192715078965768, 0.0, 0.0, 0.5084288129206541, 0.3608895674460048, 0.3608895674460048, 0.591894860746242], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7357621], dtype=float32), 0.24765293]. 
=============================================
[2019-03-23 12:11:36,972] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.9709229e-11 9.9995291e-01 4.2502538e-14 2.0369254e-19 4.7114303e-05], sum to 1.0000
[2019-03-23 12:11:36,981] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2773
[2019-03-23 12:11:36,987] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 91.0, 1.0, 2.0, 0.3316167428948806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 361732.7097774438, 361732.7097774441, 113923.2940866328], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5465400.0000, 
sim time next is 5466000.0000, 
raw observation next is [17.2, 92.0, 1.0, 2.0, 0.3295657894598234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 360245.6699801909, 360245.6699801909, 114040.1667386363], 
processed observation next is [1.0, 0.2608695652173913, 0.41818181818181815, 0.92, 1.0, 1.0, 0.16195723682477922, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13342432221488554, 0.13342432221488554, 0.2781467481430154], 
reward next is 0.7219, 
noisyNet noise sample is [array([-0.24606153], dtype=float32), -0.6386731]. 
=============================================
[2019-03-23 12:11:37,000] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[79.00184 ]
 [79.03842 ]
 [79.11786 ]
 [79.15138 ]
 [79.200195]], R is [[78.89212036]
 [78.82534027]
 [78.75975037]
 [78.69625854]
 [78.63345337]].
[2019-03-23 12:11:39,877] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.9930724e-04 4.5536503e-02 4.4719850e-06 1.2943307e-08 9.5425969e-01], sum to 1.0000
[2019-03-23 12:11:39,892] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0008
[2019-03-23 12:11:39,906] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1252505.239336556 W.
[2019-03-23 12:11:39,912] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.36666666666667, 72.33333333333334, 1.0, 2.0, 0.3694923073600299, 1.0, 2.0, 0.3694923073600299, 1.0, 2.0, 0.7476422251459124, 6.911199999999999, 6.9112, 77.3421103, 1252505.239336556, 1252505.239336557, 290722.3661665616], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5484000.0000, 
sim time next is 5484600.0000, 
raw observation next is [25.55, 71.5, 1.0, 2.0, 0.3712364304509791, 1.0, 2.0, 0.3712364304509791, 1.0, 2.0, 0.7510572069909275, 6.9112, 6.9112, 77.3421103, 1257839.657821035, 1257839.657821035, 291692.2442426807], 
processed observation next is [1.0, 0.4782608695652174, 0.7977272727272727, 0.715, 1.0, 1.0, 0.21404553806372384, 1.0, 1.0, 0.21404553806372384, 1.0, 1.0, 0.6443674385584679, 0.0, 0.0, 0.5085185399722538, 0.4658665399337167, 0.4658665399337167, 0.7114444981528798], 
reward next is 0.2886, 
noisyNet noise sample is [array([0.8654264], dtype=float32), 0.9973108]. 
=============================================
[2019-03-23 12:11:41,294] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.0448555e-02 5.9486181e-01 2.8289917e-03 2.0904755e-04 3.5165155e-01], sum to 1.0000
[2019-03-23 12:11:41,303] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1820
[2019-03-23 12:11:41,307] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.41666666666667, 90.5, 1.0, 2.0, 0.4130068238551519, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469500.4020221992, 469500.4020221992, 128685.7165170418], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5550600.0000, 
sim time next is 5551200.0000, 
raw observation next is [20.5, 90.0, 1.0, 2.0, 0.413345824781256, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469599.9463301119, 469599.9463301119, 128479.7150180203], 
processed observation next is [1.0, 0.2608695652173913, 0.5681818181818182, 0.9, 1.0, 1.0, 0.26668228097656993, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17392590604818958, 0.17392590604818958, 0.3133651585805373], 
reward next is 0.6866, 
noisyNet noise sample is [array([-0.31955948], dtype=float32), 0.13543412]. 
=============================================
[2019-03-23 12:11:42,719] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.1840341e-06 9.9942362e-01 1.9254846e-11 1.5060237e-15 5.7314831e-04], sum to 1.0000
[2019-03-23 12:11:42,723] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7613
[2019-03-23 12:11:42,727] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 80.0, 1.0, 2.0, 0.6885634090063295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 785805.5151232829, 785805.5151232831, 164429.4259385933], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5560200.0000, 
sim time next is 5560800.0000, 
raw observation next is [23.26666666666667, 78.66666666666667, 1.0, 2.0, 0.850940807477097, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 971389.2098080979, 971389.2098080983, 189773.5946625015], 
processed observation next is [1.0, 0.34782608695652173, 0.6939393939393941, 0.7866666666666667, 1.0, 1.0, 0.8136760093463713, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3597737814104066, 0.3597737814104068, 0.4628624260061012], 
reward next is 0.5371, 
noisyNet noise sample is [array([0.72018427], dtype=float32), -1.4867352]. 
=============================================
[2019-03-23 12:11:45,092] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.5416011e-09 1.0000000e+00 1.1911765e-16 1.0454369e-20 3.1435794e-09], sum to 1.0000
[2019-03-23 12:11:45,099] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4583
[2019-03-23 12:11:45,108] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 92.5, 1.0, 2.0, 0.3925075496852522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 443177.1012022761, 443177.1012022761, 124658.9178786978], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5615400.0000, 
sim time next is 5616000.0000, 
raw observation next is [19.4, 93.0, 1.0, 2.0, 0.3945933573752975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 445773.5756164278, 445773.5756164278, 124986.3211270023], 
processed observation next is [0.0, 0.0, 0.5181818181818181, 0.93, 1.0, 1.0, 0.24324169671912185, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16510132430238067, 0.16510132430238067, 0.30484468567561535], 
reward next is 0.6952, 
noisyNet noise sample is [array([-0.56712824], dtype=float32), -0.25398818]. 
=============================================
[2019-03-23 12:11:45,134] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[64.07198 ]
 [64.0714  ]
 [64.087006]
 [64.102005]
 [64.114944]], R is [[64.1989212 ]
 [64.25289154]
 [64.30704498]
 [64.36125183]
 [64.41542053]].
[2019-03-23 12:11:47,242] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.0576691e-15 1.0000000e+00 1.3845904e-24 2.7533395e-28 8.4656826e-15], sum to 1.0000
[2019-03-23 12:11:47,250] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0064
[2019-03-23 12:11:47,256] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.8, 93.0, 1.0, 2.0, 0.2787138527987563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 302634.882615133, 302634.8826151327, 96347.66724424568], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5653800.0000, 
sim time next is 5654400.0000, 
raw observation next is [15.7, 93.0, 1.0, 2.0, 0.2749694136876584, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 298567.8234122614, 298567.8234122611, 94671.9695961249], 
processed observation next is [0.0, 0.43478260869565216, 0.35, 0.93, 1.0, 1.0, 0.09371176710957302, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11058067533787458, 0.11058067533787448, 0.2309072429173778], 
reward next is 0.7691, 
noisyNet noise sample is [array([-1.7616528], dtype=float32), -0.35074297]. 
=============================================
[2019-03-23 12:11:49,083] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.3858091e-13 1.0000000e+00 1.1865754e-20 3.4200362e-25 5.3502879e-12], sum to 1.0000
[2019-03-23 12:11:49,088] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7462
[2019-03-23 12:11:49,093] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 83.0, 1.0, 2.0, 0.2300987668679725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 249833.7765943584, 249833.7765943587, 79808.73876209544], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5668800.0000, 
sim time next is 5669400.0000, 
raw observation next is [15.5, 82.0, 1.0, 2.0, 0.2261814881183015, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 245579.4486429417, 245579.4486429417, 78871.39301942098], 
processed observation next is [0.0, 0.6086956521739131, 0.3409090909090909, 0.82, 1.0, 1.0, 0.03272686014787685, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09095535134923766, 0.09095535134923766, 0.19236925126688045], 
reward next is 0.8076, 
noisyNet noise sample is [array([-0.44488072], dtype=float32), -1.4067419]. 
=============================================
[2019-03-23 12:11:50,014] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.1826208e-09 1.0000000e+00 7.8469165e-13 1.3869809e-15 2.3389378e-08], sum to 1.0000
[2019-03-23 12:11:50,024] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9461
[2019-03-23 12:11:50,027] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.1, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 163219.1922972146, 163219.1922972146, 59579.78386459305], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5708400.0000, 
sim time next is 5709000.0000, 
raw observation next is [11.1, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 162228.5255568689, 162228.5255568689, 59449.46271651904], 
processed observation next is [0.0, 0.043478260869565216, 0.1409090909090909, 0.77, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.06008463909513663, 0.06008463909513663, 0.14499868955248546], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3540969], dtype=float32), 0.4306592]. 
=============================================
[2019-03-23 12:11:50,038] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[45.749565]
 [45.825394]
 [45.82451 ]
 [45.906506]
 [45.983322]], R is [[45.24510574]
 [44.79265594]
 [44.34473038]
 [43.90128326]
 [43.46227264]].
[2019-03-23 12:11:54,095] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.5999839e-15 2.2677207e-15 7.7018507e-25 3.9009744e-20], sum to 1.0000
[2019-03-23 12:11:54,110] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2068
[2019-03-23 12:11:54,114] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [13.3, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3168899384951265, 6.9112, 6.9112, 77.32846344354104, 184714.16417701, 184714.16417701, 58715.28562488583], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5794200.0000, 
sim time next is 5794800.0000, 
raw observation next is [13.3, 74.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.318009221608451, 6.911199999999999, 6.9112, 77.32846344354104, 185366.7151478533, 185366.7151478536, 58755.22082517454], 
processed observation next is [1.0, 0.043478260869565216, 0.24090909090909093, 0.7433333333333333, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.02572745944064433, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.06865433894364938, 0.06865433894364947, 0.14330541664676716], 
reward next is 0.8567, 
noisyNet noise sample is [array([-1.0250111], dtype=float32), 0.8600332]. 
=============================================
[2019-03-23 12:11:55,269] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.000000e+00 1.710182e-08 4.981275e-08 9.077299e-14 8.546083e-12], sum to 1.0000
[2019-03-23 12:11:55,275] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8115
[2019-03-23 12:11:55,281] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [11.6, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7272655971241431, 7.088876047451895, 6.9112, 77.32785441279574, 480801.8097069741, 423096.7180809695, 94680.40924144286], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5809200.0000, 
sim time next is 5809800.0000, 
raw observation next is [11.6, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7260854448161579, 7.078971606282088, 6.9112, 77.3278862994412, 476896.8320748431, 422408.4525564483, 94534.93535869494], 
processed observation next is [1.0, 0.21739130434782608, 0.1636363636363636, 0.86, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6086934925945113, 0.016777160628208776, 0.0, 0.5084250182417416, 0.17662845632401597, 0.15644757502090678, 0.23057301306998768], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.16926923], dtype=float32), -0.0015773656]. 
=============================================
[2019-03-23 12:11:58,153] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9999738e-01 4.0526058e-11 2.5675354e-06 4.9438517e-17 2.0848731e-15], sum to 1.0000
[2019-03-23 12:11:58,160] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3059
[2019-03-23 12:11:58,165] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.36666666666667, 70.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6234487882775702, 6.911199999999999, 6.9112, 77.32846344354104, 361133.5251837177, 361133.525183718, 116584.8355163297], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5870400.0000, 
sim time next is 5871000.0000, 
raw observation next is [20.18333333333333, 71.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6261552076747688, 6.911199999999999, 6.9112, 77.32846344354104, 362727.666904875, 362727.6669048753, 116800.8147532514], 
processed observation next is [1.0, 0.9565217391304348, 0.5537878787878786, 0.7183333333333333, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.46593601096395554, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1343435803351389, 0.134343580335139, 0.28488003598354], 
reward next is 0.7151, 
noisyNet noise sample is [array([-0.7295736], dtype=float32), -0.42859688]. 
=============================================
[2019-03-23 12:11:58,187] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[59.87855 ]
 [59.8541  ]
 [59.828403]
 [59.786022]
 [59.75855 ]], R is [[60.02046204]
 [60.1359024 ]
 [60.25005722]
 [60.36273575]
 [60.47374344]].
[2019-03-23 12:12:01,055] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.00000000e+00 1.18846014e-12 1.41284255e-08 9.53857778e-15
 3.74079565e-14], sum to 1.0000
[2019-03-23 12:12:01,060] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8623
[2019-03-23 12:12:01,065] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 835742.3129615849 W.
[2019-03-23 12:12:01,070] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.93333333333333, 67.16666666666666, 1.0, 2.0, 0.2448123165608354, 1.0, 1.0, 0.2448123165608354, 1.0, 2.0, 0.4887073934724778, 6.911199999999999, 6.9112, 77.3421103, 835742.3129615849, 835742.3129615852, 229894.1800971487], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5910600.0000, 
sim time next is 5911200.0000, 
raw observation next is [23.3, 66.0, 1.0, 2.0, 0.3775439998761335, 1.0, 2.0, 0.3775439998761335, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 860089.1847812184, 860089.1847812184, 195485.6049722056], 
processed observation next is [1.0, 0.43478260869565216, 0.6954545454545454, 0.66, 1.0, 1.0, 0.22192999984516687, 1.0, 1.0, 0.22192999984516687, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3185515499189698, 0.3185515499189698, 0.47679415846879414], 
reward next is 0.5232, 
noisyNet noise sample is [array([0.2584681], dtype=float32), -0.7397498]. 
=============================================
[2019-03-23 12:12:10,157] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9999988e-01 2.9442358e-11 8.2501160e-08 1.5473827e-12 1.1403654e-09], sum to 1.0000
[2019-03-23 12:12:10,163] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0049
[2019-03-23 12:12:10,173] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.3, 83.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3859635815479872, 6.9112, 6.9112, 77.32846344354104, 224480.4473067071, 224480.4473067071, 68403.90895669455], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6065400.0000, 
sim time next is 6066000.0000, 
raw observation next is [14.4, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3839866673111975, 6.911199999999999, 6.9112, 77.32846344354104, 223330.389391577, 223330.3893915773, 68420.12514897497], 
processed observation next is [1.0, 0.21739130434782608, 0.29090909090909095, 0.83, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.11998095330171075, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0827149590339174, 0.08271495903391753, 0.16687835402189016], 
reward next is 0.8331, 
noisyNet noise sample is [array([0.6798273], dtype=float32), -0.43154058]. 
=============================================
[2019-03-23 12:12:10,196] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[33.423943]
 [33.48201 ]
 [33.508   ]
 [33.54731 ]
 [33.55233 ]], R is [[33.87934113]
 [34.37370682]
 [34.86355972]
 [35.34876633]
 [35.82878113]].
[2019-03-23 12:12:11,169] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 12:12:11,170] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:12:11,171] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:12:11,172] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:12:11,173] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:12:11,174] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:12:11,175] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:12:11,177] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:12:11,172] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:12:11,177] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:12:11,184] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:12:11,199] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run16
[2019-03-23 12:12:11,200] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run16
[2019-03-23 12:12:11,242] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run16
[2019-03-23 12:12:11,264] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run16
[2019-03-23 12:12:11,288] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run16
[2019-03-23 12:12:23,927] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01834309], dtype=float32), 0.09269144]
[2019-03-23 12:12:23,928] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.1, 64.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5718974151950127, 6.911200000000001, 6.9112, 95.55338769695034, 332636.7898075792, 332636.7898075789, 111812.7037320145]
[2019-03-23 12:12:23,931] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:12:23,935] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.00000000e+00 1.08851064e-26 4.52040275e-17 8.00713461e-24
 2.63095517e-21], sampled 0.8332066828043619
[2019-03-23 12:12:31,160] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01834309], dtype=float32), 0.09269144]
[2019-03-23 12:12:31,164] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.33333333333333, 97.16666666666667, 1.0, 2.0, 0.4862526160406053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 554788.4063558157, 554788.4063558157, 139907.8994017528]
[2019-03-23 12:12:31,165] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:12:31,170] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 1.7177706e-22 1.8543128e-14 3.9875010e-20 5.4015705e-18], sampled 0.6674230259981406
[2019-03-23 12:12:31,170] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 554788.4063558157 W.
[2019-03-23 12:12:38,741] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01834309], dtype=float32), 0.09269144]
[2019-03-23 12:12:38,743] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.36666666666667, 88.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7086772663742892, 7.101226792638856, 6.9112, 95.55273028981507, 483594.5797459419, 407332.748513533, 131244.7784518157]
[2019-03-23 12:12:38,744] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:12:38,747] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 4.7129777e-22 3.4212623e-14 9.4762095e-20 1.1761357e-17], sampled 0.4904579047133496
[2019-03-23 12:12:40,413] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01834309], dtype=float32), 0.09269144]
[2019-03-23 12:12:40,418] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.7, 55.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5181878394701709, 6.911200000000001, 6.9112, 95.55338769695034, 301389.4724740756, 301389.4724740752, 99822.4922210368]
[2019-03-23 12:12:40,419] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:12:40,421] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0000000e+00 1.0941021e-25 1.8945626e-16 6.0876301e-23 1.6192476e-20], sampled 0.05351471595642299
[2019-03-23 12:12:47,950] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01834309], dtype=float32), 0.09269144]
[2019-03-23 12:12:47,951] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.96666666666667, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6438365595960229, 6.911199999999999, 6.9112, 77.32846344354104, 372686.3429636347, 372686.342963635, 118583.5668674821]
[2019-03-23 12:12:47,952] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:12:47,957] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 4.8603113e-26 1.1423838e-16 2.9722436e-23 8.5357002e-21], sampled 0.25926859036823746
[2019-03-23 12:12:55,227] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01834309], dtype=float32), 0.09269144]
[2019-03-23 12:12:55,228] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.87827646333334, 94.19315016666667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7772721307770313, 7.598281637046703, 6.9112, 95.55124927083153, 716254.8122563887, 440518.4754187748, 143330.4615509983]
[2019-03-23 12:12:55,230] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:12:55,233] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 6.5192471e-24 2.4002116e-15 2.1809887e-21 4.0282321e-19], sampled 0.3171436939210721
[2019-03-23 12:12:55,236] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 716254.8122563887 W.
[2019-03-23 12:13:02,299] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01834309], dtype=float32), 0.09269144]
[2019-03-23 12:13:02,301] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.46666666666667, 90.66666666666667, 1.0, 2.0, 0.7222423466144087, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9297799505396644, 6.969933177323239, 6.9112, 101.0960270908588, 1370944.872462108, 1346006.570741738, 290034.6115854213]
[2019-03-23 12:13:02,303] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:13:02,306] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.00000000e+00 1.24620886e-19 1.12576105e-12 1.27619145e-17
 9.75300946e-16], sampled 0.7993011665705543
[2019-03-23 12:13:02,308] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1370944.872462108 W.
[2019-03-23 12:13:09,031] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01834309], dtype=float32), 0.09269144]
[2019-03-23 12:13:09,031] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.63706408, 89.86627945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7026708683591824, 7.087712992096399, 6.9112, 95.55255332574399, 477268.9812989359, 406430.659521029, 128731.9355204286]
[2019-03-23 12:13:09,033] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:13:09,036] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0000000e+00 1.1801641e-22 1.4545260e-14 2.7959525e-20 3.9613518e-18], sampled 0.08207002889379944
[2019-03-23 12:13:09,144] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01834309], dtype=float32), 0.09269144]
[2019-03-23 12:13:09,147] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.10614337, 98.81428143166667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4485912212475943, 6.9112, 6.9112, 95.55338769695034, 260901.7589093804, 260901.7589093804, 85687.06694735949]
[2019-03-23 12:13:09,147] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:13:09,152] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 5.1377044e-26 1.1783143e-16 3.1217006e-23 8.8776537e-21], sampled 0.9154608198623546
[2019-03-23 12:13:20,366] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01834309], dtype=float32), 0.09269144]
[2019-03-23 12:13:20,366] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.0, 83.0, 1.0, 2.0, 0.479193225248636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 546788.3110714079, 546788.3110714082, 138806.3465446754]
[2019-03-23 12:13:20,367] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:13:20,370] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 4.6701890e-21 1.4458966e-13 7.1976651e-19 7.2634558e-17], sampled 0.6844293031631771
[2019-03-23 12:13:20,371] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 546788.3110714079 W.
[2019-03-23 12:13:44,514] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01834309], dtype=float32), 0.09269144]
[2019-03-23 12:13:44,514] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.05340997333333, 37.95162875, 1.0, 2.0, 0.6937885691103435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 763624.3791670235, 763624.3791670235, 153967.3690467397]
[2019-03-23 12:13:44,516] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:13:44,518] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 2.6816211e-19 1.8207987e-12 2.5505787e-17 1.8001527e-15], sampled 0.5631022121182565
[2019-03-23 12:13:44,519] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 763624.3791670235 W.
[2019-03-23 12:13:46,716] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01834309], dtype=float32), 0.09269144]
[2019-03-23 12:13:46,716] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.0, 61.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5693830365697976, 6.911199999999999, 6.9112, 95.55338769695034, 330911.0526483497, 330911.0526483501, 115582.9355683431]
[2019-03-23 12:13:46,716] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:13:46,718] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 7.8891499e-27 3.7106171e-17 6.0541631e-24 2.0511874e-21], sampled 0.8152547618965612
[2019-03-23 12:13:46,802] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01834309], dtype=float32), 0.09269144]
[2019-03-23 12:13:46,802] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.0, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3904740450738423, 6.9112, 6.9112, 95.55338769695034, 227094.281058667, 227094.281058667, 75125.95188704178]
[2019-03-23 12:13:46,805] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:13:46,808] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0000000e+00 3.7849833e-26 9.7610072e-17 2.4042799e-23 6.9997203e-21], sampled 0.4836588050820546
[2019-03-23 12:13:50,534] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6294.9961 1685630448.6673 3228.0000
[2019-03-23 12:13:50,605] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6328.7217 1723294598.4314 3425.0000
[2019-03-23 12:13:50,785] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6862.2842 1793014293.7888 2409.0000
[2019-03-23 12:13:50,953] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6553.1725 1698634175.0084 2957.0000
[2019-03-23 12:13:50,980] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6481.6076 1678885180.2952 3057.0000
[2019-03-23 12:13:51,994] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 375000, evaluation results [375000.0, 6862.284208925443, 1793014293.78876, 2409.0, 6481.607577760913, 1678885180.2951708, 3057.0, 6294.9960618483565, 1685630448.6673346, 3228.0, 6328.721692698646, 1723294598.4313502, 3425.0, 6553.172466661831, 1698634175.0084193, 2957.0]
[2019-03-23 12:13:54,452] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.5511461e-25 3.1090060e-17 2.3187703e-24 2.0786057e-22], sum to 1.0000
[2019-03-23 12:13:54,461] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5296
[2019-03-23 12:13:54,464] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.2, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5251586495742951, 6.9112, 6.9112, 77.32846344354104, 305463.1745515835, 305463.1745515835, 101180.5020586562], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6156000.0000, 
sim time next is 6156600.0000, 
raw observation next is [17.28333333333333, 83.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5381973353388332, 6.9112, 6.9112, 77.32846344354104, 313049.6824647572, 313049.6824647572, 102405.8872243531], 
processed observation next is [1.0, 0.2608695652173913, 0.4219696969696969, 0.835, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3402819076269046, 0.0, 0.0, 0.5084288129206541, 0.11594432683879896, 0.11594432683879896, 0.24977045664476363], 
reward next is 0.7502, 
noisyNet noise sample is [array([-1.8351852], dtype=float32), -1.1638215]. 
=============================================
[2019-03-23 12:13:59,526] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.1630107e-01 2.6938622e-04 8.2646549e-02 6.6994521e-04 1.1309219e-04], sum to 1.0000
[2019-03-23 12:13:59,537] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0636
[2019-03-23 12:13:59,544] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.41666666666667, 82.83333333333334, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7589183029288196, 7.234106685693886, 6.9112, 77.32765759906708, 538060.9652361299, 433188.571199427, 134640.254504289], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6252600.0000, 
sim time next is 6253200.0000, 
raw observation next is [21.6, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7784077096357838, 7.397402515336126, 6.9112, 77.32706239380764, 602441.9910465502, 444536.2196409742, 136813.24459113], 
processed observation next is [0.0, 0.391304347826087, 0.6181818181818183, 0.82, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6834395851939769, 0.04862025153361262, 0.0, 0.5084196011243624, 0.22312666335057416, 0.16464304431147192, 0.33369084046617076], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.4608223], dtype=float32), 0.9753901]. 
=============================================
[2019-03-23 12:13:59,918] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.6833220e-01 1.3297014e-03 4.2875740e-01 1.3999460e-03 1.8072240e-04], sum to 1.0000
[2019-03-23 12:13:59,924] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6763
[2019-03-23 12:13:59,932] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.4, 55.0, 1.0, 2.0, 0.2727090497464101, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5523477879115675, 6.911199999999999, 6.9112, 77.32846344354104, 618383.2286788234, 618383.2286788237, 187135.044839689], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6278400.0000, 
sim time next is 6279000.0000, 
raw observation next is [29.5, 55.0, 1.0, 2.0, 0.2723552078309918, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5516070805184685, 6.9112, 6.9112, 77.32846344354104, 617406.3722911383, 617406.3722911383, 187128.4056057035], 
processed observation next is [0.0, 0.6956521739130435, 0.9772727272727273, 0.55, 1.0, 1.0, 0.09044400978873976, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3594386864549551, 0.0, 0.0, 0.5084288129206541, 0.22866902677449566, 0.22866902677449566, 0.45641074537976467], 
reward next is 0.5436, 
noisyNet noise sample is [array([-0.6990853], dtype=float32), -0.21480767]. 
=============================================
[2019-03-23 12:13:59,947] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[10.097268]
 [10.059495]
 [ 9.869059]
 [ 9.641969]
 [ 9.585074]], R is [[10.58409786]
 [11.02183056]
 [11.45287418]
 [11.87710762]
 [12.29360294]].
[2019-03-23 12:14:09,570] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0867201e-03 7.6167589e-07 9.9891245e-01 5.1306369e-08 1.9690694e-09], sum to 1.0000
[2019-03-23 12:14:09,575] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6926
[2019-03-23 12:14:09,583] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.3, 65.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 289720.5173065571, 289720.5173065568, 113670.4783305028], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6462000.0000, 
sim time next is 6462600.0000, 
raw observation next is [18.01666666666667, 65.83333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 282295.8953589201, 282295.8953589198, 111169.3839926881], 
processed observation next is [1.0, 0.8260869565217391, 0.45530303030303043, 0.6583333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10455403531811855, 0.10455403531811845, 0.27114483900655634], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2353951], dtype=float32), 0.8313675]. 
=============================================
[2019-03-23 12:14:11,165] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 6.7502134e-27 3.2165170e-18 2.4180878e-29 2.8430679e-30], sum to 1.0000
[2019-03-23 12:14:11,173] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1146
[2019-03-23 12:14:11,177] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.21666666666667, 54.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5008680158765578, 6.9112, 6.9112, 77.32846344354104, 291330.080690488, 291330.080690488, 84088.4479582846], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6549000.0000, 
sim time next is 6549600.0000, 
raw observation next is [19.03333333333333, 55.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4958171969542129, 6.911199999999999, 6.9112, 77.32846344354104, 288391.398813733, 288391.3988137332, 83267.12278812437], 
processed observation next is [1.0, 0.8260869565217391, 0.5015151515151515, 0.5533333333333335, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2797388527917327, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10681162919027148, 0.10681162919027155, 0.2030905433856692], 
reward next is 0.7969, 
noisyNet noise sample is [array([1.5544769], dtype=float32), 1.7986596]. 
=============================================
[2019-03-23 12:14:21,484] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9994862e-01 5.5470366e-09 5.1358249e-05 7.5605955e-10 9.2754576e-10], sum to 1.0000
[2019-03-23 12:14:21,490] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5683
[2019-03-23 12:14:21,494] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.4, 84.0, 1.0, 2.0, 0.2400448199956342, 1.0, 1.0, 0.2400448199956342, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 540210.0958282409, 540210.0958282409, 167006.3098278219], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6687000.0000, 
sim time next is 6687600.0000, 
raw observation next is [19.2, 85.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.849897701479493, 8.039547459469478, 6.9112, 77.32578655024544, 855610.1534429694, 489158.6632600853, 143080.7030896], 
processed observation next is [1.0, 0.391304347826087, 0.509090909090909, 0.85, 0.0, 0.5, -0.25, 0.0, 0.5, -0.25, 1.0, 0.5, 0.7855681449707044, 0.11283474594694783, 0.0, 0.5084112125491997, 0.316892649423322, 0.18116987528151307, 0.34897732460878045], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5580316], dtype=float32), -2.2494333]. 
=============================================
[2019-03-23 12:14:23,493] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.9999988e-01 4.9724896e-21 1.6277303e-07 3.9758850e-18 3.0385553e-21], sum to 1.0000
[2019-03-23 12:14:23,503] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5567
[2019-03-23 12:14:23,509] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.2, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6476119787473058, 6.911199999999999, 6.9112, 77.32846344353963, 374912.4863107432, 374912.4863107435, 118896.0730318284], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6735600.0000, 
sim time next is 6736200.0000, 
raw observation next is [17.2, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6404837628467105, 6.9112, 6.9112, 77.32846344354103, 370968.4879079454, 370968.4879079454, 118113.6425554667], 
processed observation next is [1.0, 1.0, 0.41818181818181815, 0.96, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4864053754953008, 0.0, 0.0, 0.508428812920654, 0.137395736262202, 0.137395736262202, 0.2880820550133334], 
reward next is 0.7119, 
noisyNet noise sample is [array([-0.2673928], dtype=float32), 1.1231391]. 
=============================================
[2019-03-23 12:14:23,532] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 9.4732459e-20 3.5372963e-08 2.9062150e-17 1.4771452e-20], sum to 1.0000
[2019-03-23 12:14:23,541] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7870
[2019-03-23 12:14:23,549] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 794367.3774655871 W.
[2019-03-23 12:14:23,556] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.35319003655858, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6911607117619617, 6.9112, 6.9112, 77.32846344354104, 794367.3774655871, 794367.3774655871, 193354.08890701], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6712800.0000, 
sim time next is 6713400.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.3512018907651925, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6857267855327821, 6.911199999999999, 6.9112, 77.32846344354104, 788687.326379267, 788687.3263792673, 192121.312868347], 
processed observation next is [1.0, 0.6956521739130435, 0.4681818181818182, 0.93, 1.0, 1.0, 0.18900236345649057, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5510382650468316, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2921064171775063, 0.2921064171775064, 0.4685885679715781], 
reward next is 0.5314, 
noisyNet noise sample is [array([0.33492714], dtype=float32), 1.0522375]. 
=============================================
[2019-03-23 12:14:30,672] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 8.7984966e-20 4.2282284e-09 1.5426912e-16 1.2089227e-19], sum to 1.0000
[2019-03-23 12:14:30,677] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8741
[2019-03-23 12:14:30,684] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.2, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6325598109603745, 6.911199999999999, 6.9112, 77.32846344354104, 366463.1238482465, 366463.1238482468, 117344.4448862926], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6848400.0000, 
sim time next is 6849000.0000, 
raw observation next is [17.2, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6318968299042255, 6.9112, 6.9112, 77.32846344354104, 366082.6883812169, 366082.6883812169, 117283.1685462704], 
processed observation next is [0.0, 0.2608695652173913, 0.41818181818181815, 0.96, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.47413832843460785, 0.0, 0.0, 0.5084288129206541, 0.1355861808819322, 0.1355861808819322, 0.28605650864944], 
reward next is 0.7139, 
noisyNet noise sample is [array([-0.5942413], dtype=float32), 0.25415102]. 
=============================================
[2019-03-23 12:14:30,696] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[43.39863 ]
 [43.420742]
 [43.441967]
 [43.437763]
 [43.433098]], R is [[43.65426254]
 [43.93151474]
 [44.20579147]
 [44.4769783 ]
 [44.7448616 ]].
[2019-03-23 12:14:32,188] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9764180e-01 1.1070834e-05 2.3214065e-03 2.2398792e-05 3.3959707e-06], sum to 1.0000
[2019-03-23 12:14:32,193] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8063
[2019-03-23 12:14:32,199] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 547210.7216449855 W.
[2019-03-23 12:14:32,205] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.4, 66.0, 1.0, 1.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3220379551297362, 6.911199999999999, 6.9112, 77.3421103, 547210.7216449855, 547210.7216449857, 205522.4307318582], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6897600.0000, 
sim time next is 6898200.0000, 
raw observation next is [24.3, 66.5, 1.0, 2.0, 0.2209321091179681, 0.0, 1.0, 0.0, 1.0, 2.0, 0.4433701373850809, 6.9112, 6.9112, 77.32846166584794, 503713.9442495832, 503713.9442495832, 168918.9392532763], 
processed observation next is [0.0, 0.8695652173913043, 0.740909090909091, 0.665, 1.0, 1.0, 0.026165136397460105, 0.0, 0.5, -0.25, 1.0, 1.0, 0.20481448197868704, 0.0, 0.0, 0.508428801232456, 0.1865607200924382, 0.1865607200924382, 0.411997412812869], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.49994788], dtype=float32), -0.59324217]. 
=============================================
[2019-03-23 12:14:34,218] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9998534e-01 9.8460051e-12 1.4670673e-05 4.3387316e-10 1.4155797e-14], sum to 1.0000
[2019-03-23 12:14:34,231] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2964
[2019-03-23 12:14:34,239] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.8, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6864877829574987, 6.911199999999999, 6.9112, 77.32846328243534, 396423.1569422868, 396423.1569422871, 123308.5202656748], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6930000.0000, 
sim time next is 6930600.0000, 
raw observation next is [18.71666666666667, 87.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.679891753863372, 6.9112, 6.9112, 77.32846344254379, 392706.0761389633, 392706.0761389633, 122592.4018700488], 
processed observation next is [0.0, 0.21739130434782608, 0.48712121212121223, 0.875, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5427025055191028, 0.0, 0.0, 0.5084288129140973, 0.1454466948662827, 0.1454466948662827, 0.2990058582196312], 
reward next is 0.7010, 
noisyNet noise sample is [array([0.00023862], dtype=float32), 0.24586578]. 
=============================================
[2019-03-23 12:14:34,517] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9998331e-01 2.9570774e-13 1.6705979e-05 6.7963149e-11 1.7866864e-15], sum to 1.0000
[2019-03-23 12:14:34,522] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5125
[2019-03-23 12:14:34,527] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.8, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6864877055931168, 6.9112, 6.9112, 77.32846328243865, 396423.1121656533, 396423.1121656533, 123308.5126993307], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6930000.0000, 
sim time next is 6930600.0000, 
raw observation next is [18.71666666666667, 87.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6798917533112993, 6.911199999999999, 6.9112, 77.3284634425438, 392706.0757924118, 392706.0757924121, 122592.4018367394], 
processed observation next is [0.0, 0.21739130434782608, 0.48712121212121223, 0.875, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5427025047304276, -8.881784197001253e-17, 0.0, 0.5084288129140974, 0.1454466947379303, 0.1454466947379304, 0.29900585813838876], 
reward next is 0.7010, 
noisyNet noise sample is [array([-0.10686544], dtype=float32), 0.30108216]. 
=============================================
[2019-03-23 12:14:35,696] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.7805995e-01 9.6032352e-08 2.1938110e-02 1.9421827e-06 4.1449213e-09], sum to 1.0000
[2019-03-23 12:14:35,704] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4262
[2019-03-23 12:14:35,709] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.65, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6958284931057085, 6.911199999999999, 6.9112, 77.32846344354104, 401224.7098717773, 401224.7098717776, 124677.5720315935], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6939000.0000, 
sim time next is 6939600.0000, 
raw observation next is [19.93333333333333, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7115975010409539, 6.9112, 6.9112, 77.32842684018605, 409989.4288013, 409989.4288013, 126534.4018588531], 
processed observation next is [0.0, 0.30434782608695654, 0.5424242424242423, 0.83, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5879964300585055, 0.0, 0.0, 0.5084285722563567, 0.15184793659307408, 0.15184793659307408, 0.3086204923386661], 
reward next is 0.6914, 
noisyNet noise sample is [array([0.10258004], dtype=float32), -0.95464337]. 
=============================================
[2019-03-23 12:14:40,591] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 12:14:40,593] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:14:40,594] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:14:40,595] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:14:40,596] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:14:40,597] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:14:40,599] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:14:40,599] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:14:40,602] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:14:40,602] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:14:40,601] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:14:40,617] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run17
[2019-03-23 12:14:40,642] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run17
[2019-03-23 12:14:40,643] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run17
[2019-03-23 12:14:40,691] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run17
[2019-03-23 12:14:40,716] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run17
[2019-03-23 12:14:53,577] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00939458], dtype=float32), 0.065998316]
[2019-03-23 12:14:53,579] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.66666666666667, 74.66666666666667, 1.0, 2.0, 0.2325083173941954, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4683794744170221, 6.911199999999999, 6.9112, 77.32846344354104, 530583.9271236982, 530583.9271236985, 172668.8251718526]
[2019-03-23 12:14:53,580] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:14:53,581] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.8503113e-05 4.4329061e-11 9.9996150e-01 9.5529579e-15 7.7270663e-18], sampled 0.7676290472824655
[2019-03-23 12:16:00,980] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00939458], dtype=float32), 0.065998316]
[2019-03-23 12:16:00,982] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.73333333333333, 83.33333333333333, 1.0, 2.0, 0.3050359695799045, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6114564497301443, 6.9112, 6.9112, 95.55338769695034, 695237.1740437635, 695237.1740437635, 193065.8653806714]
[2019-03-23 12:16:00,982] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:16:00,984] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.7190670e-05 1.3679205e-10 9.9997282e-01 2.0105304e-14 3.0305151e-17], sampled 0.746809736366022
[2019-03-23 12:16:05,029] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00939458], dtype=float32), 0.065998316]
[2019-03-23 12:16:05,032] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.81058666666667, 59.86716944333332, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3000165263789659, 6.9112, 6.9112, 95.55338769695034, 349006.2750043354, 349006.2750043354, 135663.4675237659]
[2019-03-23 12:16:05,033] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:16:05,035] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.0772264e-05 1.9037415e-10 9.9990916e-01 7.5336520e-14 8.7770619e-17], sampled 0.4624274834944696
[2019-03-23 12:16:19,891] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3363.0029 2098008223.3806 179.0000
[2019-03-23 12:16:20,373] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3615.0043 2175274589.9064 245.0000
[2019-03-23 12:16:20,437] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2761.4805 2123994684.5284 757.0000
[2019-03-23 12:16:20,490] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3120.4344 2108962323.4188 368.0000
[2019-03-23 12:16:20,533] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3519.8705 2104067451.3644 178.0000
[2019-03-23 12:16:21,546] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 400000, evaluation results [400000.0, 3615.0043166823143, 2175274589.906365, 245.0, 3363.0028858334153, 2098008223.3806045, 179.0, 3519.870480882709, 2104067451.364433, 178.0, 2761.480461622516, 2123994684.5284238, 757.0, 3120.4344149556277, 2108962323.4188242, 368.0]
[2019-03-23 12:16:22,175] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.5684220e-04 2.6216762e-07 9.9924290e-01 4.6543411e-10 2.6065716e-12], sum to 1.0000
[2019-03-23 12:16:22,181] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1593
[2019-03-23 12:16:22,187] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.2, 79.00000000000001, 1.0, 2.0, 0.4267969073484714, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8562902587486161, 6.911200000000001, 6.9112, 77.32843914423782, 973466.0836671848, 973466.0836671846, 227865.5044748208], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7056600.0000, 
sim time next is 7057200.0000, 
raw observation next is [22.2, 79.0, 1.0, 2.0, 0.3550944637593521, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7119047266430834, 6.911199999999999, 6.9112, 77.32846329312615, 809578.608083156, 809578.6080831564, 202784.5982554012], 
processed observation next is [1.0, 0.6956521739130435, 0.6454545454545454, 0.79, 1.0, 1.0, 0.19386807969919012, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5884353237758334, -8.881784197001253e-17, 0.0, 0.5084288119316875, 0.2998439289196874, 0.29984392891968753, 0.4945965811107346], 
reward next is 0.5054, 
noisyNet noise sample is [array([0.5069103], dtype=float32), -0.7897295]. 
=============================================
[2019-03-23 12:16:26,534] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9995565e-01 7.7726745e-16 4.4298977e-05 1.9358790e-16 1.2027133e-21], sum to 1.0000
[2019-03-23 12:16:26,542] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1385
[2019-03-23 12:16:26,547] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.7, 53.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6083226431805856, 6.9112, 6.9112, 77.32846344354104, 352636.7062201329, 352636.7062201329, 115089.4232179197], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7149600.0000, 
sim time next is 7150200.0000, 
raw observation next is [22.33333333333334, 54.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6021639383701028, 6.911199999999999, 6.9112, 77.32846344354104, 349571.7293260719, 349571.7293260721, 114192.2037936226], 
processed observation next is [1.0, 0.782608695652174, 0.6515151515151518, 0.54, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.43166276910014695, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1294710108615081, 0.1294710108615082, 0.2785175702283478], 
reward next is 0.7215, 
noisyNet noise sample is [array([-0.96489716], dtype=float32), -1.5403115]. 
=============================================
[2019-03-23 12:16:26,947] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 9.4320470e-24 2.2651964e-11 5.3747283e-25 2.7054128e-30], sum to 1.0000
[2019-03-23 12:16:26,959] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3644
[2019-03-23 12:16:26,966] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.08333333333334, 62.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4998220638512184, 6.911199999999999, 6.9112, 77.32846344354104, 290721.505755587, 290721.5057555872, 90585.15323083423], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7156200.0000, 
sim time next is 7156800.0000, 
raw observation next is [18.8, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4953797259452957, 6.9112, 6.9112, 77.32846344354104, 288136.8641364446, 288136.8641364446, 88847.57321912749], 
processed observation next is [1.0, 0.8695652173913043, 0.49090909090909096, 0.63, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2791138942075653, 0.0, 0.0, 0.5084288129206541, 0.10671735708757206, 0.10671735708757206, 0.2167013980954329], 
reward next is 0.7833, 
noisyNet noise sample is [array([0.2554018], dtype=float32), 1.1278628]. 
=============================================
[2019-03-23 12:16:35,098] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.8056176e-18 3.2586895e-09 9.3978843e-18 1.1639890e-20], sum to 1.0000
[2019-03-23 12:16:35,105] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5856
[2019-03-23 12:16:35,109] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 546662.9176921798 W.
[2019-03-23 12:16:35,117] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.41666666666666, 46.83333333333334, 1.0, 2.0, 0.4869832788450945, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 546662.9176921798, 546662.9176921798, 132154.9361200725], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7319400.0000, 
sim time next is 7320000.0000, 
raw observation next is [25.33333333333334, 46.66666666666667, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 1.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 394973.9338586583, 394973.9338586586, 175111.1108475315], 
processed observation next is [1.0, 0.7391304347826086, 0.7878787878787882, 0.46666666666666673, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.5, 0.0, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.14628664216987344, 0.14628664216987355, 0.42710027035983295], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6452421], dtype=float32), 0.0021716915]. 
=============================================
[2019-03-23 12:16:35,145] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[40.93474 ]
 [40.238873]
 [39.70864 ]
 [40.403297]
 [40.93194 ]], R is [[40.68302536]
 [40.27619553]
 [40.3090477 ]
 [40.47597122]
 [40.64371109]].
[2019-03-23 12:16:35,187] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.8599480e-22 1.7441127e-11 7.3297901e-23 5.3839214e-25], sum to 1.0000
[2019-03-23 12:16:35,196] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3061
[2019-03-23 12:16:35,198] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.2, 48.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6495431395633371, 6.911199999999999, 6.9112, 77.32846344354104, 375988.1070192432, 375988.1070192435, 119104.1885371423], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7324800.0000, 
sim time next is 7325400.0000, 
raw observation next is [24.0, 49.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6464250158395637, 6.9112, 6.9112, 77.32846344354104, 374289.2935324284, 374289.2935324284, 118740.1087266164], 
processed observation next is [1.0, 0.782608695652174, 0.7272727272727273, 0.4933333333333334, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4948928797708053, 0.0, 0.0, 0.5084288129206541, 0.13862566427126977, 0.13862566427126977, 0.28961002128443025], 
reward next is 0.7104, 
noisyNet noise sample is [array([-0.7712748], dtype=float32), 0.17523111]. 
=============================================
[2019-03-23 12:16:36,266] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 6.6653946e-33 5.4198522e-20 2.8611538e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 12:16:36,273] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8906
[2019-03-23 12:16:36,277] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.78333333333333, 86.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6367430913953737, 6.9112, 6.9112, 77.32846316045132, 369775.3836924434, 369775.3836924434, 117042.0078455034], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7354200.0000, 
sim time next is 7354800.0000, 
raw observation next is [17.7, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6267055898162891, 6.9112, 6.9112, 77.32846344178868, 363988.5905911997, 363988.5905911997, 116135.5920016031], 
processed observation next is [1.0, 0.13043478260869565, 0.44090909090909086, 0.87, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.46672227116612736, 0.0, 0.0, 0.5084288129091326, 0.13481058910785174, 0.13481058910785174, 0.2832575414673246], 
reward next is 0.7167, 
noisyNet noise sample is [array([1.215627], dtype=float32), -1.4124184]. 
=============================================
[2019-03-23 12:16:41,551] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 3.8189169e-28 8.1002116e-19 1.1066556e-35 3.1739235e-37], sum to 1.0000
[2019-03-23 12:16:41,558] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4111
[2019-03-23 12:16:41,564] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 572371.5863387394 W.
[2019-03-23 12:16:41,569] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.61666666666667, 53.66666666666667, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3399506970844498, 6.9112, 6.9112, 77.3421103, 572371.5863387394, 572371.5863387394, 213595.1836916168], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7488600.0000, 
sim time next is 7489200.0000, 
raw observation next is [28.43333333333334, 54.33333333333334, 1.0, 2.0, 0.2504979085597031, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5070676814749001, 6.911200000000001, 6.9112, 77.32846344354104, 570738.0544053714, 570738.0544053711, 179511.6714837927], 
processed observation next is [0.0, 0.6956521739130435, 0.9287878787878792, 0.5433333333333334, 1.0, 1.0, 0.06312238569962887, 0.0, 0.5, -0.25, 1.0, 1.0, 0.2958109735355716, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21138446459458202, 0.21138446459458188, 0.4378333450824213], 
reward next is 0.5622, 
noisyNet noise sample is [array([-0.6877494], dtype=float32), -1.2747514]. 
=============================================
[2019-03-23 12:16:46,530] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.9604106e-07 1.3486980e-08 9.9999905e-01 9.4766435e-18 6.7863360e-17], sum to 1.0000
[2019-03-23 12:16:46,537] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4669
[2019-03-23 12:16:46,545] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.1, 90.0, 1.0, 2.0, 0.220525182742026, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4424414822066723, 6.9112, 6.9112, 77.32846344354104, 502743.942645791, 502743.942645791, 168758.5880775771], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7545600.0000, 
sim time next is 7546200.0000, 
raw observation next is [21.28333333333333, 89.0, 1.0, 2.0, 0.2221786127766213, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4459811301665475, 6.911199999999999, 6.9112, 77.32846344354104, 506596.9856327844, 506596.9856327847, 169247.6666789914], 
processed observation next is [0.0, 0.34782608695652173, 0.6037878787878787, 0.89, 1.0, 1.0, 0.027723265970776602, 0.0, 1.0, -0.25, 1.0, 1.0, 0.20854447166649645, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18762851319732754, 0.18762851319732768, 0.41279918702193025], 
reward next is 0.5872, 
noisyNet noise sample is [array([-1.399389], dtype=float32), 0.12959725]. 
=============================================
[2019-03-23 12:16:51,063] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.5799013e-04 3.5822659e-10 9.9954200e-01 2.1633759e-17 1.2251118e-17], sum to 1.0000
[2019-03-23 12:16:51,074] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2958
[2019-03-23 12:16:51,078] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.0, 95.0, 1.0, 2.0, 0.2183864179593821, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4361094551475169, 6.9112, 6.9112, 77.32846344354104, 496928.5729396286, 496928.5729396286, 166972.9581171153], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7616400.0000, 
sim time next is 7617000.0000, 
raw observation next is [20.0, 95.5, 1.0, 2.0, 0.2192728976408593, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4381510262188532, 6.911200000000001, 6.9112, 77.32846344354104, 499087.3857786334, 499087.3857786331, 167313.1866636488], 
processed observation next is [1.0, 0.13043478260869565, 0.5454545454545454, 0.955, 1.0, 1.0, 0.024091122051074117, 0.0, 1.0, -0.25, 1.0, 1.0, 0.19735860888407605, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1848471799180124, 0.18484717991801228, 0.40808094308207027], 
reward next is 0.5919, 
noisyNet noise sample is [array([0.52610844], dtype=float32), -0.6066498]. 
=============================================
[2019-03-23 12:16:51,093] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[61.834076]
 [61.827435]
 [61.805782]
 [61.711052]
 [61.826332]], R is [[61.85139465]
 [61.82563019]
 [61.80177307]
 [61.7781868 ]
 [61.74930573]].
[2019-03-23 12:16:52,211] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.9014675e-04 3.5720325e-07 9.9980956e-01 1.0097478e-12 7.8095537e-11], sum to 1.0000
[2019-03-23 12:16:52,219] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6203
[2019-03-23 12:16:52,224] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.88333333333333, 56.33333333333333, 1.0, 2.0, 0.4061529667059459, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8220549472719099, 6.911199999999999, 6.9112, 77.328463443541, 925880.0582621171, 925880.0582621173, 227185.868234468], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7650600.0000, 
sim time next is 7651200.0000, 
raw observation next is [28.06666666666667, 55.66666666666667, 1.0, 2.0, 0.626627458932059, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9739513142117673, 6.9112, 6.9112, 77.32846344354104, 1262324.139141487, 1262324.139141487, 278308.0265073512], 
processed observation next is [1.0, 0.5652173913043478, 0.9121212121212122, 0.5566666666666668, 1.0, 1.0, 0.5332843236650736, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9627875917310961, 0.0, 0.0, 0.5084288129206541, 0.46752745894129144, 0.46752745894129144, 0.6788000646520761], 
reward next is 0.3212, 
noisyNet noise sample is [array([-0.8370582], dtype=float32), 0.74010926]. 
=============================================
[2019-03-23 12:16:56,079] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.0838347e-15 4.9135997e-11 5.8224138e-15 1.5856852e-17], sum to 1.0000
[2019-03-23 12:16:56,083] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7746
[2019-03-23 12:16:56,089] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 622783.668476806 W.
[2019-03-23 12:16:56,094] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.5, 63.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3589409720651034, 6.911199999999999, 6.9112, 77.3421103, 622783.668476806, 622783.6684768063, 201300.0723498602], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7725600.0000, 
sim time next is 7726200.0000, 
raw observation next is [20.68333333333334, 62.0, 1.0, 2.0, 0.2874532603081619, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5435207513900747, 6.9112, 6.9112, 77.32846344354104, 630221.9187397518, 630221.9187397518, 169183.8375969437], 
processed observation next is [1.0, 0.43478260869565216, 0.5765151515151519, 0.62, 1.0, 1.0, 0.10931657538520233, 0.0, 0.5, -0.25, 1.0, 1.0, 0.3478867877001068, 0.0, 0.0, 0.5084288129206541, 0.23341552545916733, 0.23341552545916733, 0.412643506334009], 
reward next is 0.5874, 
noisyNet noise sample is [array([-2.1622941], dtype=float32), 0.6864204]. 
=============================================
[2019-03-23 12:16:56,862] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 2.4864181e-22 7.5251914e-13 2.0059518e-20 4.3385823e-24], sum to 1.0000
[2019-03-23 12:16:56,868] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7725
[2019-03-23 12:16:56,873] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.53333333333333, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6335407904662912, 6.911199999999999, 6.9112, 77.32846344252947, 367849.8021105276, 367849.8021105279, 116811.577499919], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7717200.0000, 
sim time next is 7717800.0000, 
raw observation next is [17.61666666666667, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6309842765922313, 6.9112, 6.9112, 77.32846344353477, 366634.3324545051, 366634.3324545051, 116383.0296020607], 
processed observation next is [1.0, 0.30434782608695654, 0.4371212121212123, 0.86, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4728346808460448, 0.0, 0.0, 0.5084288129206129, 0.13579049350166855, 0.13579049350166855, 0.2838610478099042], 
reward next is 0.7161, 
noisyNet noise sample is [array([-0.5401971], dtype=float32), -0.40335155]. 
=============================================
[2019-03-23 12:17:06,422] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9671125e-01 8.5279316e-07 3.2684423e-03 3.8456403e-07 1.9098401e-05], sum to 1.0000
[2019-03-23 12:17:06,428] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7880
[2019-03-23 12:17:06,435] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 696842.0351917713 W.
[2019-03-23 12:17:06,438] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.6, 95.0, 1.0, 2.0, 0.3063751214450638, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6109984681862729, 6.911199999999999, 6.9112, 77.32846344354104, 696842.0351917713, 696842.0351917717, 186603.8281937216], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7899600.0000, 
sim time next is 7900200.0000, 
raw observation next is [19.7, 94.5, 1.0, 2.0, 0.3101992541797505, 1.0, 1.0, 0.3101992541797505, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 706628.836441803, 706628.8364418033, 183663.1992394368], 
processed observation next is [1.0, 0.43478260869565216, 0.5318181818181817, 0.945, 1.0, 1.0, 0.13774906772468815, 1.0, 0.5, 0.13774906772468815, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2617143838673345, 0.26171438386733453, 0.4479590225352117], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.1681185], dtype=float32), 0.96667594]. 
=============================================
[2019-03-23 12:17:06,621] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:17:06,622] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:17:06,643] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run3
[2019-03-23 12:17:08,420] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:17:08,421] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:17:08,423] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run3
[2019-03-23 12:17:08,573] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:17:08,573] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:17:08,575] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run3
[2019-03-23 12:17:08,595] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:17:08,600] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:17:08,605] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run3
[2019-03-23 12:17:08,628] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:17:08,629] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:17:08,635] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run3
[2019-03-23 12:17:08,700] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:17:08,701] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:17:08,702] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run3
[2019-03-23 12:17:08,732] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:17:08,733] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:17:08,733] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:17:08,739] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:17:08,734] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:17:08,734] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:17:08,739] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run3
[2019-03-23 12:17:08,741] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:17:08,743] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:17:08,765] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run3
[2019-03-23 12:17:08,771] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:17:08,771] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:17:08,802] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:17:08,803] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:17:08,809] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run3
[2019-03-23 12:17:08,832] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run3
[2019-03-23 12:17:08,864] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run3
[2019-03-23 12:17:08,895] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:17:08,895] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:17:08,897] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run3
[2019-03-23 12:17:08,961] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:17:08,961] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:17:08,963] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run3
[2019-03-23 12:17:09,082] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run3
[2019-03-23 12:17:09,251] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:17:09,251] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:17:09,253] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:17:09,253] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:17:09,255] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run3
[2019-03-23 12:17:09,341] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run3
[2019-03-23 12:17:11,648] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 5.9497114e-33 1.7543175e-16 2.7947589e-27 1.8360446e-28], sum to 1.0000
[2019-03-23 12:17:11,654] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4297
[2019-03-23 12:17:11,657] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7417313558352862, 7.145892457927217, 6.9112, 77.32781673884689, 503281.3250179279, 427058.6524362693, 129989.9731314864], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 25800.0000, 
sim time next is 26400.0000, 
raw observation next is [18.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.754260189201425, 7.248788057228048, 6.9112, 77.32746133636168, 543849.2448271695, 434208.9695669081, 131434.2567397724], 
processed observation next is [1.0, 0.30434782608695654, 0.45454545454545453, 1.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6489431274306072, 0.03375880572280483, 0.0, 0.508422224141556, 0.20142564623228498, 0.16081813687663263, 0.3205713579018839], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.185977], dtype=float32), -0.0029934156]. 
=============================================
[2019-03-23 12:17:11,689] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9999511e-01 3.5028008e-13 4.8970978e-06 1.7737371e-11 4.7731590e-11], sum to 1.0000
[2019-03-23 12:17:11,700] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7739
[2019-03-23 12:17:11,712] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 801151.5532652707 W.
[2019-03-23 12:17:11,716] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 96.0, 1.0, 1.0, 0.3540743223097905, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6993892740618257, 6.9112, 6.9112, 77.32786677478224, 801151.5532652707, 801151.5532652707, 196619.2162945492], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 30600.0000, 
sim time next is 31200.0000, 
raw observation next is [19.06666666666667, 94.66666666666666, 1.0, 2.0, 0.6994744995769666, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.3284597499944, 791103.510177731, 791103.510177731, 159240.7125674353], 
processed observation next is [1.0, 0.34782608695652173, 0.5030303030303032, 0.9466666666666665, 1.0, 1.0, 0.6243431244712082, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084287886358636, 0.2930013000658263, 0.2930013000658263, 0.38839198187179336], 
reward next is 0.6116, 
noisyNet noise sample is [array([1.980894], dtype=float32), 1.7602762]. 
=============================================
[2019-03-23 12:17:11,985] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 12:17:11,986] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:17:11,987] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:17:11,987] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:17:11,988] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:17:11,989] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:17:11,990] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:17:11,990] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:17:11,990] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:17:11,990] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:17:11,993] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:17:12,006] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run18
[2019-03-23 12:17:12,030] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run18
[2019-03-23 12:17:12,031] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run18
[2019-03-23 12:17:12,077] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run18
[2019-03-23 12:17:12,100] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run18
[2019-03-23 12:17:19,318] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02177951], dtype=float32), 0.03486537]
[2019-03-23 12:17:19,319] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.8, 58.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4467812489155342, 6.9112, 6.9112, 95.55338769695034, 259848.8472332642, 259848.8472332642, 75555.53583732767]
[2019-03-23 12:17:19,320] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:17:19,322] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 2.8957029e-24 1.0461223e-14 7.9984157e-21 7.6048191e-22], sampled 0.007014006394586714
[2019-03-23 12:17:28,360] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02177951], dtype=float32), 0.03486537]
[2019-03-23 12:17:28,362] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.0, 65.33333333333333, 1.0, 2.0, 0.3643007306026654, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7378361168450737, 6.911200000000001, 6.9112, 77.32846344354104, 826084.0410582862, 826084.0410582859, 215145.2218426685]
[2019-03-23 12:17:28,362] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:17:28,365] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.3018597e-01 1.5820458e-04 6.7184106e-02 2.0982982e-06 2.4695988e-03], sampled 0.9405898475342257
[2019-03-23 12:17:42,736] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02177951], dtype=float32), 0.03486537]
[2019-03-23 12:17:42,737] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.91866566166667, 97.72778315333332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5879626822089027, 6.9112, 6.9112, 95.55338769695034, 341478.3748817997, 341478.3748817997, 113672.350872067]
[2019-03-23 12:17:42,737] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:17:42,742] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0000000e+00 7.4550967e-26 1.1323577e-15 4.0215165e-22 2.8324152e-23], sampled 0.0315324605446774
[2019-03-23 12:18:33,123] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02177951], dtype=float32), 0.03486537]
[2019-03-23 12:18:33,124] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.55, 73.5, 1.0, 2.0, 0.5231512030208895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595303.6842155964, 595303.6842155964, 146127.042240939]
[2019-03-23 12:18:33,124] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:18:33,126] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.9893385e-01 3.1147106e-08 1.0653026e-03 2.6589042e-08 8.5189629e-07], sampled 0.8820828507094394
[2019-03-23 12:18:33,127] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 595303.6842155964 W.
[2019-03-23 12:18:50,643] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6757.1047 1800654054.5204 2404.0000
[2019-03-23 12:18:50,843] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6223.4511 1691045941.8978 3221.0000
[2019-03-23 12:18:50,887] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6454.5445 1705409094.9418 2960.0000
[2019-03-23 12:18:50,977] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6244.2297 1729486447.7373 3435.0000
[2019-03-23 12:18:51,181] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6415.8579 1683455717.5580 3059.0000
[2019-03-23 12:18:52,195] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 425000, evaluation results [425000.0, 6757.104743813375, 1800654054.5203934, 2404.0, 6415.857884292605, 1683455717.557991, 3059.0, 6223.451149832697, 1691045941.8978114, 3221.0, 6244.2296979013345, 1729486447.7372723, 3435.0, 6454.544521456141, 1705409094.9418118, 2960.0]
[2019-03-23 12:18:58,856] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 5.0592042e-28 1.3825527e-17 1.1319298e-23 1.1155900e-21], sum to 1.0000
[2019-03-23 12:18:58,864] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6999
[2019-03-23 12:18:58,875] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.83333333333333, 72.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4297077786585178, 6.911199999999999, 6.9112, 77.32846344354104, 249929.0655479052, 249929.0655479055, 73627.2713060067], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 166200.0000, 
sim time next is 166800.0000, 
raw observation next is [15.66666666666667, 73.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.425237100561902, 6.9112, 6.9112, 77.32846344354104, 247328.1433703962, 247328.1433703962, 72940.8626254338], 
processed observation next is [1.0, 0.9565217391304348, 0.3484848484848486, 0.7366666666666667, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.17891014365986002, 0.0, 0.0, 0.5084288129206541, 0.09160301606310971, 0.09160301606310971, 0.17790454298886293], 
reward next is 0.8221, 
noisyNet noise sample is [array([1.2659538], dtype=float32), 0.1676312]. 
=============================================
[2019-03-23 12:19:00,973] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 3.7011106e-28 2.5625761e-38 4.6124880e-36], sum to 1.0000
[2019-03-23 12:19:00,979] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5406
[2019-03-23 12:19:00,985] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [13.83333333333333, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3924984228338317, 6.911199999999999, 6.9112, 77.32846344354104, 228282.0710997967, 228282.071099797, 71686.29894065968], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 197400.0000, 
sim time next is 198000.0000, 
raw observation next is [14.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4029339117385904, 6.911199999999999, 6.9112, 77.32846344354104, 234352.9462430431, 234352.9462430434, 73525.43502546], 
processed observation next is [0.0, 0.30434782608695654, 0.2727272727272727, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.14704844534084344, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08679738749742337, 0.08679738749742348, 0.17933032933039025], 
reward next is 0.8207, 
noisyNet noise sample is [array([-0.10027981], dtype=float32), -0.40481332]. 
=============================================
[2019-03-23 12:19:01,000] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[82.14902]
 [82.21527]
 [82.29033]
 [82.35507]
 [82.41682]], R is [[82.06918335]
 [82.07364655]
 [82.08230591]
 [82.09508514]
 [82.11222076]].
[2019-03-23 12:19:02,357] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 2.5188570e-30 1.3359934e-18 9.4660640e-26 4.8151399e-24], sum to 1.0000
[2019-03-23 12:19:02,357] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5073
[2019-03-23 12:19:02,366] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.9, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4991968305106231, 6.9112, 6.9112, 77.32846344354104, 290357.7448868728, 290357.7448868728, 96921.28437954401], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 230400.0000, 
sim time next is 231000.0000, 
raw observation next is [19.08333333333333, 68.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5024218049478263, 6.9112, 6.9112, 77.32846344354104, 292234.1142528537, 292234.1142528537, 97835.58116937893], 
processed observation next is [0.0, 0.6956521739130435, 0.5037878787878786, 0.6816666666666668, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2891740070683233, 0.0, 0.0, 0.5084288129206541, 0.10823485713068655, 0.10823485713068655, 0.23862336870580228], 
reward next is 0.7614, 
noisyNet noise sample is [array([-0.27269226], dtype=float32), -0.6997103]. 
=============================================
[2019-03-23 12:19:02,382] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[54.656704]
 [54.81561 ]
 [54.96606 ]
 [55.114773]
 [55.250404]], R is [[54.71273804]
 [54.92921829]
 [55.14658737]
 [55.36501312]
 [55.58453751]].
[2019-03-23 12:19:04,943] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 6.9143966e-29 0.0000000e+00 1.3540775e-36], sum to 1.0000
[2019-03-23 12:19:04,949] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1720
[2019-03-23 12:19:04,955] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.66666666666667, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4201281837950629, 6.911199999999999, 6.9112, 77.32846344354104, 244355.9278572433, 244355.9278572436, 81179.267841115], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 286800.0000, 
sim time next is 287400.0000, 
raw observation next is [14.83333333333333, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4236811020220422, 6.911199999999999, 6.9112, 77.32846344354104, 246422.9078700626, 246422.9078700629, 82009.08271467657], 
processed observation next is [0.0, 0.30434782608695654, 0.3106060606060605, 0.95, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.17668728860291744, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09126774365557874, 0.09126774365557885, 0.20002215296262577], 
reward next is 0.8000, 
noisyNet noise sample is [array([-0.07024352], dtype=float32), 0.009824372]. 
=============================================
[2019-03-23 12:19:06,432] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 2.8668162e-33 1.5472497e-20 2.0558411e-28 4.1289387e-26], sum to 1.0000
[2019-03-23 12:19:06,437] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0009
[2019-03-23 12:19:06,448] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.0, 46.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4753530085483036, 6.9112, 6.9112, 77.32846344354104, 276485.0480412145, 276485.0480412145, 83417.9078081341], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 307800.0000, 
sim time next is 308400.0000, 
raw observation next is [21.0, 45.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4752493319281098, 6.9112, 6.9112, 77.32846344354104, 276424.7282769462, 276424.7282769462, 82423.21457840248], 
processed observation next is [0.0, 0.5652173913043478, 0.5909090909090909, 0.45, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2503561884687283, 0.0, 0.0, 0.5084288129206541, 0.10237952899146155, 0.10237952899146155, 0.20103223067903042], 
reward next is 0.7990, 
noisyNet noise sample is [array([0.0656027], dtype=float32), -1.4098495]. 
=============================================
[2019-03-23 12:19:07,644] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 1.3967234e-23 2.0115773e-34 1.6500119e-29], sum to 1.0000
[2019-03-23 12:19:07,650] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7995
[2019-03-23 12:19:07,657] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.0, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3533766169828324, 6.9112, 6.9112, 77.32846344354104, 205545.0970284448, 205545.0970284448, 60517.25394638805], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 340200.0000, 
sim time next is 340800.0000, 
raw observation next is [14.66666666666667, 64.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3475385838992609, 6.911199999999999, 6.9112, 77.32846344354104, 202210.5835378443, 202210.5835378446, 60219.73147295022], 
processed observation next is [0.0, 0.9565217391304348, 0.30303030303030315, 0.6433333333333333, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.06791226271322988, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07489280871772011, 0.07489280871772022, 0.14687739383646395], 
reward next is 0.8531, 
noisyNet noise sample is [array([1.9275748], dtype=float32), 0.60086167]. 
=============================================
[2019-03-23 12:19:15,769] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.6755497e-20 5.4363830e-10 3.8517673e-18 2.0843688e-16], sum to 1.0000
[2019-03-23 12:19:15,779] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4477
[2019-03-23 12:19:15,783] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5269879720555138, 6.911200000000001, 6.9112, 77.3284634353662, 306527.551488727, 306527.5514887267, 92855.89554244038], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 495000.0000, 
sim time next is 495600.0000, 
raw observation next is [16.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5225541975486114, 6.911199999999998, 6.9112, 77.32846344349043, 303947.7985881016, 303947.7985881022, 93561.20171543858], 
processed observation next is [1.0, 0.7391304347826086, 0.36363636363636365, 0.88, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3179345679265878, -1.7763568394002506e-16, 0.0, 0.5084288129203214, 0.11257325873633392, 0.11257325873633416, 0.22819805296448434], 
reward next is 0.7718, 
noisyNet noise sample is [array([-0.45504794], dtype=float32), 1.1712283]. 
=============================================
[2019-03-23 12:19:16,504] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 4.6747728e-27 1.8767004e-14 5.2089848e-26 1.2628373e-21], sum to 1.0000
[2019-03-23 12:19:16,516] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5728
[2019-03-23 12:19:16,521] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4017150878488844, 6.9112, 6.9112, 77.32846344354104, 233643.8880947118, 233643.8880947118, 73774.40869749313], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 516600.0000, 
sim time next is 517200.0000, 
raw observation next is [14.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4001365961572694, 6.911199999999999, 6.9112, 77.32846344354104, 232725.5925697291, 232725.5925697294, 73665.34109834397], 
processed observation next is [1.0, 1.0, 0.2727272727272727, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.14305228022467056, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08619466391471449, 0.08619466391471459, 0.1796715636544975], 
reward next is 0.8203, 
noisyNet noise sample is [array([-0.901518], dtype=float32), -0.93215847]. 
=============================================
[2019-03-23 12:19:16,787] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.9266751e-38 3.1012890e-13 8.9519635e-35 4.9839234e-28], sum to 1.0000
[2019-03-23 12:19:16,796] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9112
[2019-03-23 12:19:16,802] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.403531234352924, 6.911199999999999, 6.9112, 77.32846344354104, 234700.4426536908, 234700.4426536911, 73858.32765397518], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 518400.0000, 
sim time next is 519000.0000, 
raw observation next is [14.0, 94.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4027027225167745, 6.911199999999999, 6.9112, 77.32846344354104, 234218.4504395554, 234218.4504395557, 73841.55291320084], 
processed observation next is [1.0, 0.0, 0.2727272727272727, 0.9400000000000002, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.14671817502396364, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08674757423687236, 0.08674757423687247, 0.18010134856878254], 
reward next is 0.8199, 
noisyNet noise sample is [array([-0.712727], dtype=float32), 0.16313818]. 
=============================================
[2019-03-23 12:19:16,813] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[107.680954]
 [107.956345]
 [107.97194 ]
 [107.99187 ]
 [108.02623 ]], R is [[107.26255035]
 [107.00978088]
 [106.75993347]
 [106.51266479]
 [106.26760101]].
[2019-03-23 12:19:19,151] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9999905e-01 6.3802675e-14 9.9477791e-07 3.1918259e-13 7.9226230e-11], sum to 1.0000
[2019-03-23 12:19:19,159] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6838
[2019-03-23 12:19:19,170] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 570003.7945621766 W.
[2019-03-23 12:19:19,181] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [18.83333333333333, 74.66666666666667, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3281678275592569, 6.911199999999999, 6.9112, 77.3421103, 570003.7945621766, 570003.7945621768, 194931.7294757214], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 561000.0000, 
sim time next is 561600.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3179830175054978, 6.911199999999999, 6.9112, 77.3421103, 552063.0252587935, 552063.0252587938, 193354.8299463057], 
processed observation next is [1.0, 0.5217391304347826, 0.5, 0.73, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.025690025007854, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.2044677871328865, 0.2044677871328866, 0.4715971462105017], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1861888], dtype=float32), 0.7298074]. 
=============================================
[2019-03-23 12:19:22,205] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9947459e-01 8.6829480e-18 5.2543537e-04 2.0210232e-20 1.6310709e-13], sum to 1.0000
[2019-03-23 12:19:22,212] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1090
[2019-03-23 12:19:22,215] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.83333333333333, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4565346047533874, 6.911199999999999, 6.9112, 77.32846344354104, 265536.4950068438, 265536.4950068441, 84790.62733565745], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 625800.0000, 
sim time next is 626400.0000, 
raw observation next is [15.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4598551822533314, 6.911199999999999, 6.9112, 77.32846344354104, 267468.3900953325, 267468.3900953328, 85550.7946708859], 
processed observation next is [1.0, 0.2608695652173913, 0.3181818181818182, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.22836454607618772, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.099062366701975, 0.09906236670197512, 0.20866047480703875], 
reward next is 0.7913, 
noisyNet noise sample is [array([-0.51720846], dtype=float32), -1.1801249]. 
=============================================
[2019-03-23 12:19:23,510] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9822980e-01 3.8366074e-13 1.7700423e-03 6.2381246e-14 6.6077590e-08], sum to 1.0000
[2019-03-23 12:19:23,515] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2160
[2019-03-23 12:19:23,525] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 609043.9619395356 W.
[2019-03-23 12:19:23,528] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.0, 78.0, 1.0, 2.0, 0.5463027790944667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846342915347, 609043.9619395356, 609043.9619395356, 136510.1074387842], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 637200.0000, 
sim time next is 637800.0000, 
raw observation next is [20.33333333333334, 76.5, 1.0, 2.0, 0.3136490306793649, 1.0, 1.0, 0.3136490306793649, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344345198, 705702.6322239195, 705702.6322239198, 177603.7302469856], 
processed observation next is [1.0, 0.391304347826087, 0.5606060606060609, 0.765, 1.0, 1.0, 0.1420612883492061, 1.0, 0.5, 0.1420612883492061, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129200686, 0.26137134526811834, 0.26137134526811845, 0.4331798298706966], 
reward next is 0.5668, 
noisyNet noise sample is [array([0.04538508], dtype=float32), -0.55933905]. 
=============================================
[2019-03-23 12:19:25,804] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 8.3638057e-21 6.8639400e-10 3.5803054e-22 2.1326426e-16], sum to 1.0000
[2019-03-23 12:19:25,812] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9345
[2019-03-23 12:19:25,816] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.5, 85.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6473053532540856, 6.911199999999999, 6.9112, 77.32846344354104, 374699.5865371288, 374699.5865371291, 118894.697094139], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 693000.0000, 
sim time next is 693600.0000, 
raw observation next is [18.33333333333334, 86.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.643356436637028, 6.9112, 6.9112, 77.32846344354104, 372539.8036663873, 372539.8036663873, 118441.5929766687], 
processed observation next is [1.0, 0.0, 0.46969696969696995, 0.8633333333333334, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.49050919519575437, 0.0, 0.0, 0.5084288129206541, 0.1379777050616249, 0.1379777050616249, 0.28888193408943585], 
reward next is 0.7111, 
noisyNet noise sample is [array([0.34262055], dtype=float32), -0.7785147]. 
=============================================
[2019-03-23 12:19:28,528] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.000000e+00 2.729404e-12 1.094243e-08 4.833273e-14 9.580465e-10], sum to 1.0000
[2019-03-23 12:19:28,537] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5035
[2019-03-23 12:19:28,546] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 908772.0703181612 W.
[2019-03-23 12:19:28,550] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.66666666666666, 56.0, 1.0, 2.0, 0.399432180292286, 1.0, 2.0, 0.399432180292286, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 908772.0703181612, 908772.0703181612, 208315.4134975872], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 736800.0000, 
sim time next is 737400.0000, 
raw observation next is [27.83333333333334, 55.5, 1.0, 2.0, 0.3845301942635912, 1.0, 2.0, 0.3845301942635912, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 875085.0034555376, 875085.0034555378, 205074.4535187463], 
processed observation next is [1.0, 0.5217391304347826, 0.9015151515151518, 0.555, 1.0, 1.0, 0.23066274282948898, 1.0, 1.0, 0.23066274282948898, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3241055568353843, 0.3241055568353844, 0.5001815939481618], 
reward next is 0.4998, 
noisyNet noise sample is [array([-1.6737387], dtype=float32), 0.44714555]. 
=============================================
[2019-03-23 12:19:30,253] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9998760e-01 8.2528942e-08 1.1283028e-05 3.5223684e-07 5.4473782e-07], sum to 1.0000
[2019-03-23 12:19:30,260] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3600
[2019-03-23 12:19:30,264] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.66666666666667, 66.33333333333334, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 1.0, 0.3085480369070464, 6.911199999999999, 6.9112, 77.3421103, 525349.8285845564, 525349.8285845566, 201793.0036715046], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 768000.0000, 
sim time next is 768600.0000, 
raw observation next is [24.5, 67.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7830193526308344, 7.390833619999011, 6.9112, 77.32745642876027, 599852.4437266648, 444079.2827472481, 139536.4001397676], 
processed observation next is [1.0, 0.9130434782608695, 0.75, 0.67, 0.0, 0.5, -0.25, 0.0, 0.5, -0.25, 1.0, 1.0, 0.6900276466154779, 0.0479633619999011, 0.0, 0.508422191874447, 0.22216757175061658, 0.1644738084249067, 0.3403326832677258], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.83784497], dtype=float32), -0.029174855]. 
=============================================
[2019-03-23 12:19:31,566] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9999964e-01 1.2579860e-09 4.1454695e-07 3.1403002e-09 2.8265734e-09], sum to 1.0000
[2019-03-23 12:19:31,571] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9831
[2019-03-23 12:19:31,575] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7447009788617182, 7.153223467646633, 6.9112, 77.32773271648678, 506171.6898152517, 427568.1605426079, 131198.7994731405], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 795000.0000, 
sim time next is 795600.0000, 
raw observation next is [19.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7511485447776846, 7.209446737256673, 6.9112, 77.32754240578547, 528338.4523825704, 431475.1660476397, 131777.6114253485], 
processed observation next is [0.0, 0.21739130434782608, 0.5, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.644497921110978, 0.029824673725667328, 0.0, 0.508422757166901, 0.1956809082898409, 0.15980561705468135, 0.3214088083545085], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.43279526], dtype=float32), -0.33482596]. 
=============================================
[2019-03-23 12:19:36,299] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.76383604e-06 9.99991536e-01 9.29869246e-13 1.04266325e-14
 6.86096030e-07], sum to 1.0000
[2019-03-23 12:19:36,310] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6507
[2019-03-23 12:19:36,313] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 92.0, 1.0, 2.0, 0.4244887120570149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482436.8865281576, 482436.8865281576, 129705.82557311], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 888000.0000, 
sim time next is 888600.0000, 
raw observation next is [20.66666666666666, 90.0, 1.0, 2.0, 0.4282960533881998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 487012.5627388791, 487012.5627388794, 130293.7757116979], 
processed observation next is [0.0, 0.2608695652173913, 0.5757575757575755, 0.9, 1.0, 1.0, 0.28537006673524973, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18037502323662188, 0.180375023236622, 0.3177896968577998], 
reward next is 0.6822, 
noisyNet noise sample is [array([-0.27134383], dtype=float32), 1.1177675]. 
=============================================
[2019-03-23 12:19:40,623] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 12:19:40,624] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:19:40,624] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:19:40,624] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:19:40,626] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:19:40,628] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:19:40,628] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:19:40,628] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:19:40,631] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:19:40,632] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:19:40,632] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:19:40,654] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run19
[2019-03-23 12:19:40,655] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run19
[2019-03-23 12:19:40,656] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run19
[2019-03-23 12:19:40,678] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run19
[2019-03-23 12:19:40,702] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run19
[2019-03-23 12:19:59,402] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), 0.00715744]
[2019-03-23 12:19:59,404] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.13333333333334, 66.66666666666667, 1.0, 2.0, 0.7198296640383557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 820581.2644081594, 820581.2644081594, 176290.4208034157]
[2019-03-23 12:19:59,405] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:19:59,408] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.45171417e-07 9.99999404e-01 2.54232026e-17 1.03886925e-19
 4.27309255e-09], sampled 0.5142121377225881
[2019-03-23 12:20:00,274] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), 0.00715744]
[2019-03-23 12:20:00,274] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.56666666666667, 91.0, 1.0, 2.0, 0.336221021809258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 368993.6470008251, 368993.6470008251, 119363.5702197005]
[2019-03-23 12:20:00,276] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:20:00,279] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0026240e-06 9.9999905e-01 8.5028211e-17 4.4234005e-19 7.4329476e-09], sampled 0.34286782596698995
[2019-03-23 12:20:09,061] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), 0.00715744]
[2019-03-23 12:20:09,062] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.16666666666667, 55.5, 1.0, 2.0, 0.2801860821778105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 304233.968285408, 304233.9682854078, 91092.36255822657]
[2019-03-23 12:20:09,062] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:20:09,066] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.4871624e-06 9.9999857e-01 1.9384451e-16 1.1749989e-18 1.0933965e-08], sampled 0.056234638382226865
[2019-03-23 12:20:23,004] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), 0.00715744]
[2019-03-23 12:20:23,006] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.1, 90.0, 1.0, 2.0, 0.4511742784936377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 514008.2022237211, 514008.2022237211, 137966.4601015622]
[2019-03-23 12:20:23,008] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:20:23,012] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.13613111e-07 9.99999404e-01 2.43014100e-17 1.05628024e-19
 3.95005051e-09], sampled 0.9989930427724828
[2019-03-23 12:20:23,639] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), 0.00715744]
[2019-03-23 12:20:23,643] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.91666666666666, 89.5, 1.0, 2.0, 0.4655694246155329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 526673.6717440527, 526673.6717440527, 136497.1719781034]
[2019-03-23 12:20:23,644] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:20:23,646] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.2792426e-07 9.9999928e-01 4.1957205e-17 1.9332742e-19 5.3088480e-09], sampled 0.26569096115066315
[2019-03-23 12:20:26,663] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), 0.00715744]
[2019-03-23 12:20:26,665] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.66666666666667, 90.0, 1.0, 2.0, 0.3440944744035619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 378241.440399098, 378241.4403990983, 115850.3339335704]
[2019-03-23 12:20:26,667] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:20:26,669] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.2336058e-06 9.9999881e-01 1.5921879e-16 8.9022387e-19 1.0387892e-08], sampled 0.3082687858634612
[2019-03-23 12:20:31,028] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), 0.00715744]
[2019-03-23 12:20:31,029] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.0, 83.0, 1.0, 2.0, 0.5339720275695984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 607908.6198355359, 607908.6198355359, 147264.3341759643]
[2019-03-23 12:20:31,029] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:20:31,034] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.6491424e-07 9.9999928e-01 2.9510108e-17 1.3213643e-19 4.3511506e-09], sampled 0.30230135875558284
[2019-03-23 12:20:43,861] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), 0.00715744]
[2019-03-23 12:20:43,862] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.16666666666667, 87.0, 1.0, 2.0, 0.209025117192314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 226947.3532913747, 226947.3532913744, 74234.40818137574]
[2019-03-23 12:20:43,863] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:20:43,867] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.2615920e-06 9.9999774e-01 6.5244836e-16 4.5773230e-18 2.0695447e-08], sampled 0.5731378773888635
[2019-03-23 12:21:00,489] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), 0.00715744]
[2019-03-23 12:21:00,489] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.21740676666667, 85.90815766, 1.0, 2.0, 0.3350654038331308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 363819.820401866, 363819.8204018657, 117468.658522005]
[2019-03-23 12:21:00,491] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:21:00,494] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.6761960e-07 9.9999905e-01 8.5940294e-17 4.3942714e-19 7.6089250e-09], sampled 0.28720785336939203
[2019-03-23 12:21:05,121] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), 0.00715744]
[2019-03-23 12:21:05,122] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.75, 51.5, 1.0, 2.0, 0.4270598006624427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 485567.5924133039, 485567.5924133036, 134484.0757541226]
[2019-03-23 12:21:05,122] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:21:05,125] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.7776309e-07 9.9999917e-01 3.8742533e-17 1.8475671e-19 4.8793907e-09], sampled 0.5832911794220822
[2019-03-23 12:21:06,335] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), 0.00715744]
[2019-03-23 12:21:06,337] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.8, 53.16666666666667, 1.0, 2.0, 0.3928731279765161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 441833.1202253057, 441833.1202253054, 128075.9207245006]
[2019-03-23 12:21:06,337] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:21:06,340] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.7504516e-07 9.9999928e-01 2.7945791e-17 1.2618649e-19 4.1633874e-09], sampled 0.21926371793163035
[2019-03-23 12:21:13,638] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), 0.00715744]
[2019-03-23 12:21:13,639] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.161205045, 92.76838136, 1.0, 2.0, 0.3859698623741099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 423878.4270667753, 423878.427066775, 123268.3801073127]
[2019-03-23 12:21:13,640] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:21:13,642] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.6229551e-07 9.9999917e-01 6.4707282e-17 3.1720011e-19 6.6075851e-09], sampled 0.8644873188720557
[2019-03-23 12:21:19,963] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 12:21:20,000] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.5644 1773150602.3885 173.0000
[2019-03-23 12:21:20,233] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 12:21:20,247] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 12:21:20,323] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 12:21:21,336] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 450000, evaluation results [450000.0, 8511.564350848003, 1773150602.3885174, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 12:21:22,175] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.5515649e-07 9.9999964e-01 3.0625951e-22 1.8745626e-23 6.8062942e-12], sum to 1.0000
[2019-03-23 12:21:22,182] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7570
[2019-03-23 12:21:22,191] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 100.0, 1.0, 2.0, 0.6203586964080868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 696488.7595957062, 696488.7595957065, 146640.0992897169], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 983400.0000, 
sim time next is 984000.0000, 
raw observation next is [17.66666666666667, 100.0, 1.0, 2.0, 0.5757099653407326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 645141.7391754069, 645141.7391754072, 141006.2566381372], 
processed observation next is [1.0, 0.391304347826087, 0.4393939393939396, 1.0, 1.0, 1.0, 0.4696374566759157, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2389413848797803, 0.23894138487978045, 0.34391769911740777], 
reward next is 0.6561, 
noisyNet noise sample is [array([1.1386766], dtype=float32), 0.07687634]. 
=============================================
[2019-03-23 12:21:22,202] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[91.08101 ]
 [91.10185 ]
 [91.00208 ]
 [90.962585]
 [90.93028 ]], R is [[90.86011505]
 [90.59385681]
 [90.35865021]
 [90.12773132]
 [89.89939117]].
[2019-03-23 12:21:41,575] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3869919e-04 9.9986124e-01 4.7091597e-15 2.3366567e-11 1.9924093e-08], sum to 1.0000
[2019-03-23 12:21:41,582] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6862
[2019-03-23 12:21:41,586] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666666, 83.33333333333334, 1.0, 2.0, 0.4656391686224423, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 531312.4470613127, 531312.4470613124, 136818.6873916489], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1359600.0000, 
sim time next is 1360200.0000, 
raw observation next is [22.83333333333334, 80.66666666666666, 1.0, 2.0, 0.4688868223592925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 534931.8252698693, 534931.825269869, 136760.5075438515], 
processed observation next is [1.0, 0.7391304347826086, 0.6742424242424245, 0.8066666666666665, 1.0, 1.0, 0.3361085279491156, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19812289824809973, 0.19812289824809962, 0.33356221352158905], 
reward next is 0.6664, 
noisyNet noise sample is [array([0.94923466], dtype=float32), 0.3796926]. 
=============================================
[2019-03-23 12:21:47,553] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.8779234e-10 1.0000000e+00 3.1941393e-19 2.9396090e-17 1.5637039e-12], sum to 1.0000
[2019-03-23 12:21:47,560] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5084
[2019-03-23 12:21:47,563] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.4460459741421577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 508425.9900234527, 508425.9900234527, 133419.0437872846], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1483200.0000, 
sim time next is 1483800.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.4425283065744249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 504347.499098174, 504347.499098174, 132956.3659775868], 
processed observation next is [0.0, 0.17391304347826086, 0.5454545454545454, 1.0, 1.0, 1.0, 0.30316038321803107, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18679537003636074, 0.18679537003636074, 0.32428381945752877], 
reward next is 0.6757, 
noisyNet noise sample is [array([-0.10928981], dtype=float32), -1.2817332]. 
=============================================
[2019-03-23 12:21:55,203] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.4430377e-07 9.9999917e-01 7.1108911e-14 1.9961399e-10 3.8579966e-08], sum to 1.0000
[2019-03-23 12:21:55,211] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3879
[2019-03-23 12:21:55,216] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.83333333333334, 48.5, 1.0, 2.0, 0.3757371598036817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 408029.5585392249, 408029.5585392249, 86376.42158670214], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1770600.0000, 
sim time next is 1771200.0000, 
raw observation next is [17.0, 48.0, 1.0, 2.0, 0.3754418968078377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 407708.7849930892, 407708.7849930889, 86520.2411959291], 
processed observation next is [1.0, 0.5217391304347826, 0.4090909090909091, 0.48, 1.0, 1.0, 0.21930237100979708, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15100325370114415, 0.15100325370114404, 0.21102497852665636], 
reward next is 0.7890, 
noisyNet noise sample is [array([-1.5186065], dtype=float32), 1.2621546]. 
=============================================
[2019-03-23 12:22:04,575] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.1676242e-10 1.0000000e+00 4.8355093e-27 7.0415224e-22 9.1419648e-15], sum to 1.0000
[2019-03-23 12:22:04,581] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7053
[2019-03-23 12:22:04,587] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 63.0, 1.0, 2.0, 0.2039200223960056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221403.2758436803, 221403.2758436801, 70055.96774573112], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1812600.0000, 
sim time next is 1813200.0000, 
raw observation next is [14.66666666666667, 64.33333333333333, 1.0, 2.0, 0.200303200491539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 217475.4848199889, 217475.4848199886, 69516.88564728231], 
processed observation next is [1.0, 1.0, 0.30303030303030315, 0.6433333333333333, 1.0, 1.0, 0.00037900061442372457, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08054647585925515, 0.08054647585925503, 0.16955337962751782], 
reward next is 0.8304, 
noisyNet noise sample is [array([2.179688], dtype=float32), -0.34320635]. 
=============================================
[2019-03-23 12:22:07,763] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.1237232e-07 9.9999964e-01 2.6002199e-16 3.2789824e-13 5.0137370e-09], sum to 1.0000
[2019-03-23 12:22:07,769] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0009
[2019-03-23 12:22:07,776] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333333, 44.0, 1.0, 2.0, 0.61037064150413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 663002.1736877608, 663002.1736877608, 136425.2220698223], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1874400.0000, 
sim time next is 1875000.0000, 
raw observation next is [23.16666666666667, 44.0, 1.0, 2.0, 0.6181455133056297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 671453.2978604994, 671453.2978604997, 135688.1251617821], 
processed observation next is [1.0, 0.6956521739130435, 0.6893939393939396, 0.44, 1.0, 1.0, 0.5226818916320372, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24868640661499977, 0.24868640661499988, 0.33094664673605395], 
reward next is 0.6691, 
noisyNet noise sample is [array([0.51545715], dtype=float32), -1.3795406]. 
=============================================
[2019-03-23 12:22:07,789] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[63.97213 ]
 [63.9994  ]
 [63.865967]
 [63.589565]
 [63.367935]], R is [[63.97267914]
 [64.00021362]
 [64.02902222]
 [64.05607605]
 [64.0651474 ]].
[2019-03-23 12:22:09,159] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.0869097e-07 9.9999964e-01 3.0458311e-21 2.4307153e-18 3.9152975e-10], sum to 1.0000
[2019-03-23 12:22:09,165] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0521
[2019-03-23 12:22:09,168] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 46.83333333333334, 1.0, 2.0, 0.3111514929586623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 337868.7667345243, 337868.7667345246, 106673.0828546958], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1879800.0000, 
sim time next is 1880400.0000, 
raw observation next is [22.66666666666667, 46.66666666666667, 1.0, 2.0, 0.3113925527874732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 338130.6163639897, 338130.61636399, 103806.8689667771], 
processed observation next is [1.0, 0.782608695652174, 0.6666666666666669, 0.46666666666666673, 1.0, 1.0, 0.13924069098434147, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12523356161629248, 0.1252335616162926, 0.2531874852848222], 
reward next is 0.7468, 
noisyNet noise sample is [array([0.6909581], dtype=float32), -3.0095184]. 
=============================================
[2019-03-23 12:22:09,844] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 12:22:09,847] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:22:09,850] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:22:09,851] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:22:09,851] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:22:09,852] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:22:09,852] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:22:09,854] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:22:09,857] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:22:09,857] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:22:09,859] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:22:09,875] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run20
[2019-03-23 12:22:09,899] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run20
[2019-03-23 12:22:09,900] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run20
[2019-03-23 12:22:09,900] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run20
[2019-03-23 12:22:09,985] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run20
[2019-03-23 12:22:35,768] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.027427413]
[2019-03-23 12:22:35,770] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.0, 100.0, 1.0, 2.0, 0.377811891553447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 424158.2099217196, 424158.2099217199, 122067.9765168141]
[2019-03-23 12:22:35,771] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:22:35,774] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.7735718e-08 1.0000000e+00 5.3439068e-22 2.2043630e-17 9.5414718e-11], sampled 0.9140428555484619
[2019-03-23 12:23:00,901] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.027427413]
[2019-03-23 12:23:00,902] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.3, 56.5, 1.0, 2.0, 0.4805469645037583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 548284.8843683547, 548284.8843683547, 143152.8875154211]
[2019-03-23 12:23:00,904] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:23:00,905] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.2126952e-08 1.0000000e+00 1.7256783e-22 9.0642700e-18 5.5936398e-11], sampled 0.5105862122660426
[2019-03-23 12:23:49,126] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 12:23:49,230] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 12:23:49,394] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 12:23:49,490] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 12:23:49,549] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 12:23:50,564] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 475000, evaluation results [475000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 12:23:51,369] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.2474720e-06 9.9999678e-01 3.3027144e-15 7.9637182e-12 2.7900471e-08], sum to 1.0000
[2019-03-23 12:23:51,376] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2709
[2019-03-23 12:23:51,381] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 91.0, 1.0, 2.0, 0.7907212507568819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 901537.3552347525, 901537.3552347528, 177641.6208388781], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1931400.0000, 
sim time next is 1932000.0000, 
raw observation next is [21.33333333333334, 90.0, 1.0, 2.0, 0.8387312539339327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 956920.8847333324, 956920.8847333327, 186144.8324053167], 
processed observation next is [1.0, 0.34782608695652173, 0.6060606060606063, 0.9, 1.0, 1.0, 0.7984140674174158, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.35441514249382683, 0.35441514249382694, 0.45401178635443096], 
reward next is 0.5460, 
noisyNet noise sample is [array([0.01057523], dtype=float32), -0.9803311]. 
=============================================
[2019-03-23 12:23:51,404] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[57.000633]
 [57.76269 ]
 [58.45766 ]
 [58.57251 ]
 [58.635914]], R is [[56.28969193]
 [56.29352188]
 [56.34272003]
 [56.45046997]
 [56.56347656]].
[2019-03-23 12:23:52,866] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.4129848e-03 9.9191147e-01 3.2874112e-10 8.2531199e-07 4.6747169e-03], sum to 1.0000
[2019-03-23 12:23:52,874] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9479
[2019-03-23 12:23:52,885] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1252571.991309754 W.
[2019-03-23 12:23:52,888] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 61.0, 1.0, 2.0, 0.3666237822790718, 1.0, 2.0, 0.3666237822790718, 1.0, 1.0, 0.7424711481333619, 6.911199999999999, 6.9112, 77.3421103, 1252571.991309754, 1252571.991309754, 284346.5803592767], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1958400.0000, 
sim time next is 1959000.0000, 
raw observation next is [25.83333333333334, 60.33333333333334, 1.0, 2.0, 0.5214210029123559, 1.0, 2.0, 0.5214210029123559, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1189072.138448042, 1189072.138448042, 234255.3755178817], 
processed observation next is [1.0, 0.6956521739130435, 0.8106060606060609, 0.6033333333333334, 1.0, 1.0, 0.4017762536404449, 1.0, 1.0, 0.4017762536404449, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4403970883140897, 0.4403970883140897, 0.5713545744338578], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.20162585], dtype=float32), 0.669491]. 
=============================================
[2019-03-23 12:23:52,901] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[48.669617]
 [48.03205 ]
 [47.707565]
 [47.87897 ]
 [47.492027]], R is [[48.31799698]
 [47.83481598]
 [47.3564682 ]
 [47.21304703]
 [47.15234375]].
[2019-03-23 12:23:54,705] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.5412210e-09 9.9996102e-01 8.2121532e-18 2.0620727e-12 3.9007184e-05], sum to 1.0000
[2019-03-23 12:23:54,714] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9884
[2019-03-23 12:23:54,719] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 61.33333333333334, 1.0, 2.0, 0.2619692075169115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 284447.786215755, 284447.786215755, 85252.73308451926], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1992000.0000, 
sim time next is 1992600.0000, 
raw observation next is [18.5, 62.0, 1.0, 2.0, 0.2601335005053269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 282453.9853835198, 282453.9853835196, 84691.84510582272], 
processed observation next is [0.0, 0.043478260869565216, 0.4772727272727273, 0.62, 1.0, 1.0, 0.07516687563165862, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1046125871790814, 0.10461258717908134, 0.2065654758678603], 
reward next is 0.7934, 
noisyNet noise sample is [array([0.47032884], dtype=float32), -1.7916882]. 
=============================================
[2019-03-23 12:23:58,994] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.9589747e-08 9.9999917e-01 3.6309490e-20 1.7020012e-14 8.2682772e-07], sum to 1.0000
[2019-03-23 12:23:58,999] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9239
[2019-03-23 12:23:59,006] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.83333333333333, 77.83333333333334, 1.0, 2.0, 0.2252544342944469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 244572.6350061136, 244572.6350061138, 78150.92838640772], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2081400.0000, 
sim time next is 2082000.0000, 
raw observation next is [15.66666666666667, 78.66666666666667, 1.0, 2.0, 0.2230015674704277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 242125.9496795052, 242125.9496795055, 77630.55503201055], 
processed observation next is [0.0, 0.08695652173913043, 0.3484848484848486, 0.7866666666666667, 1.0, 1.0, 0.02875195933803462, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.089676277659076, 0.08967627765907611, 0.18934281715124526], 
reward next is 0.8107, 
noisyNet noise sample is [array([0.867908], dtype=float32), -0.44216144]. 
=============================================
[2019-03-23 12:23:59,023] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[94.2467 ]
 [93.89748]
 [94.00148]
 [94.11348]
 [94.06492]], R is [[94.01302338]
 [93.88227844]
 [93.75125885]
 [93.61923218]
 [93.48648071]].
[2019-03-23 12:24:00,977] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5038806e-07 9.9999988e-01 6.0602550e-19 1.3422602e-12 5.4036789e-08], sum to 1.0000
[2019-03-23 12:24:00,983] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0517
[2019-03-23 12:24:00,992] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 62.66666666666667, 1.0, 2.0, 0.2868568654603892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 311479.6129591942, 311479.6129591945, 108713.1944859344], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2104800.0000, 
sim time next is 2105400.0000, 
raw observation next is [20.66666666666666, 61.33333333333333, 1.0, 2.0, 0.2904082093815906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 315337.0415129002, 315337.0415128999, 110554.6060292125], 
processed observation next is [0.0, 0.34782608695652173, 0.5757575757575755, 0.6133333333333333, 1.0, 1.0, 0.11301026172698826, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1167914968566297, 0.1167914968566296, 0.2696453805590549], 
reward next is 0.7304, 
noisyNet noise sample is [array([-0.31377047], dtype=float32), 0.5044639]. 
=============================================
[2019-03-23 12:24:09,427] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.2306829e-07 9.9997556e-01 1.4857082e-15 1.8118838e-10 2.3902812e-05], sum to 1.0000
[2019-03-23 12:24:09,443] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9685
[2019-03-23 12:24:09,447] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333334, 59.0, 1.0, 2.0, 0.2937424230723915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 318958.6535786269, 318958.6535786269, 79655.79555698935], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2276400.0000, 
sim time next is 2277000.0000, 
raw observation next is [16.5, 59.0, 1.0, 2.0, 0.3371336967876314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 366092.5736023607, 366092.573602361, 84378.46451245506], 
processed observation next is [1.0, 0.34782608695652173, 0.38636363636363635, 0.59, 1.0, 1.0, 0.1714171209845392, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1355898420749484, 0.13558984207494854, 0.20580113295720745], 
reward next is 0.7942, 
noisyNet noise sample is [array([-0.16448471], dtype=float32), -0.8637274]. 
=============================================
[2019-03-23 12:24:09,457] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[74.575584]
 [74.83683 ]
 [74.957634]
 [75.05091 ]
 [75.179375]], R is [[74.37065125]
 [74.43266296]
 [74.50863647]
 [74.58692169]
 [74.66437531]].
[2019-03-23 12:24:21,620] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.9559620e-08 9.9999988e-01 4.5005637e-17 1.2263863e-13 1.4402494e-08], sum to 1.0000
[2019-03-23 12:24:21,629] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4339
[2019-03-23 12:24:21,632] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2069164252662467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 224657.3291245729, 224657.3291245726, 74354.62877861837], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2511600.0000, 
sim time next is 2512200.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2066225549134224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 224338.1889047143, 224338.1889047146, 74326.23472112468], 
processed observation next is [1.0, 0.043478260869565216, 0.22727272727272727, 1.0, 1.0, 1.0, 0.008278193641777995, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08308821811285715, 0.08308821811285726, 0.1812834993198163], 
reward next is 0.8187, 
noisyNet noise sample is [array([0.08556759], dtype=float32), -0.5191752]. 
=============================================
[2019-03-23 12:24:23,811] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.1310449e-07 9.9999869e-01 6.0744046e-14 1.1685670e-10 9.2918202e-07], sum to 1.0000
[2019-03-23 12:24:23,817] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7318
[2019-03-23 12:24:23,823] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 50.0, 1.0, 2.0, 0.6921186861012161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 757051.3392571855, 757051.3392571855, 147863.7098788805], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2559600.0000, 
sim time next is 2560200.0000, 
raw observation next is [23.0, 49.50000000000001, 1.0, 2.0, 0.6755542606895232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 738568.4130100884, 738568.4130100887, 145871.3030758315], 
processed observation next is [1.0, 0.6521739130434783, 0.6818181818181818, 0.49500000000000005, 1.0, 1.0, 0.5944428258619039, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2735438566704031, 0.2735438566704032, 0.3557836660386134], 
reward next is 0.6442, 
noisyNet noise sample is [array([-1.1068342], dtype=float32), -0.6276548]. 
=============================================
[2019-03-23 12:24:27,466] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3336420e-08 9.9999952e-01 1.0193639e-17 1.4560480e-12 4.7291164e-07], sum to 1.0000
[2019-03-23 12:24:27,478] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1042
[2019-03-23 12:24:27,483] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333333, 56.33333333333334, 1.0, 2.0, 0.3761056614504129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 423707.3905158738, 423707.3905158738, 122670.7787181953], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2629200.0000, 
sim time next is 2629800.0000, 
raw observation next is [24.5, 54.0, 1.0, 2.0, 0.3694156348766836, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 415144.4369555751, 415144.4369555754, 121558.1539588198], 
processed observation next is [0.0, 0.43478260869565216, 0.75, 0.54, 1.0, 1.0, 0.21176954359585448, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15375719887243522, 0.15375719887243533, 0.2964833023385849], 
reward next is 0.7035, 
noisyNet noise sample is [array([0.5339481], dtype=float32), 0.738759]. 
=============================================
[2019-03-23 12:24:36,970] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0512549e-04 9.9987674e-01 1.2672240e-11 1.7677270e-07 1.8015027e-05], sum to 1.0000
[2019-03-23 12:24:36,976] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1322
[2019-03-23 12:24:36,987] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1247214.767307301 W.
[2019-03-23 12:24:36,994] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.66666666666667, 65.66666666666667, 1.0, 2.0, 0.5477564523609175, 1.0, 1.0, 0.5477564523609175, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846341083108, 1247214.767307301, 1247214.767307301, 242416.728447174], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2803800.0000, 
sim time next is 2804400.0000, 
raw observation next is [26.0, 65.0, 1.0, 2.0, 0.4932487840722998, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9481891863552162, 6.954531288724677, 6.9112, 77.32835714461338, 1110454.195927902, 1096381.098973742, 255484.9180140291], 
processed observation next is [1.0, 0.4782608695652174, 0.8181818181818182, 0.65, 1.0, 1.0, 0.3665609800903747, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9259845519360234, 0.004333128872467729, 0.0, 0.5084281140132247, 0.41127933182514886, 0.4060670736939785, 0.6231339463756808], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.43747377], dtype=float32), 0.1761243]. 
=============================================
[2019-03-23 12:24:39,055] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 12:24:39,056] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:24:39,056] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:24:39,057] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:24:39,058] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:24:39,058] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:24:39,059] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:24:39,061] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:24:39,061] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:24:39,062] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:24:39,062] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:24:39,066] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run21
[2019-03-23 12:24:39,066] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run21
[2019-03-23 12:24:39,067] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run21
[2019-03-23 12:24:39,134] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run21
[2019-03-23 12:24:39,134] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run21
[2019-03-23 12:24:58,543] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.05015007]
[2019-03-23 12:24:58,544] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.33333333333334, 91.33333333333334, 1.0, 2.0, 0.3828008259943732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 431349.9572226438, 431349.9572226434, 127635.1279958212]
[2019-03-23 12:24:58,544] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:24:58,547] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.3157354e-07 9.9999964e-01 4.9599597e-16 1.3403290e-11 1.3343579e-07], sampled 0.6233656025272912
[2019-03-23 12:25:02,878] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.05015007]
[2019-03-23 12:25:02,879] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.15906715, 87.28393940500001, 1.0, 2.0, 0.4848551329673862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 553206.0554445464, 553206.055444546, 143551.1290473134]
[2019-03-23 12:25:02,881] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:25:02,885] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5527377e-07 9.9999976e-01 2.0062615e-16 7.0254852e-12 8.8773547e-08], sampled 0.04390312680792274
[2019-03-23 12:25:39,101] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.05015007]
[2019-03-23 12:25:39,101] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [29.15, 60.5, 1.0, 2.0, 0.6761196208096366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 762662.2036694922, 762662.2036694918, 173606.0007609834]
[2019-03-23 12:25:39,104] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:25:39,107] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.5984359e-07 9.9999976e-01 2.1420510e-16 7.3598653e-12 9.1411238e-08], sampled 0.6229457796420418
[2019-03-23 12:25:49,056] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.05015007]
[2019-03-23 12:25:49,057] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.0, 68.0, 1.0, 2.0, 0.4985893363033989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 568357.2681076314, 568357.2681076316, 142271.7990951949]
[2019-03-23 12:25:49,058] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:25:49,061] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.01559075e-07 9.99999642e-01 3.62214555e-16 1.07066196e-11
 1.15808135e-07], sampled 0.48059893221817906
[2019-03-23 12:26:19,354] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 12:26:19,826] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 12:26:19,839] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 12:26:19,918] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 12:26:19,952] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 12:26:20,964] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 500000, evaluation results [500000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 12:26:27,908] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.0604591e-06 9.9999046e-01 5.0390719e-11 1.0503061e-06 6.4475098e-06], sum to 1.0000
[2019-03-23 12:26:27,915] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1905
[2019-03-23 12:26:27,923] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1710030.372097253 W.
[2019-03-23 12:26:27,926] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.9998826371116853, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9772192859182972, 6.987795013614037, 6.9112, 77.32831006850218, 1710030.372097253, 1685153.927654973, 344236.9118209069], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2986200.0000, 
sim time next is 2986800.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.708232318439564, 1.0, 1.0, 0.708232318439564, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32841740835667, 1599737.094210401, 1599737.094210401, 292876.7194432631], 
processed observation next is [1.0, 0.5652173913043478, 0.9090909090909091, 0.58, 1.0, 1.0, 0.6352903980494551, 1.0, 0.5, 0.6352903980494551, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084285102427901, 0.5924952200779263, 0.5924952200779263, 0.7143334620567392], 
reward next is 0.2857, 
noisyNet noise sample is [array([0.60132414], dtype=float32), 1.0287906]. 
=============================================
[2019-03-23 12:26:34,192] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0617976e-07 9.9999988e-01 2.0988612e-13 2.2009844e-10 1.5875685e-08], sum to 1.0000
[2019-03-23 12:26:34,200] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7817
[2019-03-23 12:26:34,209] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 88.0, 1.0, 2.0, 0.476489102091973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 543665.5098444148, 543665.5098444148, 137810.2208180593], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3115200.0000, 
sim time next is 3115800.0000, 
raw observation next is [22.0, 88.0, 1.0, 2.0, 0.4750834596253239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 542060.3791807719, 542060.3791807722, 137652.8224352133], 
processed observation next is [1.0, 0.043478260869565216, 0.6363636363636364, 0.88, 1.0, 1.0, 0.3438543245316548, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20076310340028589, 0.20076310340028602, 0.3357385913053983], 
reward next is 0.6643, 
noisyNet noise sample is [array([-0.6849007], dtype=float32), 0.28883758]. 
=============================================
[2019-03-23 12:26:43,518] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.4818199e-11 1.0000000e+00 4.3465427e-20 1.0850514e-14 3.1832585e-08], sum to 1.0000
[2019-03-23 12:26:43,525] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2170
[2019-03-23 12:26:43,531] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 62.66666666666667, 1.0, 2.0, 0.3297741071339433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 362435.0436687138, 362435.043668714, 114766.2635298227], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3274800.0000, 
sim time next is 3275400.0000, 
raw observation next is [21.16666666666666, 63.33333333333334, 1.0, 2.0, 0.3282302873860313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 360380.6544991916, 360380.6544991918, 114520.8501141153], 
processed observation next is [0.0, 0.9130434782608695, 0.5984848484848482, 0.6333333333333334, 1.0, 1.0, 0.16028785923253913, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13347431648118208, 0.13347431648118213, 0.2793191466197934], 
reward next is 0.7207, 
noisyNet noise sample is [array([1.2477858], dtype=float32), -0.88792324]. 
=============================================
[2019-03-23 12:26:50,071] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.6214176e-06 9.9986422e-01 6.6171790e-11 7.8782918e-08 1.3006394e-04], sum to 1.0000
[2019-03-23 12:26:50,081] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2181
[2019-03-23 12:26:50,088] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1158380.879197411 W.
[2019-03-23 12:26:50,093] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 65.0, 1.0, 2.0, 0.3386778305043172, 1.0, 2.0, 0.3386778305043172, 1.0, 2.0, 0.6854682469370349, 6.911199999999998, 6.9112, 77.3421103, 1158380.879197411, 1158380.879197411, 271441.1090082301], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3409800.0000, 
sim time next is 3410400.0000, 
raw observation next is [25.0, 65.0, 1.0, 2.0, 0.4801182325242629, 1.0, 2.0, 0.4801182325242629, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1095311.98345758, 1095311.98345758, 223815.9113574423], 
processed observation next is [1.0, 0.4782608695652174, 0.7727272727272727, 0.65, 1.0, 1.0, 0.3501477906553286, 1.0, 1.0, 0.3501477906553286, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4056711049842889, 0.4056711049842889, 0.545892466725469], 
reward next is 0.4541, 
noisyNet noise sample is [array([-0.18128741], dtype=float32), -1.9320606]. 
=============================================
[2019-03-23 12:26:56,290] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.9847668e-10 9.9984896e-01 1.7768734e-19 4.4701711e-15 1.5102839e-04], sum to 1.0000
[2019-03-23 12:26:56,298] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9352
[2019-03-23 12:26:56,303] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 67.33333333333333, 1.0, 2.0, 0.5363597180140348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 609564.0886987346, 609564.0886987346, 148220.7687256025], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3525000.0000, 
sim time next is 3525600.0000, 
raw observation next is [26.66666666666667, 68.66666666666667, 1.0, 2.0, 0.5397563810762405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 613209.8646372193, 613209.8646372193, 148759.2155908644], 
processed observation next is [1.0, 0.8260869565217391, 0.8484848484848487, 0.6866666666666668, 1.0, 1.0, 0.4246954763453005, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2271147646804516, 0.2271147646804516, 0.36282735509966924], 
reward next is 0.6372, 
noisyNet noise sample is [array([0.01063075], dtype=float32), 1.013141]. 
=============================================
[2019-03-23 12:26:57,297] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.0868406e-10 9.9999511e-01 2.2117128e-18 4.4104857e-15 4.9242417e-06], sum to 1.0000
[2019-03-23 12:26:57,308] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8739
[2019-03-23 12:26:57,312] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5618655638909633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 641102.7221263779, 641102.7221263779, 148987.3271204862], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3561000.0000, 
sim time next is 3561600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.516298308417945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 589079.9125930361, 589079.9125930361, 143430.9163738232], 
processed observation next is [1.0, 0.21739130434782608, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3953728855224312, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21817774540482818, 0.21817774540482818, 0.3498315033507883], 
reward next is 0.6502, 
noisyNet noise sample is [array([-0.4011977], dtype=float32), -0.57636535]. 
=============================================
[2019-03-23 12:26:57,364] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7956117e-07 9.9963307e-01 5.4626832e-15 2.9435208e-11 3.6661775e-04], sum to 1.0000
[2019-03-23 12:26:57,371] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6486
[2019-03-23 12:26:57,378] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1453849.886795881 W.
[2019-03-23 12:26:57,385] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.33333333333333, 54.0, 1.0, 2.0, 0.4284007101175308, 1.0, 2.0, 0.4284007101175308, 1.0, 1.0, 0.8670939986234611, 6.911199999999999, 6.9112, 77.3421103, 1453849.886795881, 1453849.886795882, 318024.6347559936], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3688800.0000, 
sim time next is 3689400.0000, 
raw observation next is [28.16666666666667, 54.5, 1.0, 2.0, 0.6390171970613838, 1.0, 2.0, 0.6390171970613838, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1448334.095048729, 1448334.095048729, 270305.1846604444], 
processed observation next is [1.0, 0.6956521739130435, 0.9166666666666669, 0.545, 1.0, 1.0, 0.5487714963267297, 1.0, 1.0, 0.5487714963267297, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.536420035203233, 0.536420035203233, 0.6592809381962058], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.06052158], dtype=float32), 1.7820528]. 
=============================================
[2019-03-23 12:26:58,711] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.9941437e-06 9.9775356e-01 3.3040858e-11 1.8791415e-08 2.2384815e-03], sum to 1.0000
[2019-03-23 12:26:58,717] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1699
[2019-03-23 12:26:58,725] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1535421.681531873 W.
[2019-03-23 12:26:58,731] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.83333333333333, 89.83333333333334, 1.0, 2.0, 0.4550868861301282, 1.0, 2.0, 0.4550868861301282, 1.0, 1.0, 0.9208134458760242, 6.911199999999999, 6.9112, 77.3421103, 1535421.681531873, 1535421.681531874, 335427.9251094706], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3582600.0000, 
sim time next is 3583200.0000, 
raw observation next is [23.66666666666666, 90.66666666666667, 1.0, 2.0, 0.4461300411776227, 1.0, 2.0, 0.4461300411776227, 1.0, 2.0, 0.9026903500095887, 6.9112, 6.9112, 77.3421103, 1505161.937652913, 1505161.937652913, 330640.7579316802], 
processed observation next is [1.0, 0.4782608695652174, 0.7121212121212118, 0.9066666666666667, 1.0, 1.0, 0.30766255147202837, 1.0, 1.0, 0.30766255147202837, 1.0, 1.0, 0.8609862142994127, 0.0, 0.0, 0.5085185399722538, 0.5574673843158937, 0.5574673843158937, 0.8064408730040981], 
reward next is 0.1936, 
noisyNet noise sample is [array([0.71831506], dtype=float32), 0.8655364]. 
=============================================
[2019-03-23 12:26:59,268] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.5321523e-06 9.9921620e-01 1.6900269e-10 4.5044228e-08 7.7628199e-04], sum to 1.0000
[2019-03-23 12:26:59,276] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0158
[2019-03-23 12:26:59,285] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1670879.697281959 W.
[2019-03-23 12:26:59,291] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 74.0, 1.0, 2.0, 0.7427644305247068, 1.0, 2.0, 0.7427644305247068, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1670879.697281959, 1670879.697281959, 305568.3892289491], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3592800.0000, 
sim time next is 3593400.0000, 
raw observation next is [27.16666666666666, 73.33333333333334, 1.0, 2.0, 0.6758357813048843, 1.0, 2.0, 0.6758357813048843, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1520118.736698705, 1520118.736698705, 284292.1019264742], 
processed observation next is [1.0, 0.6086956521739131, 0.871212121212121, 0.7333333333333334, 1.0, 1.0, 0.5947947266311053, 1.0, 1.0, 0.5947947266311053, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.5630069395180389, 0.5630069395180389, 0.6933953705523761], 
reward next is 0.3066, 
noisyNet noise sample is [array([0.84942853], dtype=float32), 0.6804702]. 
=============================================
[2019-03-23 12:27:00,400] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.5075105e-08 9.9920696e-01 2.3516079e-14 1.8244220e-11 7.9305592e-04], sum to 1.0000
[2019-03-23 12:27:00,405] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6194
[2019-03-23 12:27:00,412] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 78.0, 1.0, 2.0, 0.5029712128378471, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 573748.0857050144, 573748.0857050144, 142175.854319187], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3610800.0000, 
sim time next is 3611400.0000, 
raw observation next is [23.83333333333333, 78.83333333333333, 1.0, 2.0, 0.4998359754998423, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 570223.9870153181, 570223.9870153181, 141682.5422469926], 
processed observation next is [1.0, 0.8260869565217391, 0.7196969696969695, 0.7883333333333333, 1.0, 1.0, 0.3747949693748029, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21119406926493264, 0.21119406926493264, 0.3455671762121771], 
reward next is 0.6544, 
noisyNet noise sample is [array([-0.07917071], dtype=float32), 0.40007022]. 
=============================================
[2019-03-23 12:27:00,818] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4263161e-10 9.9997461e-01 3.0520033e-19 7.3554552e-16 2.5382320e-05], sum to 1.0000
[2019-03-23 12:27:00,832] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1384
[2019-03-23 12:27:00,838] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 79.66666666666667, 1.0, 2.0, 0.5090627188428822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 580409.8749390338, 580409.8749390334, 143373.824780338], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3609600.0000, 
sim time next is 3610200.0000, 
raw observation next is [24.0, 78.83333333333333, 1.0, 2.0, 0.5064837240507358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 577627.721122733, 577627.721122733, 142830.9053484306], 
processed observation next is [1.0, 0.782608695652174, 0.7272727272727273, 0.7883333333333333, 1.0, 1.0, 0.38310465506341973, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21393619300841962, 0.21393619300841962, 0.34836806182544044], 
reward next is 0.6516, 
noisyNet noise sample is [array([0.3847839], dtype=float32), -0.7788196]. 
=============================================
[2019-03-23 12:27:05,328] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.6324706e-12 9.9953902e-01 7.4267628e-21 1.7901428e-14 4.6105377e-04], sum to 1.0000
[2019-03-23 12:27:05,338] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4093
[2019-03-23 12:27:05,345] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.5309262534271311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 604442.5532923451, 604442.5532923451, 146884.6358287195], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3711600.0000, 
sim time next is 3712200.0000, 
raw observation next is [23.83333333333333, 84.0, 1.0, 2.0, 0.5299943579672203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 603431.1016641983, 603431.1016641983, 146731.8043616287], 
processed observation next is [1.0, 1.0, 0.7196969696969695, 0.84, 1.0, 1.0, 0.4124929474590253, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22349300061636976, 0.22349300061636976, 0.357882449662509], 
reward next is 0.6421, 
noisyNet noise sample is [array([-1.6461438], dtype=float32), 1.0422348]. 
=============================================
[2019-03-23 12:27:06,938] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0863033e-09 9.9866045e-01 5.0917491e-18 5.3095218e-13 1.3395515e-03], sum to 1.0000
[2019-03-23 12:27:06,946] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8827
[2019-03-23 12:27:06,953] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 73.0, 1.0, 2.0, 0.4966388619814602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564934.6802743151, 564934.6802743151, 137552.023578243], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3742200.0000, 
sim time next is 3742800.0000, 
raw observation next is [23.0, 73.0, 1.0, 2.0, 0.5364172269859235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 610239.6773843336, 610239.6773843336, 142027.7377131846], 
processed observation next is [1.0, 0.30434782608695654, 0.6818181818181818, 0.73, 1.0, 1.0, 0.42052153373240436, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22601469532753096, 0.22601469532753096, 0.34640911637362093], 
reward next is 0.6536, 
noisyNet noise sample is [array([0.8852729], dtype=float32), -0.21393093]. 
=============================================
[2019-03-23 12:27:07,395] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.1859318e-07 9.9449617e-01 1.0109914e-12 3.0222769e-09 5.5031232e-03], sum to 1.0000
[2019-03-23 12:27:07,403] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5710
[2019-03-23 12:27:07,409] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1097884.911029377 W.
[2019-03-23 12:27:07,415] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.0, 69.66666666666666, 1.0, 2.0, 0.3205579619858472, 1.0, 2.0, 0.3205579619858472, 1.0, 2.0, 0.6457006111086369, 6.9112, 6.9112, 77.3421103, 1097884.911029377, 1097884.911029377, 259221.8146526633], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3747000.0000, 
sim time next is 3747600.0000, 
raw observation next is [23.0, 69.0, 1.0, 2.0, 0.3431443778685639, 1.0, 2.0, 0.3431443778685639, 1.0, 2.0, 0.6908670768092168, 6.9112, 6.9112, 77.3421103, 1175247.182036994, 1175247.182036994, 267206.3311360651], 
processed observation next is [1.0, 0.391304347826087, 0.6818181818181818, 0.69, 1.0, 1.0, 0.17893047233570483, 1.0, 1.0, 0.17893047233570483, 1.0, 1.0, 0.5583815382988812, 0.0, 0.0, 0.5085185399722538, 0.43527673408777556, 0.43527673408777556, 0.6517227588684515], 
reward next is 0.3483, 
noisyNet noise sample is [array([1.1734118], dtype=float32), -0.71606016]. 
=============================================
[2019-03-23 12:27:09,185] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.88013267e-08 9.88361537e-01 1.20557246e-16 4.92741958e-10
 1.16384495e-02], sum to 1.0000
[2019-03-23 12:27:09,195] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3153
[2019-03-23 12:27:09,200] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 64.83333333333334, 1.0, 2.0, 0.3360969483744123, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 369068.6140467583, 369068.6140467586, 115115.1955855498], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3780600.0000, 
sim time next is 3781200.0000, 
raw observation next is [21.0, 65.66666666666667, 1.0, 2.0, 0.3375197830685087, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 371336.5749021844, 371336.5749021844, 115480.7237170179], 
processed observation next is [1.0, 0.782608695652174, 0.5909090909090909, 0.6566666666666667, 1.0, 1.0, 0.17189972883563587, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13753206477858682, 0.13753206477858682, 0.28166030174882417], 
reward next is 0.7183, 
noisyNet noise sample is [array([0.48597428], dtype=float32), -1.4337771]. 
=============================================
[2019-03-23 12:27:09,400] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 12:27:09,402] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:27:09,403] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:27:09,403] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:27:09,404] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:27:09,405] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:27:09,405] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:27:09,406] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:27:09,407] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:27:09,409] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:27:09,409] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:27:09,423] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run22
[2019-03-23 12:27:09,423] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run22
[2019-03-23 12:27:09,470] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run22
[2019-03-23 12:27:09,503] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run22
[2019-03-23 12:27:09,503] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run22
[2019-03-23 12:27:29,494] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.06575071]
[2019-03-23 12:27:29,497] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.63333333333334, 59.00000000000001, 1.0, 2.0, 0.5052395034000002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 575821.4582777258, 575821.4582777262, 147427.1965518868]
[2019-03-23 12:27:29,497] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:27:29,500] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.0289150e-09 9.6954352e-01 5.8004998e-18 5.6545893e-11 3.0456483e-02], sampled 0.39390790740724413
[2019-03-23 12:27:49,490] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.06575071]
[2019-03-23 12:27:49,492] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.64997697, 100.0, 1.0, 2.0, 0.6356378977966705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 719936.0034179993, 719936.0034179993, 166780.3576467279]
[2019-03-23 12:27:49,494] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:27:49,496] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.5576401e-09 9.6821219e-01 9.1431954e-18 7.4305569e-11 3.1787775e-02], sampled 0.4519207037004074
[2019-03-23 12:27:58,320] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.06575071]
[2019-03-23 12:27:58,321] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.86666666666667, 87.66666666666667, 1.0, 2.0, 0.4635439843640121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 528708.0420033666, 528708.0420033663, 140284.5781572796]
[2019-03-23 12:27:58,322] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:27:58,325] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.5138318e-09 9.6835804e-01 8.8370939e-18 7.2738954e-11 3.1641908e-02], sampled 0.770187374783992
[2019-03-23 12:28:11,854] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.06575071]
[2019-03-23 12:28:11,855] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.0, 90.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 1.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 476256.6831351622, 476256.6831351622, 196503.1663269509]
[2019-03-23 12:28:11,858] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:28:11,862] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.3812246e-09 9.6678859e-01 1.5814625e-17 1.0277274e-10 3.3211391e-02], sampled 0.05199243225712169
[2019-03-23 12:28:12,965] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.06575071]
[2019-03-23 12:28:12,967] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.26007731, 78.47933166, 1.0, 2.0, 0.3314602822779958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 365749.6325958571, 365749.6325958571, 119759.9860723825]
[2019-03-23 12:28:12,970] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:28:12,972] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.0698387e-09 9.6573603e-01 2.2759550e-17 1.2763685e-10 3.4264039e-02], sampled 0.23083498842498706
[2019-03-23 12:28:20,363] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.06575071]
[2019-03-23 12:28:20,365] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.67946187666667, 76.86898586, 1.0, 2.0, 0.5379554480005352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 612163.1135215407, 612163.1135215403, 152211.9370477896]
[2019-03-23 12:28:20,368] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:28:20,372] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.2559814e-09 9.6899712e-01 7.1433763e-18 6.4007029e-11 3.1002892e-02], sampled 0.7634605274552101
[2019-03-23 12:28:51,740] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.06575071]
[2019-03-23 12:28:51,742] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.0, 96.0, 1.0, 2.0, 0.4197283954369005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 477428.3408789886, 477428.3408789889, 129596.2205581546]
[2019-03-23 12:28:51,744] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:28:51,747] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.904428e-09 9.658708e-01 2.098737e-17 1.218303e-10 3.412927e-02], sampled 0.9260421734799396
[2019-03-23 12:28:52,078] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.06575071]
[2019-03-23 12:28:52,078] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.83333333333334, 52.33333333333334, 1.0, 2.0, 0.2747265724013838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 298286.6128835671, 298286.6128835671, 89882.09230891298]
[2019-03-23 12:28:52,078] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:28:52,082] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.9780434e-09 9.6754193e-01 1.2321432e-17 8.8499943e-11 3.2458019e-02], sampled 0.6563021163559042
[2019-03-23 12:28:54,843] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8346.3199 1687814875.4578 98.0000
[2019-03-23 12:28:54,925] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8074.7129 1731405718.5348 449.0000
[2019-03-23 12:28:55,042] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 7930.1858 1801301783.5529 168.0000
[2019-03-23 12:28:55,165] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.06575071]
[2019-03-23 12:28:55,165] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.3, 62.66666666666667, 1.0, 2.0, 0.4339610774311338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 489181.2622032183, 489181.2622032179, 132398.2103388057]
[2019-03-23 12:28:55,166] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:28:55,167] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.66403308e-09 9.66317058e-01 1.85164215e-17 1.12926585e-10
 3.36829834e-02], sampled 0.006498258749823127
[2019-03-23 12:28:55,228] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8029.9804 1709493986.6317 206.0000
[2019-03-23 12:28:55,314] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 8498.5672 1681952094.5669 76.0000
[2019-03-23 12:28:56,332] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 525000, evaluation results [525000.0, 7930.185815255061, 1801301783.5528524, 168.0, 8498.567164986032, 1681952094.5669172, 76.0, 8346.31991911435, 1687814875.4577637, 98.0, 8074.712866274748, 1731405718.5348492, 449.0, 8029.98042412084, 1709493986.6316545, 206.0]
[2019-03-23 12:28:59,761] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.1425701e-10 9.9977487e-01 6.0729339e-20 2.0283041e-13 2.2516309e-04], sum to 1.0000
[2019-03-23 12:28:59,769] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5850
[2019-03-23 12:28:59,774] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.2965236362068765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 321979.6188707367, 321979.6188707367, 110959.5906936831], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3847800.0000, 
sim time next is 3848400.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.2970737408782811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 322577.1470793688, 322577.1470793688, 110996.2061466117], 
processed observation next is [0.0, 0.5652173913043478, 0.5, 0.73, 1.0, 1.0, 0.12134217609785135, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11947301743680326, 0.11947301743680326, 0.2707224540161261], 
reward next is 0.7293, 
noisyNet noise sample is [array([1.6409948], dtype=float32), 1.0797024]. 
=============================================
[2019-03-23 12:29:11,057] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5621388e-11 9.9999940e-01 5.8641903e-20 1.5687449e-13 5.5220460e-07], sum to 1.0000
[2019-03-23 12:29:11,067] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8489
[2019-03-23 12:29:11,073] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 78.0, 1.0, 2.0, 0.7001595827247264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 794987.9887246102, 794987.9887246102, 161330.7894974586], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4099800.0000, 
sim time next is 4100400.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.7174861325740939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 815504.7419662599, 815504.7419662599, 164328.8255619029], 
processed observation next is [1.0, 0.4782608695652174, 0.6363636363636364, 0.78, 1.0, 1.0, 0.6468576657176173, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.302038793320837, 0.302038793320837, 0.4008020135656168], 
reward next is 0.5992, 
noisyNet noise sample is [array([-2.0046318], dtype=float32), -1.1562041]. 
=============================================
[2019-03-23 12:29:13,636] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.4453515e-11 9.9684155e-01 1.0989606e-19 7.2139972e-12 3.1583989e-03], sum to 1.0000
[2019-03-23 12:29:13,643] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2488
[2019-03-23 12:29:13,645] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.8698653081387789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 989463.6266954651, 989463.6266954651, 187593.9173650323], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4122000.0000, 
sim time next is 4122600.0000, 
raw observation next is [21.5, 80.66666666666667, 1.0, 2.0, 0.5617753317874166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 638187.8502941434, 638187.8502941434, 144223.3823905088], 
processed observation next is [1.0, 0.7391304347826086, 0.6136363636363636, 0.8066666666666668, 1.0, 1.0, 0.45221916473427065, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23636587047931237, 0.23636587047931237, 0.3517643472939239], 
reward next is 0.6482, 
noisyNet noise sample is [array([1.055148], dtype=float32), -0.94670725]. 
=============================================
[2019-03-23 12:29:14,623] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.4610251e-13 9.9999809e-01 4.8621241e-24 6.0234689e-16 1.8558329e-06], sum to 1.0000
[2019-03-23 12:29:14,635] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9471
[2019-03-23 12:29:14,641] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3783627745050517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 424781.8325276767, 424781.8325276767, 122117.6869267412], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4155600.0000, 
sim time next is 4156200.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3700795610525945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 415452.6153433203, 415452.6153433206, 121397.4806174149], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 1.0, 1.0, 1.0, 0.2125994513157431, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15387133901604455, 0.15387133901604466, 0.2960914161400363], 
reward next is 0.7039, 
noisyNet noise sample is [array([0.5953732], dtype=float32), -0.11417315]. 
=============================================
[2019-03-23 12:29:16,985] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.3926043e-12 9.9998045e-01 4.1181584e-20 1.5113431e-13 1.9537787e-05], sum to 1.0000
[2019-03-23 12:29:16,995] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4725
[2019-03-23 12:29:17,004] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 73.0, 1.0, 2.0, 0.3897796800689018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 438508.7868315916, 438508.7868315913, 123556.0982478878], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4217400.0000, 
sim time next is 4218000.0000, 
raw observation next is [21.33333333333334, 73.0, 1.0, 2.0, 0.3844906782220098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 431805.3185267684, 431805.3185267684, 122715.1479238686], 
processed observation next is [1.0, 0.8260869565217391, 0.6060606060606063, 0.73, 1.0, 1.0, 0.2306133477775122, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15992789575065497, 0.15992789575065497, 0.2993052388387039], 
reward next is 0.7007, 
noisyNet noise sample is [array([0.09733415], dtype=float32), -1.1524776]. 
=============================================
[2019-03-23 12:29:17,020] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[70.42072 ]
 [70.4231  ]
 [70.300476]
 [69.96594 ]
 [70.1495  ]], R is [[70.50189209]
 [70.49552155]
 [70.48741913]
 [70.47800446]
 [70.46738434]].
[2019-03-23 12:29:17,797] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.2507555e-10 9.9986303e-01 1.3339823e-18 3.8528406e-11 1.3697626e-04], sum to 1.0000
[2019-03-23 12:29:17,805] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3420
[2019-03-23 12:29:17,811] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 57.0, 1.0, 2.0, 0.8838211190498367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1003265.550529062, 1003265.550529062, 188173.2032584991], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4201200.0000, 
sim time next is 4201800.0000, 
raw observation next is [24.83333333333334, 57.66666666666666, 1.0, 2.0, 0.8374811281925415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 950405.717780681, 950405.7177806806, 180748.219005973], 
processed observation next is [1.0, 0.6521739130434783, 0.7651515151515155, 0.5766666666666665, 1.0, 1.0, 0.7968514102406767, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3520021176965485, 0.3520021176965484, 0.44084931464871463], 
reward next is 0.5592, 
noisyNet noise sample is [array([-0.5815148], dtype=float32), 1.1490579]. 
=============================================
[2019-03-23 12:29:22,830] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.1885776e-11 9.9999940e-01 6.8995673e-19 2.2287430e-13 6.0102553e-07], sum to 1.0000
[2019-03-23 12:29:22,845] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2426
[2019-03-23 12:29:22,854] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 92.0, 1.0, 2.0, 0.3755998199429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 422008.4054098555, 422008.4054098558, 122043.8710782154], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4322400.0000, 
sim time next is 4323000.0000, 
raw observation next is [19.0, 93.0, 1.0, 2.0, 0.379275575625289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 426689.0673230118, 426689.0673230115, 122638.0848586589], 
processed observation next is [1.0, 0.0, 0.5, 0.93, 1.0, 1.0, 0.22409446953161125, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15803298789741177, 0.1580329878974117, 0.2991172801430705], 
reward next is 0.7009, 
noisyNet noise sample is [array([-1.2456597], dtype=float32), 0.52776355]. 
=============================================
[2019-03-23 12:29:22,871] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[61.607727]
 [61.574104]
 [61.66311 ]
 [61.65087 ]
 [61.717075]], R is [[61.62879944]
 [61.71484375]
 [61.80134201]
 [61.88816071]
 [61.97505951]].
[2019-03-23 12:29:28,531] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1678059e-11 1.0000000e+00 2.3877959e-19 1.3911294e-12 3.6013004e-09], sum to 1.0000
[2019-03-23 12:29:28,541] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4926
[2019-03-23 12:29:28,546] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 85.5, 1.0, 2.0, 0.4258980866614775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 483788.6113651771, 483788.6113651771, 129639.3641035964], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4419000.0000, 
sim time next is 4419600.0000, 
raw observation next is [21.0, 84.66666666666666, 1.0, 2.0, 0.4218202056852964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 478838.2651855056, 478838.2651855056, 128995.4474716618], 
processed observation next is [0.0, 0.13043478260869565, 0.5909090909090909, 0.8466666666666666, 1.0, 1.0, 0.27727525710662043, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17734750562426135, 0.17734750562426135, 0.31462304261380925], 
reward next is 0.6854, 
noisyNet noise sample is [array([-0.9053674], dtype=float32), 0.3788992]. 
=============================================
[2019-03-23 12:29:33,531] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.2790914e-12 1.0000000e+00 2.3832902e-20 1.3644058e-14 2.0797537e-09], sum to 1.0000
[2019-03-23 12:29:33,537] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6368
[2019-03-23 12:29:33,540] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 94.0, 1.0, 2.0, 0.4237575538908121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 481403.0800328364, 481403.0800328361, 129467.4517802623], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4502400.0000, 
sim time next is 4503000.0000, 
raw observation next is [20.0, 94.0, 1.0, 2.0, 0.4236120280421113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 481236.9680445376, 481236.9680445379, 129452.6261671528], 
processed observation next is [0.0, 0.08695652173913043, 0.5454545454545454, 0.94, 1.0, 1.0, 0.2795150350526391, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17823591409056946, 0.17823591409056957, 0.3157381126028117], 
reward next is 0.6843, 
noisyNet noise sample is [array([-0.53881127], dtype=float32), 0.33904782]. 
=============================================
[2019-03-23 12:29:33,553] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[61.445835]
 [61.545795]
 [61.556263]
 [61.53696 ]
 [61.320305]], R is [[61.46064758]
 [61.53026962]
 [61.59896851]
 [61.66662979]
 [61.73306656]].
[2019-03-23 12:29:41,858] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.0988332e-15 1.0000000e+00 3.5278747e-24 6.3647965e-19 4.3184722e-12], sum to 1.0000
[2019-03-23 12:29:41,864] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1790
[2019-03-23 12:29:41,867] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 88.0, 1.0, 2.0, 0.2010674232733537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 218305.4117290522, 218305.4117290519, 73247.96349238147], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4683000.0000, 
sim time next is 4683600.0000, 
raw observation next is [14.0, 88.0, 1.0, 2.0, 0.200442528112647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 217626.7910411878, 217626.7910411878, 73180.99076916117], 
processed observation next is [1.0, 0.21739130434782608, 0.2727272727272727, 0.88, 1.0, 1.0, 0.0005531601408087505, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08060251520043993, 0.08060251520043993, 0.17849022138819798], 
reward next is 0.8215, 
noisyNet noise sample is [array([-0.48022655], dtype=float32), 0.10929647]. 
=============================================
[2019-03-23 12:29:44,058] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 12:29:44,059] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:29:44,059] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:29:44,060] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:29:44,060] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:29:44,062] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:29:44,063] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:29:44,062] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:29:44,063] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:29:44,066] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:29:44,064] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:29:44,083] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run23
[2019-03-23 12:29:44,110] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run23
[2019-03-23 12:29:44,111] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run23
[2019-03-23 12:29:44,157] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run23
[2019-03-23 12:29:44,186] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run23
[2019-03-23 12:29:53,662] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.08454961]
[2019-03-23 12:29:53,665] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [12.54190578333333, 96.06173776666665, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 202477.611933847, 202477.6119338466, 73470.38287647962]
[2019-03-23 12:29:53,666] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:29:53,668] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.0748907e-14 1.0000000e+00 8.7141709e-24 4.1666785e-17 1.4090183e-12], sampled 0.4332564034765486
[2019-03-23 12:29:54,553] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.08454961]
[2019-03-23 12:29:54,554] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.34513037, 72.98077419833334, 1.0, 2.0, 0.3897217214934736, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 441145.433498261, 441145.433498261, 129414.2613687721]
[2019-03-23 12:29:54,555] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:29:54,559] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.8071441e-14 1.0000000e+00 6.9177650e-24 3.5353104e-17 1.2511075e-12], sampled 0.4077288575063003
[2019-03-23 12:30:01,596] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.08454961]
[2019-03-23 12:30:01,598] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.390521, 91.07235003, 1.0, 2.0, 0.3232474730768428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 352798.2740404913, 352798.274040491, 117713.8251711537]
[2019-03-23 12:30:01,600] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:30:01,604] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.8680260e-14 1.0000000e+00 7.3119139e-24 3.6775017e-17 1.2873085e-12], sampled 0.30986871359320256
[2019-03-23 12:30:10,366] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.08454961]
[2019-03-23 12:30:10,369] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.28333333333333, 79.0, 1.0, 2.0, 0.4440744831348004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 505486.7548582361, 505486.7548582358, 136732.4196737233]
[2019-03-23 12:30:10,371] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:30:10,375] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.3264643e-14 1.0000000e+00 4.1266280e-24 2.4474185e-17 9.5890797e-13], sampled 0.2436845370773315
[2019-03-23 12:30:15,478] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.08454961]
[2019-03-23 12:30:15,481] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.81907818333333, 99.32904069, 1.0, 2.0, 0.2817320806176814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 305894.8361353666, 305894.8361353662, 89781.25726093506]
[2019-03-23 12:30:15,482] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:30:15,487] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.3106761e-14 1.0000000e+00 1.0431447e-23 4.7359141e-17 1.5457221e-12], sampled 0.44117529489464546
[2019-03-23 12:30:28,544] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.08454961]
[2019-03-23 12:30:28,545] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.57687277333333, 83.89194009333335, 1.0, 2.0, 0.3255146184018806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 357940.6115071293, 357940.6115071293, 118842.8811566293]
[2019-03-23 12:30:28,547] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:30:28,551] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.3916262e-14 1.0000000e+00 1.1049076e-23 4.9338604e-17 1.5921869e-12], sampled 0.5076560830150709
[2019-03-23 12:30:40,026] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.08454961]
[2019-03-23 12:30:40,029] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.16295295, 88.4213296, 1.0, 2.0, 0.5570455139360786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 606383.6705647671, 606383.6705647667, 136917.2625501532]
[2019-03-23 12:30:40,031] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:30:40,035] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.3039624e-14 1.0000000e+00 2.9492483e-23 9.9249378e-17 2.6393861e-12], sampled 0.20587908194539462
[2019-03-23 12:31:12,357] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.08454961]
[2019-03-23 12:31:12,358] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [30.09394718, 62.04466884, 1.0, 2.0, 0.6173850527645184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 693692.7830512195, 693692.7830512195, 165653.2454848507]
[2019-03-23 12:31:12,361] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:31:12,364] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.5847744e-14 1.0000000e+00 5.5553794e-24 3.0243033e-17 1.1174990e-12], sampled 0.2395893514465951
[2019-03-23 12:31:19,200] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.08454961]
[2019-03-23 12:31:19,203] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.08333333333334, 96.0, 1.0, 2.0, 0.4369109887431744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 497190.4572456434, 497190.4572456434, 131505.3340617886]
[2019-03-23 12:31:19,204] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:31:19,206] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.6644462e-14 1.0000000e+00 1.3235115e-23 5.6106655e-17 1.7472150e-12], sampled 0.5994978758017111
[2019-03-23 12:31:22,524] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 12:31:22,778] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 12:31:22,890] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 12:31:22,919] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 12:31:22,951] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 12:31:23,966] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 550000, evaluation results [550000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 12:31:42,440] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.5081535e-13 1.0000000e+00 3.6340106e-22 1.8723617e-16 5.2610844e-08], sum to 1.0000
[2019-03-23 12:31:42,446] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0876
[2019-03-23 12:31:42,453] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333333, 63.83333333333334, 1.0, 2.0, 0.4185759729005124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 475827.4721132774, 475827.4721132774, 129223.0133811333], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5082600.0000, 
sim time next is 5083200.0000, 
raw observation next is [24.0, 65.0, 1.0, 2.0, 0.4146797079580976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 471063.2728545679, 471063.2728545679, 128565.6206473902], 
processed observation next is [0.0, 0.8695652173913043, 0.7272727272727273, 0.65, 1.0, 1.0, 0.268349634947622, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17446787883502515, 0.17446787883502515, 0.31357468450582976], 
reward next is 0.6864, 
noisyNet noise sample is [array([0.9668804], dtype=float32), 2.131133]. 
=============================================
[2019-03-23 12:31:47,803] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.3051057e-12 1.0000000e+00 3.9622678e-21 1.2690902e-15 2.4720248e-10], sum to 1.0000
[2019-03-23 12:31:47,810] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8809
[2019-03-23 12:31:47,815] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 79.66666666666667, 1.0, 2.0, 0.4119450221663046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 468479.2444958617, 468479.2444958614, 128749.8252310362], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5208000.0000, 
sim time next is 5208600.0000, 
raw observation next is [22.0, 78.83333333333333, 1.0, 2.0, 0.4075767456888517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 463229.7034251862, 463229.7034251865, 128080.4517150046], 
processed observation next is [1.0, 0.2608695652173913, 0.6363636363636364, 0.7883333333333333, 1.0, 1.0, 0.2594709321110646, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17156655682414304, 0.17156655682414315, 0.3123913456463527], 
reward next is 0.6876, 
noisyNet noise sample is [array([0.72504956], dtype=float32), 1.7539763]. 
=============================================
[2019-03-23 12:31:49,074] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.1911251e-11 1.0000000e+00 6.5003129e-20 7.7105584e-16 8.4108376e-10], sum to 1.0000
[2019-03-23 12:31:49,082] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5421
[2019-03-23 12:31:49,087] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 54.0, 1.0, 2.0, 0.4210021116400395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 478378.1768656651, 478378.1768656651, 129285.0406540036], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5345400.0000, 
sim time next is 5346000.0000, 
raw observation next is [26.1, 54.0, 1.0, 2.0, 0.4188533316751809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 475932.556197922, 475932.556197922, 129072.9868929396], 
processed observation next is [1.0, 0.9130434782608695, 0.8227272727272728, 0.54, 1.0, 1.0, 0.2735666645939761, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17627131711034147, 0.17627131711034147, 0.31481216315351124], 
reward next is 0.6852, 
noisyNet noise sample is [array([-0.9300192], dtype=float32), -1.7589053]. 
=============================================
[2019-03-23 12:31:49,110] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[62.38516 ]
 [62.30105 ]
 [62.493343]
 [62.616596]
 [62.540745]], R is [[62.41529083]
 [62.47580719]
 [62.53514862]
 [62.59353256]
 [62.65143204]].
[2019-03-23 12:31:59,212] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7746523e-09 9.9999690e-01 1.8782218e-16 3.1923655e-10 3.1465679e-06], sum to 1.0000
[2019-03-23 12:31:59,218] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6910
[2019-03-23 12:31:59,225] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 93.0, 1.0, 2.0, 0.4020107353877786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 454242.0378813867, 454242.0378813867, 125712.9460820147], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5423400.0000, 
sim time next is 5424000.0000, 
raw observation next is [19.4, 93.0, 1.0, 2.0, 0.4008838219828564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 452965.4090535752, 452965.4090535752, 125607.9082780798], 
processed observation next is [1.0, 0.782608695652174, 0.5181818181818181, 0.93, 1.0, 1.0, 0.25110477747857046, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16776496631613896, 0.16776496631613896, 0.30636075189775563], 
reward next is 0.6936, 
noisyNet noise sample is [array([-0.9857978], dtype=float32), 1.009802]. 
=============================================
[2019-03-23 12:31:59,238] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[50.035557]
 [50.077568]
 [50.2782  ]
 [50.15006 ]
 [50.396435]], R is [[50.06642532]
 [50.25914383]
 [50.44956589]
 [50.63783646]
 [50.82419968]].
[2019-03-23 12:32:04,928] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.3604305e-08 9.4879317e-01 1.4627864e-14 2.6950644e-09 5.1206704e-02], sum to 1.0000
[2019-03-23 12:32:04,934] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7871
[2019-03-23 12:32:04,939] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 71.0, 1.0, 2.0, 0.4895793834767004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558559.0249322257, 558559.0249322257, 140378.4017954002], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5515200.0000, 
sim time next is 5515800.0000, 
raw observation next is [24.9, 71.5, 1.0, 2.0, 0.4891679717990799, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 558093.3625622005, 558093.3625622009, 140318.7371843029], 
processed observation next is [1.0, 0.8695652173913043, 0.7681818181818181, 0.715, 1.0, 1.0, 0.36145996474884984, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2067012453934076, 0.20670124539340773, 0.34224082240073883], 
reward next is 0.6578, 
noisyNet noise sample is [array([-0.0610296], dtype=float32), 1.6116657]. 
=============================================
[2019-03-23 12:32:05,472] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.07683626e-11 9.99931931e-01 1.02213636e-19 2.11887785e-13
 6.81090314e-05], sum to 1.0000
[2019-03-23 12:32:05,477] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7648
[2019-03-23 12:32:05,486] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 78.5, 1.0, 2.0, 0.4547942372309273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518453.9242039738, 518453.9242039738, 134414.4901365256], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5525400.0000, 
sim time next is 5526000.0000, 
raw observation next is [22.7, 79.0, 1.0, 2.0, 0.4558791881559908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 519652.1754336376, 519652.1754336376, 134469.0918500514], 
processed observation next is [1.0, 1.0, 0.6681818181818181, 0.79, 1.0, 1.0, 0.3198489851949885, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19246376867912504, 0.19246376867912504, 0.3279733947562229], 
reward next is 0.6720, 
noisyNet noise sample is [array([0.14719737], dtype=float32), -1.2805434]. 
=============================================
[2019-03-23 12:32:05,510] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[67.07855 ]
 [67.10869 ]
 [67.12921 ]
 [67.14667 ]
 [67.146355]], R is [[67.05018616]
 [67.05184174]
 [67.0534668 ]
 [67.05471039]
 [67.05535126]].
[2019-03-23 12:32:06,552] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.8839056e-11 9.9646664e-01 1.7890060e-18 3.9278439e-14 3.5332947e-03], sum to 1.0000
[2019-03-23 12:32:06,560] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5485
[2019-03-23 12:32:06,565] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 87.0, 1.0, 2.0, 0.4808859199157585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 545219.4799410984, 545219.4799410986, 134481.6802267567], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5539200.0000, 
sim time next is 5539800.0000, 
raw observation next is [20.5, 87.0, 1.0, 2.0, 0.4695902621284575, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 532368.2521421504, 532368.2521421504, 133285.6788150413], 
processed observation next is [1.0, 0.08695652173913043, 0.5681818181818182, 0.87, 1.0, 1.0, 0.33698782766057184, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19717342671931498, 0.19717342671931498, 0.3250870215001007], 
reward next is 0.6749, 
noisyNet noise sample is [array([0.76591086], dtype=float32), 1.0519708]. 
=============================================
[2019-03-23 12:32:11,065] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.9735098e-11 9.9998820e-01 1.5475391e-19 4.1014766e-13 1.1848562e-05], sum to 1.0000
[2019-03-23 12:32:11,067] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1874
[2019-03-23 12:32:11,073] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 91.0, 1.0, 2.0, 0.395658788324861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 446140.7878636296, 446140.7878636296, 124611.3035227868], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5607600.0000, 
sim time next is 5608200.0000, 
raw observation next is [19.4, 90.5, 1.0, 2.0, 0.3943018913554053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 444348.7130469059, 444348.7130469059, 124348.0744278633], 
processed observation next is [1.0, 0.9130434782608695, 0.5181818181818181, 0.905, 1.0, 1.0, 0.24287736419425657, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16457359742477995, 0.16457359742477995, 0.30328798640942267], 
reward next is 0.6967, 
noisyNet noise sample is [array([-0.33318263], dtype=float32), 1.3430195]. 
=============================================
[2019-03-23 12:32:12,663] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 12:32:12,664] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:32:12,664] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:32:12,664] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:32:12,665] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:32:12,665] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:32:12,666] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:32:12,666] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:32:12,666] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:32:12,667] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:32:12,668] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:32:12,687] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run24
[2019-03-23 12:32:12,710] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run24
[2019-03-23 12:32:12,733] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run24
[2019-03-23 12:32:12,768] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run24
[2019-03-23 12:32:12,789] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run24
[2019-03-23 12:32:16,599] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.094897844]
[2019-03-23 12:32:16,600] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.5, 94.0, 1.0, 2.0, 0.2896228539182258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 314483.9948876724, 314483.9948876721, 110503.4848047295]
[2019-03-23 12:32:16,601] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:32:16,610] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.3248950e-12 9.9999654e-01 1.8426414e-20 3.0272742e-15 3.4684897e-06], sampled 0.04712848800479963
[2019-03-23 12:32:25,604] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.094897844]
[2019-03-23 12:32:25,605] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [28.55, 39.16666666666666, 1.0, 2.0, 0.3902535244798185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 440917.1686182701, 440917.1686182697, 128951.0726767991]
[2019-03-23 12:32:25,606] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:32:25,609] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.8710138e-12 9.9999714e-01 9.1116562e-21 1.7988572e-15 2.8448519e-06], sampled 0.7876357617334697
[2019-03-23 12:32:35,412] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.094897844]
[2019-03-23 12:32:35,414] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.1, 79.0, 1.0, 2.0, 0.3118784672996825, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 338635.9496126181, 338635.9496126178, 116024.2504382319]
[2019-03-23 12:32:35,415] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:32:35,419] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.6015882e-12 9.9999726e-01 7.6942103e-21 1.5882492e-15 2.7158328e-06], sampled 0.3468376543455327
[2019-03-23 12:32:46,048] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.094897844]
[2019-03-23 12:32:46,050] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.21666666666667, 67.33333333333333, 1.0, 2.0, 0.2553200844459992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 277211.0013650384, 277211.0013650384, 86150.71348175291]
[2019-03-23 12:32:46,050] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:32:46,053] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.7825129e-12 9.9999642e-01 2.1889168e-20 3.4342915e-15 3.6302827e-06], sampled 0.7460855861013794
[2019-03-23 12:32:48,389] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.094897844]
[2019-03-23 12:32:48,391] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.24975575166667, 95.54062134833335, 1.0, 2.0, 0.2593116088119182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 281545.7705172112, 281545.7705172109, 95210.93977662826]
[2019-03-23 12:32:48,392] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:32:48,398] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.5689847e-12 9.9999726e-01 7.5194724e-21 1.5584034e-15 2.6840851e-06], sampled 0.01556338456144113
[2019-03-23 12:33:06,943] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.094897844]
[2019-03-23 12:33:06,945] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.88333333333334, 58.33333333333334, 1.0, 2.0, 0.5283610894552835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 602870.3544814144, 602870.3544814141, 148530.5552825514]
[2019-03-23 12:33:06,946] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:33:06,951] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.1954877e-12 9.9999619e-01 2.5316239e-20 3.8502598e-15 3.8480975e-06], sampled 0.5473273477516684
[2019-03-23 12:33:29,349] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.094897844]
[2019-03-23 12:33:29,352] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.9, 50.0, 1.0, 2.0, 0.8787530683415636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 999982.4502289703, 999982.4502289703, 189390.0656552555]
[2019-03-23 12:33:29,354] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:33:29,355] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.2426957e-11 9.9999034e-01 5.9264105e-19 4.0062053e-14 9.6575031e-06], sampled 0.601578616022245
[2019-03-23 12:33:41,696] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.094897844]
[2019-03-23 12:33:41,697] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.2, 84.0, 1.0, 2.0, 0.3421649827792488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 380766.3396262446, 380766.339626245, 121858.694520332]
[2019-03-23 12:33:41,698] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:33:41,699] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.0182057e-12 9.9999714e-01 9.9286384e-21 1.9164080e-15 2.9133353e-06], sampled 0.8437724384171562
[2019-03-23 12:33:50,989] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 12:33:51,240] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 12:33:51,368] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 12:33:51,422] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 12:33:51,522] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 12:33:52,539] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 575000, evaluation results [575000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 12:33:58,107] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 12:33:58,117] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8276
[2019-03-23 12:33:58,125] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.68333333333334, 44.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4674756234568979, 6.9112, 6.9112, 77.32846344354104, 271901.9530143797, 271901.9530143797, 79277.83182731936], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5749800.0000, 
sim time next is 5750400.0000, 
raw observation next is [20.86666666666667, 44.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4718313010934221, 6.9112, 6.9112, 77.32846344354104, 274436.098829654, 274436.098829654, 80833.72870812193], 
processed observation next is [0.0, 0.5652173913043478, 0.5848484848484851, 0.4466666666666667, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2454732872763173, 0.0, 0.0, 0.5084288129206541, 0.10164299956653851, 0.10164299956653851, 0.19715543587346812], 
reward next is 0.8028, 
noisyNet noise sample is [array([-0.72331756], dtype=float32), -0.88168174]. 
=============================================
[2019-03-23 12:34:01,205] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.0809043e-03 8.5048628e-01 3.1220320e-06 5.2386493e-04 1.4690594e-01], sum to 1.0000
[2019-03-23 12:34:01,210] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1584
[2019-03-23 12:34:01,218] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 68.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 1.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 416763.7114785837, 416763.711478584, 179356.8726285599], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5959200.0000, 
sim time next is 5959800.0000, 
raw observation next is [21.9, 68.0, 1.0, 2.0, 0.3677464261147387, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 412720.2227967018, 412720.2227967018, 121143.3819038917], 
processed observation next is [1.0, 1.0, 0.6318181818181817, 0.68, 1.0, 1.0, 0.20968303264342333, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15285934177655625, 0.15285934177655625, 0.29547166318022366], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.04313499], dtype=float32), 0.01429037]. 
=============================================
[2019-03-23 12:34:09,181] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 4.1861491e-16 8.9798385e-20 1.4156523e-17 3.7471298e-14], sum to 1.0000
[2019-03-23 12:34:09,191] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8525
[2019-03-23 12:34:09,194] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.61666666666667, 90.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6544264546502778, 6.9112, 6.9112, 77.32846344354104, 379431.2372801439, 379431.2372801439, 119088.5596841725], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5980200.0000, 
sim time next is 5980800.0000, 
raw observation next is [17.53333333333333, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.660674893328674, 6.911199999999999, 6.9112, 77.32846344354104, 383136.7828231234, 383136.7828231237, 119600.9220815022], 
processed observation next is [1.0, 0.21739130434782608, 0.43333333333333324, 0.91, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5152498476123915, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14190251215671237, 0.14190251215671248, 0.2917095660524444], 
reward next is 0.7083, 
noisyNet noise sample is [array([0.45673686], dtype=float32), 1.501337]. 
=============================================
[2019-03-23 12:34:10,061] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 7.3314070e-17 3.0217996e-18 3.9734334e-16 8.0417003e-15], sum to 1.0000
[2019-03-23 12:34:10,069] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2381
[2019-03-23 12:34:10,077] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1225764.91015785 W.
[2019-03-23 12:34:10,083] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.63333333333333, 76.66666666666667, 1.0, 2.0, 0.5936333607792457, 0.0, 2.0, 0.0, 1.0, 2.0, 0.970742942039476, 6.911200000000001, 6.9112, 77.32846344354104, 1225764.91015785, 1225764.91015785, 270592.3375779231], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6021600.0000, 
sim time next is 6022200.0000, 
raw observation next is [23.16666666666667, 77.83333333333334, 1.0, 2.0, 0.5186576862113044, 1.0, 1.0, 0.5186576862113044, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1182864.467251209, 1182864.467251209, 233477.1110692064], 
processed observation next is [1.0, 0.6956521739130435, 0.6893939393939396, 0.7783333333333334, 1.0, 1.0, 0.3983221077641304, 1.0, 0.5, 0.3983221077641304, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4380979508337811, 0.4380979508337811, 0.5694563684614791], 
reward next is 0.4305, 
noisyNet noise sample is [array([-0.2822955], dtype=float32), -0.063930936]. 
=============================================
[2019-03-23 12:34:19,085] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 6.3602222e-15 1.0432553e-17 5.8251658e-16 1.7299251e-12], sum to 1.0000
[2019-03-23 12:34:19,093] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2086
[2019-03-23 12:34:19,104] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 794075.0206033055 W.
[2019-03-23 12:34:19,109] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.7, 71.0, 1.0, 2.0, 0.2333777957463717, 1.0, 1.0, 0.2333777957463717, 1.0, 2.0, 0.4629657232714312, 6.9112, 6.9112, 77.3421103, 794075.0206033055, 794075.0206033055, 224240.7693609374], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6178200.0000, 
sim time next is 6178800.0000, 
raw observation next is [21.8, 71.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3532905289214358, 6.911199999999999, 6.9112, 77.3421103, 605572.1337508272, 605572.1337508274, 207523.8687816452], 
processed observation next is [1.0, 0.5217391304347826, 0.6272727272727273, 0.71, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0761293270306226, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.2242859754632693, 0.22428597546326942, 0.5061557775162078], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.00063845], dtype=float32), -1.2150798]. 
=============================================
[2019-03-23 12:34:20,618] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9999988e-01 2.5525523e-11 1.7281217e-15 3.2309974e-14 9.9170720e-08], sum to 1.0000
[2019-03-23 12:34:20,631] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1015
[2019-03-23 12:34:20,639] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.4, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7445865675643034, 7.16069431385132, 6.9112, 77.32766894828623, 509117.1792612902, 428087.3616961964, 130758.9905042272], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6220800.0000, 
sim time next is 6221400.0000, 
raw observation next is [19.4, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7474344910507126, 7.18309356757872, 6.9112, 77.32759352350563, 517948.3815346785, 429643.9053780695, 131137.0420269596], 
processed observation next is [0.0, 0.0, 0.5181818181818181, 0.9, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6391921300724466, 0.02718935675787204, 0.0, 0.5084230932620544, 0.19183273390173278, 0.15912737236224797, 0.3198464439681941], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.45430136], dtype=float32), -0.6702711]. 
=============================================
[2019-03-23 12:34:27,173] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.8613803e-06 9.9998116e-01 8.3597707e-14 3.0657965e-09 1.0973540e-05], sum to 1.0000
[2019-03-23 12:34:27,181] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6844
[2019-03-23 12:34:27,187] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.28333333333333, 86.66666666666666, 1.0, 2.0, 0.4707285194892691, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 537127.3138136041, 537127.3138136038, 137419.2910024867], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6324600.0000, 
sim time next is 6325200.0000, 
raw observation next is [22.2, 87.0, 1.0, 2.0, 0.4687788106655684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 534891.4354269903, 534891.4354269903, 137121.2989457202], 
processed observation next is [0.0, 0.21739130434782608, 0.6454545454545454, 0.87, 1.0, 1.0, 0.3359735133319605, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19810793904703344, 0.19810793904703344, 0.33444219255053703], 
reward next is 0.6656, 
noisyNet noise sample is [array([0.74086326], dtype=float32), -0.45641425]. 
=============================================
[2019-03-23 12:34:34,186] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1643075e-07 9.9999988e-01 1.9262379e-19 1.0861114e-14 2.4084171e-10], sum to 1.0000
[2019-03-23 12:34:34,193] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4112
[2019-03-23 12:34:34,201] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.88333333333334, 69.16666666666667, 1.0, 2.0, 0.2421311779887096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 262901.7091559556, 262901.7091559556, 79852.38252398142], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6465000.0000, 
sim time next is 6465600.0000, 
raw observation next is [16.6, 70.0, 1.0, 2.0, 0.2414760763191526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 262190.2197379285, 262190.2197379285, 79115.12173672295], 
processed observation next is [1.0, 0.8695652173913043, 0.390909090909091, 0.7, 1.0, 1.0, 0.05184509539894074, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09710748879182536, 0.09710748879182536, 0.1929637115529828], 
reward next is 0.8070, 
noisyNet noise sample is [array([-0.8822706], dtype=float32), -0.8754121]. 
=============================================
[2019-03-23 12:34:37,808] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5009197e-08 1.0000000e+00 2.9980176e-20 3.3030274e-15 2.3809851e-10], sum to 1.0000
[2019-03-23 12:34:37,818] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8346
[2019-03-23 12:34:37,825] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.58333333333334, 51.83333333333334, 1.0, 2.0, 0.4776530114824568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518763.5263250472, 518763.5263250472, 105929.3504304951], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6531000.0000, 
sim time next is 6531600.0000, 
raw observation next is [19.76666666666667, 51.66666666666667, 1.0, 2.0, 0.4704479462345661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 510934.2250188418, 510934.2250188418, 105642.5587535322], 
processed observation next is [1.0, 0.6086956521739131, 0.534848484848485, 0.5166666666666667, 1.0, 1.0, 0.33805993279320756, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1892348981551266, 0.1892348981551266, 0.2576647774476395], 
reward next is 0.7423, 
noisyNet noise sample is [array([0.01985897], dtype=float32), 0.17001323]. 
=============================================
[2019-03-23 12:34:37,972] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.0057890e-09 1.0000000e+00 1.0075792e-20 2.9454825e-15 5.9925587e-10], sum to 1.0000
[2019-03-23 12:34:37,979] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6361
[2019-03-23 12:34:37,984] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 49.0, 1.0, 2.0, 0.425047333443745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 461603.071506443, 461603.0715064427, 101484.5352522724], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6526800.0000, 
sim time next is 6527400.0000, 
raw observation next is [20.31666666666667, 49.5, 1.0, 2.0, 0.4920453291824238, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 534403.1503990886, 534403.150399089, 108476.9895435054], 
processed observation next is [1.0, 0.5652173913043478, 0.559848484848485, 0.495, 1.0, 1.0, 0.3650566614780297, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19792709274040318, 0.19792709274040332, 0.26457802327684243], 
reward next is 0.7354, 
noisyNet noise sample is [array([1.2521275], dtype=float32), 2.348035]. 
=============================================
[2019-03-23 12:34:41,340] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 12:34:41,342] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:34:41,343] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:34:41,343] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:34:41,344] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:34:41,343] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:34:41,345] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:34:41,346] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:34:41,347] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:34:41,346] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:34:41,351] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:34:41,361] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run25
[2019-03-23 12:34:41,384] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run25
[2019-03-23 12:34:41,407] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run25
[2019-03-23 12:34:41,441] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run25
[2019-03-23 12:34:41,466] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run25
[2019-03-23 12:35:28,765] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.095920414]
[2019-03-23 12:35:28,766] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [28.16666666666667, 62.0, 1.0, 2.0, 0.8192307648433861, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9815380125479177, 6.911199999999999, 6.9112, 77.32846344354104, 1474409.717385645, 1474409.717385646, 315429.4703671996]
[2019-03-23 12:35:28,767] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:35:28,773] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.0625939e-06 9.9999797e-01 2.1667667e-17 4.8130179e-13 1.4854351e-08], sampled 0.3334825086859007
[2019-03-23 12:35:28,775] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1474409.717385645 W.
[2019-03-23 12:35:32,441] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.095920414]
[2019-03-23 12:35:32,443] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.9, 59.0, 1.0, 2.0, 0.8411925962751496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 957799.0609041146, 957799.0609041146, 196854.2210416657]
[2019-03-23 12:35:32,445] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:35:32,448] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.9898126e-06 9.9999702e-01 6.0672990e-17 1.0255089e-12 2.3852621e-08], sampled 0.2851626379106207
[2019-03-23 12:35:35,056] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.095920414]
[2019-03-23 12:35:35,057] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.0, 77.0, 1.0, 2.0, 0.2842231350451767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 308618.9053062461, 308618.9053062464, 102004.6711653991]
[2019-03-23 12:35:35,059] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:35:35,062] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.6764907e-04 9.9961746e-01 5.3184384e-11 2.4172254e-08 1.4874118e-05], sampled 0.285170524707543
[2019-03-23 12:35:50,255] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.095920414]
[2019-03-23 12:35:50,256] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.63333333333333, 71.0, 1.0, 2.0, 0.3070615885459281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 334394.4259826406, 334394.4259826406, 116320.8975465545]
[2019-03-23 12:35:50,256] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:35:50,259] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.3221886e-04 9.9965429e-01 4.1344608e-11 2.0281805e-08 1.3442731e-05], sampled 0.3319095167854592
[2019-03-23 12:36:09,767] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.095920414]
[2019-03-23 12:36:09,767] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.25, 78.0, 1.0, 2.0, 0.3655654977227568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 408584.1883628778, 408584.1883628778, 124491.9700924995]
[2019-03-23 12:36:09,768] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:36:09,770] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.9667075e-05 9.9990809e-01 9.9947871e-13 1.2836420e-09 2.2574118e-06], sampled 0.18157799091262827
[2019-03-23 12:36:11,089] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.095920414]
[2019-03-23 12:36:11,091] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.949062675, 96.59346536666666, 1.0, 2.0, 0.4246004482484089, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 482882.5192055159, 482882.5192055156, 134342.6482474375]
[2019-03-23 12:36:11,092] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:36:11,094] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.2201008e-05 9.9990535e-01 1.1134318e-12 1.4121828e-09 2.4259921e-06], sampled 0.33642242868013583
[2019-03-23 12:36:19,794] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.0527 1705957088.7303 465.0000
[2019-03-23 12:36:20,072] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.3472 1656152088.1057 80.0000
[2019-03-23 12:36:20,114] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8855.1678 1663742718.7838 105.0000
[2019-03-23 12:36:20,165] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8507.6093 1773091955.2150 173.0000
[2019-03-23 12:36:20,411] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8572.9060 1683295807.7725 214.0000
[2019-03-23 12:36:21,425] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 600000, evaluation results [600000.0, 8507.609287377883, 1773091955.215047, 173.0, 9061.34724494479, 1656152088.105678, 80.0, 8855.16782608149, 1663742718.783826, 105.0, 8597.05269928258, 1705957088.730333, 465.0, 8572.906037404444, 1683295807.772495, 214.0]
[2019-03-23 12:36:34,208] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.3739327e-06 9.9999297e-01 1.2518193e-16 4.6265123e-12 1.6439536e-06], sum to 1.0000
[2019-03-23 12:36:34,218] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8040
[2019-03-23 12:36:34,224] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 56.66666666666666, 1.0, 2.0, 0.4615532530767018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 526547.6860195119, 526547.6860195119, 135922.222720284], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6871200.0000, 
sim time next is 6871800.0000, 
raw observation next is [26.7, 56.33333333333334, 1.0, 2.0, 0.4564506482779281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 520602.1554241545, 520602.1554241548, 135060.8493821811], 
processed observation next is [0.0, 0.5217391304347826, 0.85, 0.5633333333333335, 1.0, 1.0, 0.3205633103474101, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1928156131200572, 0.19281561312005732, 0.32941670581019783], 
reward next is 0.6706, 
noisyNet noise sample is [array([-1.5823889], dtype=float32), -0.508491]. 
=============================================
[2019-03-23 12:36:38,178] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.2431523e-08 1.0000000e+00 2.2768446e-18 2.6022563e-15 3.2297107e-10], sum to 1.0000
[2019-03-23 12:36:38,187] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8804
[2019-03-23 12:36:38,192] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 90.0, 1.0, 2.0, 0.3836340901283909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 431963.0689651293, 431963.0689651293, 123209.0738850064], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6922800.0000, 
sim time next is 6923400.0000, 
raw observation next is [19.3, 90.0, 1.0, 2.0, 0.3819153892739152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 429693.7864921216, 429693.7864921216, 122884.7297103379], 
processed observation next is [0.0, 0.13043478260869565, 0.5136363636363637, 0.9, 1.0, 1.0, 0.227394236592394, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15914584684893393, 0.15914584684893393, 0.29971885295204365], 
reward next is 0.7003, 
noisyNet noise sample is [array([0.9435469], dtype=float32), 0.35359293]. 
=============================================
[2019-03-23 12:36:38,648] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.9742054e-09 1.0000000e+00 5.2905691e-19 6.8976873e-16 4.6141881e-09], sum to 1.0000
[2019-03-23 12:36:38,655] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0587
[2019-03-23 12:36:38,661] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.23333333333333, 78.33333333333334, 1.0, 2.0, 0.3826156258617821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 431983.3985916398, 431983.3985916401, 123761.5222860967], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6942000.0000, 
sim time next is 6942600.0000, 
raw observation next is [21.6, 77.0, 1.0, 2.0, 0.3884082816621584, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 439212.1871467398, 439212.1871467401, 124684.4298473374], 
processed observation next is [0.0, 0.34782608695652173, 0.6181818181818183, 0.77, 1.0, 1.0, 0.235510352077698, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16267118042471845, 0.16267118042471856, 0.3041083654813107], 
reward next is 0.6959, 
noisyNet noise sample is [array([-1.6570252], dtype=float32), -0.8006603]. 
=============================================
[2019-03-23 12:36:38,831] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5237055e-06 9.9999797e-01 2.7045894e-17 4.0665899e-12 4.4105585e-07], sum to 1.0000
[2019-03-23 12:36:38,838] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4782
[2019-03-23 12:36:38,844] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 58.0, 1.0, 2.0, 0.4972360187250106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 566917.837599674, 566917.837599674, 141980.2583644099], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6957000.0000, 
sim time next is 6957600.0000, 
raw observation next is [27.7, 58.0, 1.0, 2.0, 0.4979496732111359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 567731.652745638, 567731.652745638, 142064.205959798], 
processed observation next is [0.0, 0.5217391304347826, 0.8954545454545454, 0.58, 1.0, 1.0, 0.37243709151391985, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21027098249838447, 0.21027098249838447, 0.3464980633165805], 
reward next is 0.6535, 
noisyNet noise sample is [array([0.40464476], dtype=float32), 0.02805935]. 
=============================================
[2019-03-23 12:36:39,648] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.5819235e-07 9.9999785e-01 2.1464955e-17 2.3136855e-12 1.7400828e-06], sum to 1.0000
[2019-03-23 12:36:39,655] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5858
[2019-03-23 12:36:39,665] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 91.0, 1.0, 2.0, 0.3690564021933807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 413168.3410368196, 413168.3410368199, 120770.3600477249], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7071600.0000, 
sim time next is 7072200.0000, 
raw observation next is [18.8, 91.5, 1.0, 2.0, 0.3742779122291909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 419326.3984941545, 419326.3984941542, 121352.9388174012], 
processed observation next is [1.0, 0.8695652173913043, 0.49090909090909096, 0.915, 1.0, 1.0, 0.21784739028648858, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15530607351635353, 0.15530607351635342, 0.29598277760341757], 
reward next is 0.7040, 
noisyNet noise sample is [array([-0.06233304], dtype=float32), -0.81250757]. 
=============================================
[2019-03-23 12:36:46,096] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6946193e-07 9.9999964e-01 5.9247055e-18 3.2860118e-14 1.8259620e-07], sum to 1.0000
[2019-03-23 12:36:46,104] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4477
[2019-03-23 12:36:46,111] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3520297155429749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 391900.2718743069, 391900.2718743069, 118382.9755381599], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7089000.0000, 
sim time next is 7089600.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.3531672523704874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 393180.9882105388, 393180.9882105388, 118479.5319194915], 
processed observation next is [1.0, 0.043478260869565216, 0.44090909090909086, 0.97, 1.0, 1.0, 0.19145906546310923, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14562258822612548, 0.14562258822612548, 0.28897446809632077], 
reward next is 0.7110, 
noisyNet noise sample is [array([-0.7229918], dtype=float32), 0.3930157]. 
=============================================
[2019-03-23 12:36:53,076] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0928249e-07 9.9999964e-01 2.3647924e-16 1.0215519e-13 2.5140929e-07], sum to 1.0000
[2019-03-23 12:36:53,084] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4048
[2019-03-23 12:36:53,089] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.56666666666667, 59.66666666666667, 1.0, 2.0, 0.5111637878817245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 555179.2834337, 555179.2834337003, 116417.7965653], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7204800.0000, 
sim time next is 7205400.0000, 
raw observation next is [19.95, 58.0, 1.0, 2.0, 0.5212743237659514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 566166.8167573907, 566166.8167573905, 118516.8138258004], 
processed observation next is [1.0, 0.391304347826087, 0.5431818181818181, 0.58, 1.0, 1.0, 0.4015929047074392, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2096914136138484, 0.20969141361384833, 0.28906539957512295], 
reward next is 0.7109, 
noisyNet noise sample is [array([-0.18608145], dtype=float32), 2.629741]. 
=============================================
[2019-03-23 12:37:07,406] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.3743961e-11 1.0000000e+00 1.1882429e-19 1.3158793e-16 1.7534303e-13], sum to 1.0000
[2019-03-23 12:37:07,417] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6695
[2019-03-23 12:37:07,421] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.03333333333333, 96.0, 1.0, 2.0, 0.4366481642296126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 496772.7766315978, 496772.7766315978, 131364.2942170068], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7597200.0000, 
sim time next is 7597800.0000, 
raw observation next is [20.05, 96.0, 1.0, 2.0, 0.4364758971397096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 496616.6179523598, 496616.6179523601, 131385.0327189366], 
processed observation next is [0.0, 0.9565217391304348, 0.5477272727272727, 0.96, 1.0, 1.0, 0.2955948714246369, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18393208072309622, 0.18393208072309633, 0.3204512993144795], 
reward next is 0.6795, 
noisyNet noise sample is [array([-0.6028811], dtype=float32), -0.7724562]. 
=============================================
[2019-03-23 12:37:10,238] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 12:37:10,241] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:37:10,242] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:37:10,242] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:37:10,243] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:37:10,245] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:37:10,246] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:37:10,248] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:37:10,248] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:37:10,247] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:37:10,250] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:37:10,265] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run26
[2019-03-23 12:37:10,290] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run26
[2019-03-23 12:37:10,313] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run26
[2019-03-23 12:37:10,346] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run26
[2019-03-23 12:37:10,347] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run26
[2019-03-23 12:37:25,920] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.112242915]
[2019-03-23 12:37:25,922] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.33333333333334, 78.0, 1.0, 2.0, 0.4025836038248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 454624.3587368713, 454624.358736871, 129942.3820579085]
[2019-03-23 12:37:25,923] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:37:25,929] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.4231278e-11 1.0000000e+00 1.4188669e-20 8.6577084e-17 7.0821174e-15], sampled 0.7175699820400477
[2019-03-23 12:37:32,059] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.112242915]
[2019-03-23 12:37:32,061] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 100.0, 1.0, 2.0, 0.4133360006749084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468596.3374331864, 468596.3374331864, 127739.1804569113]
[2019-03-23 12:37:32,063] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:37:32,066] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.90776925e-11 1.00000000e+00 1.81815365e-20 1.05907454e-16
 8.45122719e-15], sampled 0.8725872262865759
[2019-03-23 12:37:39,025] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.112242915]
[2019-03-23 12:37:39,027] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.66666666666667, 78.66666666666667, 1.0, 2.0, 0.2230015674704277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 242125.9496795052, 242125.9496795055, 77630.55503201055]
[2019-03-23 12:37:39,029] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:37:39,030] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0328881e-10 1.0000000e+00 1.1220656e-19 4.6471864e-16 3.0911536e-14], sampled 0.6324529987465585
[2019-03-23 12:37:54,924] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.112242915]
[2019-03-23 12:37:54,925] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.44977924, 60.93689515, 1.0, 2.0, 0.3488241312880131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 387647.9745905168, 387647.9745905164, 122159.9186959763]
[2019-03-23 12:37:54,926] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:37:54,929] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.4137185e-11 1.0000000e+00 7.3769227e-21 5.0885170e-17 4.4438449e-15], sampled 0.9237175848417377
[2019-03-23 12:37:59,423] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.112242915]
[2019-03-23 12:37:59,423] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.41628743, 71.57377981, 1.0, 2.0, 0.3974120509832908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 435358.0645375483, 435358.064537548, 123811.7378441815]
[2019-03-23 12:37:59,426] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:37:59,429] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.6604030e-11 1.0000000e+00 8.8507372e-21 5.9002164e-17 5.0597975e-15], sampled 0.5918796373376668
[2019-03-23 12:38:14,203] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.112242915]
[2019-03-23 12:38:14,204] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.9, 77.5, 1.0, 2.0, 0.301400402267928, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 327255.8257965168, 327255.8257965165, 107656.9720200694]
[2019-03-23 12:38:14,204] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:38:14,207] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.0894370e-11 1.0000000e+00 1.1710259e-20 7.4077041e-17 6.1768264e-15], sampled 0.8190604074668157
[2019-03-23 12:38:42,699] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.112242915]
[2019-03-23 12:38:42,700] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.46666666666667, 82.33333333333334, 1.0, 2.0, 0.2843150713467751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 308700.0773496813, 308700.0773496813, 95852.69295769255]
[2019-03-23 12:38:42,701] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:38:42,703] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.9984886e-11 1.0000000e+00 1.1072933e-20 7.0782480e-17 5.9353712e-15], sampled 0.38218383047134497
[2019-03-23 12:38:48,789] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 12:38:48,927] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 12:38:49,205] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 12:38:49,225] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 12:38:49,256] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 12:38:50,270] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 625000, evaluation results [625000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 12:38:52,516] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.1082021e-10 1.0000000e+00 4.6106804e-19 9.8485376e-15 3.4681801e-14], sum to 1.0000
[2019-03-23 12:38:52,528] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6775
[2019-03-23 12:38:52,530] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 92.5, 1.0, 2.0, 0.4368992372754404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 497232.2300953661, 497232.2300953664, 131558.7512803515], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7690200.0000, 
sim time next is 7690800.0000, 
raw observation next is [20.5, 92.0, 1.0, 2.0, 0.4337244823417326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 493474.1552198227, 493474.1552198227, 131097.669619813], 
processed observation next is [1.0, 0.0, 0.5681818181818182, 0.92, 1.0, 1.0, 0.29215560292716575, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18276820563697138, 0.18276820563697138, 0.31975041370686097], 
reward next is 0.6802, 
noisyNet noise sample is [array([0.31867144], dtype=float32), -0.79422444]. 
=============================================
[2019-03-23 12:38:59,564] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4514491e-15 1.0000000e+00 6.4537619e-28 8.6717013e-22 3.3289216e-22], sum to 1.0000
[2019-03-23 12:38:59,570] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5017
[2019-03-23 12:38:59,578] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.36666666666667, 99.0, 1.0, 2.0, 0.3503102652807452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 389291.1396751665, 389291.1396751665, 117954.3122645001], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7708800.0000, 
sim time next is 7709400.0000, 
raw observation next is [17.45, 98.5, 1.0, 2.0, 0.3472925374207525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 386082.7523834651, 386082.7523834651, 117777.9969507661], 
processed observation next is [1.0, 0.21739130434782608, 0.4295454545454545, 0.985, 1.0, 1.0, 0.1841156717759406, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14299361199387597, 0.14299361199387597, 0.2872634071969905], 
reward next is 0.7127, 
noisyNet noise sample is [array([-1.0570006], dtype=float32), -2.127235]. 
=============================================
[2019-03-23 12:39:06,382] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:39:06,383] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:39:06,417] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run4
[2019-03-23 12:39:09,375] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0253383e-11 1.0000000e+00 1.6466806e-20 1.5599295e-16 4.5780519e-17], sum to 1.0000
[2019-03-23 12:39:09,383] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4823
[2019-03-23 12:39:09,387] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.51666666666667, 87.5, 1.0, 2.0, 0.8826518129760079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1006955.876459009, 1006955.876459009, 193130.7601018296], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7920600.0000, 
sim time next is 7921200.0000, 
raw observation next is [21.43333333333334, 88.0, 1.0, 2.0, 0.8733974489601788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 996346.8347847409, 996346.8347847413, 191512.474087127], 
processed observation next is [1.0, 0.6956521739130435, 0.6106060606060609, 0.88, 1.0, 1.0, 0.8417468112002235, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.36901734621657073, 0.36901734621657084, 0.46710359533445606], 
reward next is 0.5329, 
noisyNet noise sample is [array([-1.1446007], dtype=float32), 0.47063214]. 
=============================================
[2019-03-23 12:39:10,926] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.9156100e-14 1.0000000e+00 7.2805067e-27 1.9483781e-20 1.3582065e-20], sum to 1.0000
[2019-03-23 12:39:10,928] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3893
[2019-03-23 12:39:10,933] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.9, 96.0, 1.0, 2.0, 0.4271646093476037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 485677.0539028645, 485677.0539028642, 130138.5356890986], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7941600.0000, 
sim time next is 7942200.0000, 
raw observation next is [19.81666666666667, 93.5, 1.0, 2.0, 0.4208743368334096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 477694.0203219989, 477694.0203219989, 128850.5950965434], 
processed observation next is [1.0, 0.9565217391304348, 0.5371212121212122, 0.935, 1.0, 1.0, 0.2760929210417619, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17692371123036996, 0.17692371123036996, 0.31426974413791076], 
reward next is 0.6857, 
noisyNet noise sample is [array([-0.87526435], dtype=float32), 0.29305676]. 
=============================================
[2019-03-23 12:39:11,210] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:39:11,211] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:39:11,215] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run4
[2019-03-23 12:39:11,437] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:39:11,437] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:39:11,439] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run4
[2019-03-23 12:39:11,516] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:39:11,516] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:39:11,517] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run4
[2019-03-23 12:39:11,551] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:39:11,551] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:39:11,553] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run4
[2019-03-23 12:39:11,649] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:39:11,649] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:39:11,650] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run4
[2019-03-23 12:39:11,734] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:39:11,734] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:39:11,737] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run4
[2019-03-23 12:39:11,768] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:39:11,768] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:39:11,773] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run4
[2019-03-23 12:39:11,802] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:39:11,803] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:39:11,804] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:39:11,803] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:39:11,808] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run4
[2019-03-23 12:39:11,832] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run4
[2019-03-23 12:39:11,965] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:39:11,965] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:39:11,966] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run4
[2019-03-23 12:39:12,069] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:39:12,069] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:39:12,070] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run4
[2019-03-23 12:39:12,141] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:39:12,141] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:39:12,142] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run4
[2019-03-23 12:39:12,229] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:39:12,229] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:39:12,230] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run4
[2019-03-23 12:39:12,309] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:39:12,309] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:39:12,317] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:39:12,317] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:39:12,318] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run4
[2019-03-23 12:39:12,444] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run4
[2019-03-23 12:39:14,134] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.2856163e-18 1.0000000e+00 4.7242422e-31 3.9674365e-23 4.2506409e-25], sum to 1.0000
[2019-03-23 12:39:14,142] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7274
[2019-03-23 12:39:14,150] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 100.0, 1.0, 2.0, 0.3475641697517598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 384804.1644088887, 384804.1644088887, 117155.9469381458], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 21600.0000, 
sim time next is 22200.0000, 
raw observation next is [17.16666666666667, 100.0, 1.0, 2.0, 0.3462935757240004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 384036.6511989605, 384036.6511989605, 117314.6115286756], 
processed observation next is [1.0, 0.2608695652173913, 0.4166666666666669, 1.0, 1.0, 1.0, 0.18286696965500046, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14223579674035575, 0.14223579674035575, 0.28613319885042826], 
reward next is 0.7139, 
noisyNet noise sample is [array([1.4467964], dtype=float32), 0.68245953]. 
=============================================
[2019-03-23 12:39:17,897] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2131197e-15 1.0000000e+00 9.1873434e-30 1.4538607e-21 2.2294229e-22], sum to 1.0000
[2019-03-23 12:39:17,905] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1193
[2019-03-23 12:39:17,910] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 77.0, 1.0, 2.0, 0.228032793104376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 247590.0383623623, 247590.0383623626, 78701.35141530565], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 89400.0000, 
sim time next is 90000.0000, 
raw observation next is [16.0, 77.0, 1.0, 2.0, 0.2281749137546891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 247744.3872981316, 247744.3872981316, 78714.23637294014], 
processed observation next is [1.0, 0.043478260869565216, 0.36363636363636365, 0.77, 1.0, 1.0, 0.035218642193361356, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09175718048078949, 0.09175718048078949, 0.19198594237302474], 
reward next is 0.8080, 
noisyNet noise sample is [array([0.2572618], dtype=float32), -0.037809886]. 
=============================================
[2019-03-23 12:39:17,942] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[79.292046]
 [79.344826]
 [79.32284 ]
 [79.3027  ]
 [79.461105]], R is [[79.3529892 ]
 [79.36750793]
 [79.38182068]
 [79.39582825]
 [79.40961456]].
[2019-03-23 12:39:18,462] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.1655597e-14 1.0000000e+00 1.7782661e-28 6.2825082e-21 8.5038865e-20], sum to 1.0000
[2019-03-23 12:39:18,468] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5935
[2019-03-23 12:39:18,474] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.83333333333333, 77.83333333333334, 1.0, 2.0, 0.2024016621083762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 219754.3652706354, 219754.3652706357, 70701.9818560944], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 107400.0000, 
sim time next is 108000.0000, 
raw observation next is [14.0, 77.0, 1.0, 2.0, 0.2031448404251347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 220561.4421770214, 220561.4421770211, 70901.30757369564], 
processed observation next is [1.0, 0.2608695652173913, 0.2727272727272727, 0.77, 1.0, 1.0, 0.003931050531418359, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08168942302852644, 0.08168942302852633, 0.1729300184724284], 
reward next is 0.8271, 
noisyNet noise sample is [array([-0.68457353], dtype=float32), -0.7505089]. 
=============================================
[2019-03-23 12:39:18,493] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[73.579506]
 [73.575516]
 [73.586685]
 [73.62357 ]
 [73.64228 ]], R is [[73.66864014]
 [73.75950623]
 [73.8501358 ]
 [73.1116333 ]
 [73.20828247]].
[2019-03-23 12:39:18,630] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.7969516e-14 1.0000000e+00 4.3582366e-25 8.7884714e-19 1.5254773e-20], sum to 1.0000
[2019-03-23 12:39:18,639] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8945
[2019-03-23 12:39:18,644] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333334, 74.83333333333334, 1.0, 2.0, 0.2562709801893092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 278258.845760281, 278258.8457602813, 81811.19727544353], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 115800.0000, 
sim time next is 116400.0000, 
raw observation next is [16.66666666666667, 72.66666666666667, 1.0, 2.0, 0.3452893481345998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 374952.1879471433, 374952.1879471436, 91139.18800610153], 
processed observation next is [1.0, 0.34782608695652173, 0.39393939393939414, 0.7266666666666667, 1.0, 1.0, 0.18161168516824977, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13887118072116417, 0.1388711807211643, 0.22229070245390617], 
reward next is 0.7777, 
noisyNet noise sample is [array([-0.02173462], dtype=float32), 0.65186566]. 
=============================================
[2019-03-23 12:39:28,644] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4733207e-01 8.5266787e-01 1.9656879e-16 1.1191447e-11 7.0015384e-14], sum to 1.0000
[2019-03-23 12:39:28,656] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6653
[2019-03-23 12:39:28,659] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.16666666666667, 62.66666666666667, 1.0, 2.0, 0.2326506384253547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 252605.2354567029, 252605.2354567032, 86778.02785475046], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 299400.0000, 
sim time next is 300000.0000, 
raw observation next is [19.33333333333334, 61.33333333333334, 1.0, 2.0, 0.2334768623515518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 253502.5589337488, 253502.5589337485, 86580.37660090328], 
processed observation next is [0.0, 0.4782608695652174, 0.5151515151515155, 0.6133333333333334, 1.0, 1.0, 0.04184607793943973, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09388983664212919, 0.09388983664212908, 0.21117165024610557], 
reward next is 0.7888, 
noisyNet noise sample is [array([-0.41909593], dtype=float32), -0.19238529]. 
=============================================
[2019-03-23 12:39:28,679] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[62.592705]
 [62.471237]
 [62.965034]
 [62.98402 ]
 [65.38428 ]], R is [[62.94198608]
 [63.100914  ]
 [63.25735474]
 [63.41243744]
 [63.55121613]].
[2019-03-23 12:39:29,619] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 4.3559822e-11 2.0842808e-24 7.6021259e-21 8.2160790e-25], sum to 1.0000
[2019-03-23 12:39:29,629] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0322
[2019-03-23 12:39:29,634] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.66666666666667, 42.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4980528956622881, 6.9112, 6.9112, 77.32846344354104, 289692.1772247163, 289692.1772247163, 85369.42737694489], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 319200.0000, 
sim time next is 319800.0000, 
raw observation next is [21.33333333333333, 42.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4911587286429077, 6.911199999999999, 6.9112, 77.32846344354104, 285681.011230287, 285681.0112302873, 83415.76143054482], 
processed observation next is [0.0, 0.6956521739130435, 0.6060606060606059, 0.4266666666666667, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2730838980612968, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10580778193714334, 0.10580778193714345, 0.20345307665986542], 
reward next is 0.7965, 
noisyNet noise sample is [array([-1.1382834], dtype=float32), 1.9474331]. 
=============================================
[2019-03-23 12:39:31,119] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9857712e-01 1.4228669e-03 1.6765957e-21 3.1703964e-16 4.3951932e-19], sum to 1.0000
[2019-03-23 12:39:31,127] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3986
[2019-03-23 12:39:31,141] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.16666666666667, 43.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4623548707435623, 6.9112, 6.9112, 77.32846344354104, 268922.7011988107, 268922.7011988107, 75962.30785543112], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 327000.0000, 
sim time next is 327600.0000, 
raw observation next is [20.0, 43.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4585163852266581, 6.911199999999999, 6.9112, 77.32846344354104, 266689.4838761285, 266689.4838761288, 74988.26092844004], 
processed observation next is [0.0, 0.8260869565217391, 0.5454545454545454, 0.43, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2264519788952259, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09877388291708464, 0.09877388291708473, 0.18289819738643912], 
reward next is 0.8171, 
noisyNet noise sample is [array([-2.0012956], dtype=float32), -1.9047564]. 
=============================================
[2019-03-23 12:39:32,594] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.4758506e-04 9.9975246e-01 1.1838123e-22 3.5398091e-15 4.8281056e-18], sum to 1.0000
[2019-03-23 12:39:32,600] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3825
[2019-03-23 12:39:32,607] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 64.0, 1.0, 2.0, 0.5429727032973964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 597162.263723091, 597162.2637230906, 133191.0034076511], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 570000.0000, 
sim time next is 570600.0000, 
raw observation next is [21.0, 64.0, 1.0, 2.0, 0.5582022916123487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 613924.2630447859, 613924.2630447857, 134711.4952280321], 
processed observation next is [1.0, 0.6086956521739131, 0.5909090909090909, 0.64, 1.0, 1.0, 0.44775286451543583, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22737935668325404, 0.22737935668325396, 0.3285646225073953], 
reward next is 0.6714, 
noisyNet noise sample is [array([-0.9363013], dtype=float32), 1.35989]. 
=============================================
[2019-03-23 12:39:38,272] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.3235992e-05 9.9996674e-01 1.9440721e-22 9.5149196e-17 2.9311019e-17], sum to 1.0000
[2019-03-23 12:39:38,283] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5431
[2019-03-23 12:39:38,291] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.3176316365306361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 344907.8284712989, 344907.8284712986, 90525.33659108935], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 478800.0000, 
sim time next is 479400.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.3928897524680638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 426664.4884360067, 426664.4884360064, 98209.49341972473], 
processed observation next is [1.0, 0.5652173913043478, 0.2727272727272727, 1.0, 1.0, 1.0, 0.2411121905850797, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15802388460592842, 0.1580238846059283, 0.23953534980420668], 
reward next is 0.7605, 
noisyNet noise sample is [array([0.44990325], dtype=float32), -2.249875]. 
=============================================
[2019-03-23 12:39:40,287] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 12:39:40,289] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:39:40,289] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:39:40,291] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:39:40,291] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:39:40,293] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:39:40,294] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:39:40,295] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:39:40,294] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:39:40,298] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:39:40,296] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:39:40,314] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run27
[2019-03-23 12:39:40,314] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run27
[2019-03-23 12:39:40,357] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run27
[2019-03-23 12:39:40,382] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run27
[2019-03-23 12:39:40,409] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run27
[2019-03-23 12:39:46,858] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.13550022]
[2019-03-23 12:39:46,859] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.0, 68.0, 1.0, 2.0, 0.2371687597936241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 257512.1777016444, 257512.1777016441, 79227.39511311753]
[2019-03-23 12:39:46,860] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:39:46,866] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.3035932e-06 9.9999774e-01 3.1940784e-22 6.4263458e-16 7.9717606e-17], sampled 0.9963740303171781
[2019-03-23 12:39:49,361] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.13550022]
[2019-03-23 12:39:49,361] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [14.06666666666667, 79.66666666666666, 1.0, 2.0, 0.2023757872521031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 219716.8008118701, 219716.8008118698, 75982.56745735991]
[2019-03-23 12:39:49,362] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:39:49,366] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.8116979e-06 9.9999714e-01 5.5015493e-22 9.3997321e-16 1.1767388e-16], sampled 0.6414978187343537
[2019-03-23 12:40:05,842] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.13550022]
[2019-03-23 12:40:05,844] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.4, 90.0, 1.0, 2.0, 0.3474002826450625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 386142.3902403206, 386142.3902403206, 122079.9311255788]
[2019-03-23 12:40:05,844] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:40:05,848] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.3316393e-06 9.9999869e-01 4.4637325e-23 1.5940959e-16 1.8395718e-17], sampled 0.6897752342091861
[2019-03-23 12:40:06,232] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.13550022]
[2019-03-23 12:40:06,233] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 47.33333333333333, 1.0, 2.0, 0.390309504973079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 423861.2087826799, 423861.2087826799, 106195.281687341]
[2019-03-23 12:40:06,235] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:40:06,240] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.0866660e-06 9.9999785e-01 2.4000059e-22 5.2592159e-16 6.4832709e-17], sampled 0.8472895587801729
[2019-03-23 12:40:07,496] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.13550022]
[2019-03-23 12:40:07,497] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.24947867, 73.2696518, 1.0, 2.0, 0.5496086314234331, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 623501.3973724917, 623501.3973724917, 154697.9836946735]
[2019-03-23 12:40:07,498] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:40:07,500] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.4822760e-06 9.9999857e-01 7.2245706e-23 2.2503005e-16 2.6578906e-17], sampled 0.04757433415556389
[2019-03-23 12:40:18,161] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.13550022]
[2019-03-23 12:40:18,163] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.69152892, 78.60256127, 1.0, 2.0, 0.4989227068881397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 568199.1190198, 568199.1190197996, 147095.7368202988]
[2019-03-23 12:40:18,164] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:40:18,166] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.2378601e-06 9.9999881e-01 3.5678787e-23 1.3622446e-16 1.5624401e-17], sampled 0.6495512655824021
[2019-03-23 12:40:19,842] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.13550022]
[2019-03-23 12:40:19,844] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.0, 74.0, 1.0, 2.0, 0.7607972159652772, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9809260223003328, 6.911199999999999, 6.9112, 77.32846339354451, 1409037.121223915, 1409037.121223915, 305075.796157078]
[2019-03-23 12:40:19,845] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:40:19,848] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.5675880e-06 9.9999642e-01 1.9259281e-21 2.3159261e-15 3.1077750e-16], sampled 0.09083071189385372
[2019-03-23 12:40:19,849] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1409037.121223915 W.
[2019-03-23 12:40:21,873] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.13550022]
[2019-03-23 12:40:21,875] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.0, 68.66666666666666, 1.0, 2.0, 0.479640863627211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 547253.9215430331, 547253.9215430327, 142880.3391648878]
[2019-03-23 12:40:21,877] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:40:21,881] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.1661926e-06 9.9999881e-01 2.9878482e-23 1.2035761e-16 1.3744268e-17], sampled 0.6837357086269144
[2019-03-23 12:40:32,733] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.13550022]
[2019-03-23 12:40:32,734] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.85676632833333, 65.80440690833335, 1.0, 2.0, 0.3307111129181822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 363617.337732219, 363617.337732219, 119207.4669910179]
[2019-03-23 12:40:32,735] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:40:32,737] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.4366001e-06 9.9999857e-01 5.5732253e-23 1.8631109e-16 2.1608002e-17], sampled 0.7552229851035737
[2019-03-23 12:40:55,221] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.13550022]
[2019-03-23 12:40:55,222] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [9.600000000000001, 86.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 142239.955990045, 142239.955990045, 56840.37087747465]
[2019-03-23 12:40:55,222] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:40:55,225] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.3145311e-05 9.9990690e-01 1.3651136e-19 4.8503871e-14 4.9405628e-15], sampled 0.4293497951300749
[2019-03-23 12:41:19,260] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 12:41:19,422] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 12:41:19,434] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 12:41:19,548] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 12:41:19,565] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 12:41:20,578] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 650000, evaluation results [650000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 12:41:21,749] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.8999473e-06 9.9999511e-01 8.5553063e-23 6.3595293e-17 2.4800667e-16], sum to 1.0000
[2019-03-23 12:41:21,759] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6071
[2019-03-23 12:41:21,766] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.83333333333333, 95.0, 1.0, 2.0, 0.5535677672693956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 601263.0878089367, 601263.0878089364, 113347.1771813721], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 539400.0000, 
sim time next is 540000.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.5513825459595617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 598888.1258128324, 598888.1258128324, 113406.2039769552], 
processed observation next is [1.0, 0.2608695652173913, 0.2727272727272727, 0.94, 1.0, 1.0, 0.4392281824494521, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2218104169677157, 0.2218104169677157, 0.2766004975047688], 
reward next is 0.7234, 
noisyNet noise sample is [array([0.5197884], dtype=float32), -0.1936061]. 
=============================================
[2019-03-23 12:41:21,789] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[70.48112 ]
 [70.33643 ]
 [70.285866]
 [70.43874 ]
 [70.95133 ]], R is [[70.61419678]
 [70.63159943]
 [70.64896393]
 [70.66641235]
 [70.68720245]].
[2019-03-23 12:41:22,378] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.0869824e-05 9.9997914e-01 1.5632721e-19 8.6259267e-14 1.2106073e-15], sum to 1.0000
[2019-03-23 12:41:22,387] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8953
[2019-03-23 12:41:22,395] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.16666666666667, 99.00000000000001, 1.0, 2.0, 0.4446255314940366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482875.6306849541, 482875.6306849541, 98190.4716799634], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 537000.0000, 
sim time next is 537600.0000, 
raw observation next is [13.33333333333333, 98.0, 1.0, 2.0, 0.5527266882543359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 600348.9773298319, 600348.9773298319, 111743.0342634552], 
processed observation next is [1.0, 0.21739130434782608, 0.2424242424242423, 0.98, 1.0, 1.0, 0.44090836031791986, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22235147308512293, 0.22235147308512293, 0.27254398600842733], 
reward next is 0.7275, 
noisyNet noise sample is [array([-0.10497762], dtype=float32), -0.044512074]. 
=============================================
[2019-03-23 12:41:24,512] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.3619987e-08 1.0000000e+00 1.2989979e-22 2.2761856e-17 7.1638354e-19], sum to 1.0000
[2019-03-23 12:41:24,518] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6053
[2019-03-23 12:41:24,521] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 83.0, 1.0, 2.0, 0.3052154306531891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 332183.1740020692, 332183.1740020695, 111809.8501142641], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 601800.0000, 
sim time next is 602400.0000, 
raw observation next is [18.0, 83.0, 1.0, 2.0, 0.3046101367155888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 331520.6916012447, 331520.6916012444, 111767.4649504162], 
processed observation next is [1.0, 1.0, 0.45454545454545453, 0.83, 1.0, 1.0, 0.13076267089448596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12278544133379432, 0.12278544133379421, 0.2726035730497956], 
reward next is 0.7274, 
noisyNet noise sample is [array([0.3363766], dtype=float32), 0.01618266]. 
=============================================
[2019-03-23 12:41:42,902] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4239481e-08 1.0000000e+00 1.7004812e-21 6.6437956e-17 1.7693982e-17], sum to 1.0000
[2019-03-23 12:41:42,911] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3321
[2019-03-23 12:41:42,916] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4077568949989877, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 462231.1646850141, 462231.1646850143, 127184.529435196], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 949800.0000, 
sim time next is 950400.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4071803691327499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 461576.0187912537, 461576.0187912534, 127129.2421964145], 
processed observation next is [1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.25897546141593736, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17095408103379767, 0.17095408103379756, 0.3100713224302793], 
reward next is 0.6899, 
noisyNet noise sample is [array([1.0657694], dtype=float32), -1.0788815]. 
=============================================
[2019-03-23 12:41:44,748] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.6219900e-09 1.0000000e+00 2.3402663e-24 1.6283229e-19 1.8258366e-17], sum to 1.0000
[2019-03-23 12:41:44,760] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7878
[2019-03-23 12:41:44,773] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333334, 98.0, 1.0, 2.0, 0.3979195124491576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 447470.0345607231, 447470.0345607228, 124178.124609943], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 978000.0000, 
sim time next is 978600.0000, 
raw observation next is [18.16666666666666, 99.0, 1.0, 2.0, 0.397447656440337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 446652.7668385925, 446652.7668385925, 123993.5800890054], 
processed observation next is [1.0, 0.30434782608695654, 0.4621212121212119, 0.99, 1.0, 1.0, 0.24680957055042127, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16542695068096017, 0.16542695068096017, 0.3024233660707449], 
reward next is 0.6976, 
noisyNet noise sample is [array([0.30287406], dtype=float32), -0.08547506]. 
=============================================
[2019-03-23 12:41:48,908] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.2077070e-06 9.9999774e-01 8.6114499e-23 1.1508876e-18 2.3964596e-19], sum to 1.0000
[2019-03-23 12:41:48,914] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5519
[2019-03-23 12:41:48,917] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333334, 75.5, 1.0, 2.0, 0.4091800497393276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 444363.2641616008, 444363.2641616008, 105025.754548139], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1069800.0000, 
sim time next is 1070400.0000, 
raw observation next is [17.66666666666667, 74.0, 1.0, 2.0, 0.3974719264517249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 431642.7775009277, 431642.7775009274, 105228.7258692915], 
processed observation next is [1.0, 0.391304347826087, 0.4393939393939396, 0.74, 1.0, 1.0, 0.2468399080646561, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15986769537071396, 0.15986769537071385, 0.2566554289494915], 
reward next is 0.7433, 
noisyNet noise sample is [array([-0.45372406], dtype=float32), 0.77282894]. 
=============================================
[2019-03-23 12:41:50,998] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.05095016e-04 9.99894857e-01 2.96438025e-22 3.07304956e-16
 2.77700877e-17], sum to 1.0000
[2019-03-23 12:41:51,006] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1629
[2019-03-23 12:41:51,013] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.16666666666666, 82.16666666666667, 1.0, 2.0, 0.3122725512353015, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 340446.8553126894, 340446.8553126894, 112496.4826452149], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1122600.0000, 
sim time next is 1123200.0000, 
raw observation next is [18.0, 83.0, 1.0, 2.0, 0.3103835704567444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 337959.6061084419, 337959.6061084419, 112215.2781660227], 
processed observation next is [1.0, 0.0, 0.45454545454545453, 0.83, 1.0, 1.0, 0.1379794630709305, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1251702244846081, 0.1251702244846081, 0.2736958004049334], 
reward next is 0.7263, 
noisyNet noise sample is [array([0.13450979], dtype=float32), -0.025111416]. 
=============================================
[2019-03-23 12:41:56,150] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4496443e-06 9.9999857e-01 1.8574940e-20 1.4427519e-16 7.9114810e-17], sum to 1.0000
[2019-03-23 12:41:56,156] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0773
[2019-03-23 12:41:56,160] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.5217342743962263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593962.4831383928, 593962.4831383928, 145761.9843787778], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1200600.0000, 
sim time next is 1201200.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.522713080698724, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595076.9630608391, 595076.9630608391, 145882.0173891844], 
processed observation next is [1.0, 0.9130434782608695, 0.7272727272727273, 0.83, 1.0, 1.0, 0.403391350873405, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2203988752077182, 0.2203988752077182, 0.35580979851020583], 
reward next is 0.6442, 
noisyNet noise sample is [array([0.48669297], dtype=float32), -0.9465755]. 
=============================================
[2019-03-23 12:41:56,628] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2945414e-05 9.9998701e-01 1.8346700e-20 4.5147110e-16 1.6433045e-17], sum to 1.0000
[2019-03-23 12:41:56,640] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8207
[2019-03-23 12:41:56,645] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 89.83333333333333, 1.0, 2.0, 0.5095866048450346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 580689.2642840884, 580689.2642840884, 143803.9165157384], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1414200.0000, 
sim time next is 1414800.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5106320915119257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 581764.8880698587, 581764.8880698587, 144042.1791593184], 
processed observation next is [0.0, 0.391304347826087, 0.6818181818181818, 0.89, 1.0, 1.0, 0.38829011438990707, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2154684770629106, 0.2154684770629106, 0.35132238819345946], 
reward next is 0.6487, 
noisyNet noise sample is [array([-0.3819802], dtype=float32), -0.45306718]. 
=============================================
[2019-03-23 12:41:58,367] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.1656757e-04 9.9968350e-01 2.0767586e-15 3.1971255e-12 6.1929385e-12], sum to 1.0000
[2019-03-23 12:41:58,380] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5571
[2019-03-23 12:41:58,387] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1355361.470330955 W.
[2019-03-23 12:41:58,391] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 65.0, 1.0, 2.0, 0.3986206550182249, 1.0, 2.0, 0.3986206550182249, 1.0, 2.0, 0.807219003525321, 6.911199999999999, 6.9112, 77.3421103, 1355361.470330955, 1355361.470330955, 302458.9228970142], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1252200.0000, 
sim time next is 1252800.0000, 
raw observation next is [26.0, 65.0, 1.0, 2.0, 0.3979428572374711, 1.0, 2.0, 0.3979428572374711, 1.0, 2.0, 0.8058516585223493, 6.9112, 6.9112, 77.3421103, 1353096.961977008, 1353096.961977008, 302123.2234639348], 
processed observation next is [1.0, 0.5217391304347826, 0.8181818181818182, 0.65, 1.0, 1.0, 0.24742857154683884, 1.0, 1.0, 0.24742857154683884, 1.0, 1.0, 0.7226452264604991, 0.0, 0.0, 0.5085185399722538, 0.5011470229544475, 0.5011470229544475, 0.7368859108876459], 
reward next is 0.2631, 
noisyNet noise sample is [array([1.125731], dtype=float32), -0.70520407]. 
=============================================
[2019-03-23 12:42:03,267] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.9274659e-05 9.9998069e-01 6.6539830e-19 8.4104213e-13 2.6218167e-14], sum to 1.0000
[2019-03-23 12:42:03,275] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5447
[2019-03-23 12:42:03,278] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1170301.402271201 W.
[2019-03-23 12:42:03,285] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.0, 86.66666666666667, 1.0, 2.0, 0.5449336159748164, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9632494400860224, 6.922144537009022, 6.9112, 77.32843659483146, 1170301.402271201, 1166746.841739321, 261718.518112068], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1354800.0000, 
sim time next is 1355400.0000, 
raw observation next is [22.0, 88.5, 1.0, 2.0, 0.4850533605418945, 1.0, 1.0, 0.4850533605418945, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32845686687739, 1105889.498639561, 1105889.498639561, 225746.9907835448], 
processed observation next is [1.0, 0.6956521739130435, 0.6363636363636364, 0.885, 1.0, 1.0, 0.3563167006773681, 1.0, 0.5, 0.3563167006773681, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084287696795868, 0.4095887031998374, 0.4095887031998374, 0.5506024165452312], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.808762], dtype=float32), 2.1963925]. 
=============================================
[2019-03-23 12:42:04,097] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.0766982e-05 9.9997926e-01 1.3833207e-17 7.1863918e-15 8.4215412e-15], sum to 1.0000
[2019-03-23 12:42:04,104] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0142
[2019-03-23 12:42:04,111] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5039488317283254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 574721.646347001, 574721.6463470012, 142554.7978974083], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1370400.0000, 
sim time next is 1371000.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.506287070012806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 577389.3819990569, 577389.3819990573, 142830.9143137748], 
processed observation next is [1.0, 0.8695652173913043, 0.6363636363636364, 0.94, 1.0, 1.0, 0.3828588375160075, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21384791925890997, 0.21384791925891009, 0.3483680836921336], 
reward next is 0.6516, 
noisyNet noise sample is [array([0.7671426], dtype=float32), 1.0971956]. 
=============================================
[2019-03-23 12:42:04,127] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[54.359333]
 [54.32176 ]
 [54.383564]
 [55.06246 ]
 [55.233658]], R is [[54.43448639]
 [54.54244614]
 [54.64910507]
 [54.75478363]
 [54.8599968 ]].
[2019-03-23 12:42:04,984] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.0284763e-06 9.9999201e-01 4.8957071e-24 6.4007294e-20 1.2676273e-17], sum to 1.0000
[2019-03-23 12:42:04,990] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1154
[2019-03-23 12:42:04,996] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 84.66666666666667, 1.0, 2.0, 0.4656338014342433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 531204.357967501, 531204.357967501, 136361.7063904034], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1363200.0000, 
sim time next is 1363800.0000, 
raw observation next is [22.16666666666667, 86.33333333333334, 1.0, 2.0, 0.4678891034996849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 533813.967694544, 533813.9676945438, 136725.1077121886], 
processed observation next is [1.0, 0.782608695652174, 0.6439393939393941, 0.8633333333333334, 1.0, 1.0, 0.3348613793746061, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19770887692390518, 0.1977088769239051, 0.33347587246875265], 
reward next is 0.6665, 
noisyNet noise sample is [array([0.2854362], dtype=float32), -0.7250777]. 
=============================================
[2019-03-23 12:42:05,074] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6558234e-07 9.9999988e-01 1.4710849e-25 2.4901804e-19 8.7436324e-18], sum to 1.0000
[2019-03-23 12:42:05,081] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4137
[2019-03-23 12:42:05,087] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 88.0, 1.0, 2.0, 0.4709935921350806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 537392.160356571, 537392.160356571, 137206.1411322866], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1378800.0000, 
sim time next is 1379400.0000, 
raw observation next is [21.83333333333334, 90.0, 1.0, 2.0, 0.4722539056452588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 538856.4332507477, 538856.4332507477, 137487.4527660681], 
processed observation next is [1.0, 1.0, 0.628787878787879, 0.9, 1.0, 1.0, 0.34031738205657347, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1995764567595362, 0.1995764567595362, 0.3353352506489466], 
reward next is 0.6647, 
noisyNet noise sample is [array([1.1878593], dtype=float32), -1.2075284]. 
=============================================
[2019-03-23 12:42:09,004] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 12:42:09,005] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:42:09,005] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:42:09,006] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:42:09,006] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:42:09,007] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:42:09,007] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:42:09,008] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:42:09,008] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:42:09,009] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:42:09,009] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:42:09,031] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run28
[2019-03-23 12:42:09,031] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run28
[2019-03-23 12:42:09,081] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run28
[2019-03-23 12:42:09,081] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run28
[2019-03-23 12:42:09,108] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run28
[2019-03-23 12:43:45,995] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.14760524]
[2019-03-23 12:43:45,996] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.212341015, 66.885968595, 1.0, 2.0, 0.3616970235856238, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 400676.6375938295, 400676.6375938295, 122667.2789057073]
[2019-03-23 12:43:45,997] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:43:45,999] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.5884638e-05 9.9998415e-01 1.0191911e-20 6.0763927e-17 1.7232955e-15], sampled 0.17084038246946232
[2019-03-23 12:43:47,515] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 12:43:48,063] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 12:43:48,186] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 12:43:48,269] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 12:43:48,337] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 12:43:49,351] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 675000, evaluation results [675000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 12:43:49,557] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.3976667e-05 9.9996603e-01 1.7707940e-20 3.0505267e-16 3.3736614e-14], sum to 1.0000
[2019-03-23 12:43:49,561] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1614
[2019-03-23 12:43:49,564] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 91.5, 1.0, 2.0, 0.4879198634298686, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 556708.0896161257, 556708.0896161253, 140034.9013347213], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1441800.0000, 
sim time next is 1442400.0000, 
raw observation next is [21.66666666666667, 94.33333333333333, 1.0, 2.0, 0.4870670523919222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 555723.8185418395, 555723.8185418397, 139979.809622013], 
processed observation next is [0.0, 0.6956521739130435, 0.6212121212121214, 0.9433333333333332, 1.0, 1.0, 0.35883381548990273, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20582363649697757, 0.20582363649697769, 0.34141416980978784], 
reward next is 0.6586, 
noisyNet noise sample is [array([0.2001077], dtype=float32), 1.9120595]. 
=============================================
[2019-03-23 12:43:49,759] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.5253997e-05 9.9996471e-01 4.1302210e-21 7.0390294e-19 8.2363806e-16], sum to 1.0000
[2019-03-23 12:43:49,764] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4480
[2019-03-23 12:43:49,770] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 97.0, 1.0, 2.0, 0.47712883238344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 544440.3679564478, 544440.3679564478, 138197.7518135987], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1449000.0000, 
sim time next is 1449600.0000, 
raw observation next is [21.0, 96.0, 1.0, 2.0, 0.4724862141768345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 539107.2107068903, 539107.2107068903, 137425.6236727647], 
processed observation next is [0.0, 0.782608695652174, 0.5909090909090909, 0.96, 1.0, 1.0, 0.3406077677210431, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19966933729884828, 0.19966933729884828, 0.3351844479823529], 
reward next is 0.6648, 
noisyNet noise sample is [array([0.29461527], dtype=float32), 0.62699807]. 
=============================================
[2019-03-23 12:43:50,152] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.3363088e-05 9.9994659e-01 8.1184591e-20 6.9693114e-16 1.1874846e-14], sum to 1.0000
[2019-03-23 12:43:50,160] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2946
[2019-03-23 12:43:50,167] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4793960919468967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 546961.9143857162, 546961.914385716, 139127.3680182685], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1479600.0000, 
sim time next is 1480200.0000, 
raw observation next is [20.83333333333333, 100.0, 1.0, 2.0, 0.4764892117876702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 543696.9113737689, 543696.9113737689, 138536.3458521967], 
processed observation next is [0.0, 0.13043478260869565, 0.5833333333333331, 1.0, 1.0, 1.0, 0.3456115147345877, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20136922643472924, 0.20136922643472924, 0.33789352646877246], 
reward next is 0.6621, 
noisyNet noise sample is [array([-0.20857154], dtype=float32), -0.022997608]. 
=============================================
[2019-03-23 12:43:50,645] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3799116e-05 9.9998617e-01 3.5153935e-20 6.3475065e-15 3.2560702e-14], sum to 1.0000
[2019-03-23 12:43:50,648] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6906
[2019-03-23 12:43:50,656] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4796548861777623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 547257.3457211268, 547257.3457211268, 139156.5975824313], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1474800.0000, 
sim time next is 1475400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.480243953569103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 547929.7308278588, 547929.7308278588, 139223.4448062532], 
processed observation next is [0.0, 0.043478260869565216, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3503049419613787, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2029369373436514, 0.2029369373436514, 0.3395693775762273], 
reward next is 0.6604, 
noisyNet noise sample is [array([-0.08963383], dtype=float32), 2.0362976]. 
=============================================
[2019-03-23 12:43:56,956] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.2211954e-06 9.9999678e-01 1.4458331e-18 4.8926724e-15 5.9535108e-13], sum to 1.0000
[2019-03-23 12:43:56,965] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5261
[2019-03-23 12:43:56,970] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.83333333333334, 65.66666666666667, 1.0, 2.0, 0.3168424585629626, 1.0, 1.0, 0.3168424585629626, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32843417364293, 721389.6715933813, 721389.6715933813, 191640.240861943], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1617000.0000, 
sim time next is 1617600.0000, 
raw observation next is [25.66666666666667, 66.33333333333334, 1.0, 2.0, 0.4826169774399865, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846326235766, 550497.9341793393, 550497.9341793391, 139862.6961646907], 
processed observation next is [1.0, 0.7391304347826086, 0.8030303030303032, 0.6633333333333334, 1.0, 1.0, 0.3532712217999831, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.508428811729387, 0.20388812377012566, 0.20388812377012558, 0.3411285272309529], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4114897], dtype=float32), -1.201064]. 
=============================================
[2019-03-23 12:44:02,506] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.0966172e-05 9.9991906e-01 2.3953490e-18 4.2573472e-14 3.2686855e-12], sum to 1.0000
[2019-03-23 12:44:02,513] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1473
[2019-03-23 12:44:02,515] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 56.0, 1.0, 2.0, 0.499000025311241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 541960.75374106, 541960.7537410603, 108814.4768935334], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1702800.0000, 
sim time next is 1703400.0000, 
raw observation next is [18.83333333333334, 54.83333333333334, 1.0, 2.0, 0.3420887854002833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 371475.3462758393, 371475.3462758395, 91226.8767242701], 
processed observation next is [1.0, 0.7391304347826086, 0.4924242424242427, 0.5483333333333335, 1.0, 1.0, 0.1776109817503541, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13758346158364418, 0.13758346158364426, 0.22250457737626853], 
reward next is 0.7775, 
noisyNet noise sample is [array([0.6029258], dtype=float32), -1.1946963]. 
=============================================
[2019-03-23 12:44:03,038] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.1622302e-08 2.4718075e-14 2.1784781e-13 1.8486025e-14], sum to 1.0000
[2019-03-23 12:44:03,050] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7131
[2019-03-23 12:44:03,054] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [9.0, 71.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 149310.7694228525, 149310.7694228528, 53588.05701610231], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1733400.0000, 
sim time next is 1734000.0000, 
raw observation next is [9.0, 71.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 148761.7633045544, 148761.7633045544, 53490.33639574851], 
processed observation next is [1.0, 0.043478260869565216, 0.045454545454545456, 0.71, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.05509694937205718, 0.05509694937205718, 0.13046423511158173], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6204334], dtype=float32), 1.1007868]. 
=============================================
[2019-03-23 12:44:03,071] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[46.20757]
 [46.33619]
 [46.19248]
 [46.46623]
 [45.9678 ]], R is [[45.74646378]
 [45.28900146]
 [44.83611298]
 [44.38775253]
 [43.94387436]].
[2019-03-23 12:44:07,614] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 2.3630858e-11 8.7520628e-21 6.7967249e-19 3.3303509e-18], sum to 1.0000
[2019-03-23 12:44:07,620] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3488
[2019-03-23 12:44:07,625] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [10.66666666666667, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.732755450195765, 7.134952127084741, 6.9112, 77.3277008236881, 498967.9778030859, 426298.5801272205, 94881.75483678827], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1827600.0000, 
sim time next is 1828200.0000, 
raw observation next is [10.33333333333333, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7331932567035845, 7.13862605086929, 6.9112, 77.32771634897519, 500416.4672825509, 426553.851244201, 94739.92872141887], 
processed observation next is [1.0, 0.13043478260869565, 0.10606060606060592, 0.97, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6188475095765493, 0.022742605086928956, 0.0, 0.5084239008302499, 0.1853394323268707, 0.15798290786822258, 0.23107299688150942], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.552709], dtype=float32), -1.1210713]. 
=============================================
[2019-03-23 12:44:09,722] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 4.8372336e-16 1.4083094e-19 5.3656721e-18 1.5344469e-21], sum to 1.0000
[2019-03-23 12:44:09,727] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5206
[2019-03-23 12:44:09,736] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.16666666666667, 46.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7243484027263475, 7.064392224945103, 6.9112, 77.32788039756112, 471148.7106820088, 421395.3844787657, 115552.5718692629], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1861800.0000, 
sim time next is 1862400.0000, 
raw observation next is [22.33333333333334, 47.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7557913211158035, 7.328307445811592, 6.9112, 77.32739172884561, 575200.7003990967, 439734.6108068737, 120765.346707316], 
processed observation next is [1.0, 0.5652173913043478, 0.6515151515151518, 0.47333333333333344, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6511304587368621, 0.04171074458115918, 0.0, 0.5084217664773896, 0.2130372964441099, 0.16286467066921248, 0.29454962611540486], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.59252495], dtype=float32), 1.505922]. 
=============================================
[2019-03-23 12:44:14,320] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.5320995e-02 9.8467863e-01 1.0637223e-13 2.3999294e-10 3.2298848e-07], sum to 1.0000
[2019-03-23 12:44:14,329] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4025
[2019-03-23 12:44:14,334] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333333, 81.33333333333334, 1.0, 2.0, 0.472343197149763, 1.0, 2.0, 0.472343197149763, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1074390.099540717, 1074390.099540717, 224643.874343581], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1938000.0000, 
sim time next is 1938600.0000, 
raw observation next is [23.0, 83.0, 1.0, 2.0, 0.8901522292218673, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1015724.395440604, 1015724.395440604, 198912.2943723936], 
processed observation next is [1.0, 0.43478260869565216, 0.6818181818181818, 0.83, 1.0, 1.0, 0.8626902865273341, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.376194220533557, 0.376194220533557, 0.48515193749364294], 
reward next is 0.5148, 
noisyNet noise sample is [array([-2.2583869], dtype=float32), -0.49243984]. 
=============================================
[2019-03-23 12:44:14,595] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.8669138e-03 9.9713278e-01 8.5186710e-12 3.4099001e-09 2.1436067e-07], sum to 1.0000
[2019-03-23 12:44:14,602] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7776
[2019-03-23 12:44:14,611] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1225509.210005531 W.
[2019-03-23 12:44:14,615] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.66666666666667, 61.0, 1.0, 2.0, 0.5932024264975219, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9690980544289524, 6.9112, 6.9112, 77.32846344354104, 1225509.210005531, 1225509.210005531, 268871.8118308595], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1952400.0000, 
sim time next is 1953000.0000, 
raw observation next is [25.5, 61.0, 1.0, 2.0, 0.3626587682139888, 1.0, 1.0, 0.3626587682139888, 1.0, 2.0, 0.7336381338573219, 6.911199999999999, 6.9112, 77.3421103, 1241152.457991584, 1241152.457991585, 280254.6692519971], 
processed observation next is [1.0, 0.6086956521739131, 0.7954545454545454, 0.61, 1.0, 1.0, 0.20332346026748596, 1.0, 0.5, 0.20332346026748596, 1.0, 1.0, 0.6194830483676028, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4596860955524385, 0.45968609555243883, 0.6835479737853587], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5193715], dtype=float32), -0.5197022]. 
=============================================
[2019-03-23 12:44:14,626] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[43.805202]
 [44.022884]
 [43.344883]
 [43.875015]
 [43.11893 ]], R is [[43.43365097]
 [43.34352875]
 [43.20859909]
 [42.77651215]
 [42.34874725]].
[2019-03-23 12:44:15,807] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4755292e-03 9.9852449e-01 3.6570430e-12 5.5543179e-09 5.3735636e-08], sum to 1.0000
[2019-03-23 12:44:15,815] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9467
[2019-03-23 12:44:15,821] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 60.0, 1.0, 2.0, 0.3401680463439267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 375191.9480378009, 375191.9480378012, 116032.4629696134], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1973400.0000, 
sim time next is 1974000.0000, 
raw observation next is [22.0, 60.00000000000001, 1.0, 2.0, 0.3403009721520415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 375312.5582159061, 375312.5582159061, 116032.5736824219], 
processed observation next is [1.0, 0.8695652173913043, 0.6363636363636364, 0.6000000000000001, 1.0, 1.0, 0.1753762151900519, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13900465119107633, 0.13900465119107633, 0.28300627727419975], 
reward next is 0.7170, 
noisyNet noise sample is [array([1.0291946], dtype=float32), -1.2175443]. 
=============================================
[2019-03-23 12:44:15,841] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[39.13494 ]
 [39.276417]
 [39.88796 ]
 [38.922203]
 [37.918846]], R is [[40.23839188]
 [40.55300522]
 [40.86388779]
 [41.16976547]
 [41.47087479]].
[2019-03-23 12:44:18,225] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3375245e-05 9.9998665e-01 2.6899789e-17 8.4468809e-14 6.6746769e-12], sum to 1.0000
[2019-03-23 12:44:18,232] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4382
[2019-03-23 12:44:18,237] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 72.0, 1.0, 2.0, 0.23736251342592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 257722.6065076809, 257722.6065076809, 81463.80475235176], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2004000.0000, 
sim time next is 2004600.0000, 
raw observation next is [17.0, 72.0, 1.0, 2.0, 0.2367273186361458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 257032.7447809586, 257032.7447809589, 81392.60520600394], 
processed observation next is [0.0, 0.17391304347826086, 0.4090909090909091, 0.72, 1.0, 1.0, 0.04590914829518223, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09519731288183651, 0.09519731288183662, 0.19851854928293644], 
reward next is 0.8015, 
noisyNet noise sample is [array([-0.12744659], dtype=float32), -0.5278743]. 
=============================================
[2019-03-23 12:44:21,859] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.5999198e-06 9.9999738e-01 8.4207772e-19 1.3623564e-13 2.3500481e-12], sum to 1.0000
[2019-03-23 12:44:21,868] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9313
[2019-03-23 12:44:21,870] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 81.16666666666667, 1.0, 2.0, 0.2395534294921318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 260102.0874700418, 260102.0874700418, 82298.66045081841], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2077800.0000, 
sim time next is 2078400.0000, 
raw observation next is [16.0, 80.33333333333334, 1.0, 2.0, 0.2397347546810426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 260299.0192395611, 260299.0192395614, 81797.43346439686], 
processed observation next is [0.0, 0.043478260869565216, 0.36363636363636365, 0.8033333333333335, 1.0, 1.0, 0.04966844335130324, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09640704416280041, 0.09640704416280052, 0.19950593527901672], 
reward next is 0.8005, 
noisyNet noise sample is [array([0.7229444], dtype=float32), -0.13098778]. 
=============================================
[2019-03-23 12:44:37,908] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 12:44:37,911] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:44:37,913] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:44:37,915] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:44:37,914] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:44:37,916] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:44:37,915] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:44:37,916] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:44:37,920] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:44:37,922] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:44:37,923] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:44:37,938] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run29
[2019-03-23 12:44:37,962] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run29
[2019-03-23 12:44:37,963] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run29
[2019-03-23 12:44:38,019] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run29
[2019-03-23 12:44:38,045] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run29
[2019-03-23 12:44:39,485] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.16222034]
[2019-03-23 12:44:39,485] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.27707881166667, 79.490046105, 1.0, 2.0, 0.4037608416940494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 451715.7255340292, 451715.7255340292, 127932.7720582806]
[2019-03-23 12:44:39,486] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:44:39,491] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.2563552e-08 1.0000000e+00 3.1101723e-22 7.2857911e-18 2.5622897e-14], sampled 0.603159103896093
[2019-03-23 12:44:46,474] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.16222034]
[2019-03-23 12:44:46,476] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [13.01666666666667, 87.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 211978.9215670546, 211978.9215670546, 74445.78087695171]
[2019-03-23 12:44:46,477] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:44:46,480] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.2523545e-07 9.9999988e-01 1.4197114e-20 1.5439155e-16 2.8526305e-13], sampled 0.2399133658902003
[2019-03-23 12:44:49,737] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.16222034]
[2019-03-23 12:44:49,740] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [29.0, 60.66666666666667, 1.0, 2.0, 0.5883776255746244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 663993.3428710415, 663993.3428710415, 156652.3847923617]
[2019-03-23 12:44:49,742] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:44:49,748] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.1527493e-08 1.0000000e+00 6.1997258e-22 1.2659896e-17 3.9690138e-14], sampled 0.29486475474295315
[2019-03-23 12:45:17,203] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.16222034]
[2019-03-23 12:45:17,204] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 88.0, 1.0, 2.0, 0.4306204356474761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489912.9799970651, 489912.9799970651, 130759.8451974902]
[2019-03-23 12:45:17,204] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:45:17,209] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.0806072e-08 1.0000000e+00 1.0986128e-21 1.9991026e-17 5.6894180e-14], sampled 0.8366110646974946
[2019-03-23 12:45:28,980] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.16222034]
[2019-03-23 12:45:28,981] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.36486898, 55.899522475, 1.0, 2.0, 0.454158497255318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 515878.2776460824, 515878.2776460824, 136792.5509764739]
[2019-03-23 12:45:28,983] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:45:28,986] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.1739219e-08 1.0000000e+00 2.8920186e-22 6.8729643e-18 2.4465681e-14], sampled 0.9186890136313464
[2019-03-23 12:45:45,067] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.16222034]
[2019-03-23 12:45:45,069] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.78533500833333, 76.98477163833334, 1.0, 2.0, 0.3600057845798967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 399810.5759930148, 399810.5759930148, 122936.6647438469]
[2019-03-23 12:45:45,069] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:45:45,071] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.6495995e-08 1.0000000e+00 8.5417869e-22 1.6330522e-17 4.8433225e-14], sampled 0.1552440372634185
[2019-03-23 12:45:48,653] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.16222034]
[2019-03-23 12:45:48,655] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.85, 69.66666666666667, 1.0, 2.0, 0.3845452218290631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 431829.5089179567, 431829.508917957, 127026.2392157745]
[2019-03-23 12:45:48,655] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:45:48,658] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.1373642e-08 1.0000000e+00 6.1341859e-22 1.2529455e-17 3.9277897e-14], sampled 0.262008344188436
[2019-03-23 12:45:54,637] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.16222034]
[2019-03-23 12:45:54,638] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.08327652, 73.03287373, 1.0, 2.0, 0.3865272290307705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 436879.8228157621, 436879.8228157621, 128719.2719556384]
[2019-03-23 12:45:54,639] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:45:54,643] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.2737049e-08 1.0000000e+00 3.1571746e-22 7.3599570e-18 2.5773718e-14], sampled 0.6983841233821967
[2019-03-23 12:46:17,193] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 12:46:17,243] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 12:46:17,261] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 12:46:17,391] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 12:46:17,446] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 12:46:18,462] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 700000, evaluation results [700000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 12:46:29,865] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.6500961e-08 1.0000000e+00 1.2590518e-21 7.3692842e-18 4.7864333e-13], sum to 1.0000
[2019-03-23 12:46:29,871] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0568
[2019-03-23 12:46:29,875] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 47.0, 1.0, 2.0, 0.3458119661882273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 384911.9768175173, 384911.9768175173, 117862.3346858058], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2631600.0000, 
sim time next is 2632200.0000, 
raw observation next is [25.16666666666667, 46.16666666666667, 1.0, 2.0, 0.340944529215303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 379064.6791579946, 379064.6791579946, 117298.880895074], 
processed observation next is [0.0, 0.4782608695652174, 0.7803030303030305, 0.4616666666666667, 1.0, 1.0, 0.17618066151912873, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14039432561407206, 0.14039432561407206, 0.2860948314514], 
reward next is 0.7139, 
noisyNet noise sample is [array([-1.7816476], dtype=float32), -0.67785937]. 
=============================================
[2019-03-23 12:46:30,407] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.0854282e-08 1.0000000e+00 9.7307892e-23 7.1945357e-19 1.0052135e-14], sum to 1.0000
[2019-03-23 12:46:30,415] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4964
[2019-03-23 12:46:30,420] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 100.0, 1.0, 2.0, 0.2778725034030804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 301721.0397686819, 301721.0397686822, 95231.129414196], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2610000.0000, 
sim time next is 2610600.0000, 
raw observation next is [15.16666666666667, 100.0, 1.0, 2.0, 0.2774105151252769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 301219.245780929, 301219.245780929, 97368.71604198066], 
processed observation next is [0.0, 0.21739130434782608, 0.3257575757575759, 1.0, 1.0, 1.0, 0.09676314390659614, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1115626836225663, 0.1115626836225663, 0.23748467327312356], 
reward next is 0.7625, 
noisyNet noise sample is [array([0.10616872], dtype=float32), 0.28874722]. 
=============================================
[2019-03-23 12:46:31,648] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.8706403e-08 1.0000000e+00 3.9616048e-20 1.7687387e-15 1.4225627e-13], sum to 1.0000
[2019-03-23 12:46:31,655] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3591
[2019-03-23 12:46:31,658] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 49.0, 1.0, 2.0, 0.3753663728365512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 422320.3423818612, 422320.3423818612, 122314.8975680365], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2661000.0000, 
sim time next is 2661600.0000, 
raw observation next is [25.33333333333334, 50.0, 1.0, 2.0, 0.3723597566948149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 418454.5129125963, 418454.5129125963, 121809.8431233809], 
processed observation next is [0.0, 0.8260869565217391, 0.7878787878787882, 0.5, 1.0, 1.0, 0.21544969586851861, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15498315293059123, 0.15498315293059123, 0.2970971783497095], 
reward next is 0.7029, 
noisyNet noise sample is [array([-0.82072765], dtype=float32), 0.7049533]. 
=============================================
[2019-03-23 12:46:35,073] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.4214155e-08 1.0000000e+00 1.0145728e-18 6.6097005e-15 6.0673867e-13], sum to 1.0000
[2019-03-23 12:46:35,080] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9084
[2019-03-23 12:46:35,088] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.8, 95.0, 1.0, 2.0, 0.4025271629625695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 456707.5714443323, 456707.5714443323, 126983.2167137312], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2707200.0000, 
sim time next is 2707800.0000, 
raw observation next is [20.08333333333333, 93.5, 1.0, 2.0, 0.41090534374979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 466752.4943498238, 466752.4943498241, 128185.2223373235], 
processed observation next is [0.0, 0.34782608695652173, 0.549242424242424, 0.935, 1.0, 1.0, 0.26363167968723744, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17287129420363845, 0.17287129420363856, 0.3126468837495695], 
reward next is 0.6874, 
noisyNet noise sample is [array([-1.1865543], dtype=float32), -0.5007221]. 
=============================================
[2019-03-23 12:46:36,541] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.1658826e-10 1.0000000e+00 1.6053146e-23 2.3455813e-19 2.6264080e-17], sum to 1.0000
[2019-03-23 12:46:36,550] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8380
[2019-03-23 12:46:36,554] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 78.0, 1.0, 2.0, 0.4059084020733732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 459561.8725940645, 459561.8725940645, 126629.8482746088], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2763000.0000, 
sim time next is 2763600.0000, 
raw observation next is [21.33333333333334, 78.0, 1.0, 2.0, 0.4002925110324639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 452603.0716433539, 452603.0716433539, 125735.3220656542], 
processed observation next is [0.0, 1.0, 0.6060606060606063, 0.78, 1.0, 1.0, 0.2503656387905798, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16763076727531626, 0.16763076727531626, 0.30667151723330294], 
reward next is 0.6933, 
noisyNet noise sample is [array([-0.3959152], dtype=float32), -1.4785304]. 
=============================================
[2019-03-23 12:46:45,758] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.0820293e-05 9.9990880e-01 7.7996583e-14 3.6678372e-07 2.4099554e-08], sum to 1.0000
[2019-03-23 12:46:45,769] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0916
[2019-03-23 12:46:45,780] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 93.16666666666667, 1.0, 2.0, 0.5116908822722281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 583448.1753798381, 583448.1753798383, 143631.9034245352], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2926200.0000, 
sim time next is 2926800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5091251489413343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 580608.5132963404, 580608.5132963407, 143197.1151320841], 
processed observation next is [1.0, 0.9130434782608695, 0.6363636363636364, 0.94, 1.0, 1.0, 0.38640643617666787, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2150401901097557, 0.2150401901097558, 0.3492612564197173], 
reward next is 0.6507, 
noisyNet noise sample is [array([1.8070886], dtype=float32), 0.7309294]. 
=============================================
[2019-03-23 12:46:47,563] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.5688436e-05 9.9997318e-01 8.7760135e-14 8.9630072e-07 1.8532955e-07], sum to 1.0000
[2019-03-23 12:46:47,568] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4784
[2019-03-23 12:46:47,581] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1201499.890262823 W.
[2019-03-23 12:46:47,592] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 70.0, 1.0, 2.0, 0.5756323454102041, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9783397014392315, 6.911199999999999, 6.9112, 77.32846344354104, 1201499.890262823, 1201499.890262824, 275081.4292703581], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2973600.0000, 
sim time next is 2974200.0000, 
raw observation next is [26.16666666666667, 68.66666666666667, 1.0, 2.0, 0.5966889024932026, 1.0, 1.0, 0.5966889024932026, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 79.22590883987648, 1349467.228628422, 1349467.228628422, 260356.199107385], 
processed observation next is [1.0, 0.43478260869565216, 0.825757575757576, 0.6866666666666668, 1.0, 1.0, 0.49586112811650324, 1.0, 0.5, 0.49586112811650324, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5209043732445049, 0.4998026772697859, 0.4998026772697859, 0.6350151197741097], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.63977534], dtype=float32), -0.21199724]. 
=============================================
[2019-03-23 12:46:55,029] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9998879e-01 9.9420618e-07 8.0693324e-10 2.5556614e-07 9.9936278e-06], sum to 1.0000
[2019-03-23 12:46:55,035] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2536
[2019-03-23 12:46:55,039] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 638552.0037951319 W.
[2019-03-23 12:46:55,045] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 74.0, 1.0, 2.0, 0.562893253075237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 638552.0037951319, 638552.0037951319, 152154.1186096586], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3092400.0000, 
sim time next is 3093000.0000, 
raw observation next is [25.66666666666667, 75.5, 1.0, 2.0, 0.2810042733426028, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5691609688299856, 6.9112, 6.9112, 77.32846344354104, 637300.1421129612, 637300.1421129612, 189295.4187510045], 
processed observation next is [1.0, 0.8260869565217391, 0.8030303030303032, 0.755, 1.0, 1.0, 0.1012553416782535, 0.0, 1.0, -0.25, 1.0, 0.5, 0.38451566975712226, 0.0, 0.0, 0.5084288129206541, 0.23603708967146708, 0.23603708967146708, 0.4616961432951329], 
reward next is 0.5383, 
noisyNet noise sample is [array([-2.040441], dtype=float32), -0.5460325]. 
=============================================
[2019-03-23 12:46:55,059] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[50.72935 ]
 [51.293602]
 [51.343086]
 [50.724487]
 [50.82002 ]], R is [[50.86817551]
 [50.98838425]
 [51.1071701 ]
 [51.13188171]
 [50.62056351]].
[2019-03-23 12:46:57,800] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9998653e-01 3.0391648e-13 1.3339522e-05 1.3887387e-07 4.6894009e-08], sum to 1.0000
[2019-03-23 12:46:57,807] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9556
[2019-03-23 12:46:57,817] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 557577.5299752749 W.
[2019-03-23 12:46:57,826] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 73.0, 1.0, 2.0, 0.2449151617812166, 0.0, 2.0, 0.0, 1.0, 1.0, 0.4895717822304401, 6.9112, 6.9112, 77.32846344354104, 557577.5299752749, 557577.5299752749, 172642.0931277794], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3139200.0000, 
sim time next is 3139800.0000, 
raw observation next is [23.0, 73.0, 1.0, 2.0, 0.2729957899308801, 1.0, 1.0, 0.2729957899308801, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 622456.476741518, 622456.4767415177, 178633.648942528], 
processed observation next is [1.0, 0.34782608695652173, 0.6818181818181818, 0.73, 1.0, 1.0, 0.09124473741360009, 1.0, 0.5, 0.09124473741360009, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23053943583019185, 0.23053943583019174, 0.4356918266890927], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4774966], dtype=float32), -1.5179875]. 
=============================================
[2019-03-23 12:47:07,348] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 12:47:07,349] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:47:07,350] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:47:07,350] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:47:07,351] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:47:07,352] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:47:07,353] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:47:07,354] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:47:07,356] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:47:07,354] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:47:07,361] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:47:07,367] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run30
[2019-03-23 12:47:07,392] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run30
[2019-03-23 12:47:07,417] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run30
[2019-03-23 12:47:07,419] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run30
[2019-03-23 12:47:07,481] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run30
[2019-03-23 12:47:12,059] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.17131026]
[2019-03-23 12:47:12,061] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [13.62479893333333, 91.08746851666668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.333201747874334, 6.911199999999999, 6.9112, 95.55338769695034, 193780.1427746791, 193780.1427746795, 68946.8047285677]
[2019-03-23 12:47:12,064] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:47:12,069] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 4.7004955e-16 8.5733211e-22 4.2657769e-19 5.6944270e-20], sampled 0.2829765338743456
[2019-03-23 12:47:30,192] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.17131026]
[2019-03-23 12:47:30,194] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.7, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5438697989608832, 6.911200000000001, 6.9112, 95.55338769695034, 316330.5973279922, 316330.5973279919, 102289.6658975733]
[2019-03-23 12:47:30,195] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:47:30,197] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0000000e+00 1.2155563e-15 2.2622186e-21 1.0592269e-18 1.5274928e-19], sampled 0.8360031914086664
[2019-03-23 12:47:38,444] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.17131026]
[2019-03-23 12:47:38,445] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [13.21666666666667, 80.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5313107219149156, 6.9112, 6.9112, 70.0369243585436, 309052.9425337378, 309052.9425337378, 70707.72950379153]
[2019-03-23 12:47:38,446] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:47:38,450] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0000000e+00 8.5881756e-16 3.2472595e-21 1.2299675e-18 1.6169151e-19], sampled 0.8893639388896782
[2019-03-23 12:47:54,794] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.17131026]
[2019-03-23 12:47:54,794] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.5, 66.0, 1.0, 2.0, 0.9943398421134636, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9824899323762317, 6.911199999999999, 6.9112, 77.32846344353698, 1671014.567200342, 1671014.567200342, 348953.405989475]
[2019-03-23 12:47:54,795] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:47:54,797] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 4.5794233e-13 1.9957119e-17 2.4218900e-15 4.3744797e-16], sampled 0.6988364618251173
[2019-03-23 12:47:54,799] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 1671014.567200342 W.
[2019-03-23 12:48:13,297] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.17131026]
[2019-03-23 12:48:13,298] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.04776507333333, 91.96272271333333, 1.0, 1.0, 0.4614648593250752, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 95.55316219780971, 525764.0208500554, 525764.0208500554, 139086.2268643715]
[2019-03-23 12:48:13,299] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:48:13,303] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 3.0277956e-13 9.3857341e-19 2.8006549e-16 6.2485812e-17], sampled 0.09108613436548962
[2019-03-23 12:48:16,003] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.17131026]
[2019-03-23 12:48:16,004] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.17418775, 75.36256751666667, 1.0, 2.0, 0.4557056655755933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.5533869480147, 519446.0092884016, 519446.0092884013, 138824.8816845513]
[2019-03-23 12:48:16,005] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:48:16,007] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0000000e+00 1.9811459e-12 1.0908226e-17 2.4608175e-15 6.1581191e-16], sampled 0.47557957352508584
[2019-03-23 12:48:17,415] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.17131026]
[2019-03-23 12:48:17,416] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.326917525, 95.76561533333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.709939642943934, 7.12586906855547, 6.9112, 95.55250200918482, 495129.1891038993, 408978.0893651827, 130707.119121335]
[2019-03-23 12:48:17,418] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:48:17,420] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.000000e+00 3.972312e-16 2.091101e-21 7.394342e-19 8.821686e-20], sampled 0.9117719717348138
[2019-03-23 12:48:27,434] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.17131026]
[2019-03-23 12:48:27,435] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.72707523333333, 62.12036157999999, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7239267000557966, 7.21348551718896, 6.9112, 95.55239902131625, 536140.900100642, 414827.6534020631, 133791.3758409797]
[2019-03-23 12:48:27,435] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:48:27,436] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 8.9335397e-13 7.2301136e-18 1.4730693e-15 3.2834406e-16], sampled 0.6462981444351485
[2019-03-23 12:48:33,884] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.17131026]
[2019-03-23 12:48:33,885] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [27.18929236166667, 62.11033158833333, 1.0, 2.0, 0.7236966826905463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 824474.4887618363, 824474.4887618363, 177402.4208635215]
[2019-03-23 12:48:33,885] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:48:33,888] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 1.6108383e-12 3.3434637e-17 4.9220788e-15 1.0708522e-15], sampled 0.25067238948213844
[2019-03-23 12:48:33,888] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 824474.4887618363 W.
[2019-03-23 12:48:46,430] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6481.6076 1678885180.2952 3057.0000
[2019-03-23 12:48:46,510] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6862.2842 1793014293.7888 2409.0000
[2019-03-23 12:48:46,544] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6553.1725 1698634175.0084 2957.0000
[2019-03-23 12:48:46,553] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6328.7217 1723294598.4314 3425.0000
[2019-03-23 12:48:46,846] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6294.9961 1685630448.6673 3228.0000
[2019-03-23 12:48:47,861] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 725000, evaluation results [725000.0, 6862.284208925443, 1793014293.78876, 2409.0, 6481.607577760913, 1678885180.2951708, 3057.0, 6294.9960618483565, 1685630448.6673346, 3228.0, 6328.721692698646, 1723294598.4313502, 3425.0, 6553.172466661831, 1698634175.0084193, 2957.0]
[2019-03-23 12:48:50,867] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.3475449e-34 5.2252793e-13 3.6848402e-20 1.0363649e-18], sum to 1.0000
[2019-03-23 12:48:50,876] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6384
[2019-03-23 12:48:50,880] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.5, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5971615659683656, 6.911199999999999, 6.9112, 77.32846344354104, 346719.2564076243, 346719.2564076246, 113742.6640483598], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3389400.0000, 
sim time next is 3390000.0000, 
raw observation next is [16.66666666666666, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6065518792082433, 6.911199999999999, 6.9112, 77.32846344354104, 351875.8661059606, 351875.8661059609, 114740.3826564904], 
processed observation next is [1.0, 0.21739130434782608, 0.39393939393939365, 1.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4379312560117761, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1303243948540595, 0.1303243948540596, 0.27985459184509853], 
reward next is 0.7201, 
noisyNet noise sample is [array([0.3878684], dtype=float32), 0.77737683]. 
=============================================
[2019-03-23 12:48:50,902] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[77.72622 ]
 [77.765656]
 [77.83781 ]
 [77.8259  ]
 [77.93806 ]], R is [[77.71222687]
 [77.65768433]
 [77.60574341]
 [77.55477142]
 [77.50722504]].
[2019-03-23 12:48:55,335] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9985373e-01 9.9046871e-10 1.3950192e-04 5.5362666e-06 1.3591641e-06], sum to 1.0000
[2019-03-23 12:48:55,341] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9493
[2019-03-23 12:48:55,345] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 635353.8919032539 W.
[2019-03-23 12:48:55,348] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.2784959986491321, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5629395478522948, 6.9112, 6.9112, 77.32846344354104, 635353.8919032539, 635353.8919032539, 185266.4113749586], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3471600.0000, 
sim time next is 3472200.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.2719305448986837, 0.0, 2.0, 0.0, 1.0, 2.0, 0.549647487656658, 6.911199999999999, 6.9112, 77.32846344354104, 620376.8847618477, 620376.884761848, 183563.5036966193], 
processed observation next is [1.0, 0.17391304347826086, 0.5909090909090909, 1.0, 1.0, 1.0, 0.08991318112335459, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3566392680809401, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2297692165784621, 0.22976921657846222, 0.4477158626746812], 
reward next is 0.5523, 
noisyNet noise sample is [array([-0.4050027], dtype=float32), 2.3743699]. 
=============================================
[2019-03-23 12:48:58,336] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9977142e-01 2.6978664e-10 2.2452418e-04 3.4494985e-06 5.6857078e-07], sum to 1.0000
[2019-03-23 12:48:58,346] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2893
[2019-03-23 12:48:58,351] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 628704.0875426937 W.
[2019-03-23 12:48:58,355] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.66666666666667, 75.33333333333334, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 1.0, 0.3752861891418471, 6.9112, 6.9112, 77.3421103, 628704.0875426937, 628704.0875426937, 223954.38541663], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3529200.0000, 
sim time next is 3529800.0000, 
raw observation next is [25.5, 76.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3747730793503187, 6.9112, 6.9112, 77.3421103, 627597.1225305583, 627597.1225305583, 224007.3067360515], 
processed observation next is [1.0, 0.8695652173913043, 0.7954545454545454, 0.76, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.10681868478616963, 0.0, 0.0, 0.5085185399722538, 0.23244337871502158, 0.23244337871502158, 0.5463592847220768], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8951163], dtype=float32), 0.3932946]. 
=============================================
[2019-03-23 12:49:07,297] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2313995e-03 7.9928587e-15 9.9876863e-01 7.9007037e-11 6.9718622e-09], sum to 1.0000
[2019-03-23 12:49:07,303] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1256
[2019-03-23 12:49:07,309] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.33333333333333, 76.66666666666666, 1.0, 2.0, 0.2558498724777997, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5176181779968709, 6.911200000000001, 6.9112, 77.32846344354104, 583319.5378653273, 583319.5378653271, 180285.075009545], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3703800.0000, 
sim time next is 3704400.0000, 
raw observation next is [24.0, 78.0, 1.0, 2.0, 0.2529041634632831, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5114394958649887, 6.9112, 6.9112, 77.32846344354104, 576791.113064393, 576791.113064393, 179255.9798354543], 
processed observation next is [1.0, 0.9130434782608695, 0.7272727272727273, 0.78, 1.0, 1.0, 0.06613020432910385, 0.0, 1.0, -0.25, 1.0, 1.0, 0.30205642266426963, 0.0, 0.0, 0.5084288129206541, 0.21362633817199742, 0.21362633817199742, 0.4372097069157422], 
reward next is 0.5628, 
noisyNet noise sample is [array([-0.09295214], dtype=float32), -0.174509]. 
=============================================
[2019-03-23 12:49:09,554] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9996185e-01 3.0948568e-15 3.8102669e-05 8.6571403e-11 4.3483923e-12], sum to 1.0000
[2019-03-23 12:49:09,560] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4283
[2019-03-23 12:49:09,566] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1075884.974529258 W.
[2019-03-23 12:49:09,569] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.314135507443291, 1.0, 2.0, 0.314135507443291, 1.0, 2.0, 0.6328582480545596, 6.911199999999999, 6.9112, 77.3421103, 1075884.974529258, 1075884.974529258, 257051.5931968512], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3767400.0000, 
sim time next is 3768000.0000, 
raw observation next is [22.33333333333333, 76.33333333333334, 1.0, 2.0, 0.4790800353171986, 1.0, 2.0, 0.4790800353171986, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354103, 1093870.782028757, 1093870.782028757, 219934.8662709508], 
processed observation next is [1.0, 0.6086956521739131, 0.6515151515151513, 0.7633333333333334, 1.0, 1.0, 0.34885004414649823, 1.0, 1.0, 0.34885004414649823, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.508428812920654, 0.40513732667731744, 0.40513732667731744, 0.5364265030998799], 
reward next is 0.4636, 
noisyNet noise sample is [array([0.5594488], dtype=float32), -1.4193583]. 
=============================================
[2019-03-23 12:49:09,583] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[26.654013]
 [25.901152]
 [26.334532]
 [26.518488]
 [26.355436]], R is [[26.9209404 ]
 [27.02477646]
 [26.75452805]
 [26.48698235]
 [26.71354103]].
[2019-03-23 12:49:14,580] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 3.6674069e-10 1.2523373e-08 5.1002625e-14 2.5113867e-12], sum to 1.0000
[2019-03-23 12:49:14,588] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9124
[2019-03-23 12:49:14,594] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.0, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5528054618006023, 6.9112, 6.9112, 77.32846344354104, 321549.4683474014, 321549.4683474014, 107799.6746601076], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3845400.0000, 
sim time next is 3846000.0000, 
raw observation next is [19.0, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5531707987132589, 6.9112, 6.9112, 77.32846344354104, 321762.0671878436, 321762.0671878436, 107825.7489330681], 
processed observation next is [0.0, 0.5217391304347826, 0.5, 0.73, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3616725695903699, 0.0, 0.0, 0.5084288129206541, 0.11917113599549764, 0.11917113599549764, 0.2629896315440685], 
reward next is 0.7370, 
noisyNet noise sample is [array([-0.6397483], dtype=float32), 0.94156814]. 
=============================================
[2019-03-23 12:49:14,614] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[76.786255]
 [76.739334]
 [76.643394]
 [76.5378  ]
 [76.4187  ]], R is [[76.79371643]
 [76.76285553]
 [76.73221588]
 [76.70169067]
 [76.67133331]].
[2019-03-23 12:49:16,482] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9997067e-01 2.8041002e-05 1.3596510e-06 5.2392424e-11 2.4207167e-10], sum to 1.0000
[2019-03-23 12:49:16,488] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8242
[2019-03-23 12:49:16,492] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.83333333333334, 58.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5898189463985463, 6.911200000000001, 6.9112, 77.32846344354104, 342466.2747032584, 342466.2747032581, 113139.9906744022], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3870600.0000, 
sim time next is 3871200.0000, 
raw observation next is [21.66666666666667, 59.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5894034803363395, 6.9112, 6.9112, 77.32846344354104, 342187.6271412441, 342187.6271412441, 113135.0860502664], 
processed observation next is [0.0, 0.8260869565217391, 0.6212121212121214, 0.5933333333333334, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4134335433376279, 0.0, 0.0, 0.5084288129206541, 0.12673615820046077, 0.12673615820046077, 0.27593923426894246], 
reward next is 0.7241, 
noisyNet noise sample is [array([1.5263859], dtype=float32), 0.6497138]. 
=============================================
[2019-03-23 12:49:31,165] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.9997377e-01 8.3752075e-06 9.6949561e-06 1.0389962e-06 7.1661684e-06], sum to 1.0000
[2019-03-23 12:49:31,172] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8829
[2019-03-23 12:49:31,178] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6648950778964037, 6.911199999999999, 6.9112, 77.32846344354104, 384745.598687908, 384745.5986879083, 120625.2172736949], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4164000.0000, 
sim time next is 4164600.0000, 
raw observation next is [17.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6530529998381993, 6.9112, 6.9112, 77.32846344354104, 377893.0332581222, 377893.0332581222, 119521.3284149983], 
processed observation next is [1.0, 0.17391304347826086, 0.4090909090909091, 1.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5043614283402847, 0.0, 0.0, 0.5084288129206541, 0.1399603826881934, 0.1399603826881934, 0.2915154351585324], 
reward next is 0.7085, 
noisyNet noise sample is [array([-0.5906824], dtype=float32), 0.6548226]. 
=============================================
[2019-03-23 12:49:34,541] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 8.7909730e-22 3.8203418e-22 1.5644529e-23 2.2161992e-26], sum to 1.0000
[2019-03-23 12:49:34,543] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3208
[2019-03-23 12:49:34,547] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.83333333333334, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7291092337916207, 7.093508665976273, 6.9112, 77.32808070122982, 482628.1917607186, 423418.3589731021, 125867.0818189136], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4241400.0000, 
sim time next is 4242000.0000, 
raw observation next is [16.66666666666667, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7178108485784083, 7.000300915387706, 6.9112, 77.32801622915032, 445879.7134575223, 416941.725926765, 124639.4602878005], 
processed observation next is [1.0, 0.08695652173913043, 0.39393939393939414, 0.96, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5968726408262975, 0.008910091538770626, 0.0, 0.5084258725197762, 0.16514063461389714, 0.1544228614543574, 0.3039986836287817], 
reward next is 0.2505, 
noisyNet noise sample is [array([-0.99054265], dtype=float32), -1.1716325]. 
=============================================
[2019-03-23 12:49:34,585] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[80.59365 ]
 [80.177666]
 [79.463585]
 [79.00501 ]
 [77.90153 ]], R is [[80.83338928]
 [80.02505493]
 [79.94577789]
 [79.86721802]
 [79.78930664]].
[2019-03-23 12:49:36,605] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 12:49:36,606] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:49:36,607] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:49:36,606] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:49:36,608] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:49:36,608] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:49:36,611] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:49:36,612] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:49:36,610] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:49:36,614] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:49:36,616] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:49:36,631] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run31
[2019-03-23 12:49:36,631] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run31
[2019-03-23 12:49:36,680] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run31
[2019-03-23 12:49:36,681] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run31
[2019-03-23 12:49:36,742] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run31
[2019-03-23 12:50:05,006] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.17967369]
[2019-03-23 12:50:05,007] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.89618827, 49.10762137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5453285632530094, 6.9112, 6.9112, 95.55338769695034, 317179.281234674, 317179.281234674, 96495.11976527162]
[2019-03-23 12:50:05,009] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:50:05,013] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0000000e+00 1.8654320e-16 3.7194072e-15 2.4916169e-18 4.1031402e-19], sampled 0.19703094317277592
[2019-03-23 12:50:23,843] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.17967369]
[2019-03-23 12:50:23,844] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 100.0, 1.0, 2.0, 0.5092313253943408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 581015.4342845341, 581015.4342845341, 142585.7481271915]
[2019-03-23 12:50:23,847] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:50:23,850] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 2.2666992e-12 2.8604577e-11 1.2750554e-13 3.1219114e-14], sampled 0.13085769938895475
[2019-03-23 12:50:23,853] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 581015.4342845341 W.
[2019-03-23 12:50:26,245] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.17967369]
[2019-03-23 12:50:26,246] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.23089610333333, 98.2136129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.694097037502958, 7.006798424958838, 6.9112, 95.55305574701045, 439394.0845024303, 401028.2536588738, 128200.4729133232]
[2019-03-23 12:50:26,247] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:50:26,250] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 9.5803363e-14 1.1664852e-12 2.8096665e-15 6.1559115e-16], sampled 0.424957357569559
[2019-03-23 12:50:34,029] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.17967369]
[2019-03-23 12:50:34,030] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.3, 55.0, 1.0, 2.0, 0.5111470702778474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 582680.2327900619, 582680.2327900619, 147981.6713490112]
[2019-03-23 12:50:34,031] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:50:34,033] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 9.3198485e-13 1.1820585e-11 4.4422368e-14 1.0532176e-14], sampled 0.7970143343132278
[2019-03-23 12:50:34,035] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 582680.2327900619 W.
[2019-03-23 12:50:42,950] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.17967369]
[2019-03-23 12:50:42,951] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.16507070166666, 98.78245654666667, 1.0, 1.0, 0.5138240715599453, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 95.5530621910765, 586273.3568169464, 586273.3568169461, 146935.2082404371]
[2019-03-23 12:50:42,952] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:50:42,954] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0000000e+00 5.2719530e-12 5.9951391e-11 3.1957458e-13 8.1650717e-14], sampled 0.6741510166146865
[2019-03-23 12:50:42,955] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 586273.3568169464 W.
[2019-03-23 12:50:52,464] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.17967369]
[2019-03-23 12:50:52,466] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.60284808333333, 61.28148883333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3905448611350946, 6.911199999999998, 6.9112, 95.55338769695034, 227135.4745118756, 227135.4745118763, 71328.1763280076]
[2019-03-23 12:50:52,469] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:50:52,473] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 7.7158836e-16 1.3658249e-14 1.2238791e-17 2.1520251e-18], sampled 0.10988414317488826
[2019-03-23 12:51:13,140] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.17967369]
[2019-03-23 12:51:13,141] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.55, 46.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6430343555198631, 6.9112, 6.9112, 95.55338769695034, 374025.554733052, 374025.554733052, 113264.7858362954]
[2019-03-23 12:51:13,143] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:51:13,145] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0000000e+00 3.9593618e-16 1.0664704e-14 8.0445722e-18 1.3129197e-18], sampled 0.4317007759822512
[2019-03-23 12:51:16,254] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6481.6076 1678885180.2952 3057.0000
[2019-03-23 12:51:16,548] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02432108], dtype=float32), -0.17967369]
[2019-03-23 12:51:16,549] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.76901198, 83.89790080666667, 1.0, 2.0, 0.5547096031271773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 623913.5127463903, 623913.51274639, 144113.8890148431]
[2019-03-23 12:51:16,550] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:51:16,552] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0000000e+00 5.5156092e-12 6.1995006e-11 3.3463033e-13 8.5762838e-14], sampled 0.5141815304311577
[2019-03-23 12:51:16,552] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 623913.5127463903 W.
[2019-03-23 12:51:16,795] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6294.9961 1685630448.6673 3228.0000
[2019-03-23 12:51:16,908] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6553.1725 1698634175.0084 2957.0000
[2019-03-23 12:51:16,921] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6328.7217 1723294598.4314 3425.0000
[2019-03-23 12:51:16,982] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6862.2842 1793014293.7888 2409.0000
[2019-03-23 12:51:17,996] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 750000, evaluation results [750000.0, 6862.284208925443, 1793014293.78876, 2409.0, 6481.607577760913, 1678885180.2951708, 3057.0, 6294.9960618483565, 1685630448.6673346, 3228.0, 6328.721692698646, 1723294598.4313502, 3425.0, 6553.172466661831, 1698634175.0084193, 2957.0]
[2019-03-23 12:51:21,093] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9995875e-01 4.9117009e-11 4.1188545e-05 3.3467529e-09 3.4512040e-10], sum to 1.0000
[2019-03-23 12:51:21,100] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5387
[2019-03-23 12:51:21,108] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 558397.1905179803 W.
[2019-03-23 12:51:21,112] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.5, 63.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7626438391808771, 7.285687307862993, 6.9112, 77.32736314318348, 558397.1905179803, 436773.103117914, 134040.2018510963], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4309800.0000, 
sim time next is 4310400.0000, 
raw observation next is [23.0, 66.66666666666667, 1.0, 1.0, 0.2169561404043853, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4297659148898316, 6.9112, 6.9112, 77.3282374478465, 491572.7412023243, 491572.7412023243, 164702.1133923665], 
processed observation next is [1.0, 0.9130434782608695, 0.6818181818181818, 0.6666666666666667, 1.0, 0.5, 0.021195175505481605, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1853798784140452, 0.0, 0.0, 0.5084273270160133, 0.18206397822308307, 0.18206397822308307, 0.4017124716886988], 
reward next is 0.5983, 
noisyNet noise sample is [array([1.0565039], dtype=float32), -1.6590009]. 
=============================================
[2019-03-23 12:51:23,984] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.4252863e-04 2.9739918e-04 9.9911767e-01 1.3552433e-04 6.8603308e-06], sum to 1.0000
[2019-03-23 12:51:23,994] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3376
[2019-03-23 12:51:23,998] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.0, 48.0, 1.0, 2.0, 0.7827249341755722, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9714562624352903, 6.911199999999999, 6.9112, 77.328463443541, 1441641.895255663, 1441641.895255664, 298895.5868128295], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4370400.0000, 
sim time next is 4371000.0000, 
raw observation next is [29.0, 48.0, 1.0, 2.0, 0.8233241919091369, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9715745885589429, 6.9112, 6.9112, 78.99094608834562, 1487953.689536241, 1487953.689536241, 306262.8621275589], 
processed observation next is [1.0, 0.6086956521739131, 0.9545454545454546, 0.48, 1.0, 1.0, 0.779155239886421, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9593922693699184, 0.0, 0.0, 0.5193595108804852, 0.5510939590874967, 0.5510939590874967, 0.7469825905550217], 
reward next is 0.2530, 
noisyNet noise sample is [array([2.297646], dtype=float32), -0.37670916]. 
=============================================
[2019-03-23 12:51:24,010] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[24.283577]
 [24.256699]
 [24.187393]
 [24.099222]
 [24.119623]], R is [[24.3502388 ]
 [24.37772369]
 [24.40309334]
 [24.43224144]
 [24.46943855]].
[2019-03-23 12:51:38,276] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 8.916648e-14 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 12:51:38,282] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4419
[2019-03-23 12:51:38,285] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.33333333333333, 75.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4908815568630423, 6.911200000000001, 6.9112, 77.32846344354104, 285519.7477671632, 285519.7477671629, 90416.19939669834], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4664400.0000, 
sim time next is 4665000.0000, 
raw observation next is [17.16666666666667, 76.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4863536448809836, 6.911199999999999, 6.9112, 77.32846344354104, 282885.3357479734, 282885.3357479737, 89374.96866363495], 
processed observation next is [1.0, 1.0, 0.4166666666666669, 0.7633333333333334, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2662194926871195, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10477234657332349, 0.1047723465733236, 0.21798772844789013], 
reward next is 0.7820, 
noisyNet noise sample is [array([-0.12121074], dtype=float32), -0.46343094]. 
=============================================
[2019-03-23 12:51:38,301] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[84.33928]
 [84.36487]
 [84.36677]
 [84.35979]
 [84.40227]], R is [[84.2554245 ]
 [84.19234467]
 [84.12733459]
 [84.06047821]
 [83.99188232]].
[2019-03-23 12:51:41,664] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.8731646e-05 0.0000000e+00 9.9992120e-01 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 12:51:41,671] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3890
[2019-03-23 12:51:41,677] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.83333333333333, 78.83333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3858790366809133, 6.9112, 6.9112, 77.32846344349818, 442481.7475547494, 442481.7475547494, 159334.0661512802], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4745400.0000, 
sim time next is 4746000.0000, 
raw observation next is [20.66666666666667, 79.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3837230480046017, 6.9112, 6.9112, 77.32846344354077, 440132.1451729957, 440132.1451729957, 158941.3202772996], 
processed observation next is [1.0, 0.9565217391304348, 0.575757575757576, 0.7966666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.11960435429228819, 0.0, 0.0, 0.5084288129206523, 0.16301190561962803, 0.16301190561962803, 0.3876617567739014], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.24560119], dtype=float32), -0.3745252]. 
=============================================
[2019-03-23 12:51:41,709] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[70.00685]
 [70.77064]
 [70.50811]
 [70.50843]
 [72.23855]], R is [[70.58171082]
 [69.87589264]
 [69.17713165]
 [68.48535919]
 [68.40460205]].
[2019-03-23 12:51:42,625] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 1.0147715e-08 2.0477511e-25 1.7700388e-33], sum to 1.0000
[2019-03-23 12:51:42,632] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5207
[2019-03-23 12:51:42,638] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7356500159569861, 7.095242383950507, 6.9112, 77.32784277286126, 483311.8305122626, 423539.1082876597, 129334.741444812], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4766400.0000, 
sim time next is 4767000.0000, 
raw observation next is [18.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7659570015957899, 7.345891793587995, 6.9112, 77.32731884415499, 582133.4958182643, 440956.581947055, 132753.7303570617], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 1.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6656528594225571, 0.04346917935879953, 0.0, 0.5084212872660477, 0.215604998451209, 0.16331725257298332, 0.3237895862367358], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6339624], dtype=float32), 0.77686673]. 
=============================================
[2019-03-23 12:51:42,662] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[17.34933 ]
 [17.415722]
 [17.143013]
 [17.035835]
 [17.379143]], R is [[17.1045742 ]
 [16.9335289 ]
 [16.76419449]
 [16.5965519 ]
 [16.43058586]].
[2019-03-23 12:51:46,248] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.1558807e-20 1.9326111e-20 1.0000000e+00 1.3806765e-17 4.2359035e-21], sum to 1.0000
[2019-03-23 12:51:46,257] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1223
[2019-03-23 12:51:46,260] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.33333333333334, 98.0, 1.0, 2.0, 0.2491985598448939, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5038560437140935, 6.9112, 6.9112, 77.32846344354104, 568396.6669100837, 568396.6669100837, 178263.463216911], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4815600.0000, 
sim time next is 4816200.0000, 
raw observation next is [21.16666666666666, 99.0, 1.0, 2.0, 0.2508075891112477, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5070149636193719, 6.9112, 6.9112, 77.32846344354104, 572125.4865761545, 572125.4865761545, 178514.0602520838], 
processed observation next is [1.0, 0.7391304347826086, 0.5984848484848482, 0.99, 1.0, 1.0, 0.06350948638905958, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2957356623133885, 0.0, 0.0, 0.5084288129206541, 0.21189832836153868, 0.21189832836153868, 0.4354001469563019], 
reward next is 0.5646, 
noisyNet noise sample is [array([-0.5376288], dtype=float32), 0.26388404]. 
=============================================
[2019-03-23 12:51:47,243] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1656456e-14 6.4982220e-15 1.0000000e+00 4.6270279e-13 1.9360914e-15], sum to 1.0000
[2019-03-23 12:51:47,258] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7761
[2019-03-23 12:51:47,265] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.5, 97.0, 1.0, 2.0, 0.2058418910034678, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4099183085206009, 6.9112, 6.9112, 77.32846344354104, 467736.2835558052, 467736.2835558052, 163938.1950554727], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4854600.0000, 
sim time next is 4855200.0000, 
raw observation next is [19.33333333333334, 98.0, 1.0, 2.0, 0.2054809560690511, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4089446023847972, 6.911200000000001, 6.9112, 77.32846344354104, 466765.4732648921, 466765.4732648918, 163722.7253997234], 
processed observation next is [1.0, 0.17391304347826086, 0.5151515151515155, 0.98, 1.0, 1.0, 0.006851195086313849, 0.0, 1.0, -0.25, 1.0, 1.0, 0.155635146263996, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1728761012092193, 0.1728761012092192, 0.3993237204871302], 
reward next is 0.6007, 
noisyNet noise sample is [array([0.78553504], dtype=float32), 1.917032]. 
=============================================
[2019-03-23 12:51:48,605] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.7579025e-11 1.7137059e-11 1.0000000e+00 2.1512889e-12 1.0231453e-13], sum to 1.0000
[2019-03-23 12:51:48,613] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5175
[2019-03-23 12:51:48,616] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.2327883188546135, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4628168004252222, 6.9112, 6.9112, 77.32846344354104, 528543.5336695788, 528543.5336695788, 168621.4331333897], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4865400.0000, 
sim time next is 4866000.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.2206060658295556, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4385582521011366, 6.9112, 6.9112, 77.32846344354104, 500846.0270205991, 500846.0270205991, 166228.9552225097], 
processed observation next is [1.0, 0.30434782608695654, 0.5, 1.0, 1.0, 1.0, 0.025757582286944497, 0.0, 1.0, -0.25, 1.0, 1.0, 0.19794036014448085, 0.0, 0.0, 0.5084288129206541, 0.18549852852614782, 0.18549852852614782, 0.4054364761524627], 
reward next is 0.5946, 
noisyNet noise sample is [array([-1.2057955], dtype=float32), 0.5761759]. 
=============================================
[2019-03-23 12:51:48,631] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[44.733196]
 [44.71608 ]
 [44.705647]
 [44.664993]
 [44.62472 ]], R is [[44.89786911]
 [45.03762054]
 [45.17825699]
 [45.3196373 ]
 [45.4638176 ]].
[2019-03-23 12:51:51,390] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.2696314e-11 5.5761593e-11 1.0000000e+00 1.4773753e-10 5.4801313e-13], sum to 1.0000
[2019-03-23 12:51:51,396] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2679
[2019-03-23 12:51:51,403] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.66666666666667, 96.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3755736328450887, 6.911199999999999, 6.9112, 77.32846344354104, 430814.7479207233, 430814.7479207236, 157848.8333508749], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4926000.0000, 
sim time next is 4926600.0000, 
raw observation next is [18.5, 97.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3742814850277425, 6.9112, 6.9112, 77.32846344354104, 429460.2564127923, 429460.2564127923, 157567.1043247038], 
processed observation next is [1.0, 0.0, 0.4772727272727273, 0.97, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.10611640718248931, 0.0, 0.0, 0.5084288129206541, 0.1590593542269601, 0.1590593542269601, 0.3843100105480581], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8038584], dtype=float32), -0.6117538]. 
=============================================
[2019-03-23 12:52:00,874] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.3088568e-01 1.0928360e-09 2.6910678e-01 7.5626531e-06 2.7838935e-08], sum to 1.0000
[2019-03-23 12:52:00,885] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1589
[2019-03-23 12:52:00,892] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 571625.6545119487 W.
[2019-03-23 12:52:00,899] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5012751664943106, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 571625.6545119487, 571625.6545119489, 142311.1511640476], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5253600.0000, 
sim time next is 5254200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 1.0, 0.3407819659323094, 6.911199999999999, 6.9112, 77.3421103, 574731.8795373595, 574731.8795373597, 213035.2212977105], 
processed observation next is [1.0, 0.8260869565217391, 0.6363636363636364, 0.94, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.5, 0.05825995133187061, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.2128636590879109, 0.212863659087911, 0.5195981007261231], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3102845], dtype=float32), 1.462053]. 
=============================================
[2019-03-23 12:52:04,635] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5690429e-07 1.1303737e-04 9.9988687e-01 4.5748596e-11 1.0237710e-10], sum to 1.0000
[2019-03-23 12:52:04,639] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9930
[2019-03-23 12:52:04,646] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 66.5, 1.0, 2.0, 0.2462125913389487, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4980323623886815, 6.9112, 6.9112, 77.32846344354104, 561419.5125487079, 561419.5125487079, 177879.4613688723], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5159400.0000, 
sim time next is 5160000.0000, 
raw observation next is [26.0, 68.0, 1.0, 2.0, 0.2494283615990091, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5048685491564078, 6.9112, 6.9112, 77.32846344354104, 568357.2681076314, 568357.2681076314, 179191.9840824491], 
processed observation next is [0.0, 0.7391304347826086, 0.8181818181818182, 0.68, 1.0, 1.0, 0.06178545199876137, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2926693559377254, 0.0, 0.0, 0.5084288129206541, 0.21050269189171533, 0.21050269189171533, 0.43705361971329054], 
reward next is 0.5629, 
noisyNet noise sample is [array([0.55418587], dtype=float32), -0.02150692]. 
=============================================
[2019-03-23 12:52:04,659] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[59.36982 ]
 [59.41346 ]
 [59.43527 ]
 [59.45259 ]
 [59.458115]], R is [[59.29167557]
 [59.26490784]
 [59.23962784]
 [59.21134567]
 [59.18001556]].
[2019-03-23 12:52:05,263] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.3143773e-05 3.9440236e-04 9.9955243e-01 3.7194013e-08 1.0308875e-09], sum to 1.0000
[2019-03-23 12:52:05,271] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7291
[2019-03-23 12:52:05,276] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 79.66666666666667, 1.0, 2.0, 0.2292962031239375, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4618200263885135, 6.9112, 6.9112, 77.32846344354104, 523238.3269232359, 523238.3269232359, 171914.8138261797], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5170800.0000, 
sim time next is 5171400.0000, 
raw observation next is [23.0, 80.5, 1.0, 2.0, 0.2309272975954057, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4654401242177227, 6.9112, 6.9112, 77.32846344354104, 526997.4702333936, 526997.4702333936, 172555.5964585683], 
processed observation next is [0.0, 0.8695652173913043, 0.6818181818181818, 0.805, 1.0, 1.0, 0.03865912199425711, 0.0, 1.0, -0.25, 1.0, 1.0, 0.23634303459674671, 0.0, 0.0, 0.5084288129206541, 0.1951842482345902, 0.1951842482345902, 0.42086730843553244], 
reward next is 0.5791, 
noisyNet noise sample is [array([0.8313773], dtype=float32), -1.1919895]. 
=============================================
[2019-03-23 12:52:06,722] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 12:52:06,723] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:52:06,724] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:52:06,725] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:52:06,725] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:52:06,727] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:52:06,726] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:52:06,728] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:52:06,727] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:52:06,729] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:52:06,730] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:52:06,751] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run32
[2019-03-23 12:52:06,751] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run32
[2019-03-23 12:52:06,752] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run32
[2019-03-23 12:52:06,774] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run32
[2019-03-23 12:52:06,865] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run32
[2019-03-23 12:52:09,543] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.18243755]
[2019-03-23 12:52:09,544] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.75915926166667, 39.97850986166667, 1.0, 2.0, 0.2132357408966291, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4065302766532211, 6.911200000000001, 6.9112, 95.55338769695034, 470387.8450959419, 470387.8450959416, 161758.2149547925]
[2019-03-23 12:52:09,545] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:52:09,548] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.1672895e-05 3.7037153e-05 9.9994123e-01 3.2923914e-08 8.5160734e-10], sampled 0.8460718135881092
[2019-03-23 12:52:14,424] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.18243755]
[2019-03-23 12:52:14,426] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.34837388166667, 86.04278697333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 234669.8767382429, 234669.8767382429, 105087.8245610748]
[2019-03-23 12:52:14,427] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:52:14,432] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.4169799e-05 8.9814275e-05 9.9984598e-01 1.0865303e-07 3.3001992e-09], sampled 0.02982282710116224
[2019-03-23 12:52:46,267] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.18243755]
[2019-03-23 12:52:46,268] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.835499605, 70.98958180166666, 1.0, 2.0, 0.3551754507632049, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7174150543003741, 6.911200000000001, 6.9112, 95.55338769695034, 810514.1388897458, 810514.1388897455, 212173.6915143937]
[2019-03-23 12:52:46,270] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:52:46,273] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.2137941e-05 3.8549580e-05 9.9993920e-01 3.6130615e-08 9.6041430e-10], sampled 0.6074418296552331
[2019-03-23 12:52:52,684] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.18243755]
[2019-03-23 12:52:52,689] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.53333333333333, 78.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 262478.1159294227, 262478.1159294223, 112812.8576360001]
[2019-03-23 12:52:52,690] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:52:52,692] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.7314504e-05 8.6488537e-05 9.9984610e-01 7.9190968e-08 2.1340065e-09], sampled 0.1257343152378273
[2019-03-23 12:52:55,350] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.18243755]
[2019-03-23 12:52:55,351] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.5, 89.0, 1.0, 2.0, 0.5191740636535827, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9658640337484848, 6.942696224481231, 6.9112, 77.3283813085722, 1132324.013521342, 1122094.694884189, 268944.4920413414]
[2019-03-23 12:52:55,352] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:52:55,355] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.3629969e-06 2.2288570e-05 9.9996829e-01 3.1821862e-08 9.9009867e-10], sampled 0.7215463842112191
[2019-03-23 12:53:12,281] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.18243755]
[2019-03-23 12:53:12,283] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.20674315, 96.54877213500001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 332857.7472278679, 332857.7472278676, 146183.9507679219]
[2019-03-23 12:53:12,283] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:53:12,286] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.8200451e-05 6.6700261e-05 9.9988508e-01 5.8637568e-08 1.5396652e-09], sampled 0.7444094964194998
[2019-03-23 12:53:12,823] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.18243755]
[2019-03-23 12:53:12,824] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.46501963, 100.0, 1.0, 2.0, 0.2818340494131717, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5693438287772449, 6.911200000000001, 6.9112, 95.55338769695034, 633695.7802280545, 633695.7802280542, 196207.9649538547]
[2019-03-23 12:53:12,825] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:53:12,828] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.8106717e-05 4.6498226e-05 9.9992537e-01 4.5634515e-08 1.2446850e-09], sampled 0.8575935424438769
[2019-03-23 12:53:14,287] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.18243755]
[2019-03-23 12:53:14,288] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.66666666666667, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 253533.6308933589, 253533.6308933589, 103153.1044203728]
[2019-03-23 12:53:14,289] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:53:14,292] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.9833793e-05 1.2032887e-04 9.9977964e-01 1.1803835e-07 3.3381913e-09], sampled 0.8292952250273717
[2019-03-23 12:53:17,548] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.18243755]
[2019-03-23 12:53:17,550] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [29.6, 51.00000000000001, 1.0, 2.0, 0.8309605890247477, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9773351594255796, 6.911199999999999, 6.9112, 77.32846344354104, 1492713.482037392, 1492713.482037392, 313261.174875965]
[2019-03-23 12:53:17,551] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:53:17,556] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.6644346e-06 1.9619492e-05 9.9997270e-01 3.0101642e-08 9.6497088e-10], sampled 0.9420725245669197
[2019-03-23 12:53:24,130] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.18243755]
[2019-03-23 12:53:24,131] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.06563326, 73.47270225, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3138674615192772, 6.911200000000001, 6.9112, 95.55338769695034, 362852.7296985931, 362852.7296985928, 151938.6375085593]
[2019-03-23 12:53:24,132] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:53:24,141] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.2784199e-05 6.4119595e-05 9.9989295e-01 6.7825937e-08 1.9240405e-09], sampled 0.574224123405694
[2019-03-23 12:53:26,376] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.18243755]
[2019-03-23 12:53:26,376] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.03333333333333, 57.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3649729093574228, 6.911199999999999, 6.9112, 95.55338769695034, 420683.4246807459, 420683.4246807462, 159201.7380437625]
[2019-03-23 12:53:26,377] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:53:26,379] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.2714495e-05 5.0532974e-05 9.9991679e-01 4.5533440e-08 1.1986366e-09], sampled 0.3193400612658541
[2019-03-23 12:53:46,258] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3613.7734 2175249408.5707 246.0000
[2019-03-23 12:53:46,323] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2760.8419 2124022682.2869 757.0000
[2019-03-23 12:53:46,501] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3119.5674 2108994013.1172 368.0000
[2019-03-23 12:53:46,549] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3362.0682 2098033419.7645 179.0000
[2019-03-23 12:53:46,590] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3519.0325 2104095443.0865 178.0000
[2019-03-23 12:53:47,605] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 775000, evaluation results [775000.0, 3613.7733713833427, 2175249408.5707183, 246.0, 3362.0681964432083, 2098033419.7645345, 179.0, 3519.032511138161, 2104095443.0864863, 178.0, 2760.841938059423, 2124022682.2869394, 757.0, 3119.5674485634077, 2108994013.1172128, 368.0]
[2019-03-23 12:53:48,393] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.4584303e-04 3.9117248e-04 9.9915409e-01 8.7502658e-06 1.2532252e-07], sum to 1.0000
[2019-03-23 12:53:48,406] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9385
[2019-03-23 12:53:48,409] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.4384908132793904, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8876755760198278, 6.911200000000001, 6.9112, 77.32843810554571, 999384.8537758972, 999384.853775897, 240225.8943981836], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5236800.0000, 
sim time next is 5237400.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.4148769617146683, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8398073366384301, 6.911199999999999, 6.9112, 77.32846328669653, 945631.1346454177, 945631.134645418, 230700.4861009435], 
processed observation next is [1.0, 0.6086956521739131, 0.6363636363636364, 0.94, 1.0, 1.0, 0.26859620214333535, 0.0, 1.0, -0.25, 1.0, 1.0, 0.7711533380549003, -8.881784197001253e-17, 0.0, 0.5084288118894134, 0.3502337535723769, 0.35023375357237707, 0.5626841124413257], 
reward next is 0.4373, 
noisyNet noise sample is [array([0.028781], dtype=float32), 0.3802268]. 
=============================================
[2019-03-23 12:53:51,506] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9988353e-01 3.1925039e-17 1.1647234e-04 3.5509673e-10 2.4969940e-13], sum to 1.0000
[2019-03-23 12:53:51,514] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6397
[2019-03-23 12:53:51,519] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.21666666666667, 80.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6939519403240688, 6.911199999999999, 6.9112, 77.32846344354104, 402013.8597260787, 402013.859726079, 123088.0467473488], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5281800.0000, 
sim time next is 5282400.0000, 
raw observation next is [19.13333333333334, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6636605176853518, 6.911199999999999, 6.9112, 77.32846344354104, 384180.822764494, 384180.8227644943, 120396.9151771185], 
processed observation next is [1.0, 0.13043478260869565, 0.5060606060606063, 0.82, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5195150252647884, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14228919361647926, 0.14228919361647938, 0.2936510126271183], 
reward next is 0.7063, 
noisyNet noise sample is [array([-0.7535201], dtype=float32), -2.4471714]. 
=============================================
[2019-03-23 12:53:51,839] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.5347023e-02 2.1867017e-25 9.3465298e-01 2.8292529e-13 2.5433033e-18], sum to 1.0000
[2019-03-23 12:53:51,845] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5804
[2019-03-23 12:53:51,849] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.46666666666667, 91.0, 1.0, 1.0, 0.2450910153531445, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4907994499298751, 6.911199999999999, 6.9112, 77.32811065205341, 558394.9453831314, 558394.9453831317, 173236.7895287343], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5271600.0000, 
sim time next is 5272200.0000, 
raw observation next is [20.4, 86.5, 1.0, 2.0, 0.2132845246745902, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4240492165263637, 6.9112, 6.9112, 77.32846125969137, 484243.6796200476, 484243.6796200476, 164889.1716247602], 
processed observation next is [1.0, 0.0, 0.5636363636363636, 0.865, 1.0, 1.0, 0.016605655843237727, 0.0, 1.0, -0.25, 1.0, 1.0, 0.17721316646623386, 0.0, 0.0, 0.5084287985620073, 0.179349510970388, 0.179349510970388, 0.40216871127990295], 
reward next is 0.5978, 
noisyNet noise sample is [array([-1.3200454], dtype=float32), -0.63133436]. 
=============================================
[2019-03-23 12:53:54,684] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.6367993e-16 0.0000000e+00 1.0000000e+00 1.6425442e-30 1.4529237e-36], sum to 1.0000
[2019-03-23 12:53:54,692] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4701
[2019-03-23 12:53:54,696] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.93333333333333, 79.66666666666667, 1.0, 2.0, 0.2312049544032091, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4656507663460545, 6.9112, 6.9112, 77.32846344354104, 527594.4086957108, 527594.4086957108, 172303.1947188351], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5361600.0000, 
sim time next is 5362200.0000, 
raw observation next is [22.75, 80.0, 1.0, 2.0, 0.2291484491189397, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4610950359773295, 6.9112, 6.9112, 77.32846344354104, 522824.5514198895, 522824.5514198895, 171522.4379229426], 
processed observation next is [1.0, 0.043478260869565216, 0.6704545454545454, 0.8, 1.0, 1.0, 0.036435561398674605, 0.0, 1.0, -0.25, 1.0, 1.0, 0.23013576568189928, 0.0, 0.0, 0.5084288129206541, 0.19363872274810723, 0.19363872274810723, 0.4183474095681527], 
reward next is 0.5817, 
noisyNet noise sample is [array([-0.67043203], dtype=float32), 0.62360835]. 
=============================================
[2019-03-23 12:54:00,945] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 3.718274e-29 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 12:54:00,956] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5691
[2019-03-23 12:54:00,960] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.2, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6054826953641637, 6.911199999999999, 6.9112, 77.32846344354104, 351970.6876271881, 351970.6876271884, 114106.1707417568], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5464200.0000, 
sim time next is 5464800.0000, 
raw observation next is [17.2, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6209439370433354, 6.9112, 6.9112, 77.32846344354104, 360962.6102737087, 360962.6102737087, 115396.2861063348], 
processed observation next is [1.0, 0.2608695652173913, 0.41818181818181815, 0.9, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4584913386333363, 0.0, 0.0, 0.5084288129206541, 0.13368985565692915, 0.13368985565692915, 0.2814543563569141], 
reward next is 0.7185, 
noisyNet noise sample is [array([1.259517], dtype=float32), 0.5236122]. 
=============================================
[2019-03-23 12:54:02,531] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.3207010e-10 4.0366185e-25 1.0000000e+00 2.8540183e-17 8.1586013e-20], sum to 1.0000
[2019-03-23 12:54:02,541] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0278
[2019-03-23 12:54:02,546] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.6, 71.5, 1.0, 2.0, 0.3755443652027142, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7606457498106676, 6.911200000000001, 6.9112, 77.32846344354104, 854555.6393048107, 854555.6393048104, 217410.9007806384], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5489400.0000, 
sim time next is 5490000.0000, 
raw observation next is [25.5, 72.0, 1.0, 2.0, 0.4503836092829472, 0.0, 2.0, 0.0, 1.0, 2.0, 0.912235801177833, 6.911200000000001, 6.9112, 77.32846344354104, 1024987.907443083, 1024987.907443082, 246525.7914286048], 
processed observation next is [1.0, 0.5652173913043478, 0.7954545454545454, 0.72, 1.0, 1.0, 0.3129795116036839, 0.0, 1.0, -0.25, 1.0, 1.0, 0.8746225731111901, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.37962515090484555, 0.37962515090484517, 0.6012824181185483], 
reward next is 0.3987, 
noisyNet noise sample is [array([0.86195356], dtype=float32), 1.4773581]. 
=============================================
[2019-03-23 12:54:02,559] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[32.93009 ]
 [32.47099 ]
 [32.153618]
 [32.02806 ]
 [31.84989 ]], R is [[32.85219193]
 [32.99340057]
 [33.08614349]
 [33.08901215]
 [33.09278488]].
[2019-03-23 12:54:03,408] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.1134476e-20 0.0000000e+00 1.0000000e+00 7.7004876e-28 3.3291807e-34], sum to 1.0000
[2019-03-23 12:54:03,417] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4033
[2019-03-23 12:54:03,422] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.78333333333333, 67.0, 1.0, 2.0, 0.3987217731353806, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8076008822265599, 6.911199999999999, 6.9112, 77.32846344354104, 904596.9053069751, 904596.9053069755, 227496.7394616037], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5505000.0000, 
sim time next is 5505600.0000, 
raw observation next is [26.96666666666667, 65.0, 1.0, 2.0, 0.2681039847791131, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5430934765749741, 6.911199999999999, 6.9112, 77.32846344354104, 609311.1815209399, 609311.1815209403, 185146.4429830702], 
processed observation next is [1.0, 0.7391304347826086, 0.8621212121212122, 0.65, 1.0, 1.0, 0.08512998097389139, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3472763951071059, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22567080797071848, 0.22567080797071862, 0.45157669020261026], 
reward next is 0.5484, 
noisyNet noise sample is [array([0.7880529], dtype=float32), -0.69140285]. 
=============================================
[2019-03-23 12:54:03,846] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.8183607e-10 0.0000000e+00 1.0000000e+00 6.6367519e-25 5.3549248e-30], sum to 1.0000
[2019-03-23 12:54:03,855] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6391
[2019-03-23 12:54:03,869] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.5, 87.0, 1.0, 2.0, 0.2553255526989152, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5077701483644345, 6.911199999999999, 6.9112, 77.32846344354104, 579833.6967855927, 579833.6967855929, 173412.2816349963], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5538600.0000, 
sim time next is 5539200.0000, 
raw observation next is [20.5, 87.0, 1.0, 2.0, 0.2401315341122472, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4774062099557366, 6.911199999999999, 6.9112, 77.32846344354104, 545219.4799410984, 545219.4799410986, 170104.5510970294], 
processed observation next is [1.0, 0.08695652173913043, 0.5681818181818182, 0.87, 1.0, 1.0, 0.050164417640308975, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2534374427939095, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20193314071892532, 0.2019331407189254, 0.4148891490171449], 
reward next is 0.5851, 
noisyNet noise sample is [array([-0.6367285], dtype=float32), 0.5796621]. 
=============================================
[2019-03-23 12:54:04,903] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.9086270e-17 0.0000000e+00 1.0000000e+00 2.7443984e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 12:54:04,907] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9345
[2019-03-23 12:54:04,914] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.0, 93.0, 1.0, 2.0, 0.2140180884022724, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4263823945469005, 6.9112, 6.9112, 77.32846344354104, 486429.8484705383, 486429.8484705383, 165533.1030781733], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5545800.0000, 
sim time next is 5546400.0000, 
raw observation next is [20.0, 93.0, 1.0, 2.0, 0.2116796188077393, 0.0, 2.0, 0.0, 1.0, 2.0, 0.421689797005422, 6.9112, 6.9112, 77.32846344354104, 481092.7925237375, 481092.7925237375, 165081.1298610768], 
processed observation next is [1.0, 0.17391304347826086, 0.5454545454545454, 0.93, 1.0, 1.0, 0.014599523509674119, 0.0, 1.0, -0.25, 1.0, 1.0, 0.17384256715060284, 0.0, 0.0, 0.5084288129206541, 0.1781825157495324, 0.1781825157495324, 0.4026369021001873], 
reward next is 0.5974, 
noisyNet noise sample is [array([-0.2491607], dtype=float32), 5.8509628e-05]. 
=============================================
[2019-03-23 12:54:10,891] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.00000e+00 0.00000e+00 6.72567e-26 0.00000e+00 0.00000e+00], sum to 1.0000
[2019-03-23 12:54:10,898] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2137
[2019-03-23 12:54:10,902] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.1, 68.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4049584630683197, 6.911199999999999, 6.9112, 77.32846344354104, 235530.7434733007, 235530.743473301, 69911.79742063477], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5681400.0000, 
sim time next is 5682000.0000, 
raw observation next is [16.1, 67.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4036933227117218, 6.911199999999999, 6.9112, 77.32846344354104, 234794.7386791862, 234794.7386791865, 69413.53365900318], 
processed observation next is [0.0, 0.782608695652174, 0.3681818181818182, 0.6733333333333335, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.14813331815960262, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08696101432562452, 0.08696101432562463, 0.16930130160732482], 
reward next is 0.8307, 
noisyNet noise sample is [array([-0.11948527], dtype=float32), -0.31859115]. 
=============================================
[2019-03-23 12:54:10,916] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[71.74577]
 [71.84587]
 [71.90948]
 [71.98808]
 [72.0392 ]], R is [[71.82080841]
 [71.93208313]
 [72.04135132]
 [72.14976501]
 [72.25705719]].
[2019-03-23 12:54:12,934] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 1.8749152e-14 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 12:54:12,945] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4950
[2019-03-23 12:54:12,952] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [11.6, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 172717.6012235083, 172717.6012235083, 57755.11312535606], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5701200.0000, 
sim time next is 5701800.0000, 
raw observation next is [11.6, 77.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 172323.9402801339, 172323.9402801337, 57685.02472577358], 
processed observation next is [0.0, 1.0, 0.1636363636363636, 0.775, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.06382368158523477, 0.06382368158523472, 0.14069518225798436], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.9640527], dtype=float32), 1.4376333]. 
=============================================
[2019-03-23 12:54:18,207] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 3.2283144e-35 4.7692192e-09 8.1672849e-21 3.5049965e-28], sum to 1.0000
[2019-03-23 12:54:18,217] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1061
[2019-03-23 12:54:18,228] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [12.1, 83.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7245815962142411, 7.066351376666215, 6.9112, 77.327968422643, 471921.0882287793, 421531.4170553658, 94933.27269635594], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5803800.0000, 
sim time next is 5804400.0000, 
raw observation next is [12.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7298952780790424, 7.110946882101485, 6.9112, 77.32783770866206, 489503.5469501254, 424630.3701259151, 95417.68522275363], 
processed observation next is [1.0, 0.17391304347826086, 0.18181818181818182, 0.84, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6141361115414892, 0.01997468821014854, 0.0, 0.5084246987610348, 0.18129760998152794, 0.15727050745404264, 0.2327260615189113], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.08440596], dtype=float32), 0.9117138]. 
=============================================
[2019-03-23 12:54:21,499] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 1.8181672e-13 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 12:54:21,506] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3259
[2019-03-23 12:54:21,512] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.0, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6301192564199024, 6.911199999999999, 6.9112, 77.32846344354104, 365055.2965525914, 365055.2965525917, 117124.7615276409], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5871600.0000, 
sim time next is 5872200.0000, 
raw observation next is [19.83333333333334, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6307016038649905, 6.911199999999999, 6.9112, 77.32846344354104, 365432.0908376015, 365432.0908376017, 117146.361594558], 
processed observation next is [1.0, 1.0, 0.5378787878787882, 0.74, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4724308626642722, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13534521882874131, 0.13534521882874137, 0.2857228331574585], 
reward next is 0.7143, 
noisyNet noise sample is [array([2.152155], dtype=float32), -0.91693664]. 
=============================================
[2019-03-23 12:54:21,673] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 3.4863676e-13 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 12:54:21,681] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9791
[2019-03-23 12:54:21,692] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1143349.784538335 W.
[2019-03-23 12:54:21,696] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.7, 66.0, 1.0, 2.0, 0.5219580430530107, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9580676727448011, 6.936729583491917, 6.9112, 77.32840079352235, 1143349.784538335, 1135058.304708046, 260426.0779885501], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6014400.0000, 
sim time next is 6015000.0000, 
raw observation next is [25.6, 67.5, 1.0, 2.0, 0.4945902454294075, 1.0, 1.0, 0.4945902454294075, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.3284481024644, 1125247.124680176, 1125247.124680176, 229778.5546002231], 
processed observation next is [1.0, 0.6086956521739131, 0.8, 0.675, 1.0, 1.0, 0.3682378067867593, 1.0, 0.5, 0.3682378067867593, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084287120542327, 0.4167581943259911, 0.4167581943259911, 0.5604354990249344], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.71592593], dtype=float32), -0.6529647]. 
=============================================
[2019-03-23 12:54:21,711] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[85.70879]
 [85.25395]
 [82.61577]
 [82.12672]
 [78.28468]], R is [[85.63383484]
 [84.77749634]
 [83.92972565]
 [83.41471863]
 [82.90516663]].
[2019-03-23 12:54:36,251] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 12:54:36,253] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:54:36,254] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:54:36,255] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:54:36,256] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:54:36,257] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:54:36,259] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:54:36,259] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:54:36,260] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:54:36,261] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:54:36,260] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:54:36,279] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run33
[2019-03-23 12:54:36,279] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run33
[2019-03-23 12:54:36,279] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run33
[2019-03-23 12:54:36,357] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run33
[2019-03-23 12:54:36,357] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run33
[2019-03-23 12:54:40,611] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.18601306]
[2019-03-23 12:54:40,612] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3526561791265815, 6.9112, 6.9112, 77.32846344354104, 205104.4301694291, 205104.4301694291, 67321.3890977345]
[2019-03-23 12:54:40,614] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:54:40,617] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 2.5778293e-10 2.8941044e-37 0.0000000e+00], sampled 0.7980548166407926
[2019-03-23 12:55:01,801] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.18601306]
[2019-03-23 12:55:01,803] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.95, 78.5, 1.0, 2.0, 0.4495956975289145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338711252683, 512620.2292785657, 512620.2292785661, 138423.0116948339]
[2019-03-23 12:55:01,805] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:55:01,808] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.9999976e-01 0.0000000e+00 2.6288865e-07 6.0417205e-26 7.2568718e-37], sampled 0.6860452411899697
[2019-03-23 12:55:06,445] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.18601306]
[2019-03-23 12:55:06,447] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.75, 42.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6677994047568441, 6.9112, 6.9112, 95.55337267186553, 388434.9791507216, 388434.9791507216, 101791.5149287221]
[2019-03-23 12:55:06,448] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:55:06,452] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 0.0000000e+00 4.1852358e-10 2.0239369e-36 0.0000000e+00], sampled 0.40050120237701337
[2019-03-23 12:55:08,288] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.18601306]
[2019-03-23 12:55:08,290] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.46666666666667, 55.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4032912977507116, 6.9112, 6.9112, 95.55338769695034, 234555.3039671204, 234555.3039671204, 67122.4493206151]
[2019-03-23 12:55:08,291] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:55:08,293] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 0.0000000e+00 2.9511021e-10 5.8595585e-37 0.0000000e+00], sampled 0.14783997681940053
[2019-03-23 12:55:24,603] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.18601306]
[2019-03-23 12:55:24,604] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.33333333333334, 72.66666666666667, 1.0, 2.0, 0.9032209646065148, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9865530188920543, 6.911199999999999, 6.9112, 77.32846344354104, 1564181.773367852, 1564181.773367852, 334510.0527298551]
[2019-03-23 12:55:24,606] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:55:24,609] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.9999785e-01 0.0000000e+00 2.1038545e-06 1.0398613e-22 2.9694016e-32], sampled 0.5504656560484988
[2019-03-23 12:55:24,611] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1564181.773367852 W.
[2019-03-23 12:55:36,679] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.18601306]
[2019-03-23 12:55:36,680] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.5, 97.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7661838287390071, 7.297608097519699, 6.9112, 77.32750794245302, 563097.1628196579, 437601.2668537306, 135313.3417917302]
[2019-03-23 12:55:36,681] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:55:36,683] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.9999988e-01 0.0000000e+00 1.6717108e-07 8.7731941e-27 4.5465193e-38], sampled 0.9692913233709227
[2019-03-23 12:55:36,685] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 563097.1628196579 W.
[2019-03-23 12:55:50,814] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.18601306]
[2019-03-23 12:55:50,815] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.48333333333333, 70.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4355858864638219, 6.911200000000001, 6.9112, 95.55338769695034, 253336.2303707151, 253336.2303707147, 80188.68534517626]
[2019-03-23 12:55:50,816] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:55:50,818] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 1.5828504e-10 4.8794905e-38 0.0000000e+00], sampled 0.007761243947713381
[2019-03-23 12:56:05,681] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.18601306]
[2019-03-23 12:56:05,683] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.8, 92.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7392412823472316, 7.126445366825213, 6.9112, 77.32778698529616, 495614.0516299444, 425707.3705531299, 129654.5455340114]
[2019-03-23 12:56:05,684] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:56:05,686] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 8.9392127e-10 3.7868866e-35 0.0000000e+00], sampled 0.5523392309796139
[2019-03-23 12:56:15,189] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6862.2842 1793014293.7888 2409.0000
[2019-03-23 12:56:15,551] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6328.7217 1723294598.4314 3425.0000
[2019-03-23 12:56:15,829] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6481.6076 1678885180.2952 3057.0000
[2019-03-23 12:56:15,927] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6553.1725 1698634175.0084 2957.0000
[2019-03-23 12:56:15,977] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6294.1708 1685655849.4452 3228.0000
[2019-03-23 12:56:16,993] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 800000, evaluation results [800000.0, 6862.284208925443, 1793014293.78876, 2409.0, 6481.607577760913, 1678885180.2951708, 3057.0, 6294.170799910606, 1685655849.44522, 3228.0, 6328.721692698646, 1723294598.4313502, 3425.0, 6553.172466661831, 1698634175.0084193, 2957.0]
[2019-03-23 12:56:17,362] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 8.203488e-18 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 12:56:17,370] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7720
[2019-03-23 12:56:17,374] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.36666666666667, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5685544730977053, 6.911199999999999, 6.9112, 77.32846344354104, 330713.3219586675, 330713.3219586678, 104100.7354493778], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6151200.0000, 
sim time next is 6151800.0000, 
raw observation next is [17.28333333333333, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5627349974397644, 6.9112, 6.9112, 77.32846344354104, 327327.1453744633, 327327.1453744633, 103956.1860301053], 
processed observation next is [1.0, 0.17391304347826086, 0.4219696969696969, 0.83, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3753357106282349, 0.0, 0.0, 0.5084288129206541, 0.12123227606461603, 0.12123227606461603, 0.2535516732441593], 
reward next is 0.7464, 
noisyNet noise sample is [array([2.1944761], dtype=float32), 0.2473319]. 
=============================================
[2019-03-23 12:56:21,113] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 1.2710031e-09 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 12:56:21,126] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0415
[2019-03-23 12:56:21,126] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 546872.799294151 W.
[2019-03-23 12:56:21,132] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.2, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7561592058521744, 7.256457012415575, 6.9112, 77.32736005639507, 546872.799294151, 434741.9833877222, 132062.3086359514], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6225600.0000, 
sim time next is 6226200.0000, 
raw observation next is [19.1, 91.5, 1.0, 1.0, 0.4171665801147997, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.3282547387082, 469501.5807541409, 469501.5807541411, 126108.32846164], 
processed observation next is [0.0, 0.043478260869565216, 0.5045454545454546, 0.915, 1.0, 0.5, 0.27145822514349954, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084274407021244, 0.17388947435338553, 0.1738894743533856, 0.30758128893082926], 
reward next is 0.6924, 
noisyNet noise sample is [array([-2.8171058], dtype=float32), -0.46966118]. 
=============================================
[2019-03-23 12:56:21,923] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.7643083e-01 1.1924994e-20 2.3569210e-02 2.2044581e-11 1.0529575e-16], sum to 1.0000
[2019-03-23 12:56:21,929] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9800
[2019-03-23 12:56:21,935] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.6, 85.33333333333334, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7729523077675994, 7.332936809218284, 6.9112, 77.3274336597032, 577025.905544612, 440056.2399705488, 137117.0287358944], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6255600.0000, 
sim time next is 6256200.0000, 
raw observation next is [21.6, 86.16666666666666, 1.0, 1.0, 0.2337953432433995, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4692576298849873, 6.911199999999999, 6.9112, 77.32821000887623, 533084.2175316263, 533084.2175316267, 171590.520604992], 
processed observation next is [0.0, 0.391304347826087, 0.6181818181818183, 0.8616666666666666, 1.0, 0.5, 0.042244179054249376, 0.0, 1.0, -0.25, 1.0, 1.0, 0.24179661412141049, -8.881784197001253e-17, 0.0, 0.508427146606854, 0.19743859908578754, 0.19743859908578767, 0.4185134648902244], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.37243912], dtype=float32), 1.218583]. 
=============================================
[2019-03-23 12:56:21,943] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9422693e-01 3.6904143e-20 5.7730409e-03 3.8392328e-12 1.6937153e-16], sum to 1.0000
[2019-03-23 12:56:21,951] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9267
[2019-03-23 12:56:21,954] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.3, 94.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7195539134966767, 6.968332130382415, 6.9112, 77.32821201153224, 433275.3796815892, 414720.0926198852, 127265.4220797428], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6240600.0000, 
sim time next is 6241200.0000, 
raw observation next is [18.3, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7154583257419299, 6.936062893955348, 6.9112, 77.32830742641339, 420552.6420085834, 412477.6988779677, 126744.9285110482], 
processed observation next is [0.0, 0.21739130434782608, 0.4681818181818182, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5935118939170427, 0.0024862893955347686, 0.0, 0.5084277871198108, 0.15576023778095682, 0.152769518102951, 0.30913397197816633], 
reward next is 0.5666, 
noisyNet noise sample is [array([-1.3150535], dtype=float32), -0.24953678]. 
=============================================
[2019-03-23 12:56:25,037] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8269463e-07 0.0000000e+00 9.9999976e-01 1.1899067e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 12:56:25,045] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9469
[2019-03-23 12:56:25,050] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.6, 73.66666666666667, 1.0, 2.0, 0.243347448719213, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4919347725517665, 6.911199999999999, 6.9112, 77.32846344354104, 555097.8028887861, 555097.8028887863, 176797.8186524237], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6304800.0000, 
sim time next is 6305400.0000, 
raw observation next is [24.4, 75.0, 1.0, 2.0, 0.2433483978110085, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4919488075479999, 6.9112, 6.9112, 77.32846344354104, 555093.126277018, 555093.126277018, 176813.896136221], 
processed observation next is [0.0, 1.0, 0.7454545454545454, 0.75, 1.0, 1.0, 0.05418549726376062, 0.0, 1.0, -0.25, 1.0, 1.0, 0.27421258221142847, 0.0, 0.0, 0.5084288129206541, 0.20559004676926593, 0.20559004676926593, 0.43125340521029515], 
reward next is 0.5687, 
noisyNet noise sample is [array([-0.1708207], dtype=float32), -1.0639504]. 
=============================================
[2019-03-23 12:56:29,155] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.531601e-11 0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 12:56:29,156] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3792
[2019-03-23 12:56:29,165] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.4, 77.5, 1.0, 2.0, 0.2557096421236302, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5175791174352601, 6.9112, 6.9112, 77.32846344354104, 582684.0990064429, 582684.0990064429, 180679.58791172], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6395400.0000, 
sim time next is 6396000.0000, 
raw observation next is [24.4, 77.0, 1.0, 2.0, 0.2536840896764674, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5133824781876268, 6.9112, 6.9112, 77.32846344354104, 578207.4348070372, 578207.4348070372, 180013.2790170862], 
processed observation next is [1.0, 0.0, 0.7454545454545454, 0.77, 1.0, 1.0, 0.06710511209558422, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3048321116966098, 0.0, 0.0, 0.5084288129206541, 0.21415090178038415, 0.21415090178038415, 0.4390567780904541], 
reward next is 0.5609, 
noisyNet noise sample is [array([-0.277128], dtype=float32), 0.49230984]. 
=============================================
[2019-03-23 12:56:29,192] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[61.47337 ]
 [61.556755]
 [62.03921 ]
 [62.69555 ]
 [63.00903 ]], R is [[60.97010422]
 [60.91972351]
 [60.8682251 ]
 [60.81583786]
 [60.76317215]].
[2019-03-23 12:56:35,189] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9999988e-01 0.0000000e+00 1.5553196e-07 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 12:56:35,194] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4298
[2019-03-23 12:56:35,200] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.86666666666667, 76.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4318360309343207, 6.9112, 6.9112, 77.32846344354104, 251167.2321622811, 251167.2321622811, 75158.39030622249], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6509400.0000, 
sim time next is 6510000.0000, 
raw observation next is [16.23333333333333, 74.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5689245851138495, 6.9112, 6.9112, 77.32846344354104, 330928.6801185987, 330928.6801185987, 87012.49743303763], 
processed observation next is [1.0, 0.34782608695652173, 0.3742424242424241, 0.7433333333333334, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3841779787340707, 0.0, 0.0, 0.5084288129206541, 0.12256617782170322, 0.12256617782170322, 0.21222560349521372], 
reward next is 0.7878, 
noisyNet noise sample is [array([0.23898537], dtype=float32), -3.1696365]. 
=============================================
[2019-03-23 12:56:35,220] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[60.092594]
 [60.14994 ]
 [60.15721 ]
 [60.20692 ]
 [60.190464]], R is [[59.83686447]
 [60.05518341]
 [60.27864456]
 [60.50403595]
 [60.72962189]].
[2019-03-23 12:56:35,562] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 1.1566353e-08 4.1082782e-26 3.9271484e-35], sum to 1.0000
[2019-03-23 12:56:35,571] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5471
[2019-03-23 12:56:35,578] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 571180.8785402857 W.
[2019-03-23 12:56:35,580] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.71666666666667, 57.5, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7545764846533171, 7.318111493286268, 6.9112, 77.32750188281301, 571180.8785402857, 439025.9916347109, 102661.7269057618], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6516600.0000, 
sim time next is 6517200.0000, 
raw observation next is [18.63333333333333, 58.00000000000001, 1.0, 1.0, 0.2391277083319927, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4463990443101355, 6.9112, 6.9112, 77.32821892631517, 519418.1295787065, 519418.1295787065, 144589.203778543], 
processed observation next is [1.0, 0.43478260869565216, 0.48333333333333317, 0.5800000000000001, 1.0, 0.5, 0.04890963541499087, 0.0, 1.0, -0.25, 1.0, 1.0, 0.20914149187162218, 0.0, 0.0, 0.5084272052383422, 0.19237708502915057, 0.19237708502915057, 0.35265659458181214], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.4424589], dtype=float32), 0.44190514]. 
=============================================
[2019-03-23 12:56:35,862] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.9999964e-01 0.0000000e+00 3.3828144e-07 7.7271292e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 12:56:35,870] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4955
[2019-03-23 12:56:35,875] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.95, 51.5, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.6596894885257416, 6.9112, 6.9112, 77.32846109591468, 383745.1027498956, 383745.1027498956, 93653.49510307409], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6525000.0000, 
sim time next is 6525600.0000, 
raw observation next is [20.13333333333333, 50.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6693645677374743, 6.911200000000001, 6.9112, 77.32846342900905, 389375.404423603, 389375.4044236028, 100229.3952835948], 
processed observation next is [1.0, 0.5217391304347826, 0.5515151515151513, 0.5066666666666667, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.527663668196392, 8.881784197001253e-17, 0.0, 0.5084288128251073, 0.1442131127494826, 0.1442131127494825, 0.24446193971608488], 
reward next is 0.7555, 
noisyNet noise sample is [array([1.7321727], dtype=float32), -0.3044708]. 
=============================================
[2019-03-23 12:56:40,070] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9999928e-01 0.0000000e+00 7.2035272e-07 1.9001076e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 12:56:40,081] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7856
[2019-03-23 12:56:40,081] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 595558.3340645826 W.
[2019-03-23 12:56:40,087] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.98333333333333, 68.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7619423633165624, 7.379942441297342, 6.9112, 77.32728221003828, 595558.3340645826, 443322.7020880906, 115675.9298225367], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6599400.0000, 
sim time next is 6600000.0000, 
raw observation next is [18.26666666666667, 67.66666666666667, 1.0, 1.0, 0.4535496993220595, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.3281812546004, 492572.4348765341, 492572.4348765344, 114442.3816556117], 
processed observation next is [1.0, 0.391304347826087, 0.4666666666666668, 0.6766666666666667, 1.0, 0.5, 0.31693712415257436, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084269575496597, 0.18243423513945708, 0.18243423513945717, 0.2791277601356383], 
reward next is 0.7209, 
noisyNet noise sample is [array([0.20876451], dtype=float32), 1.0688902]. 
=============================================
[2019-03-23 12:56:40,099] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[54.41926 ]
 [55.46991 ]
 [56.034096]
 [56.562828]
 [57.146217]], R is [[51.55527878]
 [51.03972626]
 [50.5655899 ]
 [50.72575378]
 [50.96344757]].
[2019-03-23 12:56:47,853] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.9999344e-01 0.0000000e+00 6.6116800e-06 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 12:56:47,863] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2251
[2019-03-23 12:56:47,869] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.13333333333333, 93.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6271135156520061, 6.911199999999999, 6.9112, 77.32846344354104, 363916.1932793955, 363916.1932793958, 116406.3066047755], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6751200.0000, 
sim time next is 6751800.0000, 
raw observation next is [17.15, 93.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6170270716887809, 6.911199999999999, 6.9112, 77.32846344354104, 358063.4371847561, 358063.4371847563, 115539.8784948211], 
processed observation next is [1.0, 0.13043478260869565, 0.41590909090909084, 0.935, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.45289581669825846, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13261608784620596, 0.13261608784620602, 0.2818045816946856], 
reward next is 0.7182, 
noisyNet noise sample is [array([-0.5951881], dtype=float32), -1.456699]. 
=============================================
[2019-03-23 12:56:59,597] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.1277842e-03 6.2216048e-32 9.9287224e-01 1.5475528e-16 1.6525021e-25], sum to 1.0000
[2019-03-23 12:56:59,605] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6137
[2019-03-23 12:56:59,613] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.7, 58.0, 1.0, 2.0, 0.2513511493889105, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5086847720638485, 6.911199999999999, 6.9112, 77.32846344354104, 572854.9781791783, 572854.9781791787, 179501.8778400604], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6969600.0000, 
sim time next is 6970200.0000, 
raw observation next is [27.7, 58.5, 1.0, 2.0, 0.2522933611952966, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5106696387300338, 6.911199999999999, 6.9112, 77.32846344354104, 574886.1152643797, 574886.11526438, 179873.0542863822], 
processed observation next is [0.0, 0.6956521739130435, 0.8954545454545454, 0.585, 1.0, 1.0, 0.06536670149412074, 0.0, 1.0, -0.25, 1.0, 1.0, 0.30095662675719115, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21292078343125173, 0.21292078343125184, 0.4387147665521517], 
reward next is 0.5613, 
noisyNet noise sample is [array([0.04432131], dtype=float32), -0.73226184]. 
=============================================
[2019-03-23 12:57:01,349] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.2680933e-06 0.0000000e+00 9.9999774e-01 3.3634730e-19 1.1086196e-32], sum to 1.0000
[2019-03-23 12:57:01,357] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7239
[2019-03-23 12:57:01,361] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.13333333333333, 96.66666666666667, 1.0, 2.0, 0.2473145518086493, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4960026451704355, 6.911200000000001, 6.9112, 77.32846344354104, 563780.6078286021, 563780.6078286018, 174223.7585004785], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7010400.0000, 
sim time next is 7011000.0000, 
raw observation next is [19.95, 96.5, 1.0, 2.0, 0.2319329661588301, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4641988688860151, 6.9112, 6.9112, 77.32846344354104, 528285.5320336586, 528285.5320336586, 170296.4157881632], 
processed observation next is [1.0, 0.13043478260869565, 0.5431818181818181, 0.965, 1.0, 1.0, 0.03991620769853762, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2345698126943073, 0.0, 0.0, 0.5084288129206541, 0.19566130816061428, 0.19566130816061428, 0.4153571116784468], 
reward next is 0.5846, 
noisyNet noise sample is [array([1.9348469], dtype=float32), 0.39230072]. 
=============================================
[2019-03-23 12:57:01,378] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[42.386105]
 [42.498096]
 [42.5126  ]
 [42.837673]
 [43.188156]], R is [[42.38220596]
 [42.53345108]
 [42.66763687]
 [42.81204987]
 [42.95771027]].
[2019-03-23 12:57:02,805] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.3834352e-09 0.0000000e+00 1.0000000e+00 5.0249012e-24 0.0000000e+00], sum to 1.0000
[2019-03-23 12:57:02,815] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4589
[2019-03-23 12:57:02,818] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.8, 97.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3913627777989347, 6.9112, 6.9112, 77.32846344354104, 448347.5937122921, 448347.5937122921, 160430.3786062683], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7027800.0000, 
sim time next is 7028400.0000, 
raw observation next is [18.8, 97.0, 1.0, 2.0, 0.2467216575814602, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4870732045273396, 6.9112, 6.9112, 77.32846344354104, 557922.7358343714, 557922.7358343714, 169705.6345967582], 
processed observation next is [1.0, 0.34782608695652173, 0.49090909090909096, 0.97, 1.0, 1.0, 0.05840207197682523, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2672474350390566, 0.0, 0.0, 0.5084288129206541, 0.20663805030902646, 0.20663805030902646, 0.4139161819433127], 
reward next is 0.5861, 
noisyNet noise sample is [array([1.4533743], dtype=float32), 0.70533156]. 
=============================================
[2019-03-23 12:57:05,643] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 12:57:05,645] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:57:05,647] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:57:05,650] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:57:05,650] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:57:05,650] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:57:05,651] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:57:05,652] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:57:05,652] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:57:05,653] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:57:05,653] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:57:05,668] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run34
[2019-03-23 12:57:05,691] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run34
[2019-03-23 12:57:05,693] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run34
[2019-03-23 12:57:05,693] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run34
[2019-03-23 12:57:05,694] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run34
[2019-03-23 12:57:19,293] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.20450297]
[2019-03-23 12:57:19,295] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.2, 41.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7236053598871182, 7.203684392638925, 6.9112, 95.55245621972207, 531553.1937682588, 414173.2648534108, 134090.8908683459]
[2019-03-23 12:57:19,296] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:57:19,299] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.8128189e-01 7.7642324e-07 2.1831590e-01 3.9808435e-04 3.2812575e-06], sampled 0.06749801206303985
[2019-03-23 12:57:20,196] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.20450297]
[2019-03-23 12:57:20,197] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [29.63333333333333, 39.66666666666667, 1.0, 2.0, 0.6327043629442948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 720231.5770693328, 720231.5770693325, 158475.3110675587]
[2019-03-23 12:57:20,200] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:57:20,205] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.2470709e-01 8.2449253e-10 1.7528017e-01 1.2698160e-05 1.0791674e-08], sampled 0.7573781240096737
[2019-03-23 12:57:20,205] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 720231.5770693328 W.
[2019-03-23 12:57:40,386] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.20450297]
[2019-03-23 12:57:40,386] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.25, 86.0, 1.0, 2.0, 0.7930566408780994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769667301, 889500.7993768324, 889500.7993768324, 172708.3746974207]
[2019-03-23 12:57:40,387] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 12:57:40,391] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.7127123e-01 1.0893930e-06 2.2824284e-01 4.8041297e-04 4.3791556e-06], sampled 0.60139361748532
[2019-03-23 12:57:40,392] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 889500.7993768324 W.
[2019-03-23 12:57:44,766] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.20450297]
[2019-03-23 12:57:44,768] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.77193789166667, 84.28132210166666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7346634841989845, 7.329295872848215, 6.9112, 95.55183185796467, 590349.1277717517, 422559.8562915649, 133835.355060683]
[2019-03-23 12:57:44,770] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:57:44,772] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.8023160e-01 9.6312749e-07 2.1932098e-01 4.4254374e-04 3.9332808e-06], sampled 0.9007293729571884
[2019-03-23 12:58:01,626] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.20450297]
[2019-03-23 12:58:01,627] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.93333333333333, 52.83333333333334, 1.0, 2.0, 0.7723811121703394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 880055.7228033771, 880055.7228033767, 184915.6433577217]
[2019-03-23 12:58:01,628] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 12:58:01,632] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.26926172e-01 5.20149590e-10 1.73063740e-01 1.00720135e-05
 7.34034034e-09], sampled 0.08266371908730297
[2019-03-23 12:58:01,634] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 880055.7228033771 W.
[2019-03-23 12:58:02,732] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.20450297]
[2019-03-23 12:58:02,734] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.74839489, 66.372229655, 1.0, 2.0, 0.5244748347084528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 598237.3658022063, 598237.3658022063, 147128.8117012255]
[2019-03-23 12:58:02,736] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:58:02,742] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.9551488e-01 4.3271871e-08 2.0439029e-01 9.4476025e-05 2.9566669e-07], sampled 0.4867666136304938
[2019-03-23 12:58:02,743] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 598237.3658022063 W.
[2019-03-23 12:58:14,575] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.20450297]
[2019-03-23 12:58:14,576] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.11633937, 76.72869662, 1.0, 2.0, 0.56516024583288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 638746.4202456964, 638746.4202456961, 157548.4269858166]
[2019-03-23 12:58:14,578] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 12:58:14,580] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.9870665e-01 3.7514116e-08 2.0120563e-01 8.7494336e-05 2.6178051e-07], sampled 0.06416685292212188
[2019-03-23 12:58:14,581] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 638746.4202456964 W.
[2019-03-23 12:58:44,734] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 5196.4282 1872298110.3579 2046.0000
[2019-03-23 12:58:45,349] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 4922.3480 1782634743.4995 2552.0000
[2019-03-23 12:58:45,426] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 4717.4824 1773552413.0051 2726.0000
[2019-03-23 12:58:45,503] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 4740.9133 1805694896.9267 3039.0000
[2019-03-23 12:58:45,536] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 4870.8527 1763678269.4125 2618.0000
[2019-03-23 12:58:46,551] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 825000, evaluation results [825000.0, 5196.428231689767, 1872298110.3579144, 2046.0, 4870.852650521379, 1763678269.4125168, 2618.0, 4717.48239217406, 1773552413.0050604, 2726.0, 4740.913306632361, 1805694896.9266543, 3039.0, 4922.348046480753, 1782634743.4994786, 2552.0]
[2019-03-23 12:58:48,986] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.99931931e-01 0.00000000e+00 6.81019519e-05 1.13028710e-22
 1.07898645e-33], sum to 1.0000
[2019-03-23 12:58:48,993] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0788
[2019-03-23 12:58:48,998] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 57.0, 1.0, 2.0, 0.4667696366218832, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 519178.3826395639, 519178.3826395639, 128139.3322894466], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7129800.0000, 
sim time next is 7130400.0000, 
raw observation next is [23.1, 56.33333333333333, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7389726078803135, 7.141722874791995, 6.9112, 77.32783238728078, 501637.4065361157, 426768.9027980479, 128718.0659050498], 
processed observation next is [1.0, 0.5217391304347826, 0.6863636363636364, 0.5633333333333332, 0.0, 0.5, -0.25, 0.0, 1.0, -0.25, 1.0, 0.5, 0.6271037255433051, 0.023052287479199497, 0.0, 0.5084246637733544, 0.1857916320504132, 0.15806255659186957, 0.3139465022074385], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.2961816], dtype=float32), 0.97396725]. 
=============================================
[2019-03-23 12:58:53,907] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 1.2750604e-09 1.7381862e-28 1.8085851e-37], sum to 1.0000
[2019-03-23 12:58:53,912] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1518
[2019-03-23 12:58:53,920] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 874309.9470155789 W.
[2019-03-23 12:58:53,923] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.1, 44.0, 1.0, 2.0, 0.3974080170050207, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7545201861200191, 6.911199999999999, 6.9112, 77.32846344354104, 874309.9470155789, 874309.9470155792, 197214.8669200849], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7227000.0000, 
sim time next is 7227600.0000, 
raw observation next is [24.2, 44.33333333333334, 1.0, 2.0, 0.2558141799338854, 1.0, 1.0, 0.2558141799338854, 1.0, 2.0, 0.4932623793608316, 6.911199999999999, 6.9112, 77.3421103, 854125.8879404907, 854125.8879404911, 220392.67444892], 
processed observation next is [1.0, 0.6521739130434783, 0.7363636363636363, 0.4433333333333334, 1.0, 1.0, 0.06976772491735672, 1.0, 0.5, 0.06976772491735672, 1.0, 1.0, 0.2760891133726166, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.31634292145944104, 0.31634292145944115, 0.537543108412], 
reward next is 0.4625, 
noisyNet noise sample is [array([-0.31077376], dtype=float32), 0.22301601]. 
=============================================
[2019-03-23 12:58:57,533] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.00000000e+00 1.28207055e-33 3.11929260e-10 1.48086316e-20
 6.77858409e-31], sum to 1.0000
[2019-03-23 12:58:57,539] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1364
[2019-03-23 12:58:57,545] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 812389.9997429713 W.
[2019-03-23 12:58:57,554] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.21666666666667, 50.83333333333334, 1.0, 2.0, 0.3609061407447194, 1.0, 1.0, 0.3609061407447194, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 812389.9997429713, 812389.9997429713, 185407.334081468], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7300200.0000, 
sim time next is 7300800.0000, 
raw observation next is [24.4, 50.0, 1.0, 2.0, 0.2462645134641035, 1.0, 2.0, 0.2462645134641035, 1.0, 1.0, 0.4845269462583836, 6.911199999999999, 6.9112, 77.3421103, 833801.5310553537, 833801.531055354, 224496.1844087383], 
processed observation next is [1.0, 0.5217391304347826, 0.7454545454545454, 0.5, 1.0, 1.0, 0.057830641830129356, 1.0, 1.0, 0.057830641830129356, 1.0, 0.5, 0.2636099232262623, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.30881538187235325, 0.30881538187235336, 0.5475516692896056], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.4668578], dtype=float32), 0.46562278]. 
=============================================
[2019-03-23 12:58:59,242] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 9.2809298e-09 1.1137939e-24 0.0000000e+00], sum to 1.0000
[2019-03-23 12:58:59,250] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0021
[2019-03-23 12:58:59,255] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.95, 60.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6490974879490008, 6.911199999999999, 6.9112, 77.32846344354104, 375963.2602851677, 375963.260285168, 118888.5101055149], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7332600.0000, 
sim time next is 7333200.0000, 
raw observation next is [21.8, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6516004721680507, 6.911199999999999, 6.9112, 77.32846344354104, 377338.1719023077, 377338.1719023079, 119173.4242340317], 
processed observation next is [1.0, 0.9130434782608695, 0.6272727272727273, 0.62, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5022863888115011, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1397548784823362, 0.13975487848233625, 0.29066688837568705], 
reward next is 0.7093, 
noisyNet noise sample is [array([-0.2291633], dtype=float32), 0.16870925]. 
=============================================
[2019-03-23 12:59:02,820] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9999988e-01 2.9194063e-23 8.6647027e-08 4.3884044e-15 7.5788735e-21], sum to 1.0000
[2019-03-23 12:59:02,831] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8678
[2019-03-23 12:59:02,838] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1608351.999954019 W.
[2019-03-23 12:59:02,844] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.2, 60.0, 1.0, 2.0, 0.4751825849697025, 1.0, 2.0, 0.4751825849697025, 1.0, 2.0, 0.9608940022477843, 6.9112, 6.9112, 77.3421103, 1608351.999954019, 1608351.999954019, 344145.2367778868], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7405200.0000, 
sim time next is 7405800.0000, 
raw observation next is [26.18333333333333, 64.0, 1.0, 2.0, 0.2568920835110177, 1.0, 2.0, 0.2568920835110177, 1.0, 2.0, 0.5202806914987624, 6.911199999999999, 6.9112, 77.3421103, 873672.4928013984, 873672.4928013987, 246358.8960733281], 
processed observation next is [1.0, 0.7391304347826086, 0.8265151515151513, 0.64, 1.0, 1.0, 0.07111510438877214, 1.0, 1.0, 0.07111510438877214, 1.0, 1.0, 0.31468670214108924, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.32358240474125866, 0.32358240474125877, 0.60087535627641], 
reward next is 0.3991, 
noisyNet noise sample is [array([0.84668684], dtype=float32), -1.900603]. 
=============================================
[2019-03-23 12:59:05,646] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 2.9692510e-16 2.4894684e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 12:59:05,650] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9491
[2019-03-23 12:59:05,654] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.68333333333333, 86.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7163895750272974, 6.935723821992702, 6.9112, 77.32836711735617, 420418.8956154948, 412454.0697527709, 127256.0311091064], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7459800.0000, 
sim time next is 7460400.0000, 
raw observation next is [19.96666666666667, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7242516533243105, 6.994162545535721, 6.9112, 77.32821269915091, 443459.4143594013, 416514.9638169546, 128436.7990083543], 
processed observation next is [0.0, 0.34782608695652173, 0.5439393939393941, 0.86, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6060737904633008, 0.00829625455357208, 0.0, 0.508427164295207, 0.16424422754051898, 0.15426480141368687, 0.31326048538622997], 
reward next is 0.2719, 
noisyNet noise sample is [array([-1.1096565], dtype=float32), 0.9334458]. 
=============================================
[2019-03-23 12:59:09,667] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.8881295e-06 1.5440514e-32 9.9999309e-01 1.4940404e-19 2.2098479e-30], sum to 1.0000
[2019-03-23 12:59:09,673] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6577
[2019-03-23 12:59:09,683] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.51666666666667, 90.5, 1.0, 2.0, 0.2311087854248021, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4654518032744403, 6.9112, 6.9112, 77.32846344354104, 527374.0844360064, 527374.0844360064, 172278.5458254451], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7528200.0000, 
sim time next is 7528800.0000, 
raw observation next is [21.43333333333334, 91.0, 1.0, 2.0, 0.2309951457790461, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4651609212615749, 6.9112, 6.9112, 77.32846344354104, 527105.3660764828, 527105.3660764828, 172201.1532073649], 
processed observation next is [0.0, 0.13043478260869565, 0.6106060606060609, 0.91, 1.0, 1.0, 0.0387439322238076, 0.0, 1.0, -0.25, 1.0, 1.0, 0.23594417323082129, 0.0, 0.0, 0.5084288129206541, 0.1952242096579566, 0.1952242096579566, 0.42000281270089], 
reward next is 0.5800, 
noisyNet noise sample is [array([0.59973276], dtype=float32), -0.4764797]. 
=============================================
[2019-03-23 12:59:10,113] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.3960469e-03 1.4140517e-22 9.9760395e-01 7.6335334e-16 3.0812431e-21], sum to 1.0000
[2019-03-23 12:59:10,120] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6356
[2019-03-23 12:59:10,125] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.16666666666666, 95.0, 1.0, 2.0, 0.215699943530912, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4315486142716716, 6.9112, 6.9112, 77.32846344354104, 491216.2389101233, 491216.2389101233, 166978.4700351718], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7540800.0000, 
sim time next is 7541400.0000, 
raw observation next is [20.08333333333334, 95.5, 1.0, 2.0, 0.2149396820175302, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4299200437755822, 6.9112, 6.9112, 77.32846344354104, 489432.3618173103, 489432.3618173103, 166763.0861028127], 
processed observation next is [0.0, 0.2608695652173913, 0.5492424242424245, 0.955, 1.0, 1.0, 0.018674602521912727, 0.0, 1.0, -0.25, 1.0, 1.0, 0.185600062536546, 0.0, 0.0, 0.5084288129206541, 0.18127124511752232, 0.18127124511752232, 0.40673923439710413], 
reward next is 0.5933, 
noisyNet noise sample is [array([-1.0096279], dtype=float32), 1.6252455]. 
=============================================
[2019-03-23 12:59:15,840] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.9395044e-06 7.6682843e-19 9.9999702e-01 3.1888471e-11 3.5953021e-18], sum to 1.0000
[2019-03-23 12:59:15,846] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1566
[2019-03-23 12:59:15,850] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.05, 68.5, 1.0, 2.0, 0.6417327641959603, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9762444084390934, 6.9112, 6.9112, 77.32846344353972, 1278203.182745549, 1278203.182745549, 282599.9901038036], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7644600.0000, 
sim time next is 7645200.0000, 
raw observation next is [26.23333333333333, 67.33333333333333, 1.0, 2.0, 0.640675420071869, 0.0, 2.0, 0.0, 1.0, 2.0, 0.976183124052992, 6.911199999999999, 6.9112, 77.32846344354104, 1277040.645706423, 1277040.645706424, 282392.9728008267], 
processed observation next is [1.0, 0.4782608695652174, 0.8287878787878786, 0.6733333333333333, 1.0, 1.0, 0.5508442750898361, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9659758915042744, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4729780169283048, 0.4729780169283052, 0.6887633482946993], 
reward next is 0.3112, 
noisyNet noise sample is [array([1.473737], dtype=float32), 0.33544657]. 
=============================================
[2019-03-23 12:59:21,863] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.5431793e-01 3.9512970e-04 5.2836066e-01 1.6535018e-02 3.9131328e-04], sum to 1.0000
[2019-03-23 12:59:21,871] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9038
[2019-03-23 12:59:21,874] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.8, 57.0, 1.0, 1.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 286061.3065405969, 286061.3065405966, 114011.1728955244], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7762200.0000, 
sim time next is 7762800.0000, 
raw observation next is [18.8, 57.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 286368.2361327064, 286368.2361327061, 109322.7777697105], 
processed observation next is [1.0, 0.8695652173913043, 0.49090909090909096, 0.5700000000000001, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10606230967878015, 0.10606230967878004, 0.2666409213895378], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2594912], dtype=float32), 1.027192]. 
=============================================
[2019-03-23 12:59:26,674] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:59:26,677] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:59:26,692] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run5
[2019-03-23 12:59:30,770] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6636182e-05 5.4902389e-21 9.9998331e-01 9.2593830e-16 6.6990039e-19], sum to 1.0000
[2019-03-23 12:59:30,780] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7740
[2019-03-23 12:59:30,786] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.65, 88.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3938471940955779, 6.9112, 6.9112, 77.32846344354104, 451265.1186871433, 451265.1186871433, 160700.8413737154], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7943400.0000, 
sim time next is 7944000.0000, 
raw observation next is [19.56666666666667, 86.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3782307861955418, 6.9112, 6.9112, 77.32846344354104, 434271.9207657637, 434271.9207657637, 157829.3305957211], 
processed observation next is [1.0, 0.9565217391304348, 0.5257575757575759, 0.86, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.11175826599363116, 0.0, 0.0, 0.5084288129206541, 0.16084145213546802, 0.16084145213546802, 0.38494958681883196], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7386679], dtype=float32), -1.4055777]. 
=============================================
[2019-03-23 12:59:30,808] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[50.575935]
 [50.681114]
 [50.41706 ]
 [50.50236 ]
 [50.638657]], R is [[49.98584747]
 [49.48598862]
 [49.59395218]
 [49.69626236]
 [49.79409027]].
[2019-03-23 12:59:31,559] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.1459968e-04 9.7610298e-10 9.9918276e-01 2.6191856e-06 1.0560195e-08], sum to 1.0000
[2019-03-23 12:59:31,559] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5722
[2019-03-23 12:59:31,561] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.5, 45.0, 1.0, 2.0, 0.2746470345416655, 0.0, 2.0, 0.0, 1.0, 2.0, 0.512705844911112, 6.9112, 6.9112, 77.32846344354104, 596618.3193232376, 596618.3193232376, 158697.1847268001], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 135000.0000, 
sim time next is 135600.0000, 
raw observation next is [22.66666666666666, 44.66666666666667, 1.0, 2.0, 0.2969917551620955, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5544185431170792, 6.9112, 6.9112, 77.32846344354104, 645190.1837516251, 645190.1837516251, 164876.821740436], 
processed observation next is [1.0, 0.5652173913043478, 0.6666666666666664, 0.4466666666666667, 1.0, 1.0, 0.1212396939526194, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3634550615958274, 0.0, 0.0, 0.5084288129206541, 0.23895932731541672, 0.23895932731541672, 0.4021385896108195], 
reward next is 0.5979, 
noisyNet noise sample is [array([1.7744893], dtype=float32), 0.47218528]. 
=============================================
[2019-03-23 12:59:31,845] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:59:31,845] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:59:31,848] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run5
[2019-03-23 12:59:31,916] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:59:31,917] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:59:31,919] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run5
[2019-03-23 12:59:32,025] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:59:32,026] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:59:32,029] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run5
[2019-03-23 12:59:32,050] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:59:32,051] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:59:32,055] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run5
[2019-03-23 12:59:32,077] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:59:32,078] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:59:32,079] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:59:32,080] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:59:32,085] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run5
[2019-03-23 12:59:32,105] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:59:32,106] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:59:32,111] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run5
[2019-03-23 12:59:32,138] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:59:32,138] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:59:32,138] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:59:32,140] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:59:32,141] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:59:32,142] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:59:32,142] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:59:32,143] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:59:32,143] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:59:32,143] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:59:32,147] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run5
[2019-03-23 12:59:32,179] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:59:32,179] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:59:32,179] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:59:32,184] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 12:59:32,185] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:59:32,184] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:59:32,188] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run5
[2019-03-23 12:59:32,189] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run5
[2019-03-23 12:59:32,190] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run5
[2019-03-23 12:59:32,194] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run5
[2019-03-23 12:59:32,194] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run5
[2019-03-23 12:59:32,195] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run5
[2019-03-23 12:59:32,195] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run5
[2019-03-23 12:59:32,608] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run5
[2019-03-23 12:59:34,319] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9887568e-01 4.2288069e-11 1.1243391e-03 4.6069459e-08 8.9546330e-12], sum to 1.0000
[2019-03-23 12:59:34,324] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1163
[2019-03-23 12:59:34,328] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.5, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7206914423616623, 7.012369397065174, 6.9112, 77.32800971773968, 450637.8917602489, 417780.3336587956, 125576.8067880371], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 9000.0000, 
sim time next is 9600.0000, 
raw observation next is [17.43333333333333, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.712454696777049, 6.948740883363427, 6.9112, 77.3282420214371, 425551.2020797116, 413358.7259191241, 124460.6022240306], 
processed observation next is [1.0, 0.08695652173913043, 0.42878787878787866, 0.9, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5892209953957843, 0.003754088336342676, 0.0, 0.5084273570870265, 0.1576115563258191, 0.1530958244144904, 0.3035624444488551], 
reward next is 0.5087, 
noisyNet noise sample is [array([-1.2768997], dtype=float32), 0.7620415]. 
=============================================
[2019-03-23 12:59:37,199] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 12:59:37,201] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 12:59:37,203] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:59:37,205] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 12:59:37,207] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:59:37,207] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 12:59:37,208] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:59:37,209] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 12:59:37,210] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 12:59:37,213] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:59:37,213] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 12:59:37,232] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run35
[2019-03-23 12:59:37,232] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run35
[2019-03-23 12:59:37,292] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run35
[2019-03-23 12:59:37,318] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run35
[2019-03-23 12:59:37,320] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run35
[2019-03-23 12:59:51,326] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.24312113]
[2019-03-23 12:59:51,327] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.0, 100.0, 1.0, 1.0, 0.3865247938549289, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.3281194613232, 419749.3837875607, 419749.383787561, 103353.3820063213]
[2019-03-23 12:59:51,328] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 12:59:51,334] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 1.8043860e-17 4.9841834e-08 1.5319274e-12 8.3944439e-17], sampled 0.6752810925503124
[2019-03-23 12:59:52,391] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.24312113]
[2019-03-23 12:59:52,393] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.207154155, 94.77130844999999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4544282783462103, 6.9112, 6.9112, 95.55338769695034, 264297.3523301671, 264297.3523301671, 91327.99881268447]
[2019-03-23 12:59:52,395] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 12:59:52,397] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 2.3011444e-26 5.6048508e-12 8.5264661e-19 2.9698604e-25], sampled 0.34619691268340436
[2019-03-23 13:00:09,050] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.24312113]
[2019-03-23 13:00:09,053] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.1, 50.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4679450292521802, 6.911199999999999, 6.9112, 95.55338769695034, 272160.5300095143, 272160.5300095147, 74720.87816279878]
[2019-03-23 13:00:09,054] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:00:09,056] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0000000e+00 2.6044353e-27 2.0276285e-12 1.7578921e-19 3.6190760e-26], sampled 0.7538760852699319
[2019-03-23 13:00:40,912] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.24312113]
[2019-03-23 13:00:40,914] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.21524361, 86.17848786333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8596191947619787, 8.493987334746928, 6.9112, 95.54840981107024, 1135498.409439645, 500320.5952421261, 119267.5766512093]
[2019-03-23 13:00:40,915] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:00:40,916] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0000000e+00 2.9504216e-21 1.0615294e-09 3.3896865e-15 2.1479221e-20], sampled 0.49284117248793746
[2019-03-23 13:00:40,918] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1135498.409439645 W.
[2019-03-23 13:00:51,259] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.24312113]
[2019-03-23 13:00:51,260] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.8, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7481302489852981, 7.178585819492654, 6.9112, 77.32766387748735, 516171.1396934523, 429330.5924370475, 131735.4651324259]
[2019-03-23 13:00:51,261] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:00:51,265] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 1.2338190e-21 6.9149120e-10 1.7783050e-15 9.1779276e-21], sampled 0.5324083429640841
[2019-03-23 13:01:16,039] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6553.6644 1698673417.8971 2957.0000
[2019-03-23 13:01:16,533] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6328.7217 1723294598.4314 3425.0000
[2019-03-23 13:01:16,551] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6861.5582 1793126162.8957 2409.0000
[2019-03-23 13:01:16,572] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6294.9961 1685630448.6673 3228.0000
[2019-03-23 13:01:16,690] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6481.3696 1678926429.2735 3058.0000
[2019-03-23 13:01:17,705] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 850000, evaluation results [850000.0, 6861.558152885365, 1793126162.8956532, 2409.0, 6481.3695731125645, 1678926429.2734938, 3058.0, 6294.9960618483565, 1685630448.6673346, 3228.0, 6328.721692698646, 1723294598.4313502, 3425.0, 6553.664352543652, 1698673417.8970604, 2957.0]
[2019-03-23 13:01:20,064] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 3.6551291e-22 1.9585498e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 13:01:20,073] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6160
[2019-03-23 13:01:20,077] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.33333333333333, 81.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3905047147535767, 6.9112, 6.9112, 77.32846344354104, 227122.234414299, 227122.234414299, 67751.76035514318], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 112200.0000, 
sim time next is 112800.0000, 
raw observation next is [14.66666666666667, 80.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3952752318756739, 6.911199999999999, 6.9112, 77.32846344354104, 229897.4802037076, 229897.4802037079, 69108.29509190212], 
processed observation next is [1.0, 0.30434782608695654, 0.30303030303030315, 0.8033333333333335, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.13610747410810564, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08514721489026207, 0.08514721489026218, 0.16855681729732225], 
reward next is 0.8314, 
noisyNet noise sample is [array([-1.6672916], dtype=float32), -0.55743235]. 
=============================================
[2019-03-23 13:01:24,035] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 5.0820262e-14 1.9899365e-30 4.0419078e-38], sum to 1.0000
[2019-03-23 13:01:24,046] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2538
[2019-03-23 13:01:24,055] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [13.5, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3735918275749404, 6.911199999999998, 6.9112, 77.32846344354104, 217283.2989064658, 217283.2989064664, 68224.22813078515], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 196200.0000, 
sim time next is 196800.0000, 
raw observation next is [13.66666666666667, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3830581045293411, 6.911199999999999, 6.9112, 77.32846344354104, 222790.2045410514, 222790.2045410517, 69950.22344511557], 
processed observation next is [0.0, 0.2608695652173913, 0.25757575757575774, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.11865443504191585, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08251489057075978, 0.08251489057075989, 0.17061030108564773], 
reward next is 0.8294, 
noisyNet noise sample is [array([-0.41006416], dtype=float32), -0.42943385]. 
=============================================
[2019-03-23 13:01:24,283] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 4.2467534e-24 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 13:01:24,289] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4318
[2019-03-23 13:01:24,292] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.0, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4583349644414045, 6.911199999999998, 6.9112, 77.32846344354104, 266583.9341575195, 266583.9341575201, 86041.20072034064], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 201600.0000, 
sim time next is 202200.0000, 
raw observation next is [17.0, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4620922308461395, 6.911199999999999, 6.9112, 77.32846344354104, 268769.8979068807, 268769.8979068809, 86412.13676495841], 
processed observation next is [0.0, 0.34782608695652173, 0.4090909090909091, 0.77, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2315603297801993, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09954440663217803, 0.0995444066321781, 0.2107613091828254], 
reward next is 0.7892, 
noisyNet noise sample is [array([1.873286], dtype=float32), 2.4979186]. 
=============================================
[2019-03-23 13:01:26,307] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 3.5474129e-18 2.1921545e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 13:01:26,314] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0469
[2019-03-23 13:01:26,318] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.5, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5406624188443013, 6.911199999999999, 6.9112, 77.32846344354104, 314483.9948876718, 314483.9948876721, 107286.2035783888], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 239400.0000, 
sim time next is 240000.0000, 
raw observation next is [16.66666666666666, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5527952783156465, 6.9112, 6.9112, 77.32846344354104, 321518.8082313969, 321518.8082313969, 109851.3579058976], 
processed observation next is [0.0, 0.782608695652174, 0.39393939393939365, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.36113611187949496, 0.0, 0.0, 0.5084288129206541, 0.11908104008570256, 0.11908104008570256, 0.2679301412338966], 
reward next is 0.7321, 
noisyNet noise sample is [array([0.74941885], dtype=float32), -3.265511]. 
=============================================
[2019-03-23 13:01:26,347] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[78.417656]
 [78.43228 ]
 [78.40788 ]
 [78.35775 ]
 [78.22512 ]], R is [[78.3299408 ]
 [78.28496552]
 [78.24744415]
 [78.21656036]
 [78.19106293]].
[2019-03-23 13:01:37,920] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.00000000e+00 7.64648499e-27 2.35794523e-10 4.89966322e-19
 1.23503555e-26], sum to 1.0000
[2019-03-23 13:01:37,925] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2434
[2019-03-23 13:01:37,929] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6732660675254271, 6.9112, 6.9112, 77.32846344354104, 391645.8560435199, 391645.8560435199, 102830.9834481085], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 468000.0000, 
sim time next is 468600.0000, 
raw observation next is [14.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7160468109083746, 6.994727020363462, 6.9112, 77.32825440364752, 443681.9337384286, 416554.1392814019, 107546.6312692576], 
processed observation next is [1.0, 0.43478260869565216, 0.2727272727272727, 1.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5943525870119638, 0.008352702036346216, 0.0, 0.5084274384991258, 0.16432664212534392, 0.15427931084496366, 0.26230885675428683], 
reward next is 0.3201, 
noisyNet noise sample is [array([-0.2904079], dtype=float32), -1.536795]. 
=============================================
[2019-03-23 13:01:43,678] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.00000000e+00 2.27098818e-19 4.10982670e-09 1.01368946e-13
 1.23635098e-18], sum to 1.0000
[2019-03-23 13:01:43,684] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9997
[2019-03-23 13:01:43,690] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.5, 66.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6785344856210834, 6.911199999999999, 6.9112, 77.32846344354104, 391648.9620024192, 391648.9620024195, 122662.4771918692], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 581400.0000, 
sim time next is 582000.0000, 
raw observation next is [21.33333333333334, 67.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6762031227127119, 6.9112, 6.9112, 77.32846344354104, 390623.2367733146, 390623.2367733146, 122198.1810478927], 
processed observation next is [1.0, 0.7391304347826086, 0.6060606060606063, 0.6733333333333335, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5374330324467314, 0.0, 0.0, 0.5084288129206541, 0.14467527287900542, 0.14467527287900542, 0.29804434401925045], 
reward next is 0.7020, 
noisyNet noise sample is [array([0.00201675], dtype=float32), -0.034433927]. 
=============================================
[2019-03-23 13:01:43,703] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[29.466022]
 [28.470781]
 [28.14112 ]
 [28.14553 ]
 [28.22001 ]], R is [[30.37272263]
 [30.76981926]
 [30.46212196]
 [30.76133156]
 [31.10504532]].
[2019-03-23 13:01:47,454] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 2.5208480e-29 7.8455614e-15 2.6211167e-22 7.4174989e-29], sum to 1.0000
[2019-03-23 13:01:47,458] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0785
[2019-03-23 13:01:47,471] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 811480.0300886779 W.
[2019-03-23 13:01:47,476] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 55.00000000000001, 1.0, 2.0, 0.3583069316136249, 1.0, 2.0, 0.3583069316136249, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846118915778, 811480.0300886779, 811480.0300886782, 187912.6282808149], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 652800.0000, 
sim time next is 653400.0000, 
raw observation next is [24.0, 55.5, 1.0, 2.0, 0.3708254898633386, 1.0, 2.0, 0.3708254898633386, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846342958622, 840058.2779987875, 840058.2779987875, 190244.3359820115], 
processed observation next is [1.0, 0.5652173913043478, 0.7272727272727273, 0.555, 1.0, 1.0, 0.2135318623291732, 1.0, 1.0, 0.2135318623291732, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288128289023, 0.3111326955551065, 0.3111326955551065, 0.46401057556588166], 
reward next is 0.5360, 
noisyNet noise sample is [array([0.34919348], dtype=float32), 0.39762968]. 
=============================================
[2019-03-23 13:01:47,960] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.00000000e+00 1.23226815e-19 3.81416365e-09 1.10463505e-13
 6.29248894e-20], sum to 1.0000
[2019-03-23 13:01:47,965] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6081
[2019-03-23 13:01:47,975] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 746562.7509953226 W.
[2019-03-23 13:01:47,979] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.33333333333334, 65.0, 1.0, 2.0, 0.2198020552755254, 1.0, 1.0, 0.2198020552755254, 1.0, 2.0, 0.4347446461189892, 6.9112, 6.9112, 77.3421103, 746562.7509953226, 746562.7509953226, 219788.1122062554], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 642000.0000, 
sim time next is 642600.0000, 
raw observation next is [22.5, 63.0, 1.0, 2.0, 0.3363082062056359, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6595593363842632, 6.9112, 6.9112, 77.32846344354104, 757467.567139991, 757467.567139991, 189331.4829393494], 
processed observation next is [1.0, 0.43478260869565216, 0.6590909090909091, 0.63, 1.0, 1.0, 0.17038525775704486, 0.0, 0.5, -0.25, 1.0, 1.0, 0.5136561948346619, 0.0, 0.0, 0.5084288129206541, 0.28054354338518184, 0.28054354338518184, 0.4617841047301205], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.15032688], dtype=float32), 0.34238923]. 
=============================================
[2019-03-23 13:01:58,643] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6157203e-10 7.2439912e-09 1.0000000e+00 4.7735263e-08 1.0606824e-11], sum to 1.0000
[2019-03-23 13:01:58,649] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3109
[2019-03-23 13:01:58,656] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.33333333333333, 67.66666666666667, 1.0, 2.0, 0.2430048412895217, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4908454520386676, 6.9112, 6.9112, 77.32846344354104, 554481.0228170227, 554481.0228170227, 176238.283179647], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 852000.0000, 
sim time next is 852600.0000, 
raw observation next is [25.16666666666667, 68.33333333333333, 1.0, 2.0, 0.2419665910446173, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4886291782556627, 6.9112, 6.9112, 77.32846344354104, 552142.1769867184, 552142.1769867184, 175871.829590168], 
processed observation next is [0.0, 0.8695652173913043, 0.7803030303030305, 0.6833333333333332, 1.0, 1.0, 0.0524582388057716, 0.0, 1.0, -0.25, 1.0, 1.0, 0.26947025465094676, 0.0, 0.0, 0.5084288129206541, 0.2044971025876735, 0.2044971025876735, 0.42895568192723904], 
reward next is 0.5710, 
noisyNet noise sample is [array([-1.8342352], dtype=float32), -0.0104511045]. 
=============================================
[2019-03-23 13:02:03,346] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.8268203e-18 1.4306046e-15 1.0000000e+00 6.5024881e-11 7.0318663e-20], sum to 1.0000
[2019-03-23 13:02:03,357] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9843
[2019-03-23 13:02:03,367] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 96.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3838059386679022, 6.911199999999999, 6.9112, 77.32846344354104, 439558.2539451619, 439558.2539451622, 159539.7881029648], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 955200.0000, 
sim time next is 955800.0000, 
raw observation next is [19.0, 97.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3866691353713458, 6.9112, 6.9112, 77.32846344354104, 442564.1240064517, 442564.1240064517, 160157.455280397], 
processed observation next is [1.0, 0.043478260869565216, 0.5, 0.97, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.123813050530494, 0.0, 0.0, 0.5084288129206541, 0.16391263852090804, 0.16391263852090804, 0.39062793970828535], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.70384544], dtype=float32), -1.1993946]. 
=============================================
[2019-03-23 13:02:06,296] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 13:02:06,297] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:02:06,298] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:02:06,300] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:02:06,302] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:02:06,303] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:02:06,305] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:02:06,307] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:02:06,308] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:02:06,309] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:02:06,310] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:02:06,328] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run36
[2019-03-23 13:02:06,353] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run36
[2019-03-23 13:02:06,380] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run36
[2019-03-23 13:02:06,382] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run36
[2019-03-23 13:02:06,382] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run36
[2019-03-23 13:02:35,412] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.26540726]
[2019-03-23 13:02:35,415] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.11666666666667, 66.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 272369.2770332058, 272369.2770332058, 115042.3344679077]
[2019-03-23 13:02:35,417] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:02:35,421] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.0534512e-09 9.7514351e-07 9.9999797e-01 1.0079091e-06 7.5361040e-10], sampled 0.3344748496434401
[2019-03-23 13:02:43,122] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.26540726]
[2019-03-23 13:02:43,123] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.75, 99.83333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3141832739700625, 6.9112, 6.9112, 77.32846344354104, 363412.814240325, 363412.814240325, 147260.4763640441]
[2019-03-23 13:02:43,125] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:02:43,129] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.5154173e-09 5.3063150e-07 9.9999881e-01 6.2118750e-07 3.8342893e-10], sampled 0.43717973912597985
[2019-03-23 13:02:45,700] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.26540726]
[2019-03-23 13:02:45,703] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.95431547, 63.40794209, 1.0, 2.0, 0.4670851202470697, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8725680953968116, 7.014102834778203, 6.9112, 95.55297765085133, 1062355.607536443, 1021058.383995005, 248201.2365155914]
[2019-03-23 13:02:45,704] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:02:45,708] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.7008123e-11 2.3500455e-08 1.0000000e+00 3.3896534e-08 5.5516104e-12], sampled 0.20171229515049793
[2019-03-23 13:02:53,590] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.26540726]
[2019-03-23 13:02:53,593] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.0546268, 89.09054250666667, 1.0, 2.0, 0.3037652969719687, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6143700510798472, 6.911200000000001, 6.9112, 95.55338769695034, 685088.6196806193, 685088.619680619, 201945.2606997733]
[2019-03-23 13:02:53,596] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:02:53,599] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5274297e-10 5.5320768e-08 9.9999988e-01 7.4039797e-08 1.7166829e-11], sampled 0.4370014004093902
[2019-03-23 13:03:06,406] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.26540726]
[2019-03-23 13:03:06,407] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.63333333333333, 80.0, 1.0, 2.0, 0.2953175939631829, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5972551925504783, 6.911200000000001, 6.9112, 95.55338769695034, 665935.0143652053, 665935.014365205, 199498.6351018102]
[2019-03-23 13:03:06,409] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:03:06,413] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.2326789e-10 7.3124745e-08 9.9999988e-01 9.5214872e-08 2.4712217e-11], sampled 0.7802376557951571
[2019-03-23 13:03:14,976] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.26540726]
[2019-03-23 13:03:14,977] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.06666666666667, 46.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 331448.9428636442, 331448.9428636442, 145736.2482205439]
[2019-03-23 13:03:14,981] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:03:14,983] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.9169080e-09 3.5233401e-07 9.9999928e-01 3.9373492e-07 1.9304128e-10], sampled 0.99522679222526
[2019-03-23 13:03:16,266] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.26540726]
[2019-03-23 13:03:16,266] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.72714663, 88.728018545, 1.0, 2.0, 0.2783724687770229, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5597985200068971, 6.911199999999999, 6.9112, 95.55338769695034, 635046.3754045893, 635046.3754045898, 187370.1851603093]
[2019-03-23 13:03:16,267] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:03:16,269] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.0922422e-10 1.3432263e-07 9.9999964e-01 1.6685105e-07 5.6178555e-11], sampled 0.9889142162541771
[2019-03-23 13:03:20,363] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.26540726]
[2019-03-23 13:03:20,363] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.8, 95.0, 1.0, 2.0, 0.2062320311463124, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4107434551265819, 6.911199999999999, 6.9112, 77.32846344354104, 468651.3240852981, 468651.3240852983, 164036.9304905983]
[2019-03-23 13:03:20,364] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:03:20,367] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.8385843e-09 3.4115888e-07 9.9999928e-01 3.9507472e-07 1.9651181e-10], sampled 0.5360494727827952
[2019-03-23 13:03:46,027] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3614.1741 2175305489.0345 245.0000
[2019-03-23 13:03:46,054] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3519.0325 2104095443.0865 178.0000
[2019-03-23 13:03:46,129] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3361.3356 2098067941.7008 179.0000
[2019-03-23 13:03:46,146] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3118.8146 2109022190.6825 368.0000
[2019-03-23 13:03:46,215] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2760.0075 2124051917.8006 757.0000
[2019-03-23 13:03:47,230] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 875000, evaluation results [875000.0, 3614.1740929847015, 2175305489.034501, 245.0, 3361.3355917968815, 2098067941.7008436, 179.0, 3519.032511138161, 2104095443.0864863, 178.0, 2760.0074854356503, 2124051917.8006039, 757.0, 3118.8146269445274, 2109022190.6824877, 368.0]
[2019-03-23 13:03:48,168] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0739616e-04 2.6898464e-04 9.9598217e-01 3.6337911e-03 7.6525093e-06], sum to 1.0000
[2019-03-23 13:03:48,177] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0433
[2019-03-23 13:03:48,185] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [13.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 211502.767524597, 211502.7675245973, 90689.94071623003], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1030800.0000, 
sim time next is 1031400.0000, 
raw observation next is [13.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 208716.2536055604, 208716.2536055601, 90151.49414987968], 
processed observation next is [1.0, 0.9565217391304348, 0.22727272727272727, 0.94, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07730231615020755, 0.07730231615020745, 0.21988169304848704], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.02492832], dtype=float32), -0.58316916]. 
=============================================
[2019-03-23 13:03:53,890] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 1.1843677e-29 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 13:03:53,898] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6044
[2019-03-23 13:03:53,902] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6657038810378997, 6.911199999999999, 6.9112, 77.32846344354104, 384502.2080792284, 384502.2080792287, 121231.5375821202], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1140000.0000, 
sim time next is 1140600.0000, 
raw observation next is [18.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6592659670559833, 6.911199999999999, 6.9112, 77.32846344354104, 380780.5437010573, 380780.5437010576, 120624.3376015741], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5132370957942619, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1410298310003916, 0.1410298310003917, 0.2942057014672539], 
reward next is 0.7058, 
noisyNet noise sample is [array([-0.6708579], dtype=float32), 1.276526]. 
=============================================
[2019-03-23 13:03:58,407] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9992669e-01 5.9708938e-08 7.2388000e-05 9.3953213e-07 5.0468163e-09], sum to 1.0000
[2019-03-23 13:03:58,414] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1709
[2019-03-23 13:03:58,421] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.0, 100.0, 1.0, 1.0, 0.4617893669971189, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32818884913938, 523789.3819607661, 523789.3819607664, 132671.9694138615], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1224600.0000, 
sim time next is 1225200.0000, 
raw observation next is [19.0, 100.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7796868993051972, 7.415354129993, 6.9112, 77.32683688284747, 609519.4069224021, 445783.9013925152, 136598.1941105111], 
processed observation next is [1.0, 0.17391304347826086, 0.5, 1.0, 0.0, 0.5, -0.25, 0.0, 1.0, -0.25, 1.0, 0.5, 0.6852669990074246, 0.05041541299930001, 0.0, 0.5084181184068135, 0.22574792848977857, 0.16510514866389453, 0.33316632709880756], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.15117747], dtype=float32), -0.5385598]. 
=============================================
[2019-03-23 13:04:01,700] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.0214175e-04 1.4606635e-04 9.9942684e-01 2.1573849e-04 9.1986149e-06], sum to 1.0000
[2019-03-23 13:04:01,709] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1831
[2019-03-23 13:04:01,711] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3441467457357272, 6.911200000000001, 6.9112, 77.32846344354104, 396699.1692578292, 396699.1692578289, 152047.7941452736], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1297200.0000, 
sim time next is 1297800.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3450837403238399, 6.9112, 6.9112, 77.32846344354104, 397779.0933291152, 397779.0933291152, 152161.0596327151], 
processed observation next is [1.0, 0.0, 0.45454545454545453, 0.94, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.06440534331977134, 0.0, 0.0, 0.5084288129206541, 0.1473255901218945, 0.1473255901218945, 0.371124535689549], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.33577904], dtype=float32), 1.2524918]. 
=============================================
[2019-03-23 13:04:02,121] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9996197e-01 5.6510503e-09 3.7881116e-05 9.3610090e-08 1.7457846e-10], sum to 1.0000
[2019-03-23 13:04:02,125] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4178
[2019-03-23 13:04:02,129] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6931342228877497, 6.911200000000001, 6.9112, 77.32846336570412, 400342.9748479412, 400342.9748479409, 123907.8719839663], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1294800.0000, 
sim time next is 1295400.0000, 
raw observation next is [18.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6897626011720633, 6.911199999999999, 6.9112, 77.32846344305923, 398396.7449102983, 398396.7449102986, 123571.539640419], 
processed observation next is [1.0, 1.0, 0.45454545454545453, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5568037159600905, -8.881784197001253e-17, 0.0, 0.5084288129174863, 0.14755434996677716, 0.14755434996677727, 0.30139399912297316], 
reward next is 0.6986, 
noisyNet noise sample is [array([-0.46981955], dtype=float32), 0.6009855]. 
=============================================
[2019-03-23 13:04:05,237] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8743278e-15 1.4406992e-13 1.0000000e+00 3.5695841e-12 1.0966483e-15], sum to 1.0000
[2019-03-23 13:04:05,247] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2732
[2019-03-23 13:04:05,252] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.66666666666667, 81.33333333333334, 1.0, 2.0, 0.2332291417135634, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4694991964676855, 6.9112, 6.9112, 77.32846344354104, 532178.6772826695, 532178.6772826695, 172537.6190351589], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1362000.0000, 
sim time next is 1362600.0000, 
raw observation next is [22.5, 83.0, 1.0, 2.0, 0.2329248382884374, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4690762184367673, 6.9112, 6.9112, 77.32846344354104, 531515.6041937559, 531515.6041937559, 172634.0190756872], 
processed observation next is [1.0, 0.782608695652174, 0.6590909090909091, 0.83, 1.0, 1.0, 0.041156047860546746, 0.0, 1.0, -0.25, 1.0, 1.0, 0.24153745490966758, 0.0, 0.0, 0.5084288129206541, 0.19685763118287256, 0.19685763118287256, 0.4210585831114322], 
reward next is 0.5789, 
noisyNet noise sample is [array([-0.63781416], dtype=float32), -0.23851365]. 
=============================================
[2019-03-23 13:04:17,786] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.9162154e-08 1.3338177e-06 9.9999869e-01 9.3416208e-09 9.3907071e-10], sum to 1.0000
[2019-03-23 13:04:17,801] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4138
[2019-03-23 13:04:17,805] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.33333333333333, 68.0, 1.0, 2.0, 0.4455268257126496, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9009451798880671, 6.9112, 6.9112, 77.32846344354104, 1016578.374138803, 1016578.374138803, 241521.5169617489], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1597200.0000, 
sim time next is 1597800.0000, 
raw observation next is [25.66666666666667, 66.5, 1.0, 2.0, 0.4547228709686733, 0.0, 2.0, 0.0, 1.0, 2.0, 0.919813859892787, 6.9112, 6.9112, 77.32846344354104, 1037360.607639762, 1037360.607639762, 245728.0785056389], 
processed observation next is [1.0, 0.4782608695652174, 0.8030303030303032, 0.665, 1.0, 1.0, 0.3184035887108416, 0.0, 1.0, -0.25, 1.0, 1.0, 0.88544837127541, 0.0, 0.0, 0.5084288129206541, 0.3842076324591711, 0.3842076324591711, 0.5993367768430217], 
reward next is 0.4007, 
noisyNet noise sample is [array([1.8427498], dtype=float32), -1.6479094]. 
=============================================
[2019-03-23 13:04:22,275] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.6445663e-05 2.2441232e-05 9.9993539e-01 1.5638336e-05 7.7679395e-08], sum to 1.0000
[2019-03-23 13:04:22,280] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8836
[2019-03-23 13:04:22,284] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 73.83333333333333, 1.0, 2.0, 0.3220446141304681, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6092628195488559, 6.9112, 6.9112, 77.32846344354104, 706422.1996904387, 706422.1996904387, 176845.2322534526], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1684200.0000, 
sim time next is 1684800.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.3195508606465269, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6030584705632128, 6.9112, 6.9112, 77.32846344354104, 699591.8766402586, 699591.8766402586, 175757.8000898879], 
processed observation next is [1.0, 0.5217391304347826, 0.5, 0.73, 1.0, 1.0, 0.14943857580815859, 0.0, 1.0, -0.25, 1.0, 1.0, 0.43294067223316124, 0.0, 0.0, 0.5084288129206541, 0.25910810245935506, 0.25910810245935506, 0.4286775611948485], 
reward next is 0.5713, 
noisyNet noise sample is [array([1.0651468], dtype=float32), 0.5044382]. 
=============================================
[2019-03-23 13:04:25,014] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.6792529e-06 4.6309627e-09 9.9999535e-01 1.8290423e-09 2.0571897e-12], sum to 1.0000
[2019-03-23 13:04:25,020] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3158
[2019-03-23 13:04:25,024] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [8.0, 86.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3023116932078886, 6.9112, 6.9112, 77.32846344354104, 351701.2558859973, 351701.2558859973, 108776.5858089828], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1745400.0000, 
sim time next is 1746000.0000, 
raw observation next is [8.0, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.304059797925219, 6.9112, 6.9112, 77.32846344354104, 353735.6933803581, 353735.6933803581, 109049.2654037117], 
processed observation next is [1.0, 0.21739130434782608, 0.0, 0.87, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.005799711321741413, 0.0, 0.0, 0.5084288129206541, 0.131013219770503, 0.131013219770503, 0.26597381805783343], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.07480074], dtype=float32), 0.094623305]. 
=============================================
[2019-03-23 13:04:25,040] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[28.782892]
 [28.473616]
 [28.242193]
 [28.087034]
 [28.011217]], R is [[28.6281395 ]
 [28.34185791]
 [28.05843925]
 [27.77785492]
 [27.50007629]].
[2019-03-23 13:04:26,226] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 2.6599384e-28 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 13:04:26,233] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5413
[2019-03-23 13:04:26,237] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [8.0, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6067526642391436, 6.9112, 6.9112, 77.32846344354104, 353735.6933803581, 353735.6933803581, 75619.91521602399], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1746000.0000, 
sim time next is 1746600.0000, 
raw observation next is [8.166666666666668, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5337057150276712, 6.911200000000001, 6.9112, 52.99656464932399, 311181.5416826743, 311181.5416826741, 58724.97396450458], 
processed observation next is [1.0, 0.21739130434782608, 0.00757575757575763, 0.86, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.33386530718238744, 8.881784197001253e-17, 0.0, 0.3484484141237532, 0.11525242284543494, 0.11525242284543484, 0.1432316438158648], 
reward next is 0.8568, 
noisyNet noise sample is [array([-1.9168533], dtype=float32), 0.6923376]. 
=============================================
[2019-03-23 13:04:31,083] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 2.8647368e-27 4.7668401e-15 2.8591827e-25 1.4943528e-34], sum to 1.0000
[2019-03-23 13:04:31,087] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0993
[2019-03-23 13:04:31,093] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 569790.9458293122 W.
[2019-03-23 13:04:31,104] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [19.66666666666667, 50.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7541569699468396, 7.314586338661745, 6.9112, 77.32730038467263, 569790.9458293122, 438781.284190078, 107392.1849151909], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1851600.0000, 
sim time next is 1852200.0000, 
raw observation next is [20.0, 49.0, 1.0, 1.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 507448.0759778903, 507448.0759778903, 178610.7805502797], 
processed observation next is [1.0, 0.43478260869565216, 0.5454545454545454, 0.49, 1.0, 0.5, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5085185399722538, 0.18794373184366306, 0.18794373184366306, 0.43563605012263346], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1489377], dtype=float32), 0.09908311]. 
=============================================
[2019-03-23 13:04:35,866] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 13:04:35,868] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:04:35,868] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:04:35,868] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:04:35,869] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:04:35,869] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:04:35,870] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:04:35,869] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:04:35,871] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:04:35,872] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:04:35,874] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:04:35,893] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run37
[2019-03-23 13:04:35,916] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run37
[2019-03-23 13:04:35,953] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run37
[2019-03-23 13:04:35,955] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run37
[2019-03-23 13:04:35,980] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run37
[2019-03-23 13:04:38,677] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.28008762]
[2019-03-23 13:04:38,678] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.13373893333333, 61.49002990833334, 1.0, 1.0, 0.4809592983690318, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 95.5530582320355, 547225.5440141847, 547225.5440141851, 140348.2814801588]
[2019-03-23 13:04:38,678] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:04:38,682] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.2318076e-01 1.9570133e-07 7.7681887e-01 2.2962061e-07 3.9878392e-11], sampled 0.7828879749121668
[2019-03-23 13:04:48,071] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.28008762]
[2019-03-23 13:04:48,073] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [30.91200166, 50.4640358, 1.0, 2.0, 0.5670657620170867, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 641546.1883396765, 641546.1883396761, 157603.8566532365]
[2019-03-23 13:04:48,074] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:04:48,078] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.4896260e-01 9.2521887e-08 6.5103716e-01 1.1551204e-07 1.2374421e-11], sampled 0.8046648476046215
[2019-03-23 13:05:04,141] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.28008762]
[2019-03-23 13:05:04,143] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.50689841, 53.28283741666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.58140814332333, 6.911200000000001, 6.9112, 95.55338769695034, 336991.3338656398, 336991.3338656394, 117207.2834790152]
[2019-03-23 13:05:04,143] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:05:04,145] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 3.1024425e-17 7.7882731e-09 9.2282598e-16 5.9482243e-22], sampled 0.16373058454800082
[2019-03-23 13:05:16,523] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.28008762]
[2019-03-23 13:05:16,524] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.50701901333333, 95.16698388, 1.0, 2.0, 0.2411987504708633, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4874387937391917, 6.911200000000001, 6.9112, 95.55338769695034, 550210.1632663808, 550210.1632663804, 180822.0818306481]
[2019-03-23 13:05:16,526] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:05:16,529] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.3530847e-01 8.9803557e-08 7.6469141e-01 1.0839373e-07 1.1909354e-11], sampled 0.3159364156288499
[2019-03-23 13:05:20,462] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.28008762]
[2019-03-23 13:05:20,463] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.63333333333333, 65.33333333333334, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7130471268917091, 7.134078797893261, 6.9112, 95.55262958966198, 498972.0520474252, 409526.1001297926, 131938.3996570176]
[2019-03-23 13:05:20,466] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:05:20,468] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.9999928e-01 9.6767449e-14 6.6691791e-07 1.0344043e-12 9.5289916e-18], sampled 0.9777919604097406
[2019-03-23 13:05:52,979] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.28008762]
[2019-03-23 13:05:52,980] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.63333333333333, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.630535456755068, 6.911199999999999, 6.9112, 77.32846344354104, 365047.6499773367, 365047.649977337, 117347.9336460675]
[2019-03-23 13:05:52,981] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:05:52,984] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 3.9794667e-18 2.1138835e-09 1.6925125e-16 6.3589831e-23], sampled 0.3948826080470683
[2019-03-23 13:05:58,028] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.28008762]
[2019-03-23 13:05:58,028] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.0, 55.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5448346602117506, 6.911200000000001, 6.9112, 95.55338769695034, 316891.93682699, 316891.9368269896, 104542.4150613853]
[2019-03-23 13:05:58,029] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:05:58,031] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0000000e+00 1.1501090e-18 1.1235147e-09 5.6150549e-17 1.3543498e-23], sampled 0.6777130670911451
[2019-03-23 13:06:15,643] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6222.8984 1820511116.7489 2537.0000
[2019-03-23 13:06:15,726] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6612.8104 1901309089.9855 2092.0000
[2019-03-23 13:06:15,848] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6103.4745 1791649276.0785 2689.0000
[2019-03-23 13:06:15,870] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6152.2311 1821315035.9952 3195.0000
[2019-03-23 13:06:15,887] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 5978.2872 1816197036.9007 2619.0000
[2019-03-23 13:06:16,900] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 900000, evaluation results [900000.0, 6612.810407950363, 1901309089.9855192, 2092.0, 6103.474498759507, 1791649276.0785475, 2689.0, 5978.287199062236, 1816197036.900674, 2619.0, 6152.231110204328, 1821315035.9951668, 3195.0, 6222.89841844, 1820511116.748883, 2537.0]
[2019-03-23 13:06:18,408] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 5.6226272e-30 1.3858371e-17 1.6605287e-25 3.1770867e-36], sum to 1.0000
[2019-03-23 13:06:18,415] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1999
[2019-03-23 13:06:18,430] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.0, 54.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.716236829470228, 6.944776907881305, 6.9112, 77.32828113706992, 423988.3046069877, 413083.2374030795, 126710.9294747859], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1969200.0000, 
sim time next is 1969800.0000, 
raw observation next is [23.66666666666667, 55.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7114586764016284, 6.911199999999999, 6.9112, 77.32838469308656, 410477.2145819557, 410477.214581956, 126099.4746880991], 
processed observation next is [1.0, 0.8260869565217391, 0.7121212121212124, 0.55, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5877981091451835, -8.881784197001253e-17, 0.0, 0.5084282951423574, 0.15202859799331692, 0.15202859799331703, 0.30755969436121733], 
reward next is 0.6924, 
noisyNet noise sample is [array([-1.4236401], dtype=float32), 0.00474471]. 
=============================================
[2019-03-23 13:06:25,503] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 7.735043e-30 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 13:06:25,517] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1541
[2019-03-23 13:06:25,524] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.18333333333333, 53.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6784052931989378, 6.911199999999999, 6.9112, 77.32846344354104, 391252.4823613046, 391252.4823613049, 122887.4843036713], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2117400.0000, 
sim time next is 2118000.0000, 
raw observation next is [24.36666666666667, 53.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6842599359137504, 6.9112, 6.9112, 77.32846344354104, 394450.2163214167, 394450.2163214167, 123595.9646761521], 
processed observation next is [0.0, 0.5217391304347826, 0.7439393939393941, 0.5333333333333334, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5489427655910721, 0.0, 0.0, 0.5084288129206541, 0.1460926727116358, 0.1460926727116358, 0.3014535723808588], 
reward next is 0.6985, 
noisyNet noise sample is [array([-0.74924535], dtype=float32), 0.30900815]. 
=============================================
[2019-03-23 13:06:25,544] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[97.63273 ]
 [97.47471 ]
 [97.23729 ]
 [97.03558 ]
 [96.800224]], R is [[97.51727295]
 [97.24237061]
 [96.97136688]
 [96.70334625]
 [96.43827057]].
[2019-03-23 13:06:29,939] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 3.9253849e-33 2.9166267e-21 2.5630448e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 13:06:29,947] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8864
[2019-03-23 13:06:29,952] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 573458.0759783665 W.
[2019-03-23 13:06:29,955] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.66666666666666, 78.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7552647482868681, 7.323887463684846, 6.9112, 77.32740415751778, 573458.0759783665, 439427.4647389506, 114272.7088030045], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2191200.0000, 
sim time next is 2191800.0000, 
raw observation next is [16.83333333333334, 77.83333333333334, 1.0, 1.0, 0.2459567735891366, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4591474130608125, 6.9112, 6.9112, 77.32821498841557, 534259.9462034167, 534259.9462034167, 152742.3545153691], 
processed observation next is [1.0, 0.34782608695652173, 0.40151515151515177, 0.7783333333333334, 1.0, 0.5, 0.057445966986420724, 0.0, 1.0, -0.25, 1.0, 1.0, 0.22735344722973222, 0.0, 0.0, 0.5084271793469494, 0.1978740541494136, 0.1978740541494136, 0.37254232808626614], 
reward next is 0.6275, 
noisyNet noise sample is [array([-0.05115153], dtype=float32), 0.72007257]. 
=============================================
[2019-03-23 13:06:30,238] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.7821117e-26 5.5055524e-15 1.4902495e-25 1.7609947e-32], sum to 1.0000
[2019-03-23 13:06:30,245] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5307
[2019-03-23 13:06:30,253] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 681601.3108376206 W.
[2019-03-23 13:06:30,256] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [19.5, 78.0, 1.0, 2.0, 0.3061761845865686, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5906113431920739, 6.9112, 6.9112, 77.3284634350145, 681601.3108376206, 681601.3108376206, 177436.1754127835], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2208600.0000, 
sim time next is 2209200.0000, 
raw observation next is [19.66666666666666, 78.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3871199072022239, 6.911199999999999, 6.9112, 77.3421103, 668078.96147705, 668078.9614770503, 210287.6442025257], 
processed observation next is [1.0, 0.5652173913043478, 0.53030303030303, 0.78, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.12445701028889129, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.2474366523989074, 0.24743665239890753, 0.5128966931768919], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.86680835], dtype=float32), 0.2776831]. 
=============================================
[2019-03-23 13:06:36,275] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 4.908699e-34 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 13:06:36,289] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9764
[2019-03-23 13:06:36,294] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.0, 55.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4364505147122409, 6.9112, 6.9112, 77.32846344354104, 253851.8372110259, 253851.8372110259, 69376.64685913637], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2325600.0000, 
sim time next is 2326200.0000, 
raw observation next is [17.0, 54.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4359749551786867, 6.9112, 6.9112, 77.32846344354104, 253575.1663700052, 253575.1663700052, 69098.67618533062], 
processed observation next is [1.0, 0.9565217391304348, 0.4090909090909091, 0.545, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.19424993596955242, 0.0, 0.0, 0.5084288129206541, 0.09391672828518711, 0.09391672828518711, 0.1685333565495869], 
reward next is 0.8315, 
noisyNet noise sample is [array([0.73669475], dtype=float32), 0.48287943]. 
=============================================
[2019-03-23 13:06:39,945] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 3.6463963e-30 9.3578893e-18 6.6701425e-28 2.7603941e-37], sum to 1.0000
[2019-03-23 13:06:39,953] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8033
[2019-03-23 13:06:39,957] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.0, 53.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.541729167603402, 6.911199999999999, 6.9112, 77.32846344354104, 315104.685516066, 315104.6855160663, 97099.97868837992], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2400000.0000, 
sim time next is 2400600.0000, 
raw observation next is [21.0, 53.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5397256278873717, 6.9112, 6.9112, 77.32846344354104, 313938.9212085549, 313938.9212085549, 96909.86345538612], 
processed observation next is [1.0, 0.782608695652174, 0.5909090909090909, 0.53, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.34246518269624526, 0.0, 0.0, 0.5084288129206541, 0.11627367452168699, 0.11627367452168699, 0.23636552062289298], 
reward next is 0.7636, 
noisyNet noise sample is [array([2.074835], dtype=float32), 0.2591788]. 
=============================================
[2019-03-23 13:06:40,150] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 3.6452083e-33 6.9751550e-18 4.7902409e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 13:06:40,155] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2585
[2019-03-23 13:06:40,160] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.83333333333333, 53.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5355155326431839, 6.911199999999998, 6.9112, 77.32846344354104, 311489.2764703281, 311489.2764703287, 95944.51093792722], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2401800.0000, 
sim time next is 2402400.0000, 
raw observation next is [20.66666666666667, 54.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5324236579649373, 6.911200000000001, 6.9112, 77.32846344354104, 309690.2764447035, 309690.2764447032, 95089.01402255362], 
processed observation next is [1.0, 0.8260869565217391, 0.575757575757576, 0.54, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3320337970927676, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11470010238692722, 0.11470010238692711, 0.2319244244452527], 
reward next is 0.7681, 
noisyNet noise sample is [array([-1.9833827], dtype=float32), 0.239]. 
=============================================
[2019-03-23 13:06:41,653] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 9.0636964e-30 1.1963484e-18 1.9326843e-28 8.5476211e-37], sum to 1.0000
[2019-03-23 13:06:41,660] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6225
[2019-03-23 13:06:41,665] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4131818140475235, 6.9112, 6.9112, 77.32846344354104, 240314.7660975839, 240314.7660975839, 74696.88805317324], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2436000.0000, 
sim time next is 2436600.0000, 
raw observation next is [14.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.412664797116044, 6.911199999999999, 6.9112, 77.32846344354104, 240013.9845666857, 240013.9845666859, 74655.37593102425], 
processed observation next is [1.0, 0.17391304347826086, 0.2727272727272727, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.16094971016577714, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08889406835803175, 0.0888940683580318, 0.18208628275859573], 
reward next is 0.8179, 
noisyNet noise sample is [array([0.07390531], dtype=float32), 0.86662924]. 
=============================================
[2019-03-23 13:06:41,814] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 1.577317e-25 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 13:06:41,822] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4373
[2019-03-23 13:06:41,827] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4131818140475235, 6.9112, 6.9112, 77.32846344354104, 240314.7660975839, 240314.7660975839, 74696.88805317324], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2436000.0000, 
sim time next is 2436600.0000, 
raw observation next is [14.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.412664797116044, 6.911199999999999, 6.9112, 77.32846344354104, 240013.9845666857, 240013.9845666859, 74655.37593102425], 
processed observation next is [1.0, 0.17391304347826086, 0.2727272727272727, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.16094971016577714, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08889406835803175, 0.0888940683580318, 0.18208628275859573], 
reward next is 0.8179, 
noisyNet noise sample is [array([-0.87918866], dtype=float32), -1.6049205]. 
=============================================
[2019-03-23 13:06:43,164] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 7.523918e-27 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 13:06:43,170] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1614
[2019-03-23 13:06:43,177] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 572506.636036803 W.
[2019-03-23 13:06:43,180] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 82.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 1.0, 0.3284546525295729, 6.911199999999999, 6.9112, 77.3421103, 572506.636036803, 572506.6360368034, 192780.0151305022], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2462400.0000, 
sim time next is 2463000.0000, 
raw observation next is [17.16666666666667, 81.16666666666667, 1.0, 2.0, 0.7217566043847918, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 784090.4350671503, 784090.4350671503, 144843.7266979998], 
processed observation next is [1.0, 0.5217391304347826, 0.4166666666666669, 0.8116666666666668, 1.0, 1.0, 0.6521957554809898, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2904038648396853, 0.2904038648396853, 0.35327738219024346], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.62401295], dtype=float32), 0.60986066]. 
=============================================
[2019-03-23 13:06:43,190] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[75.02486 ]
 [74.30325 ]
 [72.589386]
 [72.40514 ]
 [71.037445]], R is [[73.14040375]
 [72.40900421]
 [72.29228973]
 [72.17715454]
 [72.0619812 ]].
[2019-03-23 13:06:46,083] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 5.341267e-26 2.787769e-38 0.000000e+00], sum to 1.0000
[2019-03-23 13:06:46,090] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1274
[2019-03-23 13:06:46,095] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [13.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3862676355459573, 6.9112, 6.9112, 77.32846344354104, 224657.3291245729, 224657.3291245729, 70083.15887726285], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2511600.0000, 
sim time next is 2512200.0000, 
raw observation next is [13.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3857190439771805, 6.911199999999999, 6.9112, 77.32846344354104, 224338.1889047143, 224338.1889047146, 70039.55590455957], 
processed observation next is [1.0, 0.043478260869565216, 0.22727272727272727, 1.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.12245577711025786, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08308821811285715, 0.08308821811285726, 0.17082818513307213], 
reward next is 0.8292, 
noisyNet noise sample is [array([-0.8381998], dtype=float32), 2.93904]. 
=============================================
[2019-03-23 13:06:47,240] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 6.2152536e-24 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 13:06:47,247] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4756
[2019-03-23 13:06:47,251] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [13.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3862087957909335, 6.911199999999999, 6.9112, 77.32846344354104, 224623.0994008162, 224623.0994008165, 70464.93363368163], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2529000.0000, 
sim time next is 2529600.0000, 
raw observation next is [13.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3845084905734475, 6.9112, 6.9112, 77.32846344354104, 223633.956658017, 223633.956658017, 70096.11726779534], 
processed observation next is [1.0, 0.2608695652173913, 0.22727272727272727, 1.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.12072641510492502, 0.0, 0.0, 0.5084288129206541, 0.08282739135482112, 0.08282739135482112, 0.17096613967754962], 
reward next is 0.8290, 
noisyNet noise sample is [array([-0.38353875], dtype=float32), 0.47944394]. 
=============================================
[2019-03-23 13:06:47,425] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 4.0552287e-34 2.7607564e-19 5.0315942e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 13:06:47,431] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0827
[2019-03-23 13:06:47,439] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 583343.0613519123 W.
[2019-03-23 13:06:47,444] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 77.0, 1.0, 2.0, 0.2674616383756047, 1.0, 1.0, 0.2674616383756047, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846084483508, 583343.0613519123, 583343.0613519127, 162172.0161644704], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2545200.0000, 
sim time next is 2545800.0000, 
raw observation next is [18.33333333333333, 74.83333333333334, 1.0, 2.0, 0.5764326499380177, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846342745484, 626114.002514799, 626114.002514799, 132302.3317140962], 
processed observation next is [1.0, 0.4782608695652174, 0.4696969696969695, 0.7483333333333334, 1.0, 1.0, 0.47054081242252205, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288128148885, 0.23189407500548112, 0.23189407500548112, 0.32268861393681997], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3601416], dtype=float32), -0.28064278]. 
=============================================
[2019-03-23 13:06:50,139] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.6921264e-37 1.4620697e-21 3.5342397e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 13:06:50,147] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8195
[2019-03-23 13:06:50,157] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.5, 88.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7297859205706145, 7.046978141447251, 6.9112, 77.3281017586365, 464282.8346324806, 420185.0776910678, 128679.8137810314], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2791800.0000, 
sim time next is 2792400.0000, 
raw observation next is [20.0, 86.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7418389892360348, 7.137973358167535, 6.9112, 77.32779453448741, 500159.1167270358, 426508.4054126812, 130452.3589722979], 
processed observation next is [1.0, 0.30434782608695654, 0.5454545454545454, 0.8666666666666666, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6311985560514782, 0.02267733581675353, 0.0, 0.5084244148940938, 0.18524411730630955, 0.15796607607877083, 0.31817648529828757], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3124458], dtype=float32), 0.867986]. 
=============================================
[2019-03-23 13:06:57,613] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9999356e-01 1.9142623e-13 6.4803990e-06 8.4047726e-13 3.3192733e-16], sum to 1.0000
[2019-03-23 13:06:57,624] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9907
[2019-03-23 13:06:57,627] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.66666666666667, 52.00000000000001, 1.0, 1.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3083946759787076, 6.9112, 6.9112, 77.3421103, 524719.0837425395, 524719.0837425395, 202068.0787983612], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2740800.0000, 
sim time next is 2741400.0000, 
raw observation next is [26.5, 52.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7704777837901411, 7.303487098181287, 6.9112, 77.32749307124044, 565415.0254494104, 438009.7984098985, 137259.2828104497], 
processed observation next is [0.0, 0.7391304347826086, 0.8409090909090909, 0.525, 0.0, 0.5, -0.25, 0.0, 0.5, -0.25, 1.0, 1.0, 0.6721111197002017, 0.03922870981812867, 0.0, 0.5084224327959896, 0.20941297238867054, 0.16222585126292535, 0.3347787385620724], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.59191114], dtype=float32), 0.6280269]. 
=============================================
[2019-03-23 13:07:05,570] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 13:07:05,572] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:07:05,573] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:07:05,573] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:07:05,574] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:07:05,574] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:07:05,574] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:07:05,575] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:07:05,577] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:07:05,578] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:07:05,578] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:07:05,595] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run38
[2019-03-23 13:07:05,619] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run38
[2019-03-23 13:07:05,619] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run38
[2019-03-23 13:07:05,669] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run38
[2019-03-23 13:07:05,670] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run38
[2019-03-23 13:07:07,126] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.29249755]
[2019-03-23 13:07:07,127] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.12430081833333, 85.09090324499999, 1.0, 2.0, 0.2285244032031361, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4594001309133248, 6.911200000000001, 6.9112, 95.55338769695034, 521237.8524239692, 521237.8524239688, 175733.0266191878]
[2019-03-23 13:07:07,131] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:07:07,134] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.3659696e-27 6.7635340e-21 1.0000000e+00 9.6012980e-22 1.5464535e-27], sampled 0.9122051432705537
[2019-03-23 13:07:14,545] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.29249755]
[2019-03-23 13:07:14,546] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.013565615, 75.520241195, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3254119991708285, 6.911200000000001, 6.9112, 95.55338769695034, 375715.5458219056, 375715.5458219053, 153748.6192297215]
[2019-03-23 13:07:14,547] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:07:14,550] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.8342937e-25 3.1906564e-19 1.0000000e+00 5.7397236e-20 2.4544113e-25], sampled 0.6059297027533361
[2019-03-23 13:07:33,152] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.29249755]
[2019-03-23 13:07:33,153] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.35, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3844350530438817, 6.911200000000001, 6.9112, 95.55338769695034, 440984.1613662146, 440984.1613662142, 163602.5124642643]
[2019-03-23 13:07:33,153] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:07:33,157] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.2633587e-27 3.2675636e-21 1.0000000e+00 5.3550079e-22 6.1718394e-28], sampled 0.6508901121219193
[2019-03-23 13:07:37,166] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.29249755]
[2019-03-23 13:07:37,167] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.5, 47.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 315664.3185995537, 315664.3185995537, 113930.7285359298]
[2019-03-23 13:07:37,169] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:07:37,173] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0595723e-22 1.0997388e-17 1.0000000e+00 2.3380694e-18 2.2501497e-23], sampled 0.5945052339619792
[2019-03-23 13:07:47,160] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.29249755]
[2019-03-23 13:07:47,161] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.45, 79.83333333333334, 1.0, 2.0, 0.3689759742148319, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7354194069602901, 6.9112, 6.9112, 95.55338769695022, 838973.1543894216, 838973.1543894216, 209703.6021669518]
[2019-03-23 13:07:47,162] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:07:47,166] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.6444450e-31 1.5387008e-23 1.0000000e+00 1.6254453e-24 5.3618515e-31], sampled 0.09679408488592223
[2019-03-23 13:08:22,116] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.29249755]
[2019-03-23 13:08:22,117] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.86666666666667, 67.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 222872.6470730595, 222872.6470730592, 92766.5491242407]
[2019-03-23 13:08:22,117] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:08:22,120] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.0114858e-20 6.2514695e-16 1.0000000e+00 1.4943096e-16 4.0831501e-21], sampled 0.813529265605273
[2019-03-23 13:08:23,895] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.29249755]
[2019-03-23 13:08:23,897] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.2, 47.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.397434052314002, 6.9112, 6.9112, 77.32846335318558, 453639.0405409174, 453639.0405409174, 162663.3468220135]
[2019-03-23 13:08:23,899] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:08:23,901] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.4709911e-26 6.4477837e-20 1.0000000e+00 9.4845224e-21 2.8980426e-26], sampled 0.2663651071650255
[2019-03-23 13:08:27,828] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.29249755]
[2019-03-23 13:08:27,829] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.613720585, 84.654228855, 1.0, 2.0, 0.2256297149556139, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4526197854381965, 6.911200000000001, 6.9112, 95.55338769695034, 514311.3091127798, 514311.3091127794, 174418.5859197074]
[2019-03-23 13:08:27,830] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:08:27,833] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.7617022e-28 1.8429208e-21 1.0000000e+00 2.6684431e-22 2.9535980e-28], sampled 0.2896770588600137
[2019-03-23 13:08:45,413] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3519.0325 2104095443.0865 178.0000
[2019-03-23 13:08:45,516] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3118.8146 2109022190.6825 368.0000
[2019-03-23 13:08:45,635] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2760.0075 2124051796.3784 757.0000
[2019-03-23 13:08:45,733] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3614.1741 2175305489.0345 245.0000
[2019-03-23 13:08:45,825] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3361.3356 2098067941.7008 179.0000
[2019-03-23 13:08:46,838] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 925000, evaluation results [925000.0, 3614.1740929847015, 2175305489.034501, 245.0, 3361.3355917968815, 2098067941.7008436, 179.0, 3519.032511138161, 2104095443.0864863, 178.0, 2760.0074851005825, 2124051796.3784225, 757.0, 3118.8146269445274, 2109022190.6824877, 368.0]
[2019-03-23 13:08:51,539] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.2461944e-17 1.1554190e-14 1.0000000e+00 6.8085522e-13 3.2962724e-20], sum to 1.0000
[2019-03-23 13:08:51,545] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8983
[2019-03-23 13:08:51,554] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.7068170202474761, 1.0, 1.0, 0.7068170202474761, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32843775930726, 1596582.332724238, 1596582.332724237, 292418.6393882481], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2986800.0000, 
sim time next is 2987400.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.8702755638772053, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9780683390791772, 6.9112, 6.9112, 77.3284632845533, 1536665.608661216, 1536665.608661216, 320888.6977901349], 
processed observation next is [1.0, 0.5652173913043478, 0.9090909090909091, 0.58, 1.0, 1.0, 0.8378444548465066, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9686690558273962, 0.0, 0.0, 0.5084288118753216, 0.5691354106152652, 0.5691354106152652, 0.7826553604637436], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1554496], dtype=float32), 0.48884377]. 
=============================================
[2019-03-23 13:08:52,797] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.0290158e-19 1.2146021e-14 1.0000000e+00 1.0304509e-12 5.4404190e-21], sum to 1.0000
[2019-03-23 13:08:52,802] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1322
[2019-03-23 13:08:52,806] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.0, 69.0, 1.0, 2.0, 0.2270558650877824, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4556444222572238, 6.911200000000001, 6.9112, 77.32846344354104, 517677.7234529338, 517677.7234529335, 170137.0102770373], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3009600.0000, 
sim time next is 3010200.0000, 
raw observation next is [23.83333333333333, 69.66666666666667, 1.0, 2.0, 0.2243962277804408, 0.0, 2.0, 0.0, 1.0, 2.0, 0.449940968375211, 6.9112, 6.9112, 77.32846344354104, 511469.385222715, 511469.385222715, 169339.0741659364], 
processed observation next is [1.0, 0.8695652173913043, 0.7196969696969695, 0.6966666666666668, 1.0, 1.0, 0.030495284725550985, 0.0, 1.0, -0.25, 1.0, 1.0, 0.21420138339315864, 0.0, 0.0, 0.5084288129206541, 0.18943310563804258, 0.18943310563804258, 0.41302213211204003], 
reward next is 0.5870, 
noisyNet noise sample is [array([-0.70664287], dtype=float32), 0.06796712]. 
=============================================
[2019-03-23 13:09:02,096] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.0421077e-19 2.8423509e-16 1.0000000e+00 3.7293278e-13 1.6657428e-26], sum to 1.0000
[2019-03-23 13:09:02,109] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8812
[2019-03-23 13:09:02,111] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.16666666666667, 82.16666666666667, 1.0, 2.0, 0.22570914664456, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4531417466151814, 6.9112, 6.9112, 77.32846344354104, 514677.3161875619, 514677.3161875619, 170010.2389233962], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3181800.0000, 
sim time next is 3182400.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.2248165366288811, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4511545259976339, 6.911200000000001, 6.9112, 77.32846344354104, 512570.8862577878, 512570.8862577875, 169687.3486457847], 
processed observation next is [1.0, 0.8695652173913043, 0.6363636363636364, 0.83, 1.0, 1.0, 0.031020670786101358, 0.0, 1.0, -0.25, 1.0, 1.0, 0.215935037139477, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18984106898436587, 0.18984106898436576, 0.4138715820628895], 
reward next is 0.5861, 
noisyNet noise sample is [array([0.85114455], dtype=float32), 1.3254925]. 
=============================================
[2019-03-23 13:09:04,320] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.3219749e-27 1.0583107e-17 5.3489743e-26 3.2895268e-35], sum to 1.0000
[2019-03-23 13:09:04,329] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5915
[2019-03-23 13:09:04,333] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.0, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6738206196861244, 6.9112, 6.9112, 77.32846344354104, 389302.2015234208, 389302.2015234208, 121926.8603399919], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3223800.0000, 
sim time next is 3224400.0000, 
raw observation next is [20.33333333333334, 76.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6821864676337088, 6.911199999999999, 6.9112, 77.32846344354104, 393915.8460559669, 393915.8460559672, 122902.6884570553], 
processed observation next is [0.0, 0.30434782608695654, 0.5606060606060609, 0.7633333333333334, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5459806680481555, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14589475779850627, 0.14589475779850639, 0.2997626547733056], 
reward next is 0.7002, 
noisyNet noise sample is [array([-0.3110111], dtype=float32), 0.5697786]. 
=============================================
[2019-03-23 13:09:07,883] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 4.9742658e-24 1.5605087e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 13:09:07,891] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9719
[2019-03-23 13:09:07,894] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.83333333333334, 77.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4714904285845651, 6.911200000000001, 6.9112, 77.32846344354104, 274237.7777443255, 274237.7777443252, 86778.77746454987], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3307800.0000, 
sim time next is 3308400.0000, 
raw observation next is [17.0, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4732970847853062, 6.911199999999999, 6.9112, 77.32846344354104, 275288.8989798808, 275288.8989798811, 87440.26880329009], 
processed observation next is [0.0, 0.30434782608695654, 0.4090909090909091, 0.77, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.24756726397900888, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10195885147402992, 0.10195885147403003, 0.21326894830070753], 
reward next is 0.7867, 
noisyNet noise sample is [array([1.0935444], dtype=float32), -1.2030094]. 
=============================================
[2019-03-23 13:09:14,453] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6820850e-24 3.7040069e-20 1.0000000e+00 3.0806398e-15 1.2961880e-27], sum to 1.0000
[2019-03-23 13:09:14,458] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6227
[2019-03-23 13:09:14,464] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.83333333333334, 55.83333333333334, 1.0, 2.0, 0.6561072306427534, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9736798757652968, 6.911199999999999, 6.9112, 77.32846344354104, 1296093.165243433, 1296093.165243434, 282165.3794435744], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3424200.0000, 
sim time next is 3424800.0000, 
raw observation next is [27.86666666666667, 55.66666666666667, 1.0, 2.0, 0.6704700914665025, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9736521263980993, 6.9112, 6.9112, 77.32846344354104, 1312497.375581078, 1312497.375581078, 284192.7815720555], 
processed observation next is [1.0, 0.6521739130434783, 0.9030303030303032, 0.5566666666666668, 1.0, 1.0, 0.5880876143331281, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9623601805687133, 0.0, 0.0, 0.5084288129206541, 0.48611013910410295, 0.48611013910410295, 0.6931531257855011], 
reward next is 0.3068, 
noisyNet noise sample is [array([0.11207005], dtype=float32), 1.3606188]. 
=============================================
[2019-03-23 13:09:19,402] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0203838e-13 7.1947906e-13 1.0000000e+00 1.6245258e-08 1.6062383e-17], sum to 1.0000
[2019-03-23 13:09:19,412] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2703
[2019-03-23 13:09:19,417] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.0, 62.0, 1.0, 2.0, 0.7681906587082907, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9807821453543367, 6.9112, 6.9112, 77.32846344354104, 1417589.393231005, 1417589.393231005, 306148.2773246213], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3507000.0000, 
sim time next is 3507600.0000, 
raw observation next is [28.0, 62.0, 1.0, 2.0, 0.8526931125100945, 0.0, 2.0, 0.0, 1.0, 2.0, 0.98085821023002, 6.9112, 6.9112, 77.32846344354104, 1513238.179865462, 1513238.179865462, 320612.700946981], 
processed observation next is [1.0, 0.6086956521739131, 0.9090909090909091, 0.62, 1.0, 1.0, 0.8158663906376181, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9726545860428858, 0.0, 0.0, 0.5084288129206541, 0.5604585851353563, 0.5604585851353563, 0.7819821974316609], 
reward next is 0.2180, 
noisyNet noise sample is [array([-0.37820417], dtype=float32), -1.0835326]. 
=============================================
[2019-03-23 13:09:21,299] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0496107e-18 7.4925649e-17 1.0000000e+00 1.5633693e-09 1.5013003e-27], sum to 1.0000
[2019-03-23 13:09:21,309] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4389
[2019-03-23 13:09:21,319] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.2610015418247565, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5285056083075464, 6.9112, 6.9112, 77.32846344354104, 594297.3061063971, 594297.3061063971, 182451.3530424447], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3543600.0000, 
sim time next is 3544200.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.2610671027597823, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5286383871105336, 6.9112, 6.9112, 77.32846344354104, 594446.6126932054, 594446.6126932054, 182467.6097221172], 
processed observation next is [1.0, 0.0, 0.6818181818181818, 0.89, 1.0, 1.0, 0.07633387844972785, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3266262673007623, 0.0, 0.0, 0.5084288129206541, 0.22016541210859458, 0.22016541210859458, 0.44504295054174925], 
reward next is 0.5550, 
noisyNet noise sample is [array([-0.1381185], dtype=float32), 0.16155067]. 
=============================================
[2019-03-23 13:09:21,409] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.3754347e-11 1.3100861e-13 9.9999976e-01 2.3342966e-07 3.0642680e-21], sum to 1.0000
[2019-03-23 13:09:21,415] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2355
[2019-03-23 13:09:21,420] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.2810063708397322, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5679788401144172, 6.9112, 6.9112, 77.32846344354104, 641102.7221263779, 641102.7221263779, 185874.767792194], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3561000.0000, 
sim time next is 3561600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.2582149305367127, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5218993674903702, 6.9112, 6.9112, 77.32846344354104, 589079.9125930361, 589079.9125930361, 180155.6212458714], 
processed observation next is [1.0, 0.21739130434782608, 0.5909090909090909, 1.0, 1.0, 1.0, 0.07276866317089084, 0.0, 1.0, -0.25, 1.0, 1.0, 0.31699909641481466, 0.0, 0.0, 0.5084288129206541, 0.21817774540482818, 0.21817774540482818, 0.439403954258223], 
reward next is 0.5606, 
noisyNet noise sample is [array([0.70271295], dtype=float32), -1.6308334]. 
=============================================
[2019-03-23 13:09:22,166] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.6958927e-14 1.3928313e-11 9.9999964e-01 3.4451386e-07 9.1641545e-18], sum to 1.0000
[2019-03-23 13:09:22,175] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2647
[2019-03-23 13:09:22,185] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.0, 89.0, 1.0, 2.0, 0.7342004019762302, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9818463422353767, 6.911199999999999, 6.9112, 77.32846344354104, 1377787.295743782, 1377787.295743782, 301636.6023027999], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3582000.0000, 
sim time next is 3582600.0000, 
raw observation next is [23.83333333333333, 89.83333333333334, 1.0, 2.0, 0.8738186524380254, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9820993172643864, 6.9112, 6.9112, 77.32846344354104, 1535363.680528485, 1535363.680528485, 325603.4083919729], 
processed observation next is [1.0, 0.4782608695652174, 0.7196969696969695, 0.8983333333333334, 1.0, 1.0, 0.8422733155475317, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9744275960919805, 0.0, 0.0, 0.5084288129206541, 0.56865321501055, 0.56865321501055, 0.794154654614568], 
reward next is 0.2058, 
noisyNet noise sample is [array([-1.5372214], dtype=float32), -2.7491722]. 
=============================================
[2019-03-23 13:09:25,484] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.0331876e-17 4.1155644e-14 9.9999964e-01 3.1714535e-07 2.8791577e-24], sum to 1.0000
[2019-03-23 13:09:25,492] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2065
[2019-03-23 13:09:25,495] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.246157288911402, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4974743710580478, 6.9112, 6.9112, 77.32846344354104, 561581.8406879185, 561581.8406879185, 177260.7597655524], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3631800.0000, 
sim time next is 3632400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.245918492175015, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4969910821089771, 6.9112, 6.9112, 77.32846344354104, 561037.048176059, 561037.048176059, 177205.285063861], 
processed observation next is [1.0, 0.043478260869565216, 0.5909090909090909, 1.0, 1.0, 1.0, 0.057398115218768725, 0.0, 1.0, -0.25, 1.0, 1.0, 0.281415831584253, 0.0, 0.0, 0.5084288129206541, 0.2077914993244663, 0.2077914993244663, 0.43220801235088047], 
reward next is 0.5678, 
noisyNet noise sample is [array([0.7278069], dtype=float32), -0.31151178]. 
=============================================
[2019-03-23 13:09:27,427] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.4103003e-06 7.4866890e-05 9.9499905e-01 4.9217260e-03 5.1579729e-08], sum to 1.0000
[2019-03-23 13:09:27,438] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4779
[2019-03-23 13:09:27,447] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.16666666666666, 78.0, 1.0, 2.0, 0.4893823554251112, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9475460615253807, 6.957083818975565, 6.9112, 77.32832951296838, 1105737.125779238, 1090835.025672403, 255511.3224418528], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3671400.0000, 
sim time next is 3672000.0000, 
raw observation next is [24.0, 78.0, 1.0, 2.0, 0.5042268942406409, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9520773071962263, 6.947747120830098, 6.9112, 77.32834536154401, 1122990.192985217, 1111120.453782833, 257467.235928035], 
processed observation next is [1.0, 0.5217391304347826, 0.7272727272727273, 0.78, 1.0, 1.0, 0.3802836178008011, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9315390102803233, 0.003654712083009759, 0.0, 0.5084280365404326, 0.41592229369822853, 0.4115260939936418, 0.6279688681171585], 
reward next is 0.1893, 
noisyNet noise sample is [array([-0.38552383], dtype=float32), 0.25334725]. 
=============================================
[2019-03-23 13:09:27,466] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[22.241661]
 [22.169714]
 [22.124279]
 [22.13085 ]
 [22.250383]], R is [[22.26890945]
 [22.19360352]
 [22.164608  ]
 [22.26745796]
 [22.37877846]].
[2019-03-23 13:09:35,476] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 13:09:35,478] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:09:35,478] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:09:35,479] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:09:35,479] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:09:35,479] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:09:35,480] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:09:35,480] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:09:35,481] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:09:35,483] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:09:35,483] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:09:35,500] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run39
[2019-03-23 13:09:35,526] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run39
[2019-03-23 13:09:35,526] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run39
[2019-03-23 13:09:35,527] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run39
[2019-03-23 13:09:35,598] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run39
[2019-03-23 13:09:47,395] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.31890994]
[2019-03-23 13:09:47,396] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.3, 42.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.727088732854613, 7.261971116297802, 6.9112, 95.55204450701878, 558835.8986227273, 418064.9298944172, 133109.8624382201]
[2019-03-23 13:09:47,397] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:09:47,399] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.000000e+00 0.000000e+00 7.184609e-26 2.447808e-34 0.000000e+00], sampled 0.8853816421135552
[2019-03-23 13:09:47,401] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 558835.8986227273 W.
[2019-03-23 13:10:25,565] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.31890994]
[2019-03-23 13:10:25,567] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.30674844666667, 52.62945665333334, 1.0, 2.0, 0.489742964056715, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 558646.7558966607, 558646.7558966603, 143276.7827720058]
[2019-03-23 13:10:25,570] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:10:25,573] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.5484729e-01 2.3922826e-19 7.4515271e-01 6.2831457e-10 4.7451232e-31], sampled 0.7913824860835492
[2019-03-23 13:10:38,165] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.31890994]
[2019-03-23 13:10:38,166] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.83333333333334, 83.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5122785401210218, 6.9112, 6.9112, 77.32846344354104, 297969.0498357413, 297969.0498357413, 95421.18140979293]
[2019-03-23 13:10:38,167] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:10:38,171] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.000000e+00 0.000000e+00 4.074985e-34 0.000000e+00 0.000000e+00], sampled 0.5761773170665442
[2019-03-23 13:10:38,694] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.31890994]
[2019-03-23 13:10:38,695] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.66666666666666, 57.33333333333334, 1.0, 2.0, 0.2730906205460518, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5098003609542789, 6.9112, 6.9112, 77.32846344354104, 593235.2432798712, 593235.2432798712, 162984.5347636895]
[2019-03-23 13:10:38,696] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:10:38,699] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.9063656e-01 9.5513975e-18 6.0936344e-01 3.5129477e-09 1.9054699e-28], sampled 0.6688501975396567
[2019-03-23 13:11:09,269] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.31890994]
[2019-03-23 13:11:09,270] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.6, 47.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6597581613111226, 6.911199999999999, 6.9112, 77.32846344354104, 381687.7229541142, 381687.7229541145, 120207.3481116289]
[2019-03-23 13:11:09,271] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:11:09,274] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 4.8068583e-26 7.2004625e-35 0.0000000e+00], sampled 0.13640050341807952
[2019-03-23 13:11:15,354] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6174.0308 1818288411.2165 2876.0000
[2019-03-23 13:11:15,490] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 5942.3407 1812811999.5683 2912.0000
[2019-03-23 13:11:15,522] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 5878.2819 1814259850.4061 3005.0000
[2019-03-23 13:11:15,595] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 5901.5998 1836905242.4739 3490.0000
[2019-03-23 13:11:15,721] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6400.8688 1922772439.8534 2286.0000
[2019-03-23 13:11:16,737] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 950000, evaluation results [950000.0, 6400.868812744626, 1922772439.8533835, 2286.0, 5942.340725785388, 1812811999.5683062, 2912.0, 5878.281892363433, 1814259850.4060605, 3005.0, 5901.599762880298, 1836905242.4738734, 3490.0, 6174.030808682003, 1818288411.216502, 2876.0]
[2019-03-23 13:11:21,875] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 1.1858442e-32 3.9175552e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 13:11:21,883] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8733
[2019-03-23 13:11:21,889] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 53.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6121546131861639, 6.911199999999999, 6.9112, 77.32846344354104, 354631.77917646, 354631.7791764603, 115583.2362148339], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3927000.0000, 
sim time next is 3927600.0000, 
raw observation next is [23.0, 53.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6081633128103339, 6.911199999999999, 6.9112, 77.32846344354104, 352509.7673065327, 352509.767306533, 115102.2081919298], 
processed observation next is [0.0, 0.4782608695652174, 0.6818181818181818, 0.53, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.44023330401476274, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1305591730764936, 0.1305591730764937, 0.28073709315104833], 
reward next is 0.7193, 
noisyNet noise sample is [array([-1.200844], dtype=float32), -1.6412076]. 
=============================================
[2019-03-23 13:11:21,915] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 2.3993286e-26 5.3602742e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 13:11:21,919] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2419
[2019-03-23 13:11:21,926] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.33333333333334, 70.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6558714293687476, 6.911199999999999, 6.9112, 77.32846344354104, 378655.3960795737, 378655.396079574, 120427.3165647885], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3919200.0000, 
sim time next is 3919800.0000, 
raw observation next is [21.66666666666667, 69.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6719195512099605, 6.911199999999999, 6.9112, 77.32846344354104, 387472.9961180944, 387472.9961180947, 122283.7710730016], 
processed observation next is [0.0, 0.34782608695652173, 0.6212121212121214, 0.6966666666666665, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5313136445856579, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14350851708077572, 0.14350851708077583, 0.2982531001780527], 
reward next is 0.7017, 
noisyNet noise sample is [array([0.89746475], dtype=float32), 0.10899312]. 
=============================================
[2019-03-23 13:11:22,664] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 9.8752707e-33 1.0742361e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 13:11:22,679] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9326
[2019-03-23 13:11:22,685] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.66666666666667, 51.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.61182836988626, 6.9112, 6.9112, 77.32846344354104, 354521.8972500748, 354521.8972500748, 115496.1972396789], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3928800.0000, 
sim time next is 3929400.0000, 
raw observation next is [24.0, 50.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6169730005914689, 6.9112, 6.9112, 77.32846344354104, 357310.5158367857, 357310.5158367857, 116079.3750749182], 
processed observation next is [0.0, 0.4782608695652174, 0.7272727272727273, 0.5, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.452818572273527, 0.0, 0.0, 0.5084288129206541, 0.1323372280876984, 0.1323372280876984, 0.28312042701199563], 
reward next is 0.7169, 
noisyNet noise sample is [array([1.4250554], dtype=float32), 1.3047193]. 
=============================================
[2019-03-23 13:11:23,832] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 2.5800606e-34 3.3936429e-24 4.4848848e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 13:11:23,838] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6493
[2019-03-23 13:11:23,842] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.5, 58.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5830186750251264, 6.9112, 6.9112, 77.32846344354104, 338783.7324627059, 338783.7324627059, 112393.8528870677], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3965400.0000, 
sim time next is 3966000.0000, 
raw observation next is [21.33333333333334, 59.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5767677877929023, 6.9112, 6.9112, 77.32846344354104, 335273.074745846, 335273.074745846, 111810.0793676038], 
processed observation next is [0.0, 0.9130434782608695, 0.6060606060606063, 0.59, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.39538255398986044, 0.0, 0.0, 0.5084288129206541, 0.12417521286883185, 0.12417521286883185, 0.2727075106526922], 
reward next is 0.7273, 
noisyNet noise sample is [array([-0.39821035], dtype=float32), -0.63069004]. 
=============================================
[2019-03-23 13:11:23,855] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[57.350224]
 [57.34524 ]
 [57.34337 ]
 [57.353   ]
 [57.312557]], R is [[57.50214386]
 [57.65299225]
 [57.80122757]
 [57.94726944]
 [58.09105682]].
[2019-03-23 13:11:28,355] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 13:11:28,361] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0600
[2019-03-23 13:11:28,366] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6174091736907714, 6.9112, 6.9112, 77.32846344354104, 358442.2080257083, 358442.2080257083, 115453.0448400962], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4054800.0000, 
sim time next is 4055400.0000, 
raw observation next is [17.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6106183706758913, 6.9112, 6.9112, 77.32846344354104, 354511.8315758598, 354511.8315758598, 114870.9592457653], 
processed observation next is [1.0, 0.9565217391304348, 0.4090909090909091, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4437405295369876, 0.0, 0.0, 0.5084288129206541, 0.13130067836142956, 0.13130067836142956, 0.2801730713311349], 
reward next is 0.7198, 
noisyNet noise sample is [array([0.95464396], dtype=float32), -0.09883675]. 
=============================================
[2019-03-23 13:11:28,571] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 6.8331134e-36 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 13:11:28,582] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1615
[2019-03-23 13:11:28,587] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.0, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6326978387799408, 6.911199999999999, 6.9112, 77.32846344354104, 366746.3156904154, 366746.3156904157, 117203.5657376989], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4052400.0000, 
sim time next is 4053000.0000, 
raw observation next is [17.0, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6281701187611497, 6.911199999999999, 6.9112, 77.32846344354104, 364323.1245747585, 364323.1245747588, 116654.2453891227], 
processed observation next is [1.0, 0.9130434782608695, 0.4090909090909091, 0.95, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.46881445537307104, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1349344905832439, 0.134934490583244, 0.2845225497295676], 
reward next is 0.7155, 
noisyNet noise sample is [array([1.5497123], dtype=float32), 0.33340678]. 
=============================================
[2019-03-23 13:11:28,607] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[75.37477 ]
 [75.3132  ]
 [75.25224 ]
 [75.194275]
 [75.16882 ]], R is [[75.38394928]
 [75.34424591]
 [75.30305481]
 [75.26041412]
 [75.21651459]].
[2019-03-23 13:11:30,851] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 5.0657637e-23 3.9824491e-15 1.7591993e-20 1.0132356e-31], sum to 1.0000
[2019-03-23 13:11:30,855] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1748
[2019-03-23 13:11:30,858] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 754767.0862198774 W.
[2019-03-23 13:11:30,877] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 73.0, 1.0, 2.0, 0.2205727948346686, 1.0, 1.0, 0.2205727948346686, 1.0, 2.0, 0.4430962423443565, 6.911199999999999, 6.9112, 77.3421103, 754767.0862198774, 754767.0862198776, 226543.8039655956], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4105200.0000, 
sim time next is 4105800.0000, 
raw observation next is [22.5, 73.0, 1.0, 2.0, 0.6016448044502045, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 683970.703820377, 683970.703820377, 149355.3963537611], 
processed observation next is [1.0, 0.5217391304347826, 0.6590909090909091, 0.73, 1.0, 1.0, 0.5020560055627556, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25332248289643594, 0.25332248289643594, 0.36428145452136856], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2092102], dtype=float32), 0.37228927]. 
=============================================
[2019-03-23 13:11:32,939] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 5.6517151e-25 1.9495147e-21 4.7157292e-22 3.2363500e-30], sum to 1.0000
[2019-03-23 13:11:32,950] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7554
[2019-03-23 13:11:32,952] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7518911713677728, 7.227876752083371, 6.9112, 77.32742693271577, 535604.7021086339, 432755.9487949642, 131233.7567242387], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4137000.0000, 
sim time next is 4137600.0000, 
raw observation next is [18.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7504912595864954, 7.216679282486983, 6.9112, 77.3274588549085, 531189.9669312075, 431977.833011543, 131056.1779181742], 
processed observation next is [1.0, 0.9130434782608695, 0.45454545454545453, 1.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6435589422664221, 0.03054792824869832, 0.0, 0.5084222078261886, 0.1967370247893361, 0.1599917900042752, 0.3196492144345712], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.50058156], dtype=float32), -0.4321802]. 
=============================================
[2019-03-23 13:11:35,888] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9641550e-01 1.6281594e-04 2.7201073e-03 7.0151757e-04 2.5328592e-11], sum to 1.0000
[2019-03-23 13:11:35,893] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6866
[2019-03-23 13:11:35,899] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 862684.5638319432 W.
[2019-03-23 13:11:35,903] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.33333333333333, 75.83333333333333, 1.0, 2.0, 0.3799043425740891, 1.0, 1.0, 0.3799043425740891, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 862684.5638319432, 862684.5638319432, 193338.790170545], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4187400.0000, 
sim time next is 4188000.0000, 
raw observation next is [21.66666666666667, 73.66666666666667, 1.0, 2.0, 0.34261251466896, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6784014830357848, 6.911200000000001, 6.9112, 77.32846344354104, 776324.9231741335, 776324.9231741332, 194130.3418265263], 
processed observation next is [1.0, 0.4782608695652174, 0.6212121212121214, 0.7366666666666667, 1.0, 1.0, 0.17826564333619996, 0.0, 0.5, -0.25, 1.0, 0.5, 0.5405735471939784, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.28752774932375313, 0.287527749323753, 0.47348863860128365], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.82515466], dtype=float32), -0.094055705]. 
=============================================
[2019-03-23 13:11:35,918] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[28.780886]
 [28.746931]
 [28.241158]
 [28.560637]
 [28.64345 ]], R is [[28.17541122]
 [27.89365768]
 [28.2480278 ]
 [28.43288612]
 [28.14855766]].
[2019-03-23 13:11:36,844] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.7008634e-01 5.1050088e-03 6.8452070e-03 1.7960114e-02 3.3497556e-06], sum to 1.0000
[2019-03-23 13:11:36,855] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1992
[2019-03-23 13:11:36,860] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 604210.4267239684 W.
[2019-03-23 13:11:36,866] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.5, 63.0, 1.0, 2.0, 0.266838100681587, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5279008021588327, 6.911199999999999, 6.9112, 77.32846344354104, 604210.4267239684, 604210.4267239687, 174549.1930413788], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4192200.0000, 
sim time next is 4192800.0000, 
raw observation next is [23.66666666666667, 62.33333333333333, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3677109751060993, 6.9112, 6.9112, 77.3421103, 629634.5459270482, 629634.5459270482, 211093.73828249], 
processed observation next is [1.0, 0.5217391304347826, 0.7121212121212124, 0.6233333333333333, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.09672996443728472, 0.0, 0.0, 0.5085185399722538, 0.2331979799729808, 0.2331979799729808, 0.5148627762987561], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.88004875], dtype=float32), -1.294359]. 
=============================================
[2019-03-23 13:11:38,416] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9991393e-01 4.0836807e-05 4.9550686e-06 4.0249306e-05 1.2133513e-18], sum to 1.0000
[2019-03-23 13:11:38,426] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5029
[2019-03-23 13:11:38,429] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7162088862480638, 6.943897846722494, 6.9112, 77.32832213947002, 423641.6798666957, 413022.1074432749, 126741.3781078762], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4231200.0000, 
sim time next is 4231800.0000, 
raw observation next is [19.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7162893552662936, 6.944567910996991, 6.9112, 77.32831117585754, 423905.874218353, 413068.6805579257, 126749.7218412951], 
processed observation next is [1.0, 1.0, 0.5, 0.88, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.594699078951848, 0.003336791099699088, 0.0, 0.5084278117721233, 0.15700217563642704, 0.15298840020663915, 0.30914566302754903], 
reward next is 0.5240, 
noisyNet noise sample is [array([-0.64173305], dtype=float32), 1.5029198]. 
=============================================
[2019-03-23 13:11:39,549] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9999464e-01 3.9159581e-06 1.0216722e-06 4.2948810e-07 6.6344922e-24], sum to 1.0000
[2019-03-23 13:11:39,557] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8330
[2019-03-23 13:11:39,561] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5764606721884893, 6.911199999999998, 6.9112, 77.32846344354104, 335313.2680421701, 335313.2680421707, 111617.9276787426], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4247400.0000, 
sim time next is 4248000.0000, 
raw observation next is [16.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5759312059616849, 6.911200000000001, 6.9112, 77.32846344354104, 335005.467162892, 335005.4671628917, 111576.7889163763], 
processed observation next is [1.0, 0.17391304347826086, 0.36363636363636365, 1.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3941874370881213, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12407609894921925, 0.12407609894921914, 0.2721385095521373], 
reward next is 0.7279, 
noisyNet noise sample is [array([-0.68088126], dtype=float32), -1.4929855]. 
=============================================
[2019-03-23 13:11:39,576] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[72.724915]
 [72.65732 ]
 [72.58922 ]
 [72.57652 ]
 [72.47917 ]], R is [[72.74298096]
 [72.74330902]
 [72.74340057]
 [72.74304199]
 [72.74123383]].
[2019-03-23 13:11:41,045] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.9004983e-01 1.5439354e-01 5.5601705e-02 9.9787191e-02 1.6771127e-04], sum to 1.0000
[2019-03-23 13:11:41,051] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2714
[2019-03-23 13:11:41,057] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 951894.872806017 W.
[2019-03-23 13:11:41,064] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.35, 58.0, 1.0, 2.0, 0.4197009496384314, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8321390905785369, 6.911200000000001, 6.9112, 77.32846344354104, 951894.872806017, 951894.8728060167, 219235.2431137018], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4271400.0000, 
sim time next is 4272000.0000, 
raw observation next is [24.46666666666667, 57.0, 1.0, 2.0, 0.2796519864047551, 1.0, 1.0, 0.2796519864047551, 1.0, 2.0, 0.5587345920777577, 6.911199999999999, 6.9112, 77.3421103, 955171.5542051732, 955171.5542051734, 240400.7771867342], 
processed observation next is [1.0, 0.43478260869565216, 0.7484848484848485, 0.57, 1.0, 1.0, 0.09956498300594384, 1.0, 0.5, 0.09956498300594384, 1.0, 1.0, 0.36962084582536814, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.35376724229821227, 0.3537672422982124, 0.5863433589920346], 
reward next is 0.4137, 
noisyNet noise sample is [array([0.7215721], dtype=float32), 0.9578238]. 
=============================================
[2019-03-23 13:11:41,083] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[14.294939]
 [14.310982]
 [14.079184]
 [13.709871]
 [13.789898]], R is [[15.08988762]
 [15.40426826]
 [15.81366539]
 [15.65552902]
 [15.49897385]].
[2019-03-23 13:11:41,947] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.7199748e-05 3.3977184e-01 7.7653895e-03 6.5240556e-01 9.5893089e-09], sum to 1.0000
[2019-03-23 13:11:41,956] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2530
[2019-03-23 13:11:41,963] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1218658.988632372 W.
[2019-03-23 13:11:41,970] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 46.0, 1.0, 2.0, 0.5339594910246015, 1.0, 2.0, 0.5339594910246015, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1218658.988632372, 1218658.988632372, 230846.923594715], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4294200.0000, 
sim time next is 4294800.0000, 
raw observation next is [27.0, 45.0, 1.0, 2.0, 0.5157971063965104, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9430706399987224, 6.94143823889384, 6.9112, 77.32838926427394, 1134648.700980899, 1124827.948887933, 246741.0996267834], 
processed observation next is [1.0, 0.7391304347826086, 0.8636363636363636, 0.45, 1.0, 1.0, 0.394746382995638, 0.0, 0.5, -0.25, 1.0, 0.5, 0.918672342855318, 0.0030238238893839585, 0.0, 0.5084283251975695, 0.4202402596225552, 0.4166029440325678, 0.6018075600653253], 
reward next is 0.2470, 
noisyNet noise sample is [array([-0.5284755], dtype=float32), -0.8040525]. 
=============================================
[2019-03-23 13:11:42,039] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6161015e-03 1.0209013e-01 2.6165152e-02 8.7012863e-01 1.2939992e-07], sum to 1.0000
[2019-03-23 13:11:42,053] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4646
[2019-03-23 13:11:42,057] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.16666666666666, 60.33333333333334, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 448139.4167087667, 448139.4167087667, 164396.1868585215], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4305000.0000, 
sim time next is 4305600.0000, 
raw observation next is [24.0, 61.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 448412.8635518949, 448412.8635518946, 164319.8509728545], 
processed observation next is [1.0, 0.8695652173913043, 0.7272727272727273, 0.61, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16607883835255366, 0.16607883835255355, 0.40078012432403537], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.35560462], dtype=float32), -0.8160867]. 
=============================================
[2019-03-23 13:11:48,714] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5341049e-10 9.9999845e-01 4.3280947e-13 1.5401711e-06 2.3291603e-21], sum to 1.0000
[2019-03-23 13:11:48,727] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5727
[2019-03-23 13:11:48,729] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 83.0, 1.0, 2.0, 0.4302225951392199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 489752.0131395865, 489752.0131395862, 131012.0457610883], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4434600.0000, 
sim time next is 4435200.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4367910925172884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 497557.9061455932, 497557.9061455929, 132040.853087802], 
processed observation next is [0.0, 0.34782608695652173, 0.6363636363636364, 0.83, 1.0, 1.0, 0.2959888656466105, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18428070597984933, 0.18428070597984922, 0.322050861189761], 
reward next is 0.6779, 
noisyNet noise sample is [array([3.154722], dtype=float32), 0.8829151]. 
=============================================
[2019-03-23 13:11:50,523] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2103181e-09 9.9999654e-01 7.0072718e-13 3.4843338e-06 3.3943408e-18], sum to 1.0000
[2019-03-23 13:11:50,529] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5059
[2019-03-23 13:11:50,534] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333333, 76.66666666666666, 1.0, 2.0, 0.5066527918664214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 577804.8225553636, 577804.8225553636, 142876.7362529878], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4467000.0000, 
sim time next is 4467600.0000, 
raw observation next is [24.0, 78.0, 1.0, 2.0, 0.5018138408913484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 572424.6451991906, 572424.6451991908, 142045.7654075571], 
processed observation next is [0.0, 0.7391304347826086, 0.7272727272727273, 0.78, 1.0, 1.0, 0.37726730111418544, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21200912785155207, 0.21200912785155215, 0.34645308635989536], 
reward next is 0.6535, 
noisyNet noise sample is [array([0.33597556], dtype=float32), -0.06480454]. 
=============================================
[2019-03-23 13:11:52,796] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2173386e-11 9.9999070e-01 8.4290168e-18 9.2630225e-06 6.6347194e-24], sum to 1.0000
[2019-03-23 13:11:52,802] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5780
[2019-03-23 13:11:52,808] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 94.0, 1.0, 2.0, 0.4320873064960606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 491014.4479761011, 491014.4479761011, 130404.7890287598], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4500000.0000, 
sim time next is 4500600.0000, 
raw observation next is [20.0, 94.00000000000001, 1.0, 2.0, 0.4283018009438522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 486585.0945567675, 486585.0945567675, 129927.7790875539], 
processed observation next is [0.0, 0.08695652173913043, 0.5454545454545454, 0.9400000000000002, 1.0, 1.0, 0.28537725117981516, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18021670168769166, 0.18021670168769166, 0.3168970221647656], 
reward next is 0.6831, 
noisyNet noise sample is [array([0.3075621], dtype=float32), -1.3378848]. 
=============================================
[2019-03-23 13:11:57,231] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8516271e-08 9.9988079e-01 1.3951530e-13 1.1916349e-04 2.0382572e-17], sum to 1.0000
[2019-03-23 13:11:57,237] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7634
[2019-03-23 13:11:57,243] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 96.0, 1.0, 2.0, 0.2264923647800929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 245917.0722921776, 245917.0722921773, 78807.71718214954], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4596000.0000, 
sim time next is 4596600.0000, 
raw observation next is [14.0, 95.0, 1.0, 2.0, 0.2243494969158671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 243589.8426306355, 243589.8426306352, 78139.47833202117], 
processed observation next is [1.0, 0.17391304347826086, 0.2727272727272727, 0.95, 1.0, 1.0, 0.03043687114483388, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0902184602335687, 0.0902184602335686, 0.19058409349273456], 
reward next is 0.8094, 
noisyNet noise sample is [array([-0.64592415], dtype=float32), -0.026138293]. 
=============================================
[2019-03-23 13:12:00,863] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4521879e-12 1.0000000e+00 4.4972130e-19 2.0694852e-09 9.2820579e-25], sum to 1.0000
[2019-03-23 13:12:00,871] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1496
[2019-03-23 13:12:00,877] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 82.0, 1.0, 2.0, 0.2439387727475971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 264864.8976793649, 264864.8976793646, 83409.96159285911], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4671600.0000, 
sim time next is 4672200.0000, 
raw observation next is [16.0, 82.0, 1.0, 2.0, 0.2431446729198389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 264002.4425163615, 264002.4425163612, 83321.43355007574], 
processed observation next is [1.0, 0.043478260869565216, 0.36363636363636365, 0.82, 1.0, 1.0, 0.05393084114979862, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09777868241346721, 0.09777868241346711, 0.20322300865872134], 
reward next is 0.7968, 
noisyNet noise sample is [array([1.7468156], dtype=float32), -0.8372614]. 
=============================================
[2019-03-23 13:12:05,882] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 13:12:05,883] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:12:05,884] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:12:05,884] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:12:05,884] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:12:05,886] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:12:05,887] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:12:05,889] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:12:05,891] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:12:05,890] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:12:05,893] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:12:05,908] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run40
[2019-03-23 13:12:05,932] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run40
[2019-03-23 13:12:05,933] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run40
[2019-03-23 13:12:05,956] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run40
[2019-03-23 13:12:06,007] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run40
[2019-03-23 13:12:24,702] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.3357127]
[2019-03-23 13:12:24,702] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.66666666666666, 90.66666666666666, 1.0, 2.0, 0.8335348692308497, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 950041.3257989562, 950041.3257989564, 190565.133086224]
[2019-03-23 13:12:24,704] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:12:24,706] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.2915862e-09 9.9999738e-01 3.1254482e-14 2.5840798e-06 8.7187632e-18], sampled 0.35945403402475684
[2019-03-23 13:12:27,575] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.3357127]
[2019-03-23 13:12:27,577] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.26666666666667, 86.66666666666666, 1.0, 2.0, 0.4466092595634329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 508305.9460693148, 508305.9460693145, 136923.4116696794]
[2019-03-23 13:12:27,578] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:12:27,580] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.2830273e-09 9.9999857e-01 8.0925875e-15 1.4667630e-06 1.6291166e-18], sampled 0.4724700902649628
[2019-03-23 13:12:27,598] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.3357127]
[2019-03-23 13:12:27,602] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.3, 88.0, 1.0, 2.0, 0.3764182592368283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 416964.1691787512, 416964.1691787508, 123838.1606842427]
[2019-03-23 13:12:27,604] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:12:27,606] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.8476987e-09 9.9999845e-01 9.3482563e-15 1.5424171e-06 2.0072214e-18], sampled 0.7789450840847849
[2019-03-23 13:12:32,185] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.3357127]
[2019-03-23 13:12:32,186] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.38333333333333, 68.33333333333333, 1.0, 2.0, 0.4927454410402143, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 562138.2442338907, 562138.2442338903, 144958.4195437299]
[2019-03-23 13:12:32,186] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:12:32,188] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.0269153e-09 9.9999833e-01 1.0658666e-14 1.6462814e-06 2.3136664e-18], sampled 0.3136957683556081
[2019-03-23 13:12:46,596] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.3357127]
[2019-03-23 13:12:46,598] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.1, 66.0, 1.0, 2.0, 0.5513511399829528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 628975.5365058562, 628975.5365058562, 150503.4610410506]
[2019-03-23 13:12:46,600] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:12:46,602] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.5678581e-09 9.9999845e-01 8.8942432e-15 1.5204430e-06 1.8429348e-18], sampled 0.9840693507975143
[2019-03-23 13:12:51,863] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.3357127]
[2019-03-23 13:12:51,864] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.30782092833333, 74.121031675, 1.0, 2.0, 0.4126380118100117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 468006.459793334, 468006.459793334, 132150.3449482578]
[2019-03-23 13:12:51,865] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:12:51,870] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.7725854e-09 9.9999869e-01 6.1980141e-15 1.3036831e-06 1.1909011e-18], sampled 0.9542896143085922
[2019-03-23 13:12:56,790] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.3357127]
[2019-03-23 13:12:56,791] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 90.0, 1.0, 2.0, 0.4924538081527153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 561016.7437889344, 561016.7437889348, 137964.0868590816]
[2019-03-23 13:12:56,792] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:12:56,794] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.3095542e-09 9.9999809e-01 1.5221831e-14 1.9006093e-06 3.6455492e-18], sampled 0.4273035911611933
[2019-03-23 13:13:46,161] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 13:13:46,175] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 13:13:46,299] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 13:13:46,422] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 13:13:46,453] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 13:13:47,467] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 975000, evaluation results [975000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 13:13:48,552] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.3480779e-08 9.9999869e-01 2.5873387e-13 1.2009266e-06 9.8608823e-17], sum to 1.0000
[2019-03-23 13:13:48,561] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4438
[2019-03-23 13:13:48,566] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3665180411899291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 411441.8930937733, 411441.8930937733, 121090.7568117377], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4771800.0000, 
sim time next is 4772400.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3663806582901976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 411285.1430031187, 411285.143003119, 121077.9564935384], 
processed observation next is [1.0, 0.21739130434782608, 0.45454545454545453, 1.0, 1.0, 1.0, 0.207975822862747, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15232783074189582, 0.15232783074189593, 0.29531208900863026], 
reward next is 0.7047, 
noisyNet noise sample is [array([-0.98712444], dtype=float32), -0.3325648]. 
=============================================
[2019-03-23 13:13:49,395] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.2714775e-06 9.9804902e-01 3.5941630e-10 1.9477898e-03 4.7324961e-12], sum to 1.0000
[2019-03-23 13:13:49,409] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4533
[2019-03-23 13:13:49,413] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.6057676472722936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 658440.3553333232, 658440.3553333232, 137147.38176197], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4973400.0000, 
sim time next is 4974000.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.5846227386442782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 635574.1086484538, 635574.1086484542, 135052.088789292], 
processed observation next is [1.0, 0.5652173913043478, 0.5, 0.73, 1.0, 1.0, 0.48077842330534765, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23539781801794588, 0.235397818017946, 0.3293953385104683], 
reward next is 0.6706, 
noisyNet noise sample is [array([-1.6244743], dtype=float32), 0.3241167]. 
=============================================
[2019-03-23 13:13:49,430] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[46.452057]
 [46.608414]
 [46.745052]
 [46.566166]
 [46.41596 ]], R is [[46.73968887]
 [46.9377861 ]
 [47.14658737]
 [47.37493515]
 [47.60448074]].
[2019-03-23 13:13:49,951] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.1919503e-07 9.9997079e-01 7.9713536e-12 2.8253926e-05 3.9883648e-13], sum to 1.0000
[2019-03-23 13:13:49,958] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9763
[2019-03-23 13:13:49,964] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1196391.117653815 W.
[2019-03-23 13:13:49,975] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.0, 97.0, 1.0, 2.0, 0.9971688421185341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.096505903948986, 6.9112, 77.3280642756161, 1196391.117653815, 1136207.860878699, 220715.8676370125], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4807800.0000, 
sim time next is 4808400.0000, 
raw observation next is [22.0, 98.0, 1.0, 2.0, 0.3495076310102916, 1.0, 1.0, 0.3495076310102916, 1.0, 1.0, 0.7074676985835044, 6.9112, 6.9112, 77.3421103, 1186159.553834041, 1186159.553834041, 281593.3975786894], 
processed observation next is [1.0, 0.6521739130434783, 0.6363636363636364, 0.98, 1.0, 1.0, 0.18688453876286445, 1.0, 0.5, 0.18688453876286445, 1.0, 0.5, 0.5820967122621492, 0.0, 0.0, 0.5085185399722538, 0.4393183532718671, 0.4393183532718671, 0.6868131648260717], 
reward next is 0.3132, 
noisyNet noise sample is [array([-1.1186945], dtype=float32), -0.80641145]. 
=============================================
[2019-03-23 13:13:51,048] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6733431e-08 9.9993873e-01 2.1877275e-15 6.1321785e-05 1.4601034e-19], sum to 1.0000
[2019-03-23 13:13:51,055] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9008
[2019-03-23 13:13:51,063] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 96.0, 1.0, 2.0, 0.4745700535272598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 541485.7520215359, 541485.7520215359, 137653.1586325135], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4830000.0000, 
sim time next is 4830600.0000, 
raw observation next is [21.0, 95.0, 1.0, 2.0, 0.4691840358519569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 535272.7155228277, 535272.7155228277, 136798.5318133464], 
processed observation next is [1.0, 0.9130434782608695, 0.5909090909090909, 0.95, 1.0, 1.0, 0.3364800448149461, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1982491538973436, 0.1982491538973436, 0.3336549556423083], 
reward next is 0.6663, 
noisyNet noise sample is [array([-0.95581543], dtype=float32), -1.0599098]. 
=============================================
[2019-03-23 13:13:51,847] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.7173145e-08 9.9999142e-01 1.1732014e-14 8.6243817e-06 1.8474498e-16], sum to 1.0000
[2019-03-23 13:13:51,853] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7786
[2019-03-23 13:13:51,858] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 99.00000000000001, 1.0, 2.0, 0.4418789191733853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 503457.4533027901, 503457.4533027901, 132687.2921347941], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4842600.0000, 
sim time next is 4843200.0000, 
raw observation next is [20.0, 98.0, 1.0, 2.0, 0.4385442092731947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499446.5629808224, 499446.5629808224, 132090.2017590628], 
processed observation next is [1.0, 0.043478260869565216, 0.5454545454545454, 0.98, 1.0, 1.0, 0.29818026159149336, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1849802085114157, 0.1849802085114157, 0.32217122380259217], 
reward next is 0.6778, 
noisyNet noise sample is [array([0.38083988], dtype=float32), 1.2217809]. 
=============================================
[2019-03-23 13:13:54,381] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.0759947e-08 9.9999428e-01 2.9838632e-13 5.7673255e-06 7.3066592e-16], sum to 1.0000
[2019-03-23 13:13:54,389] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3747
[2019-03-23 13:13:54,394] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.8002580497404439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 908620.9661537859, 908620.9661537859, 175481.9706051185], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4881600.0000, 
sim time next is 4882200.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.7316552364568514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 830420.0758636708, 830420.0758636708, 165405.5122401708], 
processed observation next is [1.0, 0.5217391304347826, 0.5909090909090909, 0.83, 1.0, 1.0, 0.6645690455710642, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3075629910606188, 0.3075629910606188, 0.4034280786345629], 
reward next is 0.5966, 
noisyNet noise sample is [array([0.1436561], dtype=float32), -0.40734816]. 
=============================================
[2019-03-23 13:13:54,587] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.9776263e-08 9.9999249e-01 7.4046509e-14 7.3475053e-06 1.4958218e-15], sum to 1.0000
[2019-03-23 13:13:54,596] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6434
[2019-03-23 13:13:54,600] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 75.5, 1.0, 2.0, 0.4170236586395323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 473944.5417075017, 473944.5417075017, 128971.6107150298], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4901400.0000, 
sim time next is 4902000.0000, 
raw observation next is [22.66666666666666, 74.66666666666667, 1.0, 2.0, 0.4219979539060369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 479705.1473376881, 479705.1473376884, 129546.4088727526], 
processed observation next is [1.0, 0.7391304347826086, 0.6666666666666664, 0.7466666666666667, 1.0, 1.0, 0.2774974423825461, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17766857308803263, 0.17766857308803274, 0.31596685090915266], 
reward next is 0.6840, 
noisyNet noise sample is [array([0.37471434], dtype=float32), -1.4813008]. 
=============================================
[2019-03-23 13:13:54,613] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[55.752934]
 [55.681583]
 [55.517914]
 [55.131542]
 [55.01109 ]], R is [[55.9413414 ]
 [56.06736374]
 [56.19055939]
 [56.28750992]
 [56.30575562]].
[2019-03-23 13:13:59,600] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7407759e-11 1.0000000e+00 3.1621196e-20 1.1068561e-09 1.3009375e-21], sum to 1.0000
[2019-03-23 13:13:59,607] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9764
[2019-03-23 13:13:59,610] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 62.66666666666667, 1.0, 2.0, 0.2858214888301165, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 310355.0046395057, 310355.0046395057, 97793.48697073608], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4990800.0000, 
sim time next is 4991400.0000, 
raw observation next is [19.5, 64.0, 1.0, 2.0, 0.2855333238258375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 310042.00522192, 310042.00522192, 98184.07417188774], 
processed observation next is [1.0, 0.782608695652174, 0.5227272727272727, 0.64, 1.0, 1.0, 0.10691665478229688, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1148303723044148, 0.1148303723044148, 0.23947335163875058], 
reward next is 0.7605, 
noisyNet noise sample is [array([0.8415462], dtype=float32), -0.88161206]. 
=============================================
[2019-03-23 13:14:00,617] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.1850618e-12 1.0000000e+00 1.6978819e-21 4.3948010e-09 7.1762658e-23], sum to 1.0000
[2019-03-23 13:14:00,625] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0036
[2019-03-23 13:14:00,631] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.2403248374617912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 260939.8907420854, 260939.8907420854, 82295.60234217563], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5024400.0000, 
sim time next is 5025000.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.2404852647613726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 261114.1262460451, 261114.1262460451, 82319.08217475201], 
processed observation next is [0.0, 0.13043478260869565, 0.2727272727272727, 1.0, 1.0, 1.0, 0.050606580951715746, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09670893564668337, 0.09670893564668337, 0.20077824920671222], 
reward next is 0.7992, 
noisyNet noise sample is [array([-0.72973645], dtype=float32), 2.6389406]. 
=============================================
[2019-03-23 13:14:00,657] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[85.66054 ]
 [85.695526]
 [85.72832 ]
 [85.95482 ]
 [86.176506]], R is [[85.57751465]
 [85.52101898]
 [85.465271  ]
 [85.41009521]
 [85.35525513]].
[2019-03-23 13:14:00,761] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.5053153e-10 9.9999869e-01 1.1615485e-19 1.2842280e-06 1.7651106e-22], sum to 1.0000
[2019-03-23 13:14:00,768] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4513
[2019-03-23 13:14:00,773] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4386581447584045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499775.048020429, 499775.048020429, 132342.3261533377], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5199600.0000, 
sim time next is 5200200.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4329355927031092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 493245.955639325, 493245.9556393247, 131749.8619988137], 
processed observation next is [1.0, 0.17391304347826086, 0.6363636363636364, 0.83, 1.0, 1.0, 0.2911694908788865, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18268368727382409, 0.18268368727382395, 0.32134112682637483], 
reward next is 0.6787, 
noisyNet noise sample is [array([-0.48052678], dtype=float32), -0.59359175]. 
=============================================
[2019-03-23 13:14:00,976] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0886467e-09 1.0000000e+00 2.0608308e-17 1.5720026e-08 1.5354556e-19], sum to 1.0000
[2019-03-23 13:14:00,988] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4053
[2019-03-23 13:14:00,990] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2033371395274445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 220770.275404753, 220770.2754047533, 73989.70523655422], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5032200.0000, 
sim time next is 5032800.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2031492178153666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 220566.1959399273, 220566.1959399276, 73966.73000328451], 
processed observation next is [0.0, 0.2608695652173913, 0.22727272727272727, 1.0, 1.0, 1.0, 0.003936522269208237, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08169118368145456, 0.08169118368145467, 0.18040665854459637], 
reward next is 0.8196, 
noisyNet noise sample is [array([-0.4253192], dtype=float32), -0.9564361]. 
=============================================
[2019-03-23 13:14:02,074] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1016711e-08 1.0000000e+00 2.1793807e-16 5.8674516e-08 3.7282390e-17], sum to 1.0000
[2019-03-23 13:14:02,082] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3537
[2019-03-23 13:14:02,086] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 54.0, 1.0, 2.0, 0.404759620033281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 459703.4981554026, 459703.4981554029, 127544.9407639014], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5060400.0000, 
sim time next is 5061000.0000, 
raw observation next is [26.0, 54.0, 1.0, 2.0, 0.4054335845861505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 460470.6794099267, 460470.6794099264, 127610.2129217775], 
processed observation next is [0.0, 0.5652173913043478, 0.8181818181818182, 0.54, 1.0, 1.0, 0.25679198073268805, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17054469607775063, 0.17054469607775052, 0.31124442176043293], 
reward next is 0.6888, 
noisyNet noise sample is [array([-1.833845], dtype=float32), 0.90268874]. 
=============================================
[2019-03-23 13:14:02,100] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[72.25067 ]
 [72.2084  ]
 [72.163124]
 [72.110695]
 [72.07922 ]], R is [[72.25930786]
 [72.22562408]
 [72.19263458]
 [72.16022491]
 [72.12839508]].
[2019-03-23 13:14:02,459] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.3020452e-11 1.0000000e+00 7.6891298e-20 8.9715936e-11 1.8331808e-22], sum to 1.0000
[2019-03-23 13:14:02,465] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0567
[2019-03-23 13:14:02,467] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 83.0, 1.0, 2.0, 0.3295137563419289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 364829.376629559, 364829.3766295593, 115785.6432140939], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5043600.0000, 
sim time next is 5044200.0000, 
raw observation next is [19.5, 80.66666666666667, 1.0, 2.0, 0.3338957106817803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 370686.200415692, 370686.200415692, 116527.0862205534], 
processed observation next is [0.0, 0.391304347826087, 0.5227272727272727, 0.8066666666666668, 1.0, 1.0, 0.16736963835222537, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1372911853391452, 0.1372911853391452, 0.2842124054159839], 
reward next is 0.7158, 
noisyNet noise sample is [array([-0.78074706], dtype=float32), -0.6885562]. 
=============================================
[2019-03-23 13:14:04,247] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.2325183e-09 9.9999869e-01 4.8254324e-16 1.2919658e-06 1.6302119e-17], sum to 1.0000
[2019-03-23 13:14:04,265] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7722
[2019-03-23 13:14:04,269] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.401599997068757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 455095.7677011748, 455095.7677011751, 126501.6253037097], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5109600.0000, 
sim time next is 5110200.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.4013645712513365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 454829.3641388828, 454829.3641388831, 126479.9899176332], 
processed observation next is [0.0, 0.13043478260869565, 0.5909090909090909, 0.83, 1.0, 1.0, 0.2517057140641706, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16845532005143807, 0.16845532005143818, 0.30848778028691026], 
reward next is 0.6915, 
noisyNet noise sample is [array([-0.18251021], dtype=float32), -0.45299697]. 
=============================================
[2019-03-23 13:14:10,929] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.2450677e-06 9.9998856e-01 8.4340862e-13 9.1679558e-06 2.1328196e-14], sum to 1.0000
[2019-03-23 13:14:10,936] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0483
[2019-03-23 13:14:10,943] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 92.0, 1.0, 2.0, 0.6730714769541626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 767688.9309765429, 767688.9309765429, 161221.5999084485], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5217600.0000, 
sim time next is 5218200.0000, 
raw observation next is [21.0, 91.0, 1.0, 2.0, 0.6739673546980601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 768462.5130236639, 768462.5130236642, 160938.9761513172], 
processed observation next is [1.0, 0.391304347826087, 0.5909090909090909, 0.91, 1.0, 1.0, 0.5924591933725751, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.28461574556431996, 0.28461574556432007, 0.3925340881739444], 
reward next is 0.6075, 
noisyNet noise sample is [array([-1.2377919], dtype=float32), -1.0625988]. 
=============================================
[2019-03-23 13:14:16,555] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.21273017e-04 9.97907281e-01 7.44245838e-08 1.27138908e-03
 1.19642225e-08], sum to 1.0000
[2019-03-23 13:14:16,562] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2049
[2019-03-23 13:14:16,568] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1574747.023528391 W.
[2019-03-23 13:14:16,573] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.9, 51.0, 1.0, 2.0, 0.6990515960779293, 1.0, 1.0, 0.6990515960779293, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1574747.023528391, 1574747.023528391, 290998.8700619623], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5327400.0000, 
sim time next is 5328000.0000, 
raw observation next is [30.0, 51.0, 1.0, 2.0, 0.4607725014934109, 1.0, 2.0, 0.4607725014934109, 1.0, 1.0, 0.9320740398791262, 6.9112, 6.9112, 77.3421103, 1554630.764791283, 1554630.764791283, 338382.3694256535], 
processed observation next is [1.0, 0.6956521739130435, 1.0, 0.51, 1.0, 1.0, 0.3259656268667636, 1.0, 1.0, 0.3259656268667636, 1.0, 0.5, 0.9029629141130375, 0.0, 0.0, 0.5085185399722538, 0.5757891721449196, 0.5757891721449196, 0.8253228522576914], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.8916199], dtype=float32), 0.97231615]. 
=============================================
[2019-03-23 13:14:16,587] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[22.83493 ]
 [22.493376]
 [22.538235]
 [22.507204]
 [22.285149]], R is [[22.43254662]
 [22.20822144]
 [21.9861393 ]
 [21.947649  ]
 [21.9640522 ]].
[2019-03-23 13:14:18,862] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.4803005e-06 9.9998116e-01 2.7140564e-14 1.0416066e-05 2.2124922e-14], sum to 1.0000
[2019-03-23 13:14:18,873] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0316
[2019-03-23 13:14:18,879] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 82.0, 1.0, 2.0, 0.692227033181693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 82.07701056898799, 788910.4419772085, 788910.4419772085, 164647.3166240455], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5364600.0000, 
sim time next is 5365200.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.5798783242990228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 660909.8225364233, 660909.8225364233, 148415.5508358704], 
processed observation next is [1.0, 0.08695652173913043, 0.6363636363636364, 0.83, 1.0, 1.0, 0.4748479053737784, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24478141575423087, 0.24478141575423087, 0.3619891483801717], 
reward next is 0.6380, 
noisyNet noise sample is [array([0.97595716], dtype=float32), 1.7714286]. 
=============================================
[2019-03-23 13:14:21,572] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.7626610e-05 9.9967003e-01 9.3119089e-12 2.5235597e-04 4.6032804e-12], sum to 1.0000
[2019-03-23 13:14:21,582] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5283
[2019-03-23 13:14:21,590] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.71666666666667, 93.5, 1.0, 2.0, 0.3869341765812577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 434440.1270800389, 434440.1270800389, 122874.2156452616], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5433000.0000, 
sim time next is 5433600.0000, 
raw observation next is [18.63333333333333, 94.0, 1.0, 2.0, 0.3852747066436508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 432437.145774332, 432437.1457743317, 122662.5329789096], 
processed observation next is [1.0, 0.9130434782608695, 0.48333333333333317, 0.94, 1.0, 1.0, 0.2315933833045635, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1601619058423452, 0.16016190584234508, 0.29917690970465755], 
reward next is 0.7008, 
noisyNet noise sample is [array([0.4655666], dtype=float32), 0.4894792]. 
=============================================
[2019-03-23 13:14:24,383] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5695673e-07 9.9996734e-01 3.5435913e-18 3.2487998e-05 4.9051351e-18], sum to 1.0000
[2019-03-23 13:14:24,390] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3692
[2019-03-23 13:14:24,396] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.43333333333334, 96.66666666666667, 1.0, 2.0, 0.3162513347685356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 344291.4904398115, 344291.4904398112, 112599.7774725788], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5646000.0000, 
sim time next is 5646600.0000, 
raw observation next is [16.35, 96.5, 1.0, 2.0, 0.3130413679245364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 340076.7710994083, 340076.7710994083, 112128.7185875865], 
processed observation next is [0.0, 0.34782608695652173, 0.37954545454545463, 0.965, 1.0, 1.0, 0.14130170990567048, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1259543596664475, 0.1259543596664475, 0.2734846794819183], 
reward next is 0.7265, 
noisyNet noise sample is [array([-1.2422794], dtype=float32), 1.1371285]. 
=============================================
[2019-03-23 13:14:31,521] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.5946853e-10 9.9999750e-01 4.8486426e-22 2.4834887e-06 5.0775528e-23], sum to 1.0000
[2019-03-23 13:14:31,529] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4920
[2019-03-23 13:14:31,533] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.9, 95.5, 1.0, 2.0, 0.4190094921543328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476086.2212627325, 476086.2212627325, 129068.9793964175], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5619000.0000, 
sim time next is 5619600.0000, 
raw observation next is [20.0, 96.0, 1.0, 2.0, 0.4252376167054784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 483594.7331647129, 483594.7331647129, 130046.0953618978], 
processed observation next is [0.0, 0.043478260869565216, 0.5454545454545454, 0.96, 1.0, 1.0, 0.28154702088184796, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17910916043137515, 0.17910916043137515, 0.3171855984436532], 
reward next is 0.6828, 
noisyNet noise sample is [array([0.6665033], dtype=float32), 0.18775079]. 
=============================================
[2019-03-23 13:14:35,980] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 13:14:35,984] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:14:35,986] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:14:35,987] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:14:35,988] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:14:35,989] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:14:35,987] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:14:35,988] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:14:35,991] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:14:35,992] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:14:35,994] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:14:36,011] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run41
[2019-03-23 13:14:36,035] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run41
[2019-03-23 13:14:36,059] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run41
[2019-03-23 13:14:36,061] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run41
[2019-03-23 13:14:36,104] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run41
[2019-03-23 13:14:50,903] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.35499012]
[2019-03-23 13:14:50,904] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 94.0, 1.0, 2.0, 0.3740906619797216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 421508.6794463283, 421508.6794463283, 122535.0989653488]
[2019-03-23 13:14:50,905] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:14:50,907] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.9884454e-10 9.9999976e-01 1.0102604e-22 2.3017587e-07 4.2357044e-23], sampled 0.15184244414678594
[2019-03-23 13:14:53,538] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.35499012]
[2019-03-23 13:14:53,539] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.5, 71.5, 1.0, 2.0, 0.6877321014398708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 784955.6404050133, 784955.6404050133, 165073.9166718692]
[2019-03-23 13:14:53,541] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:14:53,544] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.5840444e-09 9.9999881e-01 1.9609325e-20 1.1364629e-06 9.2047390e-21], sampled 0.4629738634695386
[2019-03-23 13:14:55,784] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.35499012]
[2019-03-23 13:14:55,785] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [29.31585029, 80.77370244, 1.0, 2.0, 0.8444458528064896, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9865530188920543, 6.911200000000001, 6.9112, 95.55302600693257, 1497614.21049562, 1497614.210495619, 328122.9876508103]
[2019-03-23 13:14:55,787] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:14:55,793] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.6592079e-08 9.9999332e-01 5.1567568e-18 6.5578806e-06 2.5206340e-18], sampled 0.18706825136144634
[2019-03-23 13:14:55,796] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1497614.21049562 W.
[2019-03-23 13:15:18,031] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.35499012]
[2019-03-23 13:15:18,033] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [28.0, 58.0, 1.0, 2.0, 0.9354178496856355, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9764690987284506, 6.9112, 6.9112, 79.40912120661223, 1612463.74589878, 1612463.74589878, 331793.032160555]
[2019-03-23 13:15:18,034] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:15:18,036] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.06497176e-08 9.99998450e-01 5.88610350e-20 1.56381964e-06
 2.87350945e-20], sampled 0.29705057180750727
[2019-03-23 13:15:18,038] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1612463.74589878 W.
[2019-03-23 13:15:22,987] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.35499012]
[2019-03-23 13:15:22,989] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.48333333333333, 43.0, 1.0, 2.0, 0.3226566257706622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 351787.5986497269, 351787.5986497265, 117542.2174069849]
[2019-03-23 13:15:22,992] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:15:22,994] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.4440775e-10 9.9999976e-01 8.0707375e-23 2.1409089e-07 3.2884298e-23], sampled 0.10213220431132686
[2019-03-23 13:15:45,385] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.35499012]
[2019-03-23 13:15:45,386] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.16666666666667, 87.0, 1.0, 2.0, 0.2672619377899217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 290196.3800568123, 290196.3800568125, 91765.90790666071]
[2019-03-23 13:15:45,389] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:15:45,395] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.9053380e-09 9.9999928e-01 3.1363233e-21 6.9711194e-07 1.1987168e-21], sampled 0.3897817795734507
[2019-03-23 13:16:17,634] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 13:16:17,693] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 13:16:17,804] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 13:16:17,823] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 13:16:17,874] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 13:16:18,886] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1000000, evaluation results [1000000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 13:16:20,019] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1733154e-06 9.9998534e-01 8.8746633e-17 1.3458061e-05 1.0983020e-16], sum to 1.0000
[2019-03-23 13:16:20,029] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9100
[2019-03-23 13:16:20,034] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [9.8, 86.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 145341.8156034347, 145341.8156034347, 57240.62030706942], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5714400.0000, 
sim time next is 5715000.0000, 
raw observation next is [9.7, 86.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 143851.6003749148, 143851.6003749148, 57047.1854626749], 
processed observation next is [0.0, 0.13043478260869565, 0.07727272727272724, 0.86, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.0532783705092277, 0.0532783705092277, 0.13913947673823146], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.29637322], dtype=float32), -0.98358196]. 
=============================================
[2019-03-23 13:16:20,056] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[49.68576 ]
 [49.708115]
 [50.48111 ]
 [50.033115]
 [49.233284]], R is [[46.85855865]
 [46.38997269]
 [45.92607498]
 [45.46681595]
 [45.01214981]].
[2019-03-23 13:16:29,077] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.5311294e-06 9.9998820e-01 6.0640861e-21 9.2738446e-06 8.0626397e-24], sum to 1.0000
[2019-03-23 13:16:29,086] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8214
[2019-03-23 13:16:29,090] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.28333333333333, 89.0, 1.0, 2.0, 0.2735049148493102, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 296977.1529124838, 296977.1529124841, 96424.61372827688], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5889000.0000, 
sim time next is 5889600.0000, 
raw observation next is [16.1, 90.0, 1.0, 2.0, 0.2704270258393386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 293634.110031416, 293634.1100314162, 95114.70163007456], 
processed observation next is [1.0, 0.17391304347826086, 0.3681818181818182, 0.9, 1.0, 1.0, 0.08803378229917322, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10875337408570963, 0.10875337408570969, 0.2319870771465233], 
reward next is 0.7680, 
noisyNet noise sample is [array([0.54498607], dtype=float32), 0.15688203]. 
=============================================
[2019-03-23 13:16:31,060] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1888488e-03 8.1106877e-01 6.3341010e-13 1.8674232e-01 3.9519027e-14], sum to 1.0000
[2019-03-23 13:16:31,067] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3664
[2019-03-23 13:16:31,073] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1175635.617005425 W.
[2019-03-23 13:16:31,075] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.28333333333333, 46.83333333333334, 1.0, 2.0, 0.5504182080030817, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9586049328537871, 6.919257894760844, 6.9112, 77.32844367625219, 1175635.617005425, 1173018.57826854, 256161.6151401872], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5935800.0000, 
sim time next is 5936400.0000, 
raw observation next is [27.2, 47.0, 1.0, 2.0, 0.499762884101992, 1.0, 1.0, 0.499762884101992, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.3284586014849, 1140703.243256723, 1140703.243256723, 223255.3761799498], 
processed observation next is [1.0, 0.7391304347826086, 0.8727272727272727, 0.47, 1.0, 1.0, 0.37470360512748996, 1.0, 0.5, 0.37470360512748996, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084287810845003, 0.4224826826876752, 0.4224826826876752, 0.5445253077559751], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6613835], dtype=float32), 0.30459204]. 
=============================================
[2019-03-23 13:16:38,268] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.1065800e-05 9.9981791e-01 4.7485796e-18 1.5098971e-04 8.1143769e-21], sum to 1.0000
[2019-03-23 13:16:38,275] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5169
[2019-03-23 13:16:38,278] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.55, 62.0, 1.0, 2.0, 0.4199603654609113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 456076.0130608899, 456076.0130608899, 101973.4788033296], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6082200.0000, 
sim time next is 6082800.0000, 
raw observation next is [18.83333333333333, 61.0, 1.0, 2.0, 0.3738509820087703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 405980.4197271408, 405980.4197271405, 98179.98514469212], 
processed observation next is [1.0, 0.391304347826087, 0.4924242424242422, 0.61, 1.0, 1.0, 0.21731372751096287, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15036311841745956, 0.15036311841745945, 0.2394633784016881], 
reward next is 0.7605, 
noisyNet noise sample is [array([0.06769519], dtype=float32), 1.8787749]. 
=============================================
[2019-03-23 13:16:47,529] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2654415e-05 9.9912256e-01 7.7381266e-18 8.6481147e-04 1.1475403e-18], sum to 1.0000
[2019-03-23 13:16:47,535] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8187
[2019-03-23 13:16:47,540] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 82.83333333333334, 1.0, 2.0, 0.4144637000002989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 471265.4742332404, 471265.4742332404, 128923.810075695], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6253800.0000, 
sim time next is 6254400.0000, 
raw observation next is [21.6, 83.66666666666667, 1.0, 2.0, 0.4180133634238242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 475563.9402971599, 475563.9402971599, 129510.5453056382], 
processed observation next is [0.0, 0.391304347826087, 0.6181818181818183, 0.8366666666666667, 1.0, 1.0, 0.27251670427978025, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1761347927026518, 0.1761347927026518, 0.3158793787942395], 
reward next is 0.6841, 
noisyNet noise sample is [array([0.8461096], dtype=float32), 1.5080591]. 
=============================================
[2019-03-23 13:16:50,626] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.7283324e-06 9.9997628e-01 4.7701964e-17 2.0941237e-05 1.6065241e-18], sum to 1.0000
[2019-03-23 13:16:50,635] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4550
[2019-03-23 13:16:50,640] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 77.66666666666667, 1.0, 2.0, 0.4868411451647196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 555407.5148399968, 555407.5148399968, 140139.6675985963], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6306600.0000, 
sim time next is 6307200.0000, 
raw observation next is [23.8, 79.0, 1.0, 2.0, 0.4868620123055888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 555433.5624498741, 555433.5624498745, 140135.9166551309], 
processed observation next is [0.0, 0.0, 0.7181818181818183, 0.79, 1.0, 1.0, 0.35857751538198596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20571613424069413, 0.20571613424069424, 0.34179491867105094], 
reward next is 0.6582, 
noisyNet noise sample is [array([1.4802804], dtype=float32), 1.5383201]. 
=============================================
[2019-03-23 13:16:53,568] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4469257e-08 9.9999750e-01 3.2592428e-19 2.5045572e-06 1.7774822e-20], sum to 1.0000
[2019-03-23 13:16:53,577] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0160
[2019-03-23 13:16:53,583] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 49.0, 1.0, 2.0, 0.398273067791633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 432513.1803217047, 432513.1803217044, 105085.412191198], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6541800.0000, 
sim time next is 6542400.0000, 
raw observation next is [21.06666666666667, 50.0, 1.0, 2.0, 0.3035918469755501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 329657.2233033167, 329657.2233033164, 94008.08356957528], 
processed observation next is [1.0, 0.7391304347826086, 0.5939393939393941, 0.5, 1.0, 1.0, 0.12948980871943758, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12209526789011729, 0.12209526789011718, 0.22928800870628116], 
reward next is 0.7707, 
noisyNet noise sample is [array([0.11454405], dtype=float32), -0.05050187]. 
=============================================
[2019-03-23 13:16:54,088] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3804662e-09 1.0000000e+00 7.5573369e-21 2.8690296e-08 2.0837683e-20], sum to 1.0000
[2019-03-23 13:16:54,095] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6360
[2019-03-23 13:16:54,103] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.08333333333334, 80.66666666666666, 1.0, 2.0, 0.5606326395388319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 635552.8002981106, 635552.8002981103, 152030.6116685191], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6382200.0000, 
sim time next is 6382800.0000, 
raw observation next is [25.0, 81.0, 1.0, 2.0, 0.5588774989736637, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 633713.6348312807, 633713.6348312807, 151743.2883847794], 
processed observation next is [0.0, 0.9130434782608695, 0.7727272727272727, 0.81, 1.0, 1.0, 0.44859687371707957, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23470875364121507, 0.23470875364121507, 0.3701055814262912], 
reward next is 0.6299, 
noisyNet noise sample is [array([0.6490869], dtype=float32), -0.2490169]. 
=============================================
[2019-03-23 13:16:59,174] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.4176463e-06 9.9996948e-01 1.2921970e-15 2.6090835e-05 1.9869457e-17], sum to 1.0000
[2019-03-23 13:16:59,186] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4326
[2019-03-23 13:16:59,194] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.26666666666667, 71.33333333333334, 1.0, 2.0, 0.2316387199432825, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 251506.2399924531, 251506.2399924534, 77539.45882353025], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6468000.0000, 
sim time next is 6468600.0000, 
raw observation next is [16.18333333333333, 71.66666666666666, 1.0, 2.0, 0.2293192025869642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 248987.1343355967, 248987.1343355964, 77145.64551072245], 
processed observation next is [1.0, 0.8695652173913043, 0.37196969696969684, 0.7166666666666666, 1.0, 1.0, 0.036649003233705235, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0922174571613321, 0.092217457161332, 0.18816011100176205], 
reward next is 0.8118, 
noisyNet noise sample is [array([-0.14336847], dtype=float32), -0.933207]. 
=============================================
[2019-03-23 13:17:02,356] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.5728493e-10 1.0000000e+00 1.2119387e-25 5.6508309e-10 7.8346532e-28], sum to 1.0000
[2019-03-23 13:17:02,359] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9663
[2019-03-23 13:17:02,365] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 54.0, 1.0, 2.0, 0.4472228466565689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 485697.7959105937, 485697.7959105937, 103055.8765280016], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6523200.0000, 
sim time next is 6523800.0000, 
raw observation next is [19.58333333333334, 53.16666666666666, 1.0, 2.0, 0.4879166613007444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 529916.6211473374, 529916.6211473374, 107649.7014498554], 
processed observation next is [1.0, 0.5217391304347826, 0.5265151515151518, 0.5316666666666666, 1.0, 1.0, 0.35989582662593045, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19626541523975458, 0.19626541523975458, 0.26256024743867173], 
reward next is 0.7374, 
noisyNet noise sample is [array([1.4851868], dtype=float32), 2.4266624]. 
=============================================
[2019-03-23 13:17:07,475] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 13:17:07,476] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:17:07,477] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:17:07,478] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:17:07,478] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:17:07,479] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:17:07,480] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:17:07,481] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:17:07,482] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:17:07,484] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:17:07,483] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:17:07,499] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run42
[2019-03-23 13:17:07,525] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run42
[2019-03-23 13:17:07,550] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run42
[2019-03-23 13:17:07,584] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run42
[2019-03-23 13:17:07,585] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run42
[2019-03-23 13:17:12,906] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.37085417]
[2019-03-23 13:17:12,908] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.702574715, 39.17877482, 1.0, 2.0, 0.2772898522271731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 301070.4119024192, 301070.4119024188, 92025.57283582246]
[2019-03-23 13:17:12,909] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:17:12,912] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.6885648e-05 9.9997759e-01 1.3664924e-18 5.5158180e-06 1.9649287e-18], sampled 0.34196786211137975
[2019-03-23 13:17:26,902] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.37085417]
[2019-03-23 13:17:26,905] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 100.0, 1.0, 2.0, 0.4883470567773606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 557179.3461798659, 557179.3461798656, 140147.019480595]
[2019-03-23 13:17:26,908] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:17:26,912] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.0488174e-05 9.9997258e-01 2.8298717e-18 6.9037851e-06 3.9884151e-18], sampled 0.14856189273102616
[2019-03-23 13:17:31,687] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.37085417]
[2019-03-23 13:17:31,688] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [13.67107573333333, 58.07915358, 1.0, 2.0, 0.2025563883932645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 219912.9130258047, 219912.9130258044, 72539.12526494605]
[2019-03-23 13:17:31,690] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:17:31,692] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.9898900e-05 9.9997354e-01 2.4706154e-18 6.5673453e-06 3.5526820e-18], sampled 0.6890904312462601
[2019-03-23 13:17:39,095] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.37085417]
[2019-03-23 13:17:39,096] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.642260865, 97.25925147666668, 1.0, 2.0, 0.2545962880970469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 276424.966649302, 276424.9666493017, 90975.80026645037]
[2019-03-23 13:17:39,099] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:17:39,101] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.2263959e-05 9.9987161e-01 7.0246507e-16 3.6094956e-05 9.0363264e-16], sampled 0.02801496018143579
[2019-03-23 13:17:48,899] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.37085417]
[2019-03-23 13:17:48,900] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.0, 63.16666666666666, 1.0, 2.0, 0.51518828214271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 586799.1366851669, 586799.1366851665, 148979.6410163338]
[2019-03-23 13:17:48,902] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:17:48,905] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.5512859e-06 9.9999142e-01 4.3701134e-20 1.9931801e-06 6.3425618e-20], sampled 0.7370433310319344
[2019-03-23 13:17:54,068] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.37085417]
[2019-03-23 13:17:54,069] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.33333333333334, 59.66666666666666, 1.0, 2.0, 0.7005006031196725, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9748997285207397, 6.9112, 6.9112, 77.32846344354104, 1346054.763271638, 1346054.763271638, 289851.1946566497]
[2019-03-23 13:17:54,070] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:17:54,074] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.1304739e-06 9.9999595e-01 3.1517124e-21 9.3418981e-07 4.4429656e-21], sampled 0.5206470977968727
[2019-03-23 13:17:54,076] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1346054.763271638 W.
[2019-03-23 13:18:07,180] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.37085417]
[2019-03-23 13:18:07,181] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [29.63333333333333, 59.33333333333334, 1.0, 2.0, 0.4781002844102351, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8842920424378983, 7.025118402244601, 6.9112, 95.55294678533767, 1074726.023237109, 1029008.019321403, 256453.522994199]
[2019-03-23 13:18:07,185] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:18:07,187] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.6519958e-06 9.9998856e-01 1.2542784e-19 2.7685580e-06 1.7644424e-19], sampled 0.10844259765339581
[2019-03-23 13:18:10,129] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.37085417]
[2019-03-23 13:18:10,131] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.4, 88.5, 1.0, 2.0, 0.5276529401183976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 593645.8399941304, 593645.8399941304, 141280.5439036574]
[2019-03-23 13:18:10,134] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:18:10,137] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.7676541e-05 9.9997652e-01 1.6413443e-18 5.8622409e-06 2.3286774e-18], sampled 0.49292426619267815
[2019-03-23 13:18:10,165] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.37085417]
[2019-03-23 13:18:10,166] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.0, 90.0, 1.0, 2.0, 0.4108348769076645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 465121.0461003952, 465121.0461003949, 131412.1391928027]
[2019-03-23 13:18:10,167] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:18:10,170] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.1792852e-05 9.9998450e-01 3.6854740e-19 3.7360574e-06 5.3382085e-19], sampled 0.983715748282914
[2019-03-23 13:18:37,813] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.37085417]
[2019-03-23 13:18:37,814] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.68937060833333, 84.25320688333333, 1.0, 2.0, 0.5385533861234264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 613749.8173087527, 613749.8173087527, 151526.1263425638]
[2019-03-23 13:18:37,814] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:18:37,816] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.45634785e-05 9.99980688e-01 8.06235365e-19 4.73686123e-06
 1.15222982e-18], sampled 0.14014199542503092
[2019-03-23 13:18:47,689] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8854.4922 1663811826.1248 106.0000
[2019-03-23 13:18:47,843] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 13:18:47,968] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 13:18:47,989] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 13:18:48,030] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.8746 1705932285.1709 465.0000
[2019-03-23 13:18:49,043] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1025000, evaluation results [1025000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8854.492234389807, 1663811826.1247985, 106.0, 8597.874621072791, 1705932285.1709144, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 13:18:52,216] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1117343e-05 9.9997640e-01 2.8324621e-19 2.4954113e-06 6.6858610e-19], sum to 1.0000
[2019-03-23 13:18:52,221] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7545
[2019-03-23 13:18:52,224] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.5894649206620893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 659056.4594391147, 659056.4594391147, 141894.7753460071], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6705000.0000, 
sim time next is 6705600.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.5670043610007668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 633845.2369193021, 633845.2369193024, 139394.5399513368], 
processed observation next is [1.0, 0.6086956521739131, 0.4681818181818182, 0.93, 1.0, 1.0, 0.45875545125095846, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2347574951552971, 0.23475749515529717, 0.33998668280813854], 
reward next is 0.6600, 
noisyNet noise sample is [array([0.23160002], dtype=float32), 1.2676426]. 
=============================================
[2019-03-23 13:18:53,949] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.1714536e-07 9.9999928e-01 1.2825751e-23 1.1333057e-07 2.8321975e-23], sum to 1.0000
[2019-03-23 13:18:53,958] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1847
[2019-03-23 13:18:53,966] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 100.0, 1.0, 2.0, 0.3648719829031241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 407974.971760404, 407974.971760404, 120188.9277730229], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6732000.0000, 
sim time next is 6732600.0000, 
raw observation next is [17.61666666666667, 99.33333333333334, 1.0, 2.0, 0.3656404582900935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 408297.7944089075, 408297.7944089072, 120012.0383508175], 
processed observation next is [1.0, 0.9565217391304348, 0.4371212121212123, 0.9933333333333334, 1.0, 1.0, 0.20705057286261686, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1512214053366324, 0.15122140533663228, 0.2927122886605305], 
reward next is 0.7073, 
noisyNet noise sample is [array([0.4176657], dtype=float32), 0.21587408]. 
=============================================
[2019-03-23 13:18:55,459] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.18959109e-07 9.99998569e-01 1.70520113e-21 5.69155759e-07
 1.20553545e-20], sum to 1.0000
[2019-03-23 13:18:55,464] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3975
[2019-03-23 13:18:55,467] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.23333333333333, 81.0, 1.0, 2.0, 0.2751303013826786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 298742.5724581809, 298742.5724581812, 97076.62968942756], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6762000.0000, 
sim time next is 6762600.0000, 
raw observation next is [17.35, 79.5, 1.0, 2.0, 0.2698975116155123, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 293058.9815521745, 293058.9815521745, 95544.40846179619], 
processed observation next is [1.0, 0.2608695652173913, 0.42500000000000004, 0.795, 1.0, 1.0, 0.08737188951939034, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10854036353784241, 0.10854036353784241, 0.2330351425897468], 
reward next is 0.7670, 
noisyNet noise sample is [array([-1.2160999], dtype=float32), 1.2355926]. 
=============================================
[2019-03-23 13:18:57,705] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.6573830e-05 9.9987197e-01 6.7188812e-20 5.1547391e-05 3.6964352e-19], sum to 1.0000
[2019-03-23 13:18:57,711] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6253
[2019-03-23 13:18:57,715] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 60.33333333333333, 1.0, 2.0, 0.4174723471938344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 474183.4788067944, 474183.4788067944, 128793.3221320273], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6804600.0000, 
sim time next is 6805200.0000, 
raw observation next is [24.6, 60.66666666666667, 1.0, 2.0, 0.4186372392091687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 475151.0085157563, 475151.0085157563, 128632.5984425807], 
processed observation next is [1.0, 0.782608695652174, 0.7545454545454546, 0.6066666666666667, 1.0, 1.0, 0.27329654901146083, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17598185500583566, 0.17598185500583566, 0.31373804498190416], 
reward next is 0.6863, 
noisyNet noise sample is [array([0.9187132], dtype=float32), 1.6248646]. 
=============================================
[2019-03-23 13:18:58,032] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.9295078e-04 9.9933618e-01 3.6198373e-17 3.7091013e-04 8.3392260e-17], sum to 1.0000
[2019-03-23 13:18:58,040] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9699
[2019-03-23 13:18:58,048] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1100110.504436897 W.
[2019-03-23 13:18:58,052] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.1, 52.0, 1.0, 2.0, 0.4845150196034326, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9344773353552495, 6.960128857703435, 6.9112, 77.32834207249843, 1100110.504436897, 1084219.437164924, 243671.7802563031], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6798600.0000, 
sim time next is 6799200.0000, 
raw observation next is [26.1, 52.0, 1.0, 2.0, 0.3197154797011458, 1.0, 1.0, 0.3197154797011458, 1.0, 2.0, 0.6428795360637157, 6.911199999999999, 6.9112, 77.3421103, 1094658.02308754, 1094658.02308754, 257575.8262891779], 
processed observation next is [1.0, 0.6956521739130435, 0.8227272727272728, 0.52, 1.0, 1.0, 0.1496443496264322, 1.0, 0.5, 0.1496443496264322, 1.0, 1.0, 0.4898279086624511, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4054288974398296, 0.4054288974398296, 0.6282337226565314], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.6973834], dtype=float32), 0.36868638]. 
=============================================
[2019-03-23 13:19:07,602] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.6534055e-06 9.9999309e-01 5.8841663e-19 4.3384057e-06 1.4213512e-17], sum to 1.0000
[2019-03-23 13:19:07,607] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4224
[2019-03-23 13:19:07,615] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.43333333333333, 86.16666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 214178.7397427159, 214178.7397427162, 70865.12861324496], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7181400.0000, 
sim time next is 7182000.0000, 
raw observation next is [13.3, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 211848.8375298896, 211848.8375298896, 70371.38542300959], 
processed observation next is [1.0, 0.13043478260869565, 0.24090909090909093, 0.87, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07846253241847763, 0.07846253241847763, 0.1716375254219746], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.507691], dtype=float32), 0.8478681]. 
=============================================
[2019-03-23 13:19:07,634] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[62.844376]
 [62.771145]
 [62.855267]
 [63.004215]
 [63.04195 ]], R is [[62.20573425]
 [61.5836792 ]
 [60.9678421 ]
 [61.18265533]
 [61.39323044]].
[2019-03-23 13:19:15,939] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.8566218e-09 9.9999869e-01 9.2680093e-23 1.3488301e-06 1.6267414e-22], sum to 1.0000
[2019-03-23 13:19:15,949] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8128
[2019-03-23 13:19:15,954] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.75, 66.5, 1.0, 2.0, 0.2489491454788834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 270306.593654204, 270306.5936542038, 82835.1979288853], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7162200.0000, 
sim time next is 7162800.0000, 
raw observation next is [17.56666666666667, 67.66666666666667, 1.0, 2.0, 0.2470909466017391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 268288.42265548, 268288.4226554803, 82506.24166605684], 
processed observation next is [1.0, 0.9130434782608695, 0.434848484848485, 0.6766666666666667, 1.0, 1.0, 0.05886368325217387, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09936608246499258, 0.09936608246499269, 0.20123473577087034], 
reward next is 0.7988, 
noisyNet noise sample is [array([-0.07301061], dtype=float32), -1.2989104]. 
=============================================
[2019-03-23 13:19:29,820] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.1531868e-11 1.0000000e+00 4.9347462e-24 1.2471990e-10 2.2344101e-24], sum to 1.0000
[2019-03-23 13:19:29,830] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3817
[2019-03-23 13:19:29,835] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.61666666666667, 91.16666666666666, 1.0, 2.0, 0.3697969050487659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 413300.8027555678, 413300.8027555681, 120515.3480078931], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7427400.0000, 
sim time next is 7428000.0000, 
raw observation next is [18.43333333333333, 92.33333333333334, 1.0, 2.0, 0.3687074003136087, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 411824.6662205631, 411824.6662205628, 120309.9391517507], 
processed observation next is [1.0, 1.0, 0.4742424242424241, 0.9233333333333335, 1.0, 1.0, 0.21088425039201086, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1525276541557641, 0.152527654155764, 0.2934388759798798], 
reward next is 0.7066, 
noisyNet noise sample is [array([-0.14761129], dtype=float32), 0.70924854]. 
=============================================
[2019-03-23 13:19:29,852] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[69.46334 ]
 [69.430664]
 [69.4039  ]
 [69.40152 ]
 [69.39911 ]], R is [[69.50026703]
 [69.51132965]
 [69.52172089]
 [69.53153229]
 [69.54075623]].
[2019-03-23 13:19:37,476] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 13:19:37,476] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:19:37,478] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:19:37,478] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:19:37,479] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:19:37,480] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:19:37,483] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:19:37,483] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:19:37,485] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:19:37,485] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:19:37,486] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:19:37,503] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run43
[2019-03-23 13:19:37,527] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run43
[2019-03-23 13:19:37,551] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run43
[2019-03-23 13:19:37,585] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run43
[2019-03-23 13:19:37,609] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run43
[2019-03-23 13:20:14,013] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.38684317]
[2019-03-23 13:20:14,015] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.28333333333333, 70.33333333333334, 1.0, 2.0, 0.4047174639746303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 456875.0456259308, 456875.0456259304, 130046.4174917952]
[2019-03-23 13:20:14,018] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:20:14,021] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.3115891e-09 1.0000000e+00 6.9369008e-23 6.9764840e-11 3.2366452e-23], sampled 0.902998239652341
[2019-03-23 13:20:35,945] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.38684317]
[2019-03-23 13:20:35,947] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.11666666666667, 81.16666666666667, 1.0, 2.0, 0.5244057767378945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 597265.3286550574, 597265.3286550569, 150131.4577613819]
[2019-03-23 13:20:35,948] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:20:35,950] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.5108351e-09 1.0000000e+00 3.4289767e-22 1.4655205e-10 1.6396710e-22], sampled 0.08118829839117536
[2019-03-23 13:20:39,171] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.38684317]
[2019-03-23 13:20:39,173] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.15579226, 93.56978482, 1.0, 2.0, 0.5201367588361481, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 591027.6809664605, 591027.6809664601, 150523.4096761911]
[2019-03-23 13:20:39,174] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:20:39,177] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.0385786e-09 1.0000000e+00 2.0549613e-22 1.1552671e-10 9.7421173e-23], sampled 0.5676248102755931
[2019-03-23 13:20:46,885] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.38684317]
[2019-03-23 13:20:46,887] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.5, 58.33333333333334, 1.0, 2.0, 0.3524139677361739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 394563.3682100208, 394563.3682100205, 123732.1677410682]
[2019-03-23 13:20:46,887] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:20:46,891] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.1970707e-09 1.0000000e+00 5.5549584e-23 6.2948230e-11 2.5795928e-23], sampled 0.54554435705953
[2019-03-23 13:20:57,361] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.38684317]
[2019-03-23 13:20:57,362] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.2550339, 65.95841671, 1.0, 2.0, 0.363139573160403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 409867.5411587994, 409867.5411587991, 126313.6806089869]
[2019-03-23 13:20:57,363] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:20:57,365] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.93007632e-09 1.00000000e+00 1.80509058e-22 1.08872716e-10
 8.52085646e-23], sampled 0.2847650562030033
[2019-03-23 13:21:04,790] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.38684317]
[2019-03-23 13:21:04,792] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.98146102833334, 98.757974735, 1.0, 2.0, 0.3720662407822795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 417258.9137303944, 417258.9137303944, 125682.7408673451]
[2019-03-23 13:21:04,793] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:21:04,794] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.1593289e-09 1.0000000e+00 2.3751284e-22 1.2366061e-10 1.1275647e-22], sampled 0.9154319404617771
[2019-03-23 13:21:09,109] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02713881], dtype=float32), -0.38684317]
[2019-03-23 13:21:09,110] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.29995929333333, 92.51881053333332, 1.0, 2.0, 0.4218563587539322, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 476832.5284658172, 476832.5284658172, 131984.2620068148]
[2019-03-23 13:21:09,111] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:21:09,114] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.1505413e-09 1.0000000e+00 2.3449513e-22 1.2286032e-10 1.1141986e-22], sampled 0.026380423461013103
[2019-03-23 13:21:17,996] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 13:21:18,342] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 13:21:18,565] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 13:21:18,659] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 13:21:18,667] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 13:21:19,681] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1050000, evaluation results [1050000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 13:21:19,893] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8839788e-09 1.0000000e+00 3.2462069e-21 5.9788749e-12 2.5544086e-22], sum to 1.0000
[2019-03-23 13:21:19,898] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8127
[2019-03-23 13:21:19,902] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 95.0, 1.0, 2.0, 0.4328460480988126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 492027.051693929, 492027.051693929, 130606.3891941198], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7594800.0000, 
sim time next is 7595400.0000, 
raw observation next is [20.0, 95.5, 1.0, 2.0, 0.4347207577195493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 494317.936026263, 494317.9360262627, 130931.2372638307], 
processed observation next is [0.0, 0.9130434782608695, 0.5454545454545454, 0.955, 1.0, 1.0, 0.2934009471494366, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18308071704676407, 0.18308071704676396, 0.3193444811312944], 
reward next is 0.6807, 
noisyNet noise sample is [array([-0.15784195], dtype=float32), -1.886466]. 
=============================================
[2019-03-23 13:21:28,696] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.946529e-11 1.000000e+00 2.592971e-23 8.345718e-10 7.889700e-25], sum to 1.0000
[2019-03-23 13:21:28,704] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1949
[2019-03-23 13:21:28,710] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.41666666666667, 58.0, 1.0, 2.0, 0.6137808907398377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 669290.1350535005, 669290.1350535003, 138623.6089274104], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7728600.0000, 
sim time next is 7729200.0000, 
raw observation next is [21.6, 57.0, 1.0, 2.0, 0.6132234648732503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 668886.8401770724, 668886.8401770727, 138629.1854238834], 
processed observation next is [1.0, 0.4782608695652174, 0.6181818181818183, 0.57, 1.0, 1.0, 0.5165293310915628, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24773586673224907, 0.24773586673224915, 0.3381199644484961], 
reward next is 0.6619, 
noisyNet noise sample is [array([0.21449943], dtype=float32), -1.0372696]. 
=============================================
[2019-03-23 13:21:31,048] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:21:31,049] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:21:31,077] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run6
[2019-03-23 13:21:31,781] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4639506e-11 1.0000000e+00 7.0157154e-26 5.0011618e-12 4.6937811e-29], sum to 1.0000
[2019-03-23 13:21:31,784] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8395
[2019-03-23 13:21:31,787] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.4, 81.0, 1.0, 2.0, 0.2132352010440429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 231519.5061294874, 231519.5061294872, 73541.75401802636], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7790400.0000, 
sim time next is 7791000.0000, 
raw observation next is [14.21666666666667, 83.0, 1.0, 2.0, 0.2260521735392129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 245439.0082561235, 245439.0082561238, 74843.61648032827], 
processed observation next is [1.0, 0.17391304347826086, 0.28257575757575776, 0.83, 1.0, 1.0, 0.0325652169240161, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09090333639115684, 0.09090333639115697, 0.18254540604958117], 
reward next is 0.8175, 
noisyNet noise sample is [array([-0.12107995], dtype=float32), 0.42151994]. 
=============================================
[2019-03-23 13:21:31,800] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[78.185265]
 [78.194756]
 [78.21402 ]
 [78.20266 ]
 [78.209404]], R is [[78.17935181]
 [78.21819305]
 [78.25730896]
 [78.2955246 ]
 [78.3326416 ]].
[2019-03-23 13:21:37,070] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.1575229e-09 1.0000000e+00 7.3048227e-19 9.1841784e-10 2.2543275e-21], sum to 1.0000
[2019-03-23 13:21:37,076] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9915
[2019-03-23 13:21:37,079] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 93.0, 1.0, 2.0, 0.6761024193290729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 768244.6200757561, 768244.6200757561, 158556.602098067], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7902000.0000, 
sim time next is 7902600.0000, 
raw observation next is [20.18333333333333, 92.0, 1.0, 2.0, 0.7763697389249862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 882680.094276569, 882680.094276569, 172896.1302843562], 
processed observation next is [1.0, 0.4782608695652174, 0.5537878787878786, 0.92, 1.0, 1.0, 0.7204621736562328, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.32691855343576626, 0.32691855343576626, 0.42169787874233217], 
reward next is 0.5783, 
noisyNet noise sample is [array([-1.0082531], dtype=float32), 0.89121616]. 
=============================================
[2019-03-23 13:21:38,117] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.5672108e-11 1.0000000e+00 4.4116124e-25 9.5657336e-13 1.8636728e-26], sum to 1.0000
[2019-03-23 13:21:38,122] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7874
[2019-03-23 13:21:38,126] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 87.0, 1.0, 2.0, 0.4487570003983725, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9068052179985395, 6.911200000000001, 6.9112, 77.32846344354104, 1024325.375339837, 1024325.375339836, 241994.0855597966], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7917000.0000, 
sim time next is 7917600.0000, 
raw observation next is [22.0, 87.0, 1.0, 2.0, 0.8887423863616745, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1014599.792410848, 1014599.792410848, 196269.3995115466], 
processed observation next is [1.0, 0.6521739130434783, 0.6363636363636364, 0.87, 1.0, 1.0, 0.8609279829520929, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.37577770089290663, 0.37577770089290663, 0.47870585246718683], 
reward next is 0.5213, 
noisyNet noise sample is [array([0.07371543], dtype=float32), -0.10627964]. 
=============================================
[2019-03-23 13:21:38,556] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:21:38,556] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:21:38,565] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run6
[2019-03-23 13:21:38,627] A3C_AGENT_WORKER-Thread-11 INFO:Local step 66500, global step 1060100: loss 0.0184
[2019-03-23 13:21:38,628] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 66500, global step 1060100: learning rate 0.0001
[2019-03-23 13:21:38,693] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:21:38,693] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:21:38,697] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run6
[2019-03-23 13:21:38,873] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:21:38,873] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:21:38,876] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run6
[2019-03-23 13:21:38,976] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:21:38,976] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:21:38,981] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run6
[2019-03-23 13:21:39,049] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:21:39,049] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:21:39,053] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run6
[2019-03-23 13:21:39,094] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:21:39,094] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:21:39,100] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run6
[2019-03-23 13:21:39,235] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:21:39,236] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:21:39,239] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run6
[2019-03-23 13:21:39,265] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:21:39,266] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:21:39,270] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run6
[2019-03-23 13:21:39,295] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:21:39,295] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:21:39,299] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run6
[2019-03-23 13:21:39,337] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:21:39,337] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:21:39,340] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run6
[2019-03-23 13:21:39,405] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:21:39,405] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:21:39,408] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run6
[2019-03-23 13:21:39,449] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:21:39,449] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:21:39,452] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run6
[2019-03-23 13:21:39,545] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:21:39,545] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:21:39,549] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run6
[2019-03-23 13:21:39,653] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:21:39,655] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:21:39,665] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:21:39,668] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run6
[2019-03-23 13:21:39,665] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:21:39,815] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run6
[2019-03-23 13:21:44,564] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.1357265e-12 1.0000000e+00 4.3520375e-26 3.2540359e-10 9.8789078e-29], sum to 1.0000
[2019-03-23 13:21:44,578] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7765
[2019-03-23 13:21:44,581] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 75.5, 1.0, 2.0, 0.374784505940061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 418401.3842179609, 418401.3842179609, 120721.8743888374], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 70200.0000, 
sim time next is 70800.0000, 
raw observation next is [20.33333333333333, 76.33333333333334, 1.0, 2.0, 0.3724580563822783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 415522.8144128206, 415522.8144128209, 120406.2365531606], 
processed observation next is [1.0, 0.8260869565217391, 0.5606060606060604, 0.7633333333333334, 1.0, 1.0, 0.21557257047784786, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15389733867141506, 0.15389733867141514, 0.29367374769063564], 
reward next is 0.7063, 
noisyNet noise sample is [array([-0.76845616], dtype=float32), -0.6394524]. 
=============================================
[2019-03-23 13:21:47,256] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1352860e-11 1.0000000e+00 4.2290309e-26 1.7645362e-12 4.8778774e-28], sum to 1.0000
[2019-03-23 13:21:47,264] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9007
[2019-03-23 13:21:47,268] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 46.0, 1.0, 2.0, 0.5650249047042086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 613715.2275185897, 613715.2275185897, 117693.7134728364], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 129600.0000, 
sim time next is 130200.0000, 
raw observation next is [21.16666666666667, 46.0, 1.0, 2.0, 0.5361207434845346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 582301.479107803, 582301.479107803, 115138.4907082736], 
processed observation next is [1.0, 0.5217391304347826, 0.5984848484848487, 0.46, 1.0, 1.0, 0.4201509293556683, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21566721448437146, 0.21566721448437146, 0.28082558709335026], 
reward next is 0.7192, 
noisyNet noise sample is [array([0.27861965], dtype=float32), 0.99823385]. 
=============================================
[2019-03-23 13:21:48,287] A3C_AGENT_WORKER-Thread-2 INFO:Local step 66500, global step 1064144: loss 0.0166
[2019-03-23 13:21:48,290] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 66500, global step 1064145: learning rate 0.0001
[2019-03-23 13:21:48,409] A3C_AGENT_WORKER-Thread-21 INFO:Local step 66500, global step 1064207: loss 0.0117
[2019-03-23 13:21:48,411] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 66500, global step 1064207: learning rate 0.0001
[2019-03-23 13:21:48,483] A3C_AGENT_WORKER-Thread-18 INFO:Local step 66500, global step 1064243: loss 0.0062
[2019-03-23 13:21:48,485] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 66500, global step 1064244: learning rate 0.0001
[2019-03-23 13:21:48,597] A3C_AGENT_WORKER-Thread-20 INFO:Local step 66500, global step 1064299: loss 0.0162
[2019-03-23 13:21:48,600] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 66500, global step 1064299: learning rate 0.0001
[2019-03-23 13:21:48,638] A3C_AGENT_WORKER-Thread-9 INFO:Local step 66500, global step 1064319: loss 0.0044
[2019-03-23 13:21:48,642] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 66500, global step 1064320: learning rate 0.0001
[2019-03-23 13:21:48,712] A3C_AGENT_WORKER-Thread-19 INFO:Local step 66500, global step 1064360: loss 0.0415
[2019-03-23 13:21:48,715] A3C_AGENT_WORKER-Thread-3 INFO:Local step 66500, global step 1064362: loss 0.0382
[2019-03-23 13:21:48,715] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 66500, global step 1064362: learning rate 0.0001
[2019-03-23 13:21:48,720] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 66500, global step 1064363: learning rate 0.0001
[2019-03-23 13:21:48,849] A3C_AGENT_WORKER-Thread-17 INFO:Local step 66500, global step 1064429: loss 0.0193
[2019-03-23 13:21:48,852] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 66500, global step 1064429: learning rate 0.0001
[2019-03-23 13:21:48,874] A3C_AGENT_WORKER-Thread-14 INFO:Local step 66500, global step 1064438: loss 0.1069
[2019-03-23 13:21:48,877] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 66500, global step 1064439: learning rate 0.0001
[2019-03-23 13:21:48,882] A3C_AGENT_WORKER-Thread-22 INFO:Local step 66500, global step 1064439: loss 0.1121
[2019-03-23 13:21:48,884] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 66500, global step 1064440: learning rate 0.0001
[2019-03-23 13:21:48,919] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3656120e-13 1.0000000e+00 1.0100919e-28 4.0230615e-13 1.0869483e-30], sum to 1.0000
[2019-03-23 13:21:48,930] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9663
[2019-03-23 13:21:48,935] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 48.0, 1.0, 2.0, 0.2770366139344274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 300813.1289951509, 300813.1289951506, 82226.88703314391], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 156000.0000, 
sim time next is 156600.0000, 
raw observation next is [19.5, 49.0, 1.0, 2.0, 0.2749379381088899, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 298533.636048353, 298533.6360483533, 82026.69888006175], 
processed observation next is [1.0, 0.8260869565217391, 0.5227272727272727, 0.49, 1.0, 1.0, 0.09367242263611235, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11056801335124185, 0.11056801335124196, 0.20006511921966283], 
reward next is 0.7999, 
noisyNet noise sample is [array([-0.58396614], dtype=float32), 0.57205456]. 
=============================================
[2019-03-23 13:21:49,074] A3C_AGENT_WORKER-Thread-15 INFO:Local step 66500, global step 1064538: loss 0.1004
[2019-03-23 13:21:49,077] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 66500, global step 1064540: learning rate 0.0001
[2019-03-23 13:21:49,111] A3C_AGENT_WORKER-Thread-13 INFO:Local step 66500, global step 1064558: loss 0.2596
[2019-03-23 13:21:49,114] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 66500, global step 1064560: learning rate 0.0001
[2019-03-23 13:21:49,180] A3C_AGENT_WORKER-Thread-10 INFO:Local step 66500, global step 1064594: loss 0.3741
[2019-03-23 13:21:49,184] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 66500, global step 1064595: learning rate 0.0001
[2019-03-23 13:21:49,597] A3C_AGENT_WORKER-Thread-12 INFO:Local step 66500, global step 1064803: loss 0.0656
[2019-03-23 13:21:49,600] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 66500, global step 1064805: learning rate 0.0001
[2019-03-23 13:21:49,624] A3C_AGENT_WORKER-Thread-16 INFO:Local step 66500, global step 1064818: loss 0.0713
[2019-03-23 13:21:49,626] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 66500, global step 1064819: learning rate 0.0001
[2019-03-23 13:21:50,449] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67000, global step 1065230: loss 3.3378
[2019-03-23 13:21:50,452] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67000, global step 1065232: learning rate 0.0001
[2019-03-23 13:21:57,808] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9981564e-01 1.8439595e-04 1.6319545e-24 4.4544410e-10 2.1271740e-29], sum to 1.0000
[2019-03-23 13:21:57,814] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2474
[2019-03-23 13:21:57,819] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.33333333333333, 50.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4256389124733065, 6.911199999999998, 6.9112, 77.32846344354104, 247561.9063356155, 247561.906335616, 70857.90364200891], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 330600.0000, 
sim time next is 331200.0000, 
raw observation next is [18.0, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4186256958067515, 6.911199999999999, 6.9112, 77.32846344354104, 243481.8285807132, 243481.8285807135, 69916.38957599632], 
processed observation next is [0.0, 0.8695652173913043, 0.45454545454545453, 0.52, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.16946527972393077, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09017845502989377, 0.0901784550298939, 0.17052777945364955], 
reward next is 0.8295, 
noisyNet noise sample is [array([0.96067405], dtype=float32), 0.90806913]. 
=============================================
[2019-03-23 13:22:04,094] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67000, global step 1072135: loss -54.6245
[2019-03-23 13:22:04,096] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67000, global step 1072136: learning rate 0.0001
[2019-03-23 13:22:04,357] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67000, global step 1072266: loss -51.3400
[2019-03-23 13:22:04,359] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67000, global step 1072267: learning rate 0.0001
[2019-03-23 13:22:04,372] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67000, global step 1072275: loss -47.5358
[2019-03-23 13:22:04,375] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67000, global step 1072276: learning rate 0.0001
[2019-03-23 13:22:04,413] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67000, global step 1072292: loss -99.3762
[2019-03-23 13:22:04,415] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67000, global step 1072293: learning rate 0.0001
[2019-03-23 13:22:04,453] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67000, global step 1072312: loss -84.3649
[2019-03-23 13:22:04,456] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67000, global step 1072313: learning rate 0.0001
[2019-03-23 13:22:04,472] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67000, global step 1072320: loss -86.0160
[2019-03-23 13:22:04,475] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67000, global step 1072323: learning rate 0.0001
[2019-03-23 13:22:04,551] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67000, global step 1072361: loss -139.4283
[2019-03-23 13:22:04,554] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67000, global step 1072362: learning rate 0.0001
[2019-03-23 13:22:04,647] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67000, global step 1072411: loss -80.5904
[2019-03-23 13:22:04,650] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67000, global step 1072411: learning rate 0.0001
[2019-03-23 13:22:04,652] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67000, global step 1072411: loss -95.8264
[2019-03-23 13:22:04,656] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67000, global step 1072411: learning rate 0.0001
[2019-03-23 13:22:04,775] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67000, global step 1072475: loss -111.4239
[2019-03-23 13:22:04,779] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67000, global step 1072476: learning rate 0.0001
[2019-03-23 13:22:04,933] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67000, global step 1072555: loss -115.6773
[2019-03-23 13:22:04,937] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67000, global step 1072555: learning rate 0.0001
[2019-03-23 13:22:05,051] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67000, global step 1072611: loss -74.3785
[2019-03-23 13:22:05,055] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67000, global step 1072612: learning rate 0.0001
[2019-03-23 13:22:05,244] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67000, global step 1072709: loss -67.5808
[2019-03-23 13:22:05,250] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67000, global step 1072712: learning rate 0.0001
[2019-03-23 13:22:05,333] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67000, global step 1072753: loss -60.0373
[2019-03-23 13:22:05,335] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67000, global step 1072754: learning rate 0.0001
[2019-03-23 13:22:05,505] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67000, global step 1072843: loss -53.8935
[2019-03-23 13:22:05,510] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67000, global step 1072845: learning rate 0.0001
[2019-03-23 13:22:06,655] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67500, global step 1073421: loss 49.6607
[2019-03-23 13:22:06,661] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67500, global step 1073421: learning rate 0.0001
[2019-03-23 13:22:08,009] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 6.2741319e-19 8.5777724e-29 4.5381622e-18 1.4590603e-37], sum to 1.0000
[2019-03-23 13:22:08,018] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2251
[2019-03-23 13:22:08,030] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.83333333333333, 89.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.437872941090045, 6.911199999999998, 6.9112, 77.32846344354104, 254679.376816901, 254679.3768169016, 78956.33190926882], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 508200.0000, 
sim time next is 508800.0000, 
raw observation next is [14.66666666666667, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4312902725980834, 6.911200000000001, 6.9112, 77.32846344354104, 250849.7219662056, 250849.7219662053, 78033.46194317582], 
processed observation next is [1.0, 0.9130434782608695, 0.30303030303030315, 0.9, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1875575322829763, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.092907304431928, 0.09290730443192789, 0.19032551693457517], 
reward next is 0.8097, 
noisyNet noise sample is [array([0.14851817], dtype=float32), 0.3787968]. 
=============================================
[2019-03-23 13:22:09,771] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 13:22:09,773] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:22:09,775] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:22:09,776] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:22:09,777] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:22:09,778] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:22:09,778] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:22:09,778] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:22:09,779] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:22:09,779] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:22:09,780] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:22:09,797] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run44
[2019-03-23 13:22:09,797] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run44
[2019-03-23 13:22:09,858] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run44
[2019-03-23 13:22:09,882] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run44
[2019-03-23 13:22:09,883] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run44
[2019-03-23 13:22:24,136] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02714703], dtype=float32), -0.40372413]
[2019-03-23 13:22:24,137] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [29.56666666666667, 42.33333333333334, 1.0, 2.0, 0.6270411614753771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 714925.3515412066, 714925.3515412062, 159147.2611446799]
[2019-03-23 13:22:24,139] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:22:24,143] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0000000e+00 9.8916875e-11 8.4838300e-20 1.6391979e-12 9.3934786e-25], sampled 0.8703425277067887
[2019-03-23 13:22:24,147] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 714925.3515412066 W.
[2019-03-23 13:23:21,358] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02714703], dtype=float32), -0.40372413]
[2019-03-23 13:23:21,359] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.53333333333333, 89.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6030268359512777, 6.9112, 6.9112, 95.55338769695034, 350031.6614100361, 350031.6614100361, 118582.7833940679]
[2019-03-23 13:23:21,360] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:23:21,364] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 2.0857939e-11 2.8567682e-21 2.2518786e-13 1.3432700e-26], sampled 0.1787919159313195
[2019-03-23 13:23:50,263] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6553.1725 1698634175.0084 2957.0000
[2019-03-23 13:23:50,363] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6294.9961 1685630448.6673 3228.0000
[2019-03-23 13:23:50,454] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6481.6076 1678885180.2952 3057.0000
[2019-03-23 13:23:50,472] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6328.7217 1723294598.4314 3425.0000
[2019-03-23 13:23:50,497] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6862.2842 1793014293.7888 2409.0000
[2019-03-23 13:23:51,512] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1075000, evaluation results [1075000.0, 6862.284208925443, 1793014293.78876, 2409.0, 6481.607577760913, 1678885180.2951708, 3057.0, 6294.9960618483565, 1685630448.6673346, 3228.0, 6328.721692698646, 1723294598.4313502, 3425.0, 6553.172466661831, 1698634175.0084193, 2957.0]
[2019-03-23 13:23:52,344] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9993610e-01 6.3799380e-05 3.2545803e-13 1.2957203e-07 6.6317551e-15], sum to 1.0000
[2019-03-23 13:23:52,349] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3065
[2019-03-23 13:23:52,354] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 604321.0857531163 W.
[2019-03-23 13:23:52,358] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [17.16666666666667, 87.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7648113619186463, 7.402168442086912, 6.9112, 77.32715543922038, 604321.0857531163, 444867.2749976891, 126758.2360347682], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 555000.0000, 
sim time next is 555600.0000, 
raw observation next is [17.33333333333334, 86.33333333333334, 1.0, 1.0, 0.2549872237225517, 1.0, 1.0, 0.2549872237225517, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32816760295322, 562350.6633154203, 562350.6633154203, 163197.5484514687], 
processed observation next is [1.0, 0.43478260869565216, 0.42424242424242453, 0.8633333333333334, 1.0, 0.5, 0.06873402965318964, 1.0, 0.5, 0.06873402965318964, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084268677911096, 0.20827802345015567, 0.20827802345015567, 0.39804280110114315], 
reward next is 0.6020, 
noisyNet noise sample is [array([0.03218294], dtype=float32), 0.78713554]. 
=============================================
[2019-03-23 13:23:52,361] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.6888915e-08 2.7508382e-15 1.0278810e-09 1.4073917e-18], sum to 1.0000
[2019-03-23 13:23:52,376] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4364
[2019-03-23 13:23:52,384] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 650582.4976362342 W.
[2019-03-23 13:23:52,393] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.33333333333334, 64.0, 1.0, 2.0, 0.2931178481201345, 0.0, 2.0, 0.0, 1.0, 2.0, 0.563165650009871, 6.9112, 6.9112, 77.32846344354104, 650582.4976362342, 650582.4976362342, 173585.1363009607], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 573600.0000, 
sim time next is 574200.0000, 
raw observation next is [21.5, 64.0, 1.0, 2.0, 0.2032988858062041, 1.0, 1.0, 0.2032988858062041, 1.0, 2.0, 0.3951739192976932, 6.9112, 6.9112, 77.3421103, 682618.3520219993, 682618.3520219993, 210694.7924141399], 
processed observation next is [1.0, 0.6521739130434783, 0.6136363636363636, 0.64, 1.0, 1.0, 0.004123607257755096, 1.0, 0.5, 0.004123607257755096, 1.0, 1.0, 0.13596274185384744, 0.0, 0.0, 0.5085185399722538, 0.25282161185999974, 0.25282161185999974, 0.5138897375954632], 
reward next is 0.4861, 
noisyNet noise sample is [array([1.1211851], dtype=float32), -0.9126331]. 
=============================================
[2019-03-23 13:23:54,857] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.9503562e-20 1.3539701e-27 1.6097330e-19 3.0204827e-35], sum to 1.0000
[2019-03-23 13:23:54,868] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9331
[2019-03-23 13:23:54,876] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.0, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5714078160919, 6.911199999999999, 6.9112, 77.32846344354104, 332183.1740020692, 332183.1740020695, 111375.5153217523], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 601800.0000, 
sim time next is 602400.0000, 
raw observation next is [18.0, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5702685619403473, 6.9112, 6.9112, 77.32846344354104, 331520.6916012444, 331520.6916012444, 111288.1345059546], 
processed observation next is [1.0, 1.0, 0.45454545454545453, 0.83, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3860979456290675, 0.0, 0.0, 0.5084288129206541, 0.12278544133379421, 0.12278544133379421, 0.2714344744047673], 
reward next is 0.7286, 
noisyNet noise sample is [array([-0.01936181], dtype=float32), -1.3869351]. 
=============================================
[2019-03-23 13:23:56,204] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9999869e-01 1.3378868e-06 3.8020755e-15 2.1277189e-09 7.0575554e-18], sum to 1.0000
[2019-03-23 13:23:56,210] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8823
[2019-03-23 13:23:56,216] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 596570.6149563491 W.
[2019-03-23 13:23:56,221] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 78.83333333333333, 1.0, 2.0, 0.2674072322626571, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5174065337451046, 6.9112, 6.9112, 77.32846111710255, 596570.6149563491, 596570.6149563491, 169559.0260302316], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 636600.0000, 
sim time next is 637200.0000, 
raw observation next is [20.0, 78.0, 1.0, 2.0, 0.5458973962945195, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.3284634291402, 609044.1348653779, 609044.1348653779, 136648.4819158653], 
processed observation next is [1.0, 0.391304347826087, 0.5454545454545454, 0.78, 1.0, 1.0, 0.4323717453681493, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288128259696, 0.22557190180199183, 0.22557190180199183, 0.3332889802825983], 
reward next is 0.6667, 
noisyNet noise sample is [array([1.5376561], dtype=float32), 0.9850959]. 
=============================================
[2019-03-23 13:23:59,027] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 7.9057420e-14 1.4755747e-19 5.2458580e-14 2.7422329e-25], sum to 1.0000
[2019-03-23 13:23:59,037] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8678
[2019-03-23 13:23:59,043] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.0, 96.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.749261653126916, 7.160317551116139, 6.9112, 77.32781939496343, 508968.6148516964, 428061.0034482339, 133238.4544484188], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 952800.0000, 
sim time next is 953400.0000, 
raw observation next is [19.0, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7566197357647412, 7.240753259547756, 6.9112, 77.32746946203488, 540681.428936843, 433650.6465589118, 133103.2762365345], 
processed observation next is [1.0, 0.0, 0.5, 0.95, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6523139082353446, 0.03295532595477564, 0.0, 0.5084222775672443, 0.20025238108771962, 0.16061135057737472, 0.32464213716227924], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.28368518], dtype=float32), -0.35624957]. 
=============================================
[2019-03-23 13:24:01,133] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67500, global step 1080079: loss 101.8456
[2019-03-23 13:24:01,134] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67500, global step 1080079: learning rate 0.0001
[2019-03-23 13:24:01,292] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67500, global step 1080164: loss 60.7754
[2019-03-23 13:24:01,293] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67500, global step 1080164: learning rate 0.0001
[2019-03-23 13:24:01,414] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67500, global step 1080227: loss 114.0960
[2019-03-23 13:24:01,416] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67500, global step 1080228: learning rate 0.0001
[2019-03-23 13:24:01,486] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67500, global step 1080264: loss 148.0856
[2019-03-23 13:24:01,487] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67500, global step 1080265: learning rate 0.0001
[2019-03-23 13:24:01,495] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67500, global step 1080270: loss 130.3887
[2019-03-23 13:24:01,498] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67500, global step 1080271: learning rate 0.0001
[2019-03-23 13:24:01,564] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67500, global step 1080307: loss 62.4076
[2019-03-23 13:24:01,565] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67500, global step 1080307: learning rate 0.0001
[2019-03-23 13:24:01,626] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67500, global step 1080343: loss 169.4509
[2019-03-23 13:24:01,635] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67500, global step 1080346: learning rate 0.0001
[2019-03-23 13:24:01,786] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67500, global step 1080423: loss 126.8837
[2019-03-23 13:24:01,788] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67500, global step 1080423: learning rate 0.0001
[2019-03-23 13:24:01,802] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67500, global step 1080431: loss 110.8474
[2019-03-23 13:24:01,806] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67500, global step 1080432: learning rate 0.0001
[2019-03-23 13:24:01,838] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67500, global step 1080443: loss 164.3174
[2019-03-23 13:24:01,840] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67500, global step 1080444: learning rate 0.0001
[2019-03-23 13:24:01,971] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67500, global step 1080518: loss 45.3183
[2019-03-23 13:24:01,972] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67500, global step 1080518: learning rate 0.0001
[2019-03-23 13:24:02,101] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67500, global step 1080592: loss 77.6891
[2019-03-23 13:24:02,106] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67500, global step 1080592: learning rate 0.0001
[2019-03-23 13:24:02,236] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67500, global step 1080666: loss 66.2842
[2019-03-23 13:24:02,243] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67500, global step 1080667: learning rate 0.0001
[2019-03-23 13:24:02,258] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67500, global step 1080674: loss 54.8393
[2019-03-23 13:24:02,263] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67500, global step 1080675: learning rate 0.0001
[2019-03-23 13:24:02,490] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67500, global step 1080786: loss 19.0215
[2019-03-23 13:24:02,490] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67500, global step 1080786: learning rate 0.0001
[2019-03-23 13:24:04,016] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68000, global step 1081590: loss 7.1880
[2019-03-23 13:24:04,017] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68000, global step 1081590: learning rate 0.0001
[2019-03-23 13:24:04,597] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 8.5570648e-11 5.0906224e-10 1.4495168e-09 3.7307649e-13], sum to 1.0000
[2019-03-23 13:24:04,603] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3340
[2019-03-23 13:24:04,610] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 652881.3656992795 W.
[2019-03-23 13:24:04,615] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 59.33333333333334, 1.0, 2.0, 0.5773069449583605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 652881.3656992795, 652881.3656992795, 154764.7460273479], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 823800.0000, 
sim time next is 824400.0000, 
raw observation next is [29.0, 58.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 1.0, 0.3831483998088739, 6.9112, 6.9112, 77.3421103, 640689.1980006988, 640689.1980006988, 226651.4497810629], 
processed observation next is [0.0, 0.5652173913043478, 0.9545454545454546, 0.58, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.5, 0.1187834282983913, 0.0, 0.0, 0.5085185399722538, 0.23729229555581438, 0.23729229555581438, 0.5528084141001534], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7208986], dtype=float32), -2.5028348]. 
=============================================
[2019-03-23 13:24:05,849] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7142263e-01 5.2398866e-01 1.3897689e-03 3.0319154e-01 7.3856786e-06], sum to 1.0000
[2019-03-23 13:24:05,858] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7892
[2019-03-23 13:24:05,863] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.33333333333334, 64.0, 1.0, 2.0, 0.5013658715487073, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 571701.5251141771, 571701.5251141771, 142361.5027981452], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 848400.0000, 
sim time next is 849000.0000, 
raw observation next is [26.16666666666667, 64.5, 1.0, 2.0, 0.2493467432095513, 1.0, 1.0, 0.2493467432095513, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 568167.527474704, 568167.527474704, 179488.1301876266], 
processed observation next is [0.0, 0.8260869565217391, 0.825757575757576, 0.645, 1.0, 1.0, 0.061683429011939114, 1.0, 0.5, 0.061683429011939114, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2104324175832237, 0.2104324175832237, 0.4377759272868942], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8221051], dtype=float32), 1.1693133]. 
=============================================
[2019-03-23 13:24:05,875] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[19.409817]
 [19.594679]
 [19.520319]
 [19.60563 ]
 [19.533953]], R is [[19.26130104]
 [19.06868744]
 [18.87800026]
 [19.33967018]
 [19.14627457]].
[2019-03-23 13:24:07,644] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.9647738e-06 9.9998605e-01 1.8707891e-13 1.0940291e-05 1.7582439e-18], sum to 1.0000
[2019-03-23 13:24:07,649] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8226
[2019-03-23 13:24:07,655] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 91.0, 1.0, 2.0, 0.4001911386064904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 451698.6344087053, 451698.6344087053, 125266.6551988192], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 873000.0000, 
sim time next is 873600.0000, 
raw observation next is [19.33333333333334, 92.0, 1.0, 2.0, 0.3982856696525125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 449340.4083661537, 449340.4083661534, 124977.9712152732], 
processed observation next is [0.0, 0.08695652173913043, 0.5151515151515155, 0.92, 1.0, 1.0, 0.2478570870656406, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1664223734689458, 0.1664223734689457, 0.3048243200372517], 
reward next is 0.6952, 
noisyNet noise sample is [array([-1.4362625], dtype=float32), 1.7156291]. 
=============================================
[2019-03-23 13:24:16,483] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68000, global step 1088108: loss 0.9297
[2019-03-23 13:24:16,486] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68000, global step 1088110: learning rate 0.0001
[2019-03-23 13:24:16,490] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68000, global step 1088111: loss 0.7654
[2019-03-23 13:24:16,496] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68000, global step 1088112: learning rate 0.0001
[2019-03-23 13:24:16,673] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68000, global step 1088204: loss 1.3846
[2019-03-23 13:24:16,675] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68000, global step 1088204: learning rate 0.0001
[2019-03-23 13:24:16,694] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68000, global step 1088209: loss 1.2807
[2019-03-23 13:24:16,695] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68000, global step 1088209: learning rate 0.0001
[2019-03-23 13:24:16,749] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68000, global step 1088239: loss 1.3247
[2019-03-23 13:24:16,753] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68000, global step 1088242: learning rate 0.0001
[2019-03-23 13:24:16,994] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68000, global step 1088364: loss 0.7614
[2019-03-23 13:24:16,995] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68000, global step 1088364: learning rate 0.0001
[2019-03-23 13:24:17,006] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68000, global step 1088366: loss 0.7524
[2019-03-23 13:24:17,008] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68000, global step 1088366: learning rate 0.0001
[2019-03-23 13:24:17,084] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68000, global step 1088400: loss 0.6843
[2019-03-23 13:24:17,086] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68000, global step 1088400: learning rate 0.0001
[2019-03-23 13:24:17,132] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68000, global step 1088430: loss 0.6783
[2019-03-23 13:24:17,134] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68000, global step 1088431: learning rate 0.0001
[2019-03-23 13:24:17,178] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68000, global step 1088449: loss 0.6229
[2019-03-23 13:24:17,180] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68000, global step 1088449: learning rate 0.0001
[2019-03-23 13:24:17,196] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68000, global step 1088455: loss 0.6330
[2019-03-23 13:24:17,199] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68000, global step 1088456: learning rate 0.0001
[2019-03-23 13:24:17,409] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68000, global step 1088561: loss 0.7163
[2019-03-23 13:24:17,412] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68000, global step 1088561: learning rate 0.0001
[2019-03-23 13:24:17,471] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68000, global step 1088597: loss 0.6958
[2019-03-23 13:24:17,476] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68000, global step 1088597: learning rate 0.0001
[2019-03-23 13:24:17,715] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68000, global step 1088716: loss 1.0801
[2019-03-23 13:24:17,715] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68000, global step 1088716: learning rate 0.0001
[2019-03-23 13:24:17,847] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68000, global step 1088788: loss 0.9452
[2019-03-23 13:24:17,855] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68000, global step 1088789: learning rate 0.0001
[2019-03-23 13:24:20,110] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68500, global step 1089918: loss -174.7014
[2019-03-23 13:24:20,112] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68500, global step 1089919: learning rate 0.0001
[2019-03-23 13:24:21,007] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.7696114e-08 1.0000000e+00 1.3428305e-17 7.6353290e-10 2.8074159e-23], sum to 1.0000
[2019-03-23 13:24:21,008] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4824
[2019-03-23 13:24:21,018] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.322030116543866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 354408.92718199, 354408.92718199, 114387.0272751574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1132200.0000, 
sim time next is 1132800.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3205560426927667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 352763.7268760317, 352763.7268760314, 114271.4958762545], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 0.88, 1.0, 1.0, 0.15069505336595837, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13065323217630806, 0.13065323217630792, 0.2787109655518402], 
reward next is 0.7213, 
noisyNet noise sample is [array([-0.8627419], dtype=float32), -0.95024014]. 
=============================================
[2019-03-23 13:24:29,615] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.4050114e-07 9.9999905e-01 3.8398259e-16 1.1902530e-09 1.4242069e-20], sum to 1.0000
[2019-03-23 13:24:29,625] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4153
[2019-03-23 13:24:29,631] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 95.0, 1.0, 2.0, 0.3661001686027214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 407944.7643818352, 407944.7643818352, 119674.5478427627], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1285800.0000, 
sim time next is 1286400.0000, 
raw observation next is [18.0, 96.0, 1.0, 2.0, 0.3674363540030123, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 410048.5883753601, 410048.5883753604, 120048.6498996827], 
processed observation next is [1.0, 0.9130434782608695, 0.45454545454545453, 0.96, 1.0, 1.0, 0.20929544250376533, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15186984754642968, 0.1518698475464298, 0.2928015851211773], 
reward next is 0.7072, 
noisyNet noise sample is [array([-0.30351534], dtype=float32), 0.6198607]. 
=============================================
[2019-03-23 13:24:32,429] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68500, global step 1096129: loss -262.7881
[2019-03-23 13:24:32,430] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68500, global step 1096129: learning rate 0.0001
[2019-03-23 13:24:32,575] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68500, global step 1096203: loss -146.7856
[2019-03-23 13:24:32,577] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68500, global step 1096203: learning rate 0.0001
[2019-03-23 13:24:32,651] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68500, global step 1096243: loss -120.4881
[2019-03-23 13:24:32,656] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68500, global step 1096246: learning rate 0.0001
[2019-03-23 13:24:32,661] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68500, global step 1096246: loss -233.8479
[2019-03-23 13:24:32,663] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68500, global step 1096247: learning rate 0.0001
[2019-03-23 13:24:32,756] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68500, global step 1096292: loss -52.0776
[2019-03-23 13:24:32,758] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68500, global step 1096292: learning rate 0.0001
[2019-03-23 13:24:32,926] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68500, global step 1096376: loss -0.3938
[2019-03-23 13:24:32,927] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68500, global step 1096376: learning rate 0.0001
[2019-03-23 13:24:33,018] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68500, global step 1096423: loss 17.2579
[2019-03-23 13:24:33,021] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68500, global step 1096425: learning rate 0.0001
[2019-03-23 13:24:33,056] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68500, global step 1096443: loss -60.2342
[2019-03-23 13:24:33,061] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68500, global step 1096443: loss -22.5341
[2019-03-23 13:24:33,061] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68500, global step 1096443: learning rate 0.0001
[2019-03-23 13:24:33,063] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68500, global step 1096444: learning rate 0.0001
[2019-03-23 13:24:33,069] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68500, global step 1096445: loss -6.5996
[2019-03-23 13:24:33,071] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68500, global step 1096445: learning rate 0.0001
[2019-03-23 13:24:33,088] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68500, global step 1096455: loss 11.1067
[2019-03-23 13:24:33,089] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68500, global step 1096455: learning rate 0.0001
[2019-03-23 13:24:33,264] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68500, global step 1096542: loss -40.5020
[2019-03-23 13:24:33,265] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68500, global step 1096543: learning rate 0.0001
[2019-03-23 13:24:33,370] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68500, global step 1096595: loss 71.3624
[2019-03-23 13:24:33,372] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68500, global step 1096595: learning rate 0.0001
[2019-03-23 13:24:33,639] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68500, global step 1096730: loss -61.6398
[2019-03-23 13:24:33,643] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68500, global step 1096731: learning rate 0.0001
[2019-03-23 13:24:33,743] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68500, global step 1096777: loss -9.9860
[2019-03-23 13:24:33,747] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68500, global step 1096778: learning rate 0.0001
[2019-03-23 13:24:35,483] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69000, global step 1097667: loss 0.0661
[2019-03-23 13:24:35,485] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69000, global step 1097667: learning rate 0.0001
[2019-03-23 13:24:38,381] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.2812556e-07 9.9999952e-01 4.1686340e-16 1.6579771e-10 4.2557606e-20], sum to 1.0000
[2019-03-23 13:24:38,391] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4084
[2019-03-23 13:24:38,397] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4860244246430601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 554527.6198770255, 554527.6198770255, 139882.9128070861], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1443600.0000, 
sim time next is 1444200.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.486770813360034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 555379.8039080298, 555379.8039080298, 139967.5530452713], 
processed observation next is [0.0, 0.7391304347826086, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3584635167000425, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20569622366964066, 0.20569622366964066, 0.34138427572017394], 
reward next is 0.6586, 
noisyNet noise sample is [array([0.34165716], dtype=float32), -0.3351552]. 
=============================================
[2019-03-23 13:24:39,052] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.99101043e-06 9.99997020e-01 1.18002125e-14 6.23318508e-09
 3.03353642e-18], sum to 1.0000
[2019-03-23 13:24:39,059] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2681
[2019-03-23 13:24:39,065] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 97.0, 1.0, 2.0, 0.4528485277200386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 516358.0627373224, 516358.0627373226, 134414.512776952], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1456200.0000, 
sim time next is 1456800.0000, 
raw observation next is [20.33333333333333, 98.0, 1.0, 2.0, 0.4503761201835743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 513471.1863817452, 513471.1863817452, 134039.8223614694], 
processed observation next is [0.0, 0.8695652173913043, 0.5606060606060604, 0.98, 1.0, 1.0, 0.31297015022946784, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19017451347472045, 0.19017451347472045, 0.3269263960035839], 
reward next is 0.6731, 
noisyNet noise sample is [array([0.10703243], dtype=float32), 0.33714885]. 
=============================================
[2019-03-23 13:24:40,076] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 13:24:40,077] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:24:40,078] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:24:40,078] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:24:40,079] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:24:40,080] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:24:40,081] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:24:40,079] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:24:40,082] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:24:40,084] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:24:40,084] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:24:40,101] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run45
[2019-03-23 13:24:40,102] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run45
[2019-03-23 13:24:40,102] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run45
[2019-03-23 13:24:40,171] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run45
[2019-03-23 13:24:40,198] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run45
[2019-03-23 13:24:47,167] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02714703], dtype=float32), -0.41946247]
[2019-03-23 13:24:47,168] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [12.5, 89.0, 1.0, 2.0, 0.3235927642300959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 83.03472174601369, 351374.4746524325, 351374.4746524328, 83987.4562904093]
[2019-03-23 13:24:47,170] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:24:47,173] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.2741224e-07 9.9999976e-01 2.2550638e-16 1.4708995e-10 1.5001775e-20], sampled 0.00043910621946052775
[2019-03-23 13:25:00,646] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02714703], dtype=float32), -0.41946247]
[2019-03-23 13:25:00,647] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.9, 63.0, 1.0, 2.0, 0.4835310090986188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 551682.1786282671, 551682.1786282668, 143129.6423109003]
[2019-03-23 13:25:00,648] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:25:00,652] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.7801821e-07 9.9999988e-01 1.9306546e-16 1.4386967e-10 1.1446060e-20], sampled 0.2760719094444324
[2019-03-23 13:25:45,317] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02714703], dtype=float32), -0.41946247]
[2019-03-23 13:25:45,318] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.73333333333333, 57.66666666666666, 1.0, 2.0, 0.5397553794844412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 605882.560310528, 605882.5603105277, 141926.5794001937]
[2019-03-23 13:25:45,321] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:25:45,325] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.8878434e-07 9.9999976e-01 1.9558729e-16 1.4182894e-10 1.1934388e-20], sampled 0.5872267077930763
[2019-03-23 13:25:55,820] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02714703], dtype=float32), -0.41946247]
[2019-03-23 13:25:55,823] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.2, 75.33333333333334, 1.0, 2.0, 0.2122937578287923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 230486.6789119667, 230486.6789119664, 78344.11921077735]
[2019-03-23 13:25:55,824] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:25:55,826] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.6792389e-07 9.9999976e-01 2.8435971e-16 1.6905234e-10 1.9339307e-20], sampled 0.1656378965496953
[2019-03-23 13:26:01,307] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02714703], dtype=float32), -0.41946247]
[2019-03-23 13:26:01,307] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.2, 84.0, 1.0, 2.0, 0.2808332890831409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 304936.9441614789, 304936.9441614786, 102659.9957913804]
[2019-03-23 13:26:01,309] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:26:01,310] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.8675334e-07 9.9999976e-01 1.3964830e-16 1.0781753e-10 8.2205775e-21], sampled 0.43519859808190897
[2019-03-23 13:26:04,611] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02714703], dtype=float32), -0.41946247]
[2019-03-23 13:26:04,612] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.85, 82.5, 1.0, 2.0, 0.2953962343533197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 320734.8549430572, 320734.8549430568, 115191.638680542]
[2019-03-23 13:26:04,612] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:26:04,615] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.8560387e-07 9.9999976e-01 1.3403437e-16 1.0455755e-10 7.8159924e-21], sampled 0.8550524923568749
[2019-03-23 13:26:20,515] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 13:26:20,875] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 13:26:20,926] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 13:26:20,959] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 13:26:21,061] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 13:26:22,077] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1100000, evaluation results [1100000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 13:26:23,140] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.8126869e-08 1.0000000e+00 7.7345379e-16 3.3382377e-10 2.4448101e-21], sum to 1.0000
[2019-03-23 13:26:23,148] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5001
[2019-03-23 13:26:23,161] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 74.5, 1.0, 2.0, 0.6191868178795072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 695813.4065992214, 695813.4065992214, 161599.2810034892], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1510200.0000, 
sim time next is 1510800.0000, 
raw observation next is [27.66666666666666, 73.0, 1.0, 2.0, 0.6147844078796242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 690862.6657883872, 690862.6657883872, 160973.3350896789], 
processed observation next is [0.0, 0.4782608695652174, 0.8939393939393937, 0.73, 1.0, 1.0, 0.5184805098495302, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25587506140310634, 0.25587506140310634, 0.39261789046263146], 
reward next is 0.6074, 
noisyNet noise sample is [array([1.1064419], dtype=float32), -0.49432778]. 
=============================================
[2019-03-23 13:26:29,803] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69000, global step 1104115: loss 0.1978
[2019-03-23 13:26:29,805] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69000, global step 1104115: learning rate 0.0001
[2019-03-23 13:26:29,896] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69000, global step 1104172: loss 0.3928
[2019-03-23 13:26:29,898] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69000, global step 1104173: learning rate 0.0001
[2019-03-23 13:26:29,923] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69000, global step 1104184: loss 0.4949
[2019-03-23 13:26:29,924] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69000, global step 1104184: learning rate 0.0001
[2019-03-23 13:26:30,015] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69000, global step 1104233: loss 0.3077
[2019-03-23 13:26:30,019] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69000, global step 1104234: learning rate 0.0001
[2019-03-23 13:26:30,022] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69000, global step 1104235: loss 0.3698
[2019-03-23 13:26:30,024] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69000, global step 1104237: learning rate 0.0001
[2019-03-23 13:26:30,227] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69000, global step 1104349: loss 0.0713
[2019-03-23 13:26:30,230] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69000, global step 1104349: learning rate 0.0001
[2019-03-23 13:26:30,267] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69000, global step 1104365: loss 0.0193
[2019-03-23 13:26:30,270] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69000, global step 1104365: learning rate 0.0001
[2019-03-23 13:26:30,332] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69000, global step 1104406: loss 0.0035
[2019-03-23 13:26:30,334] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69000, global step 1104406: learning rate 0.0001
[2019-03-23 13:26:30,385] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69000, global step 1104428: loss 0.0114
[2019-03-23 13:26:30,388] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69000, global step 1104429: learning rate 0.0001
[2019-03-23 13:26:30,410] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69000, global step 1104441: loss 0.0535
[2019-03-23 13:26:30,411] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69000, global step 1104441: learning rate 0.0001
[2019-03-23 13:26:30,429] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69000, global step 1104447: loss 0.1050
[2019-03-23 13:26:30,431] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69000, global step 1104450: learning rate 0.0001
[2019-03-23 13:26:30,683] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69000, global step 1104589: loss 0.0132
[2019-03-23 13:26:30,686] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69000, global step 1104589: learning rate 0.0001
[2019-03-23 13:26:30,743] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69000, global step 1104618: loss 0.0061
[2019-03-23 13:26:30,744] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69000, global step 1104618: learning rate 0.0001
[2019-03-23 13:26:30,942] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69000, global step 1104726: loss 0.0027
[2019-03-23 13:26:30,943] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69000, global step 1104726: learning rate 0.0001
[2019-03-23 13:26:31,102] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69000, global step 1104816: loss 0.0367
[2019-03-23 13:26:31,103] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69000, global step 1104817: learning rate 0.0001
[2019-03-23 13:26:32,794] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69500, global step 1105718: loss -260.6261
[2019-03-23 13:26:32,795] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69500, global step 1105718: learning rate 0.0001
[2019-03-23 13:26:33,805] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9999964e-01 3.0013976e-07 2.7888711e-10 1.2164277e-08 2.6533881e-15], sum to 1.0000
[2019-03-23 13:26:33,810] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2510
[2019-03-23 13:26:33,814] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [10.33333333333333, 67.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 170944.2480844528, 170944.2480844525, 57438.94768628012], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1729200.0000, 
sim time next is 1729800.0000, 
raw observation next is [10.0, 68.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 166700.2814281439, 166700.2814281442, 56683.46210855516], 
processed observation next is [1.0, 0.0, 0.09090909090909091, 0.685, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.06174084497338663, 0.06174084497338674, 0.1382523466062321], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5880073], dtype=float32), 0.29419938]. 
=============================================
[2019-03-23 13:26:36,259] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 4.6064081e-08 1.7019244e-18 1.4693051e-13 4.3875285e-25], sum to 1.0000
[2019-03-23 13:26:36,265] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8985
[2019-03-23 13:26:36,270] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.66666666666667, 45.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7260376134895923, 7.078570668846934, 6.9112, 77.32791648015743, 476738.7428429261, 422380.557415266, 99657.69673311144], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1777200.0000, 
sim time next is 1777800.0000, 
raw observation next is [18.83333333333333, 45.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7259333624350597, 7.07769539525494, 6.9112, 77.32789851700596, 476393.6623415494, 422319.7584246935, 100438.7204531313], 
processed observation next is [1.0, 0.5652173913043478, 0.4924242424242422, 0.4583333333333334, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6084762320500853, 0.016649539525494018, 0.0, 0.5084250985713081, 0.17644209716353682, 0.15641472534247908, 0.24497248891007636], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.9705234], dtype=float32), 0.37326154]. 
=============================================
[2019-03-23 13:26:41,851] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 6.0224665e-17 1.5877302e-18 2.8803584e-15 1.1843288e-26], sum to 1.0000
[2019-03-23 13:26:41,857] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3469
[2019-03-23 13:26:41,865] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 786109.6887045735 W.
[2019-03-23 13:26:41,870] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 43.0, 1.0, 2.0, 0.7236138283299158, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.3284634434205, 786109.6887045735, 786109.6887045738, 149825.0312070093], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1870800.0000, 
sim time next is 1871400.0000, 
raw observation next is [23.83333333333333, 43.5, 1.0, 2.0, 0.7402955539205279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.3284634435403, 804247.1534611309, 804247.1534611307, 151769.5785791905], 
processed observation next is [1.0, 0.6521739130434783, 0.7196969696969695, 0.435, 1.0, 1.0, 0.6753694424006598, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206492, 0.29786931609671513, 0.2978693160967151, 0.3701697038516842], 
reward next is 0.6298, 
noisyNet noise sample is [array([-0.17431732], dtype=float32), 0.60088193]. 
=============================================
[2019-03-23 13:26:44,033] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2009704e-02 9.6672940e-01 4.5149850e-06 2.1256402e-02 3.2455958e-08], sum to 1.0000
[2019-03-23 13:26:44,042] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3808
[2019-03-23 13:26:44,047] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7512217240231605, 7.223089137970827, 6.9112, 77.32744080850739, 533717.1288455784, 432423.2556535053, 131119.6510808124], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1917000.0000, 
sim time next is 1917600.0000, 
raw observation next is [18.0, 100.0, 1.0, 1.0, 0.4104285167325846, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32827481919249, 461091.37025076, 461091.37025076, 125082.4438049476], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 1.0, 1.0, 0.5, 0.26303564591573075, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084275727297936, 0.17077458157435554, 0.17077458157435554, 0.30507913123157954], 
reward next is 0.6949, 
noisyNet noise sample is [array([0.8976382], dtype=float32), -0.015926225]. 
=============================================
[2019-03-23 13:26:45,014] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69500, global step 1112192: loss -110.0084
[2019-03-23 13:26:45,016] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69500, global step 1112192: learning rate 0.0001
[2019-03-23 13:26:45,025] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69500, global step 1112195: loss -32.5787
[2019-03-23 13:26:45,026] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69500, global step 1112197: learning rate 0.0001
[2019-03-23 13:26:45,037] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69500, global step 1112198: loss -107.0569
[2019-03-23 13:26:45,039] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69500, global step 1112198: learning rate 0.0001
[2019-03-23 13:26:45,261] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69500, global step 1112313: loss -42.8027
[2019-03-23 13:26:45,262] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9341935e-01 6.5719234e-03 1.3975720e-08 8.7253675e-06 6.9331720e-13], sum to 1.0000
[2019-03-23 13:26:45,266] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69500, global step 1112314: learning rate 0.0001
[2019-03-23 13:26:45,270] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69500, global step 1112317: loss -51.4763
[2019-03-23 13:26:45,271] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69500, global step 1112318: learning rate 0.0001
[2019-03-23 13:26:45,274] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3213
[2019-03-23 13:26:45,280] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1226915.346532753 W.
[2019-03-23 13:26:45,284] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.0, 61.0, 1.0, 2.0, 0.5372972012960309, 1.0, 2.0, 0.5372972012960309, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1226915.346532753, 1226915.346532753, 235399.1055258815], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1954800.0000, 
sim time next is 1955400.0000, 
raw observation next is [25.16666666666667, 61.0, 1.0, 2.0, 0.3593731605242299, 1.0, 2.0, 0.3593731605242299, 1.0, 1.0, 0.7263537433409243, 6.911199999999999, 6.9112, 77.3421103, 1230560.382880996, 1230560.382880996, 277605.8658522922], 
processed observation next is [1.0, 0.6521739130434783, 0.7803030303030305, 0.61, 1.0, 1.0, 0.19921645065528737, 1.0, 1.0, 0.19921645065528737, 1.0, 0.5, 0.6090767762013205, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4557631047707392, 0.4557631047707392, 0.6770874776885176], 
reward next is 0.3229, 
noisyNet noise sample is [array([1.0992833], dtype=float32), -0.14025824]. 
=============================================
[2019-03-23 13:26:45,316] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69500, global step 1112343: loss -48.2521
[2019-03-23 13:26:45,319] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69500, global step 1112344: learning rate 0.0001
[2019-03-23 13:26:45,351] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69500, global step 1112357: loss -19.8157
[2019-03-23 13:26:45,352] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69500, global step 1112357: learning rate 0.0001
[2019-03-23 13:26:45,376] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69500, global step 1112366: loss -43.5129
[2019-03-23 13:26:45,378] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69500, global step 1112366: learning rate 0.0001
[2019-03-23 13:26:45,511] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69500, global step 1112434: loss -16.1264
[2019-03-23 13:26:45,513] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69500, global step 1112435: learning rate 0.0001
[2019-03-23 13:26:45,565] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69500, global step 1112461: loss -50.2385
[2019-03-23 13:26:45,567] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69500, global step 1112461: learning rate 0.0001
[2019-03-23 13:26:45,595] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69500, global step 1112479: loss -104.8692
[2019-03-23 13:26:45,598] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69500, global step 1112481: learning rate 0.0001
[2019-03-23 13:26:45,666] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69500, global step 1112513: loss -119.5975
[2019-03-23 13:26:45,674] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69500, global step 1112515: learning rate 0.0001
[2019-03-23 13:26:45,835] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69500, global step 1112595: loss 27.7836
[2019-03-23 13:26:45,840] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69500, global step 1112595: learning rate 0.0001
[2019-03-23 13:26:46,063] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69500, global step 1112711: loss -102.0855
[2019-03-23 13:26:46,066] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69500, global step 1112711: learning rate 0.0001
[2019-03-23 13:26:46,368] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69500, global step 1112857: loss 1.0385
[2019-03-23 13:26:46,372] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69500, global step 1112858: learning rate 0.0001
[2019-03-23 13:26:47,494] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9998641e-01 1.3586777e-05 3.5581309e-15 1.4339856e-12 2.5426506e-21], sum to 1.0000
[2019-03-23 13:26:47,502] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8093
[2019-03-23 13:26:47,511] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.33333333333333, 67.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.556669821487752, 6.9112, 6.9112, 77.32846344354104, 323780.4152251236, 323780.4152251236, 103693.4945310668], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1986600.0000, 
sim time next is 1987200.0000, 
raw observation next is [19.0, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5439469824890332, 6.9112, 6.9112, 77.32846344354104, 316389.3571492416, 316389.3571492416, 100433.3437121379], 
processed observation next is [0.0, 0.0, 0.5, 0.68, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3484956892700474, 0.0, 0.0, 0.5084288129206541, 0.117181243388608, 0.117181243388608, 0.2449593749076534], 
reward next is 0.7550, 
noisyNet noise sample is [array([-0.46721926], dtype=float32), -1.5400136]. 
=============================================
[2019-03-23 13:26:47,816] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70000, global step 1113592: loss 0.2535
[2019-03-23 13:26:47,818] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70000, global step 1113594: learning rate 0.0001
[2019-03-23 13:26:51,521] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9994218e-01 5.7776695e-05 7.4026352e-19 1.0277612e-12 3.9831254e-25], sum to 1.0000
[2019-03-23 13:26:51,528] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5948
[2019-03-23 13:26:51,533] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.5, 54.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5317255417530611, 6.911199999999999, 6.9112, 77.32846344354104, 309284.0800290591, 309284.0800290594, 94618.91110364988], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2061000.0000, 
sim time next is 2061600.0000, 
raw observation next is [20.33333333333333, 55.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5273269567706061, 6.911200000000001, 6.9112, 77.32846344354104, 306724.7873231794, 306724.7873231791, 93644.13563950289], 
processed observation next is [0.0, 0.8695652173913043, 0.5606060606060604, 0.55, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.32475279538658025, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11360177308265905, 0.11360177308265891, 0.22840033082805583], 
reward next is 0.7716, 
noisyNet noise sample is [array([-1.022018], dtype=float32), 0.3332252]. 
=============================================
[2019-03-23 13:26:51,989] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9998140e-01 1.8574196e-05 1.8431888e-21 2.5378392e-15 1.3509835e-27], sum to 1.0000
[2019-03-23 13:26:51,994] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7811
[2019-03-23 13:26:51,998] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.5, 79.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4125297847580092, 6.911199999999999, 6.9112, 77.32846344354104, 239935.4393480825, 239935.4393480828, 74485.27982508198], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2082600.0000, 
sim time next is 2083200.0000, 
raw observation next is [15.33333333333333, 80.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4087054250925485, 6.911199999999999, 6.9112, 77.32846344354104, 237710.5729800045, 237710.5729800048, 73763.86508906662], 
processed observation next is [0.0, 0.08695652173913043, 0.3333333333333332, 0.8033333333333332, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.15529346441792644, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08804095295555722, 0.08804095295555733, 0.17991186607089418], 
reward next is 0.8201, 
noisyNet noise sample is [array([-0.7429082], dtype=float32), 0.74829614]. 
=============================================
[2019-03-23 13:26:55,597] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 3.2110469e-12 2.2773391e-11 8.4633592e-11 7.3077528e-18], sum to 1.0000
[2019-03-23 13:26:55,606] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6823
[2019-03-23 13:26:55,612] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 561316.5690368554 W.
[2019-03-23 13:26:55,615] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.5, 65.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7633138937602267, 7.293091989685305, 6.9112, 77.32735029957776, 561316.5690368554, 437287.6472522625, 134024.3222932294], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2143800.0000, 
sim time next is 2144400.0000, 
raw observation next is [23.33333333333333, 66.33333333333334, 1.0, 1.0, 0.2198925834012565, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4366570719892207, 6.9112, 6.9112, 77.32823300721108, 498925.0381099939, 498925.0381099939, 165825.6493422606], 
processed observation next is [0.0, 0.8260869565217391, 0.6969696969696968, 0.6633333333333334, 1.0, 0.5, 0.024865729251570615, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1952243885560296, 0.0, 0.0, 0.5084272978191704, 0.1847870511518496, 0.1847870511518496, 0.4044528032738064], 
reward next is 0.5955, 
noisyNet noise sample is [array([-1.6401055], dtype=float32), -1.6545676]. 
=============================================
[2019-03-23 13:26:59,128] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 9.7913136e-12 1.2446821e-14 2.2254056e-13 5.7098460e-21], sum to 1.0000
[2019-03-23 13:26:59,137] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6406
[2019-03-23 13:26:59,140] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 939939.2313807359 W.
[2019-03-23 13:26:59,146] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.0, 69.66666666666667, 1.0, 2.0, 0.4135020061127893, 1.0, 2.0, 0.4135020061127893, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 939939.2313807359, 939939.2313807359, 200340.7863201553], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2214600.0000, 
sim time next is 2215200.0000, 
raw observation next is [22.0, 70.33333333333334, 1.0, 2.0, 0.2691496068400157, 1.0, 2.0, 0.2691496068400157, 1.0, 1.0, 0.5368392602976404, 6.911199999999999, 6.9112, 77.3421103, 918535.2570263803, 918535.2570263805, 236395.1225567271], 
processed observation next is [1.0, 0.6521739130434783, 0.6363636363636364, 0.7033333333333335, 1.0, 1.0, 0.08643700855001962, 1.0, 1.0, 0.08643700855001962, 1.0, 0.5, 0.3383418004252006, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.3401982433431038, 0.3401982433431039, 0.5765734696505539], 
reward next is 0.4234, 
noisyNet noise sample is [array([1.9690603], dtype=float32), 0.69651496]. 
=============================================
[2019-03-23 13:27:00,784] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70000, global step 1120100: loss 0.6382
[2019-03-23 13:27:00,788] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70000, global step 1120101: learning rate 0.0001
[2019-03-23 13:27:00,870] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 2.4223036e-13 4.6513378e-23 5.8997408e-18 3.0858282e-29], sum to 1.0000
[2019-03-23 13:27:00,879] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4750
[2019-03-23 13:27:00,882] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4131369749353919, 6.911199999999999, 6.9112, 77.32846344354104, 240288.680335632, 240288.6803356323, 74793.84749408936], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2256600.0000, 
sim time next is 2257200.0000, 
raw observation next is [14.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.412011333534325, 6.911199999999999, 6.9112, 77.32846344354104, 239633.8236339513, 239633.8236339515, 74661.61070356237], 
processed observation next is [1.0, 0.13043478260869565, 0.2727272727272727, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.16001619076332146, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08875326801257456, 0.08875326801257463, 0.18210148952088384], 
reward next is 0.8179, 
noisyNet noise sample is [array([0.22188587], dtype=float32), 1.0318829]. 
=============================================
[2019-03-23 13:27:00,883] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70000, global step 1120151: loss 0.0819
[2019-03-23 13:27:00,886] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70000, global step 1120153: learning rate 0.0001
[2019-03-23 13:27:00,964] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70000, global step 1120188: loss 0.0647
[2019-03-23 13:27:00,967] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70000, global step 1120188: learning rate 0.0001
[2019-03-23 13:27:01,091] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70000, global step 1120252: loss 0.0455
[2019-03-23 13:27:01,092] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70000, global step 1120253: learning rate 0.0001
[2019-03-23 13:27:01,209] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70000, global step 1120312: loss 0.0481
[2019-03-23 13:27:01,211] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70000, global step 1120313: learning rate 0.0001
[2019-03-23 13:27:01,217] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70000, global step 1120317: loss 0.0429
[2019-03-23 13:27:01,220] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70000, global step 1120317: learning rate 0.0001
[2019-03-23 13:27:01,259] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70000, global step 1120334: loss 0.0988
[2019-03-23 13:27:01,261] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70000, global step 1120335: learning rate 0.0001
[2019-03-23 13:27:01,331] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70000, global step 1120368: loss 0.1831
[2019-03-23 13:27:01,336] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70000, global step 1120371: learning rate 0.0001
[2019-03-23 13:27:01,397] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70000, global step 1120406: loss 0.0354
[2019-03-23 13:27:01,400] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70000, global step 1120407: learning rate 0.0001
[2019-03-23 13:27:01,421] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70000, global step 1120414: loss 0.0780
[2019-03-23 13:27:01,423] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70000, global step 1120416: learning rate 0.0001
[2019-03-23 13:27:01,481] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70000, global step 1120446: loss 0.1345
[2019-03-23 13:27:01,483] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70000, global step 1120446: learning rate 0.0001
[2019-03-23 13:27:01,641] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70000, global step 1120525: loss 0.0598
[2019-03-23 13:27:01,645] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70000, global step 1120527: learning rate 0.0001
[2019-03-23 13:27:01,987] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70000, global step 1120699: loss 0.1149
[2019-03-23 13:27:01,989] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70000, global step 1120700: learning rate 0.0001
[2019-03-23 13:27:02,062] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70000, global step 1120740: loss 0.2150
[2019-03-23 13:27:02,065] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70000, global step 1120740: learning rate 0.0001
[2019-03-23 13:27:02,347] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70000, global step 1120881: loss 0.0144
[2019-03-23 13:27:02,349] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70000, global step 1120881: learning rate 0.0001
[2019-03-23 13:27:03,356] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.9609343e-09 4.4204159e-13 3.7967238e-12 2.3592674e-18], sum to 1.0000
[2019-03-23 13:27:03,364] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5466
[2019-03-23 13:27:03,381] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 610905.3258969223 W.
[2019-03-23 13:27:03,384] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 72.66666666666667, 1.0, 2.0, 0.5624395570882605, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344344154, 610905.3258969223, 610905.3258969225, 131624.3670665644], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2546400.0000, 
sim time next is 2547000.0000, 
raw observation next is [19.0, 70.5, 1.0, 2.0, 0.5657044306703566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354043, 614453.7773649913, 614453.777364991, 132492.4176619576], 
processed observation next is [1.0, 0.4782608695652174, 0.5, 0.705, 1.0, 1.0, 0.4571305383379457, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206501, 0.2275754730981449, 0.22757547309814483, 0.3231522381998966], 
reward next is 0.6768, 
noisyNet noise sample is [array([1.018268], dtype=float32), 0.8215695]. 
=============================================
[2019-03-23 13:27:03,393] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[41.106365]
 [41.265297]
 [41.852703]
 [42.650345]
 [42.735325]], R is [[41.14659119]
 [41.41409302]
 [40.99995422]
 [40.58995438]
 [40.18405533]].
[2019-03-23 13:27:03,911] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70500, global step 1121662: loss 22.0079
[2019-03-23 13:27:03,913] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70500, global step 1121664: learning rate 0.0001
[2019-03-23 13:27:05,376] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.00000000e+00 6.60738602e-36 1.05997125e-32 6.02303469e-34
 0.00000000e+00], sum to 1.0000
[2019-03-23 13:27:05,385] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3797
[2019-03-23 13:27:05,387] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.66666666666667, 67.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4043967937166855, 6.911199999999999, 6.9112, 77.32846344354104, 235203.9880210163, 235203.9880210166, 68053.16884036198], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2334000.0000, 
sim time next is 2334600.0000, 
raw observation next is [15.5, 67.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4005105582241349, 6.9112, 6.9112, 77.32846344354104, 232943.1467367666, 232943.1467367666, 67054.82727525786], 
processed observation next is [1.0, 0.0, 0.3409090909090909, 0.675, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.14358651174876416, 0.0, 0.0, 0.5084288129206541, 0.08627523953213577, 0.08627523953213577, 0.163548359207946], 
reward next is 0.8365, 
noisyNet noise sample is [array([-0.31242093], dtype=float32), 0.88430524]. 
=============================================
[2019-03-23 13:27:07,331] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 3.6531338e-23 2.3892878e-21 4.7234012e-21 3.0511077e-31], sum to 1.0000
[2019-03-23 13:27:07,340] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8597
[2019-03-23 13:27:07,344] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.0, 49.0, 1.0, 2.0, 0.2250457461931197, 1.0, 1.0, 0.2250457461931197, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846137814377, 488814.7998883704, 488814.7998883704, 139917.9171253154], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2374200.0000, 
sim time next is 2374800.0000, 
raw observation next is [20.0, 49.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7492180954707205, 7.273132455563444, 6.9112, 77.3275843563706, 553447.3606508336, 435900.4381974931, 99229.40427142117], 
processed observation next is [1.0, 0.4782608695652174, 0.5454545454545454, 0.49, 0.0, 0.5, -0.25, 0.0, 0.5, -0.25, 1.0, 0.5, 0.6417401363867437, 0.03619324555634442, 0.0, 0.5084230329888332, 0.20498050394475317, 0.16144460673981226, 0.2420229372473687], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3059818], dtype=float32), 0.29631203]. 
=============================================
[2019-03-23 13:27:10,483] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 13:27:10,486] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:27:10,488] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:27:10,488] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:27:10,489] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:27:10,489] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:27:10,491] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:27:10,491] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:27:10,492] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:27:10,492] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:27:10,495] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:27:10,512] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run46
[2019-03-23 13:27:10,538] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run46
[2019-03-23 13:27:10,539] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run46
[2019-03-23 13:27:10,584] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run46
[2019-03-23 13:27:10,610] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run46
[2019-03-23 13:27:17,951] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02714703], dtype=float32), -0.42059046]
[2019-03-23 13:27:17,952] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [12.734435315, 99.75601508, 1.0, 2.0, 0.5323963066809138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769552652, 578188.2262688391, 578188.2262688391, 112451.0925239122]
[2019-03-23 13:27:17,953] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:27:17,957] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 2.6485856e-15 1.0698640e-15 3.5473776e-15 9.7724897e-23], sampled 0.7407672404172047
[2019-03-23 13:27:17,958] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 578188.2262688391 W.
[2019-03-23 13:27:59,806] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02714703], dtype=float32), -0.42059046]
[2019-03-23 13:27:59,807] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.8, 53.0, 1.0, 2.0, 0.8321679916620245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 948573.1828330699, 948573.1828330696, 194364.0725455078]
[2019-03-23 13:27:59,808] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:27:59,810] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 7.7847309e-26 3.4569649e-22 1.1665126e-22 2.9443771e-33], sampled 0.7464589453348728
[2019-03-23 13:27:59,811] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 948573.1828330699 W.
[2019-03-23 13:28:03,106] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02714703], dtype=float32), -0.42059046]
[2019-03-23 13:28:03,108] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.16666666666667, 51.83333333333334, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7141505827172309, 7.142090350863956, 6.9112, 95.55261161937679, 502722.1231215227, 410060.9838259087, 132127.7205698875]
[2019-03-23 13:28:03,110] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:28:03,115] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 4.4170344e-25 1.3305138e-21 4.4465931e-22 2.6181154e-32], sampled 0.41162053162720746
[2019-03-23 13:28:11,161] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02714703], dtype=float32), -0.42059046]
[2019-03-23 13:28:11,162] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.8, 90.0, 1.0, 2.0, 0.5287709669218036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 602482.7775919647, 602482.7775919643, 150439.7084080317]
[2019-03-23 13:28:11,163] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:28:11,166] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0000000e+00 2.1899719e-17 5.2423564e-18 2.1279364e-17 4.3225864e-26], sampled 0.3518329830720349
[2019-03-23 13:28:11,167] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 602482.7775919647 W.
[2019-03-23 13:28:23,374] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02714703], dtype=float32), -0.42059046]
[2019-03-23 13:28:23,376] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.42159718, 96.53601492333333, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7354435726148475, 7.293765384902636, 6.9112, 95.55216800051868, 573718.3029361978, 420187.504832719, 135948.1223427527]
[2019-03-23 13:28:23,378] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:28:23,382] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 1.5544427e-21 5.5440674e-19 3.1253412e-19 2.9780128e-28], sampled 0.7297321489800769
[2019-03-23 13:28:23,383] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 573718.3029361978 W.
[2019-03-23 13:28:24,288] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02714703], dtype=float32), -0.42059046]
[2019-03-23 13:28:24,290] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.96666666666667, 82.33333333333334, 1.0, 2.0, 0.4498657919104016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846147034736, 512408.4651318485, 512408.4651318485, 133326.8149667613]
[2019-03-23 13:28:24,291] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:28:24,294] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 4.4464639e-19 6.0188546e-19 1.5688016e-18 1.1899618e-27], sampled 0.4452899994540995
[2019-03-23 13:28:26,147] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02714703], dtype=float32), -0.42059046]
[2019-03-23 13:28:26,148] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [12.2, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3166349065472757, 6.9112, 6.9112, 77.32846344354104, 184565.4786423801, 184565.4786423801, 58706.34581439264]
[2019-03-23 13:28:26,150] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:28:26,154] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 3.3414698e-20 4.5529637e-21 2.3270158e-20 1.4814489e-30], sampled 0.5824934618187244
[2019-03-23 13:28:32,424] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02714703], dtype=float32), -0.42059046]
[2019-03-23 13:28:32,425] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.53333333333333, 91.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7148034269096203, 7.175858257946349, 6.9112, 95.55227158911819, 518528.1865483627, 412315.6560336746, 130822.8156705337]
[2019-03-23 13:28:32,427] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:28:32,429] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 3.9076130e-22 1.1123488e-19 6.7709722e-20 2.9169708e-29], sampled 0.7831029684204647
[2019-03-23 13:28:36,509] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02714703], dtype=float32), -0.42059046]
[2019-03-23 13:28:36,510] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.9, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7218602446565177, 6.988084268422186, 6.9112, 77.32817568420761, 441062.9915239185, 416092.6466171276, 127478.6356255207]
[2019-03-23 13:28:36,511] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:28:36,513] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 9.8287232e-22 6.3000757e-21 1.1113939e-20 1.0141216e-30], sampled 0.609162201461958
[2019-03-23 13:28:37,033] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02714703], dtype=float32), -0.42059046]
[2019-03-23 13:28:37,034] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.19388035333333, 79.39893417, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7328239773468818, 7.2881009769747, 6.9112, 95.55218719587488, 571066.9141406926, 419809.3207746748, 134858.5659429819]
[2019-03-23 13:28:37,034] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:28:37,039] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0000000e+00 8.2606504e-23 5.6720073e-21 5.3040424e-21 4.9592047e-31], sampled 0.41622721308778887
[2019-03-23 13:28:37,041] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 571066.9141406926 W.
[2019-03-23 13:28:39,006] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02714703], dtype=float32), -0.42059046]
[2019-03-23 13:28:39,007] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.59830654666667, 65.78124509833333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7054898255501261, 7.107098272163611, 6.9112, 95.5525464748132, 486342.9040278949, 407724.8732558488, 129271.4317256724]
[2019-03-23 13:28:39,007] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:28:39,008] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.000000e+00 9.787530e-22 5.109183e-21 9.586042e-21 7.781890e-31], sampled 0.09611017426131996
[2019-03-23 13:28:46,646] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02714703], dtype=float32), -0.42059046]
[2019-03-23 13:28:46,647] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [28.3, 56.0, 1.0, 2.0, 0.5071986909159997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 578004.9305567789, 578004.9305567786, 143479.6288561249]
[2019-03-23 13:28:46,648] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:28:46,650] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 1.8015584e-18 2.7980999e-18 6.9166250e-18 1.1162725e-26], sampled 0.9472460366916042
[2019-03-23 13:28:46,651] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 578004.9305567789 W.
[2019-03-23 13:28:48,320] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02714703], dtype=float32), -0.42059046]
[2019-03-23 13:28:48,322] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.8, 63.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4729776715112765, 6.911199999999999, 6.9112, 95.55338769695034, 275088.2243785477, 275088.224378548, 85082.9643469809]
[2019-03-23 13:28:48,323] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:28:48,327] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0000000e+00 1.7328743e-23 1.4104793e-22 2.4557917e-22 3.4872899e-33], sampled 0.872548776074853
[2019-03-23 13:28:50,752] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6862.2842 1793014293.7888 2409.0000
[2019-03-23 13:28:50,987] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6328.7217 1723294598.4314 3425.0000
[2019-03-23 13:28:51,114] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6481.6076 1678885180.2952 3057.0000
[2019-03-23 13:28:51,217] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6294.9961 1685630448.6673 3228.0000
[2019-03-23 13:28:51,313] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6553.1725 1698634175.0084 2957.0000
[2019-03-23 13:28:52,331] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1125000, evaluation results [1125000.0, 6862.284208925443, 1793014293.78876, 2409.0, 6481.607577760913, 1678885180.2951708, 3057.0, 6294.9960618483565, 1685630448.6673346, 3228.0, 6328.721692698646, 1723294598.4313502, 3425.0, 6553.172466661831, 1698634175.0084193, 2957.0]
[2019-03-23 13:28:55,553] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 7.3511729e-26 1.3457268e-26 6.1066234e-26 4.1278581e-38], sum to 1.0000
[2019-03-23 13:28:55,555] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1530
[2019-03-23 13:28:55,562] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.66666666666667, 94.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5537511711078604, 6.911199999999999, 6.9112, 77.32846344354104, 322097.3435833148, 322097.3435833151, 99492.82909277856], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2484600.0000, 
sim time next is 2485200.0000, 
raw observation next is [15.33333333333333, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5394514414032758, 6.911199999999999, 6.9112, 77.32846344354104, 313778.5907647004, 313778.5907647007, 95411.82299765323], 
processed observation next is [1.0, 0.782608695652174, 0.3333333333333332, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3420734877189655, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11621429287581496, 0.11621429287581508, 0.2327117634089103], 
reward next is 0.7673, 
noisyNet noise sample is [array([-0.29403266], dtype=float32), 0.032640304]. 
=============================================
[2019-03-23 13:28:58,200] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70500, global step 1128107: loss -263.7023
[2019-03-23 13:28:58,202] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70500, global step 1128108: learning rate 0.0001
[2019-03-23 13:28:58,323] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70500, global step 1128171: loss -128.6169
[2019-03-23 13:28:58,329] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70500, global step 1128173: learning rate 0.0001
[2019-03-23 13:28:58,485] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70500, global step 1128254: loss -154.9007
[2019-03-23 13:28:58,486] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70500, global step 1128255: learning rate 0.0001
[2019-03-23 13:28:58,532] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70500, global step 1128280: loss -292.1042
[2019-03-23 13:28:58,535] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70500, global step 1128281: learning rate 0.0001
[2019-03-23 13:28:58,538] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70500, global step 1128283: loss -224.9664
[2019-03-23 13:28:58,541] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70500, global step 1128283: learning rate 0.0001
[2019-03-23 13:28:58,621] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70500, global step 1128322: loss 0.9296
[2019-03-23 13:28:58,624] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70500, global step 1128323: learning rate 0.0001
[2019-03-23 13:28:58,642] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70500, global step 1128333: loss -100.3411
[2019-03-23 13:28:58,643] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70500, global step 1128334: learning rate 0.0001
[2019-03-23 13:28:58,726] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70500, global step 1128378: loss -150.4337
[2019-03-23 13:28:58,727] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70500, global step 1128379: learning rate 0.0001
[2019-03-23 13:28:58,736] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70500, global step 1128384: loss -121.6009
[2019-03-23 13:28:58,738] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70500, global step 1128384: learning rate 0.0001
[2019-03-23 13:28:58,828] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70500, global step 1128431: loss -40.5888
[2019-03-23 13:28:58,829] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70500, global step 1128432: learning rate 0.0001
[2019-03-23 13:28:58,993] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70500, global step 1128517: loss -74.3305
[2019-03-23 13:28:58,995] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70500, global step 1128518: learning rate 0.0001
[2019-03-23 13:28:59,185] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70500, global step 1128625: loss -13.8773
[2019-03-23 13:28:59,188] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70500, global step 1128626: learning rate 0.0001
[2019-03-23 13:28:59,189] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70500, global step 1128626: loss -31.6727
[2019-03-23 13:28:59,192] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70500, global step 1128627: learning rate 0.0001
[2019-03-23 13:28:59,256] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70500, global step 1128661: loss -59.9533
[2019-03-23 13:28:59,258] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70500, global step 1128661: learning rate 0.0001
[2019-03-23 13:28:59,561] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70500, global step 1128824: loss -70.2765
[2019-03-23 13:28:59,562] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70500, global step 1128824: learning rate 0.0001
[2019-03-23 13:29:01,173] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71000, global step 1129689: loss -272.8656
[2019-03-23 13:29:01,174] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71000, global step 1129689: learning rate 0.0001
[2019-03-23 13:29:02,269] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.3198827e-21 8.4762923e-20 4.7981389e-18 1.1566809e-28], sum to 1.0000
[2019-03-23 13:29:02,279] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5740
[2019-03-23 13:29:02,283] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.0, 42.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6963989396332257, 6.911199999999999, 6.9112, 77.32846344354104, 400914.6992449747, 400914.699244975, 125204.38500871], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2639400.0000, 
sim time next is 2640000.0000, 
raw observation next is [27.0, 42.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6974302634864101, 6.9112, 6.9112, 77.32846344354104, 401450.6938179074, 401450.6938179074, 125351.7835637295], 
processed observation next is [0.0, 0.5652173913043478, 0.8636363636363636, 0.42, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5677575192663002, 0.0, 0.0, 0.5084288129206541, 0.14868544215478052, 0.14868544215478052, 0.305736057472511], 
reward next is 0.6943, 
noisyNet noise sample is [array([0.93345994], dtype=float32), -2.8009703]. 
=============================================
[2019-03-23 13:29:02,300] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[43.26325 ]
 [43.673283]
 [43.703743]
 [43.347736]
 [43.21906 ]], R is [[43.52617264]
 [43.78553391]
 [44.0439949 ]
 [44.30328751]
 [44.56298828]].
[2019-03-23 13:29:06,286] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 5.7105048e-08 9.8584281e-14 2.0391131e-11 8.6550952e-18], sum to 1.0000
[2019-03-23 13:29:06,293] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5726
[2019-03-23 13:29:06,297] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.63333333333333, 98.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6194260809500398, 6.911199999999999, 6.9112, 77.32846344354104, 359346.220064264, 359346.2200642643, 115827.2721045044], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2695800.0000, 
sim time next is 2696400.0000, 
raw observation next is [16.5, 99.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6153170053211345, 6.9112, 6.9112, 77.32846344354104, 357079.1318651711, 357079.1318651711, 115388.529663235], 
processed observation next is [0.0, 0.21739130434782608, 0.38636363636363635, 0.99, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.45045286474447793, 0.0, 0.0, 0.5084288129206541, 0.13225153032043374, 0.13225153032043374, 0.2814354382030122], 
reward next is 0.7186, 
noisyNet noise sample is [array([0.7804334], dtype=float32), -0.8192007]. 
=============================================
[2019-03-23 13:29:07,469] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.8506843e-10 3.9584830e-10 8.7757433e-11 1.0184365e-15], sum to 1.0000
[2019-03-23 13:29:07,473] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6901
[2019-03-23 13:29:07,484] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 575088.497650442 W.
[2019-03-23 13:29:07,488] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 65.0, 1.0, 1.0, 0.2520272401095942, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5072937057854828, 6.9112, 6.9112, 77.32810992000249, 575088.497650442, 575088.497650442, 176637.6179860498], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2732400.0000, 
sim time next is 2733000.0000, 
raw observation next is [25.16666666666667, 64.33333333333334, 1.0, 2.0, 0.2287689797669477, 1.0, 1.0, 0.2287689797669477, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846125515975, 522076.8416505295, 522076.8416505298, 173852.681544771], 
processed observation next is [0.0, 0.6521739130434783, 0.7803030303030305, 0.6433333333333334, 1.0, 1.0, 0.035961224708684625, 1.0, 0.5, 0.035961224708684625, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084287985322122, 0.19336179320389982, 0.19336179320389993, 0.4240309305970025], 
reward next is 0.5760, 
noisyNet noise sample is [array([-0.3455164], dtype=float32), -2.0657456]. 
=============================================
[2019-03-23 13:29:07,500] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[27.20401 ]
 [27.441473]
 [26.944607]
 [27.20602 ]
 [27.1182  ]], R is [[27.18177986]
 [26.9099617 ]
 [26.64086151]
 [26.37445259]
 [26.11070824]].
[2019-03-23 13:29:12,917] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.0647850e-11 2.5783212e-10 4.7631077e-10 5.7100734e-14], sum to 1.0000
[2019-03-23 13:29:12,924] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3027
[2019-03-23 13:29:12,931] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 572918.7881612873 W.
[2019-03-23 13:29:12,933] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.16666666666666, 53.5, 1.0, 1.0, 0.2510410304262772, 1.0, 1.0, 0.2510410304262772, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.3281289887976, 572918.7881612873, 572918.7881612875, 177699.8795538451], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2832600.0000, 
sim time next is 2833200.0000, 
raw observation next is [27.0, 54.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 1.0, 0.3089486295852988, 6.911199999999999, 6.9112, 77.3421103, 524171.5029667155, 524171.5029667158, 203468.3348463575], 
processed observation next is [1.0, 0.8260869565217391, 0.8636363636363636, 0.54, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.01278375655042685, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.19413759369137612, 0.1941375936913762, 0.49626423133257924], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2047745], dtype=float32), 0.20247655]. 
=============================================
[2019-03-23 13:29:13,208] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71000, global step 1136052: loss 766.1011
[2019-03-23 13:29:13,212] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71000, global step 1136053: learning rate 0.0001
[2019-03-23 13:29:13,380] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71000, global step 1136138: loss -92.9984
[2019-03-23 13:29:13,383] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71000, global step 1136138: learning rate 0.0001
[2019-03-23 13:29:13,620] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71000, global step 1136249: loss -234.2849
[2019-03-23 13:29:13,622] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71000, global step 1136249: learning rate 0.0001
[2019-03-23 13:29:13,639] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71000, global step 1136258: loss 504.2476
[2019-03-23 13:29:13,642] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71000, global step 1136258: learning rate 0.0001
[2019-03-23 13:29:13,720] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71000, global step 1136307: loss 10.0423
[2019-03-23 13:29:13,723] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71000, global step 1136307: loss 205.0898
[2019-03-23 13:29:13,724] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71000, global step 1136307: learning rate 0.0001
[2019-03-23 13:29:13,726] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71000, global step 1136307: learning rate 0.0001
[2019-03-23 13:29:13,743] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71000, global step 1136312: loss 518.4030
[2019-03-23 13:29:13,744] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71000, global step 1136313: learning rate 0.0001
[2019-03-23 13:29:13,759] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71000, global step 1136317: loss 114.8226
[2019-03-23 13:29:13,760] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71000, global step 1136318: learning rate 0.0001
[2019-03-23 13:29:13,777] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71000, global step 1136324: loss 83.4459
[2019-03-23 13:29:13,778] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71000, global step 1136324: learning rate 0.0001
[2019-03-23 13:29:13,904] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71000, global step 1136389: loss 247.4166
[2019-03-23 13:29:13,906] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71000, global step 1136389: learning rate 0.0001
[2019-03-23 13:29:14,156] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71000, global step 1136515: loss -70.3395
[2019-03-23 13:29:14,157] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71000, global step 1136515: learning rate 0.0001
[2019-03-23 13:29:14,233] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71000, global step 1136550: loss -52.9404
[2019-03-23 13:29:14,240] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71000, global step 1136550: learning rate 0.0001
[2019-03-23 13:29:14,348] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71000, global step 1136611: loss -12.6720
[2019-03-23 13:29:14,351] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71000, global step 1136613: learning rate 0.0001
[2019-03-23 13:29:14,369] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71000, global step 1136621: loss -33.3616
[2019-03-23 13:29:14,370] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71000, global step 1136621: learning rate 0.0001
[2019-03-23 13:29:14,805] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71000, global step 1136840: loss -39.4113
[2019-03-23 13:29:14,809] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71000, global step 1136841: learning rate 0.0001
[2019-03-23 13:29:15,168] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 3.6123296e-12 1.0134054e-09 2.7528554e-10 6.1041687e-14], sum to 1.0000
[2019-03-23 13:29:15,179] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0044
[2019-03-23 13:29:15,192] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 564992.7399849148 W.
[2019-03-23 13:29:15,195] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.0, 88.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7690343076467316, 7.302416014342815, 6.9112, 77.3274990809491, 564992.7399849148, 437935.3648288192, 136564.7396098203], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2872800.0000, 
sim time next is 2873400.0000, 
raw observation next is [21.16666666666667, 88.00000000000001, 1.0, 1.0, 0.250416543572946, 1.0, 1.0, 0.250416543572946, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32822834872404, 571315.583072559, 571315.5830725587, 176037.0077148075], 
processed observation next is [1.0, 0.2608695652173913, 0.5984848484848487, 0.8800000000000001, 1.0, 0.5, 0.0630206794661825, 1.0, 0.5, 0.0630206794661825, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084272671899696, 0.21159836410094776, 0.21159836410094768, 0.4293585554019695], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5885343], dtype=float32), 0.02625022]. 
=============================================
[2019-03-23 13:29:16,060] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9999988e-01 1.4271603e-10 6.9845889e-08 1.7518902e-08 1.2418904e-11], sum to 1.0000
[2019-03-23 13:29:16,066] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1430
[2019-03-23 13:29:16,077] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1507244.679452672 W.
[2019-03-23 13:29:16,080] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 74.0, 1.0, 2.0, 0.6701196608948419, 1.0, 2.0, 0.6701196608948419, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1507244.679452672, 1507244.679452672, 282543.4208724344], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2890800.0000, 
sim time next is 2891400.0000, 
raw observation next is [27.16666666666666, 73.33333333333334, 1.0, 2.0, 0.4537545412913476, 1.0, 2.0, 0.4537545412913476, 1.0, 1.0, 0.918117606730833, 6.911199999999998, 6.9112, 77.3421103, 1530920.394433755, 1530920.394433755, 334710.3987223132], 
processed observation next is [1.0, 0.4782608695652174, 0.871212121212121, 0.7333333333333334, 1.0, 1.0, 0.3171931766141845, 1.0, 1.0, 0.3171931766141845, 1.0, 0.5, 0.8830251524726186, -1.7763568394002506e-16, 0.0, 0.5085185399722538, 0.5670075534939834, 0.5670075534939834, 0.8163668261519835], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.40359864], dtype=float32), -0.5191912]. 
=============================================
[2019-03-23 13:29:16,549] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9999321e-01 1.2181665e-07 4.8482962e-06 1.8258885e-06 6.0112608e-09], sum to 1.0000
[2019-03-23 13:29:16,557] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4479
[2019-03-23 13:29:16,565] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1433301.277090369 W.
[2019-03-23 13:29:16,570] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.33333333333334, 74.0, 1.0, 2.0, 0.4248574607226936, 1.0, 2.0, 0.4248574607226936, 1.0, 1.0, 0.8596478482184536, 6.911199999999999, 6.9112, 77.3421103, 1433301.277090369, 1433301.27709037, 319614.9431885995], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2888400.0000, 
sim time next is 2889000.0000, 
raw observation next is [26.5, 74.0, 1.0, 2.0, 0.4492184843295862, 1.0, 2.0, 0.4492184843295862, 1.0, 2.0, 0.9089394423649738, 6.9112, 6.9112, 77.3421103, 1515595.730261536, 1515595.730261536, 332281.7543771725], 
processed observation next is [1.0, 0.43478260869565216, 0.8409090909090909, 0.74, 1.0, 1.0, 0.31152310541198275, 1.0, 1.0, 0.31152310541198275, 1.0, 1.0, 0.8699134890928198, 0.0, 0.0, 0.5085185399722538, 0.5613317519487171, 0.5613317519487171, 0.8104433033589573], 
reward next is 0.1896, 
noisyNet noise sample is [array([0.57002157], dtype=float32), 0.37779394]. 
=============================================
[2019-03-23 13:29:16,582] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[8.482933]
 [8.5769  ]
 [8.565514]
 [8.673508]
 [8.867099]], R is [[8.55245876]
 [8.68738556]
 [8.96251583]
 [9.22767735]
 [9.46084404]].
[2019-03-23 13:29:17,105] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71500, global step 1137973: loss 7.4517
[2019-03-23 13:29:17,106] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71500, global step 1137973: learning rate 0.0001
[2019-03-23 13:29:25,948] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.3156740e-03 9.8838347e-01 3.4703064e-07 6.3005625e-03 7.7792273e-10], sum to 1.0000
[2019-03-23 13:29:25,953] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4703
[2019-03-23 13:29:25,962] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1187558.375318242 W.
[2019-03-23 13:29:25,969] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.0, 74.0, 1.0, 2.0, 0.3475446487583199, 1.0, 1.0, 0.3475446487583199, 1.0, 2.0, 0.7037854204271199, 6.911199999999999, 6.9112, 77.3421103, 1187558.375318242, 1187558.375318243, 276212.231119524], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3073800.0000, 
sim time next is 3074400.0000, 
raw observation next is [24.0, 74.0, 1.0, 2.0, 0.3434779303306734, 1.0, 2.0, 0.3434779303306734, 1.0, 2.0, 0.695694134420261, 6.911199999999999, 6.9112, 77.3421103, 1172759.892270899, 1172759.892270899, 275310.8960935584], 
processed observation next is [1.0, 0.6086956521739131, 0.7272727272727273, 0.74, 1.0, 1.0, 0.17934741291334175, 1.0, 1.0, 0.17934741291334175, 1.0, 1.0, 0.5652773348860871, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4343555156558885, 0.4343555156558885, 0.6714899904720937], 
reward next is 0.3285, 
noisyNet noise sample is [array([-1.1765282], dtype=float32), -0.10107755]. 
=============================================
[2019-03-23 13:29:26,260] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.2270458e-03 9.9235028e-01 9.0436833e-07 1.4216773e-03 4.6618640e-11], sum to 1.0000
[2019-03-23 13:29:26,264] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8782
[2019-03-23 13:29:26,267] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1498775.923019259 W.
[2019-03-23 13:29:26,277] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 74.0, 1.0, 2.0, 0.6663594365109146, 1.0, 2.0, 0.6663594365109146, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1498775.923019259, 1498775.923019259, 281385.9178908829], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3079800.0000, 
sim time next is 3080400.0000, 
raw observation next is [26.0, 74.0, 1.0, 2.0, 0.7031863686227355, 1.0, 2.0, 0.7031863686227355, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1581722.790553844, 1581722.790553844, 292790.513918773], 
processed observation next is [1.0, 0.6521739130434783, 0.8181818181818182, 0.74, 1.0, 1.0, 0.6289829607784194, 1.0, 1.0, 0.6289829607784194, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.585823255760683, 0.585823255760683, 0.7141232046799341], 
reward next is 0.2859, 
noisyNet noise sample is [array([-0.5659435], dtype=float32), 1.6965196]. 
=============================================
[2019-03-23 13:29:28,081] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.8677969e-01 1.3216728e-02 5.9862354e-10 3.6132537e-06 1.8202310e-12], sum to 1.0000
[2019-03-23 13:29:28,089] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8752
[2019-03-23 13:29:28,096] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 566762.1320344583 W.
[2019-03-23 13:29:28,100] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 88.33333333333334, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3356733114012823, 6.9112, 6.9112, 77.3421103, 566762.1320344583, 566762.1320344583, 211383.7651305401], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3112800.0000, 
sim time next is 3113400.0000, 
raw observation next is [22.16666666666667, 88.16666666666667, 1.0, 2.0, 0.4892508965336103, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 558249.3003999807, 558249.3003999805, 140083.852285927], 
processed observation next is [1.0, 0.0, 0.6439393939393941, 0.8816666666666667, 1.0, 1.0, 0.36156362066701286, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20675900014814103, 0.20675900014814094, 0.34166793240469995], 
reward next is 0.6583, 
noisyNet noise sample is [array([1.4189806], dtype=float32), -0.6259725]. 
=============================================
[2019-03-23 13:29:28,145] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.7911997e-01 2.2086620e-01 2.1168898e-08 1.3821469e-05 1.5226901e-11], sum to 1.0000
[2019-03-23 13:29:28,157] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3004
[2019-03-23 13:29:28,158] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 551243.4646798642 W.
[2019-03-23 13:29:28,162] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.83333333333334, 1.0, 2.0, 0.4835650115116032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 551243.4646798642, 551243.4646798642, 137471.23578969], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3120600.0000, 
sim time next is 3121200.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4915930525002802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560207.2436248924, 560207.2436248924, 138085.0311944], 
processed observation next is [1.0, 0.13043478260869565, 0.6363636363636364, 0.83, 1.0, 1.0, 0.3644913156253502, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20748416430551572, 0.20748416430551572, 0.33679275901073175], 
reward next is 0.6632, 
noisyNet noise sample is [array([0.7501324], dtype=float32), 1.1872034]. 
=============================================
[2019-03-23 13:29:29,249] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.4813457e-02 9.2076820e-01 6.0174523e-05 1.4357315e-02 7.7729970e-07], sum to 1.0000
[2019-03-23 13:29:29,257] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2554
[2019-03-23 13:29:29,260] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 71.66666666666667, 1.0, 2.0, 0.7913947879024849, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344311459, 902304.7615241678, 902304.7615241678, 177739.1229103608], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3144000.0000, 
sim time next is 3144600.0000, 
raw observation next is [23.5, 71.0, 1.0, 2.0, 0.8145689112189193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.3284634435384, 928180.3980923295, 928180.3980923295, 180596.3998022273], 
processed observation next is [1.0, 0.391304347826087, 0.7045454545454546, 0.71, 1.0, 1.0, 0.768211139023649, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206367, 0.3437705178119739, 0.3437705178119739, 0.44047902390787147], 
reward next is 0.5595, 
noisyNet noise sample is [array([-0.2250471], dtype=float32), -1.929219]. 
=============================================
[2019-03-23 13:29:29,553] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71500, global step 1144179: loss -9.5804
[2019-03-23 13:29:29,555] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71500, global step 1144179: learning rate 0.0001
[2019-03-23 13:29:29,673] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71500, global step 1144242: loss -11.3264
[2019-03-23 13:29:29,677] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71500, global step 1144243: learning rate 0.0001
[2019-03-23 13:29:29,761] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71500, global step 1144282: loss -23.1364
[2019-03-23 13:29:29,762] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71500, global step 1144282: learning rate 0.0001
[2019-03-23 13:29:29,839] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71500, global step 1144327: loss 1.0697
[2019-03-23 13:29:29,839] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71500, global step 1144327: loss -1.3562
[2019-03-23 13:29:29,841] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71500, global step 1144327: learning rate 0.0001
[2019-03-23 13:29:29,841] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71500, global step 1144327: learning rate 0.0001
[2019-03-23 13:29:29,859] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71500, global step 1144337: loss 11.0532
[2019-03-23 13:29:29,861] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71500, global step 1144338: learning rate 0.0001
[2019-03-23 13:29:29,866] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71500, global step 1144339: loss -30.6150
[2019-03-23 13:29:29,867] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71500, global step 1144339: learning rate 0.0001
[2019-03-23 13:29:29,884] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71500, global step 1144346: loss -3.0416
[2019-03-23 13:29:29,886] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71500, global step 1144346: learning rate 0.0001
[2019-03-23 13:29:29,993] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71500, global step 1144405: loss -16.1312
[2019-03-23 13:29:29,994] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71500, global step 1144405: learning rate 0.0001
[2019-03-23 13:29:30,003] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71500, global step 1144406: loss -5.7080
[2019-03-23 13:29:30,004] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71500, global step 1144407: learning rate 0.0001
[2019-03-23 13:29:30,265] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71500, global step 1144540: loss -19.5433
[2019-03-23 13:29:30,267] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71500, global step 1144540: learning rate 0.0001
[2019-03-23 13:29:30,369] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71500, global step 1144590: loss -0.0975
[2019-03-23 13:29:30,371] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71500, global step 1144590: learning rate 0.0001
[2019-03-23 13:29:30,409] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71500, global step 1144610: loss -6.3854
[2019-03-23 13:29:30,412] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71500, global step 1144610: learning rate 0.0001
[2019-03-23 13:29:30,430] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71500, global step 1144619: loss -8.5973
[2019-03-23 13:29:30,433] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71500, global step 1144620: learning rate 0.0001
[2019-03-23 13:29:30,818] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71500, global step 1144817: loss -0.1939
[2019-03-23 13:29:30,821] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71500, global step 1144819: learning rate 0.0001
[2019-03-23 13:29:32,162] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72000, global step 1145502: loss 0.4019
[2019-03-23 13:29:32,163] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72000, global step 1145502: learning rate 0.0001
[2019-03-23 13:29:32,230] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.2335430e-03 5.7571918e-02 7.7765158e-05 9.3711674e-01 1.4152663e-07], sum to 1.0000
[2019-03-23 13:29:32,238] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0865
[2019-03-23 13:29:32,243] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.0, 94.00000000000001, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 443133.9690793836, 443133.9690793836, 162608.1516254684], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3201000.0000, 
sim time next is 3201600.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 442476.8074578716, 442476.8074578716, 162473.2051140764], 
processed observation next is [0.0, 0.043478260869565216, 0.5, 0.94, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16388029905847096, 0.16388029905847096, 0.3962761100343327], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.16751769], dtype=float32), 1.0182533]. 
=============================================
[2019-03-23 13:29:34,149] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 5.9108905e-11 1.8954087e-23 3.0829473e-13 3.9621480e-28], sum to 1.0000
[2019-03-23 13:29:34,151] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9764
[2019-03-23 13:29:34,155] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.33333333333333, 53.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6509898008118521, 6.911199999999999, 6.9112, 77.32846344354104, 376555.4868175569, 376555.4868175572, 119438.5469386719], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3238800.0000, 
sim time next is 3239400.0000, 
raw observation next is [23.16666666666667, 53.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6393317252557827, 6.9112, 6.9112, 77.32846344354104, 370133.5441822273, 370133.5441822273, 118136.0539649501], 
processed observation next is [0.0, 0.4782608695652174, 0.6893939393939396, 0.5316666666666667, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.48475960750826114, 0.0, 0.0, 0.5084288129206541, 0.13708649784526936, 0.13708649784526936, 0.2881367169876832], 
reward next is 0.7119, 
noisyNet noise sample is [array([0.78066874], dtype=float32), 1.0386932]. 
=============================================
[2019-03-23 13:29:36,869] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 3.1299323e-09 7.9347061e-24 4.7083200e-16 2.0088229e-28], sum to 1.0000
[2019-03-23 13:29:36,880] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7194
[2019-03-23 13:29:36,885] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.66666666666667, 78.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5486858235633998, 6.911199999999999, 6.9112, 77.32846344354104, 319151.4493971828, 319151.4493971831, 101404.3872106862], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3280800.0000, 
sim time next is 3281400.0000, 
raw observation next is [17.5, 79.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5458301536510571, 6.9112, 6.9112, 77.32846344354104, 317490.5274397876, 317490.5274397876, 100547.6232624246], 
processed observation next is [0.0, 1.0, 0.4318181818181818, 0.795, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3511859337872245, 0.0, 0.0, 0.5084288129206541, 0.11758908423695837, 0.11758908423695837, 0.2452381055181088], 
reward next is 0.7548, 
noisyNet noise sample is [array([-0.8001445], dtype=float32), -0.8271855]. 
=============================================
[2019-03-23 13:29:38,828] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 5.8070682e-10 8.4032336e-22 2.3192509e-14 8.3726184e-28], sum to 1.0000
[2019-03-23 13:29:38,838] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8976
[2019-03-23 13:29:38,841] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.33333333333334, 56.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6529403129853107, 6.911199999999999, 6.9112, 77.32846344354104, 377375.5865507112, 377375.5865507115, 119847.9657501222], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3325200.0000, 
sim time next is 3325800.0000, 
raw observation next is [23.66666666666666, 55.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6609465090249437, 6.911199999999999, 6.9112, 77.32846344354104, 381734.0431585675, 381734.0431585677, 120795.5681629423], 
processed observation next is [0.0, 0.4782608695652174, 0.7121212121212118, 0.55, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5156378700356339, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1413829789476176, 0.14138297894761767, 0.2946233369827861], 
reward next is 0.7054, 
noisyNet noise sample is [array([0.03728343], dtype=float32), -0.18522324]. 
=============================================
[2019-03-23 13:29:40,153] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.00000000e+00 5.14746219e-08 1.93899963e-19 1.16763034e-14
 9.70027742e-25], sum to 1.0000
[2019-03-23 13:29:40,158] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5610
[2019-03-23 13:29:40,162] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.5, 59.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7283765586582065, 7.033960185950972, 6.9112, 77.32803488749738, 459150.3559313374, 419280.5793748851, 128595.4222691489], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3349800.0000, 
sim time next is 3350400.0000, 
raw observation next is [23.33333333333333, 59.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7279577291884135, 7.031844052510165, 6.9112, 77.32803908630036, 458316.0368001175, 419133.5311663677, 128480.9199847139], 
processed observation next is [0.0, 0.782608695652174, 0.6969696969696968, 0.5966666666666667, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6113681845548765, 0.012064405251016463, 0.0, 0.5084260228038132, 0.16974668029633982, 0.15523464117272878, 0.31336809752369243], 
reward next is 0.0834, 
noisyNet noise sample is [array([0.76757455], dtype=float32), -0.38989633]. 
=============================================
[2019-03-23 13:29:41,055] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 13:29:41,057] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:29:41,058] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:29:41,058] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:29:41,059] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:29:41,060] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:29:41,060] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:29:41,062] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:29:41,063] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:29:41,063] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:29:41,066] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:29:41,078] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run47
[2019-03-23 13:29:41,105] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run47
[2019-03-23 13:29:41,107] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run47
[2019-03-23 13:29:41,107] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run47
[2019-03-23 13:29:41,130] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run47
[2019-03-23 13:29:52,060] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02714703], dtype=float32), -0.41927534]
[2019-03-23 13:29:52,063] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.74136460333333, 59.25267791333334, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7625261858432117, 7.517553020983124, 6.9112, 95.55148799481208, 678467.9621026554, 435128.64180129, 139457.1424786739]
[2019-03-23 13:29:52,064] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:29:52,065] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.9999964e-01 3.1247927e-07 8.2136653e-17 4.8357659e-12 9.7503733e-22], sampled 0.9326348282417561
[2019-03-23 13:29:52,068] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 678467.9621026554 W.
[2019-03-23 13:29:59,372] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02714703], dtype=float32), -0.41927534]
[2019-03-23 13:29:59,375] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [28.94059230166667, 72.60472552333333, 1.0, 2.0, 0.6456399065200731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 725459.0614206821, 725459.0614206821, 169738.7160374682]
[2019-03-23 13:29:59,376] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:29:59,378] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.9999857e-01 1.4135198e-06 4.9689523e-15 8.6527202e-11 1.8894111e-19], sampled 0.9417841574413811
[2019-03-23 13:29:59,379] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 725459.0614206821 W.
[2019-03-23 13:30:11,105] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02714703], dtype=float32), -0.41927534]
[2019-03-23 13:30:11,108] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.13843601, 79.31145075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.512345935191722, 6.9112, 6.9112, 95.55338769694897, 297885.5959213469, 297885.5959213469, 92181.84745924326]
[2019-03-23 13:30:11,109] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:30:11,111] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0000000e+00 1.8548552e-09 6.6941462e-23 3.0267055e-16 1.3950365e-29], sampled 0.6246065385137592
[2019-03-23 13:30:46,739] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02714703], dtype=float32), -0.41927534]
[2019-03-23 13:30:46,742] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.25985686166667, 94.73663191666668, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7714996714245638, 7.561054435361309, 6.9112, 95.55137022128909, 698829.8215103139, 438032.9981890619, 142075.9895435784]
[2019-03-23 13:30:46,743] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:30:46,745] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.9999964e-01 3.1222578e-07 1.1141671e-17 1.9294286e-12 7.8969319e-23], sampled 0.504308872702485
[2019-03-23 13:30:46,747] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 698829.8215103139 W.
[2019-03-23 13:30:50,107] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02714703], dtype=float32), -0.41927534]
[2019-03-23 13:30:50,111] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.61666666666667, 48.66666666666666, 1.0, 1.0, 0.4452492933313025, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 95.5530972150828, 504380.4113227042, 504380.4113227042, 134912.4978001755]
[2019-03-23 13:30:50,115] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:30:50,118] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0000000e+00 2.4746786e-08 5.4127035e-20 3.3345847e-14 7.8767348e-26], sampled 0.5365348740678678
[2019-03-23 13:31:20,917] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6481.6076 1678885180.2952 3057.0000
[2019-03-23 13:31:21,214] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6862.2842 1793014293.7888 2409.0000
[2019-03-23 13:31:21,585] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6328.7217 1723294598.4314 3425.0000
[2019-03-23 13:31:21,621] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6552.8133 1698593122.3941 2957.0000
[2019-03-23 13:31:21,677] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6294.9961 1685630448.6673 3228.0000
[2019-03-23 13:31:22,691] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1150000, evaluation results [1150000.0, 6862.284208925443, 1793014293.78876, 2409.0, 6481.607577760913, 1678885180.2951708, 3057.0, 6294.9960618483565, 1685630448.6673346, 3228.0, 6328.721692698646, 1723294598.4313502, 3425.0, 6552.813300279973, 1698593122.3940735, 2957.0]
[2019-03-23 13:31:23,778] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9997687e-01 2.3104392e-05 2.1107190e-14 1.3727464e-09 7.1857535e-20], sum to 1.0000
[2019-03-23 13:31:23,783] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0704
[2019-03-23 13:31:23,790] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 562291.4233656187 W.
[2019-03-23 13:31:23,795] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.2466969896091707, 1.0, 2.0, 0.2466969896091707, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 562291.4233656187, 562291.4233656187, 178845.2808169714], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3631200.0000, 
sim time next is 3631800.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4922775325451654, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 561581.8406879185, 561581.8406879181, 140842.0869733979], 
processed observation next is [1.0, 0.0, 0.5909090909090909, 1.0, 1.0, 1.0, 0.36534691568145666, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2079932743288587, 0.20799327432885856, 0.3435172853009705], 
reward next is 0.6565, 
noisyNet noise sample is [array([-0.20785879], dtype=float32), -0.39075956]. 
=============================================
[2019-03-23 13:31:26,828] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72000, global step 1152189: loss 2.6433
[2019-03-23 13:31:26,831] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72000, global step 1152191: learning rate 0.0001
[2019-03-23 13:31:26,907] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72000, global step 1152228: loss -33.5993
[2019-03-23 13:31:26,909] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72000, global step 1152229: learning rate 0.0001
[2019-03-23 13:31:26,994] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72000, global step 1152274: loss 101.2304
[2019-03-23 13:31:26,996] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72000, global step 1152276: learning rate 0.0001
[2019-03-23 13:31:27,037] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72000, global step 1152297: loss 28.0474
[2019-03-23 13:31:27,039] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72000, global step 1152297: learning rate 0.0001
[2019-03-23 13:31:27,068] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72000, global step 1152311: loss 50.1696
[2019-03-23 13:31:27,070] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72000, global step 1152311: learning rate 0.0001
[2019-03-23 13:31:27,114] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72000, global step 1152337: loss 11.6366
[2019-03-23 13:31:27,116] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72000, global step 1152337: loss -24.8467
[2019-03-23 13:31:27,119] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72000, global step 1152337: learning rate 0.0001
[2019-03-23 13:31:27,122] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72000, global step 1152337: learning rate 0.0001
[2019-03-23 13:31:27,168] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72000, global step 1152363: loss 11.8430
[2019-03-23 13:31:27,170] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72000, global step 1152365: learning rate 0.0001
[2019-03-23 13:31:27,188] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72000, global step 1152375: loss -25.1612
[2019-03-23 13:31:27,190] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72000, global step 1152375: learning rate 0.0001
[2019-03-23 13:31:27,195] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72000, global step 1152379: loss 16.2165
[2019-03-23 13:31:27,198] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72000, global step 1152379: learning rate 0.0001
[2019-03-23 13:31:27,320] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.1119876e-01 4.8363048e-01 1.1963637e-04 5.0510508e-03 1.2836473e-07], sum to 1.0000
[2019-03-23 13:31:27,325] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4985
[2019-03-23 13:31:27,331] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 571492.8492846964 W.
[2019-03-23 13:31:27,335] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5012643252762338, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 571492.8492846964, 571492.8492846964, 142478.1474599813], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3459000.0000, 
sim time next is 3459600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 1.0, 0.3389049390800773, 6.911199999999999, 6.9112, 77.3421103, 571522.7098480952, 571522.7098480955, 212653.5151124034], 
processed observation next is [1.0, 0.043478260869565216, 0.6363636363636364, 0.94, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.5, 0.05557848440011044, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.21167507772151675, 0.21167507772151686, 0.5186671100302522], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.45923114], dtype=float32), 0.73909175]. 
=============================================
[2019-03-23 13:31:27,363] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72000, global step 1152469: loss 4.4214
[2019-03-23 13:31:27,364] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72000, global step 1152469: learning rate 0.0001
[2019-03-23 13:31:27,443] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72000, global step 1152508: loss 3.8590
[2019-03-23 13:31:27,446] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72000, global step 1152509: learning rate 0.0001
[2019-03-23 13:31:27,458] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72000, global step 1152515: loss 3.3082
[2019-03-23 13:31:27,462] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72000, global step 1152516: learning rate 0.0001
[2019-03-23 13:31:27,526] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72000, global step 1152555: loss 3.7588
[2019-03-23 13:31:27,530] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72000, global step 1152555: learning rate 0.0001
[2019-03-23 13:31:27,939] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72000, global step 1152775: loss 7.7327
[2019-03-23 13:31:27,943] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72000, global step 1152775: learning rate 0.0001
[2019-03-23 13:31:29,308] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.2198655e-11 1.0000000e+00 1.0003009e-16 2.7854488e-10 6.1123970e-28], sum to 1.0000
[2019-03-23 13:31:29,320] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4202
[2019-03-23 13:31:29,324] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 95.0, 1.0, 2.0, 0.5061850143396202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 577336.5339282692, 577336.5339282692, 142710.1965997812], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3484200.0000, 
sim time next is 3484800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5121555535231749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 584096.161508431, 584096.1615084307, 143509.2588899656], 
processed observation next is [1.0, 0.34782608695652173, 0.6363636363636364, 0.94, 1.0, 1.0, 0.39019444190396857, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21633191166978924, 0.21633191166978916, 0.35002258265845265], 
reward next is 0.6500, 
noisyNet noise sample is [array([-0.14621872], dtype=float32), 2.5484424]. 
=============================================
[2019-03-23 13:31:29,418] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.2085080e-07 9.9999893e-01 1.7009145e-13 5.5410453e-07 2.6221866e-20], sum to 1.0000
[2019-03-23 13:31:29,436] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8166
[2019-03-23 13:31:29,442] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1671014.526459168 W.
[2019-03-23 13:31:29,446] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.5, 66.0, 1.0, 2.0, 0.9943494397884528, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9824960757920598, 6.911199999999999, 6.9112, 77.32846344354101, 1671014.526459168, 1671014.526459168, 348961.6845109111], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3504600.0000, 
sim time next is 3505200.0000, 
raw observation next is [27.66666666666666, 64.66666666666666, 1.0, 2.0, 0.4433862730025375, 1.0, 1.0, 0.4433862730025375, 1.0, 2.0, 0.8971386659136803, 6.9112, 6.9112, 77.3421103, 1495892.733516104, 1495892.733516104, 329191.4514695173], 
processed observation next is [1.0, 0.5652173913043478, 0.8939393939393937, 0.6466666666666666, 1.0, 1.0, 0.30423284125317185, 1.0, 0.5, 0.30423284125317185, 1.0, 1.0, 0.8530552370195434, 0.0, 0.0, 0.5085185399722538, 0.5540343457467052, 0.5540343457467052, 0.8029059791939447], 
reward next is 0.1971, 
noisyNet noise sample is [array([1.537907], dtype=float32), -0.84587145]. 
=============================================
[2019-03-23 13:31:30,049] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72500, global step 1153884: loss -82.2794
[2019-03-23 13:31:30,054] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72500, global step 1153886: learning rate 0.0001
[2019-03-23 13:31:33,134] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.8681475e-07 9.9999917e-01 6.2720215e-19 1.0291836e-15 1.7621293e-24], sum to 1.0000
[2019-03-23 13:31:33,147] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9762
[2019-03-23 13:31:33,153] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 88.0, 1.0, 2.0, 0.3027770488037801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 328772.1702185383, 328772.1702185383, 110306.6089348219], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3816000.0000, 
sim time next is 3816600.0000, 
raw observation next is [17.0, 88.00000000000001, 1.0, 2.0, 0.3002865741871277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 326066.9676520651, 326066.9676520648, 109939.1674121107], 
processed observation next is [0.0, 0.17391304347826086, 0.4090909090909091, 0.8800000000000001, 1.0, 1.0, 0.12535821773390957, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12076554357483893, 0.12076554357483882, 0.2681443107612456], 
reward next is 0.7319, 
noisyNet noise sample is [array([-0.39186186], dtype=float32), -0.1819781]. 
=============================================
[2019-03-23 13:31:39,938] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8361851e-04 9.9981636e-01 5.9467753e-20 6.5731874e-15 1.4824801e-26], sum to 1.0000
[2019-03-23 13:31:39,947] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5342
[2019-03-23 13:31:39,951] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 82.16666666666667, 1.0, 2.0, 0.5212456028507321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593767.1744465517, 593767.1744465517, 145410.8617434678], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3707400.0000, 
sim time next is 3708000.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.5274011231970989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 600504.9613337169, 600504.9613337169, 146391.2918606537], 
processed observation next is [1.0, 0.9565217391304348, 0.7272727272727273, 0.83, 1.0, 1.0, 0.40925140399637355, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22240924493841366, 0.22240924493841366, 0.35705193136744806], 
reward next is 0.6429, 
noisyNet noise sample is [array([0.68985385], dtype=float32), 1.5771967]. 
=============================================
[2019-03-23 13:31:39,974] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[64.74189 ]
 [64.801605]
 [64.847694]
 [64.88848 ]
 [64.9198  ]], R is [[64.67713928]
 [64.67570496]
 [64.67646027]
 [64.67897797]
 [64.68305969]].
[2019-03-23 13:31:41,792] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72500, global step 1160135: loss -101.4754
[2019-03-23 13:31:41,794] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72500, global step 1160137: learning rate 0.0001
[2019-03-23 13:31:42,030] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72500, global step 1160265: loss -46.5533
[2019-03-23 13:31:42,032] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72500, global step 1160265: learning rate 0.0001
[2019-03-23 13:31:42,047] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72500, global step 1160274: loss 24.0882
[2019-03-23 13:31:42,050] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72500, global step 1160275: learning rate 0.0001
[2019-03-23 13:31:42,054] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72500, global step 1160277: loss -74.0883
[2019-03-23 13:31:42,056] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72500, global step 1160277: learning rate 0.0001
[2019-03-23 13:31:42,159] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72500, global step 1160330: loss -13.1622
[2019-03-23 13:31:42,161] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72500, global step 1160330: learning rate 0.0001
[2019-03-23 13:31:42,238] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72500, global step 1160367: loss -101.6262
[2019-03-23 13:31:42,239] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72500, global step 1160367: learning rate 0.0001
[2019-03-23 13:31:42,286] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72500, global step 1160394: loss -134.5634
[2019-03-23 13:31:42,289] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72500, global step 1160394: learning rate 0.0001
[2019-03-23 13:31:42,315] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72500, global step 1160408: loss -26.6141
[2019-03-23 13:31:42,317] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72500, global step 1160408: learning rate 0.0001
[2019-03-23 13:31:42,322] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72500, global step 1160411: loss -81.7017
[2019-03-23 13:31:42,327] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72500, global step 1160411: learning rate 0.0001
[2019-03-23 13:31:42,352] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72500, global step 1160428: loss -123.9943
[2019-03-23 13:31:42,353] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72500, global step 1160428: learning rate 0.0001
[2019-03-23 13:31:42,372] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72500, global step 1160436: loss -49.0131
[2019-03-23 13:31:42,374] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72500, global step 1160436: learning rate 0.0001
[2019-03-23 13:31:42,453] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72500, global step 1160476: loss -172.7104
[2019-03-23 13:31:42,455] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72500, global step 1160479: learning rate 0.0001
[2019-03-23 13:31:42,495] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72500, global step 1160500: loss -153.2853
[2019-03-23 13:31:42,496] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72500, global step 1160500: learning rate 0.0001
[2019-03-23 13:31:42,576] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72500, global step 1160536: loss -42.5448
[2019-03-23 13:31:42,577] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72500, global step 1160536: learning rate 0.0001
[2019-03-23 13:31:43,238] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72500, global step 1160874: loss -99.5906
[2019-03-23 13:31:43,244] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72500, global step 1160875: learning rate 0.0001
[2019-03-23 13:31:44,530] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.0126171e-10 1.0000000e+00 4.0700085e-29 6.3835127e-21 2.7946928e-36], sum to 1.0000
[2019-03-23 13:31:44,537] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6156
[2019-03-23 13:31:44,546] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 90.0, 1.0, 2.0, 0.3364556650475947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369740.0342850531, 369740.0342850531, 115243.3074458712], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3795600.0000, 
sim time next is 3796200.0000, 
raw observation next is [17.5, 91.0, 1.0, 2.0, 0.334727113946463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 367491.3285960814, 367491.3285960814, 114987.2903776571], 
processed observation next is [1.0, 0.9565217391304348, 0.4318181818181818, 0.91, 1.0, 1.0, 0.16840889243307872, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13610789948003016, 0.13610789948003016, 0.28045680579916366], 
reward next is 0.7195, 
noisyNet noise sample is [array([-0.83877474], dtype=float32), 0.1969177]. 
=============================================
[2019-03-23 13:31:45,003] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73000, global step 1161762: loss 0.0269
[2019-03-23 13:31:45,006] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73000, global step 1161762: learning rate 0.0001
[2019-03-23 13:31:46,111] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.3297062e-05 9.9993670e-01 1.3916068e-19 7.3242097e-16 4.1582006e-27], sum to 1.0000
[2019-03-23 13:31:46,121] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9031
[2019-03-23 13:31:46,126] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 88.0, 1.0, 2.0, 0.2965172265616656, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 321972.6566658337, 321972.6566658337, 109591.238919511], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3822000.0000, 
sim time next is 3822600.0000, 
raw observation next is [17.0, 88.0, 1.0, 2.0, 0.2961933979626872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 321620.9117323952, 321620.9117323955, 109562.6256351484], 
processed observation next is [0.0, 0.21739130434782608, 0.4090909090909091, 0.88, 1.0, 1.0, 0.12024174745335896, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1191188561971834, 0.11911885619718353, 0.2672259161832888], 
reward next is 0.7328, 
noisyNet noise sample is [array([0.34495154], dtype=float32), 0.55204433]. 
=============================================
[2019-03-23 13:31:52,237] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.1652781e-07 9.9999940e-01 2.7450300e-22 1.4811260e-15 6.3006585e-33], sum to 1.0000
[2019-03-23 13:31:52,244] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8679
[2019-03-23 13:31:52,250] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 51.5, 1.0, 2.0, 0.3309122441848896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 364898.7988099745, 364898.7988099745, 115308.0534541003], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3954600.0000, 
sim time next is 3955200.0000, 
raw observation next is [23.33333333333333, 52.0, 1.0, 2.0, 0.3296402082665599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 363115.3113986875, 363115.3113986875, 115067.9772517413], 
processed observation next is [0.0, 0.782608695652174, 0.6969696969696968, 0.52, 1.0, 1.0, 0.16205026033319983, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13448715236988426, 0.13448715236988426, 0.28065360305302756], 
reward next is 0.7193, 
noisyNet noise sample is [array([-1.447458], dtype=float32), 0.43141252]. 
=============================================
[2019-03-23 13:31:57,552] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73000, global step 1168105: loss 0.1494
[2019-03-23 13:31:57,553] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73000, global step 1168106: learning rate 0.0001
[2019-03-23 13:31:57,780] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73000, global step 1168219: loss 0.0002
[2019-03-23 13:31:57,781] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73000, global step 1168219: learning rate 0.0001
[2019-03-23 13:31:57,798] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73000, global step 1168227: loss 0.0000
[2019-03-23 13:31:57,799] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73000, global step 1168227: learning rate 0.0001
[2019-03-23 13:31:57,919] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73000, global step 1168287: loss 0.0153
[2019-03-23 13:31:57,923] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73000, global step 1168288: learning rate 0.0001
[2019-03-23 13:31:57,983] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73000, global step 1168320: loss 0.0149
[2019-03-23 13:31:57,985] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73000, global step 1168322: learning rate 0.0001
[2019-03-23 13:31:58,007] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73000, global step 1168332: loss 0.0004
[2019-03-23 13:31:58,010] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73000, global step 1168332: learning rate 0.0001
[2019-03-23 13:31:58,019] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73000, global step 1168337: loss 0.0001
[2019-03-23 13:31:58,021] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73000, global step 1168338: learning rate 0.0001
[2019-03-23 13:31:58,056] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73000, global step 1168354: loss 0.0016
[2019-03-23 13:31:58,057] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73000, global step 1168354: learning rate 0.0001
[2019-03-23 13:31:58,202] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73000, global step 1168428: loss 0.0405
[2019-03-23 13:31:58,206] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73000, global step 1168429: learning rate 0.0001
[2019-03-23 13:31:58,270] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73000, global step 1168461: loss 0.0275
[2019-03-23 13:31:58,275] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73000, global step 1168462: learning rate 0.0001
[2019-03-23 13:31:58,296] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73000, global step 1168476: loss 0.0491
[2019-03-23 13:31:58,300] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73000, global step 1168476: learning rate 0.0001
[2019-03-23 13:31:58,363] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73000, global step 1168503: loss 0.0027
[2019-03-23 13:31:58,365] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73000, global step 1168504: learning rate 0.0001
[2019-03-23 13:31:58,376] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73000, global step 1168514: loss 0.0261
[2019-03-23 13:31:58,378] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73000, global step 1168514: learning rate 0.0001
[2019-03-23 13:31:58,399] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73000, global step 1168522: loss 0.0109
[2019-03-23 13:31:58,401] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73000, global step 1168523: learning rate 0.0001
[2019-03-23 13:31:59,122] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73000, global step 1168894: loss 0.0270
[2019-03-23 13:31:59,124] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73000, global step 1168895: learning rate 0.0001
[2019-03-23 13:31:59,458] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9300150e-09 1.0000000e+00 6.4207110e-20 4.6727157e-15 4.7234181e-29], sum to 1.0000
[2019-03-23 13:31:59,466] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9551
[2019-03-23 13:31:59,471] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.96666666666667, 100.0, 1.0, 2.0, 0.303579817062175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 329644.1561145856, 329644.1561145854, 111433.2129561958], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4075800.0000, 
sim time next is 4076400.0000, 
raw observation next is [15.93333333333333, 100.0, 1.0, 2.0, 0.3009609258678907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 326799.4602401032, 326799.4602401035, 111256.9060053026], 
processed observation next is [1.0, 0.17391304347826086, 0.36060606060606043, 1.0, 1.0, 1.0, 0.12620115733486334, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12103683712596415, 0.12103683712596425, 0.2713583073300064], 
reward next is 0.7286, 
noisyNet noise sample is [array([-0.8842917], dtype=float32), 0.0758813]. 
=============================================
[2019-03-23 13:32:01,002] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73500, global step 1169837: loss -14.7155
[2019-03-23 13:32:01,006] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73500, global step 1169837: learning rate 0.0001
[2019-03-23 13:32:07,868] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.0520415e-07 9.9999940e-01 1.3566521e-20 7.2768708e-18 7.0490684e-30], sum to 1.0000
[2019-03-23 13:32:07,875] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4934
[2019-03-23 13:32:07,880] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 73.0, 1.0, 2.0, 0.3660961150829387, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 409322.867486709, 409322.8674867087, 120280.4680762273], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4221600.0000, 
sim time next is 4222200.0000, 
raw observation next is [21.0, 73.0, 1.0, 2.0, 0.3653083579086901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 408439.0412104639, 408439.0412104641, 120214.0198250457], 
processed observation next is [1.0, 0.8695652173913043, 0.5909090909090909, 0.73, 1.0, 1.0, 0.2066354473858626, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15127371896683847, 0.15127371896683856, 0.29320492640255047], 
reward next is 0.7068, 
noisyNet noise sample is [array([-0.88645977], dtype=float32), 0.55817914]. 
=============================================
[2019-03-23 13:32:11,159] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 13:32:11,162] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:32:11,163] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:32:11,164] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:32:11,164] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:32:11,166] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:32:11,167] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:32:11,169] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:32:11,170] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:32:11,167] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:32:11,170] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:32:11,184] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run48
[2019-03-23 13:32:11,211] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run48
[2019-03-23 13:32:11,212] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run48
[2019-03-23 13:32:11,260] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run48
[2019-03-23 13:32:11,297] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run48
[2019-03-23 13:32:37,146] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02714703], dtype=float32), -0.43412817]
[2019-03-23 13:32:37,149] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [13.39255424666667, 95.42822482, 1.0, 2.0, 0.6349332522220393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 689608.3941614018, 689608.3941614014, 125335.8840496705]
[2019-03-23 13:32:37,151] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:32:37,155] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.7364187e-07 9.9999988e-01 2.0848572e-20 1.5159549e-16 1.1603577e-28], sampled 0.6303130561635133
[2019-03-23 13:33:02,926] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02714703], dtype=float32), -0.43412817]
[2019-03-23 13:33:02,927] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.66833912, 83.83430745000001, 1.0, 2.0, 0.4436000991359995, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 505977.6828079747, 505977.6828079747, 138233.3775434144]
[2019-03-23 13:33:02,930] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:33:02,933] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.3941927e-07 9.9999988e-01 1.0817954e-20 8.9102751e-17 4.5953101e-29], sampled 0.3232166950169586
[2019-03-23 13:33:10,091] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02714703], dtype=float32), -0.43412817]
[2019-03-23 13:33:10,092] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.23333333333333, 69.0, 1.0, 2.0, 0.6683656631624012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 756034.2664640395, 756034.2664640395, 171853.1209989204]
[2019-03-23 13:33:10,092] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:33:10,097] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.3633763e-07 9.9999976e-01 5.4019140e-20 3.2779834e-16 4.4322682e-28], sampled 0.8141762735144497
[2019-03-23 13:33:10,407] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02714703], dtype=float32), -0.43412817]
[2019-03-23 13:33:10,408] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.88055152333333, 63.68742790333334, 1.0, 2.0, 0.6494957842837107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 740300.9430059871, 740300.9430059867, 166123.6403009777]
[2019-03-23 13:33:10,411] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:33:10,415] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.9469213e-07 9.9999976e-01 2.9784674e-20 2.0226294e-16 1.9179801e-28], sampled 0.19956478608603956
[2019-03-23 13:33:12,402] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02714703], dtype=float32), -0.43412817]
[2019-03-23 13:33:12,403] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.4, 82.0, 1.0, 2.0, 0.5452660996537458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 619905.2686227205, 619905.2686227201, 153493.3757725642]
[2019-03-23 13:33:12,406] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:33:12,410] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.5481956e-07 9.9999988e-01 1.4853382e-20 1.1520069e-16 7.1785981e-29], sampled 0.1960885367924643
[2019-03-23 13:33:15,445] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02714703], dtype=float32), -0.43412817]
[2019-03-23 13:33:15,446] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.66666666666666, 53.00000000000001, 1.0, 2.0, 0.5797387606804305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 651746.4719381328, 651746.4719381328, 142398.7586743468]
[2019-03-23 13:33:15,447] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:33:15,451] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.1067827e-07 9.9999976e-01 3.7705826e-20 2.4497731e-16 2.6718159e-28], sampled 0.7464408704959721
[2019-03-23 13:33:20,324] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02714703], dtype=float32), -0.43412817]
[2019-03-23 13:33:20,325] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.8, 70.0, 1.0, 2.0, 0.2711166343402285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 294366.1333938649, 294366.1333938646, 103124.2792740364]
[2019-03-23 13:33:20,328] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:33:20,331] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0904016e-07 9.9999988e-01 5.1762547e-21 4.9077301e-17 1.6203213e-29], sampled 0.5068659964078647
[2019-03-23 13:33:20,712] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02714703], dtype=float32), -0.43412817]
[2019-03-23 13:33:20,715] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.17988843666667, 54.733503705, 1.0, 2.0, 0.3549217307487917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 398005.660276785, 398005.660276785, 124239.0601058508]
[2019-03-23 13:33:20,716] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:33:20,721] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.2512059e-07 9.9999988e-01 7.7993438e-21 6.8383160e-17 2.8930342e-29], sampled 0.6309115177559549
[2019-03-23 13:33:52,629] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 13:33:52,669] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 13:33:52,719] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 13:33:52,935] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 13:33:53,171] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 13:33:54,186] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1175000, evaluation results [1175000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 13:33:56,224] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73500, global step 1176074: loss -29.6586
[2019-03-23 13:33:56,225] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73500, global step 1176074: learning rate 0.0001
[2019-03-23 13:33:56,524] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73500, global step 1176236: loss -46.0347
[2019-03-23 13:33:56,528] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73500, global step 1176237: learning rate 0.0001
[2019-03-23 13:33:56,542] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73500, global step 1176245: loss -36.9170
[2019-03-23 13:33:56,546] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73500, global step 1176245: learning rate 0.0001
[2019-03-23 13:33:56,575] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73500, global step 1176260: loss -28.2533
[2019-03-23 13:33:56,576] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73500, global step 1176260: learning rate 0.0001
[2019-03-23 13:33:56,658] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73500, global step 1176306: loss -29.7533
[2019-03-23 13:33:56,659] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73500, global step 1176307: learning rate 0.0001
[2019-03-23 13:33:56,734] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73500, global step 1176346: loss -27.7442
[2019-03-23 13:33:56,735] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73500, global step 1176346: learning rate 0.0001
[2019-03-23 13:33:56,793] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73500, global step 1176371: loss -24.2770
[2019-03-23 13:33:56,796] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73500, global step 1176373: learning rate 0.0001
[2019-03-23 13:33:56,818] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73500, global step 1176385: loss -42.5673
[2019-03-23 13:33:56,821] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73500, global step 1176385: learning rate 0.0001
[2019-03-23 13:33:56,850] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73500, global step 1176404: loss -21.2847
[2019-03-23 13:33:56,854] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73500, global step 1176406: loss -31.2681
[2019-03-23 13:33:56,855] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73500, global step 1176405: learning rate 0.0001
[2019-03-23 13:33:56,858] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73500, global step 1176407: learning rate 0.0001
[2019-03-23 13:33:56,965] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73500, global step 1176458: loss 22.3661
[2019-03-23 13:33:56,968] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73500, global step 1176459: learning rate 0.0001
[2019-03-23 13:33:57,018] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73500, global step 1176492: loss 8.8458
[2019-03-23 13:33:57,019] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73500, global step 1176492: loss -6.0822
[2019-03-23 13:33:57,019] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73500, global step 1176492: learning rate 0.0001
[2019-03-23 13:33:57,023] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73500, global step 1176493: learning rate 0.0001
[2019-03-23 13:33:57,042] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73500, global step 1176501: loss 21.9626
[2019-03-23 13:33:57,044] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73500, global step 1176501: learning rate 0.0001
[2019-03-23 13:33:57,260] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8300817e-07 9.9999976e-01 2.4434228e-19 3.4500863e-15 4.5720785e-26], sum to 1.0000
[2019-03-23 13:33:57,267] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7807
[2019-03-23 13:33:57,282] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1176644.662569998 W.
[2019-03-23 13:33:57,286] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 58.0, 1.0, 2.0, 0.551001863779555, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9680246232872818, 6.918711843838082, 6.9112, 77.32844501580801, 1176644.662569998, 1174204.969916556, 265546.1817459221], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4359600.0000, 
sim time next is 4360200.0000, 
raw observation next is [27.0, 58.0, 1.0, 2.0, 0.582803450905451, 1.0, 1.0, 0.582803450905451, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32845892961147, 1326787.072643348, 1326787.072643349, 251775.7075466389], 
processed observation next is [1.0, 0.4782608695652174, 0.8636363636363636, 0.58, 1.0, 1.0, 0.4785043136318138, 1.0, 0.5, 0.4785043136318138, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084287832419078, 0.4914026194975363, 0.49140261949753666, 0.6140870915771681], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6363917], dtype=float32), 0.30225068]. 
=============================================
[2019-03-23 13:33:57,616] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73500, global step 1176804: loss -25.9178
[2019-03-23 13:33:57,617] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73500, global step 1176804: learning rate 0.0001
[2019-03-23 13:33:59,512] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74000, global step 1177809: loss 0.1620
[2019-03-23 13:33:59,514] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74000, global step 1177810: learning rate 0.0001
[2019-03-23 13:34:00,599] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5203068e-09 1.0000000e+00 9.6170916e-23 2.6510984e-18 2.5436837e-29], sum to 1.0000
[2019-03-23 13:34:00,604] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6887
[2019-03-23 13:34:00,608] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.4066224760334996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 460728.8088693629, 460728.8088693629, 126931.3438945497], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4428000.0000, 
sim time next is 4428600.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.4078062964738363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 462123.3719804597, 462123.3719804597, 127077.8129050841], 
processed observation next is [0.0, 0.2608695652173913, 0.5909090909090909, 0.83, 1.0, 1.0, 0.2597578705922954, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1711568044372073, 0.1711568044372073, 0.30994588513435145], 
reward next is 0.6901, 
noisyNet noise sample is [array([-2.303784], dtype=float32), 0.7078126]. 
=============================================
[2019-03-23 13:34:01,854] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.4242686e-08 1.0000000e+00 7.4487802e-20 3.2742491e-15 9.5055736e-27], sum to 1.0000
[2019-03-23 13:34:01,859] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2640
[2019-03-23 13:34:01,862] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 74.0, 1.0, 2.0, 0.5131656526916156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 584887.0182421989, 584887.0182421989, 144108.7675804619], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4456800.0000, 
sim time next is 4457400.0000, 
raw observation next is [25.16666666666667, 72.5, 1.0, 2.0, 0.5104945328805117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 581952.6501440438, 581952.6501440438, 143659.7178353012], 
processed observation next is [0.0, 0.6086956521739131, 0.7803030303030305, 0.725, 1.0, 1.0, 0.3881181661006396, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21553801857186808, 0.21553801857186808, 0.3503895556958566], 
reward next is 0.6496, 
noisyNet noise sample is [array([-0.29253644], dtype=float32), -0.8943564]. 
=============================================
[2019-03-23 13:34:08,509] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.0027136e-09 1.0000000e+00 1.3440050e-23 7.7965055e-17 3.7231244e-31], sum to 1.0000
[2019-03-23 13:34:08,518] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3067
[2019-03-23 13:34:08,522] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 75.0, 1.0, 2.0, 0.3021695800055246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 328112.3242610672, 328112.3242610672, 108482.2778852786], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4570200.0000, 
sim time next is 4570800.0000, 
raw observation next is [18.33333333333334, 75.66666666666666, 1.0, 2.0, 0.2998105721936438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 325549.9266271527, 325549.9266271524, 106653.3822497664], 
processed observation next is [0.0, 0.9130434782608695, 0.46969696969696995, 0.7566666666666666, 1.0, 1.0, 0.12476321524205476, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12057404689894545, 0.12057404689894534, 0.26013020060918635], 
reward next is 0.7399, 
noisyNet noise sample is [array([-1.1928674], dtype=float32), 1.5232918]. 
=============================================
[2019-03-23 13:34:10,505] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.0433414e-09 1.0000000e+00 2.0949254e-21 9.4380911e-17 2.7058490e-28], sum to 1.0000
[2019-03-23 13:34:10,510] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4724
[2019-03-23 13:34:10,517] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 46.0, 1.0, 2.0, 0.3945548556439733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 428473.5288490071, 428473.5288490074, 115146.0741114096], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4624800.0000, 
sim time next is 4625400.0000, 
raw observation next is [23.0, 45.0, 1.0, 2.0, 0.3828546905462714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415762.1038161949, 415762.1038161949, 111201.534304881], 
processed observation next is [1.0, 0.5217391304347826, 0.6818181818181818, 0.45, 1.0, 1.0, 0.22856836318283924, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1539859643763685, 0.1539859643763685, 0.2712232544021488], 
reward next is 0.7288, 
noisyNet noise sample is [array([-0.9969254], dtype=float32), -0.43499678]. 
=============================================
[2019-03-23 13:34:10,650] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.3271531e-08 1.0000000e+00 1.7067859e-20 6.7118388e-16 7.8114694e-27], sum to 1.0000
[2019-03-23 13:34:10,657] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9590
[2019-03-23 13:34:10,661] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 47.0, 1.0, 2.0, 0.7369535615681042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 811768.7900455818, 811768.7900455818, 154996.2182078901], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4636800.0000, 
sim time next is 4637400.0000, 
raw observation next is [23.83333333333333, 47.5, 1.0, 2.0, 0.7477705406904742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 823767.4823943279, 823767.4823943279, 156355.1618308878], 
processed observation next is [1.0, 0.6956521739130435, 0.7196969696969695, 0.475, 1.0, 1.0, 0.6847131758630928, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3050990675534548, 0.3050990675534548, 0.3813540532460678], 
reward next is 0.6186, 
noisyNet noise sample is [array([-1.4240937], dtype=float32), 1.474999]. 
=============================================
[2019-03-23 13:34:11,273] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.2720913e-07 9.9999976e-01 3.3714812e-20 2.0838992e-16 2.8511629e-27], sum to 1.0000
[2019-03-23 13:34:11,281] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8504
[2019-03-23 13:34:11,285] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 49.5, 1.0, 2.0, 0.5945319167907074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 651379.8308408065, 651379.8308408065, 137617.5136349936], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4639800.0000, 
sim time next is 4640400.0000, 
raw observation next is [23.0, 50.0, 1.0, 2.0, 0.6643276404652619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 727293.9938021059, 727293.9938021061, 144940.5289095514], 
processed observation next is [1.0, 0.7391304347826086, 0.6818181818181818, 0.5, 1.0, 1.0, 0.5804095505815774, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2693681458526318, 0.2693681458526319, 0.3535134851452473], 
reward next is 0.6465, 
noisyNet noise sample is [array([-0.8558306], dtype=float32), -0.6130809]. 
=============================================
[2019-03-23 13:34:11,403] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74000, global step 1184094: loss 0.0071
[2019-03-23 13:34:11,406] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74000, global step 1184096: learning rate 0.0001
[2019-03-23 13:34:11,529] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74000, global step 1184159: loss 0.0134
[2019-03-23 13:34:11,531] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74000, global step 1184160: learning rate 0.0001
[2019-03-23 13:34:11,546] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74000, global step 1184170: loss 0.0114
[2019-03-23 13:34:11,547] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74000, global step 1184170: learning rate 0.0001
[2019-03-23 13:34:11,611] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74000, global step 1184207: loss 0.0157
[2019-03-23 13:34:11,613] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74000, global step 1184207: learning rate 0.0001
[2019-03-23 13:34:11,794] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74000, global step 1184304: loss 0.0013
[2019-03-23 13:34:11,797] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74000, global step 1184305: learning rate 0.0001
[2019-03-23 13:34:11,914] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74000, global step 1184369: loss 0.0131
[2019-03-23 13:34:11,920] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74000, global step 1184369: learning rate 0.0001
[2019-03-23 13:34:11,944] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74000, global step 1184384: loss 0.0086
[2019-03-23 13:34:11,945] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74000, global step 1184384: learning rate 0.0001
[2019-03-23 13:34:11,955] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74000, global step 1184388: loss 0.0138
[2019-03-23 13:34:11,956] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74000, global step 1184389: learning rate 0.0001
[2019-03-23 13:34:12,009] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74000, global step 1184414: loss 0.0062
[2019-03-23 13:34:12,011] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74000, global step 1184414: learning rate 0.0001
[2019-03-23 13:34:12,094] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74000, global step 1184465: loss 0.0074
[2019-03-23 13:34:12,098] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74000, global step 1184465: learning rate 0.0001
[2019-03-23 13:34:12,126] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74000, global step 1184478: loss 0.0327
[2019-03-23 13:34:12,132] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74000, global step 1184479: learning rate 0.0001
[2019-03-23 13:34:12,145] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74000, global step 1184485: loss 0.0599
[2019-03-23 13:34:12,147] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74000, global step 1184485: learning rate 0.0001
[2019-03-23 13:34:12,235] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74000, global step 1184540: loss 0.0769
[2019-03-23 13:34:12,242] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74000, global step 1184542: learning rate 0.0001
[2019-03-23 13:34:12,278] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74000, global step 1184559: loss 0.0157
[2019-03-23 13:34:12,279] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74000, global step 1184559: learning rate 0.0001
[2019-03-23 13:34:12,774] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74000, global step 1184821: loss 0.0316
[2019-03-23 13:34:12,775] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74000, global step 1184821: learning rate 0.0001
[2019-03-23 13:34:13,159] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.5705844e-11 1.0000000e+00 3.4218274e-23 4.9690416e-20 1.1282302e-32], sum to 1.0000
[2019-03-23 13:34:13,167] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7540
[2019-03-23 13:34:13,169] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.16666666666667, 82.0, 1.0, 2.0, 0.2225859754265449, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 241674.6047906237, 241674.6047906234, 77198.79126156302], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4675800.0000, 
sim time next is 4676400.0000, 
raw observation next is [15.0, 82.0, 1.0, 2.0, 0.2186767177904648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 237429.0592848869, 237429.0592848866, 76194.12820743215], 
processed observation next is [1.0, 0.13043478260869565, 0.3181818181818182, 0.82, 1.0, 1.0, 0.023345897238080983, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08793668862403219, 0.08793668862403207, 0.18583933709129793], 
reward next is 0.8142, 
noisyNet noise sample is [array([0.70259184], dtype=float32), 0.8647577]. 
=============================================
[2019-03-23 13:34:13,741] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5105003e-08 1.0000000e+00 1.1036360e-22 4.5257322e-18 7.4217444e-29], sum to 1.0000
[2019-03-23 13:34:13,747] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1621
[2019-03-23 13:34:13,753] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.16666666666667, 82.0, 1.0, 2.0, 0.2225859754265449, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 241674.6047906237, 241674.6047906234, 77198.79126156302], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4675800.0000, 
sim time next is 4676400.0000, 
raw observation next is [15.0, 82.0, 1.0, 2.0, 0.2186767177904648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 237429.0592848869, 237429.0592848866, 76194.12820743215], 
processed observation next is [1.0, 0.13043478260869565, 0.3181818181818182, 0.82, 1.0, 1.0, 0.023345897238080983, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08793668862403219, 0.08793668862403207, 0.18583933709129793], 
reward next is 0.8142, 
noisyNet noise sample is [array([-0.81405526], dtype=float32), -0.7460165]. 
=============================================
[2019-03-23 13:34:13,836] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.5626141e-09 1.0000000e+00 1.6876406e-21 2.6139141e-17 9.2789191e-30], sum to 1.0000
[2019-03-23 13:34:13,843] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9101
[2019-03-23 13:34:13,849] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 61.33333333333333, 1.0, 2.0, 0.5300316826756711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 575683.9979979505, 575683.9979979503, 129618.3491055833], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4701000.0000, 
sim time next is 4701600.0000, 
raw observation next is [21.0, 60.0, 1.0, 2.0, 0.5201519362201849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 565164.3220961037, 565164.3220961037, 128770.2886701927], 
processed observation next is [1.0, 0.43478260869565216, 0.5909090909090909, 0.6, 1.0, 1.0, 0.40018992027523104, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20932011929485322, 0.20932011929485322, 0.31407387480534804], 
reward next is 0.6859, 
noisyNet noise sample is [array([-0.7292227], dtype=float32), -2.3979337]. 
=============================================
[2019-03-23 13:34:14,777] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74500, global step 1185958: loss 0.6668
[2019-03-23 13:34:14,778] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74500, global step 1185958: learning rate 0.0001
[2019-03-23 13:34:23,636] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.4986601e-09 1.0000000e+00 5.4462774e-20 1.3677656e-16 1.2205166e-26], sum to 1.0000
[2019-03-23 13:34:23,646] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2522
[2019-03-23 13:34:23,651] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 96.0, 1.0, 2.0, 0.7351547566057287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 835538.2243005793, 835538.2243005793, 166750.2695299561], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4875600.0000, 
sim time next is 4876200.0000, 
raw observation next is [20.0, 94.0, 1.0, 2.0, 0.7543024719924672, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 857811.8297521704, 857811.8297521704, 169884.1683639233], 
processed observation next is [1.0, 0.43478260869565216, 0.5454545454545454, 0.94, 1.0, 1.0, 0.692878089990584, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.31770808509339643, 0.31770808509339643, 0.4143516301559105], 
reward next is 0.5856, 
noisyNet noise sample is [array([-0.59504026], dtype=float32), -0.9852687]. 
=============================================
[2019-03-23 13:34:24,639] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.0810137e-09 1.0000000e+00 4.3548385e-21 1.3632480e-18 1.1478421e-27], sum to 1.0000
[2019-03-23 13:34:24,645] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8087
[2019-03-23 13:34:24,654] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 76.33333333333334, 1.0, 2.0, 0.8282519989132043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 942502.5012604315, 942502.5012604318, 181405.3786250471], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4898400.0000, 
sim time next is 4899000.0000, 
raw observation next is [22.16666666666667, 77.16666666666666, 1.0, 2.0, 0.8358557384090535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 950973.6548023261, 950973.6548023263, 182417.5353428069], 
processed observation next is [1.0, 0.6956521739130435, 0.6439393939393941, 0.7716666666666666, 1.0, 1.0, 0.7948196730113168, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3522124647416023, 0.35221246474160234, 0.4449208179092851], 
reward next is 0.5551, 
noisyNet noise sample is [array([-0.92060465], dtype=float32), -0.8051823]. 
=============================================
[2019-03-23 13:34:24,667] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[60.840786]
 [60.90139 ]
 [60.991207]
 [61.048355]
 [61.08005 ]], R is [[60.73842239]
 [60.68858719]
 [60.64772415]
 [60.59990311]
 [60.52978897]].
[2019-03-23 13:34:27,122] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74500, global step 1192134: loss 0.3545
[2019-03-23 13:34:27,125] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74500, global step 1192135: learning rate 0.0001
[2019-03-23 13:34:27,127] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74500, global step 1192138: loss 0.3250
[2019-03-23 13:34:27,131] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74500, global step 1192138: learning rate 0.0001
[2019-03-23 13:34:27,334] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74500, global step 1192241: loss 0.2397
[2019-03-23 13:34:27,337] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74500, global step 1192241: learning rate 0.0001
[2019-03-23 13:34:27,378] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74500, global step 1192260: loss 0.3273
[2019-03-23 13:34:27,380] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74500, global step 1192260: learning rate 0.0001
[2019-03-23 13:34:27,504] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74500, global step 1192323: loss 0.4091
[2019-03-23 13:34:27,506] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74500, global step 1192323: learning rate 0.0001
[2019-03-23 13:34:27,606] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74500, global step 1192378: loss 0.4968
[2019-03-23 13:34:27,609] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74500, global step 1192378: learning rate 0.0001
[2019-03-23 13:34:27,643] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74500, global step 1192397: loss 0.4273
[2019-03-23 13:34:27,645] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74500, global step 1192397: learning rate 0.0001
[2019-03-23 13:34:27,672] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74500, global step 1192408: loss 0.2681
[2019-03-23 13:34:27,673] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74500, global step 1192408: learning rate 0.0001
[2019-03-23 13:34:27,729] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74500, global step 1192437: loss 0.2564
[2019-03-23 13:34:27,729] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74500, global step 1192437: learning rate 0.0001
[2019-03-23 13:34:27,737] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74500, global step 1192441: loss 0.3011
[2019-03-23 13:34:27,739] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74500, global step 1192441: learning rate 0.0001
[2019-03-23 13:34:27,793] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74500, global step 1192470: loss 0.2384
[2019-03-23 13:34:27,796] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74500, global step 1192471: learning rate 0.0001
[2019-03-23 13:34:27,837] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74500, global step 1192490: loss 0.2112
[2019-03-23 13:34:27,840] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74500, global step 1192490: learning rate 0.0001
[2019-03-23 13:34:27,891] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74500, global step 1192514: loss 0.1774
[2019-03-23 13:34:27,894] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74500, global step 1192516: learning rate 0.0001
[2019-03-23 13:34:28,015] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74500, global step 1192578: loss 0.1343
[2019-03-23 13:34:28,020] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74500, global step 1192578: learning rate 0.0001
[2019-03-23 13:34:28,346] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74500, global step 1192744: loss 0.2536
[2019-03-23 13:34:28,350] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74500, global step 1192745: learning rate 0.0001
[2019-03-23 13:34:30,566] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75000, global step 1193858: loss 1.0102
[2019-03-23 13:34:30,570] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75000, global step 1193858: learning rate 0.0001
[2019-03-23 13:34:33,940] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.0051723e-11 1.0000000e+00 4.2133951e-26 6.9323842e-21 9.9362269e-32], sum to 1.0000
[2019-03-23 13:34:33,946] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0052
[2019-03-23 13:34:33,955] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 51.5, 1.0, 2.0, 0.4161175248792196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 473304.5104742421, 473304.5104742421, 129228.3884650239], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5071800.0000, 
sim time next is 5072400.0000, 
raw observation next is [27.0, 51.0, 1.0, 2.0, 0.4177714993195757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 475310.8212366672, 475310.8212366674, 129507.9764528291], 
processed observation next is [0.0, 0.7391304347826086, 0.8636363636363636, 0.51, 1.0, 1.0, 0.2722143741494696, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17604104490246933, 0.1760410449024694, 0.3158731132995832], 
reward next is 0.6841, 
noisyNet noise sample is [array([0.22774503], dtype=float32), -1.8249446]. 
=============================================
[2019-03-23 13:34:36,530] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.7213456e-09 1.0000000e+00 4.9107523e-22 1.2229264e-18 6.1032171e-28], sum to 1.0000
[2019-03-23 13:34:36,535] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6513
[2019-03-23 13:34:36,538] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 83.0, 1.0, 2.0, 0.4217101730958001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 480058.424160891, 480058.424160891, 130162.7684465008], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5122200.0000, 
sim time next is 5122800.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4274831785391158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 486950.7841951788, 486950.7841951791, 131097.4701473657], 
processed observation next is [0.0, 0.30434782608695654, 0.6363636363636364, 0.83, 1.0, 1.0, 0.28435397317389477, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1803521422945107, 0.1803521422945108, 0.3197499271886968], 
reward next is 0.6803, 
noisyNet noise sample is [array([-0.31313396], dtype=float32), 0.5130941]. 
=============================================
[2019-03-23 13:34:36,555] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.3556661e-09 1.0000000e+00 3.1129734e-22 2.4207408e-18 1.1110423e-27], sum to 1.0000
[2019-03-23 13:34:36,565] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9730
[2019-03-23 13:34:36,569] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 81.33333333333334, 1.0, 2.0, 0.4405094203863841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 502031.8750374049, 502031.8750374049, 132728.6578790347], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5127600.0000, 
sim time next is 5128200.0000, 
raw observation next is [22.5, 80.5, 1.0, 2.0, 0.4418730382646242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 503662.6630114675, 503662.6630114675, 132979.4906987095], 
processed observation next is [0.0, 0.34782608695652173, 0.6590909090909091, 0.805, 1.0, 1.0, 0.30234129783078023, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18654172704128424, 0.18654172704128424, 0.32434022121636463], 
reward next is 0.6757, 
noisyNet noise sample is [array([0.26767412], dtype=float32), 0.11305011]. 
=============================================
[2019-03-23 13:34:39,994] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.6631287e-10 1.0000000e+00 2.9562334e-22 6.3696299e-19 7.6087672e-29], sum to 1.0000
[2019-03-23 13:34:40,002] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2791
[2019-03-23 13:34:40,007] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 84.66666666666667, 1.0, 2.0, 0.5113176646236545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 582506.7669803014, 582506.7669803011, 140050.2541670307], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5192400.0000, 
sim time next is 5193000.0000, 
raw observation next is [21.5, 85.5, 1.0, 2.0, 0.4549093991982819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 518049.1965510637, 518049.196551064, 133730.0767880293], 
processed observation next is [1.0, 0.08695652173913043, 0.6136363636363636, 0.855, 1.0, 1.0, 0.3186367489978523, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19187007279669024, 0.19187007279669036, 0.32617091899519346], 
reward next is 0.6738, 
noisyNet noise sample is [array([0.0358602], dtype=float32), 1.2074842]. 
=============================================
[2019-03-23 13:34:40,033] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[61.165977]
 [61.40155 ]
 [62.034466]
 [62.189297]
 [62.406387]], R is [[61.34188461]
 [61.38687897]
 [61.39532471]
 [61.45890808]
 [61.5217514 ]].
[2019-03-23 13:34:40,446] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.3094435e-07 9.9999976e-01 3.6557454e-20 2.1931734e-17 3.5135936e-26], sum to 1.0000
[2019-03-23 13:34:40,450] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2298
[2019-03-23 13:34:40,459] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4386581447584045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499775.048020429, 499775.048020429, 132342.3261533377], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5199600.0000, 
sim time next is 5200200.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4329355927031092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 493245.955639325, 493245.9556393247, 131749.8619988137], 
processed observation next is [1.0, 0.17391304347826086, 0.6363636363636364, 0.83, 1.0, 1.0, 0.2911694908788865, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18268368727382409, 0.18268368727382395, 0.32134112682637483], 
reward next is 0.6787, 
noisyNet noise sample is [array([-0.00138217], dtype=float32), 1.0674725]. 
=============================================
[2019-03-23 13:34:41,485] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6883914e-09 1.0000000e+00 1.1819804e-21 3.3651011e-17 6.7553657e-27], sum to 1.0000
[2019-03-23 13:34:41,494] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1711
[2019-03-23 13:34:41,502] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 82.16666666666667, 1.0, 2.0, 0.4523018113033654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516041.2081376446, 516041.2081376446, 135121.4700703672], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5212200.0000, 
sim time next is 5212800.0000, 
raw observation next is [23.0, 83.0, 1.0, 2.0, 0.4827279381595127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 550836.2374234125, 550836.2374234129, 139047.0717958689], 
processed observation next is [1.0, 0.34782608695652173, 0.6818181818181818, 0.83, 1.0, 1.0, 0.35340992269939087, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20401342126793057, 0.20401342126793068, 0.33913919950211924], 
reward next is 0.6609, 
noisyNet noise sample is [array([-0.796423], dtype=float32), 0.03669343]. 
=============================================
[2019-03-23 13:34:42,745] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 13:34:42,747] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:34:42,748] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:34:42,750] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:34:42,752] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:34:42,754] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:34:42,756] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:34:42,756] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:34:42,757] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:34:42,755] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:34:42,760] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:34:42,770] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run49
[2019-03-23 13:34:42,795] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run49
[2019-03-23 13:34:42,821] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run49
[2019-03-23 13:34:42,821] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run49
[2019-03-23 13:34:42,876] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run49
[2019-03-23 13:34:54,030] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02714703], dtype=float32), -0.4416966]
[2019-03-23 13:34:54,031] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.56666666666667, 52.33333333333334, 1.0, 2.0, 0.2790885631538746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 303023.8737899679, 303023.8737899683, 94322.94108249029]
[2019-03-23 13:34:54,033] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:34:54,036] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0893057e-08 1.0000000e+00 1.7728143e-20 3.3100876e-17 4.6726182e-26], sampled 0.2923524906679359
[2019-03-23 13:35:22,429] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02714703], dtype=float32), -0.4416966]
[2019-03-23 13:35:22,430] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.83333333333334, 51.0, 1.0, 2.0, 0.4932505929958531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 562556.900503912, 562556.900503912, 143438.5374169839]
[2019-03-23 13:35:22,433] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:35:22,436] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.3498548e-08 1.0000000e+00 3.0226265e-20 5.1799400e-17 9.2231799e-26], sampled 0.7014686015357674
[2019-03-23 13:35:54,712] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02714703], dtype=float32), -0.4416966]
[2019-03-23 13:35:54,715] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.45, 52.33333333333333, 1.0, 2.0, 0.7239098725751483, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 823577.6169350063, 823577.6169350063, 170293.6258435167]
[2019-03-23 13:35:54,716] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:35:54,721] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.0571486e-08 1.0000000e+00 8.6569686e-20 1.2528123e-16 3.5275769e-25], sampled 0.7710451339415458
[2019-03-23 13:36:15,937] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02714703], dtype=float32), -0.4416966]
[2019-03-23 13:36:15,938] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.43333333333333, 54.66666666666666, 1.0, 2.0, 0.4594539548843291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 498939.1383902502, 498939.1383902502, 125623.3759499045]
[2019-03-23 13:36:15,939] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:36:15,940] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.4610702e-08 1.0000000e+00 3.6839830e-20 6.1156732e-17 1.1870478e-25], sampled 0.2961431045070557
[2019-03-23 13:36:23,810] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 13:36:23,843] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 13:36:23,848] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 13:36:23,914] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 13:36:24,073] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 13:36:25,086] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1200000, evaluation results [1200000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 13:36:25,298] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75000, global step 1200110: loss 0.0214
[2019-03-23 13:36:25,300] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75000, global step 1200110: learning rate 0.0001
[2019-03-23 13:36:25,318] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75000, global step 1200122: loss 0.0216
[2019-03-23 13:36:25,330] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75000, global step 1200122: learning rate 0.0001
[2019-03-23 13:36:25,363] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75000, global step 1200144: loss 0.0174
[2019-03-23 13:36:25,364] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75000, global step 1200144: learning rate 0.0001
[2019-03-23 13:36:25,669] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75000, global step 1200304: loss 0.1142
[2019-03-23 13:36:25,670] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75000, global step 1200305: learning rate 0.0001
[2019-03-23 13:36:25,693] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75000, global step 1200313: loss 0.1593
[2019-03-23 13:36:25,695] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75000, global step 1200314: learning rate 0.0001
[2019-03-23 13:36:25,724] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75000, global step 1200331: loss 0.0971
[2019-03-23 13:36:25,726] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75000, global step 1200332: learning rate 0.0001
[2019-03-23 13:36:25,792] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75000, global step 1200367: loss 0.2045
[2019-03-23 13:36:25,794] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75000, global step 1200367: learning rate 0.0001
[2019-03-23 13:36:25,811] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75000, global step 1200376: loss 0.0711
[2019-03-23 13:36:25,812] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75000, global step 1200376: learning rate 0.0001
[2019-03-23 13:36:25,849] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75000, global step 1200392: loss 0.0165
[2019-03-23 13:36:25,852] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75000, global step 1200394: learning rate 0.0001
[2019-03-23 13:36:25,920] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75000, global step 1200427: loss 0.0777
[2019-03-23 13:36:25,921] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75000, global step 1200428: learning rate 0.0001
[2019-03-23 13:36:25,933] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75000, global step 1200435: loss 0.0522
[2019-03-23 13:36:25,935] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75000, global step 1200435: learning rate 0.0001
[2019-03-23 13:36:26,020] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75000, global step 1200482: loss 0.0157
[2019-03-23 13:36:26,023] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75000, global step 1200482: learning rate 0.0001
[2019-03-23 13:36:26,148] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75000, global step 1200549: loss 0.0074
[2019-03-23 13:36:26,150] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75000, global step 1200549: learning rate 0.0001
[2019-03-23 13:36:26,252] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75000, global step 1200608: loss 0.0115
[2019-03-23 13:36:26,254] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75000, global step 1200608: learning rate 0.0001
[2019-03-23 13:36:26,469] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75000, global step 1200720: loss 0.2224
[2019-03-23 13:36:26,472] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75000, global step 1200720: learning rate 0.0001
[2019-03-23 13:36:29,104] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75500, global step 1202137: loss 0.1183
[2019-03-23 13:36:29,107] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75500, global step 1202138: learning rate 0.0001
[2019-03-23 13:36:33,740] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.3651235e-09 1.0000000e+00 4.5071847e-22 3.0084001e-18 5.1142291e-30], sum to 1.0000
[2019-03-23 13:36:33,750] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3116
[2019-03-23 13:36:33,754] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.1, 96.0, 1.0, 2.0, 0.301172453081669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 327029.2250260085, 327029.2250260088, 109585.0841047266], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5648400.0000, 
sim time next is 5649000.0000, 
raw observation next is [16.1, 95.5, 1.0, 2.0, 0.2982001825135869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 323800.6995189617, 323800.6995189614, 108011.2288264677], 
processed observation next is [0.0, 0.391304347826087, 0.3681818181818182, 0.955, 1.0, 1.0, 0.12275022814198358, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11992618500702286, 0.11992618500702275, 0.26344202152797], 
reward next is 0.7366, 
noisyNet noise sample is [array([0.7580581], dtype=float32), 1.1414053]. 
=============================================
[2019-03-23 13:36:33,770] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[63.455864]
 [63.46199 ]
 [63.454147]
 [63.435642]
 [63.42436 ]], R is [[63.54676437]
 [63.64401627]
 [63.73556137]
 [63.82551956]
 [63.91378021]].
[2019-03-23 13:36:35,293] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.4094834e-10 1.0000000e+00 8.4096706e-24 2.0528949e-20 2.7541246e-30], sum to 1.0000
[2019-03-23 13:36:35,297] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8720
[2019-03-23 13:36:35,305] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 95.0, 1.0, 2.0, 0.3875191256664936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 436368.2788051249, 436368.2788051246, 123566.239880875], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5441400.0000, 
sim time next is 5442000.0000, 
raw observation next is [18.8, 94.33333333333334, 1.0, 2.0, 0.3846915320118071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 432832.0780843063, 432832.0780843063, 123134.5011362064], 
processed observation next is [1.0, 1.0, 0.49090909090909096, 0.9433333333333335, 1.0, 1.0, 0.23086441501475888, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16030817706826161, 0.16030817706826161, 0.30032805155172293], 
reward next is 0.6997, 
noisyNet noise sample is [array([-1.7920837], dtype=float32), -0.7482304]. 
=============================================
[2019-03-23 13:36:35,333] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[63.00834 ]
 [62.958557]
 [62.926723]
 [62.90251 ]
 [62.889763]], R is [[63.12958908]
 [63.19691467]
 [63.26264572]
 [63.32699203]
 [63.39046478]].
[2019-03-23 13:36:37,706] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6398648e-07 9.9999988e-01 3.1207334e-17 2.9987910e-15 6.9545460e-23], sum to 1.0000
[2019-03-23 13:36:37,714] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5371
[2019-03-23 13:36:37,718] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1469951.64769197 W.
[2019-03-23 13:36:37,725] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.6, 71.5, 1.0, 2.0, 0.6535607082001207, 1.0, 2.0, 0.6535607082001207, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1469951.64769197, 1469951.647691971, 277531.6371460145], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5502600.0000, 
sim time next is 5503200.0000, 
raw observation next is [26.6, 70.66666666666667, 1.0, 2.0, 0.4141694047178194, 1.0, 2.0, 0.4141694047178194, 1.0, 1.0, 0.8380218555135133, 6.911199999999999, 6.9112, 77.3421103, 1397199.518872424, 1397199.518872424, 314257.9248329118], 
processed observation next is [1.0, 0.6956521739130435, 0.8454545454545456, 0.7066666666666667, 1.0, 1.0, 0.2677117558972742, 1.0, 1.0, 0.2677117558972742, 1.0, 0.5, 0.7686026507335904, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.517481303286083, 0.517481303286083, 0.7664827434949069], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.14255771], dtype=float32), 0.7642467]. 
=============================================
[2019-03-23 13:36:38,661] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.1095453e-07 9.9999917e-01 6.8319883e-13 5.3893365e-12 3.3096178e-17], sum to 1.0000
[2019-03-23 13:36:38,669] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3550
[2019-03-23 13:36:38,677] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.15, 63.0, 1.0, 2.0, 0.502606201705477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 572228.8106244564, 572228.8106244564, 143410.6247775325], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5506200.0000, 
sim time next is 5506800.0000, 
raw observation next is [27.33333333333334, 61.0, 1.0, 2.0, 0.5013652276671129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 571215.1654239085, 571215.1654239087, 142924.1024028481], 
processed observation next is [1.0, 0.7391304347826086, 0.878787878787879, 0.61, 1.0, 1.0, 0.3767065345838911, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21156117237922537, 0.21156117237922545, 0.3485953717142637], 
reward next is 0.6514, 
noisyNet noise sample is [array([-0.79684955], dtype=float32), -1.5005515]. 
=============================================
[2019-03-23 13:36:39,641] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.2661073e-13 1.0000000e+00 2.4776819e-27 1.8167476e-26 2.3375509e-34], sum to 1.0000
[2019-03-23 13:36:39,651] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5976
[2019-03-23 13:36:39,653] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 78.5, 1.0, 2.0, 0.4547942372309273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518453.9242039738, 518453.9242039738, 134414.4901365256], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5525400.0000, 
sim time next is 5526000.0000, 
raw observation next is [22.7, 79.0, 1.0, 2.0, 0.4558791881559908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 519652.1754336376, 519652.1754336376, 134469.0918500514], 
processed observation next is [1.0, 1.0, 0.6681818181818181, 0.79, 1.0, 1.0, 0.3198489851949885, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19246376867912504, 0.19246376867912504, 0.3279733947562229], 
reward next is 0.6720, 
noisyNet noise sample is [array([0.15001757], dtype=float32), 0.93674046]. 
=============================================
[2019-03-23 13:36:39,667] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[70.41752 ]
 [70.397285]
 [70.36647 ]
 [70.3175  ]
 [70.264786]], R is [[70.42665863]
 [70.39454651]
 [70.36274719]
 [70.33089447]
 [70.29877472]].
[2019-03-23 13:36:40,288] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75500, global step 1208049: loss 0.0380
[2019-03-23 13:36:40,290] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75500, global step 1208049: learning rate 0.0001
[2019-03-23 13:36:40,305] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75500, global step 1208055: loss 0.0392
[2019-03-23 13:36:40,308] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75500, global step 1208055: learning rate 0.0001
[2019-03-23 13:36:40,343] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75500, global step 1208079: loss 0.0410
[2019-03-23 13:36:40,345] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75500, global step 1208080: learning rate 0.0001
[2019-03-23 13:36:40,731] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75500, global step 1208285: loss 0.2196
[2019-03-23 13:36:40,732] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75500, global step 1208286: learning rate 0.0001
[2019-03-23 13:36:40,742] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75500, global step 1208293: loss 0.1666
[2019-03-23 13:36:40,744] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75500, global step 1208293: learning rate 0.0001
[2019-03-23 13:36:40,810] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75500, global step 1208327: loss 0.1387
[2019-03-23 13:36:40,813] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75500, global step 1208327: learning rate 0.0001
[2019-03-23 13:36:40,878] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75500, global step 1208361: loss 0.0608
[2019-03-23 13:36:40,880] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75500, global step 1208361: learning rate 0.0001
[2019-03-23 13:36:40,895] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75500, global step 1208370: loss 0.0575
[2019-03-23 13:36:40,897] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75500, global step 1208370: learning rate 0.0001
[2019-03-23 13:36:40,975] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75500, global step 1208411: loss 0.0956
[2019-03-23 13:36:40,977] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75500, global step 1208411: learning rate 0.0001
[2019-03-23 13:36:41,070] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75500, global step 1208459: loss 0.1147
[2019-03-23 13:36:41,072] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75500, global step 1208459: learning rate 0.0001
[2019-03-23 13:36:41,095] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75500, global step 1208472: loss 0.1251
[2019-03-23 13:36:41,097] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75500, global step 1208473: learning rate 0.0001
[2019-03-23 13:36:41,173] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75500, global step 1208513: loss 0.1240
[2019-03-23 13:36:41,175] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75500, global step 1208513: learning rate 0.0001
[2019-03-23 13:36:41,242] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75500, global step 1208551: loss 0.1037
[2019-03-23 13:36:41,244] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75500, global step 1208551: learning rate 0.0001
[2019-03-23 13:36:41,310] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75500, global step 1208589: loss 0.1111
[2019-03-23 13:36:41,311] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75500, global step 1208589: learning rate 0.0001
[2019-03-23 13:36:41,677] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75500, global step 1208782: loss 0.1353
[2019-03-23 13:36:41,681] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75500, global step 1208782: learning rate 0.0001
[2019-03-23 13:36:41,775] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.3276856e-11 1.0000000e+00 3.4334962e-20 3.9119891e-19 2.4421286e-26], sum to 1.0000
[2019-03-23 13:36:41,782] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9014
[2019-03-23 13:36:41,787] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1221251.276090321 W.
[2019-03-23 13:36:41,791] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.53333333333333, 61.33333333333333, 1.0, 2.0, 0.3608861798254521, 1.0, 2.0, 0.3608861798254521, 1.0, 2.0, 0.7298073009581586, 6.9112, 6.9112, 77.3421103, 1221251.276090321, 1221251.276090321, 287641.3599283253], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5575200.0000, 
sim time next is 5575800.0000, 
raw observation next is [27.61666666666666, 61.16666666666666, 1.0, 2.0, 0.3680339423550532, 1.0, 2.0, 0.3680339423550532, 1.0, 2.0, 0.7440774852040929, 6.9112, 6.9112, 77.3421103, 1244640.707291982, 1244640.707291982, 291013.5076566857], 
processed observation next is [1.0, 0.5217391304347826, 0.8916666666666664, 0.6116666666666666, 1.0, 1.0, 0.2100424279438165, 1.0, 1.0, 0.2100424279438165, 1.0, 1.0, 0.6343964074344185, 0.0, 0.0, 0.5085185399722538, 0.4609780397377711, 0.4609780397377711, 0.7097890430650872], 
reward next is 0.2902, 
noisyNet noise sample is [array([-0.82731944], dtype=float32), 1.2137346]. 
=============================================
[2019-03-23 13:36:41,821] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4716752e-09 1.0000000e+00 4.7515622e-19 1.7402319e-18 3.0115238e-25], sum to 1.0000
[2019-03-23 13:36:41,826] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1809
[2019-03-23 13:36:41,832] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1221244.086263377 W.
[2019-03-23 13:36:41,838] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.53333333333333, 61.33333333333333, 1.0, 2.0, 0.5926678067955983, 0.0, 1.0, 0.0, 1.0, 1.0, 0.977828078810232, 6.9112, 6.9112, 77.32846344354104, 1221244.086263377, 1221244.086263377, 277086.2606988019], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5575200.0000, 
sim time next is 5575800.0000, 
raw observation next is [27.61666666666666, 61.16666666666666, 1.0, 2.0, 0.5503906991381399, 1.0, 1.0, 0.5503906991381399, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1244634.594723333, 1244634.594723333, 246731.7806205671], 
processed observation next is [1.0, 0.5217391304347826, 0.8916666666666664, 0.6116666666666666, 1.0, 1.0, 0.4379883739226748, 1.0, 0.5, 0.4379883739226748, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4609757758234566, 0.4609757758234566, 0.601784830781871], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.837119], dtype=float32), 1.5279903]. 
=============================================
[2019-03-23 13:36:44,128] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76000, global step 1210075: loss 1.4253
[2019-03-23 13:36:44,131] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76000, global step 1210075: learning rate 0.0001
[2019-03-23 13:36:44,289] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.5273481e-10 1.0000000e+00 1.5848459e-23 1.6419064e-21 7.2316691e-30], sum to 1.0000
[2019-03-23 13:36:44,304] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0207
[2019-03-23 13:36:44,307] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 96.0, 1.0, 2.0, 0.4289267806846641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 487904.9345462692, 487904.9345462689, 130515.0450143794], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5620800.0000, 
sim time next is 5621400.0000, 
raw observation next is [20.0, 96.0, 1.0, 2.0, 0.4291071747729935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 488111.6327151711, 488111.6327151711, 130534.3275074358], 
processed observation next is [0.0, 0.043478260869565216, 0.5454545454545454, 0.96, 1.0, 1.0, 0.2863839684662418, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1807820861908041, 0.1807820861908041, 0.31837640855472144], 
reward next is 0.6816, 
noisyNet noise sample is [array([0.76769114], dtype=float32), 0.27309713]. 
=============================================
[2019-03-23 13:36:44,716] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.2601051e-13 1.0000000e+00 1.6141169e-27 2.1180980e-23 3.8942392e-35], sum to 1.0000
[2019-03-23 13:36:44,727] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8890
[2019-03-23 13:36:44,732] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.36666666666667, 64.5, 1.0, 2.0, 0.3306808328297766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 365153.4007974748, 365153.4007974746, 115488.6798416348], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5867400.0000, 
sim time next is 5868000.0000, 
raw observation next is [21.1, 66.0, 1.0, 2.0, 0.3303556551985043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 364612.2633612806, 364612.2633612808, 115393.4737466515], 
processed observation next is [1.0, 0.9565217391304348, 0.5954545454545456, 0.66, 1.0, 1.0, 0.16294456899813034, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13504157902269653, 0.1350415790226966, 0.28144749694305243], 
reward next is 0.7186, 
noisyNet noise sample is [array([0.542287], dtype=float32), -0.34503368]. 
=============================================
[2019-03-23 13:36:44,748] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[72.48054 ]
 [72.47584 ]
 [72.465004]
 [72.44766 ]
 [72.434814]], R is [[72.49547577]
 [72.48884583]
 [72.48217773]
 [72.47558594]
 [72.46899414]].
[2019-03-23 13:36:45,794] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0567107e-14 1.0000000e+00 7.2826309e-31 3.1741165e-30 0.0000000e+00], sum to 1.0000
[2019-03-23 13:36:45,800] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5532
[2019-03-23 13:36:45,806] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.6, 93.0, 1.0, 2.0, 0.2713747903675169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 294663.5200952712, 294663.5200952712, 93110.5000201491], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5655000.0000, 
sim time next is 5655600.0000, 
raw observation next is [15.5, 93.0, 1.0, 2.0, 0.2678561507841918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 290841.7769385207, 290841.776938521, 91646.33390618628], 
processed observation next is [0.0, 0.4782608695652174, 0.3409090909090909, 0.93, 1.0, 1.0, 0.08482018848023971, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10771917664389656, 0.10771917664389667, 0.22352764367362507], 
reward next is 0.7765, 
noisyNet noise sample is [array([0.02353174], dtype=float32), -0.7363618]. 
=============================================
[2019-03-23 13:36:48,921] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.9883516e-01 2.0116402e-01 5.2255501e-07 2.8414510e-07 5.7037829e-12], sum to 1.0000
[2019-03-23 13:36:48,922] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2752
[2019-03-23 13:36:48,926] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [11.83333333333333, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 159234.0501139188, 159234.050113919, 55355.11789271545], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5728800.0000, 
sim time next is 5729400.0000, 
raw observation next is [12.2, 80.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 163825.1198455309, 163825.1198455306, 56172.34923576458], 
processed observation next is [0.0, 0.30434782608695654, 0.1909090909090909, 0.8, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.06067597031315959, 0.06067597031315948, 0.13700572984332823], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2393433], dtype=float32), 0.05124658]. 
=============================================
[2019-03-23 13:36:49,131] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.8856806e-01 8.1143194e-01 3.8998824e-10 5.3122073e-10 1.2861175e-15], sum to 1.0000
[2019-03-23 13:36:49,142] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1683
[2019-03-23 13:36:49,146] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [9.4, 86.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 138852.1080439692, 138852.1080439689, 56397.322429287], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5716800.0000, 
sim time next is 5717400.0000, 
raw observation next is [9.3, 86.66666666666667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 137354.0834759081, 137354.0834759081, 51460.07725228005], 
processed observation next is [0.0, 0.17391304347826086, 0.059090909090909124, 0.8666666666666667, 0.0, 0.5, -0.25, 0.0, 1.0, -0.25, 1.0, 0.5, 0.0, 0.0, 0.0, 0.5084288129206541, 0.05087188276885485, 0.05087188276885485, 0.12551238354214644], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5831068], dtype=float32), 0.2841352]. 
=============================================
[2019-03-23 13:36:51,202] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9996114e-01 3.8873757e-05 1.8344597e-22 1.6683341e-21 2.3431303e-33], sum to 1.0000
[2019-03-23 13:36:51,208] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8396
[2019-03-23 13:36:51,212] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.13333333333333, 44.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4547568376891039, 6.9112, 6.9112, 77.32846344354104, 264502.2023312642, 264502.2023312642, 75766.48082735931], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5748000.0000, 
sim time next is 5748600.0000, 
raw observation next is [20.31666666666667, 44.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4589452019811261, 6.911199999999999, 6.9112, 77.32846344354104, 266938.9674412486, 266938.9674412489, 76769.69985446811], 
processed observation next is [0.0, 0.5217391304347826, 0.559848484848485, 0.4416666666666667, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2270645742587516, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09886628423749948, 0.09886628423749959, 0.1872431703767515], 
reward next is 0.8128, 
noisyNet noise sample is [array([1.0761335], dtype=float32), -1.8133737]. 
=============================================
[2019-03-23 13:36:55,238] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.7352718e-03 9.9326468e-01 5.5471092e-16 1.0890796e-14 5.5272341e-23], sum to 1.0000
[2019-03-23 13:36:55,246] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0899
[2019-03-23 13:36:55,254] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.98333333333333, 51.16666666666666, 1.0, 2.0, 0.5530233878750175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 604831.3214859593, 604831.3214859596, 133083.654160529], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5829000.0000, 
sim time next is 5829600.0000, 
raw observation next is [23.26666666666667, 51.33333333333334, 1.0, 2.0, 0.5249002176578421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 577044.7951857757, 577044.7951857757, 131347.0450825013], 
processed observation next is [1.0, 0.4782608695652174, 0.6939393939393941, 0.5133333333333334, 1.0, 1.0, 0.4061252720723026, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21372029451325028, 0.21372029451325028, 0.32035864654268614], 
reward next is 0.6796, 
noisyNet noise sample is [array([0.32318178], dtype=float32), -1.303681]. 
=============================================
[2019-03-23 13:36:55,701] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76000, global step 1215998: loss 0.5244
[2019-03-23 13:36:55,703] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76000, global step 1215999: learning rate 0.0001
[2019-03-23 13:36:55,720] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76000, global step 1216009: loss 0.2055
[2019-03-23 13:36:55,724] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76000, global step 1216010: learning rate 0.0001
[2019-03-23 13:36:55,786] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.7063008e-06 9.9999130e-01 2.5988107e-23 4.2378062e-21 2.4190262e-29], sum to 1.0000
[2019-03-23 13:36:55,793] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1314
[2019-03-23 13:36:55,801] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.4, 83.0, 1.0, 2.0, 0.2034028898534142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 220841.6790493211, 220841.6790493214, 73123.9625441438], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6067800.0000, 
sim time next is 6068400.0000, 
raw observation next is [14.4, 83.0, 1.0, 2.0, 0.2025419094327117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 219906.6709796646, 219906.6709796643, 73033.27918472176], 
processed observation next is [1.0, 0.21739130434782608, 0.29090909090909095, 0.83, 1.0, 1.0, 0.003177386790889601, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08144691517765355, 0.08144691517765344, 0.17812994923102868], 
reward next is 0.8219, 
noisyNet noise sample is [array([-0.3273978], dtype=float32), 0.2493134]. 
=============================================
[2019-03-23 13:36:55,946] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76000, global step 1216120: loss 0.4011
[2019-03-23 13:36:55,949] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76000, global step 1216122: learning rate 0.0001
[2019-03-23 13:36:56,016] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.20721873e-05 9.99927878e-01 2.52784640e-24 4.61479288e-22
 1.10160344e-32], sum to 1.0000
[2019-03-23 13:36:56,023] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9842
[2019-03-23 13:36:56,027] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.2, 52.0, 1.0, 2.0, 0.3237186538484458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 355644.8542954048, 355644.8542954048, 114275.4813723212], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5861400.0000, 
sim time next is 5862000.0000, 
raw observation next is [23.1, 53.00000000000001, 1.0, 2.0, 0.3272190541158103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 359948.7914783374, 359948.7914783377, 114700.788594425], 
processed observation next is [1.0, 0.8695652173913043, 0.6863636363636364, 0.53, 1.0, 1.0, 0.15902381764476287, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13331436721419904, 0.13331436721419915, 0.2797580209620122], 
reward next is 0.7202, 
noisyNet noise sample is [array([-0.5074478], dtype=float32), 2.4414482]. 
=============================================
[2019-03-23 13:36:56,044] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[75.58021 ]
 [75.41359 ]
 [75.72661 ]
 [76.199936]
 [76.04904 ]], R is [[75.68345642]
 [75.64790344]
 [75.61322784]
 [75.578125  ]
 [75.54271698]].
[2019-03-23 13:36:56,192] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76000, global step 1216246: loss 0.0059
[2019-03-23 13:36:56,199] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76000, global step 1216246: learning rate 0.0001
[2019-03-23 13:36:56,222] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76000, global step 1216257: loss 0.0185
[2019-03-23 13:36:56,225] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76000, global step 1216258: learning rate 0.0001
[2019-03-23 13:36:56,241] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76000, global step 1216266: loss 0.0582
[2019-03-23 13:36:56,244] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76000, global step 1216266: learning rate 0.0001
[2019-03-23 13:36:56,429] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76000, global step 1216366: loss 0.4365
[2019-03-23 13:36:56,432] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76000, global step 1216367: learning rate 0.0001
[2019-03-23 13:36:56,456] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76000, global step 1216380: loss 0.4112
[2019-03-23 13:36:56,458] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76000, global step 1216380: learning rate 0.0001
[2019-03-23 13:36:56,500] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76000, global step 1216401: loss 0.2950
[2019-03-23 13:36:56,501] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76000, global step 1216402: learning rate 0.0001
[2019-03-23 13:36:56,549] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76000, global step 1216422: loss 0.2375
[2019-03-23 13:36:56,551] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76000, global step 1216422: learning rate 0.0001
[2019-03-23 13:36:56,635] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76000, global step 1216468: loss 0.1432
[2019-03-23 13:36:56,637] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76000, global step 1216468: learning rate 0.0001
[2019-03-23 13:36:56,655] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76000, global step 1216476: loss 0.0732
[2019-03-23 13:36:56,657] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76000, global step 1216476: learning rate 0.0001
[2019-03-23 13:36:56,774] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76000, global step 1216536: loss 0.0682
[2019-03-23 13:36:56,778] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76000, global step 1216537: learning rate 0.0001
[2019-03-23 13:36:56,918] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76000, global step 1216610: loss 0.0062
[2019-03-23 13:36:56,921] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76000, global step 1216610: learning rate 0.0001
[2019-03-23 13:36:57,443] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76000, global step 1216877: loss 0.0013
[2019-03-23 13:36:57,446] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76000, global step 1216880: learning rate 0.0001
[2019-03-23 13:36:59,002] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5246102e-06 9.9999845e-01 7.6863786e-23 2.1448779e-23 9.1506248e-33], sum to 1.0000
[2019-03-23 13:36:59,009] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3098
[2019-03-23 13:36:59,012] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 70.66666666666667, 1.0, 2.0, 0.6781210972128503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 763409.3043953661, 763409.3043953661, 154585.0807421559], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5908800.0000, 
sim time next is 5909400.0000, 
raw observation next is [22.2, 69.5, 1.0, 2.0, 0.7048320900037263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 795070.3406869319, 795070.3406869319, 158799.298055268], 
processed observation next is [1.0, 0.391304347826087, 0.6454545454545454, 0.695, 1.0, 1.0, 0.6310401125046577, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2944704965507155, 0.2944704965507155, 0.38731536111040976], 
reward next is 0.6127, 
noisyNet noise sample is [array([0.6094735], dtype=float32), 0.29035255]. 
=============================================
[2019-03-23 13:37:00,382] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76500, global step 1218357: loss 0.5381
[2019-03-23 13:37:00,383] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76500, global step 1218357: learning rate 0.0001
[2019-03-23 13:37:08,897] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9999523e-01 4.7306276e-06 2.2780982e-14 6.4731071e-14 5.1217666e-20], sum to 1.0000
[2019-03-23 13:37:08,906] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5393
[2019-03-23 13:37:08,910] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.1, 55.0, 1.0, 2.0, 0.2485258743297686, 1.0, 1.0, 0.2485258743297686, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 540607.0364384719, 540607.0364384715, 159256.4034418012], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6091200.0000, 
sim time next is 6091800.0000, 
raw observation next is [21.46666666666667, 53.83333333333334, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7470628745751194, 7.247959536803561, 6.9112, 77.32760615997037, 543522.6213734277, 434151.2242766763, 118557.0144105148], 
processed observation next is [1.0, 0.5217391304347826, 0.6121212121212122, 0.5383333333333334, 0.0, 0.5, -0.25, 0.0, 0.5, -0.25, 1.0, 0.5, 0.6386612493930278, 0.03367595368035614, 0.0, 0.5084231763458567, 0.201304674582751, 0.16079674973210234, 0.2891634497817434], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.12060164], dtype=float32), -0.34636885]. 
=============================================
[2019-03-23 13:37:11,631] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76500, global step 1223994: loss 0.9504
[2019-03-23 13:37:11,633] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76500, global step 1223994: learning rate 0.0001
[2019-03-23 13:37:11,773] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76500, global step 1224066: loss 1.4843
[2019-03-23 13:37:11,776] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76500, global step 1224066: learning rate 0.0001
[2019-03-23 13:37:11,975] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76500, global step 1224165: loss 2.7693
[2019-03-23 13:37:11,976] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76500, global step 1224165: learning rate 0.0001
[2019-03-23 13:37:12,020] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76500, global step 1224186: loss 2.8034
[2019-03-23 13:37:12,021] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76500, global step 1224187: learning rate 0.0001
[2019-03-23 13:37:12,057] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76500, global step 1224206: loss 0.4914
[2019-03-23 13:37:12,060] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76500, global step 1224206: learning rate 0.0001
[2019-03-23 13:37:12,164] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76500, global step 1224253: loss 0.7237
[2019-03-23 13:37:12,166] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76500, global step 1224254: learning rate 0.0001
[2019-03-23 13:37:12,201] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76500, global step 1224279: loss 3.0127
[2019-03-23 13:37:12,202] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76500, global step 1224279: learning rate 0.0001
[2019-03-23 13:37:12,339] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76500, global step 1224330: loss 2.5453
[2019-03-23 13:37:12,340] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76500, global step 1224330: learning rate 0.0001
[2019-03-23 13:37:12,423] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76500, global step 1224379: loss 0.8779
[2019-03-23 13:37:12,425] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76500, global step 1224380: loss 1.0206
[2019-03-23 13:37:12,426] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76500, global step 1224379: learning rate 0.0001
[2019-03-23 13:37:12,427] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76500, global step 1224380: learning rate 0.0001
[2019-03-23 13:37:12,453] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76500, global step 1224392: loss 0.5202
[2019-03-23 13:37:12,456] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76500, global step 1224392: learning rate 0.0001
[2019-03-23 13:37:12,644] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76500, global step 1224486: loss 0.2949
[2019-03-23 13:37:12,648] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76500, global step 1224486: learning rate 0.0001
[2019-03-23 13:37:12,725] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76500, global step 1224528: loss 0.3135
[2019-03-23 13:37:12,731] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76500, global step 1224530: learning rate 0.0001
[2019-03-23 13:37:12,765] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76500, global step 1224550: loss 3.2350
[2019-03-23 13:37:12,767] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76500, global step 1224550: learning rate 0.0001
[2019-03-23 13:37:13,349] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76500, global step 1224837: loss 2.5703
[2019-03-23 13:37:13,351] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76500, global step 1224837: learning rate 0.0001
[2019-03-23 13:37:13,675] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 13:37:13,678] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:37:13,678] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:37:13,679] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:37:13,679] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:37:13,680] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:37:13,680] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:37:13,680] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:37:13,683] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:37:13,683] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:37:13,682] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:37:13,705] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run50
[2019-03-23 13:37:13,728] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run50
[2019-03-23 13:37:13,755] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run50
[2019-03-23 13:37:13,756] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run50
[2019-03-23 13:37:13,810] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run50
[2019-03-23 13:37:27,832] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01493103], dtype=float32), -0.44456536]
[2019-03-23 13:37:27,834] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.01613946, 94.78583864000001, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7310776837452656, 7.255098899364459, 6.9112, 95.5523007378693, 555619.3275584985, 417605.9371254195, 135516.8787756019]
[2019-03-23 13:37:27,836] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:37:27,838] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 2.5123931e-08 9.1785714e-18 2.1774850e-17 1.7828655e-27], sampled 0.9570880176094542
[2019-03-23 13:37:27,840] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 555619.3275584985 W.
[2019-03-23 13:37:37,741] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01493103], dtype=float32), -0.44456536]
[2019-03-23 13:37:37,742] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [8.0, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6102636169357293, 6.911199999999999, 6.9112, 77.32846344354104, 355783.3211844937, 355783.321184494, 75905.58265173636]
[2019-03-23 13:37:37,743] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:37:37,744] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.9996448e-01 3.5498924e-05 1.3773516e-15 7.1978353e-15 1.9105702e-24], sampled 0.604292633341208
[2019-03-23 13:38:40,782] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01493103], dtype=float32), -0.44456536]
[2019-03-23 13:38:40,784] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.680745902265476, 6.911199999999999, 6.9112, 77.32846344354104, 393349.019857602, 393349.0198576023, 122564.5382606854]
[2019-03-23 13:38:40,785] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:38:40,787] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.9990022e-01 9.9786244e-05 3.7697119e-16 2.6412588e-15 1.6682164e-25], sampled 0.17446296952418838
[2019-03-23 13:38:41,727] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01493103], dtype=float32), -0.44456536]
[2019-03-23 13:38:41,728] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.15431626333333, 87.25563788666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6849597606139589, 6.925953346397736, 6.9112, 95.55327323359879, 401551.5609938774, 395630.6927281756, 127376.1665870801]
[2019-03-23 13:38:41,729] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:38:41,734] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.9634653e-01 3.6535230e-03 7.8104595e-15 7.4684643e-14 9.9500170e-24], sampled 0.1861881207038536
[2019-03-23 13:38:54,611] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6481.6076 1678885180.2952 3057.0000
[2019-03-23 13:38:54,691] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6328.7217 1723294598.4314 3425.0000
[2019-03-23 13:38:54,874] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6866.6644 1792856133.3401 2398.0000
[2019-03-23 13:38:54,949] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6553.6457 1698599441.3770 2952.0000
[2019-03-23 13:38:55,018] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6298.1433 1685545636.9164 3224.0000
[2019-03-23 13:38:56,034] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1225000, evaluation results [1225000.0, 6866.66441049583, 1792856133.3400793, 2398.0, 6481.607577760913, 1678885180.2951708, 3057.0, 6298.143250045877, 1685545636.9164386, 3224.0, 6328.721692698646, 1723294598.4313502, 3425.0, 6553.645677180776, 1698599441.3770142, 2952.0]
[2019-03-23 13:38:59,812] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77000, global step 1227010: loss 25.6247
[2019-03-23 13:38:59,813] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77000, global step 1227011: learning rate 0.0001
[2019-03-23 13:39:08,971] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9831097e-05 9.9998021e-01 2.1306720e-17 6.4590705e-15 5.8025296e-27], sum to 1.0000
[2019-03-23 13:39:08,979] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6835
[2019-03-23 13:39:08,985] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666667, 93.0, 1.0, 2.0, 0.7493232561221989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 852401.4832620022, 852401.4832620022, 169388.4633961199], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6434400.0000, 
sim time next is 6435000.0000, 
raw observation next is [20.25, 93.0, 1.0, 2.0, 0.7682902198310207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 874356.3701174725, 874356.3701174725, 172473.2510642278], 
processed observation next is [1.0, 0.4782608695652174, 0.5568181818181818, 0.93, 1.0, 1.0, 0.7103627747887759, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3238356926361009, 0.3238356926361009, 0.4206664660103117], 
reward next is 0.5793, 
noisyNet noise sample is [array([0.614881], dtype=float32), 0.2653288]. 
=============================================
[2019-03-23 13:39:09,013] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[65.4201  ]
 [65.53174 ]
 [65.376945]
 [65.43675 ]
 [65.22681 ]], R is [[65.43637848]
 [65.3688736 ]
 [65.28843689]
 [65.23644257]
 [65.18661499]].
[2019-03-23 13:39:09,057] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77000, global step 1231911: loss 0.0056
[2019-03-23 13:39:09,061] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77000, global step 1231912: learning rate 0.0001
[2019-03-23 13:39:09,378] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77000, global step 1232081: loss 0.1083
[2019-03-23 13:39:09,379] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77000, global step 1232081: learning rate 0.0001
[2019-03-23 13:39:09,409] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77000, global step 1232096: loss 0.1264
[2019-03-23 13:39:09,411] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77000, global step 1232096: learning rate 0.0001
[2019-03-23 13:39:09,455] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77000, global step 1232119: loss 0.1643
[2019-03-23 13:39:09,457] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77000, global step 1232119: learning rate 0.0001
[2019-03-23 13:39:09,486] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77000, global step 1232139: loss 0.0591
[2019-03-23 13:39:09,491] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77000, global step 1232140: learning rate 0.0001
[2019-03-23 13:39:09,584] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77000, global step 1232192: loss 0.0025
[2019-03-23 13:39:09,591] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77000, global step 1232193: learning rate 0.0001
[2019-03-23 13:39:09,866] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77000, global step 1232337: loss 0.0988
[2019-03-23 13:39:09,869] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77000, global step 1232337: learning rate 0.0001
[2019-03-23 13:39:09,904] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77000, global step 1232357: loss 0.0229
[2019-03-23 13:39:09,905] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77000, global step 1232357: learning rate 0.0001
[2019-03-23 13:39:09,966] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77000, global step 1232387: loss 0.0068
[2019-03-23 13:39:09,967] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77000, global step 1232387: learning rate 0.0001
[2019-03-23 13:39:10,060] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77000, global step 1232443: loss 0.0484
[2019-03-23 13:39:10,067] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77000, global step 1232443: learning rate 0.0001
[2019-03-23 13:39:10,214] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77000, global step 1232475: loss 6.9904
[2019-03-23 13:39:10,217] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77000, global step 1232475: learning rate 0.0001
[2019-03-23 13:39:10,234] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77000, global step 1232482: loss -9.3664
[2019-03-23 13:39:10,237] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77000, global step 1232484: learning rate 0.0001
[2019-03-23 13:39:10,449] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77000, global step 1232599: loss 0.1187
[2019-03-23 13:39:10,450] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77000, global step 1232600: learning rate 0.0001
[2019-03-23 13:39:10,485] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77000, global step 1232617: loss 0.0511
[2019-03-23 13:39:10,495] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77000, global step 1232617: learning rate 0.0001
[2019-03-23 13:39:10,781] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77000, global step 1232772: loss 0.0413
[2019-03-23 13:39:10,782] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77000, global step 1232773: learning rate 0.0001
[2019-03-23 13:39:13,979] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.3355543e-09 1.0000000e+00 9.1595746e-19 6.4490632e-20 7.9089270e-32], sum to 1.0000
[2019-03-23 13:39:13,990] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2272
[2019-03-23 13:39:13,996] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.76666666666667, 52.33333333333334, 1.0, 2.0, 0.3930829261151755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 426874.3603314558, 426874.3603314561, 98230.1927735927], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6524400.0000, 
sim time next is 6525000.0000, 
raw observation next is [19.95, 51.5, 1.0, 2.0, 0.3459057338185508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 375621.7841234512, 375621.7841234512, 93124.26614675506], 
processed observation next is [1.0, 0.5217391304347826, 0.5431818181818181, 0.515, 1.0, 1.0, 0.18238216727318846, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13911917930498194, 0.13911917930498194, 0.22713235645550015], 
reward next is 0.7729, 
noisyNet noise sample is [array([-1.6915547], dtype=float32), -0.04600359]. 
=============================================
[2019-03-23 13:39:14,022] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[73.39028 ]
 [73.242805]
 [72.93525 ]
 [73.21    ]
 [72.98083 ]], R is [[73.56775665]
 [73.59249115]
 [73.5940094 ]
 [73.60671234]
 [73.62149811]].
[2019-03-23 13:39:14,725] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77500, global step 1234872: loss 0.0594
[2019-03-23 13:39:14,728] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77500, global step 1234874: learning rate 0.0001
[2019-03-23 13:39:20,936] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 2.2370450e-13 5.6736142e-19 6.1535242e-21 4.2438069e-31], sum to 1.0000
[2019-03-23 13:39:20,944] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3883
[2019-03-23 13:39:20,947] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.3, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7120799929250096, 6.913187448083579, 6.9112, 77.32837371334264, 411533.564945023, 410888.083206823, 126125.0155164405], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6666600.0000, 
sim time next is 6667200.0000, 
raw observation next is [18.3, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6909413067987374, 6.9112, 6.9112, 77.32846210273603, 398685.4066636177, 398685.4066636177, 123979.7223141799], 
processed observation next is [1.0, 0.17391304347826086, 0.4681818181818182, 0.93, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5584875811410536, 0.0, 0.0, 0.5084288041049623, 0.14766126172726582, 0.14766126172726582, 0.302389566619951], 
reward next is 0.6976, 
noisyNet noise sample is [array([0.5810834], dtype=float32), -2.2125103]. 
=============================================
[2019-03-23 13:39:24,451] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77500, global step 1239897: loss 0.8789
[2019-03-23 13:39:24,453] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77500, global step 1239898: learning rate 0.0001
[2019-03-23 13:39:24,709] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77500, global step 1240018: loss 0.2785
[2019-03-23 13:39:24,711] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77500, global step 1240018: learning rate 0.0001
[2019-03-23 13:39:24,762] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77500, global step 1240050: loss 0.1605
[2019-03-23 13:39:24,765] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77500, global step 1240051: learning rate 0.0001
[2019-03-23 13:39:24,919] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77500, global step 1240131: loss 0.0085
[2019-03-23 13:39:24,921] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77500, global step 1240131: learning rate 0.0001
[2019-03-23 13:39:24,965] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77500, global step 1240155: loss 0.3781
[2019-03-23 13:39:24,969] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77500, global step 1240155: learning rate 0.0001
[2019-03-23 13:39:24,973] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77500, global step 1240155: loss 0.7397
[2019-03-23 13:39:24,978] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77500, global step 1240156: learning rate 0.0001
[2019-03-23 13:39:25,275] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77500, global step 1240312: loss 0.1345
[2019-03-23 13:39:25,276] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77500, global step 1240312: learning rate 0.0001
[2019-03-23 13:39:25,472] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77500, global step 1240404: loss 0.0022
[2019-03-23 13:39:25,474] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77500, global step 1240405: learning rate 0.0001
[2019-03-23 13:39:25,490] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77500, global step 1240413: loss 0.0147
[2019-03-23 13:39:25,495] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77500, global step 1240414: learning rate 0.0001
[2019-03-23 13:39:25,593] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77500, global step 1240466: loss 0.0048
[2019-03-23 13:39:25,596] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77500, global step 1240466: learning rate 0.0001
[2019-03-23 13:39:25,662] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77500, global step 1240499: loss 0.0066
[2019-03-23 13:39:25,667] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77500, global step 1240500: learning rate 0.0001
[2019-03-23 13:39:25,679] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77500, global step 1240506: loss 0.0077
[2019-03-23 13:39:25,683] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77500, global step 1240507: learning rate 0.0001
[2019-03-23 13:39:25,772] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77500, global step 1240556: loss 0.0320
[2019-03-23 13:39:25,775] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77500, global step 1240558: learning rate 0.0001
[2019-03-23 13:39:25,991] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77500, global step 1240665: loss 0.0573
[2019-03-23 13:39:25,992] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77500, global step 1240665: learning rate 0.0001
[2019-03-23 13:39:26,154] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77500, global step 1240748: loss 0.0010
[2019-03-23 13:39:26,158] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77500, global step 1240748: learning rate 0.0001
[2019-03-23 13:39:27,549] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.12629447e-06 9.99993920e-01 1.82184367e-12 3.09813102e-13
 1.15327985e-23], sum to 1.0000
[2019-03-23 13:39:27,556] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5707
[2019-03-23 13:39:27,564] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1208039.998333966 W.
[2019-03-23 13:39:27,571] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.0, 62.0, 1.0, 2.0, 0.3528428630288413, 1.0, 2.0, 0.3528428630288413, 1.0, 2.0, 0.7133237361472589, 6.911200000000001, 6.9112, 77.3421103, 1208039.998333966, 1208039.998333966, 275274.36820065], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6789600.0000, 
sim time next is 6790200.0000, 
raw observation next is [25.08333333333334, 61.66666666666667, 1.0, 2.0, 0.307418678456936, 1.0, 2.0, 0.307418678456936, 1.0, 2.0, 0.6212867610429457, 6.9112, 6.9112, 77.3421103, 1052534.562112098, 1052534.562112098, 257636.6569656063], 
processed observation next is [1.0, 0.6086956521739131, 0.7765151515151518, 0.6166666666666667, 1.0, 1.0, 0.13427334807116997, 1.0, 1.0, 0.13427334807116997, 1.0, 1.0, 0.45898108720420816, 0.0, 0.0, 0.5085185399722538, 0.38982761559707335, 0.38982761559707335, 0.6283820901600153], 
reward next is 0.3716, 
noisyNet noise sample is [array([-0.7405272], dtype=float32), -0.6021415]. 
=============================================
[2019-03-23 13:39:30,344] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78000, global step 1242861: loss 3.7198
[2019-03-23 13:39:30,346] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78000, global step 1242862: learning rate 0.0001
[2019-03-23 13:39:35,015] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 2.4567069e-17 1.9802332e-18 6.7387626e-20 2.0012334e-30], sum to 1.0000
[2019-03-23 13:39:35,029] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9116
[2019-03-23 13:39:35,032] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.71666666666667, 87.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6723289270668851, 6.911199999999999, 6.9112, 77.32846344354104, 388445.6571335755, 388445.6571335758, 121779.2306481996], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6936600.0000, 
sim time next is 6937200.0000, 
raw observation next is [18.8, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6724625856067178, 6.9112, 6.9112, 77.32846344354104, 388475.4457211792, 388475.4457211792, 121827.3230572917], 
processed observation next is [0.0, 0.30434782608695654, 0.49090909090909096, 0.87, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5320894080095969, 0.0, 0.0, 0.5084288129206541, 0.14387979471154785, 0.14387979471154785, 0.2971398123348578], 
reward next is 0.7029, 
noisyNet noise sample is [array([0.24880446], dtype=float32), -0.8175256]. 
=============================================
[2019-03-23 13:39:36,425] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 8.4520828e-11 2.8937729e-11 2.7153412e-13 1.0623463e-19], sum to 1.0000
[2019-03-23 13:39:36,432] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4888
[2019-03-23 13:39:36,436] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 585303.9665237591 W.
[2019-03-23 13:39:36,443] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.7, 60.0, 1.0, 2.0, 0.2576607496133987, 1.0, 2.0, 0.2576607496133987, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 585303.9665237591, 585303.9665237594, 182376.9358697238], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6972000.0000, 
sim time next is 6972600.0000, 
raw observation next is [27.7, 60.5, 1.0, 2.0, 0.2593214073628621, 1.0, 2.0, 0.2593214073628621, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 588747.2699160958, 588747.269916096, 182853.8150282484], 
processed observation next is [0.0, 0.6956521739130435, 0.8954545454545454, 0.605, 1.0, 1.0, 0.07415175920357758, 1.0, 1.0, 0.07415175920357758, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2180545444133688, 0.21805454441336888, 0.4459849147030449], 
reward next is 0.5540, 
noisyNet noise sample is [array([0.6496223], dtype=float32), 2.2367754]. 
=============================================
[2019-03-23 13:39:40,569] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78000, global step 1247983: loss 92.7772
[2019-03-23 13:39:40,575] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78000, global step 1247983: learning rate 0.0001
[2019-03-23 13:39:40,782] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78000, global step 1248089: loss -7.6342
[2019-03-23 13:39:40,784] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78000, global step 1248089: learning rate 0.0001
[2019-03-23 13:39:40,834] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78000, global step 1248118: loss 43.4908
[2019-03-23 13:39:40,836] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78000, global step 1248119: learning rate 0.0001
[2019-03-23 13:39:40,841] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78000, global step 1248123: loss 100.1177
[2019-03-23 13:39:40,845] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78000, global step 1248124: learning rate 0.0001
[2019-03-23 13:39:40,878] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78000, global step 1248138: loss 50.0000
[2019-03-23 13:39:40,880] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78000, global step 1248139: learning rate 0.0001
[2019-03-23 13:39:40,925] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78000, global step 1248161: loss 31.6230
[2019-03-23 13:39:40,927] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78000, global step 1248161: learning rate 0.0001
[2019-03-23 13:39:41,121] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78000, global step 1248260: loss 79.6954
[2019-03-23 13:39:41,124] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78000, global step 1248262: learning rate 0.0001
[2019-03-23 13:39:41,349] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78000, global step 1248379: loss 84.9243
[2019-03-23 13:39:41,351] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78000, global step 1248380: learning rate 0.0001
[2019-03-23 13:39:41,524] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78000, global step 1248467: loss 82.1001
[2019-03-23 13:39:41,526] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78000, global step 1248467: learning rate 0.0001
[2019-03-23 13:39:41,557] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78000, global step 1248478: loss -0.8890
[2019-03-23 13:39:41,561] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78000, global step 1248478: learning rate 0.0001
[2019-03-23 13:39:41,601] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78000, global step 1248501: loss 84.7790
[2019-03-23 13:39:41,604] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78000, global step 1248501: learning rate 0.0001
[2019-03-23 13:39:41,661] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78000, global step 1248535: loss 1.3177
[2019-03-23 13:39:41,664] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78000, global step 1248535: learning rate 0.0001
[2019-03-23 13:39:41,717] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78000, global step 1248559: loss 86.1538
[2019-03-23 13:39:41,719] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78000, global step 1248559: learning rate 0.0001
[2019-03-23 13:39:41,969] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78000, global step 1248687: loss -21.9690
[2019-03-23 13:39:41,972] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78000, global step 1248688: learning rate 0.0001
[2019-03-23 13:39:42,134] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78000, global step 1248774: loss -11.1628
[2019-03-23 13:39:42,138] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78000, global step 1248775: learning rate 0.0001
[2019-03-23 13:39:42,204] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.1838128e-10 1.0000000e+00 8.4873150e-15 1.6210086e-13 8.8495488e-30], sum to 1.0000
[2019-03-23 13:39:42,216] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0307
[2019-03-23 13:39:42,218] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.1, 91.0, 1.0, 2.0, 0.3452921885978212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 382925.0684406343, 382925.0684406343, 117236.0947227413], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7082400.0000, 
sim time next is 7083000.0000, 
raw observation next is [18.0, 91.5, 1.0, 2.0, 0.3437428327402404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 380949.6613173622, 380949.6613173622, 117012.2219896434], 
processed observation next is [1.0, 1.0, 0.45454545454545453, 0.915, 1.0, 1.0, 0.1796785409253005, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1410924671545786, 0.1410924671545786, 0.2853956633893741], 
reward next is 0.7146, 
noisyNet noise sample is [array([0.8545467], dtype=float32), 0.8698727]. 
=============================================
[2019-03-23 13:39:42,227] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[72.711655]
 [72.71908 ]
 [72.73058 ]
 [72.73157 ]
 [72.730156]], R is [[72.69987488]
 [72.68693542]
 [72.67347717]
 [72.65946198]
 [72.64474487]].
[2019-03-23 13:39:44,584] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 13:39:44,586] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:39:44,588] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:39:44,588] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:39:44,589] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:39:44,590] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:39:44,590] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:39:44,591] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:39:44,589] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:39:44,590] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:39:44,596] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:39:44,613] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run51
[2019-03-23 13:39:44,639] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run51
[2019-03-23 13:39:44,640] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run51
[2019-03-23 13:39:44,640] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run51
[2019-03-23 13:39:44,661] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run51
[2019-03-23 13:40:01,374] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01493103], dtype=float32), -0.45288646]
[2019-03-23 13:40:01,375] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.33853855, 92.50068933, 1.0, 2.0, 0.4190234094596417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 476270.3341848706, 476270.3341848706, 133555.2539043291]
[2019-03-23 13:40:01,376] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:40:01,379] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.5121490e-07 9.9999940e-01 8.5390028e-13 1.2957578e-11 3.8094357e-24], sampled 0.9253045281736296
[2019-03-23 13:40:16,443] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01493103], dtype=float32), -0.45288646]
[2019-03-23 13:40:16,446] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [13.37238999666667, 77.54705155666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 206792.7155675152, 206792.7155675148, 72510.68928514796]
[2019-03-23 13:40:16,447] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:40:16,450] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.4816163e-05 9.9997520e-01 2.2449678e-11 2.3277157e-10 1.1816986e-21], sampled 0.818791812860889
[2019-03-23 13:40:28,477] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01493103], dtype=float32), -0.45288646]
[2019-03-23 13:40:28,480] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.44436262166667, 58.08322734333333, 1.0, 2.0, 0.337231835748196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 372966.8686889539, 372966.8686889542, 120522.6399075242]
[2019-03-23 13:40:28,481] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:40:28,488] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0262203e-06 9.9999893e-01 1.0918129e-12 1.6137527e-11 6.5863310e-24], sampled 0.29566747002271143
[2019-03-23 13:40:41,959] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01493103], dtype=float32), -0.45288646]
[2019-03-23 13:40:41,961] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [29.83333333333334, 52.5, 1.0, 2.0, 0.4666273210743367, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8741831309018131, 7.009976750795833, 6.9112, 95.55299540475099, 1057722.018751248, 1018080.678208709, 250238.8502615612]
[2019-03-23 13:40:41,962] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:40:41,966] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.0571112e-09 1.0000000e+00 1.5871771e-13 2.9613670e-12 6.6057314e-26], sampled 0.3734564584819745
[2019-03-23 13:40:56,781] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01493103], dtype=float32), -0.45288646]
[2019-03-23 13:40:56,783] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.66428435333333, 80.47306912333333, 1.0, 2.0, 0.4430704924271442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 505125.8918771634, 505125.8918771634, 137647.1840310348]
[2019-03-23 13:40:56,785] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:40:56,788] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.8169463e-07 9.9999964e-01 1.0515322e-12 1.5818409e-11 5.0897590e-24], sampled 0.3828011898783683
[2019-03-23 13:41:03,520] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01493103], dtype=float32), -0.45288646]
[2019-03-23 13:41:03,521] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.55, 86.0, 1.0, 2.0, 0.3363549885867304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 372104.0265247816, 372104.0265247816, 120499.2844674755]
[2019-03-23 13:41:03,523] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:41:03,526] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.3303346e-07 9.9999928e-01 6.0845925e-13 9.4563801e-12 2.1781236e-24], sampled 0.9598064716687856
[2019-03-23 13:41:25,190] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.2746 1663752963.5593 106.0000
[2019-03-23 13:41:25,718] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8605.5688 1705748602.7489 465.0000
[2019-03-23 13:41:25,983] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9069.5859 1656059627.1529 80.0000
[2019-03-23 13:41:26,019] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.5126 1773156615.2347 175.0000
[2019-03-23 13:41:26,025] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1234 1683281427.5389 214.0000
[2019-03-23 13:41:27,039] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1250000, evaluation results [1250000.0, 8512.512624588599, 1773156615.2347376, 175.0, 9069.585854885721, 1656059627.1528785, 80.0, 8857.274563406845, 1663752963.5592508, 106.0, 8605.568814619504, 1705748602.7489219, 465.0, 8575.123356354823, 1683281427.538946, 214.0]
[2019-03-23 13:41:28,094] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78500, global step 1250564: loss 0.0114
[2019-03-23 13:41:28,097] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78500, global step 1250564: learning rate 0.0001
[2019-03-23 13:41:34,304] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.5407969e-09 1.0000000e+00 1.6172192e-17 2.9542328e-18 3.2965793e-32], sum to 1.0000
[2019-03-23 13:41:34,311] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6073
[2019-03-23 13:41:34,316] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.1, 82.0, 1.0, 2.0, 0.2049514934436297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 222523.4370935205, 222523.4370935202, 72304.23822570723], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7270200.0000, 
sim time next is 7270800.0000, 
raw observation next is [14.2, 80.33333333333333, 1.0, 2.0, 0.2056863673418732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 223321.500102078, 223321.5001020778, 72198.50859499874], 
processed observation next is [1.0, 0.13043478260869565, 0.2818181818181818, 0.8033333333333332, 1.0, 1.0, 0.007107959177341493, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08271166670447333, 0.08271166670447326, 0.17609392340243596], 
reward next is 0.8239, 
noisyNet noise sample is [array([0.59229046], dtype=float32), -0.47224906]. 
=============================================
[2019-03-23 13:41:38,213] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78500, global step 1255940: loss 0.3619
[2019-03-23 13:41:38,214] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78500, global step 1255941: learning rate 0.0001
[2019-03-23 13:41:38,386] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78500, global step 1256034: loss 0.0479
[2019-03-23 13:41:38,389] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78500, global step 1256034: learning rate 0.0001
[2019-03-23 13:41:38,505] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78500, global step 1256096: loss 0.4967
[2019-03-23 13:41:38,510] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78500, global step 1256098: learning rate 0.0001
[2019-03-23 13:41:38,595] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78500, global step 1256137: loss 1.4786
[2019-03-23 13:41:38,597] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78500, global step 1256137: learning rate 0.0001
[2019-03-23 13:41:38,736] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78500, global step 1256214: loss 0.0870
[2019-03-23 13:41:38,739] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78500, global step 1256214: learning rate 0.0001
[2019-03-23 13:41:38,750] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78500, global step 1256221: loss 0.0242
[2019-03-23 13:41:38,751] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78500, global step 1256221: learning rate 0.0001
[2019-03-23 13:41:38,855] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78500, global step 1256285: loss 0.2217
[2019-03-23 13:41:38,858] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78500, global step 1256286: learning rate 0.0001
[2019-03-23 13:41:38,868] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78500, global step 1256289: loss 0.1713
[2019-03-23 13:41:38,869] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78500, global step 1256290: learning rate 0.0001
[2019-03-23 13:41:39,118] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78500, global step 1256428: loss 0.0361
[2019-03-23 13:41:39,122] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78500, global step 1256428: learning rate 0.0001
[2019-03-23 13:41:39,222] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78500, global step 1256481: loss 0.1144
[2019-03-23 13:41:39,225] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78500, global step 1256482: learning rate 0.0001
[2019-03-23 13:41:39,287] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78500, global step 1256517: loss 0.1646
[2019-03-23 13:41:39,290] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78500, global step 1256518: learning rate 0.0001
[2019-03-23 13:41:39,295] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78500, global step 1256519: loss 0.1084
[2019-03-23 13:41:39,296] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78500, global step 1256519: learning rate 0.0001
[2019-03-23 13:41:39,372] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78500, global step 1256557: loss 0.0446
[2019-03-23 13:41:39,376] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78500, global step 1256558: learning rate 0.0001
[2019-03-23 13:41:39,452] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78500, global step 1256604: loss 0.3141
[2019-03-23 13:41:39,452] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78500, global step 1256604: learning rate 0.0001
[2019-03-23 13:41:39,690] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78500, global step 1256724: loss 0.1265
[2019-03-23 13:41:39,693] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78500, global step 1256725: learning rate 0.0001
[2019-03-23 13:41:42,461] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9997902e-01 2.0972773e-05 5.6399378e-20 5.2413095e-17 1.7078373e-28], sum to 1.0000
[2019-03-23 13:41:42,465] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4373
[2019-03-23 13:41:42,470] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.61666666666667, 91.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7319601830067114, 7.074319176412756, 6.9112, 77.32788870987373, 475062.5455331661, 422085.1671487801, 128435.8633347228], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7427400.0000, 
sim time next is 7428000.0000, 
raw observation next is [18.43333333333333, 92.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7291613806727072, 7.052264581510204, 6.9112, 77.32795768672321, 466367.1742207321, 420552.5830622435, 128073.8133104237], 
processed observation next is [1.0, 1.0, 0.4742424242424241, 0.9233333333333335, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.613087686675296, 0.014106458151020362, 0.0, 0.5084254876077349, 0.1727285830447156, 0.15576021594897907, 0.3123751544156676], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.27733356], dtype=float32), 1.1598797]. 
=============================================
[2019-03-23 13:41:42,494] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[53.13068 ]
 [52.786713]
 [53.225285]
 [53.074295]
 [52.18893 ]], R is [[53.69334793]
 [53.15641403]
 [52.62485123]
 [52.09860229]
 [51.57761765]].
[2019-03-23 13:41:43,415] A3C_AGENT_WORKER-Thread-11 INFO:Local step 79000, global step 1258709: loss -136.0057
[2019-03-23 13:41:43,416] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 79000, global step 1258710: learning rate 0.0001
[2019-03-23 13:41:45,538] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 4.3942809e-09 3.0219526e-16 5.8425908e-16 2.5724069e-25], sum to 1.0000
[2019-03-23 13:41:45,543] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7319
[2019-03-23 13:41:45,546] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.16666666666666, 92.0, 1.0, 1.0, 0.2257855004474852, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4504605254946221, 6.911199999999999, 6.9112, 77.32823319472729, 513545.8364504282, 513545.8364504285, 168152.511299754], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7695600.0000, 
sim time next is 7696200.0000, 
raw observation next is [20.08333333333334, 92.5, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7642391579522221, 7.27541738467142, 6.9112, 77.32756107126238, 554348.2155358852, 436059.2388990275, 135387.5903098328], 
processed observation next is [1.0, 0.043478260869565216, 0.5492424242424245, 0.925, 0.0, 0.5, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.663198797074603, 0.03642173846714201, 0.0, 0.5084228798910034, 0.2053141539021797, 0.16150342181445465, 0.3302136349020312], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5302505], dtype=float32), 1.9967476]. 
=============================================
[2019-03-23 13:41:48,326] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.1296567e-18 1.0000000e+00 3.8407563e-29 1.6423306e-23 0.0000000e+00], sum to 1.0000
[2019-03-23 13:41:48,332] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1154
[2019-03-23 13:41:48,334] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.91666666666667, 94.16666666666666, 1.0, 2.0, 0.457272754421011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 521494.2436956788, 521494.2436956788, 135051.8565328335], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7531800.0000, 
sim time next is 7532400.0000, 
raw observation next is [20.73333333333333, 95.33333333333334, 1.0, 2.0, 0.455351687237387, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 519253.2373434082, 519253.2373434079, 134751.7706242601], 
processed observation next is [0.0, 0.17391304347826086, 0.5787878787878786, 0.9533333333333335, 1.0, 1.0, 0.3191896090467337, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19231601383089195, 0.1923160138308918, 0.3286628551811222], 
reward next is 0.6713, 
noisyNet noise sample is [array([0.27396452], dtype=float32), 0.56208485]. 
=============================================
[2019-03-23 13:41:53,466] A3C_AGENT_WORKER-Thread-13 INFO:Local step 79000, global step 1264019: loss -177.4723
[2019-03-23 13:41:53,469] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 79000, global step 1264020: learning rate 0.0001
[2019-03-23 13:41:53,651] A3C_AGENT_WORKER-Thread-21 INFO:Local step 79000, global step 1264110: loss -74.8068
[2019-03-23 13:41:53,653] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 79000, global step 1264110: learning rate 0.0001
[2019-03-23 13:41:53,788] A3C_AGENT_WORKER-Thread-20 INFO:Local step 79000, global step 1264182: loss -76.7546
[2019-03-23 13:41:53,791] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 79000, global step 1264182: learning rate 0.0001
[2019-03-23 13:41:53,792] A3C_AGENT_WORKER-Thread-19 INFO:Local step 79000, global step 1264184: loss -121.1972
[2019-03-23 13:41:53,795] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 79000, global step 1264184: learning rate 0.0001
[2019-03-23 13:41:53,835] A3C_AGENT_WORKER-Thread-2 INFO:Local step 79000, global step 1264202: loss -54.3302
[2019-03-23 13:41:53,841] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 79000, global step 1264203: learning rate 0.0001
[2019-03-23 13:41:54,015] A3C_AGENT_WORKER-Thread-10 INFO:Local step 79000, global step 1264293: loss -56.5094
[2019-03-23 13:41:54,020] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 79000, global step 1264295: learning rate 0.0001
[2019-03-23 13:41:54,037] A3C_AGENT_WORKER-Thread-18 INFO:Local step 79000, global step 1264302: loss -104.5426
[2019-03-23 13:41:54,038] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 79000, global step 1264302: learning rate 0.0001
[2019-03-23 13:41:54,062] A3C_AGENT_WORKER-Thread-22 INFO:Local step 79000, global step 1264313: loss -55.8031
[2019-03-23 13:41:54,065] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 79000, global step 1264314: learning rate 0.0001
[2019-03-23 13:41:54,066] A3C_AGENT_WORKER-Thread-9 INFO:Local step 79000, global step 1264315: loss -89.8239
[2019-03-23 13:41:54,068] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 79000, global step 1264315: learning rate 0.0001
[2019-03-23 13:41:54,198] A3C_AGENT_WORKER-Thread-3 INFO:Local step 79000, global step 1264386: loss -98.4548
[2019-03-23 13:41:54,202] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 79000, global step 1264386: learning rate 0.0001
[2019-03-23 13:41:54,354] A3C_AGENT_WORKER-Thread-16 INFO:Local step 79000, global step 1264463: loss -53.4742
[2019-03-23 13:41:54,356] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 79000, global step 1264463: learning rate 0.0001
[2019-03-23 13:41:54,418] A3C_AGENT_WORKER-Thread-17 INFO:Local step 79000, global step 1264487: loss -122.1336
[2019-03-23 13:41:54,420] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 79000, global step 1264489: learning rate 0.0001
[2019-03-23 13:41:54,454] A3C_AGENT_WORKER-Thread-15 INFO:Local step 79000, global step 1264504: loss -68.5754
[2019-03-23 13:41:54,457] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 79000, global step 1264506: learning rate 0.0001
[2019-03-23 13:41:54,681] A3C_AGENT_WORKER-Thread-14 INFO:Local step 79000, global step 1264624: loss -90.7206
[2019-03-23 13:41:54,683] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 79000, global step 1264624: learning rate 0.0001
[2019-03-23 13:41:54,895] A3C_AGENT_WORKER-Thread-12 INFO:Local step 79000, global step 1264722: loss -8.8023
[2019-03-23 13:41:54,896] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 79000, global step 1264723: learning rate 0.0001
[2019-03-23 13:41:58,112] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.3880680e-11 1.0000000e+00 6.8114466e-25 4.4313869e-22 7.8685866e-36], sum to 1.0000
[2019-03-23 13:41:58,117] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8744
[2019-03-23 13:41:58,125] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.26666666666667, 79.33333333333334, 1.0, 2.0, 0.4240851942199189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 460557.6896106615, 460557.6896106615, 120379.6934372796], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7719600.0000, 
sim time next is 7720200.0000, 
raw observation next is [18.55, 77.0, 1.0, 2.0, 0.4807614692249967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522330.5743212356, 522330.5743212356, 125220.6565754012], 
processed observation next is [1.0, 0.34782608695652173, 0.47954545454545455, 0.77, 1.0, 1.0, 0.35095183653124584, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1934557682671243, 0.1934557682671243, 0.305416235549759], 
reward next is 0.6946, 
noisyNet noise sample is [array([-0.25747648], dtype=float32), -0.064658254]. 
=============================================
[2019-03-23 13:41:59,404] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:41:59,405] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:41:59,465] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run7
[2019-03-23 13:42:04,007] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3754415e-12 1.0000000e+00 5.0354909e-25 4.8384345e-23 3.6665419e-35], sum to 1.0000
[2019-03-23 13:42:04,015] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8727
[2019-03-23 13:42:04,018] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 73.0, 1.0, 2.0, 0.4039180377046535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 456430.36293256, 456430.3629325603, 125907.1311998837], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 64800.0000, 
sim time next is 65400.0000, 
raw observation next is [21.83333333333334, 73.0, 1.0, 2.0, 0.4046139376039445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 456665.7007414348, 456665.7007414351, 125655.3767639931], 
processed observation next is [1.0, 0.782608695652174, 0.628787878787879, 0.73, 1.0, 1.0, 0.2557674220049306, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16913544471904993, 0.16913544471905004, 0.3064765286926661], 
reward next is 0.6935, 
noisyNet noise sample is [array([-0.21461375], dtype=float32), 1.5029821]. 
=============================================
[2019-03-23 13:42:05,465] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.4257819e-08 1.0000000e+00 2.4955283e-24 1.6048685e-22 1.4902427e-34], sum to 1.0000
[2019-03-23 13:42:05,475] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7561
[2019-03-23 13:42:05,480] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 70.0, 1.0, 2.0, 0.2777516875252713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 301589.8141356527, 301589.8141356524, 99318.4266431259], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7869600.0000, 
sim time next is 7870200.0000, 
raw observation next is [18.9, 69.66666666666667, 1.0, 2.0, 0.3398368486354471, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369029.0327528053, 369029.0327528053, 105991.501743097], 
processed observation next is [1.0, 0.08695652173913043, 0.49545454545454537, 0.6966666666666668, 1.0, 1.0, 0.17479606079430887, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13667741953807602, 0.13667741953807602, 0.2585158579099927], 
reward next is 0.7415, 
noisyNet noise sample is [array([-0.464106], dtype=float32), -1.3736928]. 
=============================================
[2019-03-23 13:42:06,641] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.7871434e-06 9.9999416e-01 2.6086426e-22 2.4811097e-20 1.7155908e-32], sum to 1.0000
[2019-03-23 13:42:06,654] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9726
[2019-03-23 13:42:06,657] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.13333333333333, 83.0, 1.0, 2.0, 0.5497561305635711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 618344.628416449, 618344.6284164487, 139234.1641121624], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7892400.0000, 
sim time next is 7893000.0000, 
raw observation next is [19.95, 85.5, 1.0, 2.0, 0.6400528667938046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 721403.306539613, 721403.306539613, 150311.7303872512], 
processed observation next is [1.0, 0.34782608695652173, 0.5431818181818181, 0.855, 1.0, 1.0, 0.5500660834922557, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2671864098294863, 0.2671864098294863, 0.36661397655427125], 
reward next is 0.6334, 
noisyNet noise sample is [array([0.4152177], dtype=float32), -0.75679934]. 
=============================================
[2019-03-23 13:42:06,674] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[65.367645]
 [65.89505 ]
 [66.07669 ]
 [66.13216 ]
 [66.10976 ]], R is [[64.84658051]
 [64.85852051]
 [64.90789795]
 [64.9668808 ]
 [65.026474  ]].
[2019-03-23 13:42:07,437] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.0357836e-08 1.0000000e+00 1.1108810e-20 3.9507238e-20 3.7594194e-30], sum to 1.0000
[2019-03-23 13:42:07,446] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3857
[2019-03-23 13:42:07,454] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.9, 93.0, 1.0, 2.0, 0.8741729395362463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 997348.673033981, 997348.673033981, 191859.0089857454], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7911600.0000, 
sim time next is 7912200.0000, 
raw observation next is [21.0, 93.0, 1.0, 2.0, 0.8846569812455307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1009534.44231164, 1009534.44231164, 194067.2788573074], 
processed observation next is [1.0, 0.5652173913043478, 0.5909090909090909, 0.93, 1.0, 1.0, 0.8558212265569134, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.37390164530060743, 0.37390164530060743, 0.47333482648123754], 
reward next is 0.5267, 
noisyNet noise sample is [array([-0.3039269], dtype=float32), 0.3248014]. 
=============================================
[2019-03-23 13:42:09,558] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:42:09,558] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:42:09,561] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run7
[2019-03-23 13:42:09,864] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:42:09,865] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:42:09,870] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run7
[2019-03-23 13:42:09,906] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:42:09,906] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:42:09,908] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:42:09,908] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:42:09,913] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run7
[2019-03-23 13:42:09,942] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run7
[2019-03-23 13:42:10,040] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:42:10,041] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:42:10,046] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run7
[2019-03-23 13:42:10,076] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:42:10,078] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:42:10,085] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run7
[2019-03-23 13:42:10,136] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:42:10,137] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:42:10,141] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run7
[2019-03-23 13:42:10,173] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:42:10,173] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:42:10,181] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run7
[2019-03-23 13:42:10,225] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:42:10,226] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:42:10,229] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:42:10,229] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:42:10,232] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run7
[2019-03-23 13:42:10,268] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run7
[2019-03-23 13:42:10,298] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:42:10,298] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:42:10,306] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run7
[2019-03-23 13:42:10,349] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:42:10,349] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:42:10,353] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run7
[2019-03-23 13:42:10,462] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:42:10,462] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:42:10,466] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run7
[2019-03-23 13:42:10,522] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:42:10,523] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:42:10,526] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run7
[2019-03-23 13:42:10,601] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 13:42:10,601] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:42:10,605] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run7
[2019-03-23 13:42:16,905] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 13:42:16,906] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:42:16,907] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:42:16,908] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:42:16,909] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:42:16,911] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:42:16,913] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:42:16,912] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:42:16,915] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:42:16,917] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:42:16,917] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:42:16,942] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run52
[2019-03-23 13:42:16,965] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run52
[2019-03-23 13:42:16,991] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run52
[2019-03-23 13:42:17,015] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run52
[2019-03-23 13:42:17,015] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run52
[2019-03-23 13:42:21,354] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01493103], dtype=float32), -0.4545371]
[2019-03-23 13:42:21,359] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.13037677666667, 91.76514054666667, 1.0, 2.0, 0.2017071194687519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 218990.7045206559, 218990.7045206555, 76749.74367814026]
[2019-03-23 13:42:21,360] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:42:21,365] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.4182362e-10 1.0000000e+00 3.9506577e-23 1.4322273e-21 7.1546353e-33], sampled 0.6957258499166435
[2019-03-23 13:42:39,531] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01493103], dtype=float32), -0.4545371]
[2019-03-23 13:42:39,534] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.63333333333333, 67.33333333333334, 1.0, 2.0, 0.5007223365878829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 564986.0621490668, 564986.0621490665, 139305.5749850376]
[2019-03-23 13:42:39,535] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:42:39,542] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.2609587e-08 1.0000000e+00 1.7568570e-22 5.2086206e-21 3.9295072e-32], sampled 0.28705101673012345
[2019-03-23 13:42:57,888] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01493103], dtype=float32), -0.4545371]
[2019-03-23 13:42:57,889] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.65, 65.0, 1.0, 2.0, 0.7910458218846607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 902815.8630765355, 902815.8630765355, 185139.0933250849]
[2019-03-23 13:42:57,889] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:42:57,891] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.288122e-09 1.000000e+00 2.259380e-22 7.327449e-21 8.637421e-32], sampled 0.10482733826770363
[2019-03-23 13:43:00,710] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01493103], dtype=float32), -0.4545371]
[2019-03-23 13:43:00,712] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.78333333333333, 84.33333333333333, 1.0, 2.0, 0.4181556392285021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 473757.1253801452, 473757.1253801448, 132329.0360006275]
[2019-03-23 13:43:00,713] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:43:00,716] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.1054019e-08 1.0000000e+00 2.7935281e-23 8.3003601e-22 1.7473364e-33], sampled 0.7447756771404374
[2019-03-23 13:43:08,977] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01493103], dtype=float32), -0.4545371]
[2019-03-23 13:43:08,979] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.00196053333333, 89.38759087333334, 1.0, 2.0, 0.3420805370160179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 377301.097520215, 377301.0975202153, 120493.8750932476]
[2019-03-23 13:43:08,981] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:43:08,984] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.3767715e-09 1.0000000e+00 3.1541275e-23 1.0774541e-21 3.8045554e-33], sampled 0.30201156041937893
[2019-03-23 13:43:17,319] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01493103], dtype=float32), -0.4545371]
[2019-03-23 13:43:17,321] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.86666666666667, 88.33333333333334, 1.0, 2.0, 0.5078298082427877, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 578945.0781700722, 578945.0781700722, 147524.6434160763]
[2019-03-23 13:43:17,323] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:43:17,328] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.7739611e-09 1.0000000e+00 1.2683549e-22 3.8947718e-21 2.6067745e-32], sampled 0.25534805851045683
[2019-03-23 13:43:18,905] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01493103], dtype=float32), -0.4545371]
[2019-03-23 13:43:18,908] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.45, 80.0, 1.0, 2.0, 0.5347175982828084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 608686.0750427556, 608686.0750427556, 151662.7719713631]
[2019-03-23 13:43:18,909] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:43:18,912] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.8510859e-09 1.0000000e+00 3.9153401e-23 1.2802603e-21 4.5092059e-33], sampled 0.6679840240126208
[2019-03-23 13:43:33,180] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01493103], dtype=float32), -0.4545371]
[2019-03-23 13:43:33,181] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.748009625, 92.52804293333335, 1.0, 2.0, 0.3584258385370334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 397171.8743920571, 397171.8743920571, 122454.8693752223]
[2019-03-23 13:43:33,182] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:43:33,184] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.2192500e-09 1.0000000e+00 9.4265123e-23 2.9893253e-21 1.7847322e-32], sampled 0.15034428812217604
[2019-03-23 13:43:58,251] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 13:43:58,468] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 13:43:58,512] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 13:43:58,516] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 13:43:58,631] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 13:43:59,647] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1275000, evaluation results [1275000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 13:44:00,182] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.7211081e-12 1.0000000e+00 3.7721383e-27 2.3740094e-26 7.3224997e-37], sum to 1.0000
[2019-03-23 13:44:00,187] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4012
[2019-03-23 13:44:00,194] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.5, 85.0, 1.0, 2.0, 0.2026878342127567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 220065.1423394215, 220065.1423394212, 71529.42150467083], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 99000.0000, 
sim time next is 99600.0000, 
raw observation next is [13.33333333333333, 86.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 216589.5979799582, 216589.5979799579, 71056.06002399609], 
processed observation next is [1.0, 0.13043478260869565, 0.2424242424242423, 0.86, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08021836962220674, 0.08021836962220663, 0.1733074634731612], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.32917312], dtype=float32), 0.6128053]. 
=============================================
[2019-03-23 13:44:03,618] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.7643192e-10 1.0000000e+00 4.3197456e-21 2.2437588e-20 3.2604250e-31], sum to 1.0000
[2019-03-23 13:44:03,619] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4399
[2019-03-23 13:44:03,625] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.83333333333333, 89.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 214108.1917454251, 214108.1917454248, 72418.21090997373], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 187800.0000, 
sim time next is 188400.0000, 
raw observation next is [13.66666666666667, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 212259.4433789966, 212259.4433789966, 71937.62038282063], 
processed observation next is [0.0, 0.17391304347826086, 0.25757575757575774, 0.9, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07861460865888763, 0.07861460865888763, 0.17545761068980642], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.46634042], dtype=float32), -0.721403]. 
=============================================
[2019-03-23 13:44:06,920] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9999714e-01 2.8285526e-06 6.6879400e-26 6.7082818e-25 4.7562721e-38], sum to 1.0000
[2019-03-23 13:44:06,926] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8996
[2019-03-23 13:44:06,940] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.66666666666667, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5224397557950857, 6.911199999999999, 6.9112, 77.32846344354104, 303881.2118363635, 303881.2118363638, 101470.2591296516], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 237000.0000, 
sim time next is 237600.0000, 
raw observation next is [16.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5176835962435824, 6.911200000000001, 6.9112, 77.32846344354104, 301113.8976105615, 301113.8976105612, 99766.70229029037], 
processed observation next is [0.0, 0.782608695652174, 0.36363636363636365, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3109765660622606, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11152366578168944, 0.11152366578168935, 0.24333342022022042], 
reward next is 0.7567, 
noisyNet noise sample is [array([-0.06934864], dtype=float32), -0.34840196]. 
=============================================
[2019-03-23 13:44:07,158] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9998891e-01 1.1132092e-05 5.4448391e-30 2.6069994e-28 0.0000000e+00], sum to 1.0000
[2019-03-23 13:44:07,161] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9135
[2019-03-23 13:44:07,166] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4486568214501341, 6.9112, 6.9112, 77.32846344354104, 260953.271474756, 260953.271474756, 84700.07637675917], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 255000.0000, 
sim time next is 255600.0000, 
raw observation next is [15.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4490387078209727, 6.9112, 6.9112, 77.32846344354104, 261175.4485374042, 261175.4485374042, 84713.76826193585], 
processed observation next is [0.0, 1.0, 0.3181818181818182, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.21291243974424676, 0.0, 0.0, 0.5084288129206541, 0.09673164760644601, 0.09673164760644601, 0.20661894698033134], 
reward next is 0.7934, 
noisyNet noise sample is [array([-0.8194129], dtype=float32), -0.84374774]. 
=============================================
[2019-03-23 13:44:08,672] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.8239680e-09 1.9357335e-26 1.1469979e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 13:44:08,678] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4879
[2019-03-23 13:44:08,684] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.16666666666667, 99.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4099744748618175, 6.9112, 6.9112, 77.32846344354104, 238448.8565315725, 238448.8565315725, 78830.5376798298], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 285000.0000, 
sim time next is 285600.0000, 
raw observation next is [14.33333333333333, 98.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4123772010363696, 6.9112, 6.9112, 77.32846344354104, 239846.6717723987, 239846.6717723987, 79529.68268383137], 
processed observation next is [0.0, 0.30434782608695654, 0.28787878787878773, 0.98, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.16053885862338518, 0.0, 0.0, 0.5084288129206541, 0.08883210065644397, 0.08883210065644397, 0.19397483581422287], 
reward next is 0.8060, 
noisyNet noise sample is [array([0.9091542], dtype=float32), -0.079807736]. 
=============================================
[2019-03-23 13:44:09,018] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.6810080e-08 2.2195959e-30 9.9653465e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 13:44:09,029] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8184
[2019-03-23 13:44:09,033] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3699223118150272, 6.9112, 6.9112, 77.32846344354104, 215148.6140267725, 215148.6140267725, 71016.12053056921], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 277200.0000, 
sim time next is 277800.0000, 
raw observation next is [14.0, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3777746055448704, 6.911199999999999, 6.9112, 77.32846344354104, 219716.5776817505, 219716.5776817508, 72158.8951292718], 
processed observation next is [0.0, 0.21739130434782608, 0.2727272727272727, 0.95, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1111065793498149, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08137651025250019, 0.0813765102525003, 0.17599730519334586], 
reward next is 0.8240, 
noisyNet noise sample is [array([-1.4484833], dtype=float32), 0.262927]. 
=============================================
[2019-03-23 13:44:11,005] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.999993e-01 6.813934e-07 9.711252e-28 1.652785e-26 0.000000e+00], sum to 1.0000
[2019-03-23 13:44:11,012] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9350
[2019-03-23 13:44:11,016] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 43.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.495138854013188, 6.9112, 6.9112, 77.32846344354104, 287996.7247408383, 287996.7247408383, 87485.53599702464], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 313200.0000, 
sim time next is 313800.0000, 
raw observation next is [22.16666666666667, 42.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4984436115743925, 6.911200000000001, 6.9112, 77.32846344354104, 289919.5046458542, 289919.5046458539, 88365.59358972416], 
processed observation next is [0.0, 0.6521739130434783, 0.6439393939393941, 0.4266666666666667, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2834908736777036, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10737759431327933, 0.10737759431327921, 0.21552583802371747], 
reward next is 0.7845, 
noisyNet noise sample is [array([0.6138981], dtype=float32), 1.6962776]. 
=============================================
[2019-03-23 13:44:11,498] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9998856e-01 1.1408127e-05 8.9812064e-28 8.0119153e-28 0.0000000e+00], sum to 1.0000
[2019-03-23 13:44:11,504] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4429
[2019-03-23 13:44:11,508] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.83333333333334, 59.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3908209246944715, 6.9112, 6.9112, 77.32846344354104, 227306.1888886212, 227306.1888886212, 67009.28669292192], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 335400.0000, 
sim time next is 336000.0000, 
raw observation next is [16.66666666666667, 59.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.387555583289719, 6.911199999999999, 6.9112, 77.32846344354104, 225406.5866796116, 225406.5866796119, 66154.07709663965], 
processed observation next is [0.0, 0.9130434782608695, 0.39393939393939414, 0.59, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1250794046995986, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08348392099244874, 0.08348392099244885, 0.16135140755277963], 
reward next is 0.8386, 
noisyNet noise sample is [array([-0.44488797], dtype=float32), 0.44645536]. 
=============================================
[2019-03-23 13:44:11,521] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[88.317215]
 [88.30472 ]
 [88.27212 ]
 [88.249725]
 [88.21828 ]], R is [[88.26759338]
 [88.22148132]
 [88.17364502]
 [88.12550354]
 [88.07700348]].
[2019-03-23 13:44:13,849] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.1529784e-07 9.9999940e-01 5.9589739e-26 2.0034077e-24 1.5643633e-37], sum to 1.0000
[2019-03-23 13:44:13,855] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9298
[2019-03-23 13:44:13,859] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 68.0, 1.0, 2.0, 0.3005985135564933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 326405.8015128142, 326405.801512814, 85961.99678761537], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 381600.0000, 
sim time next is 382200.0000, 
raw observation next is [17.16666666666667, 65.33333333333334, 1.0, 2.0, 0.2978825625404838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 323455.697139952, 323455.6971399517, 85031.4236234208], 
processed observation next is [1.0, 0.43478260869565216, 0.4166666666666669, 0.6533333333333334, 1.0, 1.0, 0.12235320317560472, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11979840634813037, 0.11979840634813026, 0.20739371615468485], 
reward next is 0.7926, 
noisyNet noise sample is [array([0.00399257], dtype=float32), 0.16590272]. 
=============================================
[2019-03-23 13:44:14,427] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.1701184e-04 9.9968302e-01 1.7739677e-23 3.7601071e-22 2.6178506e-35], sum to 1.0000
[2019-03-23 13:44:14,434] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7107
[2019-03-23 13:44:14,439] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 56.0, 1.0, 2.0, 0.3669833770500902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 398519.5439380624, 398519.5439380624, 94215.13369855806], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 399600.0000, 
sim time next is 400200.0000, 
raw observation next is [19.0, 56.66666666666667, 1.0, 2.0, 0.3814802626328043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 414268.9041875168, 414268.9041875168, 96081.3262792755], 
processed observation next is [1.0, 0.6521739130434783, 0.5, 0.5666666666666668, 1.0, 1.0, 0.22685032829100538, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15343292747685808, 0.15343292747685808, 0.23434469824213536], 
reward next is 0.7657, 
noisyNet noise sample is [array([-0.7734369], dtype=float32), 0.37090826]. 
=============================================
[2019-03-23 13:44:15,920] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.9990312e-03 9.9300098e-01 7.0444686e-23 9.6383594e-21 8.3097212e-32], sum to 1.0000
[2019-03-23 13:44:15,928] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4251
[2019-03-23 13:44:15,932] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 72.0, 1.0, 2.0, 0.2134411880630266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 231743.2092218061, 231743.2092218059, 75062.76469372556], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 415800.0000, 
sim time next is 416400.0000, 
raw observation next is [16.0, 72.0, 1.0, 2.0, 0.21429526515936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 232670.7429789252, 232670.7429789255, 75146.91190379756], 
processed observation next is [1.0, 0.8260869565217391, 0.36363636363636365, 0.72, 1.0, 1.0, 0.0178690814492, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08617434925145379, 0.08617434925145388, 0.1832851509848721], 
reward next is 0.8167, 
noisyNet noise sample is [array([-0.60099584], dtype=float32), -0.7631122]. 
=============================================
[2019-03-23 13:44:20,037] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.3581073e-10 1.0000000e+00 1.2039957e-23 4.5867978e-22 8.9483538e-33], sum to 1.0000
[2019-03-23 13:44:20,045] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2119
[2019-03-23 13:44:20,049] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.16666666666667, 93.0, 1.0, 2.0, 0.2214802994809067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 240473.8110155591, 240473.8110155594, 77695.92208119389], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 510600.0000, 
sim time next is 511200.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2200659032811425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 238937.7430740639, 238937.7430740639, 77265.67466179955], 
processed observation next is [1.0, 0.9565217391304348, 0.2727272727272727, 0.94, 1.0, 1.0, 0.025082379101428118, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08849546039780144, 0.08849546039780144, 0.1884528650287794], 
reward next is 0.8115, 
noisyNet noise sample is [array([-0.2042719], dtype=float32), -0.32911366]. 
=============================================
[2019-03-23 13:44:32,026] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.9564554e-03 9.9504280e-01 5.6052848e-08 7.4286186e-07 5.4477624e-11], sum to 1.0000
[2019-03-23 13:44:32,031] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9523
[2019-03-23 13:44:32,036] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1157892.8310715 W.
[2019-03-23 13:44:32,041] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.33333333333334, 57.0, 1.0, 2.0, 0.3400761523994999, 1.0, 2.0, 0.3400761523994999, 1.0, 2.0, 0.6888375513201491, 6.911199999999999, 6.9112, 77.3421103, 1157892.8310715, 1157892.8310715, 275987.7981191892], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 735600.0000, 
sim time next is 736200.0000, 
raw observation next is [27.5, 56.5, 1.0, 2.0, 0.4452751624111672, 1.0, 2.0, 0.4452751624111672, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1012735.663301239, 1012735.663301239, 218487.1079528827], 
processed observation next is [1.0, 0.5217391304347826, 0.8863636363636364, 0.565, 1.0, 1.0, 0.306593953013959, 1.0, 1.0, 0.306593953013959, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3750872827041626, 0.3750872827041626, 0.5328953852509335], 
reward next is 0.4671, 
noisyNet noise sample is [array([0.1575265], dtype=float32), 1.1201463]. 
=============================================
[2019-03-23 13:44:38,449] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 2.6687277e-11 3.7408469e-17 4.1604069e-16 6.6464520e-26], sum to 1.0000
[2019-03-23 13:44:38,454] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9136
[2019-03-23 13:44:38,461] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.16666666666667, 93.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7521897833491172, 7.213630399789596, 6.9112, 77.32758155094696, 529987.9168913399, 431765.8289978348, 132119.8964548235], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 868200.0000, 
sim time next is 868800.0000, 
raw observation next is [19.33333333333334, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7630148882052484, 7.305359960888604, 6.9112, 77.32727747010047, 566153.3291925726, 438140.1992069773, 133245.105115293], 
processed observation next is [0.0, 0.043478260869565216, 0.5151515151515155, 0.92, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6614498402932121, 0.03941599608886044, 0.0, 0.5084210152347608, 0.20968641821947134, 0.16227414785443606, 0.3249880612568122], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3148814], dtype=float32), -1.8698198]. 
=============================================
[2019-03-23 13:44:44,708] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.8335585e-12 1.0000000e+00 1.0112660e-24 3.0950157e-19 1.9133970e-37], sum to 1.0000
[2019-03-23 13:44:44,715] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6348
[2019-03-23 13:44:44,719] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.4352035554142433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 488738.3581778428, 488738.3581778428, 127265.3371222012], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 980400.0000, 
sim time next is 981000.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.502706830734828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 564774.1228476957, 564774.122847696, 133954.3022511934], 
processed observation next is [1.0, 0.34782608695652173, 0.45454545454545453, 1.0, 1.0, 1.0, 0.378383538418535, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20917560105470212, 0.2091756010547022, 0.3267178103687644], 
reward next is 0.6733, 
noisyNet noise sample is [array([-2.58701], dtype=float32), -0.20136882]. 
=============================================
[2019-03-23 13:44:44,732] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[75.9078  ]
 [75.88581 ]
 [75.91263 ]
 [75.950714]
 [75.95742 ]], R is [[75.80833435]
 [75.73985291]
 [75.68157196]
 [75.62436676]
 [75.56570435]].
[2019-03-23 13:44:47,890] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.0307525e-01 7.9692471e-01 6.3765033e-18 5.6021082e-15 6.3557221e-31], sum to 1.0000
[2019-03-23 13:44:47,898] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3936
[2019-03-23 13:44:47,905] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.409834981646832, 6.9112, 6.9112, 77.32846344354104, 238367.7047767387, 238367.7047767387, 72174.75659842306], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1023600.0000, 
sim time next is 1024200.0000, 
raw observation next is [13.0, 100.0, 1.0, 1.0, 0.2194719503185628, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 238292.6974644288, 238292.6974644291, 81414.92060972143], 
processed observation next is [1.0, 0.8695652173913043, 0.22727272727272727, 1.0, 1.0, 0.5, 0.02433993789820347, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08825655461645511, 0.08825655461645522, 0.19857297709688154], 
reward next is 0.8014, 
noisyNet noise sample is [array([1.3186076], dtype=float32), 0.83034474]. 
=============================================
[2019-03-23 13:44:47,980] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 13:44:47,982] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:44:47,983] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:44:47,984] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:44:47,985] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:44:47,986] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:44:47,988] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:44:47,984] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:44:47,989] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:44:47,990] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:44:47,990] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:44:48,019] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run53
[2019-03-23 13:44:48,046] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run53
[2019-03-23 13:44:48,084] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run53
[2019-03-23 13:44:48,085] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run53
[2019-03-23 13:44:48,085] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run53
[2019-03-23 13:45:18,302] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01494183], dtype=float32), -0.46284252]
[2019-03-23 13:45:18,304] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.355749855, 93.08561919, 1.0, 2.0, 0.2041695298640372, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 221664.6032740136, 221664.6032740132, 77716.92474378824]
[2019-03-23 13:45:18,305] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:45:18,308] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.0123310e-07 9.9999952e-01 2.1442127e-20 1.0279592e-16 3.1171289e-31], sampled 0.6557071500943887
[2019-03-23 13:45:36,882] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01494183], dtype=float32), -0.46284252]
[2019-03-23 13:45:36,883] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 100.0, 1.0, 2.0, 0.5134010860295842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 585768.5627337467, 585768.562733747, 143100.863924485]
[2019-03-23 13:45:36,883] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:45:36,887] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.0455111e-09 1.0000000e+00 1.2135101e-20 6.7454084e-17 6.5241964e-32], sampled 0.19980006918138737
[2019-03-23 13:45:50,113] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01494183], dtype=float32), -0.46284252]
[2019-03-23 13:45:50,114] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.45, 81.5, 1.0, 2.0, 0.4979295091491955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 568016.2267638358, 568016.2267638354, 145681.5232358535]
[2019-03-23 13:45:50,115] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:45:50,119] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.4050480e-09 1.0000000e+00 1.2238585e-20 6.8095778e-17 6.6592731e-32], sampled 0.9856489461866649
[2019-03-23 13:46:00,386] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01494183], dtype=float32), -0.46284252]
[2019-03-23 13:46:00,387] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.9, 51.0, 1.0, 2.0, 0.4512769390481609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 510589.3996868288, 510589.3996868288, 135121.374018569]
[2019-03-23 13:46:00,389] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:46:00,393] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.5338830e-09 1.0000000e+00 1.1434279e-20 6.4490481e-17 5.7809995e-32], sampled 0.447662869875012
[2019-03-23 13:46:29,485] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.2364 1683273117.9290 214.0000
[2019-03-23 13:46:29,538] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0881 1773145109.2736 173.0000
[2019-03-23 13:46:29,607] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8601.2273 1705854681.3043 465.0000
[2019-03-23 13:46:29,631] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9064.5960 1656096918.1783 80.0000
[2019-03-23 13:46:29,675] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.4444 1663743408.6107 105.0000
[2019-03-23 13:46:30,691] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1300000, evaluation results [1300000.0, 8513.088130171045, 1773145109.2735505, 173.0, 9064.595992232586, 1656096918.1783414, 80.0, 8857.444398451198, 1663743408.6107142, 105.0, 8601.227306753684, 1705854681.3043094, 465.0, 8575.23641278377, 1683273117.9290264, 214.0]
[2019-03-23 13:46:31,543] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.708192e-07 9.999993e-01 2.818987e-20 5.971132e-16 3.245546e-30], sum to 1.0000
[2019-03-23 13:46:31,550] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8688
[2019-03-23 13:46:31,552] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 94.0, 1.0, 2.0, 0.4627171722405037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 502533.8085797434, 502533.8085797434, 98787.29578845794], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1056000.0000, 
sim time next is 1056600.0000, 
raw observation next is [13.0, 94.0, 1.0, 2.0, 0.4691761297639991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 509552.2333683389, 509552.2333683389, 100010.083905165], 
processed observation next is [1.0, 0.21739130434782608, 0.22727272727272727, 0.94, 1.0, 1.0, 0.3364701622049988, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18872304939568108, 0.18872304939568108, 0.2439270339150366], 
reward next is 0.7561, 
noisyNet noise sample is [array([-0.03575738], dtype=float32), 0.36535802]. 
=============================================
[2019-03-23 13:46:33,113] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.68970888e-07 9.99999642e-01 2.94521567e-20 1.07630213e-16
 1.13815983e-31], sum to 1.0000
[2019-03-23 13:46:33,124] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4268
[2019-03-23 13:46:33,131] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 69.0, 1.0, 2.0, 0.5988447953058884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 671170.7373362853, 671170.737336285, 143636.4371743201], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1086000.0000, 
sim time next is 1086600.0000, 
raw observation next is [21.83333333333334, 69.0, 1.0, 2.0, 0.59084048527951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 663350.2624669801, 663350.2624669805, 143247.8980568724], 
processed observation next is [1.0, 0.5652173913043478, 0.628787878787879, 0.69, 1.0, 1.0, 0.48855060659938754, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24568528239517784, 0.24568528239517795, 0.34938511721188387], 
reward next is 0.6506, 
noisyNet noise sample is [array([-1.3574482], dtype=float32), -0.7971384]. 
=============================================
[2019-03-23 13:46:37,724] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.5484991e-04 9.9964392e-01 1.8920073e-08 1.1484342e-06 6.8032116e-12], sum to 1.0000
[2019-03-23 13:46:37,732] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0675
[2019-03-23 13:46:37,736] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1396661.909645475 W.
[2019-03-23 13:46:37,739] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 65.33333333333333, 1.0, 2.0, 0.414010238414541, 1.0, 2.0, 0.414010238414541, 1.0, 2.0, 0.8362588349535242, 6.9112, 6.9112, 77.3421103, 1396661.909645475, 1396661.909645475, 313465.5457218484], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1174200.0000, 
sim time next is 1174800.0000, 
raw observation next is [27.0, 64.66666666666667, 1.0, 2.0, 0.6145090108167416, 1.0, 2.0, 0.6145090108167416, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1385196.978697932, 1385196.978697933, 265410.736644723], 
processed observation next is [1.0, 0.6086956521739131, 0.8636363636363636, 0.6466666666666667, 1.0, 1.0, 0.5181362635209269, 1.0, 1.0, 0.5181362635209269, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5130359180362711, 0.5130359180362715, 0.6473432601090805], 
reward next is 0.3527, 
noisyNet noise sample is [array([1.0273521], dtype=float32), -1.5909815]. 
=============================================
[2019-03-23 13:46:49,219] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.7028934e-13 1.0000000e+00 2.9933588e-25 1.7990215e-21 9.0045610e-37], sum to 1.0000
[2019-03-23 13:46:49,228] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5679
[2019-03-23 13:46:49,232] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4904671842698733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 559599.3683662912, 559599.3683662912, 140390.6703692838], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1393800.0000, 
sim time next is 1394400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.489766517749625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558799.5579841435, 558799.5579841435, 140310.1909021104], 
processed observation next is [0.0, 0.13043478260869565, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3622081471870312, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20696279925338648, 0.20696279925338648, 0.34221997781002533], 
reward next is 0.6578, 
noisyNet noise sample is [array([-0.5812932], dtype=float32), 0.3733052]. 
=============================================
[2019-03-23 13:46:52,471] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.6564946e-11 1.0000000e+00 1.5733328e-25 4.3071373e-23 2.9968826e-37], sum to 1.0000
[2019-03-23 13:46:52,477] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2876
[2019-03-23 13:46:52,482] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4796548861777623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 547257.3457211268, 547257.3457211268, 139156.5975824313], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1474800.0000, 
sim time next is 1475400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.480243953569103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 547929.7308278588, 547929.7308278588, 139223.4448062532], 
processed observation next is [0.0, 0.043478260869565216, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3503049419613787, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2029369373436514, 0.2029369373436514, 0.3395693775762273], 
reward next is 0.6604, 
noisyNet noise sample is [array([-1.1710646], dtype=float32), -0.92686987]. 
=============================================
[2019-03-23 13:46:53,149] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.1079748e-10 1.0000000e+00 2.3874995e-23 2.1027007e-20 6.8821136e-35], sum to 1.0000
[2019-03-23 13:46:53,160] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9462
[2019-03-23 13:46:53,163] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 98.0, 1.0, 2.0, 0.4888425109474595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 557361.9166576172, 557361.9166576172, 140978.1940865699], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1495200.0000, 
sim time next is 1495800.0000, 
raw observation next is [22.0, 97.0, 1.0, 2.0, 0.4968571669372808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 566134.3073804653, 566134.3073804653, 142336.779502821], 
processed observation next is [0.0, 0.30434782608695654, 0.6363636363636364, 0.97, 1.0, 1.0, 0.371071458671601, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20967937310387605, 0.20967937310387605, 0.3471628768361488], 
reward next is 0.6528, 
noisyNet noise sample is [array([1.1287851], dtype=float32), 0.9603138]. 
=============================================
[2019-03-23 13:46:56,112] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.8419588e-09 1.0000000e+00 4.8600912e-25 1.1982878e-21 1.3492249e-37], sum to 1.0000
[2019-03-23 13:46:56,116] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3337
[2019-03-23 13:46:56,122] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.5, 91.0, 1.0, 2.0, 0.4384379172198824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476152.4194818587, 476152.4194818587, 94518.8340625178], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1837800.0000, 
sim time next is 1838400.0000, 
raw observation next is [13.0, 88.0, 1.0, 2.0, 0.4434670359627658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 481616.8492606614, 481616.8492606617, 95526.92839380637], 
processed observation next is [1.0, 0.2608695652173913, 0.22727272727272727, 0.88, 1.0, 1.0, 0.30433379495345725, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.178376610837282, 0.1783766108372821, 0.23299250827757653], 
reward next is 0.7670, 
noisyNet noise sample is [array([-1.0822257], dtype=float32), -1.932243]. 
=============================================
[2019-03-23 13:47:09,321] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 4.6144354e-16 1.3176826e-31 1.4509025e-28 0.0000000e+00], sum to 1.0000
[2019-03-23 13:47:09,330] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9259
[2019-03-23 13:47:09,334] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.16666666666667, 45.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5985420606885409, 6.9112, 6.9112, 77.32846344354103, 348162.5645092042, 348162.5645092042, 84016.6700653061], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1775400.0000, 
sim time next is 1776000.0000, 
raw observation next is [18.33333333333334, 45.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.686936547286466, 6.911199999999999, 6.9112, 77.32846344354104, 399601.3836583252, 399601.3836583255, 93077.72751811854], 
processed observation next is [1.0, 0.5652173913043478, 0.46969696969696995, 0.4533333333333334, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5527664961235229, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14800051246604637, 0.14800051246604648, 0.22701884760516716], 
reward next is 0.7730, 
noisyNet noise sample is [array([0.42893296], dtype=float32), -0.0126935905]. 
=============================================
[2019-03-23 13:47:09,351] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[70.32787]
 [70.25123]
 [70.24133]
 [70.18751]
 [70.01618]], R is [[70.30023193]
 [70.3923111 ]
 [70.48290253]
 [70.57506561]
 [70.6673584 ]].
[2019-03-23 13:47:11,961] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 2.6421416e-08 6.8171466e-23 3.9982829e-21 8.7723425e-38], sum to 1.0000
[2019-03-23 13:47:11,973] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8951
[2019-03-23 13:47:11,980] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 48.66666666666667, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 495435.1874975358, 495435.1874975361, 184436.6746366357], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1858800.0000, 
sim time next is 1859400.0000, 
raw observation next is [22.0, 48.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7174111978495596, 7.00057368991649, 6.9112, 77.32817935588838, 445987.1318047597, 416960.491965808, 109827.2213058278], 
processed observation next is [1.0, 0.5217391304347826, 0.6363636363636364, 0.48, 0.0, 0.5, -0.25, 0.0, 0.5, -0.25, 1.0, 1.0, 0.5963017112136567, 0.008937368991649031, 0.0, 0.5084269450657715, 0.16518041918694804, 0.15442981183918814, 0.2678712714776288], 
reward next is 0.2853, 
noisyNet noise sample is [array([2.2723746], dtype=float32), 1.1069777]. 
=============================================
[2019-03-23 13:47:13,748] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.5719243e-16 3.2055809e-24 1.5266342e-22 2.1328487e-36], sum to 1.0000
[2019-03-23 13:47:13,756] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1860
[2019-03-23 13:47:13,764] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 575195.1451141459 W.
[2019-03-23 13:47:13,770] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.33333333333334, 47.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7557925455038702, 7.328293355405824, 6.9112, 77.32739177772693, 575195.1451141459, 439733.6316484638, 120769.4555554636], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1862400.0000, 
sim time next is 1863000.0000, 
raw observation next is [22.5, 48.0, 1.0, 1.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3319402806137144, 6.911199999999999, 6.9112, 77.3421103, 576930.4255085876, 576930.4255085879, 195219.2313442647], 
processed observation next is [1.0, 0.5652173913043478, 0.6590909090909091, 0.48, 1.0, 0.5, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.04562897230530629, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.21367793537355098, 0.21367793537355106, 0.47614446669332855], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.363715], dtype=float32), 0.18533152]. 
=============================================
[2019-03-23 13:47:13,786] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[44.03166 ]
 [43.736378]
 [43.24001 ]
 [42.87351 ]
 [41.543617]], R is [[41.01412582]
 [40.60398483]
 [40.19794464]
 [39.7959671 ]
 [39.39800644]].
[2019-03-23 13:47:14,763] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 5.6661924e-20 2.3890807e-34 4.5946948e-30 0.0000000e+00], sum to 1.0000
[2019-03-23 13:47:14,768] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4439
[2019-03-23 13:47:14,771] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.0, 64.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4956558197641569, 6.9112, 6.9112, 77.32846344354104, 288297.5061692973, 288297.5061692973, 91383.69122664946], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1895400.0000, 
sim time next is 1896000.0000, 
raw observation next is [19.0, 64.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4947772615280412, 6.911199999999998, 6.9112, 77.32846344354104, 287786.3428212563, 287786.3428212569, 91341.66327158506], 
processed observation next is [1.0, 0.9565217391304348, 0.5, 0.64, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2782532307543446, -1.7763568394002506e-16, 0.0, 0.5084288129206541, 0.10658753437824307, 0.1065875343782433, 0.2227845445648416], 
reward next is 0.7772, 
noisyNet noise sample is [array([-0.10373944], dtype=float32), -0.775347]. 
=============================================
[2019-03-23 13:47:14,790] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[71.60739 ]
 [71.61891 ]
 [71.61551 ]
 [71.598495]
 [71.53457 ]], R is [[71.64977264]
 [71.71038818]
 [71.77073669]
 [71.83112335]
 [71.89096069]].
[2019-03-23 13:47:16,758] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9998987e-01 1.0109675e-05 9.9546348e-18 2.7109950e-15 9.4755686e-28], sum to 1.0000
[2019-03-23 13:47:16,764] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1359
[2019-03-23 13:47:16,771] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1019420.123181273 W.
[2019-03-23 13:47:16,775] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 83.0, 1.0, 2.0, 0.4476174050148859, 1.0, 1.0, 0.4476174050148859, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32844122069208, 1019420.123181273, 1019420.123181273, 218130.0663076602], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1938600.0000, 
sim time next is 1939200.0000, 
raw observation next is [22.66666666666666, 84.66666666666667, 1.0, 2.0, 0.4013270588579604, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8114608085857533, 6.911199999999999, 6.9112, 77.3284633059796, 915703.4510077264, 915703.4510077266, 224114.4049140592], 
processed observation next is [1.0, 0.43478260869565216, 0.6666666666666664, 0.8466666666666667, 1.0, 1.0, 0.25165882357245045, 0.0, 0.5, -0.25, 1.0, 0.5, 0.7306582979796475, -8.881784197001253e-17, 0.0, 0.508428812016198, 0.3391494262991579, 0.339149426299158, 0.5466204997903883], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8081678], dtype=float32), -1.8642493]. 
=============================================
[2019-03-23 13:47:19,163] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 13:47:19,165] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:47:19,169] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:47:19,169] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:47:19,169] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:47:19,171] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:47:19,171] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:47:19,172] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:47:19,172] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:47:19,172] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:47:19,174] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:47:19,191] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run54
[2019-03-23 13:47:19,191] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run54
[2019-03-23 13:47:19,192] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run54
[2019-03-23 13:47:19,258] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run54
[2019-03-23 13:47:19,258] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run54
[2019-03-23 13:47:22,499] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01494183], dtype=float32), -0.46411514]
[2019-03-23 13:47:22,501] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.76666666666667, 50.66666666666667, 1.0, 1.0, 0.2408268532215254, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 261471.7106227656, 261471.7106227652, 82623.5481043638]
[2019-03-23 13:47:22,502] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:47:22,507] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.5338107e-01 7.4661893e-01 3.8713881e-14 3.2080418e-11 8.2315673e-23], sampled 0.0620495858569583
[2019-03-23 13:47:37,890] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01494183], dtype=float32), -0.46411514]
[2019-03-23 13:47:37,891] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.8, 68.0, 1.0, 2.0, 0.8555185122006519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 975500.1817399272, 975500.1817399272, 197982.0548214589]
[2019-03-23 13:47:37,893] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:47:37,895] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.9999976e-01 1.8496173e-07 8.0151716e-16 5.2948819e-14 8.2883219e-25], sampled 0.8190901444928659
[2019-03-23 13:47:37,897] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 975500.1817399272 W.
[2019-03-23 13:48:22,268] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01494183], dtype=float32), -0.46411514]
[2019-03-23 13:48:22,272] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.0142322, 57.28079147, 1.0, 1.0, 0.5385578792950148, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 95.55300702528879, 590567.4769032663, 590567.4769032666, 136511.1091414413]
[2019-03-23 13:48:22,274] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:48:22,276] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.7965756e-01 8.2034236e-01 8.7906800e-14 6.2588039e-11 4.1777246e-22], sampled 0.7120188656215587
[2019-03-23 13:49:00,465] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6195.1574 1677439774.9509 2373.0000
[2019-03-23 13:49:00,475] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6001.6380 1716775708.9441 2600.0000
[2019-03-23 13:49:00,600] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6264.9765 1670157947.5534 2309.0000
[2019-03-23 13:49:00,636] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6308.1984 1692541860.7418 2200.0000
[2019-03-23 13:49:00,869] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6380.2993 1785476898.4749 1764.0000
[2019-03-23 13:49:01,883] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1325000, evaluation results [1325000.0, 6380.299327583565, 1785476898.4748864, 1764.0, 6264.976499731371, 1670157947.5534492, 2309.0, 6195.157411314495, 1677439774.9508588, 2373.0, 6001.637981298807, 1716775708.9440758, 2600.0, 6308.198356677176, 1692541860.7417877, 2200.0]
[2019-03-23 13:49:07,427] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.0528685e-08 1.0000000e+00 3.5926404e-25 3.5223972e-19 0.0000000e+00], sum to 1.0000
[2019-03-23 13:49:07,441] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3564
[2019-03-23 13:49:07,447] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 90.0, 1.0, 2.0, 0.2043563863869114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221877.1599239327, 221877.1599239324, 74146.01881921983], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2092800.0000, 
sim time next is 2093400.0000, 
raw observation next is [14.0, 91.0, 1.0, 2.0, 0.2075792287084974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 225377.1277029504, 225377.1277029501, 74795.78442021983], 
processed observation next is [0.0, 0.21739130434782608, 0.2727272727272727, 0.91, 1.0, 1.0, 0.009474035885621741, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.083473010260352, 0.08347301026035188, 0.18242874248834107], 
reward next is 0.8176, 
noisyNet noise sample is [array([-1.2159963], dtype=float32), 0.31323296]. 
=============================================
[2019-03-23 13:49:19,443] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 2.7447302e-09 8.8113877e-29 2.1921541e-24 0.0000000e+00], sum to 1.0000
[2019-03-23 13:49:19,453] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3645
[2019-03-23 13:49:19,457] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.0, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4351822193826437, 6.9112, 6.9112, 77.32846344354104, 253113.9691958241, 253113.9691958241, 67896.57132707747], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2329200.0000, 
sim time next is 2329800.0000, 
raw observation next is [16.83333333333334, 54.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4338307428631248, 6.911199999999999, 6.9112, 77.32846344354104, 252327.709315084, 252327.7093150843, 68485.53293890994], 
processed observation next is [1.0, 1.0, 0.40151515151515177, 0.5466666666666667, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1911867755187497, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09345470715373481, 0.09345470715373493, 0.1670378852168535], 
reward next is 0.8330, 
noisyNet noise sample is [array([-0.28478426], dtype=float32), 0.7222985]. 
=============================================
[2019-03-23 13:49:21,146] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9999022e-01 9.8055925e-06 1.4827657e-19 5.8772520e-15 6.2463854e-29], sum to 1.0000
[2019-03-23 13:49:21,155] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9513
[2019-03-23 13:49:21,158] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.0, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3673642318336288, 6.911200000000001, 6.9112, 77.32846344354104, 213660.4955176899, 213660.4955176896, 63012.02456449294], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2340000.0000, 
sim time next is 2340600.0000, 
raw observation next is [13.66666666666667, 78.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4231034601346901, 6.911200000000001, 6.9112, 77.32846344354104, 246086.8527503005, 246086.8527503003, 66024.16061738688], 
processed observation next is [1.0, 0.08695652173913043, 0.25757575757575774, 0.7883333333333334, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.17586208590670013, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09114327879640759, 0.09114327879640752, 0.1610345380911875], 
reward next is 0.8390, 
noisyNet noise sample is [array([0.6036365], dtype=float32), 0.7605705]. 
=============================================
[2019-03-23 13:49:22,191] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9780208e-01 2.1979485e-03 1.7240223e-21 3.5332791e-16 6.6808952e-35], sum to 1.0000
[2019-03-23 13:49:22,198] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4392
[2019-03-23 13:49:22,204] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.2, 76.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.678121247440948, 6.9112, 6.9112, 77.32846344354074, 391600.1388838796, 391600.1388838796, 122481.7834396365], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2679600.0000, 
sim time next is 2680200.0000, 
raw observation next is [20.15, 77.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6820816331270108, 6.9112, 6.9112, 77.32846344354104, 393792.1446941854, 393792.1446941854, 122939.221005529], 
processed observation next is [0.0, 0.0, 0.5522727272727272, 0.775, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5458309044671583, 0.0, 0.0, 0.5084288129206541, 0.14584894247932792, 0.14584894247932792, 0.29985175855007073], 
reward next is 0.7001, 
noisyNet noise sample is [array([0.18237609], dtype=float32), 1.8475622]. 
=============================================
[2019-03-23 13:49:31,895] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.0215806e-11 6.5418391e-25 3.3918121e-20 1.3591017e-37], sum to 1.0000
[2019-03-23 13:49:31,908] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1884
[2019-03-23 13:49:31,914] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 735080.5018482986 W.
[2019-03-23 13:49:31,920] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 51.0, 1.0, 2.0, 0.3325795079490061, 1.0, 1.0, 0.3325795079490061, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 735080.5018482986, 735080.5018482984, 174522.2752098892], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2559000.0000, 
sim time next is 2559600.0000, 
raw observation next is [23.0, 50.0, 1.0, 2.0, 0.6897979440224616, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 757051.3384037816, 757051.3384037816, 148423.5949941589], 
processed observation next is [1.0, 0.6521739130434783, 0.6818181818181818, 0.5, 1.0, 1.0, 0.612247430028077, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2803893845939932, 0.2803893845939932, 0.3620087682784363], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5243053], dtype=float32), 1.4464564]. 
=============================================
[2019-03-23 13:49:39,568] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.6500561e-01 6.3499433e-01 1.0189015e-11 5.0790788e-08 1.0972837e-17], sum to 1.0000
[2019-03-23 13:49:39,579] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8756
[2019-03-23 13:49:39,584] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.21666666666667, 87.5, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7699477170013659, 7.313361405982865, 6.9112, 77.32749944251788, 569308.096514868, 438695.9257477109, 136507.0986857717], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2710200.0000, 
sim time next is 2710800.0000, 
raw observation next is [21.5, 86.0, 1.0, 1.0, 0.4698594884131457, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32822178077569, 535143.1716734301, 535143.1716734299, 135374.5603592704], 
processed observation next is [0.0, 0.391304347826087, 0.6136363636363636, 0.86, 1.0, 0.5, 0.33732436051643205, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084272240062048, 0.198201174693863, 0.19820117469386292, 0.33018185453480586], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.6959032], dtype=float32), -0.3935014]. 
=============================================
[2019-03-23 13:49:39,763] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9941814e-01 5.8184064e-04 8.8677961e-11 1.0622709e-08 1.4513511e-16], sum to 1.0000
[2019-03-23 13:49:39,772] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8796
[2019-03-23 13:49:39,777] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 544986.8824606403 W.
[2019-03-23 13:49:39,781] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 69.0, 1.0, 2.0, 0.2388469525662335, 0.0, 1.0, 0.0, 1.0, 2.0, 0.4824519236898717, 6.911199999999999, 6.9112, 77.32846344354104, 544986.8824606403, 544986.8824606406, 175314.6849186016], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2728800.0000, 
sim time next is 2729400.0000, 
raw observation next is [25.0, 68.33333333333333, 1.0, 2.0, 0.4740133347747719, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 540887.6297973342, 540887.6297973342, 137947.5927195576], 
processed observation next is [0.0, 0.6086956521739131, 0.7727272727272727, 0.6833333333333332, 1.0, 1.0, 0.34251666846846485, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20032875177679044, 0.20032875177679044, 0.3364575432184332], 
reward next is 0.6635, 
noisyNet noise sample is [array([0.15090388], dtype=float32), -1.8418279]. 
=============================================
[2019-03-23 13:49:40,195] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.9976379e-01 2.3614435e-04 7.0168982e-10 7.6774697e-08 4.6039777e-15], sum to 1.0000
[2019-03-23 13:49:40,202] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7605
[2019-03-23 13:49:40,206] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.66666666666667, 52.00000000000001, 1.0, 1.0, 0.4612273179890536, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32820470216186, 524709.1416507476, 524709.1416507476, 133847.537973954], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2740800.0000, 
sim time next is 2741400.0000, 
raw observation next is [26.5, 52.5, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7681528743258222, 7.303601937392382, 6.9112, 77.32749275046476, 565460.3020895185, 438017.778619812, 136048.5433595942], 
processed observation next is [0.0, 0.7391304347826086, 0.8409090909090909, 0.525, 0.0, 0.5, -0.25, 0.0, 1.0, -0.25, 1.0, 0.5, 0.6687898204654604, 0.03924019373923819, 0.0, 0.5084224306869137, 0.20942974151463647, 0.16222880689622665, 0.3318257155112053], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.4969511], dtype=float32), 1.7806972]. 
=============================================
[2019-03-23 13:49:45,174] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0745503e-03 9.9892300e-01 1.6359436e-08 2.4202689e-06 3.7561139e-12], sum to 1.0000
[2019-03-23 13:49:45,186] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1639
[2019-03-23 13:49:45,194] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1467377.703444388 W.
[2019-03-23 13:49:45,201] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.16666666666667, 57.0, 1.0, 2.0, 0.8081790954480239, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9767050971623596, 6.9112, 6.9112, 77.32846344354087, 1467377.703444388, 1467377.703444388, 308749.3007200991], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2815800.0000, 
sim time next is 2816400.0000, 
raw observation next is [28.33333333333334, 56.0, 1.0, 2.0, 0.427851111550354, 1.0, 1.0, 0.427851111550354, 1.0, 2.0, 0.8655131463285075, 6.911199999999999, 6.9112, 77.3421103, 1449500.259675398, 1449500.259675398, 318613.2538624823], 
processed observation next is [1.0, 0.6086956521739131, 0.9242424242424245, 0.56, 1.0, 1.0, 0.28481388943794245, 1.0, 0.5, 0.28481388943794245, 1.0, 1.0, 0.8078759233264393, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5368519480279252, 0.5368519480279252, 0.7771054972255667], 
reward next is 0.2229, 
noisyNet noise sample is [array([0.34804937], dtype=float32), -2.111168]. 
=============================================
[2019-03-23 13:49:47,444] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.8077492e-02 9.6192253e-01 5.1080370e-21 3.8633007e-14 2.6249417e-29], sum to 1.0000
[2019-03-23 13:49:47,449] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0994
[2019-03-23 13:49:47,452] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 80.5, 1.0, 2.0, 0.4778307976591012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 545205.3448756548, 545205.3448756544, 137998.4399626691], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2849400.0000, 
sim time next is 2850000.0000, 
raw observation next is [23.0, 79.66666666666667, 1.0, 2.0, 0.4730715053908062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 539710.0485056804, 539710.0485056808, 137223.6590833212], 
processed observation next is [1.0, 1.0, 0.6818181818181818, 0.7966666666666667, 1.0, 1.0, 0.34133938173850775, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19989261055765942, 0.19989261055765953, 0.3346918514227346], 
reward next is 0.6653, 
noisyNet noise sample is [array([3.3377182], dtype=float32), 0.72638416]. 
=============================================
[2019-03-23 13:49:47,463] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[60.907455]
 [60.928535]
 [60.931232]
 [60.94436 ]
 [61.185772]], R is [[60.95955276]
 [61.01337433]
 [61.06485748]
 [61.11421967]
 [61.16190338]].
[2019-03-23 13:49:50,362] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 13:49:50,365] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:49:50,366] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:49:50,367] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:49:50,368] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:49:50,369] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:49:50,369] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:49:50,370] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:49:50,371] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:49:50,371] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:49:50,372] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:49:50,398] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run55
[2019-03-23 13:49:50,399] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run55
[2019-03-23 13:49:50,447] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run55
[2019-03-23 13:49:50,448] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run55
[2019-03-23 13:49:50,508] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run55
[2019-03-23 13:50:00,898] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01494183], dtype=float32), -0.4703173]
[2019-03-23 13:50:00,900] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [13.3, 73.33333333333334, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.6065017008792506, 6.9112, 6.9112, 71.57718169551335, 353154.39815422, 353154.39815422, 72223.48120145654]
[2019-03-23 13:50:00,901] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:50:00,904] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.20238318e-02 9.47976172e-01 4.16508031e-19 1.02858775e-13
 4.95249563e-28], sampled 0.7707047535585695
[2019-03-23 13:50:25,250] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01494183], dtype=float32), -0.4703173]
[2019-03-23 13:50:25,252] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.33366819166667, 100.0, 1.0, 2.0, 0.2286609161332597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 248260.1219505908, 248260.1219505905, 82254.14440189973]
[2019-03-23 13:50:25,254] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:50:25,256] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.3141079e-01 6.8589196e-02 9.0269776e-19 9.3232883e-14 6.4290767e-28], sampled 0.6116012141221407
[2019-03-23 13:50:54,279] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01494183], dtype=float32), -0.4703173]
[2019-03-23 13:50:54,281] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.33616521, 74.32678783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3794370231224231, 6.9112, 6.9112, 95.55338769695034, 220688.511284088, 220688.511284088, 67709.26354479154]
[2019-03-23 13:50:54,284] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:50:54,289] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.0773174e-01 5.9226823e-01 3.0216591e-20 1.4822643e-14 4.6007303e-30], sampled 0.09454007417131438
[2019-03-23 13:51:17,979] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01494183], dtype=float32), -0.4703173]
[2019-03-23 13:51:17,979] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.63333333333333, 89.0, 1.0, 2.0, 0.550982444669249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 614740.6387721668, 614740.6387721668, 137190.9222559921]
[2019-03-23 13:51:17,981] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:51:17,983] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.6313541e-01 8.3686465e-01 9.8444431e-15 1.2908973e-10 9.7868583e-22], sampled 0.9768914619027603
[2019-03-23 13:51:27,276] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01494183], dtype=float32), -0.4703173]
[2019-03-23 13:51:27,276] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.71666666666667, 55.66666666666666, 1.0, 2.0, 0.3278047267758084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 361796.7257673452, 361796.7257673448, 119520.1625351819]
[2019-03-23 13:51:27,279] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:51:27,282] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.7264448e-01 5.2735549e-01 2.2341298e-17 1.5605468e-12 8.1658061e-26], sampled 0.13025644555508886
[2019-03-23 13:51:30,906] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01494183], dtype=float32), -0.4703173]
[2019-03-23 13:51:30,908] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.55, 68.0, 1.0, 2.0, 0.6648600875848696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 750579.6768259121, 750579.6768259117, 158367.3153619443]
[2019-03-23 13:51:30,909] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:51:30,910] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.0926556e-01 7.9073441e-01 7.7404861e-15 1.0758743e-10 5.7923837e-22], sampled 0.8086580521062414
[2019-03-23 13:51:31,285] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6982.3287 1713789117.2726 2109.0000
[2019-03-23 13:51:31,390] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 7207.0182 1667609229.0361 1805.0000
[2019-03-23 13:51:31,555] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 7363.7375 1781510850.0179 1299.0000
[2019-03-23 13:51:31,721] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 7268.9428 1688763864.4428 1649.0000
[2019-03-23 13:51:31,950] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 7249.8449 1672974639.6733 1783.0000
[2019-03-23 13:51:32,966] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1350000, evaluation results [1350000.0, 7363.737461834001, 1781510850.0179322, 1299.0, 7207.018227427149, 1667609229.0360713, 1805.0, 7249.844919539473, 1672974639.6732624, 1783.0, 6982.328695527796, 1713789117.2726283, 2109.0, 7268.942763540033, 1688763864.4428043, 1649.0]
[2019-03-23 13:51:41,909] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.2349593e-01 7.7569687e-01 1.4383404e-07 8.0708065e-04 1.8053107e-12], sum to 1.0000
[2019-03-23 13:51:41,914] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5188
[2019-03-23 13:51:41,919] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1180064.838970375 W.
[2019-03-23 13:51:41,923] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.0, 74.0, 1.0, 2.0, 0.5179907463793896, 1.0, 2.0, 0.5179907463793896, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1180064.838970375, 1180064.838970375, 234456.1997792147], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3073200.0000, 
sim time next is 3073800.0000, 
raw observation next is [24.0, 74.0, 1.0, 2.0, 0.3469553789905809, 1.0, 2.0, 0.3469553789905809, 1.0, 1.0, 0.7027149104290593, 6.911199999999999, 6.9112, 77.3421103, 1184826.766064927, 1184826.766064927, 276577.2167131652], 
processed observation next is [1.0, 0.5652173913043478, 0.7272727272727273, 0.74, 1.0, 1.0, 0.18369422373822608, 1.0, 1.0, 0.18369422373822608, 1.0, 0.5, 0.5753070148986562, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4388247281721952, 0.4388247281721952, 0.6745785773491835], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6311115], dtype=float32), -0.62041986]. 
=============================================
[2019-03-23 13:51:53,090] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.9687049e-11 2.2963344e-30 5.2915207e-18 0.0000000e+00], sum to 1.0000
[2019-03-23 13:51:53,095] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0806
[2019-03-23 13:51:53,098] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4323885712643737, 6.911199999999999, 6.9112, 77.32846344354104, 251488.6863958591, 251488.6863958593, 78616.2291276823], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3303000.0000, 
sim time next is 3303600.0000, 
raw observation next is [15.33333333333333, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4365468044275754, 6.911199999999999, 6.9112, 77.32846344354104, 253907.8566234334, 253907.8566234336, 79745.06809502342], 
processed observation next is [0.0, 0.21739130434782608, 0.3333333333333332, 0.86, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.19506686346796484, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09403994689756794, 0.09403994689756799, 0.19450016608542298], 
reward next is 0.8055, 
noisyNet noise sample is [array([-2.3593187], dtype=float32), 0.0024998232]. 
=============================================
[2019-03-23 13:51:54,514] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 3.7353114e-11 7.4451420e-28 2.3899866e-16 3.1021979e-37], sum to 1.0000
[2019-03-23 13:51:54,520] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8282
[2019-03-23 13:51:54,525] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.83333333333334, 61.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7234575778086483, 6.999239429866789, 6.9112, 77.32812593420634, 445461.121462457, 416867.8401588147, 127756.5159735572], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3352200.0000, 
sim time next is 3352800.0000, 
raw observation next is [22.66666666666667, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7201133014289127, 6.973638280048628, 6.9112, 77.32819708434755, 435367.4233644134, 415088.8169385399, 127290.5690757568], 
processed observation next is [0.0, 0.8260869565217391, 0.6666666666666669, 0.62, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6001618591841611, 0.006243828004862806, 0.0, 0.5084270616290529, 0.16124719383867162, 0.1537365988661259, 0.31046480262379705], 
reward next is 0.3773, 
noisyNet noise sample is [array([-0.1386452], dtype=float32), -0.81158483]. 
=============================================
[2019-03-23 13:51:54,571] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 6.0178262e-10 1.3053024e-28 1.4023762e-17 1.3592929e-38], sum to 1.0000
[2019-03-23 13:51:54,579] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3431
[2019-03-23 13:51:54,582] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.16666666666667, 63.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6891147000340505, 6.9112, 6.9112, 77.3284633239468, 397679.6738509625, 397679.6738509625, 123761.7696717761], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3354600.0000, 
sim time next is 3355200.0000, 
raw observation next is [22.0, 64.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.680417733816795, 6.9112, 6.9112, 77.32846344280075, 392819.5651582034, 392819.5651582034, 122784.9201748388], 
processed observation next is [0.0, 0.8695652173913043, 0.6363636363636364, 0.64, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5434539054525644, 0.0, 0.0, 0.5084288129157868, 0.14548872783637162, 0.14548872783637162, 0.29947541506058245], 
reward next is 0.7005, 
noisyNet noise sample is [array([0.8468485], dtype=float32), -0.13510132]. 
=============================================
[2019-03-23 13:51:55,733] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3886425e-01 8.6078489e-01 8.9586525e-09 3.5086423e-04 3.9417108e-13], sum to 1.0000
[2019-03-23 13:51:55,742] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5904
[2019-03-23 13:51:55,746] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 100.0, 1.0, 1.0, 0.3070475551200073, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 333912.1262077861, 333912.1262077861, 111842.3283003279], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3387600.0000, 
sim time next is 3388200.0000, 
raw observation next is [16.16666666666667, 100.0, 1.0, 2.0, 0.3143527555831769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 342469.4254815449, 342469.4254815452, 112554.4676743466], 
processed observation next is [1.0, 0.21739130434782608, 0.37121212121212144, 1.0, 1.0, 1.0, 0.14294094447897107, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12684052795612774, 0.12684052795612785, 0.27452309188865026], 
reward next is 0.7255, 
noisyNet noise sample is [array([-1.1796893], dtype=float32), 0.491386]. 
=============================================
[2019-03-23 13:52:00,497] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.2881023e-15 3.1581237e-16 1.5162515e-14 1.2494711e-24], sum to 1.0000
[2019-03-23 13:52:00,507] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0899
[2019-03-23 13:52:00,513] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 569669.4179498142 W.
[2019-03-23 13:52:00,518] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4993746128093053, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 569669.4179498142, 569669.4179498142, 141695.3555268653], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3468600.0000, 
sim time next is 3469200.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4915789786504923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560865.4327363514, 560865.4327363514, 140529.3999078126], 
processed observation next is [1.0, 0.13043478260869565, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3644737233131154, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20772793805050052, 0.20772793805050052, 0.34275463392149413], 
reward next is 0.6572, 
noisyNet noise sample is [array([0.6747756], dtype=float32), 0.8690612]. 
=============================================
[2019-03-23 13:52:02,717] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.4674405e-12 7.2185124e-14 1.4648713e-11 1.0737250e-20], sum to 1.0000
[2019-03-23 13:52:02,724] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4377
[2019-03-23 13:52:02,731] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1140618.387551577 W.
[2019-03-23 13:52:02,735] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.5, 91.5, 1.0, 2.0, 0.3357676054130266, 1.0, 2.0, 0.3357676054130266, 1.0, 2.0, 0.6798310882259697, 6.9112, 6.9112, 77.3421103, 1140618.387551577, 1140618.387551577, 275473.4476984807], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3490200.0000, 
sim time next is 3490800.0000, 
raw observation next is [22.66666666666666, 90.66666666666666, 1.0, 2.0, 0.3218373552791349, 1.0, 2.0, 0.3218373552791349, 1.0, 2.0, 0.6515650057743698, 6.911199999999999, 6.9112, 77.3421103, 1092833.843671906, 1092833.843671906, 270135.7584280357], 
processed observation next is [1.0, 0.391304347826087, 0.6666666666666664, 0.9066666666666666, 1.0, 1.0, 0.15229669409891858, 1.0, 1.0, 0.15229669409891858, 1.0, 1.0, 0.5022357225348141, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4047532754340393, 0.4047532754340393, 0.6588677034830139], 
reward next is 0.3411, 
noisyNet noise sample is [array([-0.09534299], dtype=float32), -1.9699124]. 
=============================================
[2019-03-23 13:52:08,676] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 4.3146284e-19 3.6698147e-21 5.0013017e-17 6.6595844e-30], sum to 1.0000
[2019-03-23 13:52:08,682] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2022
[2019-03-23 13:52:08,687] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1670879.153401542 W.
[2019-03-23 13:52:08,691] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 74.0, 1.0, 2.0, 0.5027756358218388, 1.0, 2.0, 0.4951762548525268, 1.0, 2.0, 0.9865530188920543, 6.9112, 6.9112, 77.3421103, 1670879.153401542, 1670879.153401542, 356202.8904862982], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3592800.0000, 
sim time next is 3593400.0000, 
raw observation next is [27.16666666666666, 73.33333333333334, 1.0, 2.0, 0.4505574561771719, 1.0, 2.0, 0.4505574561771719, 1.0, 2.0, 0.911648690463487, 6.9112, 6.9112, 77.3421103, 1520119.284168737, 1520119.284168737, 332996.364244663], 
processed observation next is [1.0, 0.6086956521739131, 0.871212121212121, 0.7333333333333334, 1.0, 1.0, 0.31319682022146483, 1.0, 1.0, 0.31319682022146483, 1.0, 1.0, 0.8737838435192672, 0.0, 0.0, 0.5085185399722538, 0.5630071422847174, 0.5630071422847174, 0.8121862542552756], 
reward next is 0.1878, 
noisyNet noise sample is [array([0.6876201], dtype=float32), -0.33373898]. 
=============================================
[2019-03-23 13:52:14,677] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 6.2812412e-20 3.1341146e-20 1.3989298e-17 3.1593439e-29], sum to 1.0000
[2019-03-23 13:52:14,687] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9054
[2019-03-23 13:52:14,694] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 591285.4146116201 W.
[2019-03-23 13:52:14,700] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.5, 91.5, 1.0, 2.0, 0.2595797606350114, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5255332097389686, 6.9112, 6.9112, 77.32846344354104, 591285.4146116201, 591285.4146116201, 181870.3133675863], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3717000.0000, 
sim time next is 3717600.0000, 
raw observation next is [22.33333333333334, 92.33333333333334, 1.0, 2.0, 0.2588137657102752, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5238235426074552, 6.911199999999999, 6.9112, 77.32846344354104, 589821.59051095, 589821.5905109502, 181357.8735139811], 
processed observation next is [1.0, 0.0, 0.6515151515151518, 0.9233333333333335, 1.0, 1.0, 0.07351720713784399, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3197479180106504, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21845244092998148, 0.21845244092998156, 0.4423362768633685], 
reward next is 0.5577, 
noisyNet noise sample is [array([-0.53548557], dtype=float32), 0.59058064]. 
=============================================
[2019-03-23 13:52:16,239] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 1.3189780e-19 3.6478596e-21 5.5658780e-17 4.5333222e-31], sum to 1.0000
[2019-03-23 13:52:16,245] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9970
[2019-03-23 13:52:16,255] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 654541.1289874138 W.
[2019-03-23 13:52:16,258] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.0, 93.00000000000001, 1.0, 2.0, 0.286854646987116, 0.0, 2.0, 0.0, 1.0, 1.0, 0.577058987910532, 6.9112, 6.9112, 77.32846344354104, 654541.1289874138, 654541.1289874138, 184857.803997593], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3733800.0000, 
sim time next is 3734400.0000, 
raw observation next is [21.0, 92.0, 1.0, 2.0, 0.2637652768290651, 1.0, 1.0, 0.2637652768290651, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 601982.7834695334, 601982.7834695334, 179079.6247291928], 
processed observation next is [1.0, 0.21739130434782608, 0.5909090909090909, 0.92, 1.0, 1.0, 0.07970659603633135, 1.0, 0.5, 0.07970659603633135, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22295658647019756, 0.22295658647019756, 0.4367795725102263], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.04772709], dtype=float32), -0.38546333]. 
=============================================
[2019-03-23 13:52:16,485] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 6.0014267e-20 3.9573738e-21 1.2824527e-17 2.1471083e-30], sum to 1.0000
[2019-03-23 13:52:16,490] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9534
[2019-03-23 13:52:16,494] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 748368.3572888867 W.
[2019-03-23 13:52:16,500] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 54.0, 1.0, 2.0, 0.3286138798379095, 0.0, 1.0, 0.0, 1.0, 1.0, 0.65707058876208, 6.9112, 6.9112, 77.32846344354104, 748368.3572888867, 748368.3572888867, 193703.2170970942], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3762000.0000, 
sim time next is 3762600.0000, 
raw observation next is [25.16666666666667, 58.83333333333333, 1.0, 2.0, 0.2369596456486971, 1.0, 1.0, 0.2369596456486971, 1.0, 2.0, 0.4760487436066663, 6.911199999999999, 6.9112, 77.3421103, 810903.326237233, 810903.3262372334, 230943.6198931692], 
processed observation next is [1.0, 0.5652173913043478, 0.7803030303030305, 0.5883333333333333, 1.0, 1.0, 0.04619955706087135, 1.0, 0.5, 0.04619955706087135, 1.0, 1.0, 0.25149820515238047, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.30033456527304925, 0.3003345652730494, 0.5632771216906566], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.09678032], dtype=float32), -0.034474]. 
=============================================
[2019-03-23 13:52:21,726] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 13:52:21,731] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:52:21,733] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:52:21,733] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:52:21,734] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:52:21,734] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:52:21,735] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:52:21,733] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:52:21,738] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:52:21,739] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:52:21,735] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:52:21,760] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run56
[2019-03-23 13:52:21,785] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run56
[2019-03-23 13:52:21,810] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run56
[2019-03-23 13:52:21,811] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run56
[2019-03-23 13:52:21,868] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run56
[2019-03-23 13:52:34,932] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01494183], dtype=float32), -0.47809613]
[2019-03-23 13:52:34,933] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.48333333333333, 42.5, 1.0, 1.0, 0.4424359260307723, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 95.55310155866155, 499486.0898629188, 499486.0898629188, 133613.3935559847]
[2019-03-23 13:52:34,936] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:52:34,941] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0000000e+00 1.2129803e-16 5.7263540e-30 1.4320041e-20 0.0000000e+00], sampled 0.2860485994929076
[2019-03-23 13:52:38,640] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01494183], dtype=float32), -0.47809613]
[2019-03-23 13:52:38,640] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.83333333333333, 92.16666666666667, 1.0, 1.0, 0.4806926908748408, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32812772509929, 545707.0278507962, 545707.0278507962, 134955.5251057963]
[2019-03-23 13:52:38,641] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:52:38,645] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 6.0160308e-19 6.5167902e-30 1.6931345e-21 0.0000000e+00], sampled 0.9341597300046379
[2019-03-23 13:52:38,646] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 545707.0278507962 W.
[2019-03-23 13:52:52,077] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01494183], dtype=float32), -0.47809613]
[2019-03-23 13:52:52,079] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.198074355, 73.91320817, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7669688106238958, 7.636264949214497, 6.9112, 95.55115732516498, 734033.7503784966, 443054.4112383966, 136036.164103952]
[2019-03-23 13:52:52,082] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:52:52,084] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 1.9662955e-15 2.8717036e-29 9.9926959e-20 0.0000000e+00], sampled 0.49357024880918254
[2019-03-23 13:52:52,086] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 734033.7503784966 W.
[2019-03-23 13:52:58,669] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01494183], dtype=float32), -0.47809613]
[2019-03-23 13:52:58,671] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.26666666666667, 47.33333333333334, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7230115057252461, 7.211899512005047, 6.9112, 95.55240830865382, 535398.5237766247, 414721.761069484, 133391.1117889629]
[2019-03-23 13:52:58,672] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:52:58,676] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0000000e+00 4.2315516e-17 6.8891966e-30 1.0056246e-20 0.0000000e+00], sampled 0.18760919338721427
[2019-03-23 13:53:15,440] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01494183], dtype=float32), -0.47809613]
[2019-03-23 13:53:15,441] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.20850951833333, 59.49202676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5773690638924347, 6.9112, 6.9112, 95.55338769695034, 335768.8897950219, 335768.8897950219, 116033.7605015725]
[2019-03-23 13:53:15,442] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:53:15,445] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.00000000e+00 3.11230779e-15 1.49883175e-30 3.69542616e-20
 0.00000000e+00], sampled 0.10941552308165425
[2019-03-23 13:53:29,019] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01494183], dtype=float32), -0.47809613]
[2019-03-23 13:53:29,020] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.963878475, 64.576067735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5754139978263506, 6.911199999999999, 6.9112, 95.55338769695034, 334682.7354649568, 334682.7354649571, 111613.2196950064]
[2019-03-23 13:53:29,021] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:53:29,023] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 1.5135693e-15 1.2503446e-30 2.3886238e-20 0.0000000e+00], sampled 0.1338218292914236
[2019-03-23 13:53:53,622] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01494183], dtype=float32), -0.47809613]
[2019-03-23 13:53:53,623] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.61948715666667, 92.22732378666666, 1.0, 2.0, 0.5133688316974201, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769605694, 568366.067161592, 568366.067161592, 135966.0193713803]
[2019-03-23 13:53:53,624] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 13:53:53,627] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0000000e+00 3.6954335e-16 5.7405074e-29 6.5205291e-20 0.0000000e+00], sampled 0.5323584855613441
[2019-03-23 13:53:53,628] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 568366.067161592 W.
[2019-03-23 13:54:02,864] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6553.1725 1698634175.0084 2957.0000
[2019-03-23 13:54:02,887] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6481.6076 1678885180.2952 3057.0000
[2019-03-23 13:54:03,103] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6862.2842 1793014293.7888 2409.0000
[2019-03-23 13:54:03,194] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6328.7217 1723294598.4314 3425.0000
[2019-03-23 13:54:03,259] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6294.9961 1685630448.6673 3228.0000
[2019-03-23 13:54:04,273] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1375000, evaluation results [1375000.0, 6862.284208925443, 1793014293.78876, 2409.0, 6481.607577760913, 1678885180.2951708, 3057.0, 6294.9960618483565, 1685630448.6673346, 3228.0, 6328.721692698646, 1723294598.4313502, 3425.0, 6553.172466661831, 1698634175.0084193, 2957.0]
[2019-03-23 13:54:09,168] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 4.3391092e-14 5.5233910e-30 1.2047287e-19 0.0000000e+00], sum to 1.0000
[2019-03-23 13:54:09,176] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1363
[2019-03-23 13:54:09,184] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.0, 66.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5629576513297714, 6.911199999999999, 6.9112, 77.32846344354104, 327455.4353379757, 327455.435337976, 109548.4222520861], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3969000.0000, 
sim time next is 3969600.0000, 
raw observation next is [19.66666666666667, 68.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5646235953633759, 6.911199999999999, 6.9112, 77.32846344354104, 328425.6350661683, 328425.6350661686, 109471.240885307], 
processed observation next is [0.0, 0.9565217391304348, 0.5303030303030305, 0.6866666666666668, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.37803370766196565, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12163912409858087, 0.12163912409858096, 0.26700302654952923], 
reward next is 0.7330, 
noisyNet noise sample is [array([0.6428583], dtype=float32), 0.5008986]. 
=============================================
[2019-03-23 13:54:13,000] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.3828067e-16 1.2112322e-24 1.2613089e-17 9.3292683e-33], sum to 1.0000
[2019-03-23 13:54:13,009] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9881
[2019-03-23 13:54:13,019] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 677915.4308351355 W.
[2019-03-23 13:54:13,025] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.3025650752311149, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5889139502236045, 6.9112, 6.9112, 77.32846344354104, 677915.4308351355, 677915.4308351355, 178707.8712248864], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4033800.0000, 
sim time next is 4034400.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.2909095674018151, 1.0, 1.0, 0.2909095674018151, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 654098.1632336036, 654098.1632336036, 173900.0689766975], 
processed observation next is [1.0, 0.6956521739130435, 0.45454545454545453, 0.94, 1.0, 1.0, 0.11363695925226888, 1.0, 0.5, 0.11363695925226888, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24225857897540873, 0.24225857897540873, 0.4241465096992622], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.25819165], dtype=float32), -0.8772674]. 
=============================================
[2019-03-23 13:54:14,468] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 5.1924483e-15 6.3242255e-29 2.2006807e-19 0.0000000e+00], sum to 1.0000
[2019-03-23 13:54:14,472] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8925
[2019-03-23 13:54:14,478] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6548604888968174, 6.911199999999999, 6.9112, 77.32846344354104, 378940.7548002168, 378940.7548002171, 119686.9837791679], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4047000.0000, 
sim time next is 4047600.0000, 
raw observation next is [17.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6531417176112981, 6.911199999999999, 6.9112, 77.32846344354104, 377945.7247698665, 377945.7247698668, 119528.5005406797], 
processed observation next is [1.0, 0.8695652173913043, 0.4090909090909091, 1.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5044881680161403, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13997989806291353, 0.13997989806291364, 0.29153292814799925], 
reward next is 0.7085, 
noisyNet noise sample is [array([-0.95479125], dtype=float32), -0.3243497]. 
=============================================
[2019-03-23 13:54:18,720] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.000000e+00 7.303723e-15 9.511953e-13 8.057450e-12 4.565055e-19], sum to 1.0000
[2019-03-23 13:54:18,727] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3567
[2019-03-23 13:54:18,730] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.08333333333333, 87.66666666666667, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 502337.7067686555, 502337.7067686555, 198531.5579216964], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4416600.0000, 
sim time next is 4417200.0000, 
raw observation next is [21.0, 88.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7754991796383695, 7.346839502906726, 6.9112, 77.32741554451715, 582507.2002154655, 441022.3173661892, 137764.7443354808], 
processed observation next is [0.0, 0.13043478260869565, 0.5909090909090909, 0.88, 0.0, 0.5, -0.25, 0.0, 0.5, -0.25, 1.0, 1.0, 0.6792845423405278, 0.043563950290672615, 0.0, 0.5084219230636332, 0.21574340748720944, 0.16334159902451453, 0.33601157154995315], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7707772], dtype=float32), -0.3435564]. 
=============================================
[2019-03-23 13:54:20,057] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.93295711e-01 5.37522770e-02 1.16124675e-02 6.41261697e-01
 7.78058456e-05], sum to 1.0000
[2019-03-23 13:54:20,064] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5063
[2019-03-23 13:54:20,066] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.0, 94.0, 1.0, 1.0, 0.2, 1.0, 1.0, 0.2, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 382366.4556820476, 382366.4556820474, 151476.2527107709], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4174200.0000, 
sim time next is 4174800.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 382334.9903288567, 382334.9903288564, 151463.9004302173], 
processed observation next is [1.0, 0.30434782608695654, 0.45454545454545453, 0.94, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14160555197365063, 0.14160555197365052, 0.3694241473907739], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.20401931], dtype=float32), -0.28533068]. 
=============================================
[2019-03-23 13:54:24,654] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3802879e-08 1.0000000e+00 5.1959464e-26 3.7407404e-13 4.4765689e-35], sum to 1.0000
[2019-03-23 13:54:24,662] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9062
[2019-03-23 13:54:24,665] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.00000000000001, 1.0, 2.0, 0.3251114337970676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 355764.2018745523, 355764.2018745523, 113860.028921453], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4237800.0000, 
sim time next is 4238400.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3233467958571533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 353783.3540624561, 353783.3540624561, 113716.1826719446], 
processed observation next is [1.0, 0.043478260869565216, 0.4090909090909091, 0.94, 1.0, 1.0, 0.1541834948214416, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13103087187498375, 0.13103087187498375, 0.2773565431023039], 
reward next is 0.7226, 
noisyNet noise sample is [array([0.5028605], dtype=float32), 1.3776997]. 
=============================================
[2019-03-23 13:54:41,012] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6171467e-06 9.9999833e-01 1.6069131e-28 3.7911319e-19 1.4260902e-38], sum to 1.0000
[2019-03-23 13:54:41,018] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9099
[2019-03-23 13:54:41,024] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333333, 70.33333333333334, 1.0, 2.0, 0.3806277383491374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 429504.1920744546, 429504.1920744549, 123451.6922389061], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4545600.0000, 
sim time next is 4546200.0000, 
raw observation next is [22.66666666666667, 69.66666666666666, 1.0, 2.0, 0.3878812418472717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 438551.6346627735, 438551.6346627735, 124597.6792095668], 
processed observation next is [0.0, 0.6086956521739131, 0.6666666666666669, 0.6966666666666665, 1.0, 1.0, 0.23485155230908958, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16242653135658278, 0.16242653135658278, 0.30389677855991903], 
reward next is 0.6961, 
noisyNet noise sample is [array([0.80000633], dtype=float32), 0.58179367]. 
=============================================
[2019-03-23 13:54:45,747] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.7107516e-08 9.9999988e-01 5.6492841e-23 4.7037058e-16 1.0799798e-30], sum to 1.0000
[2019-03-23 13:54:45,756] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0463
[2019-03-23 13:54:45,761] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 58.66666666666667, 1.0, 2.0, 0.2722991093854227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 295667.4670252064, 295667.4670252064, 90456.7191960068], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4652400.0000, 
sim time next is 4653000.0000, 
raw observation next is [19.5, 60.0, 1.0, 2.0, 0.2697692136057032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 292919.63159376, 292919.6315937598, 90481.42442068117], 
processed observation next is [1.0, 0.8695652173913043, 0.5227272727272727, 0.6, 1.0, 1.0, 0.08721151700712901, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10848875244213332, 0.10848875244213327, 0.22068640102605164], 
reward next is 0.7793, 
noisyNet noise sample is [array([0.5755937], dtype=float32), 0.61259615]. 
=============================================
[2019-03-23 13:54:45,777] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[61.292156]
 [61.344578]
 [61.419598]
 [61.380016]
 [61.37907 ]], R is [[61.46959686]
 [61.63427353]
 [61.79732513]
 [61.95877457]
 [62.11283493]].
[2019-03-23 13:54:46,660] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.5572025e-14 1.0000000e+00 2.3957922e-31 4.7267152e-22 0.0000000e+00], sum to 1.0000
[2019-03-23 13:54:46,668] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5230
[2019-03-23 13:54:46,676] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 82.0, 1.0, 2.0, 0.2469945163870566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 268183.6910035915, 268183.6910035918, 83763.32337957884], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4669200.0000, 
sim time next is 4669800.0000, 
raw observation next is [16.0, 82.00000000000001, 1.0, 2.0, 0.245904861658743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 267000.2321787049, 267000.2321787049, 83633.08821628056], 
processed observation next is [1.0, 0.043478260869565216, 0.36363636363636365, 0.8200000000000002, 1.0, 1.0, 0.057381077073428745, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.0988889748810018, 0.0988889748810018, 0.2039831419909282], 
reward next is 0.7960, 
noisyNet noise sample is [array([-0.18267351], dtype=float32), 0.9835038]. 
=============================================
[2019-03-23 13:54:46,849] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.8934940e-12 1.0000000e+00 1.4509863e-27 9.1749917e-20 3.6372836e-37], sum to 1.0000
[2019-03-23 13:54:46,856] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1411
[2019-03-23 13:54:46,861] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3223177634561957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 352872.4165057332, 352872.4165057334, 113720.2672367843], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4942800.0000, 
sim time next is 4943400.0000, 
raw observation next is [16.83333333333334, 95.0, 1.0, 2.0, 0.3441372640831968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 376305.0747595722, 376305.0747595722, 115143.3570224131], 
processed observation next is [1.0, 0.21739130434782608, 0.40151515151515177, 0.95, 1.0, 1.0, 0.18017158010399595, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13937224991095268, 0.13937224991095268, 0.28083745615222705], 
reward next is 0.7192, 
noisyNet noise sample is [array([-0.02211178], dtype=float32), -0.6594066]. 
=============================================
[2019-03-23 13:54:53,729] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 13:54:53,730] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:54:53,732] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:54:53,732] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:54:53,733] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:54:53,734] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:54:53,736] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:54:53,735] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:54:53,737] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:54:53,739] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:54:53,737] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:54:53,757] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run57
[2019-03-23 13:54:53,782] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run57
[2019-03-23 13:54:53,810] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run57
[2019-03-23 13:54:53,811] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run57
[2019-03-23 13:54:53,863] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run57
[2019-03-23 13:55:18,403] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.48439804]
[2019-03-23 13:55:18,403] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.33333333333334, 50.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6784065956059975, 6.9112, 6.9112, 77.32846344354104, 394653.4621224057, 394653.4621224057, 89872.40275311276]
[2019-03-23 13:55:18,404] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 13:55:18,407] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.9485282e-01 1.0514717e-01 2.1595072e-18 9.0539902e-13 5.9917718e-27], sampled 0.7173364848455682
[2019-03-23 13:56:11,257] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.48439804]
[2019-03-23 13:56:11,258] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.51666666666667, 79.0, 1.0, 1.0, 0.2775460351806002, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 301348.6350070191, 301348.6350070187, 106373.1223226644]
[2019-03-23 13:56:11,259] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:56:11,261] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.1339866e-02 9.8866010e-01 2.9405039e-21 1.4905725e-14 4.6503158e-30], sampled 0.8435055021841027
[2019-03-23 13:56:11,474] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.48439804]
[2019-03-23 13:56:11,474] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.9, 78.0, 1.0, 2.0, 0.3155314681976198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 345434.8245742064, 345434.8245742064, 117551.2787252336]
[2019-03-23 13:56:11,474] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 13:56:11,478] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.4339883e-01 5.6601230e-02 5.2521018e-18 1.4266167e-12 1.7920093e-26], sampled 0.9980024736512546
[2019-03-23 13:56:34,898] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6978.2523 1669904943.5135 2048.0000
[2019-03-23 13:56:35,180] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 7081.9443 1689708926.2545 1782.0000
[2019-03-23 13:56:35,349] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 7098.1986 1674270660.1607 1924.0000
[2019-03-23 13:56:35,534] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 7319.4797 1781008334.8472 1273.0000
[2019-03-23 13:56:35,565] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6640.5038 1715253006.6775 2331.0000
[2019-03-23 13:56:36,577] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1400000, evaluation results [1400000.0, 7319.479672870701, 1781008334.8472364, 1273.0, 6978.252290161502, 1669904943.5134933, 2048.0, 7098.1986051024105, 1674270660.1606572, 1924.0, 6640.503753263882, 1715253006.6774905, 2331.0, 7081.944345311156, 1689708926.2545183, 1782.0]
[2019-03-23 13:56:41,527] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.9892942e-07 9.9999964e-01 3.4820424e-23 2.1839657e-16 3.2732096e-31], sum to 1.0000
[2019-03-23 13:56:41,550] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7714
[2019-03-23 13:56:41,554] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.886954844273999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1011448.076831095, 1011448.076831095, 193156.3005196558], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4888800.0000, 
sim time next is 4889400.0000, 
raw observation next is [22.0, 82.16666666666667, 1.0, 2.0, 0.9122416741472431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1040238.859719652, 1040238.859719652, 197318.6827937914], 
processed observation next is [1.0, 0.6086956521739131, 0.6363636363636364, 0.8216666666666668, 1.0, 1.0, 0.8903020926840538, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.38527365174801925, 0.38527365174801925, 0.48126507998485707], 
reward next is 0.5187, 
noisyNet noise sample is [array([0.32358056], dtype=float32), 0.8144083]. 
=============================================
[2019-03-23 13:56:41,892] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.1640113e-06 9.9999678e-01 3.2727408e-22 2.6533286e-16 8.3124321e-31], sum to 1.0000
[2019-03-23 13:56:41,899] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4354
[2019-03-23 13:56:41,904] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 74.66666666666667, 1.0, 2.0, 0.4260505502798739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 484405.2937297414, 484405.2937297414, 130024.2489444241], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4907400.0000, 
sim time next is 4908000.0000, 
raw observation next is [22.33333333333334, 76.33333333333334, 1.0, 2.0, 0.422754148930917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 480434.0143689322, 480434.0143689322, 129509.3809257295], 
processed observation next is [1.0, 0.8260869565217391, 0.6515151515151518, 0.7633333333333334, 1.0, 1.0, 0.2784426861636462, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17793852384034528, 0.17793852384034528, 0.3158765388432427], 
reward next is 0.6841, 
noisyNet noise sample is [array([0.49690896], dtype=float32), -1.9424677]. 
=============================================
[2019-03-23 13:56:41,924] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[60.722473]
 [60.85488 ]
 [60.946377]
 [61.06981 ]
 [61.1176  ]], R is [[60.63557434]
 [60.71208954]
 [60.78710938]
 [60.86149979]
 [60.93505859]].
[2019-03-23 13:56:42,015] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9842298e-01 1.5769829e-03 4.3089418e-19 2.7083200e-13 7.8841039e-27], sum to 1.0000
[2019-03-23 13:56:42,025] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5878
[2019-03-23 13:56:42,032] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.33333333333334, 83.83333333333333, 1.0, 2.0, 0.4590334534385412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846342846675, 523616.6568940183, 523616.656894018, 135496.2773755982], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5181000.0000, 
sim time next is 5181600.0000, 
raw observation next is [22.26666666666667, 83.66666666666667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7941730906475051, 7.488049263151977, 6.9112, 77.32705965540616, 638180.4333746172, 450834.9923621112, 140650.6273985941], 
processed observation next is [0.0, 1.0, 0.6484848484848486, 0.8366666666666667, 0.0, 0.5, -0.25, 0.0, 1.0, -0.25, 1.0, 0.5, 0.7059615580678644, 0.057684926315197685, 0.0, 0.5084195831195792, 0.23636312347208047, 0.16697592309707823, 0.3430503107282783], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7495053], dtype=float32), -0.47294772]. 
=============================================
[2019-03-23 13:56:50,694] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.4165892e-05 9.9995577e-01 2.7281543e-23 7.5375884e-16 5.5983840e-31], sum to 1.0000
[2019-03-23 13:56:50,702] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9252
[2019-03-23 13:56:50,706] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.73333333333333, 56.66666666666667, 1.0, 2.0, 0.4220159346560499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 479832.641665652, 479832.641665652, 129641.4642792418], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5347200.0000, 
sim time next is 5347800.0000, 
raw observation next is [25.55, 58.0, 1.0, 2.0, 0.4266002193183771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 485204.5014636535, 485204.5014636535, 130234.9462516586], 
processed observation next is [1.0, 0.9130434782608695, 0.7977272727272727, 0.58, 1.0, 1.0, 0.2832502741479713, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17970537091246427, 0.17970537091246427, 0.31764621036989904], 
reward next is 0.6824, 
noisyNet noise sample is [array([-1.2711375], dtype=float32), -0.025683219]. 
=============================================
[2019-03-23 13:56:55,919] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.7795824e-05 9.9995220e-01 7.7135747e-23 3.3777270e-15 4.6930507e-31], sum to 1.0000
[2019-03-23 13:56:55,925] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4792
[2019-03-23 13:56:55,930] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 80.5, 1.0, 2.0, 0.4619080028716219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 526997.4702333936, 526997.4702333934, 136116.8585817769], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5171400.0000, 
sim time next is 5172000.0000, 
raw observation next is [23.0, 81.33333333333333, 1.0, 2.0, 0.4662716072978075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 532027.1963674589, 532027.1963674589, 136833.6169174108], 
processed observation next is [0.0, 0.8695652173913043, 0.6818181818181818, 0.8133333333333332, 1.0, 1.0, 0.3328395091222593, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1970471097657255, 0.1970471097657255, 0.33374052906685564], 
reward next is 0.6663, 
noisyNet noise sample is [array([0.45536965], dtype=float32), -0.9069116]. 
=============================================
[2019-03-23 13:56:55,946] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[59.365005]
 [59.37147 ]
 [59.37922 ]
 [59.392643]
 [59.4044  ]], R is [[59.43733215]
 [59.51096725]
 [59.58530807]
 [59.65986252]
 [59.73348999]].
[2019-03-23 13:56:56,863] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.4652958e-07 9.9999940e-01 7.3477231e-25 4.0390007e-19 3.9949592e-35], sum to 1.0000
[2019-03-23 13:56:56,877] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2769
[2019-03-23 13:56:56,883] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4378336890909922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 498831.1369946161, 498831.1369946161, 132252.5528133897], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5190600.0000, 
sim time next is 5191200.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4374253869066658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 498365.5747741654, 498365.5747741654, 132210.5413427456], 
processed observation next is [1.0, 0.08695652173913043, 0.6363636363636364, 0.83, 1.0, 1.0, 0.29678173363333227, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18457984250895015, 0.18457984250895015, 0.3224647349823063], 
reward next is 0.6775, 
noisyNet noise sample is [array([0.10783771], dtype=float32), -1.2834313]. 
=============================================
[2019-03-23 13:56:59,760] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.31256421e-07 9.99999285e-01 3.50097929e-24 7.61308025e-16
 1.20358066e-32], sum to 1.0000
[2019-03-23 13:56:59,771] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1508
[2019-03-23 13:56:59,775] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 100.0, 1.0, 2.0, 0.5091433106194566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 580323.253879287, 580323.2538792868, 143602.2588631997], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5263200.0000, 
sim time next is 5263800.0000, 
raw observation next is [21.43333333333333, 100.0, 1.0, 2.0, 0.5077729129636704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 578833.6500893852, 578833.6500893852, 143353.6001958245], 
processed observation next is [1.0, 0.9565217391304348, 0.6106060606060605, 1.0, 1.0, 1.0, 0.384716141204588, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21438283336643896, 0.21438283336643896, 0.349642927306889], 
reward next is 0.6504, 
noisyNet noise sample is [array([1.365409], dtype=float32), 0.26848593]. 
=============================================
[2019-03-23 13:57:00,258] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.0173809e-06 9.9999797e-01 2.0068707e-23 3.3643881e-17 1.3159619e-31], sum to 1.0000
[2019-03-23 13:57:00,264] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9037
[2019-03-23 13:57:00,269] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.3, 78.0, 1.0, 2.0, 0.3272811312038689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 360478.5514607484, 360478.5514607484, 114880.1570995462], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5281200.0000, 
sim time next is 5281800.0000, 
raw observation next is [19.21666666666667, 80.0, 1.0, 2.0, 0.3640694599360926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 402013.8597260793, 402013.8597260793, 118039.6688491421], 
processed observation next is [1.0, 0.13043478260869565, 0.5098484848484849, 0.8, 1.0, 1.0, 0.2050868249201157, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1488940221207701, 0.1488940221207701, 0.28790163133937097], 
reward next is 0.7121, 
noisyNet noise sample is [array([-0.613199], dtype=float32), 0.3907181]. 
=============================================
[2019-03-23 13:57:04,886] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.6821542e-08 9.9999988e-01 3.2896655e-27 2.3488939e-19 1.6551689e-36], sum to 1.0000
[2019-03-23 13:57:04,890] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4603
[2019-03-23 13:57:04,895] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 73.16666666666667, 1.0, 2.0, 0.4542541373852049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518036.5411738124, 518036.5411738124, 134704.3665189638], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5356200.0000, 
sim time next is 5356800.0000, 
raw observation next is [23.8, 74.0, 1.0, 2.0, 0.4584147193921645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522902.7746323407, 522902.7746323407, 135410.8662569273], 
processed observation next is [1.0, 0.0, 0.7181818181818183, 0.74, 1.0, 1.0, 0.3230183992402056, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19366769430827432, 0.19366769430827432, 0.3302704055047007], 
reward next is 0.6697, 
noisyNet noise sample is [array([2.1358457], dtype=float32), 0.6109247]. 
=============================================
[2019-03-23 13:57:10,251] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.5035882e-09 1.0000000e+00 1.1347971e-29 7.1286146e-19 1.7246056e-37], sum to 1.0000
[2019-03-23 13:57:10,260] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6281
[2019-03-23 13:57:10,263] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 92.0, 1.0, 2.0, 0.3295657894598234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 360245.6699801909, 360245.6699801909, 114040.1667386363], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5466000.0000, 
sim time next is 5466600.0000, 
raw observation next is [17.2, 93.0, 1.0, 2.0, 0.3332596685183787, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 365048.0657648138, 365048.0657648138, 114578.0097195225], 
processed observation next is [1.0, 0.2608695652173913, 0.41818181818181815, 0.93, 1.0, 1.0, 0.16657458564797334, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13520298732030142, 0.13520298732030142, 0.2794585602915183], 
reward next is 0.7205, 
noisyNet noise sample is [array([0.35230947], dtype=float32), -0.83502746]. 
=============================================
[2019-03-23 13:57:12,987] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.5109350e-04 9.9984884e-01 1.1051039e-14 1.4118452e-08 7.9821928e-18], sum to 1.0000
[2019-03-23 13:57:12,992] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8594
[2019-03-23 13:57:12,996] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 72.0, 1.0, 2.0, 0.488759981543264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 557639.0891078191, 557639.0891078194, 140234.7672900624], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5516400.0000, 
sim time next is 5517000.0000, 
raw observation next is [24.7, 72.5, 1.0, 2.0, 0.4896328763170602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558646.8539649968, 558646.8539649968, 140295.3429073463], 
processed observation next is [1.0, 0.8695652173913043, 0.759090909090909, 0.725, 1.0, 1.0, 0.36204109539632523, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20690624220925805, 0.20690624220925805, 0.3421837631886495], 
reward next is 0.6578, 
noisyNet noise sample is [array([-0.7153143], dtype=float32), -0.4790478]. 
=============================================
[2019-03-23 13:57:13,017] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[31.055079]
 [31.431608]
 [33.418064]
 [33.58118 ]
 [34.573975]], R is [[30.43888092]
 [30.79245758]
 [31.14229202]
 [31.48848343]
 [31.83158302]].
[2019-03-23 13:57:14,418] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6657319e-07 9.9999988e-01 1.4850182e-31 4.0113025e-19 4.4154547e-38], sum to 1.0000
[2019-03-23 13:57:14,428] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5252
[2019-03-23 13:57:14,432] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.85, 75.0, 1.0, 2.0, 0.475715878318144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 542807.6085882082, 542807.6085882082, 137861.1512232863], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5520600.0000, 
sim time next is 5521200.0000, 
raw observation next is [23.66666666666667, 75.33333333333333, 1.0, 2.0, 0.4714904823778032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 537925.9790988469, 537925.9790988469, 137122.0285332809], 
processed observation next is [1.0, 0.9130434782608695, 0.7121212121212124, 0.7533333333333333, 1.0, 1.0, 0.33936310297225397, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19923184411068404, 0.19923184411068404, 0.33444397203239246], 
reward next is 0.6656, 
noisyNet noise sample is [array([1.5648974], dtype=float32), -0.66121376]. 
=============================================
[2019-03-23 13:57:16,105] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.04918385e-04 9.99895096e-01 6.20751907e-16 8.87007445e-09
 1.40441247e-18], sum to 1.0000
[2019-03-23 13:57:16,113] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3034
[2019-03-23 13:57:16,122] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.08333333333334, 92.5, 1.0, 2.0, 0.4279802564110227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 485904.5644636375, 485904.5644636375, 129649.9669244974], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5548200.0000, 
sim time next is 5548800.0000, 
raw observation next is [20.16666666666667, 92.0, 1.0, 2.0, 0.4165408001200906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 472974.0394364214, 472974.0394364214, 128585.1290687598], 
processed observation next is [1.0, 0.21739130434782608, 0.5530303030303032, 0.92, 1.0, 1.0, 0.2706760001501132, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17517557016163757, 0.17517557016163757, 0.31362226602136534], 
reward next is 0.6864, 
noisyNet noise sample is [array([-1.8247814], dtype=float32), -1.4926858]. 
=============================================
[2019-03-23 13:57:19,807] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1937509e-07 9.9999988e-01 6.3386125e-31 3.3894645e-16 5.2928671e-35], sum to 1.0000
[2019-03-23 13:57:19,823] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2499
[2019-03-23 13:57:19,826] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.8, 98.0, 1.0, 2.0, 0.3334887827893163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 366772.9087828037, 366772.908782804, 115133.3716332418], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5643600.0000, 
sim time next is 5644200.0000, 
raw observation next is [16.7, 97.5, 1.0, 2.0, 0.3279431783570608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 359649.8988505, 359649.8988504997, 114347.1475445627], 
processed observation next is [0.0, 0.30434782608695654, 0.39545454545454545, 0.975, 1.0, 1.0, 0.15992897294632602, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13320366624092592, 0.1332036662409258, 0.2788954818160066], 
reward next is 0.7211, 
noisyNet noise sample is [array([2.0317552], dtype=float32), -0.18289563]. 
=============================================
[2019-03-23 13:57:23,467] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.0897924e-08 1.0000000e+00 7.4216388e-27 2.0290683e-15 5.3621379e-31], sum to 1.0000
[2019-03-23 13:57:23,475] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0005
[2019-03-23 13:57:23,481] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.0, 78.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 180449.6676127078, 180449.6676127081, 62375.00319456595], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5696400.0000, 
sim time next is 5697000.0000, 
raw observation next is [11.9, 78.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 178829.8871663527, 178829.8871663529, 62074.6551271955], 
processed observation next is [0.0, 0.9565217391304348, 0.17727272727272728, 0.785, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0662332915430936, 0.06623329154309367, 0.15140159787120855], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.22640595], dtype=float32), -0.18613526]. 
=============================================
[2019-03-23 13:57:23,501] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[57.60167 ]
 [57.673927]
 [57.742607]
 [57.814484]
 [57.884174]], R is [[56.94944382]
 [56.37995148]
 [55.81615067]
 [55.25798798]
 [54.70541   ]].
[2019-03-23 13:57:24,848] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 13:57:24,850] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:57:24,851] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:57:24,851] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:57:24,851] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:57:24,852] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:57:24,853] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:57:24,853] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:57:24,857] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:57:24,857] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:57:24,863] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:57:24,882] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run58
[2019-03-23 13:57:24,910] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run58
[2019-03-23 13:57:24,911] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run58
[2019-03-23 13:57:24,934] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run58
[2019-03-23 13:57:24,987] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run58
[2019-03-23 13:57:33,727] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.48280507]
[2019-03-23 13:57:33,728] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.2, 61.0, 1.0, 2.0, 0.3240748902120582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 351882.6365027394, 351882.6365027394, 90088.5333514037]
[2019-03-23 13:57:33,730] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:57:33,734] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.2028933e-02 6.6769838e-01 2.1332780e-05 2.5025102e-01 2.8220913e-07], sampled 0.7954793954718753
[2019-03-23 13:57:35,962] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.48280507]
[2019-03-23 13:57:35,963] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.7, 41.0, 1.0, 2.0, 0.5189538620474432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338675503953, 563582.7362363801, 563582.7362363801, 120618.0436766138]
[2019-03-23 13:57:35,965] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:57:35,969] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.40811455e-01 5.90676814e-02 2.97634850e-09 1.20912635e-04
 2.41167351e-12], sampled 0.7013212846638405
[2019-03-23 13:57:35,970] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 563582.7362363801 W.
[2019-03-23 13:57:49,466] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.48280507]
[2019-03-23 13:57:49,467] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.33333333333334, 61.33333333333334, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5956897827675744, 6.9112, 6.9112, 95.55338769695034, 345563.356944409, 345563.356944409, 118139.9655479481]
[2019-03-23 13:57:49,468] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 13:57:49,471] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.1822954e-02 8.4252900e-01 3.8559419e-06 7.5644150e-02 4.0344574e-08], sampled 0.594388854599106
[2019-03-23 13:58:51,595] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.48280507]
[2019-03-23 13:58:51,597] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [13.5050139, 67.68210949, 1.0, 2.0, 0.2014125259900938, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 218670.8101702995, 218670.8101702995, 72564.77488025409]
[2019-03-23 13:58:51,598] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 13:58:51,600] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.4303084e-02 7.3860675e-01 1.0081994e-05 2.0707998e-01 1.2420237e-07], sampled 0.21440773084081377
[2019-03-23 13:59:06,611] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6165.7169 1702469226.0175 1168.0000
[2019-03-23 13:59:06,862] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6072.1499 1716443340.8728 1066.0000
[2019-03-23 13:59:06,992] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 5716.7436 1752592011.1659 1525.0000
[2019-03-23 13:59:07,044] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 5841.6938 1738763687.3760 1017.0000
[2019-03-23 13:59:07,048] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6125.4443 1817705620.0924 946.0000
[2019-03-23 13:59:08,061] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1425000, evaluation results [1425000.0, 6125.444346422181, 1817705620.092442, 946.0, 6165.716937949943, 1702469226.017477, 1168.0, 6072.149897486472, 1716443340.8728147, 1066.0, 5716.743569756525, 1752592011.1659229, 1525.0, 5841.693759387251, 1738763687.376035, 1017.0]
[2019-03-23 13:59:08,155] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.5536095e-02 9.2547715e-01 7.2500126e-07 1.8986035e-02 9.7635429e-09], sum to 1.0000
[2019-03-23 13:59:08,172] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2979
[2019-03-23 13:59:08,175] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.36666666666667, 54.0, 1.0, 2.0, 0.2126820947372278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 230918.8299947906, 230918.8299947903, 72339.84625748674], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5739600.0000, 
sim time next is 5740200.0000, 
raw observation next is [17.45, 53.0, 1.0, 2.0, 0.2131073388395338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 231380.6470886599, 231380.6470886602, 72397.52970912564], 
processed observation next is [0.0, 0.43478260869565216, 0.4295454545454545, 0.53, 1.0, 1.0, 0.01638417354941725, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08569653595876292, 0.08569653595876303, 0.17657934075396498], 
reward next is 0.8234, 
noisyNet noise sample is [array([-0.5872407], dtype=float32), 0.16560999]. 
=============================================
[2019-03-23 13:59:17,668] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5679562e-09 1.0000000e+00 1.5563307e-27 7.5839373e-13 4.8820584e-31], sum to 1.0000
[2019-03-23 13:59:17,674] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0604
[2019-03-23 13:59:17,682] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1091744.691541041 W.
[2019-03-23 13:59:17,687] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.7, 46.0, 1.0, 2.0, 0.4787255525435692, 0.0, 1.0, 0.0, 1.0, 2.0, 0.933206305117606, 6.957697865356947, 6.9112, 77.32835039825751, 1091744.691541041, 1076643.157995651, 243993.312093048], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5932800.0000, 
sim time next is 5933400.0000, 
raw observation next is [27.61666666666667, 46.16666666666667, 1.0, 2.0, 0.3446554066616176, 1.0, 1.0, 0.3446554066616176, 1.0, 2.0, 0.6943183359306243, 6.911200000000001, 6.9112, 77.3421103, 1180517.232954615, 1180517.232954615, 268301.8726545922], 
processed observation next is [1.0, 0.6956521739130435, 0.8916666666666668, 0.4616666666666667, 1.0, 1.0, 0.18081925832702198, 1.0, 0.5, 0.18081925832702198, 1.0, 1.0, 0.5633119084723205, 8.881784197001253e-17, 0.0, 0.5085185399722538, 0.43722860479800557, 0.43722860479800557, 0.654394811352664], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.97194684], dtype=float32), -1.0667197]. 
=============================================
[2019-03-23 13:59:21,048] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.8065916e-07 9.9999940e-01 1.1916737e-27 1.6363511e-12 2.4071661e-33], sum to 1.0000
[2019-03-23 13:59:21,051] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5547
[2019-03-23 13:59:21,054] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.45, 67.0, 1.0, 2.0, 0.3823334691046923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 430128.3348658252, 430128.3348658252, 122902.8666410573], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5956200.0000, 
sim time next is 5956800.0000, 
raw observation next is [22.36666666666667, 67.33333333333333, 1.0, 2.0, 0.3797133451616082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 427045.0660358286, 427045.0660358286, 122605.7993173715], 
processed observation next is [1.0, 0.9565217391304348, 0.6530303030303032, 0.6733333333333333, 1.0, 1.0, 0.22464168145201024, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1581648392725291, 0.1581648392725291, 0.29903853492041826], 
reward next is 0.7010, 
noisyNet noise sample is [array([-0.4557684], dtype=float32), 0.5092922]. 
=============================================
[2019-03-23 13:59:28,009] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.7073288e-05 9.9994290e-01 7.3072355e-30 1.9748672e-13 1.0187642e-35], sum to 1.0000
[2019-03-23 13:59:28,018] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2552
[2019-03-23 13:59:28,026] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 63.0, 1.0, 2.0, 0.2728139606640939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 296226.6724307628, 296226.6724307628, 93805.4674603494], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6123600.0000, 
sim time next is 6124200.0000, 
raw observation next is [19.3, 63.33333333333333, 1.0, 2.0, 0.2710656806213578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 294327.7817330501, 294327.7817330498, 93098.58440776798], 
processed observation next is [1.0, 0.9130434782608695, 0.5136363636363637, 0.6333333333333333, 1.0, 1.0, 0.0888321007766972, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10901028953075931, 0.10901028953075918, 0.22706971806772677], 
reward next is 0.7729, 
noisyNet noise sample is [array([0.3361927], dtype=float32), 1.1113408]. 
=============================================
[2019-03-23 13:59:29,520] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4415996e-05 9.9998558e-01 5.2897854e-27 3.1461324e-12 7.9856950e-32], sum to 1.0000
[2019-03-23 13:59:29,527] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9314
[2019-03-23 13:59:29,539] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 75.0, 1.0, 2.0, 0.2880317909917877, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 312755.8000494815, 312755.8000494815, 103120.8446124918], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6138000.0000, 
sim time next is 6138600.0000, 
raw observation next is [18.11666666666667, 76.5, 1.0, 2.0, 0.2887854142243096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 313574.3764493893, 313574.376449389, 103374.7318834981], 
processed observation next is [1.0, 0.043478260869565216, 0.459848484848485, 0.765, 1.0, 1.0, 0.11098176778038697, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11613865794421827, 0.11613865794421814, 0.25213349239877586], 
reward next is 0.7479, 
noisyNet noise sample is [array([0.09792363], dtype=float32), 1.2406937]. 
=============================================
[2019-03-23 13:59:29,970] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.9550720e-08 1.0000000e+00 1.6916556e-29 5.8526599e-13 1.3794517e-37], sum to 1.0000
[2019-03-23 13:59:29,971] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3361
[2019-03-23 13:59:29,979] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 84.0, 1.0, 2.0, 0.2807868083412831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 304886.4582011487, 304886.458201149, 102703.7185544112], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6153600.0000, 
sim time next is 6154200.0000, 
raw observation next is [17.2, 84.0, 1.0, 2.0, 0.2804419281063732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 304511.8600008488, 304511.8600008485, 102624.6188872893], 
processed observation next is [1.0, 0.21739130434782608, 0.41818181818181815, 0.84, 1.0, 1.0, 0.10055241013296648, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11278217037068475, 0.11278217037068462, 0.25030394850558363], 
reward next is 0.7497, 
noisyNet noise sample is [array([-0.5236062], dtype=float32), -1.2367722]. 
=============================================
[2019-03-23 13:59:31,990] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3598922e-03 9.9864012e-01 1.4429848e-26 2.1655715e-13 6.5505561e-34], sum to 1.0000
[2019-03-23 13:59:31,997] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5668
[2019-03-23 13:59:32,000] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 57.0, 1.0, 2.0, 0.7725301617661826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 858746.9489750079, 858746.9489750079, 162282.4684391895], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6195600.0000, 
sim time next is 6196200.0000, 
raw observation next is [22.7, 57.0, 1.0, 2.0, 0.4750279709630296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 526744.162036301, 526744.162036301, 128296.3329849911], 
processed observation next is [1.0, 0.7391304347826086, 0.6681818181818181, 0.57, 1.0, 1.0, 0.34378496370378697, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19509043038381518, 0.19509043038381518, 0.3129178853292466], 
reward next is 0.6871, 
noisyNet noise sample is [array([-0.2531529], dtype=float32), 0.47822902]. 
=============================================
[2019-03-23 13:59:32,552] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.259692e-04 9.995740e-01 3.120701e-25 2.205390e-11 8.997075e-32], sum to 1.0000
[2019-03-23 13:59:32,561] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1592
[2019-03-23 13:59:32,565] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 63.0, 1.0, 2.0, 0.7974092338583135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 898733.225115499, 898733.225115499, 171044.4216257751], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6186600.0000, 
sim time next is 6187200.0000, 
raw observation next is [23.1, 62.0, 1.0, 2.0, 0.7976801594589442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 898545.3379758967, 898545.3379758967, 170829.6250690989], 
processed observation next is [1.0, 0.6086956521739131, 0.6863636363636364, 0.62, 1.0, 1.0, 0.7471001993236803, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3327945696207025, 0.3327945696207025, 0.4166576221197534], 
reward next is 0.5833, 
noisyNet noise sample is [array([-0.8863155], dtype=float32), -0.40370658]. 
=============================================
[2019-03-23 13:59:39,157] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.5679983e-04 9.9984312e-01 6.1487658e-26 3.2337245e-12 2.9626519e-32], sum to 1.0000
[2019-03-23 13:59:39,170] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8815
[2019-03-23 13:59:39,175] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 87.0, 1.0, 2.0, 0.4671713808469269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 533052.9212049391, 533052.9212049391, 136921.5853998406], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6327000.0000, 
sim time next is 6327600.0000, 
raw observation next is [22.2, 87.0, 1.0, 2.0, 0.4669439120475695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 532793.1986276763, 532793.1986276763, 136896.44599159], 
processed observation next is [0.0, 0.21739130434782608, 0.6454545454545454, 0.87, 1.0, 1.0, 0.33367989005946186, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1973308143065468, 0.1973308143065468, 0.33389377071119514], 
reward next is 0.6661, 
noisyNet noise sample is [array([0.73759615], dtype=float32), 0.3304737]. 
=============================================
[2019-03-23 13:59:44,258] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.8386166e-06 9.9999821e-01 5.0442961e-29 3.8563242e-15 5.4187527e-33], sum to 1.0000
[2019-03-23 13:59:44,265] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8834
[2019-03-23 13:59:44,270] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 93.0, 1.0, 2.0, 0.813595435827436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 926374.0816118559, 926374.0816118562, 179687.9964832561], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6435600.0000, 
sim time next is 6436200.0000, 
raw observation next is [20.41666666666667, 93.0, 1.0, 2.0, 0.8355350123996518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 951763.7396956108, 951763.7396956108, 183510.7210739334], 
processed observation next is [1.0, 0.4782608695652174, 0.5643939393939396, 0.93, 1.0, 1.0, 0.7944187654995646, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.35250508877615216, 0.35250508877615216, 0.4475871245705693], 
reward next is 0.5524, 
noisyNet noise sample is [array([0.32811138], dtype=float32), 1.0193379]. 
=============================================
[2019-03-23 13:59:47,938] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.2190054e-06 9.9999583e-01 2.3692203e-28 6.9169530e-14 4.0088062e-35], sum to 1.0000
[2019-03-23 13:59:47,949] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6985
[2019-03-23 13:59:47,951] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 52.0, 1.0, 2.0, 0.5132314261096821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 557426.2503531997, 557426.2503531994, 109068.1462380622], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6530400.0000, 
sim time next is 6531000.0000, 
raw observation next is [19.58333333333334, 51.83333333333334, 1.0, 2.0, 0.4776530114824568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518763.5263250472, 518763.5263250472, 105929.3504304951], 
processed observation next is [1.0, 0.6086956521739131, 0.5265151515151518, 0.5183333333333334, 1.0, 1.0, 0.347066264353071, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19213463937964712, 0.19213463937964712, 0.258364269342671], 
reward next is 0.7416, 
noisyNet noise sample is [array([0.01734675], dtype=float32), 0.95762026]. 
=============================================
[2019-03-23 13:59:47,975] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[69.60204]
 [69.56625]
 [69.51141]
 [69.52629]
 [69.58638]], R is [[69.78388977]
 [69.82003021]
 [69.85835266]
 [69.89444733]
 [69.93096924]].
[2019-03-23 13:59:48,343] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1153814e-07 9.9999976e-01 5.3194340e-31 4.8508721e-15 3.4951778e-38], sum to 1.0000
[2019-03-23 13:59:48,353] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7011
[2019-03-23 13:59:48,359] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 51.0, 1.0, 2.0, 0.4990273486575963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 541990.4459981371, 541990.4459981371, 111888.7488547302], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6537000.0000, 
sim time next is 6537600.0000, 
raw observation next is [20.5, 51.0, 1.0, 2.0, 0.5107007127003637, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 554676.046621735, 554676.046621735, 113232.6533263355], 
processed observation next is [1.0, 0.6956521739130435, 0.5681818181818182, 0.51, 1.0, 1.0, 0.38837589087545454, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20543557282286481, 0.20543557282286481, 0.27617720323496464], 
reward next is 0.7238, 
noisyNet noise sample is [array([0.3650012], dtype=float32), -0.8616073]. 
=============================================
[2019-03-23 13:59:53,586] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.3079291e-04 9.9966919e-01 5.3579504e-24 6.0648739e-12 3.0696779e-28], sum to 1.0000
[2019-03-23 13:59:53,593] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9070
[2019-03-23 13:59:53,599] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.43333333333333, 59.0, 1.0, 2.0, 0.6451406158761561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 715665.1998112559, 715665.1998112559, 146051.369148186], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6609000.0000, 
sim time next is 6609600.0000, 
raw observation next is [22.7, 59.0, 1.0, 2.0, 0.6824756810152209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 759851.6174636288, 759851.6174636288, 151461.065748837], 
processed observation next is [1.0, 0.5217391304347826, 0.6681818181818181, 0.59, 1.0, 1.0, 0.6030946012690261, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.28142652498652915, 0.28142652498652915, 0.3694172335337488], 
reward next is 0.6306, 
noisyNet noise sample is [array([-1.3284955], dtype=float32), -0.42705262]. 
=============================================
[2019-03-23 13:59:56,265] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 13:59:56,265] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 13:59:56,268] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 13:59:56,269] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:59:56,270] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 13:59:56,272] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:59:56,278] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 13:59:56,276] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 13:59:56,282] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:59:56,282] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:59:56,279] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 13:59:56,303] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run59
[2019-03-23 13:59:56,329] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run59
[2019-03-23 13:59:56,366] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run59
[2019-03-23 13:59:56,367] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run59
[2019-03-23 13:59:56,412] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run59
[2019-03-23 14:00:20,623] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.49444655]
[2019-03-23 14:00:20,624] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [8.960463656, 85.55981188166666, 1.0, 2.0, 0.3782646968145449, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 410742.3917401322, 410742.3917401318, 87078.69933598126]
[2019-03-23 14:00:20,626] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:00:20,628] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.3005457e-07 9.9999952e-01 2.4644143e-30 3.8673339e-15 1.2433294e-36], sampled 0.91909988678366
[2019-03-23 14:00:21,324] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.49444655]
[2019-03-23 14:00:21,325] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.52549425666666, 52.40278223, 1.0, 2.0, 0.2228980395240264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 242002.0325259905, 242002.0325259901, 76433.49070333819]
[2019-03-23 14:00:21,328] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:00:21,331] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.3166901e-07 9.9999952e-01 1.1071145e-29 8.3251514e-15 8.0870783e-36], sampled 0.14052230606714577
[2019-03-23 14:00:26,368] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.49444655]
[2019-03-23 14:00:26,368] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [13.07713633833333, 84.64764526500001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 206017.3126796212, 206017.3126796212, 73014.5836356997]
[2019-03-23 14:00:26,369] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:00:26,372] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.5953501e-07 9.9999940e-01 1.5341771e-28 3.0513186e-14 2.0735787e-34], sampled 0.3453830758062917
[2019-03-23 14:01:02,176] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.49444655]
[2019-03-23 14:01:02,177] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.8, 87.0, 1.0, 2.0, 0.4703852129799927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 524023.6946335539, 524023.6946335534, 133131.6017586647]
[2019-03-23 14:01:02,178] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:01:02,182] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.7518957e-07 9.9999940e-01 1.4996315e-30 2.9426058e-15 6.3442997e-37], sampled 0.87680570611819
[2019-03-23 14:01:03,678] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.49444655]
[2019-03-23 14:01:03,680] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.3913518, 91.72678871333333, 1.0, 2.0, 0.3414080537823127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 375859.4555451191, 375859.4555451184, 120176.80230402]
[2019-03-23 14:01:03,683] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:01:03,687] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.2799840e-07 9.9999952e-01 3.2243705e-30 4.3613502e-15 1.6760211e-36], sampled 0.22101373176742223
[2019-03-23 14:01:27,304] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.49444655]
[2019-03-23 14:01:27,305] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.797347465, 59.25476099166667, 1.0, 2.0, 0.3677470496300607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 409850.7112856775, 409850.7112856772, 124158.668953553]
[2019-03-23 14:01:27,307] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:01:27,309] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.3189923e-07 9.9999964e-01 5.2697083e-31 1.8116982e-15 1.8884373e-37], sampled 0.9426473722438128
[2019-03-23 14:01:29,648] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.49444655]
[2019-03-23 14:01:29,649] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.38333333333333, 86.5, 1.0, 2.0, 0.4299315285654583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 475381.11365843, 475381.11365843, 128027.4375354566]
[2019-03-23 14:01:29,651] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:01:29,653] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.2600378e-07 9.9999940e-01 4.7944108e-30 5.2678809e-15 2.6691962e-36], sampled 0.9650052255749215
[2019-03-23 14:01:30,695] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.49444655]
[2019-03-23 14:01:30,696] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.398937375, 51.22167879, 1.0, 2.0, 0.3146942355842616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 341694.16470691, 341694.16470691, 116493.4846164966]
[2019-03-23 14:01:30,698] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:01:30,701] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.1169451e-07 9.9999964e-01 1.3301926e-30 2.8490163e-15 5.7836076e-37], sampled 0.8479033460470436
[2019-03-23 14:01:38,023] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:01:38,520] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 14:01:38,575] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 14:01:38,595] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 14:01:38,598] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 14:01:39,612] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1450000, evaluation results [1450000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 14:01:40,720] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.2688652e-06 9.9999475e-01 1.6164376e-27 1.3750428e-13 4.0051682e-33], sum to 1.0000
[2019-03-23 14:01:40,728] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7472
[2019-03-23 14:01:40,736] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.55, 90.0, 1.0, 2.0, 0.5428086919597414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 605815.7290868693, 605815.7290868693, 136414.6589517729], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6690600.0000, 
sim time next is 6691200.0000, 
raw observation next is [18.46666666666667, 91.0, 1.0, 2.0, 0.5379200566376311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 600585.8079747509, 600585.8079747509, 135998.7360822183], 
processed observation next is [1.0, 0.43478260869565216, 0.4757575757575758, 0.91, 1.0, 1.0, 0.42240007079703884, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22243918813879662, 0.22243918813879662, 0.3317042343468739], 
reward next is 0.6683, 
noisyNet noise sample is [array([0.05365834], dtype=float32), -0.65756613]. 
=============================================
[2019-03-23 14:01:40,868] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.1059727e-07 9.9999917e-01 1.7649183e-27 9.2129083e-14 1.1425654e-32], sum to 1.0000
[2019-03-23 14:01:40,876] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1450
[2019-03-23 14:01:40,879] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.6702363632258862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 749887.8932270061, 749887.8932270061, 151484.8962622922], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6710400.0000, 
sim time next is 6711000.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.7107348139008107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 795286.3764351836, 795286.3764351836, 156544.1857780683], 
processed observation next is [1.0, 0.6956521739130435, 0.4681818181818182, 0.93, 1.0, 1.0, 0.6384185173760134, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2945505097908087, 0.2945505097908087, 0.3818150872635812], 
reward next is 0.6182, 
noisyNet noise sample is [array([-1.0143263], dtype=float32), -0.38609102]. 
=============================================
[2019-03-23 14:01:40,893] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[64.49746]
 [64.41951]
 [64.41029]
 [64.42104]
 [64.47159]], R is [[64.45034027]
 [64.43636322]
 [64.4125061 ]
 [64.38933563]
 [64.36899567]].
[2019-03-23 14:01:47,610] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4792039e-08 1.0000000e+00 1.1942477e-31 2.8254743e-17 5.5899930e-37], sum to 1.0000
[2019-03-23 14:01:47,620] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2088
[2019-03-23 14:01:47,626] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.78333333333333, 75.16666666666667, 1.0, 2.0, 0.4003068646311877, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 452674.6514718512, 452674.6514718515, 125770.3538795809], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6821400.0000, 
sim time next is 6822000.0000, 
raw observation next is [21.6, 76.0, 1.0, 2.0, 0.3993626293498188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 451368.4349880773, 451368.4349880773, 125540.7308191262], 
processed observation next is [1.0, 1.0, 0.6181818181818183, 0.76, 1.0, 1.0, 0.24920328668727348, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16717349444002863, 0.16717349444002863, 0.3061969044368932], 
reward next is 0.6938, 
noisyNet noise sample is [array([0.31621185], dtype=float32), 0.61436325]. 
=============================================
[2019-03-23 14:01:47,638] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[68.555786]
 [68.55073 ]
 [68.54397 ]
 [68.53785 ]
 [68.53335 ]], R is [[68.56748199]
 [68.57505035]
 [68.5816803 ]
 [68.58709717]
 [68.59170532]].
[2019-03-23 14:01:51,517] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.2130007e-08 9.9999988e-01 1.6525873e-30 2.3081452e-16 7.4998655e-37], sum to 1.0000
[2019-03-23 14:01:51,522] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6237
[2019-03-23 14:01:51,524] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 73.5, 1.0, 2.0, 0.400985186252394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 453677.3355138682, 453677.3355138685, 125977.2574405846], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6909000.0000, 
sim time next is 6909600.0000, 
raw observation next is [22.0, 74.0, 1.0, 2.0, 0.3995037085007925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 451899.6559121301, 451899.6559121301, 125778.2075790037], 
processed observation next is [0.0, 1.0, 0.6363636363636364, 0.74, 1.0, 1.0, 0.24937963562599058, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16737024293041855, 0.16737024293041855, 0.3067761160463505], 
reward next is 0.6932, 
noisyNet noise sample is [array([-0.93355775], dtype=float32), 0.15820745]. 
=============================================
[2019-03-23 14:01:55,726] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.4637215e-08 1.0000000e+00 7.8166146e-30 4.5169234e-16 8.2607894e-35], sum to 1.0000
[2019-03-23 14:01:55,732] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0575
[2019-03-23 14:01:55,737] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 56.0, 1.0, 2.0, 0.5082284163819534, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 579158.086095728, 579158.086095728, 143623.8581856616], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6966000.0000, 
sim time next is 6966600.0000, 
raw observation next is [28.2, 56.33333333333334, 1.0, 2.0, 0.5095415151416667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 580694.2641760103, 580694.2641760103, 143740.0315757251], 
processed observation next is [0.0, 0.6521739130434783, 0.9181818181818181, 0.5633333333333335, 1.0, 1.0, 0.3869268939270833, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21507194969481863, 0.21507194969481863, 0.35058544286762217], 
reward next is 0.6494, 
noisyNet noise sample is [array([0.6069418], dtype=float32), 0.78439724]. 
=============================================
[2019-03-23 14:01:57,716] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.2949135e-09 1.0000000e+00 3.8492009e-31 1.8091012e-16 3.3325030e-38], sum to 1.0000
[2019-03-23 14:01:57,726] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5358
[2019-03-23 14:01:57,730] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 96.0, 1.0, 2.0, 0.4171159771969333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 472680.6950330479, 472680.6950330479, 127962.3621849736], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7019400.0000, 
sim time next is 7020000.0000, 
raw observation next is [19.4, 96.0, 1.0, 2.0, 0.4156335644639096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 470998.6085970011, 470998.6085970011, 127820.0561424329], 
processed observation next is [1.0, 0.2608695652173913, 0.5181818181818181, 0.96, 1.0, 1.0, 0.26954195557988697, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17444392911000042, 0.17444392911000042, 0.3117562344937388], 
reward next is 0.6882, 
noisyNet noise sample is [array([-0.52452], dtype=float32), 0.95115703]. 
=============================================
[2019-03-23 14:01:57,745] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[68.66123]
 [68.6533 ]
 [68.65421]
 [68.64484]
 [68.63688]], R is [[68.66924286]
 [68.6704483 ]
 [68.67169189]
 [68.67299652]
 [68.67035675]].
[2019-03-23 14:01:57,764] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.9913922e-09 1.0000000e+00 2.0643027e-30 4.9055007e-18 2.7774329e-36], sum to 1.0000
[2019-03-23 14:01:57,769] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4200
[2019-03-23 14:01:57,776] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.63333333333334, 77.0, 1.0, 2.0, 0.4730930639397318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 539825.6496128661, 539825.6496128658, 137668.4572545365], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6992400.0000, 
sim time next is 6993000.0000, 
raw observation next is [23.55, 77.5, 1.0, 2.0, 0.4724695954014746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 539111.6443574842, 539111.6443574845, 137579.5744897374], 
processed observation next is [0.0, 0.9565217391304348, 0.7068181818181819, 0.775, 1.0, 1.0, 0.3405869942518432, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1996709793916608, 0.19967097939166092, 0.33555993777984733], 
reward next is 0.6644, 
noisyNet noise sample is [array([1.4127777], dtype=float32), -0.78310245]. 
=============================================
[2019-03-23 14:01:57,796] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[68.66588 ]
 [68.671875]
 [68.67871 ]
 [68.68225 ]
 [68.68564 ]], R is [[68.63474274]
 [68.61261749]
 [68.5904541 ]
 [68.56806183]
 [68.54498291]].
[2019-03-23 14:02:06,009] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.0649237e-08 1.0000000e+00 4.3053502e-29 3.2186173e-17 1.7583557e-33], sum to 1.0000
[2019-03-23 14:02:06,015] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6657
[2019-03-23 14:02:06,022] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.55, 73.0, 1.0, 2.0, 0.2413622582613274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 262066.6049190946, 262066.6049190943, 80200.1660369734], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7200600.0000, 
sim time next is 7201200.0000, 
raw observation next is [17.0, 71.0, 1.0, 2.0, 0.3158414111672111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 342963.1843867769, 342963.1843867772, 88676.34535079358], 
processed observation next is [1.0, 0.34782608695652173, 0.4090909090909091, 0.71, 1.0, 1.0, 0.14480176395901384, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12702340162473216, 0.1270234016247323, 0.21628376914827702], 
reward next is 0.7837, 
noisyNet noise sample is [array([-0.58690053], dtype=float32), -0.24108574]. 
=============================================
[2019-03-23 14:02:11,089] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.6290270e-09 1.0000000e+00 5.5861490e-32 4.5360033e-16 7.9702034e-38], sum to 1.0000
[2019-03-23 14:02:11,098] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9980
[2019-03-23 14:02:11,105] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.73333333333333, 44.0, 1.0, 2.0, 0.946288603644319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1057946.324428792, 1057946.324428793, 189467.1445150287], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7306800.0000, 
sim time next is 7307400.0000, 
raw observation next is [25.91666666666667, 43.5, 1.0, 2.0, 0.9533343975935962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1066741.732274866, 1066741.732274866, 190982.4908020717], 
processed observation next is [1.0, 0.5652173913043478, 0.8143939393939396, 0.435, 1.0, 1.0, 0.9416679969919952, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3950895304721726, 0.3950895304721726, 0.46581095317578464], 
reward next is 0.5342, 
noisyNet noise sample is [array([1.2800914], dtype=float32), -1.9212812]. 
=============================================
[2019-03-23 14:02:18,472] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.1576608e-08 1.0000000e+00 9.2924268e-20 7.2485236e-13 4.3124148e-23], sum to 1.0000
[2019-03-23 14:02:18,478] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3212
[2019-03-23 14:02:18,483] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1608292.380671382 W.
[2019-03-23 14:02:18,486] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.2, 60.0, 1.0, 2.0, 0.7112227309240235, 1.0, 2.0, 0.7112227309240235, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1608292.380671382, 1608292.380671382, 293332.775220317], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7405200.0000, 
sim time next is 7405800.0000, 
raw observation next is [26.18333333333333, 64.0, 1.0, 2.0, 0.383474686308067, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7763916183511752, 6.9112, 6.9112, 77.32846344354104, 873696.3618861418, 873696.3618861418, 219318.4733341197], 
processed observation next is [1.0, 0.7391304347826086, 0.8265151515151513, 0.64, 1.0, 1.0, 0.22934335788508375, 0.0, 0.5, -0.25, 1.0, 0.5, 0.6805594547873932, 0.0, 0.0, 0.5084288129206541, 0.3235912451430155, 0.3235912451430155, 0.534923105692975], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.73161805], dtype=float32), -0.7363485]. 
=============================================
[2019-03-23 14:02:27,882] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 14:02:27,885] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:02:27,886] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:02:27,887] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:02:27,887] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:02:27,888] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:02:27,889] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:02:27,889] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:02:27,888] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:02:27,890] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:02:27,891] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:02:27,913] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run60
[2019-03-23 14:02:27,940] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run60
[2019-03-23 14:02:27,941] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run60
[2019-03-23 14:02:27,941] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run60
[2019-03-23 14:02:28,003] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run60
[2019-03-23 14:03:05,038] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.494593]
[2019-03-23 14:03:05,039] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.7, 40.0, 1.0, 2.0, 0.3819246461827437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 429423.4638466459, 429423.4638466459, 127067.355004542]
[2019-03-23 14:03:05,042] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:03:05,045] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.3788403e-11 1.0000000e+00 2.1258257e-33 3.8994994e-21 0.0000000e+00], sampled 0.9085931938863138
[2019-03-23 14:03:16,725] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.494593]
[2019-03-23 14:03:16,728] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.58788703, 74.62259427000001, 1.0, 2.0, 0.6283831226679416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 708174.4417408006, 708174.4417408006, 153221.0821088858]
[2019-03-23 14:03:16,729] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:03:16,732] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.5526163e-11 1.0000000e+00 2.0539007e-32 1.6279929e-20 4.7586089e-38], sampled 0.8102563519581724
[2019-03-23 14:03:31,981] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.494593]
[2019-03-23 14:03:31,984] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.83333333333333, 54.66666666666666, 1.0, 2.0, 0.3510810043003462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 386984.0918387604, 386984.0918387604, 121086.5490885305]
[2019-03-23 14:03:31,985] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:03:31,987] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.7058906e-11 1.0000000e+00 2.7152204e-33 4.5037323e-21 0.0000000e+00], sampled 0.29136304837667415
[2019-03-23 14:03:49,792] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.494593]
[2019-03-23 14:03:49,794] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.21666666666667, 79.16666666666667, 1.0, 2.0, 0.3781093935020606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 423176.5376646718, 423176.5376646715, 125795.4611607225]
[2019-03-23 14:03:49,795] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:03:49,798] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.2701025e-11 1.0000000e+00 3.4825306e-33 5.2659190e-21 0.0000000e+00], sampled 0.13947059262981842
[2019-03-23 14:03:59,755] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.494593]
[2019-03-23 14:03:59,758] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.98886841333333, 94.11456132, 1.0, 2.0, 0.5737380468525277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 652563.2550898307, 652563.2550898304, 150641.4684919888]
[2019-03-23 14:03:59,759] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:03:59,760] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5270134e-10 1.0000000e+00 1.5574381e-31 5.9387535e-20 5.3338052e-37], sampled 0.7434185510405987
[2019-03-23 14:04:01,510] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.494593]
[2019-03-23 14:04:01,511] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.99166104, 54.93289399333334, 1.0, 2.0, 0.2676934276959833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 290648.4723337161, 290648.4723337157, 84187.37888891414]
[2019-03-23 14:04:01,511] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:04:01,513] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.6230984e-11 1.0000000e+00 2.3601765e-33 4.1655733e-21 0.0000000e+00], sampled 0.6388756720546074
[2019-03-23 14:04:09,689] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 14:04:09,768] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:04:09,778] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 14:04:09,951] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 14:04:09,975] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 14:04:10,990] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1475000, evaluation results [1475000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 14:04:11,239] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.7937722e-11 1.0000000e+00 2.0454653e-31 7.1165747e-20 0.0000000e+00], sum to 1.0000
[2019-03-23 14:04:11,249] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7979
[2019-03-23 14:04:11,264] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 96.0, 1.0, 2.0, 0.4361318391049388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 496125.616411851, 496125.616411851, 131256.2054072407], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7603200.0000, 
sim time next is 7603800.0000, 
raw observation next is [20.0, 96.0, 1.0, 2.0, 0.4355059958080447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 495402.3814129931, 495402.3814129928, 131183.0339392504], 
processed observation next is [1.0, 0.0, 0.5454545454545454, 0.96, 1.0, 1.0, 0.29438249476005585, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18348236348629374, 0.18348236348629363, 0.31995861936402537], 
reward next is 0.6800, 
noisyNet noise sample is [array([-0.6358189], dtype=float32), 0.6937923]. 
=============================================
[2019-03-23 14:04:14,000] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.1305043e-08 1.0000000e+00 1.0019734e-24 5.3130146e-13 6.2588698e-30], sum to 1.0000
[2019-03-23 14:04:14,006] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6779
[2019-03-23 14:04:14,012] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1216026.458658851 W.
[2019-03-23 14:04:14,016] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.46666666666667, 54.33333333333334, 1.0, 2.0, 0.5870260934546373, 0.0, 1.0, 0.0, 1.0, 2.0, 0.97605020923665, 6.9112, 6.9112, 77.32846344354104, 1216026.458658851, 1216026.458658851, 274684.6095673646], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7658400.0000, 
sim time next is 7659000.0000, 
raw observation next is [28.55, 54.0, 1.0, 2.0, 0.5612567197490093, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9738760124366735, 6.912938227503329, 6.9112, 77.3284591793963, 1187313.712308008, 1186749.171598958, 269829.7510135082], 
processed observation next is [1.0, 0.6521739130434783, 0.9340909090909091, 0.54, 1.0, 1.0, 0.4515708996862615, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9626800177666767, 0.00017382275033286376, 0.0, 0.5084287848842242, 0.4397458193733363, 0.4395367302218363, 0.6581213439353858], 
reward next is 0.3332, 
noisyNet noise sample is [array([0.83515453], dtype=float32), 0.52365935]. 
=============================================
[2019-03-23 14:04:14,034] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[53.53353 ]
 [52.719807]
 [53.33138 ]
 [53.045406]
 [52.119846]], R is [[53.82568359]
 [53.28742599]
 [52.75455093]
 [52.227005  ]
 [51.7047348 ]].
[2019-03-23 14:04:14,832] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.2997592e-08 1.0000000e+00 3.4540053e-26 1.4555092e-13 6.2846066e-32], sum to 1.0000
[2019-03-23 14:04:14,841] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2131
[2019-03-23 14:04:14,844] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.06666666666667, 83.0, 1.0, 2.0, 0.4860405029980224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 554581.4421086087, 554581.4421086083, 139734.5676223674], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7674000.0000, 
sim time next is 7674600.0000, 
raw observation next is [22.88333333333333, 84.0, 1.0, 2.0, 0.4853435127684545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 553801.6111547775, 553801.6111547775, 139563.6858100314], 
processed observation next is [1.0, 0.8260869565217391, 0.6765151515151513, 0.84, 1.0, 1.0, 0.3566793909605681, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20511170783510277, 0.20511170783510277, 0.3403992336830034], 
reward next is 0.6596, 
noisyNet noise sample is [array([0.82513833], dtype=float32), -0.9808059]. 
=============================================
[2019-03-23 14:04:15,681] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:04:15,682] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:04:15,734] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run8
[2019-03-23 14:04:18,119] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1706812e-10 1.0000000e+00 2.0482273e-33 1.5481967e-17 0.0000000e+00], sum to 1.0000
[2019-03-23 14:04:18,131] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3322
[2019-03-23 14:04:18,136] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 57.0, 1.0, 2.0, 0.2634095527107171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 286012.1818046219, 286012.1818046216, 82874.43580390759], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7765200.0000, 
sim time next is 7765800.0000, 
raw observation next is [18.61666666666667, 58.0, 1.0, 2.0, 0.2620948233396426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 284584.2205589421, 284584.2205589418, 82636.52113082484], 
processed observation next is [1.0, 0.9130434782608695, 0.48257575757575777, 0.58, 1.0, 1.0, 0.07761852917455327, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10540156316997856, 0.10540156316997844, 0.2015524905629874], 
reward next is 0.7984, 
noisyNet noise sample is [array([-1.0492167], dtype=float32), -0.5805653]. 
=============================================
[2019-03-23 14:04:21,244] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.1480532e-11 1.0000000e+00 4.8676864e-30 7.6063802e-16 2.3268015e-36], sum to 1.0000
[2019-03-23 14:04:21,250] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8510
[2019-03-23 14:04:21,255] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 45.16666666666666, 1.0, 2.0, 0.6861997191501938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 750143.1150832915, 750143.1150832915, 147050.9495919729], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7827000.0000, 
sim time next is 7827600.0000, 
raw observation next is [24.0, 45.33333333333334, 1.0, 2.0, 0.6271621381716037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 686461.1098702074, 686461.1098702074, 140838.9315818353], 
processed observation next is [1.0, 0.6086956521739131, 0.7272727272727273, 0.4533333333333334, 1.0, 1.0, 0.5339526727145046, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2542448555074842, 0.2542448555074842, 0.3435095892239885], 
reward next is 0.6565, 
noisyNet noise sample is [array([-0.35415176], dtype=float32), -0.69744307]. 
=============================================
[2019-03-23 14:04:27,767] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:04:27,767] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:04:27,982] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run8
[2019-03-23 14:04:28,227] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:04:28,227] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:04:28,236] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run8
[2019-03-23 14:04:28,332] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:04:28,333] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:04:28,335] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run8
[2019-03-23 14:04:28,409] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:04:28,409] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:04:28,415] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run8
[2019-03-23 14:04:28,574] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:04:28,575] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:04:28,578] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run8
[2019-03-23 14:04:28,609] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:04:28,611] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:04:28,617] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run8
[2019-03-23 14:04:28,729] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:04:28,729] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:04:28,733] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run8
[2019-03-23 14:04:28,785] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:04:28,785] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:04:28,794] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run8
[2019-03-23 14:04:28,893] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:04:28,893] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:04:28,896] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run8
[2019-03-23 14:04:28,941] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:04:28,941] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:04:28,945] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run8
[2019-03-23 14:04:28,971] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:04:28,971] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:04:28,975] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run8
[2019-03-23 14:04:29,101] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:04:29,101] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:04:29,104] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run8
[2019-03-23 14:04:29,199] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:04:29,200] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:04:29,203] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run8
[2019-03-23 14:04:29,305] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:04:29,305] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:04:29,308] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run8
[2019-03-23 14:04:29,395] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:04:29,399] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:04:29,432] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run8
[2019-03-23 14:04:31,340] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.0432935e-12 1.0000000e+00 1.3056042e-31 2.2521363e-13 0.0000000e+00], sum to 1.0000
[2019-03-23 14:04:31,347] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5654
[2019-03-23 14:04:31,361] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333334, 100.0, 1.0, 2.0, 0.3476839489630847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 386534.0548766736, 386534.0548766739, 117815.8059404389], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 22800.0000, 
sim time next is 23400.0000, 
raw observation next is [17.5, 100.0, 1.0, 2.0, 0.3517304822575608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 391990.3134290471, 391990.3134290468, 118541.2166372691], 
processed observation next is [1.0, 0.2608695652173913, 0.4318181818181818, 1.0, 1.0, 1.0, 0.189663102821951, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14518159756631374, 0.14518159756631363, 0.2891249186274856], 
reward next is 0.7109, 
noisyNet noise sample is [array([-0.98996663], dtype=float32), -1.1892998]. 
=============================================
[2019-03-23 14:04:32,381] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8343813e-10 1.0000000e+00 8.9849418e-28 8.5184984e-12 5.6923476e-33], sum to 1.0000
[2019-03-23 14:04:32,389] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9140
[2019-03-23 14:04:32,392] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 86.66666666666666, 1.0, 2.0, 0.9045792239539844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344353831, 1028212.92770051, 1028212.92770051, 192589.9180691664], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 56400.0000, 
sim time next is 57000.0000, 
raw observation next is [20.83333333333333, 84.83333333333333, 1.0, 2.0, 0.9180685261511548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354103, 1043198.238140968, 1043198.238140968, 194527.408486087], 
processed observation next is [1.0, 0.6521739130434783, 0.5833333333333331, 0.8483333333333333, 1.0, 1.0, 0.8975856576889435, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.508428812920654, 0.38636971782998814, 0.38636971782998814, 0.4744570938685049], 
reward next is 0.5255, 
noisyNet noise sample is [array([-0.09818003], dtype=float32), -0.18787868]. 
=============================================
[2019-03-23 14:04:32,407] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[62.69203 ]
 [62.703056]
 [62.567432]
 [62.590767]
 [62.389286]], R is [[62.6425209 ]
 [62.54636765]
 [62.45610428]
 [62.37384415]
 [62.17289734]].
[2019-03-23 14:04:36,980] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.7220161e-10 1.0000000e+00 5.4240620e-31 6.1918273e-16 2.6268134e-36], sum to 1.0000
[2019-03-23 14:04:36,990] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0882
[2019-03-23 14:04:36,998] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 39.5, 1.0, 2.0, 0.6923010863515708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 752066.2527857721, 752066.2527857721, 136747.2544038418], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 142200.0000, 
sim time next is 142800.0000, 
raw observation next is [23.0, 39.0, 1.0, 2.0, 0.6723338292170249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 730358.9541540021, 730358.9541540021, 133656.6394845964], 
processed observation next is [1.0, 0.6521739130434783, 0.6818181818181818, 0.39, 1.0, 1.0, 0.5904172865212811, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.27050331635333413, 0.27050331635333413, 0.32599180362096686], 
reward next is 0.6740, 
noisyNet noise sample is [array([-0.18832959], dtype=float32), 0.44656628]. 
=============================================
[2019-03-23 14:04:37,300] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.17553295e-10 1.00000000e+00 1.21641848e-31 1.09050284e-16
 6.49046640e-38], sum to 1.0000
[2019-03-23 14:04:37,308] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6885
[2019-03-23 14:04:37,318] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 39.5, 1.0, 2.0, 0.6923010863515708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 752066.2527857721, 752066.2527857721, 136747.2544038418], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 142200.0000, 
sim time next is 142800.0000, 
raw observation next is [23.0, 39.0, 1.0, 2.0, 0.6723338292170249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 730358.9541540021, 730358.9541540021, 133656.6394845964], 
processed observation next is [1.0, 0.6521739130434783, 0.6818181818181818, 0.39, 1.0, 1.0, 0.5904172865212811, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.27050331635333413, 0.27050331635333413, 0.32599180362096686], 
reward next is 0.6740, 
noisyNet noise sample is [array([0.18272924], dtype=float32), -0.67629397]. 
=============================================
[2019-03-23 14:04:54,656] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.0569585e-09 1.0000000e+00 3.0674227e-31 7.0176977e-18 5.1236817e-37], sum to 1.0000
[2019-03-23 14:04:54,663] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5177
[2019-03-23 14:04:54,667] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 92.0, 1.0, 2.0, 0.3950171694603548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 446675.0952701232, 446675.0952701232, 125276.7800462557], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 800400.0000, 
sim time next is 801000.0000, 
raw observation next is [20.0, 91.0, 1.0, 2.0, 0.4017562483629625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 455092.6761234325, 455092.6761234325, 126396.3004898321], 
processed observation next is [0.0, 0.2608695652173913, 0.5454545454545454, 0.91, 1.0, 1.0, 0.2521953104537031, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1685528430086787, 0.1685528430086787, 0.3082836597312978], 
reward next is 0.6917, 
noisyNet noise sample is [array([-0.9843299], dtype=float32), -0.19118468]. 
=============================================
[2019-03-23 14:04:54,684] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[70.342514]
 [70.23934 ]
 [70.20611 ]
 [70.18575 ]
 [70.201904]], R is [[70.46505737]
 [70.45485687]
 [70.44736481]
 [70.4417038 ]
 [70.43610382]].
[2019-03-23 14:04:55,116] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.5882122e-11 1.0000000e+00 7.6064053e-32 1.0513654e-17 0.0000000e+00], sum to 1.0000
[2019-03-23 14:04:55,124] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8816
[2019-03-23 14:04:55,131] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.3922951742869611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 426018.5145058231, 426018.5145058231, 98448.32050316261], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 468600.0000, 
sim time next is 469200.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.3710343515046918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 402920.4555089363, 402920.455508936, 96527.64996024047], 
processed observation next is [1.0, 0.43478260869565216, 0.2727272727272727, 1.0, 1.0, 1.0, 0.2137929393808647, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14922979833664307, 0.14922979833664296, 0.23543329258595236], 
reward next is 0.7646, 
noisyNet noise sample is [array([0.41846177], dtype=float32), -0.08217376]. 
=============================================
[2019-03-23 14:04:55,580] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.9893596e-11 1.0000000e+00 2.5371746e-34 1.7181862e-19 0.0000000e+00], sum to 1.0000
[2019-03-23 14:04:55,585] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5005
[2019-03-23 14:04:55,590] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.33333333333334, 92.0, 1.0, 2.0, 0.4161077050417683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 451890.0880324716, 451890.0880324719, 105177.1745047302], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 490800.0000, 
sim time next is 491400.0000, 
raw observation next is [15.5, 91.0, 1.0, 2.0, 0.4164467614944541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 452258.4722565571, 452258.4722565574, 105601.9027467257], 
processed observation next is [1.0, 0.6956521739130435, 0.3409090909090909, 0.91, 1.0, 1.0, 0.2705584518680676, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1675031378727989, 0.16750313787279902, 0.2575656164554285], 
reward next is 0.7424, 
noisyNet noise sample is [array([-1.3140395], dtype=float32), 1.0160056]. 
=============================================
[2019-03-23 14:04:59,712] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.89892119e-09 1.00000000e+00 1.05055164e-32 1.21237308e-18
 0.00000000e+00], sum to 1.0000
[2019-03-23 14:04:59,727] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8658
[2019-03-23 14:04:59,732] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 64.83333333333333, 1.0, 2.0, 0.6313628427356152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 696800.9337796195, 696800.9337796195, 143203.5832120972], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 568200.0000, 
sim time next is 568800.0000, 
raw observation next is [21.0, 64.0, 1.0, 2.0, 0.600504341781836, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 661314.3703234686, 661314.3703234689, 139359.4035555972], 
processed observation next is [1.0, 0.6086956521739131, 0.5909090909090909, 0.64, 1.0, 1.0, 0.5006304272272949, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24493124826795132, 0.24493124826795146, 0.33990098428194443], 
reward next is 0.6601, 
noisyNet noise sample is [array([0.01447904], dtype=float32), -1.1061856]. 
=============================================
[2019-03-23 14:05:00,824] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 14:05:00,825] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:05:00,829] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:05:00,831] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:05:00,833] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:05:00,834] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:05:00,835] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:05:00,836] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:05:00,833] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:05:00,836] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:05:00,837] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:05:00,865] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run61
[2019-03-23 14:05:00,887] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run61
[2019-03-23 14:05:00,890] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run61
[2019-03-23 14:05:00,891] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run61
[2019-03-23 14:05:00,913] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run61
[2019-03-23 14:05:16,930] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.5058879]
[2019-03-23 14:05:16,932] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.63864428333333, 72.86632960333334, 1.0, 2.0, 0.3981954619468117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 432392.1930569646, 432392.1930569646, 101945.4376873393]
[2019-03-23 14:05:16,933] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:05:16,935] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.26742089e-09 1.00000000e+00 1.02943175e-30 6.40396158e-18
 1.25902710e-37], sampled 0.22853577308787199
[2019-03-23 14:06:12,832] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.5058879]
[2019-03-23 14:06:12,833] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.29607812333333, 100.0, 1.0, 2.0, 0.6617119192635235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 743529.2032053682, 743529.2032053679, 172091.0364522709]
[2019-03-23 14:06:12,836] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:06:12,839] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.4616556e-08 1.0000000e+00 8.9290626e-31 6.5119099e-18 7.6030750e-38], sampled 0.12179854004867796
[2019-03-23 14:06:18,465] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.5058879]
[2019-03-23 14:06:18,466] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.5, 87.0, 1.0, 2.0, 0.2442024177183899, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 265151.2372891362, 265151.2372891362, 83776.42692844664]
[2019-03-23 14:06:18,467] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:06:18,470] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.5016930e-10 1.0000000e+00 3.7932848e-31 3.2848029e-18 8.4956376e-38], sampled 0.448310870258957
[2019-03-23 14:06:43,378] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 14:06:43,538] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 14:06:43,568] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 14:06:43,569] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:06:43,638] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 14:06:44,652] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1500000, evaluation results [1500000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 14:06:51,739] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.4090155e-10 1.0000000e+00 1.3940531e-28 4.3370588e-17 6.4206406e-34], sum to 1.0000
[2019-03-23 14:06:51,745] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8533
[2019-03-23 14:06:51,755] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1248285.577606333 W.
[2019-03-23 14:06:51,758] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.16666666666667, 60.5, 1.0, 2.0, 0.3652555231952946, 1.0, 1.0, 0.3652555231952946, 1.0, 2.0, 0.7396184774231059, 6.911199999999999, 6.9112, 77.3421103, 1248285.577606333, 1248285.577606334, 283418.7792064714], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 731400.0000, 
sim time next is 732000.0000, 
raw observation next is [26.33333333333334, 60.0, 1.0, 2.0, 0.3560671575097906, 1.0, 2.0, 0.3560671575097906, 1.0, 2.0, 0.7212152253647138, 6.9112, 6.9112, 77.3421103, 1215582.34039731, 1215582.34039731, 280623.3937695708], 
processed observation next is [1.0, 0.4782608695652174, 0.8333333333333336, 0.6, 1.0, 1.0, 0.19508394688723826, 1.0, 1.0, 0.19508394688723826, 1.0, 1.0, 0.6017360362353055, 0.0, 0.0, 0.5085185399722538, 0.45021568162863335, 0.45021568162863335, 0.684447301877002], 
reward next is 0.3156, 
noisyNet noise sample is [array([1.9103253], dtype=float32), 0.8873483]. 
=============================================
[2019-03-23 14:06:51,834] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[60.51427 ]
 [61.541325]
 [62.049976]
 [63.110023]
 [63.396526]], R is [[59.64866638]
 [59.05218124]
 [58.46165848]
 [57.87704086]
 [57.55670929]].
[2019-03-23 14:06:54,547] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.9283572e-10 1.0000000e+00 1.5617082e-33 4.7619211e-20 0.0000000e+00], sum to 1.0000
[2019-03-23 14:06:54,557] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1866
[2019-03-23 14:06:54,566] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 92.0, 1.0, 2.0, 0.392595533803232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 442901.732444361, 442901.7324443607, 124455.3523888723], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 790800.0000, 
sim time next is 791400.0000, 
raw observation next is [19.16666666666667, 93.0, 1.0, 2.0, 0.3903464638541379, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 440147.9374080677, 440147.9374080674, 124134.8074224899], 
processed observation next is [0.0, 0.13043478260869565, 0.5075757575757578, 0.93, 1.0, 1.0, 0.23793307981767237, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16301775459558063, 0.16301775459558052, 0.3027678229816827], 
reward next is 0.6972, 
noisyNet noise sample is [array([0.01345384], dtype=float32), -1.3826555]. 
=============================================
[2019-03-23 14:06:55,052] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.9823342e-12 1.0000000e+00 9.6726306e-34 1.2312385e-20 0.0000000e+00], sum to 1.0000
[2019-03-23 14:06:55,059] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9333
[2019-03-23 14:06:55,063] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 88.00000000000001, 1.0, 2.0, 0.3986569959993617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 450470.500832469, 450470.500832469, 125417.1214424027], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 785400.0000, 
sim time next is 786000.0000, 
raw observation next is [20.0, 88.0, 1.0, 2.0, 0.3980543219520277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 449777.8037989632, 449777.8037989632, 125355.3590414407], 
processed observation next is [0.0, 0.08695652173913043, 0.5454545454545454, 0.88, 1.0, 1.0, 0.24756790244003463, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16658437177739377, 0.16658437177739377, 0.30574477814985535], 
reward next is 0.6943, 
noisyNet noise sample is [array([1.0102733], dtype=float32), 1.1050357]. 
=============================================
[2019-03-23 14:06:55,083] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[67.26393 ]
 [67.336395]
 [67.39204 ]
 [67.39155 ]
 [67.424126]], R is [[67.26760101]
 [67.28903198]
 [67.30960083]
 [67.32826996]
 [67.3451004 ]].
[2019-03-23 14:06:58,112] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.7412365e-11 1.0000000e+00 2.0130072e-32 9.2542214e-20 5.6376384e-38], sum to 1.0000
[2019-03-23 14:06:58,116] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5983
[2019-03-23 14:06:58,123] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 88.5, 1.0, 2.0, 0.4082270318469771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 461663.2579130239, 461663.2579130237, 126520.4756696958], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 865800.0000, 
sim time next is 866400.0000, 
raw observation next is [19.66666666666667, 90.33333333333334, 1.0, 2.0, 0.4046431637875781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 457171.7438285849, 457171.7438285852, 125928.0887092646], 
processed observation next is [0.0, 0.0, 0.5303030303030305, 0.9033333333333334, 1.0, 1.0, 0.2558039547344726, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16932286808466107, 0.16932286808466118, 0.30714167977869417], 
reward next is 0.6929, 
noisyNet noise sample is [array([0.7692992], dtype=float32), -1.4201034]. 
=============================================
[2019-03-23 14:07:00,688] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.2336400e-10 1.0000000e+00 7.5834009e-32 7.3702045e-20 0.0000000e+00], sum to 1.0000
[2019-03-23 14:07:00,703] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9567
[2019-03-23 14:07:00,708] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 68.0, 1.0, 2.0, 0.4887756194992752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 557621.4801042372, 557621.4801042369, 140345.0468093229], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 906600.0000, 
sim time next is 907200.0000, 
raw observation next is [26.0, 65.0, 1.0, 2.0, 0.4881343267555268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 556894.8919247905, 556894.8919247901, 140256.09526002], 
processed observation next is [0.0, 0.5217391304347826, 0.8181818181818182, 0.65, 1.0, 1.0, 0.3601679084444085, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20625736737955203, 0.2062573673795519, 0.342088037219561], 
reward next is 0.6579, 
noisyNet noise sample is [array([-1.6016886], dtype=float32), -0.7932216]. 
=============================================
[2019-03-23 14:07:03,061] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.4062443e-11 1.0000000e+00 1.0102714e-31 5.3195489e-19 0.0000000e+00], sum to 1.0000
[2019-03-23 14:07:03,076] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4859
[2019-03-23 14:07:03,080] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 98.0, 1.0, 2.0, 0.3941092203418264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 445840.0598500473, 445840.0598500476, 125311.6679990339], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 956400.0000, 
sim time next is 957000.0000, 
raw observation next is [19.0, 99.0, 1.0, 2.0, 0.3970490575713334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 449580.8590858579, 449580.8590858579, 125842.8932464762], 
processed observation next is [1.0, 0.043478260869565216, 0.5, 0.99, 1.0, 1.0, 0.24631132196416675, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1665114292910585, 0.1665114292910585, 0.30693388596701515], 
reward next is 0.6931, 
noisyNet noise sample is [array([-0.0324657], dtype=float32), 0.21201852]. 
=============================================
[2019-03-23 14:07:03,095] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[64.93004]
 [64.85192]
 [64.9086 ]
 [64.86596]
 [64.89016]], R is [[64.93984222]
 [64.98480225]
 [65.03051758]
 [65.07691193]
 [65.12385559]].
[2019-03-23 14:07:05,503] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.00846371e-12 1.00000000e+00 1.01291225e-36 1.50186479e-23
 0.00000000e+00], sum to 1.0000
[2019-03-23 14:07:05,513] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8725
[2019-03-23 14:07:05,521] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.3511510256618388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 381319.9215895876, 381319.9215895876, 94553.3399303609], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1006200.0000, 
sim time next is 1006800.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.4218970131532324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 458180.1991574928, 458180.1991574931, 101428.3177178962], 
processed observation next is [1.0, 0.6521739130434783, 0.2727272727272727, 1.0, 1.0, 1.0, 0.2773712664415405, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16969637005833066, 0.16969637005833077, 0.2473861407753566], 
reward next is 0.7526, 
noisyNet noise sample is [array([0.5443003], dtype=float32), 0.23313025]. 
=============================================
[2019-03-23 14:07:18,986] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.4740524e-08 1.0000000e+00 2.8228663e-25 5.6986323e-16 1.6926351e-31], sum to 1.0000
[2019-03-23 14:07:18,991] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6820
[2019-03-23 14:07:18,997] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1091146.656434251 W.
[2019-03-23 14:07:18,999] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.66666666666667, 62.66666666666667, 1.0, 2.0, 0.9565072054609609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1091146.656434251, 1091146.656434251, 211461.7192966726], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1257600.0000, 
sim time next is 1258200.0000, 
raw observation next is [27.0, 61.5, 1.0, 2.0, 0.547945439817856, 0.0, 2.0, 0.0, 1.0, 1.0, 0.968454905431389, 6.920950122533045, 6.9112, 77.32843895235519, 1172508.547230707, 1169341.907859394, 266526.425125515], 
processed observation next is [1.0, 0.5652173913043478, 0.8636363636363636, 0.615, 1.0, 1.0, 0.43493179977232, 0.0, 1.0, -0.25, 1.0, 0.5, 0.9549355791876988, 0.0009750122533045413, 0.0, 0.5084286518929549, 0.43426242490026185, 0.4330895955034793, 0.6500644515256463], 
reward next is 0.3012, 
noisyNet noise sample is [array([0.93157554], dtype=float32), 1.6949714]. 
=============================================
[2019-03-23 14:07:20,068] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4605679e-09 1.0000000e+00 2.4683130e-28 7.0005056e-18 3.2959723e-34], sum to 1.0000
[2019-03-23 14:07:20,076] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9953
[2019-03-23 14:07:20,083] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3790241848661575, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 425362.2683634814, 425362.2683634817, 122095.9433677044], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1288800.0000, 
sim time next is 1289400.0000, 
raw observation next is [18.0, 99.00000000000001, 1.0, 2.0, 0.3791619269409191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 425262.0862942651, 425262.0862942651, 121984.941408], 
processed observation next is [1.0, 0.9565217391304348, 0.45454545454545453, 0.9900000000000001, 1.0, 1.0, 0.22395240867614885, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15750447640528337, 0.15750447640528337, 0.2975242473365854], 
reward next is 0.7025, 
noisyNet noise sample is [array([0.45892844], dtype=float32), -2.1776447]. 
=============================================
[2019-03-23 14:07:22,324] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.1640379e-10 1.0000000e+00 4.4738019e-28 5.7744314e-17 1.1141213e-31], sum to 1.0000
[2019-03-23 14:07:22,331] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7408
[2019-03-23 14:07:22,341] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1224401.016547299 W.
[2019-03-23 14:07:22,357] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.66666666666667, 89.0, 1.0, 2.0, 0.3628555292949302, 1.0, 1.0, 0.3628555292949302, 1.0, 2.0, 0.7329523138089392, 6.911199999999999, 6.9112, 77.3421103, 1224401.016547299, 1224401.016547299, 289484.8633825704], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1330800.0000, 
sim time next is 1331400.0000, 
raw observation next is [23.83333333333333, 89.0, 1.0, 2.0, 0.5494170795552844, 1.0, 2.0, 0.5494170795552844, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344338533, 1235462.200373684, 1235462.200373684, 248166.856920626], 
processed observation next is [1.0, 0.391304347826087, 0.7196969696969695, 0.89, 1.0, 1.0, 0.43677134944410545, 1.0, 1.0, 0.43677134944410545, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129196304, 0.4575785927309941, 0.4575785927309941, 0.6052850168795757], 
reward next is 0.3947, 
noisyNet noise sample is [array([0.32901654], dtype=float32), 1.6460736]. 
=============================================
[2019-03-23 14:07:33,019] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 14:07:33,022] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:07:33,022] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:07:33,022] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:07:33,023] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:07:33,023] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:07:33,025] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:07:33,025] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:07:33,026] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:07:33,027] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:07:33,027] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:07:33,053] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run62
[2019-03-23 14:07:33,082] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run62
[2019-03-23 14:07:33,083] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run62
[2019-03-23 14:07:33,105] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run62
[2019-03-23 14:07:33,154] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run62
[2019-03-23 14:07:34,603] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.50871456]
[2019-03-23 14:07:34,603] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.76666666666667, 84.5, 1.0, 2.0, 0.7272589110168323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 825105.3458794056, 825105.3458794056, 164570.571435739]
[2019-03-23 14:07:34,605] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:07:34,607] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.8446373e-10 1.0000000e+00 5.0261294e-31 4.4857338e-19 1.6933921e-37], sampled 0.3626462301351372
[2019-03-23 14:07:35,634] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.50871456]
[2019-03-23 14:07:35,637] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.9, 31.0, 1.0, 2.0, 0.3186509301610486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 345991.5698578457, 345991.5698578453, 90173.17285299762]
[2019-03-23 14:07:35,637] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:07:35,640] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.1677615e-10 1.0000000e+00 8.3084637e-31 6.2398096e-19 3.2291981e-37], sampled 0.7488207465524793
[2019-03-23 14:07:39,431] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.50871456]
[2019-03-23 14:07:39,433] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.9, 64.66666666666667, 1.0, 2.0, 0.5032411416788023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 566692.4252744606, 566692.4252744601, 138982.4226002951]
[2019-03-23 14:07:39,435] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:07:39,437] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0236081e-09 1.0000000e+00 9.8691045e-31 6.8903659e-19 3.9308314e-37], sampled 0.5018248956926387
[2019-03-23 14:07:54,127] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.50871456]
[2019-03-23 14:07:54,127] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.9, 66.0, 1.0, 2.0, 0.4924698232483085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 561769.3134239682, 561769.3134239682, 145095.719775895]
[2019-03-23 14:07:54,130] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:07:54,134] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0920532e-09 1.0000000e+00 9.8515012e-31 6.8248098e-19 3.8881198e-37], sampled 0.25467988400637354
[2019-03-23 14:07:57,519] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.50871456]
[2019-03-23 14:07:57,520] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [9.333333333333332, 70.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 157323.8519062379, 157323.8519062382, 58803.31590595789]
[2019-03-23 14:07:57,524] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:07:57,527] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.0087636e-10 1.0000000e+00 2.3742582e-30 1.2494940e-18 1.2672046e-36], sampled 0.5621445369863864
[2019-03-23 14:08:01,795] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.50871456]
[2019-03-23 14:08:01,796] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.36872413, 45.69313944, 1.0, 2.0, 0.2891098719745225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 313907.4758300048, 313907.4758300048, 92972.9849007777]
[2019-03-23 14:08:01,798] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:08:01,802] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.2021434e-10 1.0000000e+00 8.7961988e-31 6.5750834e-19 3.5317293e-37], sampled 0.4446343584227378
[2019-03-23 14:08:46,840] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.50871456]
[2019-03-23 14:08:46,843] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.83134351666667, 82.80418457333333, 1.0, 2.0, 0.3949204485500421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 443022.2565676795, 443022.2565676792, 127711.7493458245]
[2019-03-23 14:08:46,846] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:08:46,848] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.7338681e-10 1.0000000e+00 6.9364224e-31 5.6184346e-19 2.5863338e-37], sampled 0.05876897041168616
[2019-03-23 14:08:53,511] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.50871456]
[2019-03-23 14:08:53,514] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.2, 47.0, 1.0, 2.0, 0.3871619078550936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354103, 438971.2871945577, 438971.2871945577, 125337.3977963381]
[2019-03-23 14:08:53,514] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:08:53,517] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.1118073e-10 1.0000000e+00 2.8022260e-31 3.2357261e-19 8.5110777e-38], sampled 0.5508577771672687
[2019-03-23 14:09:03,971] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.50871456]
[2019-03-23 14:09:03,974] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.5, 92.0, 1.0, 2.0, 0.3458456310738804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 385960.9630441724, 385960.963044172, 122626.4131969782]
[2019-03-23 14:09:03,976] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:09:03,980] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.1020151e-09 1.0000000e+00 9.7940214e-31 6.8003816e-19 3.8486019e-37], sampled 0.23277993651375584
[2019-03-23 14:09:14,781] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 14:09:14,938] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 14:09:15,016] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 14:09:15,030] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:09:15,229] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 14:09:16,244] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1525000, evaluation results [1525000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 14:09:21,669] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.4331707e-11 1.0000000e+00 1.2721141e-31 1.1570878e-19 0.0000000e+00], sum to 1.0000
[2019-03-23 14:09:21,680] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7772
[2019-03-23 14:09:21,683] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666666, 82.16666666666667, 1.0, 2.0, 0.4088941023134426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 463644.2118670251, 463644.2118670251, 127377.2818492511], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1630200.0000, 
sim time next is 1630800.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.4076701599356919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 462071.7985642829, 462071.7985642829, 127134.4513215325], 
processed observation next is [1.0, 0.9130434782608695, 0.5909090909090909, 0.83, 1.0, 1.0, 0.25958769991961483, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17113770317195662, 0.17113770317195662, 0.3100840276134939], 
reward next is 0.6899, 
noisyNet noise sample is [array([0.3336711], dtype=float32), -0.7992797]. 
=============================================
[2019-03-23 14:09:22,489] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3497048e-09 1.0000000e+00 1.1704125e-30 1.5978093e-19 3.1666534e-38], sum to 1.0000
[2019-03-23 14:09:22,496] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4988
[2019-03-23 14:09:22,501] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666666, 82.16666666666667, 1.0, 2.0, 0.4088941023134426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 463644.2118670251, 463644.2118670251, 127377.2818492511], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1630200.0000, 
sim time next is 1630800.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.4076701599356919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 462071.7985642829, 462071.7985642829, 127134.4513215325], 
processed observation next is [1.0, 0.9130434782608695, 0.5909090909090909, 0.83, 1.0, 1.0, 0.25958769991961483, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17113770317195662, 0.17113770317195662, 0.3100840276134939], 
reward next is 0.6899, 
noisyNet noise sample is [array([1.3197061], dtype=float32), 0.17732325]. 
=============================================
[2019-03-23 14:09:26,135] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.8459286e-07 9.9999928e-01 1.5793108e-15 1.7874543e-08 5.0264824e-19], sum to 1.0000
[2019-03-23 14:09:26,141] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2773
[2019-03-23 14:09:26,148] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [9.333333333333332, 70.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 157323.8519062379, 157323.8519062382, 58803.31590595789], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1731000.0000, 
sim time next is 1731600.0000, 
raw observation next is [9.0, 71.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 152933.5571519193, 152933.5571519193, 58228.37617940515], 
processed observation next is [1.0, 0.043478260869565216, 0.045454545454545456, 0.71, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.05664205820441455, 0.05664205820441455, 0.14202042970586623], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.20134607], dtype=float32), 1.2722743]. 
=============================================
[2019-03-23 14:09:30,475] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.8228601e-11 1.0000000e+00 3.8465764e-37 5.4342767e-22 0.0000000e+00], sum to 1.0000
[2019-03-23 14:09:30,482] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2072
[2019-03-23 14:09:30,490] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 62.33333333333334, 1.0, 2.0, 0.398721207694917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 450936.0906935387, 450936.090693539, 125658.5232557976], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2142600.0000, 
sim time next is 2143200.0000, 
raw observation next is [23.66666666666666, 63.66666666666667, 1.0, 2.0, 0.3993542943487522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 451842.5353639371, 451842.5353639371, 125833.9196497645], 
processed observation next is [0.0, 0.8260869565217391, 0.7121212121212118, 0.6366666666666667, 1.0, 1.0, 0.24919286793594023, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16734908717182856, 0.16734908717182856, 0.30691199914576706], 
reward next is 0.6931, 
noisyNet noise sample is [array([-0.1976674], dtype=float32), -0.033195287]. 
=============================================
[2019-03-23 14:09:35,273] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.6278540e-11 1.0000000e+00 5.1242732e-35 2.1002156e-20 0.0000000e+00], sum to 1.0000
[2019-03-23 14:09:35,279] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4926
[2019-03-23 14:09:35,283] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 70.5, 1.0, 2.0, 0.2818586710612455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 306050.684040926, 306050.6840409263, 104436.9582432379], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1906200.0000, 
sim time next is 1906800.0000, 
raw observation next is [19.0, 71.33333333333333, 1.0, 2.0, 0.2852572488578103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 309742.1379636796, 309742.1379636799, 107085.9293260492], 
processed observation next is [1.0, 0.043478260869565216, 0.5, 0.7133333333333333, 1.0, 1.0, 0.10657156107226284, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11471931035691837, 0.11471931035691849, 0.26118519347816876], 
reward next is 0.7388, 
noisyNet noise sample is [array([-0.5532087], dtype=float32), -1.4163314]. 
=============================================
[2019-03-23 14:09:35,602] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.1713380e-08 1.0000000e+00 1.5755578e-29 1.0501875e-16 2.6304949e-35], sum to 1.0000
[2019-03-23 14:09:35,610] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0443
[2019-03-23 14:09:35,613] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3755137714353925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 421567.8024995067, 421567.8024995067, 121866.4362379608], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1918800.0000, 
sim time next is 1919400.0000, 
raw observation next is [18.16666666666667, 100.0, 1.0, 2.0, 0.3721683294274126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 418393.2156114434, 418393.2156114437, 121871.8235144521], 
processed observation next is [1.0, 0.21739130434782608, 0.4621212121212123, 1.0, 1.0, 1.0, 0.21521041178426575, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15496045022646052, 0.15496045022646063, 0.297248350035249], 
reward next is 0.7028, 
noisyNet noise sample is [array([-0.58308345], dtype=float32), -0.15285693]. 
=============================================
[2019-03-23 14:09:37,871] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.5597421e-05 9.9997437e-01 1.6493055e-18 7.1998990e-11 2.1488647e-22], sum to 1.0000
[2019-03-23 14:09:37,879] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1957
[2019-03-23 14:09:37,885] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1279090.577316713 W.
[2019-03-23 14:09:37,889] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.66666666666666, 61.0, 1.0, 2.0, 0.6400489379297357, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9685371355148538, 6.911199999999999, 6.9112, 77.32846344354104, 1279090.577316713, 1279090.577316714, 274642.0318512883], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1957200.0000, 
sim time next is 1957800.0000, 
raw observation next is [25.83333333333334, 61.0, 1.0, 2.0, 0.5681882531010093, 1.0, 1.0, 0.5681882531010093, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1296173.260414872, 1296173.260414873, 245683.7238190469], 
processed observation next is [1.0, 0.6521739130434783, 0.8106060606060609, 0.61, 1.0, 1.0, 0.4602353163762616, 1.0, 0.5, 0.4602353163762616, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4800641705240267, 0.48006417052402706, 0.5992285946806022], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.091933], dtype=float32), -0.1183185]. 
=============================================
[2019-03-23 14:09:39,330] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.5157569e-10 1.0000000e+00 1.5075332e-34 1.2137891e-18 0.0000000e+00], sum to 1.0000
[2019-03-23 14:09:39,337] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7575
[2019-03-23 14:09:39,340] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 62.66666666666667, 1.0, 2.0, 0.2669017627502136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 289805.1809379679, 289805.1809379679, 89305.56281330952], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1989600.0000, 
sim time next is 1990200.0000, 
raw observation next is [19.0, 61.33333333333333, 1.0, 2.0, 0.2635257681061897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 286138.406524096, 286138.4065240963, 87469.31461861811], 
processed observation next is [0.0, 0.0, 0.5, 0.6133333333333333, 1.0, 1.0, 0.07940721013273713, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10597718760151703, 0.10597718760151716, 0.2133397917527271], 
reward next is 0.7867, 
noisyNet noise sample is [array([1.3146992], dtype=float32), -0.44313365]. 
=============================================
[2019-03-23 14:09:40,783] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.4434621e-09 1.0000000e+00 4.0349878e-32 1.7960424e-17 0.0000000e+00], sum to 1.0000
[2019-03-23 14:09:40,788] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3157
[2019-03-23 14:09:40,798] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 84.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 200636.0258646388, 200636.0258646385, 67444.22407610032], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2349600.0000, 
sim time next is 2350200.0000, 
raw observation next is [13.0, 83.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 200022.9509727736, 200022.9509727733, 67192.07788667391], 
processed observation next is [1.0, 0.17391304347826086, 0.22727272727272727, 0.83, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07408257443436059, 0.07408257443436049, 0.16388311679676565], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6306642], dtype=float32), -1.0779737]. 
=============================================
[2019-03-23 14:09:41,270] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.5855074e-10 1.0000000e+00 1.8392736e-31 4.2715576e-19 0.0000000e+00], sum to 1.0000
[2019-03-23 14:09:41,277] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3219
[2019-03-23 14:09:41,284] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333334, 72.0, 1.0, 2.0, 0.224026097151617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 243238.6201104992, 243238.6201104989, 77198.92311310809], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2359200.0000, 
sim time next is 2359800.0000, 
raw observation next is [16.5, 72.0, 1.0, 2.0, 0.2232926975379479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 242442.1255389441, 242442.1255389441, 77723.29404970822], 
processed observation next is [1.0, 0.30434782608695654, 0.38636363636363635, 0.72, 1.0, 1.0, 0.029115871922434852, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08979337982923856, 0.08979337982923856, 0.1895690098773371], 
reward next is 0.8104, 
noisyNet noise sample is [array([-1.9197369], dtype=float32), -1.9775089]. 
=============================================
[2019-03-23 14:09:43,271] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.0226880e-09 1.0000000e+00 4.2586674e-36 2.5370100e-19 0.0000000e+00], sum to 1.0000
[2019-03-23 14:09:43,279] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3646
[2019-03-23 14:09:43,283] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 60.0, 1.0, 2.0, 0.2633868447400624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 285987.5180604642, 285987.5180604642, 86137.10863042015], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2071800.0000, 
sim time next is 2072400.0000, 
raw observation next is [19.0, 60.0, 1.0, 2.0, 0.2635478106643171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 286162.3475530308, 286162.3475530305, 86153.99459433836], 
processed observation next is [0.0, 1.0, 0.5, 0.6, 1.0, 1.0, 0.07943476333039635, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10598605464927068, 0.10598605464927055, 0.2101316941325326], 
reward next is 0.7899, 
noisyNet noise sample is [array([0.8586897], dtype=float32), 0.8124451]. 
=============================================
[2019-03-23 14:09:47,224] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.8664314e-09 1.0000000e+00 2.9213523e-33 3.7231472e-19 0.0000000e+00], sum to 1.0000
[2019-03-23 14:09:47,232] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9123
[2019-03-23 14:09:47,236] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 67.66666666666666, 1.0, 2.0, 0.4047306038769443, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 458449.1702108418, 458449.1702108421, 126664.1636508687], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2145000.0000, 
sim time next is 2145600.0000, 
raw observation next is [23.0, 69.0, 1.0, 2.0, 0.4052951390176697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 459232.2343133339, 459232.2343133339, 126812.1094900594], 
processed observation next is [0.0, 0.8695652173913043, 0.6818181818181818, 0.69, 1.0, 1.0, 0.2566189237720871, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17008601270864218, 0.17008601270864218, 0.30929782802453515], 
reward next is 0.6907, 
noisyNet noise sample is [array([0.5648179], dtype=float32), -0.6805534]. 
=============================================
[2019-03-23 14:09:53,875] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.2644438e-09 1.0000000e+00 6.9277718e-32 3.7118750e-18 0.0000000e+00], sum to 1.0000
[2019-03-23 14:09:53,883] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7809
[2019-03-23 14:09:53,888] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 212926.119624529, 212926.119624529, 69880.05984338488], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2271600.0000, 
sim time next is 2272200.0000, 
raw observation next is [14.33333333333333, 74.0, 1.0, 2.0, 0.205848072062362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 223497.1093939642, 223497.1093939645, 71077.14885395825], 
processed observation next is [1.0, 0.30434782608695654, 0.28787878787878773, 0.74, 1.0, 1.0, 0.007310090077952483, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0827767071829497, 0.08277670718294981, 0.1733588996438006], 
reward next is 0.8266, 
noisyNet noise sample is [array([0.02330603], dtype=float32), 0.83288777]. 
=============================================
[2019-03-23 14:09:53,964] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3230868e-09 1.0000000e+00 1.0219886e-32 2.6029190e-17 0.0000000e+00], sum to 1.0000
[2019-03-23 14:09:53,972] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5380
[2019-03-23 14:09:53,978] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.16666666666667, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 206282.872545548, 206282.8725455478, 67599.86999013372], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2268600.0000, 
sim time next is 2269200.0000, 
raw observation next is [13.33333333333333, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 206034.2047042501, 206034.2047042501, 67788.9275718799], 
processed observation next is [1.0, 0.2608695652173913, 0.2424242424242423, 0.77, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07630896470527782, 0.07630896470527782, 0.16533884773629245], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.34417403], dtype=float32), 1.2198967]. 
=============================================
[2019-03-23 14:09:54,528] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3045541e-08 1.0000000e+00 1.5667989e-32 5.3044954e-18 0.0000000e+00], sum to 1.0000
[2019-03-23 14:09:54,536] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8879
[2019-03-23 14:09:54,541] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 56.0, 1.0, 2.0, 0.4288957900087293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 465784.5125564045, 465784.5125564045, 97119.44651303478], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2284800.0000, 
sim time next is 2285400.0000, 
raw observation next is [18.0, 56.0, 1.0, 2.0, 0.417896616191652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 453833.7399179361, 453833.7399179361, 95878.29035823677], 
processed observation next is [1.0, 0.43478260869565216, 0.45454545454545453, 0.56, 1.0, 1.0, 0.272370770239565, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16808657033997634, 0.16808657033997634, 0.2338494886786263], 
reward next is 0.7662, 
noisyNet noise sample is [array([-0.63740814], dtype=float32), -0.452339]. 
=============================================
[2019-03-23 14:09:55,228] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.2734787e-09 1.0000000e+00 7.1153327e-33 2.8724413e-19 0.0000000e+00], sum to 1.0000
[2019-03-23 14:09:55,235] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7176
[2019-03-23 14:09:55,239] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.83333333333333, 46.5, 1.0, 2.0, 0.3380724187769599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 367112.3140748596, 367112.3140748593, 92676.43971926], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2308200.0000, 
sim time next is 2308800.0000, 
raw observation next is [20.66666666666667, 47.0, 1.0, 2.0, 0.2933454701880447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 318527.4832324717, 318527.4832324717, 87266.30587697738], 
processed observation next is [1.0, 0.7391304347826086, 0.575757575757576, 0.47, 1.0, 1.0, 0.11668183773505585, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11797314193795247, 0.11797314193795247, 0.21284464848043264], 
reward next is 0.7872, 
noisyNet noise sample is [array([-2.1027207], dtype=float32), -0.3831062]. 
=============================================
[2019-03-23 14:09:56,346] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.5280489e-13 1.0000000e+00 0.0000000e+00 7.3549067e-25 0.0000000e+00], sum to 1.0000
[2019-03-23 14:09:56,357] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6600
[2019-03-23 14:09:56,362] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 50.5, 1.0, 2.0, 0.2568497716041949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 278887.4772486778, 278887.4772486778, 78106.87618102557], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2316600.0000, 
sim time next is 2317200.0000, 
raw observation next is [18.33333333333334, 51.0, 1.0, 2.0, 0.2570318953463854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 279085.2839428603, 279085.28394286, 77929.4060849144], 
processed observation next is [1.0, 0.8260869565217391, 0.46969696969696995, 0.51, 1.0, 1.0, 0.0712898691829817, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10336491997883715, 0.10336491997883705, 0.1900717221583278], 
reward next is 0.8099, 
noisyNet noise sample is [array([0.32441804], dtype=float32), 1.3131161]. 
=============================================
[2019-03-23 14:10:04,173] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 14:10:04,175] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:10:04,176] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:10:04,177] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:10:04,177] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:10:04,177] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:10:04,178] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:10:04,178] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:10:04,179] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:10:04,178] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:10:04,180] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:10:04,203] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run63
[2019-03-23 14:10:04,228] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run63
[2019-03-23 14:10:04,255] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run63
[2019-03-23 14:10:04,256] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run63
[2019-03-23 14:10:04,256] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run63
[2019-03-23 14:10:16,303] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.51628244]
[2019-03-23 14:10:16,305] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.75, 48.5, 1.0, 2.0, 0.3594017377678734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 400000.4653901177, 400000.465390117, 123246.4203863882]
[2019-03-23 14:10:16,307] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:10:16,309] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.88033029e-08 1.00000000e+00 1.09025856e-29 6.85503169e-17
 3.33670392e-36], sampled 0.8023900900489774
[2019-03-23 14:10:22,686] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.51628244]
[2019-03-23 14:10:22,687] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.78458612833333, 98.94920340666667, 1.0, 2.0, 0.4558594213719298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 495034.0848451551, 495034.0848451551, 127319.9749783887]
[2019-03-23 14:10:22,688] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:10:22,691] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.4806580e-09 1.0000000e+00 3.0398255e-32 2.4477627e-18 0.0000000e+00], sampled 0.4198864436876969
[2019-03-23 14:10:26,913] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.51628244]
[2019-03-23 14:10:26,914] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.33333333333333, 67.66666666666667, 1.0, 2.0, 0.4675686331809251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344353432, 533508.696495856, 533508.6964958558, 137570.7981939237]
[2019-03-23 14:10:26,919] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:10:26,922] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.506341e-09 1.000000e+00 4.925511e-32 3.302191e-18 0.000000e+00], sampled 0.5343838492462897
[2019-03-23 14:10:37,378] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.51628244]
[2019-03-23 14:10:37,379] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.93333333333333, 68.16666666666667, 1.0, 2.0, 0.2617794443152999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 284225.8392475603, 284225.8392475603, 83090.86734265332]
[2019-03-23 14:10:37,380] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:10:37,383] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.6832154e-09 1.0000000e+00 3.2833122e-33 7.3599253e-19 0.0000000e+00], sampled 0.19076493079746282
[2019-03-23 14:10:49,778] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.51628244]
[2019-03-23 14:10:49,779] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.66666666666667, 69.5, 1.0, 2.0, 0.2721299658511076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 295483.7520178293, 295483.7520178293, 96087.65841329355]
[2019-03-23 14:10:49,782] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:10:49,786] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.3457544e-09 1.0000000e+00 1.2708475e-32 1.5621073e-18 0.0000000e+00], sampled 0.79184255126645
[2019-03-23 14:11:06,698] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.51628244]
[2019-03-23 14:11:06,699] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.12523307, 90.11417876, 1.0, 2.0, 0.2358839007960171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 256103.8807625396, 256103.8807625392, 87005.09139370253]
[2019-03-23 14:11:06,701] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:11:06,704] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.4095744e-09 1.0000000e+00 1.9477207e-31 7.2809844e-18 2.5222313e-38], sampled 0.8858025632093313
[2019-03-23 14:11:20,073] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.51628244]
[2019-03-23 14:11:20,074] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [28.34699421333334, 74.61787392666668, 1.0, 2.0, 0.6005730434800182, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9230791853611663, 6.99906702554634, 6.9112, 95.55306241238641, 1223182.227044301, 1187919.180865017, 278778.1358180814]
[2019-03-23 14:11:20,076] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:11:20,079] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.1844840e-09 1.0000000e+00 2.4165441e-32 2.2189744e-18 0.0000000e+00], sampled 0.6108725880493109
[2019-03-23 14:11:20,081] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1223182.227044301 W.
[2019-03-23 14:11:30,715] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.51628244]
[2019-03-23 14:11:30,716] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.65, 96.5, 1.0, 2.0, 0.6830364057432371, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 776680.5422104098, 776680.5422104095, 159923.5391370104]
[2019-03-23 14:11:30,717] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:11:30,719] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.1407881e-08 1.0000000e+00 2.6539330e-32 2.1742715e-18 0.0000000e+00], sampled 0.965530152710439
[2019-03-23 14:11:37,949] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.51628244]
[2019-03-23 14:11:37,950] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.7, 84.5, 1.0, 2.0, 0.580079521133011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 661912.1152119564, 661912.1152119561, 155022.4809932069]
[2019-03-23 14:11:37,952] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:11:37,955] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.6491926e-08 1.0000000e+00 1.1698182e-31 5.0572425e-18 0.0000000e+00], sampled 0.8483664244782346
[2019-03-23 14:11:39,990] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.51628244]
[2019-03-23 14:11:39,991] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [12.7, 86.0, 1.0, 2.0, 0.366728757031997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 398211.8290838769, 398211.8290838769, 90484.54575695368]
[2019-03-23 14:11:39,993] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:11:39,996] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.6064568e-09 1.0000000e+00 3.0899684e-33 7.1203800e-19 0.0000000e+00], sampled 0.034181024801398174
[2019-03-23 14:11:44,880] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.51628244]
[2019-03-23 14:11:44,881] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.41500721333333, 68.41020711000002, 1.0, 2.0, 0.2460229804060186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 267114.5288684207, 267114.52886842, 82871.78678345757]
[2019-03-23 14:11:44,882] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:11:44,887] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.8509410e-08 1.0000000e+00 3.9282691e-29 1.4461041e-16 1.7107818e-35], sampled 0.4231246274189344
[2019-03-23 14:11:46,387] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:11:46,654] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 14:11:46,747] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 14:11:46,830] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 14:11:46,840] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 14:11:47,862] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1550000, evaluation results [1550000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 14:11:49,279] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1270357e-11 1.0000000e+00 6.3461153e-38 5.8480362e-22 0.0000000e+00], sum to 1.0000
[2019-03-23 14:11:49,287] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5175
[2019-03-23 14:11:49,291] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 99.00000000000001, 1.0, 2.0, 0.2226776898347961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 241774.2092345547, 241774.2092345547, 75703.32646338739], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2495400.0000, 
sim time next is 2496000.0000, 
raw observation next is [13.0, 98.0, 1.0, 2.0, 0.2211530336842767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 240118.3921387536, 240118.3921387533, 75264.69524092523], 
processed observation next is [1.0, 0.9130434782608695, 0.22727272727272727, 0.98, 1.0, 1.0, 0.02644129210534585, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08893273782916801, 0.08893273782916788, 0.18357242741689078], 
reward next is 0.8164, 
noisyNet noise sample is [array([-0.25785503], dtype=float32), 0.10685782]. 
=============================================
[2019-03-23 14:11:49,311] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[82.798485]
 [82.80106 ]
 [82.80693 ]
 [82.84591 ]
 [82.86857 ]], R is [[82.78311157]
 [82.77064514]
 [82.75731659]
 [82.74326324]
 [82.7283783 ]].
[2019-03-23 14:11:50,872] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.7520089e-11 1.0000000e+00 1.6216382e-37 5.1277512e-21 0.0000000e+00], sum to 1.0000
[2019-03-23 14:11:50,879] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0215
[2019-03-23 14:11:50,887] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2149151857801894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 233343.9822581548, 233343.9822581546, 75168.98958633718], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2503200.0000, 
sim time next is 2503800.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2148052168522444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 233224.5549614195, 233224.5549614198, 75173.43390988157], 
processed observation next is [1.0, 1.0, 0.22727272727272727, 1.0, 1.0, 1.0, 0.018506521065305495, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08637946480052573, 0.08637946480052586, 0.1833498388045892], 
reward next is 0.8167, 
noisyNet noise sample is [array([-0.49900422], dtype=float32), 0.48133788]. 
=============================================
[2019-03-23 14:11:53,989] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.4190316e-08 1.0000000e+00 9.1471490e-33 3.8522082e-18 0.0000000e+00], sum to 1.0000
[2019-03-23 14:11:53,998] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4587
[2019-03-23 14:11:54,003] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.33333333333333, 100.0, 1.0, 2.0, 0.2887272125598588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 313511.1584594193, 313511.1584594193, 101199.5483148039], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2608800.0000, 
sim time next is 2609400.0000, 
raw observation next is [15.16666666666667, 100.0, 1.0, 2.0, 0.283472227236668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 307803.2866754752, 307803.2866754755, 98080.49205514033], 
processed observation next is [0.0, 0.17391304347826086, 0.3257575757575759, 1.0, 1.0, 1.0, 0.10434028404583497, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11400121728721303, 0.11400121728721314, 0.23922071232961056], 
reward next is 0.7608, 
noisyNet noise sample is [array([-1.0245873], dtype=float32), 2.5657165]. 
=============================================
[2019-03-23 14:12:01,377] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.6157073e-07 9.9999976e-01 1.0750929e-29 6.6083091e-16 1.0253803e-35], sum to 1.0000
[2019-03-23 14:12:01,385] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5418
[2019-03-23 14:12:01,389] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 65.5, 1.0, 2.0, 0.4891518255307687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 557974.8189840426, 557974.8189840426, 140573.9278032719], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2727000.0000, 
sim time next is 2727600.0000, 
raw observation next is [25.66666666666666, 66.66666666666667, 1.0, 2.0, 0.4857574119188512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 554196.1048241829, 554196.1048241829, 139941.0990274265], 
processed observation next is [0.0, 0.5652173913043478, 0.8030303030303028, 0.6666666666666667, 1.0, 1.0, 0.35719676489856395, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20525781660154924, 0.20525781660154924, 0.3413197537254305], 
reward next is 0.6587, 
noisyNet noise sample is [array([0.7713075], dtype=float32), -0.66489786]. 
=============================================
[2019-03-23 14:12:05,965] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.5734549e-08 1.0000000e+00 9.1188152e-20 1.0767452e-10 9.1891892e-25], sum to 1.0000
[2019-03-23 14:12:05,971] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7860
[2019-03-23 14:12:05,977] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.16666666666667, 51.16666666666666, 1.0, 2.0, 0.4541452260371927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518189.8476544881, 518189.8476544881, 135565.6108595241], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2829000.0000, 
sim time next is 2829600.0000, 
raw observation next is [28.0, 51.0, 1.0, 2.0, 0.4529501762729211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516752.5424577967, 516752.5424577967, 135079.1486097329], 
processed observation next is [1.0, 0.782608695652174, 0.9090909090909091, 0.51, 1.0, 1.0, 0.31618772034115133, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1913898305399247, 0.1913898305399247, 0.32946133807251926], 
reward next is 0.6705, 
noisyNet noise sample is [array([-1.7010401], dtype=float32), 0.58207375]. 
=============================================
[2019-03-23 14:12:06,275] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.6251679e-07 9.9915385e-01 1.0773849e-13 8.4549218e-04 1.4909548e-18], sum to 1.0000
[2019-03-23 14:12:06,279] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9368
[2019-03-23 14:12:06,286] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1557602.616963233 W.
[2019-03-23 14:12:06,291] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.16666666666666, 51.16666666666666, 1.0, 2.0, 0.4594166099981855, 1.0, 1.0, 0.4594166099981855, 1.0, 2.0, 0.9295988136426786, 6.911199999999999, 6.9112, 83.26111830642255, 1557602.616963233, 1557602.616963234, 337818.2129542403], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2823000.0000, 
sim time next is 2823600.0000, 
raw observation next is [29.13333333333333, 51.33333333333334, 1.0, 2.0, 0.6491380523587161, 1.0, 2.0, 0.6491380523587161, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1468179.278570378, 1468179.278570377, 274245.4793522255], 
processed observation next is [1.0, 0.6956521739130435, 0.9606060606060605, 0.5133333333333334, 1.0, 1.0, 0.5614225654483951, 1.0, 1.0, 0.5614225654483951, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.543770103174214, 0.5437701031742137, 0.6688914130542085], 
reward next is 0.3311, 
noisyNet noise sample is [array([0.16347775], dtype=float32), -0.86116934]. 
=============================================
[2019-03-23 14:12:07,592] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.8255672e-08 1.0000000e+00 6.4274534e-19 2.0614356e-10 4.5478013e-24], sum to 1.0000
[2019-03-23 14:12:07,599] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2869
[2019-03-23 14:12:07,601] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.00000000000001, 1.0, 2.0, 0.4900773483942352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 557658.0005121512, 557658.0005121512, 137016.0770267598], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2866200.0000, 
sim time next is 2866800.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.4508753187143489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 513007.0155125057, 513007.0155125054, 132851.5677507168], 
processed observation next is [1.0, 0.17391304347826086, 0.5909090909090909, 0.88, 1.0, 1.0, 0.3135941483929361, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1900025983379651, 0.19000259833796496, 0.3240282140261385], 
reward next is 0.6760, 
noisyNet noise sample is [array([0.32965624], dtype=float32), -1.302196]. 
=============================================
[2019-03-23 14:12:14,847] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1059673e-06 9.9993813e-01 4.7209053e-16 6.0819420e-05 2.1357698e-21], sum to 1.0000
[2019-03-23 14:12:14,856] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5448
[2019-03-23 14:12:14,877] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1596265.893703834 W.
[2019-03-23 14:12:14,879] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.472533794325152, 1.0, 2.0, 0.472533794325152, 1.0, 1.0, 0.9548110163946641, 6.9112, 6.9112, 77.3421103, 1596265.893703834, 1596265.893703834, 343555.1590975673], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2988000.0000, 
sim time next is 2988600.0000, 
raw observation next is [28.0, 57.5, 1.0, 2.0, 0.3928456579083601, 1.0, 2.0, 0.3928456579083601, 1.0, 2.0, 0.7942269636436458, 6.9112, 6.9112, 77.3421103, 1328587.953771987, 1328587.953771987, 302308.8287962697], 
processed observation next is [1.0, 0.6086956521739131, 0.9090909090909091, 0.575, 1.0, 1.0, 0.24105707238545013, 1.0, 1.0, 0.24105707238545013, 1.0, 1.0, 0.7060385194909226, 0.0, 0.0, 0.5085185399722538, 0.49206961250814335, 0.49206961250814335, 0.73733860682017], 
reward next is 0.2627, 
noisyNet noise sample is [array([-0.1438091], dtype=float32), -0.012265221]. 
=============================================
[2019-03-23 14:12:24,655] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7895808e-08 1.0000000e+00 2.3884919e-31 3.9144540e-18 0.0000000e+00], sum to 1.0000
[2019-03-23 14:12:24,661] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2517
[2019-03-23 14:12:24,664] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 79.66666666666667, 1.0, 2.0, 0.4537841598840254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 517347.8455972456, 517347.8455972459, 134381.1988996805], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3180000.0000, 
sim time next is 3180600.0000, 
raw observation next is [22.5, 80.5, 1.0, 2.0, 0.453273291397208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516699.1811813164, 516699.1811813164, 134223.0309055061], 
processed observation next is [1.0, 0.8260869565217391, 0.6590909090909091, 0.805, 1.0, 1.0, 0.31659161424651, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19137006710419124, 0.19137006710419124, 0.3273732461109905], 
reward next is 0.6726, 
noisyNet noise sample is [array([-1.468426], dtype=float32), -1.6219203]. 
=============================================
[2019-03-23 14:12:31,751] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.4042375e-08 9.9999988e-01 9.2896539e-29 5.8962167e-15 2.8684508e-37], sum to 1.0000
[2019-03-23 14:12:31,760] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1615
[2019-03-23 14:12:31,764] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 64.33333333333334, 1.0, 2.0, 0.2859606606910335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 310506.1705741361, 310506.1705741361, 107082.2427293034], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3316800.0000, 
sim time next is 3317400.0000, 
raw observation next is [20.5, 62.5, 1.0, 2.0, 0.2918493521509614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 316902.4027919875, 316902.4027919878, 110649.7960178242], 
processed observation next is [0.0, 0.391304347826087, 0.5681818181818182, 0.625, 1.0, 1.0, 0.11481169018870176, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11737126029332871, 0.11737126029332882, 0.26987755126298585], 
reward next is 0.7301, 
noisyNet noise sample is [array([-0.07695026], dtype=float32), -2.1146116]. 
=============================================
[2019-03-23 14:12:32,559] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.1459903e-08 9.9999988e-01 4.8058187e-31 5.3155399e-16 4.2256503e-38], sum to 1.0000
[2019-03-23 14:12:32,569] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8659
[2019-03-23 14:12:32,573] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.83333333333334, 50.66666666666667, 1.0, 2.0, 0.35516308773364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 397442.5333027554, 397442.5333027554, 119542.649569941], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3333000.0000, 
sim time next is 3333600.0000, 
raw observation next is [25.0, 50.0, 1.0, 2.0, 0.35580770895976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 398304.5154536546, 398304.5154536549, 119660.7020961405], 
processed observation next is [0.0, 0.6086956521739131, 0.7727272727272727, 0.5, 1.0, 1.0, 0.19475963619969996, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14752019090876095, 0.1475201909087611, 0.29185537096619635], 
reward next is 0.7081, 
noisyNet noise sample is [array([0.7987861], dtype=float32), 0.4362233]. 
=============================================
[2019-03-23 14:12:36,050] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 14:12:36,051] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:12:36,051] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:12:36,052] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:12:36,052] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:12:36,052] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:12:36,053] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:12:36,053] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:12:36,054] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:12:36,055] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:12:36,055] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:12:36,075] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run64
[2019-03-23 14:12:36,100] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run64
[2019-03-23 14:12:36,128] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run64
[2019-03-23 14:12:36,151] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run64
[2019-03-23 14:12:36,180] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run64
[2019-03-23 14:12:45,199] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.5230055]
[2019-03-23 14:12:45,200] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [14.9, 73.0, 1.0, 2.0, 0.2226182463311649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 241698.1979339309, 241698.1979339313, 78149.08044111385]
[2019-03-23 14:12:45,201] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:12:45,204] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.2355530e-08 1.0000000e+00 2.1240073e-28 1.1143812e-15 9.7408268e-36], sampled 0.9566398267153909
[2019-03-23 14:13:01,589] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.5230055]
[2019-03-23 14:13:01,592] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [13.65009323333333, 70.821575055, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 193360.0155279233, 193360.0155279233, 69379.27428717648]
[2019-03-23 14:13:01,594] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:13:01,600] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.9130877e-08 1.0000000e+00 1.9753039e-28 1.0906739e-15 9.0140170e-36], sampled 0.958234441423932
[2019-03-23 14:13:06,087] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.5230055]
[2019-03-23 14:13:06,087] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.08333333333333, 55.16666666666667, 1.0, 2.0, 0.2114703348909016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 229592.5204298074, 229592.5204298074, 74192.44223458643]
[2019-03-23 14:13:06,088] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:13:06,090] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.6215786e-08 1.0000000e+00 1.9652616e-29 3.0557203e-16 4.8685790e-37], sampled 0.33326757638642657
[2019-03-23 14:13:15,417] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.5230055]
[2019-03-23 14:13:15,418] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.46666666666667, 88.66666666666667, 1.0, 2.0, 0.409701394478151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 464923.2664042044, 464923.2664042044, 132052.2635914734]
[2019-03-23 14:13:15,420] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:13:15,424] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.9337411e-08 1.0000000e+00 6.2595990e-26 3.9600532e-14 1.6291633e-32], sampled 0.18068064417828644
[2019-03-23 14:13:18,983] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.5230055]
[2019-03-23 14:13:18,987] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.46382889, 75.44040389, 1.0, 2.0, 0.4722477183080966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 538642.2259359169, 538642.2259359169, 141235.4522100364]
[2019-03-23 14:13:18,988] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:13:18,992] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.2038980e-08 1.0000000e+00 2.7026244e-25 1.1510644e-13 1.1083901e-31], sampled 0.35681792859999817
[2019-03-23 14:13:41,891] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.5230055]
[2019-03-23 14:13:42,014] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 100.0, 1.0, 2.0, 0.4417414720324274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 500846.0270205991, 500846.0270205993, 130519.1796274957]
[2019-03-23 14:13:42,015] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:13:42,017] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.5272925e-08 1.0000000e+00 1.5043575e-25 7.3643809e-14 5.1451805e-32], sampled 0.0725282395904171
[2019-03-23 14:13:45,452] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.5230055]
[2019-03-23 14:13:45,456] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.7, 48.0, 1.0, 2.0, 0.3068012337785496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 333121.5890973671, 333121.5890973671, 111783.4983685883]
[2019-03-23 14:13:45,457] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:13:45,460] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.7060830e-08 1.0000000e+00 5.8074660e-29 5.3273756e-16 1.8367237e-36], sampled 0.2824402692826765
[2019-03-23 14:13:56,233] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.5230055]
[2019-03-23 14:13:56,233] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.46666666666667, 86.66666666666667, 1.0, 2.0, 0.3425197229210035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 378929.7244078231, 378929.7244078231, 120970.6642279985]
[2019-03-23 14:13:56,233] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:13:56,237] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.1323485e-08 1.0000000e+00 5.2548430e-28 1.8555538e-15 3.0497983e-35], sampled 0.13030476456020357
[2019-03-23 14:13:58,147] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.5230055]
[2019-03-23 14:13:58,148] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.8, 58.33333333333333, 1.0, 2.0, 0.5144118327864242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 558709.0397448604, 558709.03974486, 116895.7331968369]
[2019-03-23 14:13:58,149] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:13:58,151] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.0286468e-08 1.0000000e+00 3.3762464e-26 2.6438575e-14 7.3199451e-33], sampled 0.4738260907789835
[2019-03-23 14:14:02,620] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.5230055]
[2019-03-23 14:14:02,620] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.31666666666667, 69.0, 1.0, 2.0, 0.6755010030044005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 770430.3787984625, 770430.3787984625, 166020.5200706692]
[2019-03-23 14:14:02,621] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:14:02,624] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.3379025e-08 1.0000000e+00 3.5963719e-24 9.8040911e-13 2.9662184e-30], sampled 0.9103546140185695
[2019-03-23 14:14:03,374] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.5230055]
[2019-03-23 14:14:03,375] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.90749306, 45.91524184, 1.0, 2.0, 0.2931831204189642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 318331.2672162552, 318331.2672162555, 87866.64677893452]
[2019-03-23 14:14:03,376] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:14:03,378] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.3472994e-08 1.0000000e+00 8.2029094e-29 6.7419651e-16 2.9598571e-36], sampled 0.8898723827080666
[2019-03-23 14:14:18,619] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8567.2106 1752698080.1645 103.0000
[2019-03-23 14:14:18,705] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8873.1060 1663357677.6358 56.0000
[2019-03-23 14:14:18,710] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8612.0968 1680540511.4563 112.0000
[2019-03-23 14:14:18,830] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8703.6146 1698876144.3816 185.0000
[2019-03-23 14:14:18,910] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9069.0013 1656814494.4410 50.0000
[2019-03-23 14:14:19,927] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1575000, evaluation results [1575000.0, 8567.210644622204, 1752698080.164465, 103.0, 9069.001268457534, 1656814494.4409814, 50.0, 8873.10604816175, 1663357677.6358323, 56.0, 8703.614620523918, 1698876144.3816419, 185.0, 8612.096838206236, 1680540511.4562619, 112.0]
[2019-03-23 14:14:20,817] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.2420267e-08 1.0000000e+00 3.9201038e-25 2.7828372e-13 1.1821418e-30], sum to 1.0000
[2019-03-23 14:14:20,823] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1889
[2019-03-23 14:14:20,827] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 84.0, 1.0, 2.0, 0.5576422747363429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 631899.2616776883, 631899.2616776883, 151738.7030773514], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3440400.0000, 
sim time next is 3441000.0000, 
raw observation next is [24.33333333333333, 86.5, 1.0, 2.0, 0.5601452009889805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 634643.2759094269, 634643.2759094265, 152099.0642522732], 
processed observation next is [1.0, 0.8260869565217391, 0.7424242424242422, 0.865, 1.0, 1.0, 0.4501815012362255, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23505306515163957, 0.23505306515163946, 0.3709733274445688], 
reward next is 0.6290, 
noisyNet noise sample is [array([1.0783049], dtype=float32), -1.2247192]. 
=============================================
[2019-03-23 14:14:20,845] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[54.06143 ]
 [53.95885 ]
 [53.815987]
 [54.843193]
 [55.411922]], R is [[53.7269249 ]
 [53.819561  ]
 [53.91201401]
 [54.00432587]
 [54.09654236]].
[2019-03-23 14:14:22,300] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.23602773e-07 9.99335349e-01 1.25955255e-17 6.64034451e-04
 3.93415307e-24], sum to 1.0000
[2019-03-23 14:14:22,313] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7016
[2019-03-23 14:14:22,321] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5200246696497826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 592430.0349842858, 592430.0349842862, 145213.240420755], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3450000.0000, 
sim time next is 3450600.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5180790456492395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 590213.3560913217, 590213.3560913217, 144976.4171016198], 
processed observation next is [1.0, 0.9565217391304348, 0.6818181818181818, 0.89, 1.0, 1.0, 0.39759880706154926, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2185975392930821, 0.2185975392930821, 0.3536010173210239], 
reward next is 0.6464, 
noisyNet noise sample is [array([0.80556244], dtype=float32), -0.26048264]. 
=============================================
[2019-03-23 14:14:25,448] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3136360e-05 9.9991703e-01 1.3621696e-12 6.9812573e-05 1.3083876e-16], sum to 1.0000
[2019-03-23 14:14:25,457] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2829
[2019-03-23 14:14:25,466] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1474415.703499776 W.
[2019-03-23 14:14:25,470] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.16666666666667, 62.0, 1.0, 2.0, 0.4370287054673982, 1.0, 2.0, 0.4370287054673982, 1.0, 2.0, 0.8842748945156462, 6.911199999999999, 6.9112, 77.3421103, 1474415.703499776, 1474415.703499776, 325864.2029197617], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3510600.0000, 
sim time next is 3511200.0000, 
raw observation next is [28.33333333333334, 62.0, 1.0, 2.0, 0.9046218021106968, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9836932334563093, 6.9112, 6.9112, 77.32846344354104, 1567572.192449657, 1567572.192449657, 332794.6728468138], 
processed observation next is [1.0, 0.6521739130434783, 0.9242424242424245, 0.62, 1.0, 1.0, 0.8807772526383708, 0.0, 0.5, -0.25, 1.0, 1.0, 0.976704619223299, 0.0, 0.0, 0.5084288129206541, 0.580582293499873, 0.580582293499873, 0.811694324016619], 
reward next is 0.1883, 
noisyNet noise sample is [array([-0.61394364], dtype=float32), -1.3426943]. 
=============================================
[2019-03-23 14:14:27,300] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.8057120e-09 1.0000000e+00 2.5787645e-32 5.8837777e-20 0.0000000e+00], sum to 1.0000
[2019-03-23 14:14:27,307] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8512
[2019-03-23 14:14:27,315] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 57.0, 1.0, 2.0, 0.3233270437903236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 354823.0249299369, 354823.0249299371, 114101.2042399927], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3865800.0000, 
sim time next is 3866400.0000, 
raw observation next is [22.0, 57.0, 1.0, 2.0, 0.3209466917271195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 351258.3460179931, 351258.3460179933, 113581.6675574525], 
processed observation next is [0.0, 0.782608695652174, 0.6363636363636364, 0.57, 1.0, 1.0, 0.15118336465889934, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1300956837103678, 0.1300956837103679, 0.2770284574572012], 
reward next is 0.7230, 
noisyNet noise sample is [array([-0.2937288], dtype=float32), -2.6316702]. 
=============================================
[2019-03-23 14:14:30,055] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.7666808e-06 3.8405240e-03 2.0993445e-11 9.9615473e-01 2.0122801e-15], sum to 1.0000
[2019-03-23 14:14:30,061] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0184
[2019-03-23 14:14:30,065] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.66666666666666, 71.33333333333333, 1.0, 2.0, 0.7457964560402162, 1.0, 2.0, 0.7457964560402162, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1677710.474899539, 1677710.474899539, 306570.3151895795], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3595200.0000, 
sim time next is 3595800.0000, 
raw observation next is [27.83333333333334, 70.66666666666667, 1.0, 2.0, 0.7616922082852932, 1.0, 2.0, 0.7616922082852932, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1713522.98331768, 1713522.98331768, 311862.0544305695], 
processed observation next is [1.0, 0.6086956521739131, 0.9015151515151518, 0.7066666666666667, 1.0, 1.0, 0.7021152603566163, 1.0, 1.0, 0.7021152603566163, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.6346381419695111, 0.6346381419695111, 0.7606391571477306], 
reward next is 0.2394, 
noisyNet noise sample is [array([-0.95277876], dtype=float32), 1.8029855]. 
=============================================
[2019-03-23 14:14:31,848] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.0787253e-09 1.0000000e+00 3.9971860e-28 1.9633938e-16 5.2471525e-35], sum to 1.0000
[2019-03-23 14:14:31,856] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1779
[2019-03-23 14:14:31,867] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.5232949826791164, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595627.0434995419, 595627.0434995419, 146034.3591401553], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3607200.0000, 
sim time next is 3607800.0000, 
raw observation next is [24.0, 82.16666666666667, 1.0, 2.0, 0.5181408438980091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 590086.3562937574, 590086.3562937574, 145154.2168747396], 
processed observation next is [1.0, 0.782608695652174, 0.7272727272727273, 0.8216666666666668, 1.0, 1.0, 0.3976760548725113, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21855050233102127, 0.21855050233102127, 0.35403467530424293], 
reward next is 0.6460, 
noisyNet noise sample is [array([-1.736017], dtype=float32), 0.08075557]. 
=============================================
[2019-03-23 14:14:32,878] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.1505469e-08 9.9999988e-01 1.5690532e-25 5.3549855e-15 2.0226903e-32], sum to 1.0000
[2019-03-23 14:14:32,884] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2337
[2019-03-23 14:14:32,887] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5203347313852147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593690.5704783297, 593690.5704783297, 143901.8144030864], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3644400.0000, 
sim time next is 3645000.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5137384904233374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 586161.6258329304, 586161.6258329304, 143114.1073258262], 
processed observation next is [1.0, 0.17391304347826086, 0.5909090909090909, 1.0, 1.0, 1.0, 0.39217311302917174, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2170968984566409, 0.2170968984566409, 0.3490587983556736], 
reward next is 0.6509, 
noisyNet noise sample is [array([1.1722271], dtype=float32), 1.0322429]. 
=============================================
[2019-03-23 14:14:32,899] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[59.23525 ]
 [59.0525  ]
 [59.028   ]
 [58.84768 ]
 [58.672676]], R is [[59.23390579]
 [59.29058838]
 [59.3413887 ]
 [59.40439606]
 [59.46680832]].
[2019-03-23 14:14:43,742] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.3442213e-10 1.0000000e+00 7.5417357e-34 3.3283442e-18 0.0000000e+00], sum to 1.0000
[2019-03-23 14:14:43,747] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0754
[2019-03-23 14:14:43,750] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 59.33333333333334, 1.0, 2.0, 0.3126743235885007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 342187.6271412449, 342187.6271412452, 112992.2675114917], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3871200.0000, 
sim time next is 3871800.0000, 
raw observation next is [21.5, 60.5, 1.0, 2.0, 0.3134762194941135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 343215.6778855157, 343215.6778855157, 113103.4473898302], 
processed observation next is [0.0, 0.8260869565217391, 0.6136363636363636, 0.605, 1.0, 1.0, 0.14184527436764183, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12711691773537617, 0.12711691773537617, 0.2758620668044639], 
reward next is 0.7241, 
noisyNet noise sample is [array([-1.7229054], dtype=float32), -0.08759793]. 
=============================================
[2019-03-23 14:14:48,017] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5976986e-09 1.0000000e+00 4.7933326e-31 4.0174898e-19 0.0000000e+00], sum to 1.0000
[2019-03-23 14:14:48,022] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0196
[2019-03-23 14:14:48,027] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.16666666666666, 76.33333333333334, 1.0, 2.0, 0.2929213914807777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 318066.8492314044, 318066.8492314044, 104308.1695263644], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3973800.0000, 
sim time next is 3974400.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.2895903108613428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 314448.6469200488, 314448.6469200488, 102576.4528121615], 
processed observation next is [1.0, 0.0, 0.45454545454545453, 0.77, 1.0, 1.0, 0.11198788857667848, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11646246182224029, 0.11646246182224029, 0.2501864702735646], 
reward next is 0.7498, 
noisyNet noise sample is [array([-0.06391087], dtype=float32), 0.42954227]. 
=============================================
[2019-03-23 14:14:54,819] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2041278e-10 1.0000000e+00 7.8610421e-32 2.6014771e-19 0.0000000e+00], sum to 1.0000
[2019-03-23 14:14:54,831] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2982
[2019-03-23 14:14:54,833] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3275885088858099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 358442.2080257083, 358442.2080257086, 114025.8127584549], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4054800.0000, 
sim time next is 4055400.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3240118310928842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 354511.8315758604, 354511.8315758601, 113763.892294335], 
processed observation next is [1.0, 0.9565217391304348, 0.4090909090909091, 0.94, 1.0, 1.0, 0.1550147888661052, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13130067836142978, 0.13130067836142967, 0.27747290803496344], 
reward next is 0.7225, 
noisyNet noise sample is [array([2.1736069], dtype=float32), 0.24250558]. 
=============================================
[2019-03-23 14:14:56,823] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.1724137e-10 1.0000000e+00 7.4746653e-32 2.6052012e-19 0.0000000e+00], sum to 1.0000
[2019-03-23 14:14:56,831] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6719
[2019-03-23 14:14:56,837] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.05, 93.5, 1.0, 2.0, 0.386659997405606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 435644.7209368874, 435644.7209368874, 123619.9834467794], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4131000.0000, 
sim time next is 4131600.0000, 
raw observation next is [19.03333333333333, 93.66666666666667, 1.0, 2.0, 0.3858669302594047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 434760.1323010832, 434760.1323010835, 123554.8339795395], 
processed observation next is [1.0, 0.8260869565217391, 0.5015151515151515, 0.9366666666666668, 1.0, 1.0, 0.23233366282425588, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16102227122262341, 0.1610222712226235, 0.3013532536086329], 
reward next is 0.6986, 
noisyNet noise sample is [array([-1.2817336], dtype=float32), 0.45018074]. 
=============================================
[2019-03-23 14:14:57,114] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.4059033e-09 1.0000000e+00 6.0272098e-29 9.0414778e-18 2.8202365e-35], sum to 1.0000
[2019-03-23 14:14:57,120] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5515
[2019-03-23 14:14:57,123] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3700795610525945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 415452.6153433203, 415452.6153433206, 121397.4806174149], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4156200.0000, 
sim time next is 4156800.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3684948876279565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 413660.0463934981, 413660.0463934984, 121256.8717781028], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 1.0, 1.0, 1.0, 0.21061860953494563, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15320742459018447, 0.1532074245901846, 0.29574846775147023], 
reward next is 0.7043, 
noisyNet noise sample is [array([-1.4185679], dtype=float32), 0.92397225]. 
=============================================
[2019-03-23 14:15:02,425] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.4263984e-09 1.0000000e+00 5.3428301e-28 1.2904630e-15 5.6463207e-35], sum to 1.0000
[2019-03-23 14:15:02,435] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9975
[2019-03-23 14:15:02,438] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 94.0, 1.0, 2.0, 0.3068004210912782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 333142.4682113059, 333142.4682113059, 103826.8948120292], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4251600.0000, 
sim time next is 4252200.0000, 
raw observation next is [16.0, 95.0, 1.0, 2.0, 0.2942196758952476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 319477.0462490141, 319477.0462490144, 104538.7488213434], 
processed observation next is [1.0, 0.21739130434782608, 0.36363636363636365, 0.95, 1.0, 1.0, 0.1177745948690595, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11832483194407929, 0.1183248319440794, 0.2549725581008376], 
reward next is 0.7450, 
noisyNet noise sample is [array([-0.78599817], dtype=float32), -0.93488]. 
=============================================
[2019-03-23 14:15:02,936] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.6434141e-10 1.0000000e+00 1.8239816e-28 3.2667511e-15 3.0189289e-34], sum to 1.0000
[2019-03-23 14:15:02,944] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4013
[2019-03-23 14:15:02,950] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333334, 98.0, 1.0, 2.0, 0.3115481504541676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 339094.4452016596, 339094.4452016593, 112248.9429774826], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4256400.0000, 
sim time next is 4257000.0000, 
raw observation next is [16.5, 97.0, 1.0, 2.0, 0.3104689424536223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 338325.302756962, 338325.3027569623, 112317.4164684966], 
processed observation next is [1.0, 0.2608695652173913, 0.38636363636363635, 0.97, 1.0, 1.0, 0.13808617806702783, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12530566768776372, 0.12530566768776383, 0.2739449182158454], 
reward next is 0.7261, 
noisyNet noise sample is [array([1.1843792], dtype=float32), 2.6007552]. 
=============================================
[2019-03-23 14:15:02,964] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[63.215374]
 [63.21049 ]
 [63.452187]
 [63.538982]
 [63.603382]], R is [[63.25298691]
 [63.34667969]
 [63.43746948]
 [63.53153229]
 [63.6252594 ]].
[2019-03-23 14:15:08,046] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 14:15:08,047] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:15:08,048] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:15:08,048] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:15:08,049] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:15:08,050] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:15:08,051] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:15:08,052] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:15:08,049] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:15:08,053] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:15:08,055] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:15:08,072] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run65
[2019-03-23 14:15:08,098] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run65
[2019-03-23 14:15:08,122] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run65
[2019-03-23 14:15:08,123] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run65
[2019-03-23 14:15:08,146] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run65
[2019-03-23 14:15:34,809] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.5319257]
[2019-03-23 14:15:34,810] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.0, 74.0, 1.0, 2.0, 0.6038424209281738, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9702590194697985, 6.911199999999999, 6.9112, 77.32846344354091, 1237524.344167022, 1237524.344167023, 271565.4123748221]
[2019-03-23 14:15:34,811] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:15:34,813] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.6734239e-11 1.0000000e+00 7.4247214e-28 4.0579323e-10 3.7604691e-36], sampled 0.4852106515149781
[2019-03-23 14:15:34,817] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1237524.344167022 W.
[2019-03-23 14:15:35,225] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.5319257]
[2019-03-23 14:15:35,226] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.5, 85.0, 1.0, 2.0, 0.7889410826614125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 900420.2932573862, 900420.2932573862, 184576.6244016683]
[2019-03-23 14:15:35,227] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:15:35,229] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.3577108e-12 1.0000000e+00 9.7206635e-30 6.3965343e-12 4.7483817e-38], sampled 0.7887493327893152
[2019-03-23 14:15:43,957] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.5319257]
[2019-03-23 14:15:43,959] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.85, 80.0, 1.0, 2.0, 0.4603884188231069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 525056.4988569678, 525056.4988569674, 139822.2361123892]
[2019-03-23 14:15:43,960] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:15:43,963] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.12103927e-11 1.00000000e+00 9.68064561e-33 1.13810755e-17
 0.00000000e+00], sampled 0.4730071345644413
[2019-03-23 14:15:45,930] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.5319257]
[2019-03-23 14:15:45,932] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.68674695, 57.767012655, 1.0, 2.0, 0.3738886421193985, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 419184.522854668, 419184.522854668, 125781.4607668372]
[2019-03-23 14:15:45,933] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:15:45,937] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.2540140e-11 1.0000000e+00 2.8175633e-32 1.9268721e-17 0.0000000e+00], sampled 0.8047644252687913
[2019-03-23 14:16:00,953] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.5319257]
[2019-03-23 14:16:00,955] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.25, 61.66666666666667, 1.0, 2.0, 0.3566885519697873, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 396482.6717767558, 396482.6717767554, 122820.4110381474]
[2019-03-23 14:16:00,956] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:16:00,959] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.0547574e-11 1.0000000e+00 2.6105161e-32 1.8954362e-17 0.0000000e+00], sampled 0.15496503617313628
[2019-03-23 14:16:03,003] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.5319257]
[2019-03-23 14:16:03,004] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.0, 100.0, 1.0, 2.0, 0.622074511099224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 699572.9680630157, 699572.968063016, 147379.2489082561]
[2019-03-23 14:16:03,004] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:16:03,007] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.5959814e-12 1.0000000e+00 2.8944226e-31 1.0137663e-14 0.0000000e+00], sampled 0.5279791587767194
[2019-03-23 14:16:29,570] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.5319257]
[2019-03-23 14:16:29,571] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.36666666666667, 56.83333333333333, 1.0, 2.0, 0.4038933584420536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 438581.6787025275, 438581.6787025272, 123069.7154700402]
[2019-03-23 14:16:29,572] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:16:29,576] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.3619175e-12 1.0000000e+00 2.8222196e-33 1.0252726e-17 0.0000000e+00], sampled 0.835191387166213
[2019-03-23 14:16:35,113] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.5319257]
[2019-03-23 14:16:35,113] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [10.02106593, 91.04662725, 1.0, 2.0, 0.2595844365931598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 55.49369071677366, 281889.7800634753, 281889.7800634753, 61134.53226444587]
[2019-03-23 14:16:35,115] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:16:35,117] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.7585833e-11 1.0000000e+00 6.0049369e-33 9.0146499e-18 0.0000000e+00], sampled 0.779580045705445
[2019-03-23 14:16:51,424] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:16:51,826] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 14:16:51,842] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 14:16:51,860] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 14:16:51,943] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 14:16:52,961] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1600000, evaluation results [1600000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 14:16:57,806] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.7469458e-09 1.0000000e+00 5.5343526e-32 4.4553778e-19 1.6005634e-38], sum to 1.0000
[2019-03-23 14:16:57,817] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7689
[2019-03-23 14:16:57,820] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.4078062964738363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 462123.3719804597, 462123.3719804597, 127077.8129050841], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4428600.0000, 
sim time next is 4429200.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.4078241235968862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 462148.5021010289, 462148.5021010286, 127082.7944508396], 
processed observation next is [0.0, 0.2608695652173913, 0.5909090909090909, 0.83, 1.0, 1.0, 0.2597801544961077, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17116611188926997, 0.17116611188926983, 0.3099580352459502], 
reward next is 0.6900, 
noisyNet noise sample is [array([0.9709327], dtype=float32), -0.010943268]. 
=============================================
[2019-03-23 14:16:58,956] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.4049804e-09 1.0000000e+00 3.1768645e-31 2.8808815e-18 0.0000000e+00], sum to 1.0000
[2019-03-23 14:16:58,967] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0738
[2019-03-23 14:16:58,976] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 81.33333333333334, 1.0, 2.0, 0.4812188917576605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 549107.309003255, 549107.309003255, 138617.868606542], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4476000.0000, 
sim time next is 4476600.0000, 
raw observation next is [23.0, 80.5, 1.0, 2.0, 0.4780033534584129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 545401.8148420979, 545401.8148420979, 138014.8854261381], 
processed observation next is [0.0, 0.8260869565217391, 0.6818181818181818, 0.805, 1.0, 1.0, 0.34750419182301606, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20200067216373999, 0.20200067216373999, 0.3366216717710685], 
reward next is 0.6634, 
noisyNet noise sample is [array([-0.5178649], dtype=float32), -0.99230015]. 
=============================================
[2019-03-23 14:17:01,653] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.13617524e-07 9.99999881e-01 6.58918261e-30 1.71691014e-17
 2.81934184e-36], sum to 1.0000
[2019-03-23 14:17:01,661] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0221
[2019-03-23 14:17:01,665] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.4984969799084182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 568504.6540156854, 568504.6540156854, 141909.1799212786], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4527600.0000, 
sim time next is 4528200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5000855555840359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 570316.6669871402, 570316.6669871402, 142096.0399269016], 
processed observation next is [0.0, 0.391304347826087, 0.6363636363636364, 0.94, 1.0, 1.0, 0.37510694448004483, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2112283951804223, 0.2112283951804223, 0.3465757071387844], 
reward next is 0.6534, 
noisyNet noise sample is [array([0.34421346], dtype=float32), 0.7906318]. 
=============================================
[2019-03-23 14:17:08,268] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.6917108e-10 1.0000000e+00 3.7489612e-32 5.5825063e-17 0.0000000e+00], sum to 1.0000
[2019-03-23 14:17:08,278] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2799
[2019-03-23 14:17:08,282] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 73.66666666666667, 1.0, 2.0, 0.2699091308117739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 293071.6016603995, 293071.6016603992, 92803.50591762588], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4662600.0000, 
sim time next is 4663200.0000, 
raw observation next is [17.66666666666667, 74.33333333333334, 1.0, 2.0, 0.2677887603696582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 290768.5816543337, 290768.581654334, 91763.70488888826], 
processed observation next is [1.0, 1.0, 0.4393939393939396, 0.7433333333333334, 1.0, 1.0, 0.08473595046207275, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10769206727938285, 0.10769206727938295, 0.2238139143631421], 
reward next is 0.7762, 
noisyNet noise sample is [array([-1.1853], dtype=float32), -0.3590766]. 
=============================================
[2019-03-23 14:17:09,327] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.2989150e-12 1.0000000e+00 3.4166657e-36 1.6274304e-17 0.0000000e+00], sum to 1.0000
[2019-03-23 14:17:09,336] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0761
[2019-03-23 14:17:09,340] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 88.0, 1.0, 2.0, 0.2010674232733537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 218305.4117290522, 218305.4117290519, 73247.96349238147], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4683000.0000, 
sim time next is 4683600.0000, 
raw observation next is [14.0, 88.0, 1.0, 2.0, 0.200442528112647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 217626.7910411878, 217626.7910411878, 73180.99076916117], 
processed observation next is [1.0, 0.21739130434782608, 0.2727272727272727, 0.88, 1.0, 1.0, 0.0005531601408087505, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08060251520043993, 0.08060251520043993, 0.17849022138819798], 
reward next is 0.8215, 
noisyNet noise sample is [array([-0.7205177], dtype=float32), 1.3698448]. 
=============================================
[2019-03-23 14:17:10,105] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.6593319e-12 1.0000000e+00 8.9452727e-35 1.5409612e-17 0.0000000e+00], sum to 1.0000
[2019-03-23 14:17:10,112] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6609
[2019-03-23 14:17:10,116] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 87.00000000000001, 1.0, 2.0, 0.2194727158757639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 238293.528875358, 238293.528875358, 74672.27844658685], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4684200.0000, 
sim time next is 4684800.0000, 
raw observation next is [14.0, 86.0, 1.0, 2.0, 0.2105302754364159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 228581.9508431006, 228581.9508431003, 73724.72356642838], 
processed observation next is [1.0, 0.21739130434782608, 0.2727272727272727, 0.86, 1.0, 1.0, 0.013162844295519852, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08465998179374097, 0.08465998179374085, 0.17981639894250825], 
reward next is 0.8202, 
noisyNet noise sample is [array([0.53055096], dtype=float32), 0.688164]. 
=============================================
[2019-03-23 14:17:13,756] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.3210605e-09 1.0000000e+00 1.1328113e-30 3.9881461e-17 1.2883630e-37], sum to 1.0000
[2019-03-23 14:17:13,764] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6074
[2019-03-23 14:17:13,770] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3739746812178723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 419842.3906121263, 419842.390612126, 121736.4368353642], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4770600.0000, 
sim time next is 4771200.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3676180742593604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 412686.5390323272, 412686.5390323272, 121188.2040947743], 
processed observation next is [1.0, 0.21739130434782608, 0.45454545454545453, 1.0, 1.0, 1.0, 0.20952259282420047, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15284686630826932, 0.15284686630826932, 0.29558098559701046], 
reward next is 0.7044, 
noisyNet noise sample is [array([-0.92443556], dtype=float32), 0.21109252]. 
=============================================
[2019-03-23 14:17:15,577] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3769743e-08 9.9999976e-01 8.6013032e-20 2.5104012e-07 1.6953282e-25], sum to 1.0000
[2019-03-23 14:17:15,586] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2685
[2019-03-23 14:17:15,592] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1111023.290672842 W.
[2019-03-23 14:17:15,600] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.66666666666667, 96.0, 1.0, 2.0, 0.4884939648131923, 1.0, 1.0, 0.4884939648131923, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1111023.290672842, 1111023.290672842, 228521.4428467782], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4801200.0000, 
sim time next is 4801800.0000, 
raw observation next is [21.83333333333334, 95.0, 1.0, 2.0, 0.4922947749668048, 1.0, 2.0, 0.4922947749668048, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1118411.004384887, 1118411.004384887, 230075.230431726], 
processed observation next is [1.0, 0.5652173913043478, 0.628787878787879, 0.95, 1.0, 1.0, 0.365368468708506, 1.0, 1.0, 0.365368468708506, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4142262979203285, 0.4142262979203285, 0.5611590986139658], 
reward next is 0.4388, 
noisyNet noise sample is [array([-1.1716275], dtype=float32), 0.61094284]. 
=============================================
[2019-03-23 14:17:19,123] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.3152176e-13 1.0000000e+00 1.4084902e-29 1.4918334e-14 2.4017455e-34], sum to 1.0000
[2019-03-23 14:17:19,134] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7200
[2019-03-23 14:17:19,139] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.4634748584484546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 528660.754092332, 528660.754092332, 135912.5286652597], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4831200.0000, 
sim time next is 4831800.0000, 
raw observation next is [21.0, 94.00000000000001, 1.0, 2.0, 0.4614734026214813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 526347.2341572782, 526347.2341572782, 135628.7829817845], 
processed observation next is [1.0, 0.9565217391304348, 0.5909090909090909, 0.9400000000000002, 1.0, 1.0, 0.32684175327685155, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1949434200582512, 0.1949434200582512, 0.3308019097116695], 
reward next is 0.6692, 
noisyNet noise sample is [array([-0.6366513], dtype=float32), 0.80841297]. 
=============================================
[2019-03-23 14:17:22,785] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.1753289e-12 1.0000000e+00 6.9277189e-32 2.6901995e-17 4.6562200e-38], sum to 1.0000
[2019-03-23 14:17:22,795] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3377
[2019-03-23 14:17:22,798] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5044632631784157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 575308.1216672318, 575308.1216672318, 142616.198997969], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5256000.0000, 
sim time next is 5256600.0000, 
raw observation next is [22.0, 94.00000000000001, 1.0, 2.0, 0.502438074223152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 572998.042733782, 572998.042733782, 142376.7688173873], 
processed observation next is [1.0, 0.8695652173913043, 0.6363636363636364, 0.9400000000000002, 1.0, 1.0, 0.37804759277893996, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21222149730880813, 0.21222149730880813, 0.3472604117497251], 
reward next is 0.6527, 
noisyNet noise sample is [array([0.9220552], dtype=float32), -0.7009391]. 
=============================================
[2019-03-23 14:17:23,916] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.19802063e-12 1.00000000e+00 1.85496620e-30 3.82468436e-16
 1.08242295e-35], sum to 1.0000
[2019-03-23 14:17:23,928] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5739
[2019-03-23 14:17:23,932] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.5188150923229332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 569011.1481951758, 569011.1481951762, 130316.4644521534], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4956600.0000, 
sim time next is 4957200.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.5136556265279839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 563418.3496465817, 563418.3496465817, 129850.1772988182], 
processed observation next is [1.0, 0.391304347826087, 0.4090909090909091, 0.94, 1.0, 1.0, 0.39206953315997983, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20867346283206728, 0.20867346283206728, 0.3167077495093127], 
reward next is 0.6833, 
noisyNet noise sample is [array([0.68253607], dtype=float32), -1.3658444]. 
=============================================
[2019-03-23 14:17:30,890] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.1057512e-10 1.0000000e+00 2.9888999e-31 4.2836699e-17 1.2240487e-37], sum to 1.0000
[2019-03-23 14:17:30,898] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0380
[2019-03-23 14:17:30,904] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.83333333333333, 1.0, 2.0, 0.4222681988924745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 479958.2522027525, 479958.2522027525, 129526.2586143676], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5097000.0000, 
sim time next is 5097600.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.4198812988407658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 476935.7398152747, 476935.739815275, 129039.0891290468], 
processed observation next is [0.0, 0.0, 0.6363636363636364, 0.78, 1.0, 1.0, 0.2748516235509572, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1766428665982499, 0.17664286659825001, 0.31472948568060194], 
reward next is 0.6853, 
noisyNet noise sample is [array([0.15977529], dtype=float32), -0.4920499]. 
=============================================
[2019-03-23 14:17:31,241] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.4886242e-11 1.0000000e+00 7.5983426e-32 6.4956879e-17 6.6013837e-38], sum to 1.0000
[2019-03-23 14:17:31,253] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7077
[2019-03-23 14:17:31,260] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 60.33333333333334, 1.0, 2.0, 0.3547009803813498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 397405.8090113272, 397405.8090113272, 119730.7924657525], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5051400.0000, 
sim time next is 5052000.0000, 
raw observation next is [23.33333333333334, 59.66666666666667, 1.0, 2.0, 0.3548661972544613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 397803.3600179646, 397803.3600179646, 119846.0049458088], 
processed observation next is [0.0, 0.4782608695652174, 0.6969696969696972, 0.5966666666666667, 1.0, 1.0, 0.19358274656807659, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14733457778443135, 0.14733457778443135, 0.292307329136119], 
reward next is 0.7077, 
noisyNet noise sample is [array([0.8993397], dtype=float32), 0.067225635]. 
=============================================
[2019-03-23 14:17:31,271] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[67.321465]
 [67.262596]
 [67.2094  ]
 [67.15657 ]
 [67.12132 ]], R is [[67.41194916]
 [67.44580841]
 [67.47927856]
 [67.51165771]
 [67.54299927]].
[2019-03-23 14:17:40,984] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 14:17:40,985] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:17:40,985] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:17:40,987] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:17:40,987] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:17:40,988] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:17:40,990] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:17:40,990] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:17:40,989] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:17:40,990] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:17:40,992] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:17:41,019] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run66
[2019-03-23 14:17:41,044] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run66
[2019-03-23 14:17:41,068] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run66
[2019-03-23 14:17:41,069] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run66
[2019-03-23 14:17:41,125] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run66
[2019-03-23 14:17:45,074] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.53047085]
[2019-03-23 14:17:45,076] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.63333333333333, 30.33333333333334, 1.0, 2.0, 0.3374197913061668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 366377.0343897753, 366377.034389775, 97488.86105562192]
[2019-03-23 14:17:45,077] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:17:45,079] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.2008460e-09 1.0000000e+00 5.0631982e-29 1.1022515e-15 6.0058469e-35], sampled 0.13831447582638434
[2019-03-23 14:17:46,756] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.53047085]
[2019-03-23 14:17:46,758] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.33333333333334, 79.66666666666667, 1.0, 2.0, 0.3384030719676079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 374410.9639224412, 374410.9639224416, 120670.8277102502]
[2019-03-23 14:17:46,760] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:17:46,763] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.1695860e-09 1.0000000e+00 1.6895550e-27 1.1101902e-13 3.3101491e-33], sampled 0.8586105103893487
[2019-03-23 14:18:19,275] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.53047085]
[2019-03-23 14:18:19,275] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.01238285333333, 84.19346379000001, 1.0, 2.0, 0.4719315573951924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 538419.2345925567, 538419.2345925564, 142442.9832819628]
[2019-03-23 14:18:19,277] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:18:19,279] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.3058948e-09 1.0000000e+00 2.0161381e-29 3.6741102e-16 1.8808911e-35], sampled 0.44692706780971936
[2019-03-23 14:18:34,849] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.53047085]
[2019-03-23 14:18:34,849] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.83333333333333, 56.83333333333334, 1.0, 2.0, 0.3926228112155678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 444018.5941844452, 444018.5941844452, 129420.1635384873]
[2019-03-23 14:18:34,851] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:18:34,856] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.5378021e-09 1.0000000e+00 9.9329777e-30 2.1251711e-16 7.6164938e-36], sampled 0.7709641580530356
[2019-03-23 14:18:50,306] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.53047085]
[2019-03-23 14:18:50,309] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.889859795, 66.54931178999999, 1.0, 2.0, 0.332817826850288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 366681.0442299647, 366681.0442299647, 119644.0241898815]
[2019-03-23 14:18:50,311] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:18:50,314] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.6664182e-09 1.0000000e+00 3.6048806e-28 1.2904292e-14 6.2675058e-34], sampled 0.6604850361582268
[2019-03-23 14:18:53,389] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01433507], dtype=float32), -0.53047085]
[2019-03-23 14:18:53,392] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.6, 51.0, 1.0, 2.0, 0.8508516581404496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 967768.4945002882, 967768.4945002882, 188992.926548294]
[2019-03-23 14:18:53,393] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:18:53,398] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.4121838e-09 1.0000000e+00 2.2450350e-27 4.2302425e-14 5.5260169e-33], sampled 0.4933228276666639
[2019-03-23 14:19:23,641] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:19:23,710] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.7303 1663721990.8039 104.0000
[2019-03-23 14:19:23,887] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8577.1424 1682848735.3926 212.0000
[2019-03-23 14:19:23,997] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.9398 1705910596.8174 464.0000
[2019-03-23 14:19:24,030] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.4991 1772289300.4412 173.0000
[2019-03-23 14:19:25,046] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1625000, evaluation results [1625000.0, 8511.499103214292, 1772289300.441162, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.730274146657, 1663721990.8038862, 104.0, 8597.939758372268, 1705910596.817383, 464.0, 8577.14243377717, 1682848735.3926203, 212.0]
[2019-03-23 14:19:34,128] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.4560332e-12 1.0000000e+00 1.1084989e-33 1.9520255e-18 0.0000000e+00], sum to 1.0000
[2019-03-23 14:19:34,137] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4625
[2019-03-23 14:19:34,141] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.38333333333333, 95.0, 1.0, 2.0, 0.3324295737164704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 366804.1771581601, 366804.1771581604, 115510.4856929733], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5469000.0000, 
sim time next is 5469600.0000, 
raw observation next is [17.56666666666667, 94.0, 1.0, 2.0, 0.3408441789054418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 376582.669593591, 376582.669593591, 116332.0987962633], 
processed observation next is [1.0, 0.30434782608695654, 0.434848484848485, 0.94, 1.0, 1.0, 0.1760552236318022, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13947506281244113, 0.13947506281244113, 0.2837368263323495], 
reward next is 0.7163, 
noisyNet noise sample is [array([1.4868022], dtype=float32), 1.6587539]. 
=============================================
[2019-03-23 14:19:34,346] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.3875915e-11 1.0000000e+00 8.8723522e-33 4.9122098e-16 0.0000000e+00], sum to 1.0000
[2019-03-23 14:19:34,357] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5258
[2019-03-23 14:19:34,361] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 91.66666666666666, 1.0, 2.0, 0.3266550761551892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 357410.055713587, 357410.0557135867, 113954.584086342], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5460600.0000, 
sim time next is 5461200.0000, 
raw observation next is [17.2, 90.0, 1.0, 2.0, 0.3203618277270365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 349246.3897203763, 349246.3897203763, 113052.1303451766], 
processed observation next is [1.0, 0.21739130434782608, 0.41818181818181815, 0.9, 1.0, 1.0, 0.15045228465879557, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12935051471125047, 0.12935051471125047, 0.27573690328091854], 
reward next is 0.7243, 
noisyNet noise sample is [array([-1.0436034], dtype=float32), 0.19832872]. 
=============================================
[2019-03-23 14:19:35,138] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.6201578e-13 1.0000000e+00 3.7304071e-29 5.8068683e-10 6.1926114e-37], sum to 1.0000
[2019-03-23 14:19:35,144] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5130
[2019-03-23 14:19:35,148] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 95.66666666666667, 1.0, 2.0, 0.3897283972857394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 439197.6405743325, 439197.6405743325, 123942.422193243], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5440800.0000, 
sim time next is 5441400.0000, 
raw observation next is [18.8, 95.0, 1.0, 2.0, 0.3875191256664936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 436368.2788051249, 436368.2788051246, 123566.239880875], 
processed observation next is [1.0, 1.0, 0.49090909090909096, 0.95, 1.0, 1.0, 0.23439890708311698, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16161788103893515, 0.16161788103893504, 0.30138107288018295], 
reward next is 0.6986, 
noisyNet noise sample is [array([-0.69995016], dtype=float32), -0.6902024]. 
=============================================
[2019-03-23 14:19:35,243] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.3561375e-10 3.6144629e-02 3.4039872e-21 9.6385539e-01 6.6569610e-28], sum to 1.0000
[2019-03-23 14:19:35,250] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0553
[2019-03-23 14:19:35,253] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.8, 83.66666666666667, 1.0, 2.0, 0.4011665450871494, 1.0, 1.0, 0.4011665450871494, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 915800.6174273356, 915800.6174273358, 203342.6120247788], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5478000.0000, 
sim time next is 5478600.0000, 
raw observation next is [22.25, 82.83333333333334, 1.0, 2.0, 0.4096299021300381, 1.0, 2.0, 0.4096299021300381, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 935101.3056346566, 935101.3056346566, 206825.9728213839], 
processed observation next is [1.0, 0.391304347826087, 0.6477272727272727, 0.8283333333333335, 1.0, 1.0, 0.2620373776625476, 1.0, 1.0, 0.2620373776625476, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.34633381690172466, 0.34633381690172466, 0.5044535922472778], 
reward next is 0.4955, 
noisyNet noise sample is [array([-1.6009345], dtype=float32), 0.43503988]. 
=============================================
[2019-03-23 14:19:36,276] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.5256151e-12 1.0000000e+00 2.2379432e-30 2.6438914e-15 7.9623447e-35], sum to 1.0000
[2019-03-23 14:19:36,287] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0953
[2019-03-23 14:19:36,291] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.53333333333333, 67.33333333333333, 1.0, 2.0, 0.4859855118875488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 554499.0339686736, 554499.0339686736, 139817.6860439459], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5514000.0000, 
sim time next is 5514600.0000, 
raw observation next is [25.26666666666667, 69.16666666666667, 1.0, 2.0, 0.4888479769887009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 557744.8180061703, 557744.8180061703, 140226.9926849105], 
processed observation next is [1.0, 0.8260869565217391, 0.784848484848485, 0.6916666666666668, 1.0, 1.0, 0.36105997123587613, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20657215481710012, 0.20657215481710012, 0.34201705532905], 
reward next is 0.6580, 
noisyNet noise sample is [array([-1.5233151], dtype=float32), -0.3143269]. 
=============================================
[2019-03-23 14:19:36,378] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1120309e-11 1.0000000e+00 1.4451769e-32 5.1376858e-18 3.7258410e-37], sum to 1.0000
[2019-03-23 14:19:36,383] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9526
[2019-03-23 14:19:36,397] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.2, 76.5, 1.0, 2.0, 0.4596358172115907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 524119.8523714778, 524119.8523714778, 135168.7029339673], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5523000.0000, 
sim time next is 5523600.0000, 
raw observation next is [23.1, 77.0, 1.0, 2.0, 0.4568593474838961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 520917.6882117395, 520917.6882117395, 134811.3280431421], 
processed observation next is [1.0, 0.9565217391304348, 0.6863636363636364, 0.77, 1.0, 1.0, 0.3210741843548701, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19293247711545908, 0.19293247711545908, 0.32880811717839536], 
reward next is 0.6712, 
noisyNet noise sample is [array([0.24126418], dtype=float32), -0.15977299]. 
=============================================
[2019-03-23 14:19:39,955] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3096962e-06 9.9998856e-01 2.3997801e-16 1.0121133e-05 1.1828740e-20], sum to 1.0000
[2019-03-23 14:19:39,967] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0183
[2019-03-23 14:19:39,974] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1442038.604040084 W.
[2019-03-23 14:19:39,981] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.25, 58.0, 1.0, 2.0, 0.4269635094489239, 1.0, 2.0, 0.4269635094489239, 1.0, 1.0, 0.862708546084333, 6.911199999999999, 6.9112, 77.3421103, 1442038.604040084, 1442038.604040084, 319459.6129717829], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5578200.0000, 
sim time next is 5578800.0000, 
raw observation next is [28.43333333333333, 57.0, 1.0, 2.0, 0.7828780597430102, 0.0, 1.0, 0.0, 1.0, 2.0, 0.979051556087706, 6.911199999999999, 6.9112, 77.32846344354104, 1436256.997824704, 1436256.997824704, 306908.650348046], 
processed observation next is [1.0, 0.5652173913043478, 0.9287878787878786, 0.57, 1.0, 1.0, 0.7285975746787626, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9700736515538657, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5319470362313719, 0.5319470362313719, 0.7485576837757218], 
reward next is 0.2514, 
noisyNet noise sample is [array([0.09702848], dtype=float32), -1.376637]. 
=============================================
[2019-03-23 14:19:41,192] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.4113301e-09 1.0000000e+00 2.4395161e-23 2.4649731e-09 8.4126423e-27], sum to 1.0000
[2019-03-23 14:19:41,200] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5896
[2019-03-23 14:19:41,202] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 57.0, 1.0, 2.0, 0.4872839418891906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 555779.8287216409, 555779.8287216411, 140486.4146269667], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5594400.0000, 
sim time next is 5595000.0000, 
raw observation next is [26.5, 62.0, 1.0, 2.0, 0.4885156538473523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 557333.4282363129, 557333.4282363129, 140289.7546485621], 
processed observation next is [1.0, 0.782608695652174, 0.8409090909090909, 0.62, 1.0, 1.0, 0.3606445673091903, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20641978823567145, 0.20641978823567145, 0.3421701332891759], 
reward next is 0.6578, 
noisyNet noise sample is [array([0.17307106], dtype=float32), -2.3963735]. 
=============================================
[2019-03-23 14:19:41,222] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[48.992416]
 [49.489548]
 [49.90921 ]
 [49.38086 ]
 [47.151028]], R is [[48.23301697]
 [48.40803528]
 [48.58364868]
 [48.75960159]
 [48.93513489]].
[2019-03-23 14:19:46,379] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.3083172e-08 9.8256069e-01 3.5311618e-16 1.7439332e-02 1.3953937e-21], sum to 1.0000
[2019-03-23 14:19:46,388] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4025
[2019-03-23 14:19:46,394] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1226437.117798804 W.
[2019-03-23 14:19:46,402] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.5, 70.5, 1.0, 2.0, 0.596091772717581, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9759103515515654, 6.911200000000001, 6.9112, 77.32846344354104, 1226437.117798804, 1226437.117798804, 275866.3349313712], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6017400.0000, 
sim time next is 6018000.0000, 
raw observation next is [25.5, 71.0, 1.0, 2.0, 0.626476374827574, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9753994915176263, 6.9112, 6.9112, 77.32846344354104, 1261364.372919842, 1261364.372919842, 279668.8110472257], 
processed observation next is [1.0, 0.6521739130434783, 0.7954545454545454, 0.71, 1.0, 1.0, 0.5330954685344674, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9648564164537519, 0.0, 0.0, 0.5084288129206541, 0.46717198997031184, 0.46717198997031184, 0.6821190513346969], 
reward next is 0.3179, 
noisyNet noise sample is [array([0.867704], dtype=float32), 0.14544621]. 
=============================================
[2019-03-23 14:19:46,418] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[43.197647]
 [42.725677]
 [45.06749 ]
 [44.47995 ]
 [44.171883]], R is [[42.76565933]
 [42.33800125]
 [41.91462326]
 [41.82847977]
 [41.84460449]].
[2019-03-23 14:19:46,753] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.4855759e-06 9.9726629e-01 1.7427642e-12 2.7282038e-03 7.5630783e-16], sum to 1.0000
[2019-03-23 14:19:46,761] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3454
[2019-03-23 14:19:46,768] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [10.71666666666667, 87.83333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 145976.272943368, 145976.272943368, 57324.45494052627], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5727000.0000, 
sim time next is 5727600.0000, 
raw observation next is [11.1, 86.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 150442.7336004584, 150442.7336004587, 57907.22720819731], 
processed observation next is [0.0, 0.30434782608695654, 0.1409090909090909, 0.86, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.055719530963132737, 0.055719530963132854, 0.14123713953218858], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.0171494], dtype=float32), 1.0719634]. 
=============================================
[2019-03-23 14:19:51,847] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.2227824e-10 1.0000000e+00 7.7363693e-38 8.7335302e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 14:19:51,854] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6712
[2019-03-23 14:19:51,859] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 55.0, 1.0, 2.0, 0.3508365266543678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 380978.2688271229, 380978.2688271226, 114490.9128698865], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5824800.0000, 
sim time next is 5825400.0000, 
raw observation next is [21.78333333333334, 54.33333333333334, 1.0, 2.0, 0.3808226893769292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 413554.5081083887, 413554.508108389, 116974.5412300251], 
processed observation next is [1.0, 0.43478260869565216, 0.6265151515151518, 0.5433333333333334, 1.0, 1.0, 0.22602836172116147, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15316833633644025, 0.15316833633644036, 0.28530375909762223], 
reward next is 0.7147, 
noisyNet noise sample is [array([-0.06334883], dtype=float32), -0.71557003]. 
=============================================
[2019-03-23 14:20:01,949] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.4904620e-08 1.0000000e+00 5.1225467e-30 1.0457451e-18 4.4480881e-36], sum to 1.0000
[2019-03-23 14:20:01,956] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0035
[2019-03-23 14:20:01,962] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.86666666666667, 74.33333333333334, 1.0, 2.0, 0.5574914355708759, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 624209.7570064282, 624209.7570064284, 138796.3089383842], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5991600.0000, 
sim time next is 5992200.0000, 
raw observation next is [21.05, 73.5, 1.0, 2.0, 0.6727169408303043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 754541.0401853174, 754541.0401853172, 152605.0408732859], 
processed observation next is [1.0, 0.34782608695652173, 0.5931818181818183, 0.735, 1.0, 1.0, 0.5908961760378804, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.27945964451308053, 0.2794596445130804, 0.37220741676411195], 
reward next is 0.6278, 
noisyNet noise sample is [array([-1.434931], dtype=float32), -0.5450857]. 
=============================================
[2019-03-23 14:20:04,359] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.06924865e-10 1.00000000e+00 0.00000000e+00 1.25334733e-24
 0.00000000e+00], sum to 1.0000
[2019-03-23 14:20:04,365] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6084
[2019-03-23 14:20:04,370] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.6, 78.0, 1.0, 2.0, 0.3482529342171777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 385741.5672069881, 385741.5672069878, 117278.5149623292], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6036000.0000, 
sim time next is 6036600.0000, 
raw observation next is [19.5, 78.0, 1.0, 2.0, 0.3451982450690521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 381768.960394321, 381768.9603943212, 116809.4428643841], 
processed observation next is [1.0, 0.8695652173913043, 0.5227272727272727, 0.78, 1.0, 1.0, 0.18149780633631513, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14139591125715592, 0.141395911257156, 0.28490108015703436], 
reward next is 0.7151, 
noisyNet noise sample is [array([-0.07991081], dtype=float32), -0.90700537]. 
=============================================
[2019-03-23 14:20:05,685] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.2119154e-09 1.0000000e+00 5.0178000e-37 1.4153941e-23 0.0000000e+00], sum to 1.0000
[2019-03-23 14:20:05,692] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6275
[2019-03-23 14:20:05,696] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.8, 76.0, 1.0, 2.0, 0.2216784694222283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 240689.0286765649, 240689.0286765649, 76799.35049337146], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6075000.0000, 
sim time next is 6075600.0000, 
raw observation next is [16.06666666666667, 74.66666666666667, 1.0, 2.0, 0.2244057218486411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 243650.9047374635, 243650.9047374635, 77441.49270844988], 
processed observation next is [1.0, 0.30434782608695654, 0.3666666666666668, 0.7466666666666667, 1.0, 1.0, 0.030507152310801366, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09024107582869019, 0.09024107582869019, 0.18888168953280457], 
reward next is 0.8111, 
noisyNet noise sample is [array([0.5702298], dtype=float32), 0.93524235]. 
=============================================
[2019-03-23 14:20:05,914] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.9239341e-09 1.0000000e+00 2.4577873e-30 8.7626861e-21 6.2422964e-38], sum to 1.0000
[2019-03-23 14:20:05,924] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7842
[2019-03-23 14:20:05,940] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.56666666666667, 50.33333333333334, 1.0, 2.0, 0.3621310504390671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 393248.1090848544, 393248.1090848544, 115570.9364651491], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6093600.0000, 
sim time next is 6094200.0000, 
raw observation next is [22.93333333333333, 49.16666666666666, 1.0, 2.0, 0.3541324789199662, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 384558.8046003226, 384558.8046003223, 114983.4898363577], 
processed observation next is [1.0, 0.5217391304347826, 0.6787878787878786, 0.4916666666666666, 1.0, 1.0, 0.19266559864995772, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14242918688900838, 0.14242918688900827, 0.2804475361862383], 
reward next is 0.7196, 
noisyNet noise sample is [array([0.46043482], dtype=float32), 1.3236955]. 
=============================================
[2019-03-23 14:20:13,002] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 14:20:13,005] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:20:13,007] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:20:13,008] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:20:13,009] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:20:13,009] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:20:13,009] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:20:13,010] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:20:13,011] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:20:13,011] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:20:13,011] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:20:13,037] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run67
[2019-03-23 14:20:13,064] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run67
[2019-03-23 14:20:13,090] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run67
[2019-03-23 14:20:13,090] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run67
[2019-03-23 14:20:13,147] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run67
[2019-03-23 14:20:38,744] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5240401]
[2019-03-23 14:20:38,745] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.56650738, 58.4644122, 1.0, 2.0, 0.3274380045609883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 356681.018591631, 356681.0185916306, 117769.8662388081]
[2019-03-23 14:20:38,747] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:20:38,751] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.9547788e-09 1.0000000e+00 7.6253316e-36 1.1561110e-22 0.0000000e+00], sampled 0.3474700830172094
[2019-03-23 14:20:46,235] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5240401]
[2019-03-23 14:20:46,236] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.88333333333333, 44.33333333333334, 1.0, 2.0, 0.3173710840158018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 344601.5129267104, 344601.51292671, 92707.92400377835]
[2019-03-23 14:20:46,237] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:20:46,240] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.9782475e-09 1.0000000e+00 4.3745519e-36 8.2146459e-23 0.0000000e+00], sampled 0.020522956731766517
[2019-03-23 14:20:56,789] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5240401]
[2019-03-23 14:20:56,791] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.25, 87.0, 1.0, 2.0, 0.3502257659773099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 386395.6459512385, 386395.6459512381, 121155.1284320642]
[2019-03-23 14:20:56,794] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:20:56,797] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.7360236e-09 1.0000000e+00 7.8617455e-36 1.1903189e-22 0.0000000e+00], sampled 0.1064205807838059
[2019-03-23 14:21:12,791] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5240401]
[2019-03-23 14:21:12,792] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [30.93480113, 46.73489489, 1.0, 2.0, 0.9491523863907064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 1079866.576173855, 1079866.576173855, 216854.324018967]
[2019-03-23 14:21:12,792] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:21:12,797] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.2316767e-08 1.0000000e+00 2.7371634e-33 4.6803188e-21 0.0000000e+00], sampled 0.3474181029450244
[2019-03-23 14:21:12,798] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1079866.576173855 W.
[2019-03-23 14:21:19,709] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5240401]
[2019-03-23 14:21:19,710] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.934304525, 96.34736964, 1.0, 2.0, 0.4038788629838106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 458736.1363427193, 458736.1363427193, 131829.1665259608]
[2019-03-23 14:21:19,712] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:21:19,716] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.1894542e-09 1.0000000e+00 1.0345666e-35 1.4093605e-22 0.0000000e+00], sampled 0.7650721704419357
[2019-03-23 14:21:49,955] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5240401]
[2019-03-23 14:21:49,955] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.05, 61.16666666666667, 1.0, 2.0, 0.60719041004137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 663831.9005438518, 663831.9005438518, 142816.4326043931]
[2019-03-23 14:21:49,958] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:21:49,962] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.5792875e-08 1.0000000e+00 6.0846940e-34 1.8058972e-21 0.0000000e+00], sampled 0.3550060091713927
[2019-03-23 14:21:56,010] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:21:56,094] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 14:21:56,223] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 14:21:56,269] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 14:21:56,447] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 14:21:57,464] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1650000, evaluation results [1650000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 14:22:11,497] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.5985899e-08 1.0000000e+00 5.7675630e-32 1.8498656e-21 0.0000000e+00], sum to 1.0000
[2019-03-23 14:22:11,506] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8512
[2019-03-23 14:22:11,510] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 73.66666666666667, 1.0, 2.0, 0.469753693686724, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 520269.142999238, 520269.142999238, 127572.631693107], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6455400.0000, 
sim time next is 6456000.0000, 
raw observation next is [20.0, 72.33333333333334, 1.0, 2.0, 0.3568955481932563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 393536.5653918713, 393536.5653918713, 117268.8249083241], 
processed observation next is [1.0, 0.7391304347826086, 0.5454545454545454, 0.7233333333333334, 1.0, 1.0, 0.19611943524157036, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14575428347847086, 0.14575428347847086, 0.2860215241666441], 
reward next is 0.7140, 
noisyNet noise sample is [array([-0.07432525], dtype=float32), 1.074239]. 
=============================================
[2019-03-23 14:22:11,527] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[69.20329 ]
 [68.93172 ]
 [68.9819  ]
 [69.027794]
 [69.01463 ]], R is [[69.84510803]
 [69.83551025]
 [69.7576828 ]
 [69.68678284]
 [69.62236023]].
[2019-03-23 14:22:13,913] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.16245076e-10 1.00000000e+00 0.00000000e+00 2.38851749e-25
 0.00000000e+00], sum to 1.0000
[2019-03-23 14:22:13,922] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0561
[2019-03-23 14:22:13,926] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 58.0, 1.0, 2.0, 0.2573448116553187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 279425.1461381757, 279425.146138176, 80929.5388924426], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6552600.0000, 
sim time next is 6553200.0000, 
raw observation next is [18.3, 58.0, 1.0, 2.0, 0.2551797860017956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 277073.690401235, 277073.690401235, 80704.04408169414], 
processed observation next is [1.0, 0.8695652173913043, 0.4681818181818182, 0.58, 1.0, 1.0, 0.06897473250224447, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10261988533379074, 0.10261988533379074, 0.19683913190657107], 
reward next is 0.8032, 
noisyNet noise sample is [array([0.7817663], dtype=float32), 1.2818618]. 
=============================================
[2019-03-23 14:22:17,472] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.4870982e-08 9.9999988e-01 3.5387326e-27 1.0859979e-17 6.1701546e-32], sum to 1.0000
[2019-03-23 14:22:17,475] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8157
[2019-03-23 14:22:17,481] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.88333333333333, 58.83333333333334, 1.0, 2.0, 0.7270683113475145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 811575.9665175374, 811575.9665175371, 157795.7206753604], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6610200.0000, 
sim time next is 6610800.0000, 
raw observation next is [23.06666666666667, 58.66666666666667, 1.0, 2.0, 0.5888705095500675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 658131.8823766798, 658131.8823766798, 141720.9014785327], 
processed observation next is [1.0, 0.5217391304347826, 0.684848484848485, 0.5866666666666667, 1.0, 1.0, 0.4860881369375843, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24375254902839993, 0.24375254902839993, 0.3456607353134944], 
reward next is 0.6543, 
noisyNet noise sample is [array([0.661613], dtype=float32), -1.8920618]. 
=============================================
[2019-03-23 14:22:19,552] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.4623997e-08 9.9999988e-01 1.6509276e-33 7.5606772e-22 0.0000000e+00], sum to 1.0000
[2019-03-23 14:22:19,561] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6353
[2019-03-23 14:22:19,567] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.358518946634396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 400035.842202737, 400035.8422027373, 119293.7018252963], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6666600.0000, 
sim time next is 6667200.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.3555564666249294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 396716.7036304264, 396716.7036304264, 119048.2967152688], 
processed observation next is [1.0, 0.17391304347826086, 0.4681818181818182, 0.93, 1.0, 1.0, 0.19444558328116174, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14693211245571347, 0.14693211245571347, 0.2903616993055337], 
reward next is 0.7096, 
noisyNet noise sample is [array([-1.4012437], dtype=float32), -0.09838842]. 
=============================================
[2019-03-23 14:22:31,931] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.3486685e-07 9.9999964e-01 3.3931620e-32 1.6398534e-20 0.0000000e+00], sum to 1.0000
[2019-03-23 14:22:31,941] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6073
[2019-03-23 14:22:31,945] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.86666666666667, 69.33333333333334, 1.0, 2.0, 0.424516150420243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 483328.0352529646, 483328.0352529649, 130521.1054552806], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6862800.0000, 
sim time next is 6863400.0000, 
raw observation next is [24.15, 68.5, 1.0, 2.0, 0.4298501289165441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 489670.1434233871, 489670.1434233874, 131363.1700146077], 
processed observation next is [0.0, 0.43478260869565216, 0.734090909090909, 0.685, 1.0, 1.0, 0.2873126611456801, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18135931237903224, 0.18135931237903236, 0.32039797564538464], 
reward next is 0.6796, 
noisyNet noise sample is [array([-1.501889], dtype=float32), -0.43878677]. 
=============================================
[2019-03-23 14:22:44,059] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.6018322e-06 9.9999738e-01 1.5739370e-30 8.9760863e-19 2.7100751e-37], sum to 1.0000
[2019-03-23 14:22:44,069] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7707
[2019-03-23 14:22:44,079] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3486156781534118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 388102.0326459363, 388102.0326459363, 118113.4604598618], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7095000.0000, 
sim time next is 7095600.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.3487361066442998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 388234.856754711, 388234.856754711, 118122.4499008419], 
processed observation next is [1.0, 0.13043478260869565, 0.44090909090909086, 0.97, 1.0, 1.0, 0.18592013330537477, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14379068768693, 0.14379068768693, 0.2881035363435168], 
reward next is 0.7119, 
noisyNet noise sample is [array([0.65806615], dtype=float32), -0.67688584]. 
=============================================
[2019-03-23 14:22:45,491] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 14:22:45,494] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:22:45,496] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:22:45,496] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:22:45,497] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:22:45,497] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:22:45,498] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:22:45,498] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:22:45,499] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:22:45,499] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:22:45,499] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:22:45,521] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run68
[2019-03-23 14:22:45,522] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run68
[2019-03-23 14:22:45,573] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run68
[2019-03-23 14:22:45,574] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run68
[2019-03-23 14:22:45,606] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run68
[2019-03-23 14:23:14,168] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5270741]
[2019-03-23 14:23:14,169] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.74849833833333, 42.70757793333333, 1.0, 2.0, 0.2876951200578438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 312370.9782668909, 312370.9782668909, 88041.75426540543]
[2019-03-23 14:23:14,171] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:23:14,173] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.30948913e-08 1.00000000e+00 1.42009755e-33 2.79368014e-21
 0.00000000e+00], sampled 0.5426751344855129
[2019-03-23 14:23:27,385] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5270741]
[2019-03-23 14:23:27,386] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.1045532, 75.405195765, 1.0, 2.0, 0.4182477681856833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 471596.4329707412, 471596.4329707408, 130991.8110176532]
[2019-03-23 14:23:27,389] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:23:27,396] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.35022304e-08 1.00000000e+00 1.60274178e-34 7.22436394e-22
 0.00000000e+00], sampled 0.3175739357303351
[2019-03-23 14:23:35,514] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5270741]
[2019-03-23 14:23:35,516] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.30721268166667, 97.767016125, 1.0, 2.0, 0.3535560537550303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 390137.6273454253, 390137.627345425, 121438.8335620647]
[2019-03-23 14:23:35,517] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:23:35,520] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.819229e-09 1.000000e+00 2.393741e-35 2.181179e-22 0.000000e+00], sampled 0.4537846362752843
[2019-03-23 14:23:42,721] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5270741]
[2019-03-23 14:23:42,724] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.33333333333334, 76.0, 1.0, 2.0, 0.518620247162946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 591545.080603701, 591545.080603701, 148323.6388914722]
[2019-03-23 14:23:42,725] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:23:42,730] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.7426277e-08 1.0000000e+00 1.2788285e-31 4.8943369e-20 4.3815955e-38], sampled 0.35212320652118456
[2019-03-23 14:23:55,444] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5270741]
[2019-03-23 14:23:55,445] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.351820415, 79.642286745, 1.0, 2.0, 0.429103061431144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 488518.1677727566, 488518.1677727566, 135300.3684370108]
[2019-03-23 14:23:55,446] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:23:55,450] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.5716276e-08 1.0000000e+00 1.1855909e-32 1.0747741e-20 0.0000000e+00], sampled 0.021989524413395523
[2019-03-23 14:24:15,897] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5270741]
[2019-03-23 14:24:15,900] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.9, 75.0, 1.0, 2.0, 0.6275928540356981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 711622.242446784, 711622.2424467837, 165341.2705441679]
[2019-03-23 14:24:15,902] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:24:15,905] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.9875469e-08 9.9999988e-01 3.2636350e-31 8.8773178e-20 1.3641504e-37], sampled 0.19388842027490005
[2019-03-23 14:24:20,641] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5270741]
[2019-03-23 14:24:20,644] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.7, 59.0, 1.0, 2.0, 0.4544933702809317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 493550.0317091316, 493550.0317091312, 125205.913646276]
[2019-03-23 14:24:20,645] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:24:20,647] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.3595135e-08 1.0000000e+00 1.9014679e-33 3.4100900e-21 0.0000000e+00], sampled 0.20831550756844397
[2019-03-23 14:24:26,485] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5270741]
[2019-03-23 14:24:26,486] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.01185965166666, 91.900749545, 1.0, 2.0, 0.4218320763294303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 478694.4573166249, 478694.4573166245, 133218.7527326754]
[2019-03-23 14:24:26,487] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:24:26,489] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.0630385e-08 1.0000000e+00 6.9860195e-33 7.7291797e-21 0.0000000e+00], sampled 0.7418038416069446
[2019-03-23 14:24:27,743] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 14:24:28,430] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:24:28,480] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 14:24:28,563] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 14:24:28,674] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 14:24:29,688] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1675000, evaluation results [1675000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 14:24:34,760] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.4619109e-08 1.0000000e+00 3.2124632e-30 4.8978530e-18 1.2312566e-36], sum to 1.0000
[2019-03-23 14:24:34,765] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8010
[2019-03-23 14:24:34,770] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.9, 85.33333333333333, 1.0, 2.0, 0.2096210281071027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 227594.5101849722, 227594.5101849719, 73131.82829662437], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7269000.0000, 
sim time next is 7269600.0000, 
raw observation next is [14.0, 83.66666666666667, 1.0, 2.0, 0.2047935839777773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 222351.9497429699, 222351.9497429699, 72504.71548530653], 
processed observation next is [1.0, 0.13043478260869565, 0.2727272727272727, 0.8366666666666667, 1.0, 1.0, 0.005991979972221617, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08235257397887774, 0.08235257397887774, 0.17684076947635738], 
reward next is 0.8232, 
noisyNet noise sample is [array([0.48591563], dtype=float32), 0.88580424]. 
=============================================
[2019-03-23 14:24:35,264] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.4107298e-09 1.0000000e+00 8.4773962e-34 9.5150715e-21 0.0000000e+00], sum to 1.0000
[2019-03-23 14:24:35,271] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6429
[2019-03-23 14:24:35,278] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.8, 80.0, 1.0, 2.0, 0.2659645323725769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 288787.2226502139, 288787.2226502136, 89925.69389646107], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7258800.0000, 
sim time next is 7259400.0000, 
raw observation next is [16.35, 82.5, 1.0, 2.0, 0.2623340147336939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 284844.0121467164, 284844.0121467161, 88243.60172593076], 
processed observation next is [1.0, 0.0, 0.37954545454545463, 0.825, 1.0, 1.0, 0.07791751841711735, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10549778227656163, 0.10549778227656152, 0.21522829689251405], 
reward next is 0.7848, 
noisyNet noise sample is [array([1.6297358], dtype=float32), -0.09609116]. 
=============================================
[2019-03-23 14:24:38,554] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.8894691e-10 1.0000000e+00 5.1657861e-34 1.5175431e-20 0.0000000e+00], sum to 1.0000
[2019-03-23 14:24:38,561] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1400
[2019-03-23 14:24:38,563] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.36666666666667, 45.0, 1.0, 2.0, 0.810657948460391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 903188.409937692, 903188.409937692, 168185.118246935], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7305600.0000, 
sim time next is 7306200.0000, 
raw observation next is [25.55, 44.5, 1.0, 2.0, 0.9281228769052476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1036321.652059497, 1036321.652059497, 186078.9973958394], 
processed observation next is [1.0, 0.5652173913043478, 0.7977272727272727, 0.445, 1.0, 1.0, 0.9101535961315596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.38382283409611, 0.38382283409611, 0.4538512131605839], 
reward next is 0.5461, 
noisyNet noise sample is [array([0.69766873], dtype=float32), 0.75022143]. 
=============================================
[2019-03-23 14:24:39,295] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.2369276e-09 1.0000000e+00 1.4551550e-34 7.7875384e-22 0.0000000e+00], sum to 1.0000
[2019-03-23 14:24:39,303] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7058
[2019-03-23 14:24:39,310] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.55, 71.5, 1.0, 2.0, 0.3487961044847705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 386515.8965156064, 386515.8965156067, 117389.7122426689], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7338600.0000, 
sim time next is 7339200.0000, 
raw observation next is [20.36666666666667, 72.66666666666667, 1.0, 2.0, 0.3481321985366734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 385685.2244684424, 385685.2244684421, 117300.201846574], 
processed observation next is [1.0, 0.9565217391304348, 0.5621212121212124, 0.7266666666666667, 1.0, 1.0, 0.1851652481708417, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14284637943275644, 0.14284637943275633, 0.2860980532843268], 
reward next is 0.7139, 
noisyNet noise sample is [array([0.73074067], dtype=float32), -0.8952633]. 
=============================================
[2019-03-23 14:24:44,495] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.8302105e-09 1.0000000e+00 2.1677516e-35 1.4314244e-21 0.0000000e+00], sum to 1.0000
[2019-03-23 14:24:44,503] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6708
[2019-03-23 14:24:44,508] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.53333333333333, 85.0, 1.0, 2.0, 0.3868483173644824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 437418.308608358, 437418.3086083583, 124525.8321601542], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7461600.0000, 
sim time next is 7462200.0000, 
raw observation next is [20.81666666666667, 84.5, 1.0, 2.0, 0.3939581267136576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 446243.9436637323, 446243.943663732, 125666.459660997], 
processed observation next is [0.0, 0.34782608695652173, 0.5825757575757577, 0.845, 1.0, 1.0, 0.24244765839207197, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16527553469027123, 0.1652755346902711, 0.30650356014877317], 
reward next is 0.6935, 
noisyNet noise sample is [array([-2.5408146], dtype=float32), 1.179997]. 
=============================================
[2019-03-23 14:24:49,952] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.6459977e-08 9.9999988e-01 1.6944050e-31 6.1730176e-20 4.7170397e-38], sum to 1.0000
[2019-03-23 14:24:49,959] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9610
[2019-03-23 14:24:49,961] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.2, 56.16666666666667, 1.0, 2.0, 0.5061700043625438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576893.0009884045, 576893.0009884045, 143291.9260216209], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7567800.0000, 
sim time next is 7568400.0000, 
raw observation next is [28.1, 56.33333333333334, 1.0, 2.0, 0.504418069118668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 574992.9498880189, 574992.9498880189, 142972.8136656805], 
processed observation next is [0.0, 0.6086956521739131, 0.9136363636363637, 0.5633333333333335, 1.0, 1.0, 0.380522586398335, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21296035181037737, 0.21296035181037737, 0.3487141796723915], 
reward next is 0.6513, 
noisyNet noise sample is [array([-0.5004462], dtype=float32), 0.6063737]. 
=============================================
[2019-03-23 14:24:50,730] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.7797400e-08 1.0000000e+00 1.6638525e-31 2.3094001e-20 6.0087022e-38], sum to 1.0000
[2019-03-23 14:24:50,738] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9427
[2019-03-23 14:24:50,744] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.2, 56.16666666666667, 1.0, 2.0, 0.5061700043625438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576893.0009884045, 576893.0009884045, 143291.9260216209], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7567800.0000, 
sim time next is 7568400.0000, 
raw observation next is [28.1, 56.33333333333334, 1.0, 2.0, 0.504418069118668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 574992.9498880189, 574992.9498880189, 142972.8136656805], 
processed observation next is [0.0, 0.6086956521739131, 0.9136363636363637, 0.5633333333333335, 1.0, 1.0, 0.380522586398335, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21296035181037737, 0.21296035181037737, 0.3487141796723915], 
reward next is 0.6513, 
noisyNet noise sample is [array([0.12936871], dtype=float32), -0.99071753]. 
=============================================
[2019-03-23 14:24:52,536] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3569608e-09 1.0000000e+00 2.0288553e-34 9.0291550e-22 0.0000000e+00], sum to 1.0000
[2019-03-23 14:24:52,549] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8820
[2019-03-23 14:24:52,558] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.45, 61.83333333333334, 1.0, 2.0, 0.479080943323461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 546660.2509918964, 546660.2509918964, 138793.5463987878], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7578600.0000, 
sim time next is 7579200.0000, 
raw observation next is [25.7, 67.66666666666667, 1.0, 2.0, 0.4878007413277032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 556471.1049699124, 556471.1049699124, 140332.0326201703], 
processed observation next is [0.0, 0.7391304347826086, 0.8045454545454546, 0.6766666666666667, 1.0, 1.0, 0.35975092665962893, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2061004092481157, 0.2061004092481157, 0.3422732502930983], 
reward next is 0.6577, 
noisyNet noise sample is [array([-1.4503673], dtype=float32), 0.86489314]. 
=============================================
[2019-03-23 14:24:55,002] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:24:55,002] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:24:55,049] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run9
[2019-03-23 14:25:06,382] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.2780471e-08 1.0000000e+00 2.6115745e-30 6.9324435e-19 2.0982996e-37], sum to 1.0000
[2019-03-23 14:25:06,389] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9292
[2019-03-23 14:25:06,395] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.7980281095254543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 908880.588905085, 908880.588905085, 177560.578849469], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7906200.0000, 
sim time next is 7906800.0000, 
raw observation next is [20.9, 89.0, 1.0, 2.0, 0.6899126735169094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 785665.4198230907, 785665.4198230907, 161925.0481418428], 
processed observation next is [1.0, 0.5217391304347826, 0.5863636363636363, 0.89, 1.0, 1.0, 0.6123908418961368, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2909871925270706, 0.2909871925270706, 0.3949391418093727], 
reward next is 0.6051, 
noisyNet noise sample is [array([1.4750504], dtype=float32), -1.4292833]. 
=============================================
[2019-03-23 14:25:09,459] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:25:09,460] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:25:09,500] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run9
[2019-03-23 14:25:09,684] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:25:09,684] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:25:09,698] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run9
[2019-03-23 14:25:09,740] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:25:09,741] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:25:09,783] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run9
[2019-03-23 14:25:10,132] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:25:10,132] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:25:10,142] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:25:10,143] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:25:10,146] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run9
[2019-03-23 14:25:10,183] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run9
[2019-03-23 14:25:10,265] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:25:10,265] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:25:10,269] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run9
[2019-03-23 14:25:10,472] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:25:10,472] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:25:10,477] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run9
[2019-03-23 14:25:10,639] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:25:10,640] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:25:10,640] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:25:10,643] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run9
[2019-03-23 14:25:10,640] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:25:10,674] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run9
[2019-03-23 14:25:10,745] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:25:10,746] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:25:10,750] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run9
[2019-03-23 14:25:10,845] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:25:10,845] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:25:10,850] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run9
[2019-03-23 14:25:11,045] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:25:11,045] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:25:11,048] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run9
[2019-03-23 14:25:11,173] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:25:11,173] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:25:11,179] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run9
[2019-03-23 14:25:11,246] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:25:11,247] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:25:11,250] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run9
[2019-03-23 14:25:11,385] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:25:11,385] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:25:11,388] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run9
[2019-03-23 14:25:18,785] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 14:25:18,786] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:25:18,787] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:25:18,788] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:25:18,788] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:25:18,789] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:25:18,791] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:25:18,791] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:25:18,793] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:25:18,794] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:25:18,795] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:25:18,816] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run69
[2019-03-23 14:25:18,846] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run69
[2019-03-23 14:25:18,872] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run69
[2019-03-23 14:25:18,872] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run69
[2019-03-23 14:25:18,928] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run69
[2019-03-23 14:25:37,927] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.53246266]
[2019-03-23 14:25:37,928] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.63333333333333, 81.0, 1.0, 2.0, 0.6794599407496961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 766518.8891085752, 766518.8891085747, 159931.987599292]
[2019-03-23 14:25:37,929] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:25:37,932] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.24699095e-08 1.00000000e+00 2.32484966e-36 5.87490969e-23
 0.00000000e+00], sampled 0.8191691640908471
[2019-03-23 14:26:01,581] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.53246266]
[2019-03-23 14:26:01,584] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.951931795, 64.90914090499999, 1.0, 2.0, 0.6122462594340125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 82.00608767066505, 694653.4525533874, 694653.4525533874, 151311.332273706]
[2019-03-23 14:26:01,585] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:26:01,592] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.8013957e-08 1.0000000e+00 1.3367873e-35 1.7828224e-22 0.0000000e+00], sampled 0.23767153683807185
[2019-03-23 14:26:34,275] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.53246266]
[2019-03-23 14:26:34,277] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.5, 90.0, 1.0, 2.0, 0.4155191641408669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 472083.086276988, 472083.086276988, 128700.3444280101]
[2019-03-23 14:26:34,279] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:26:34,283] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.9959495e-08 1.0000000e+00 2.0807180e-35 2.3407778e-22 0.0000000e+00], sampled 0.9081666357753337
[2019-03-23 14:26:46,581] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.53246266]
[2019-03-23 14:26:46,582] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.21666666666667, 70.66666666666667, 1.0, 2.0, 0.4258070845959265, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 483929.9338345004, 483929.9338345004, 134175.2683442838]
[2019-03-23 14:26:46,582] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:26:46,584] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.3299949e-08 1.0000000e+00 2.5574030e-36 6.1705369e-23 0.0000000e+00], sampled 0.5821037893862183
[2019-03-23 14:26:49,549] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.53246266]
[2019-03-23 14:26:49,550] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.98333333333333, 81.16666666666667, 1.0, 2.0, 0.3794947440028856, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 424802.6681932147, 424802.6681932143, 125947.4446388974]
[2019-03-23 14:26:49,551] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:26:49,554] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.39217535e-08 1.00000000e+00 4.93426453e-36 9.47832786e-23
 0.00000000e+00], sampled 0.15156777268863664
[2019-03-23 14:27:01,500] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 14:27:01,673] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 14:27:01,776] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:27:01,814] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 14:27:01,852] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 14:27:02,862] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1700000, evaluation results [1700000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 14:27:04,956] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.18972175 0.44605333 0.01289591 0.34925964 0.00206945], sum to 1.0000
[2019-03-23 14:27:04,959] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4350
[2019-03-23 14:27:04,965] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.83333333333333, 89.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 212779.0505135562, 212779.0505135562, 72154.60416248516], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 186600.0000, 
sim time next is 187200.0000, 
raw observation next is [14.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 214612.8955391621, 214612.8955391624, 72657.29541522531], 
processed observation next is [0.0, 0.17391304347826086, 0.2727272727272727, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07948625760709707, 0.07948625760709718, 0.17721291564689098], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8960206], dtype=float32), 0.4647882]. 
=============================================
[2019-03-23 14:27:26,114] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.3893653e-04 9.9936110e-01 1.9136691e-31 2.8625890e-20 5.9744293e-38], sum to 1.0000
[2019-03-23 14:27:26,119] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3255
[2019-03-23 14:27:26,123] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 83.0, 1.0, 2.0, 0.3053011844579351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 332273.9157875156, 332273.9157875153, 111814.7644030474], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 604200.0000, 
sim time next is 604800.0000, 
raw observation next is [18.0, 83.0, 1.0, 2.0, 0.3051854132995366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 332148.1158842784, 332148.1158842781, 111806.9727754394], 
processed observation next is [1.0, 0.0, 0.45454545454545453, 0.83, 1.0, 1.0, 0.1314817666244207, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12301782069788088, 0.12301782069788077, 0.27269993359863265], 
reward next is 0.7273, 
noisyNet noise sample is [array([-2.5360348], dtype=float32), 0.11291897]. 
=============================================
[2019-03-23 14:27:27,634] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8910860e-05 9.9998105e-01 3.1053659e-33 1.8676420e-21 0.0000000e+00], sum to 1.0000
[2019-03-23 14:27:27,639] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0278
[2019-03-23 14:27:27,643] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 54.5, 1.0, 2.0, 0.4207321994038681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 470742.1919842254, 470742.1919842256, 125130.4178360193], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 651000.0000, 
sim time next is 651600.0000, 
raw observation next is [24.0, 54.0, 1.0, 2.0, 0.4696473163292594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 525076.7476214888, 525076.7476214888, 129507.3613147756], 
processed observation next is [1.0, 0.5652173913043478, 0.7272727272727273, 0.54, 1.0, 1.0, 0.33705914541157417, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1944728694894403, 0.1944728694894403, 0.3158716129628673], 
reward next is 0.6841, 
noisyNet noise sample is [array([0.9723812], dtype=float32), 1.5857528]. 
=============================================
[2019-03-23 14:27:28,014] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2351100e-05 9.9998760e-01 1.6036478e-31 3.4155939e-21 0.0000000e+00], sum to 1.0000
[2019-03-23 14:27:28,022] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4974
[2019-03-23 14:27:28,024] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.16666666666667, 99.0, 1.0, 2.0, 0.2394367839817808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 259975.4023731966, 259975.4023731964, 82637.22653088131], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 622200.0000, 
sim time next is 622800.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.237778277905807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 258174.153565648, 258174.1535656483, 82034.47943843364], 
processed observation next is [1.0, 0.21739130434782608, 0.2727272727272727, 1.0, 1.0, 1.0, 0.04722284738225873, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09562005687616593, 0.09562005687616604, 0.20008409619130157], 
reward next is 0.7999, 
noisyNet noise sample is [array([-0.03585068], dtype=float32), -0.33644944]. 
=============================================
[2019-03-23 14:27:32,579] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.6480079e-02 9.7351992e-01 2.2027805e-14 2.4270241e-09 6.3049414e-17], sum to 1.0000
[2019-03-23 14:27:32,586] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6038
[2019-03-23 14:27:32,594] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1313692.005024707 W.
[2019-03-23 14:27:32,598] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.83333333333333, 58.5, 1.0, 2.0, 0.6707043760171354, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9712873501616395, 6.911199999999999, 6.9112, 77.32846344354104, 1313692.005024707, 1313692.005024707, 281810.0196178632], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 733800.0000, 
sim time next is 734400.0000, 
raw observation next is [27.0, 58.0, 1.0, 2.0, 0.3892982497809303, 1.0, 1.0, 0.3892982497809303, 1.0, 2.0, 0.7885962314616216, 6.911199999999999, 6.9112, 77.3421103, 1327972.968271839, 1327972.968271839, 295858.0810826706], 
processed observation next is [1.0, 0.5217391304347826, 0.8636363636363636, 0.58, 1.0, 1.0, 0.23662281222616285, 1.0, 0.5, 0.23662281222616285, 1.0, 1.0, 0.6979946163737453, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4918418401006811, 0.4918418401006811, 0.7216050758113917], 
reward next is 0.2784, 
noisyNet noise sample is [array([-0.5300021], dtype=float32), 0.13207927]. 
=============================================
[2019-03-23 14:27:37,723] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.3177734e-04 9.9936825e-01 6.0979859e-29 1.2245618e-18 1.1192445e-36], sum to 1.0000
[2019-03-23 14:27:37,732] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0328
[2019-03-23 14:27:37,735] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 60.66666666666666, 1.0, 2.0, 0.5138824072122535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 585628.0492384688, 585628.049238469, 144276.548314711], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 844800.0000, 
sim time next is 845400.0000, 
raw observation next is [27.16666666666666, 61.33333333333334, 1.0, 2.0, 0.5123332837895886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 583929.4797424771, 583929.4797424771, 144018.2681338968], 
processed observation next is [0.0, 0.782608695652174, 0.871212121212121, 0.6133333333333334, 1.0, 1.0, 0.39041660473698575, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21627017768239892, 0.21627017768239892, 0.3512640686192605], 
reward next is 0.6487, 
noisyNet noise sample is [array([0.59534025], dtype=float32), 0.9133581]. 
=============================================
[2019-03-23 14:27:41,668] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0485627e-04 9.9989510e-01 3.0618068e-30 8.0876297e-19 1.1443196e-36], sum to 1.0000
[2019-03-23 14:27:41,673] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6361
[2019-03-23 14:27:41,679] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.4357469089393176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 495765.5165771325, 495765.5165771325, 131291.0864896584], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 931200.0000, 
sim time next is 931800.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.4344637956233835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 494303.4449868612, 494303.4449868612, 131160.4252940213], 
processed observation next is [0.0, 0.782608695652174, 0.5909090909090909, 0.88, 1.0, 1.0, 0.29307974452922936, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18307534999513378, 0.18307534999513378, 0.3199034763268812], 
reward next is 0.6801, 
noisyNet noise sample is [array([-0.3679606], dtype=float32), 2.0398135]. 
=============================================
[2019-03-23 14:27:48,186] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2223143e-05 9.9998772e-01 1.2474450e-33 2.0501688e-21 0.0000000e+00], sum to 1.0000
[2019-03-23 14:27:48,193] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4561
[2019-03-23 14:27:48,197] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4926168909590926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 562053.2479628029, 562053.2479628029, 140638.1040530833], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1383600.0000, 
sim time next is 1384200.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4928981113490927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 562374.0132666683, 562374.0132666685, 140671.4107044684], 
processed observation next is [0.0, 0.0, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3661226391863659, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20828667158024752, 0.2082866715802476, 0.3431010017182156], 
reward next is 0.6569, 
noisyNet noise sample is [array([-1.3243036], dtype=float32), -0.088563345]. 
=============================================
[2019-03-23 14:27:50,965] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 14:27:50,966] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:27:50,967] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:27:50,967] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:27:50,968] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:27:50,969] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:27:50,968] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:27:50,970] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:27:50,972] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:27:50,971] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:27:50,974] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:27:50,988] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run70
[2019-03-23 14:27:51,017] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run70
[2019-03-23 14:27:51,018] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run70
[2019-03-23 14:27:51,052] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run70
[2019-03-23 14:27:51,054] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run70
[2019-03-23 14:27:54,191] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5334083]
[2019-03-23 14:27:54,192] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.45, 33.66666666666667, 1.0, 2.0, 0.3057708512540092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 332002.5014430651, 332002.5014430651, 86974.18092393053]
[2019-03-23 14:27:54,193] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:27:54,199] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.2549359e-05 9.9997747e-01 2.7985309e-31 1.7752453e-19 0.0000000e+00], sampled 0.841098663279846
[2019-03-23 14:27:55,227] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5334083]
[2019-03-23 14:27:55,227] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.70801909333333, 90.82474487333334, 1.0, 2.0, 0.2460883084784692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 267185.4732811078, 267185.4732811082, 86568.55285956156]
[2019-03-23 14:27:55,228] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:27:55,232] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.6238569e-05 9.9994373e-01 2.0356001e-28 1.0566980e-17 3.8072991e-35], sampled 0.8438352605105287
[2019-03-23 14:28:36,336] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5334083]
[2019-03-23 14:28:36,337] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [13.78333333333333, 88.50000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 216140.7545793752, 216140.7545793752, 77004.4524094368]
[2019-03-23 14:28:36,339] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:28:36,345] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.1154133e-05 9.9996889e-01 4.1232140e-30 9.4180076e-19 3.0213766e-37], sampled 0.10779042842485731
[2019-03-23 14:29:04,184] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5334083]
[2019-03-23 14:29:04,185] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.4, 81.33333333333334, 1.0, 2.0, 0.5948097408923162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 662606.1010630616, 662606.1010630616, 145847.8791884706]
[2019-03-23 14:29:04,186] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:29:04,190] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.0358551e-05 9.9996960e-01 1.4197105e-29 2.1139304e-18 1.4711949e-36], sampled 0.01650106855616673
[2019-03-23 14:29:04,554] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5334083]
[2019-03-23 14:29:04,555] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.67036656, 95.76023055, 1.0, 2.0, 0.4757089764446924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 542440.9543892953, 542440.954389295, 141284.6966603109]
[2019-03-23 14:29:04,557] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:29:04,559] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.6144900e-05 9.9997389e-01 4.9705144e-31 2.4949840e-19 2.1124992e-38], sampled 0.11348193455248612
[2019-03-23 14:29:10,278] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5334083]
[2019-03-23 14:29:10,280] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.33333333333334, 45.0, 1.0, 2.0, 0.6486634199476116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 721887.6126921391, 721887.6126921389, 147331.1261635341]
[2019-03-23 14:29:10,282] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:29:10,284] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.1488964e-05 9.9997854e-01 2.9519872e-31 1.8501949e-19 0.0000000e+00], sampled 0.9075994699863555
[2019-03-23 14:29:16,329] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5334083]
[2019-03-23 14:29:16,330] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.61666666666667, 49.83333333333334, 1.0, 2.0, 0.3071405971051007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 333490.1685036264, 333490.168503626, 115978.2766498546]
[2019-03-23 14:29:16,331] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:29:16,334] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.6367799e-05 9.9997365e-01 7.7659091e-31 3.3328415e-19 3.7320995e-38], sampled 0.6961737424606382
[2019-03-23 14:29:18,029] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5334083]
[2019-03-23 14:29:18,030] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.42755963166667, 59.05466135333334, 1.0, 2.0, 0.3851492365112064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 421323.3053194509, 421323.3053194513, 122632.0978336042]
[2019-03-23 14:29:18,031] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:29:18,034] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.3576529e-05 9.9997640e-01 4.5910625e-31 2.4033937e-19 1.9547313e-38], sampled 0.27146346010644895
[2019-03-23 14:29:33,699] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 14:29:34,105] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 14:29:34,171] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 14:29:34,267] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 14:29:34,301] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:29:35,314] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1725000, evaluation results [1725000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 14:29:43,110] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.8907742e-05 9.9993110e-01 1.2443852e-25 4.4256892e-16 5.7574937e-32], sum to 1.0000
[2019-03-23 14:29:43,117] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4113
[2019-03-23 14:29:43,120] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 94.0, 1.0, 2.0, 0.4845365974698492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 552871.0291276808, 552871.0291276808, 138801.271408502], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1236000.0000, 
sim time next is 1236600.0000, 
raw observation next is [21.5, 94.0, 1.0, 2.0, 0.5111215921736657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 583257.0207420805, 583257.0207420805, 142229.5678702007], 
processed observation next is [1.0, 0.30434782608695654, 0.6136363636363636, 0.94, 1.0, 1.0, 0.3889019902170821, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21602111879336316, 0.21602111879336316, 0.34690138504927], 
reward next is 0.6531, 
noisyNet noise sample is [array([-0.78860116], dtype=float32), -1.6112432]. 
=============================================
[2019-03-23 14:29:44,025] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.2634069e-04 9.9977368e-01 1.2543843e-23 5.2831139e-14 1.6090535e-29], sum to 1.0000
[2019-03-23 14:29:44,032] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2841
[2019-03-23 14:29:44,040] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1613633.353044285 W.
[2019-03-23 14:29:44,042] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.0, 58.66666666666666, 1.0, 2.0, 0.4782352220276107, 1.0, 2.0, 0.4782352220276107, 1.0, 2.0, 0.9667243377676721, 6.911199999999999, 6.9112, 77.3421103, 1613633.353044285, 1613633.353044285, 347693.5268219127], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1266600.0000, 
sim time next is 1267200.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.8056081487852388, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9785277919409434, 6.911199999999999, 6.9112, 77.32846344354104, 1462647.612077958, 1462647.612077958, 310175.9257895162], 
processed observation next is [1.0, 0.6956521739130435, 0.9090909090909091, 0.58, 1.0, 1.0, 0.7570101859815483, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9693254170584906, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5417213378066511, 0.5417213378066511, 0.7565266482671127], 
reward next is 0.2435, 
noisyNet noise sample is [array([-0.8956409], dtype=float32), -0.9867537]. 
=============================================
[2019-03-23 14:29:47,108] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.8518431e-06 9.9999416e-01 4.3033216e-29 1.1371592e-17 2.5187000e-36], sum to 1.0000
[2019-03-23 14:29:47,125] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5617
[2019-03-23 14:29:47,129] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 94.00000000000001, 1.0, 2.0, 0.4480783693847389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 509752.1005246878, 509752.1005246875, 132497.9028448156], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1321800.0000, 
sim time next is 1322400.0000, 
raw observation next is [20.66666666666667, 94.0, 1.0, 2.0, 0.4462706018181077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 508409.1649987157, 508409.164998716, 133073.9982583707], 
processed observation next is [1.0, 0.30434782608695654, 0.575757575757576, 0.94, 1.0, 1.0, 0.30783825227263456, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18829969074026506, 0.18829969074026517, 0.3245707274594407], 
reward next is 0.6754, 
noisyNet noise sample is [array([-0.25346893], dtype=float32), 0.8316962]. 
=============================================
[2019-03-23 14:29:49,105] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.9080973e-05 9.9997091e-01 1.2984640e-23 2.4470382e-14 1.5133759e-29], sum to 1.0000
[2019-03-23 14:29:49,112] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1258
[2019-03-23 14:29:49,117] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 91.5, 1.0, 2.0, 0.8806536790181808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1004028.916596205, 1004028.916596205, 198435.2383753793], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1326600.0000, 
sim time next is 1327200.0000, 
raw observation next is [22.66666666666666, 90.66666666666666, 1.0, 2.0, 0.8335348692308497, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 950041.3257989562, 950041.3257989564, 190565.133086224], 
processed observation next is [1.0, 0.34782608695652173, 0.6666666666666664, 0.9066666666666666, 1.0, 1.0, 0.7919185865385622, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3518671577033171, 0.3518671577033172, 0.4647930075273756], 
reward next is 0.5352, 
noisyNet noise sample is [array([0.93700296], dtype=float32), 0.3363728]. 
=============================================
[2019-03-23 14:29:51,576] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.4524117e-05 9.9995542e-01 2.0226730e-29 1.7963040e-18 4.8495136e-36], sum to 1.0000
[2019-03-23 14:29:51,593] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0750
[2019-03-23 14:29:51,602] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 96.0, 1.0, 2.0, 0.4825788112335291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 550657.1097465534, 550657.1097465534, 139156.1086258985], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1381200.0000, 
sim time next is 1381800.0000, 
raw observation next is [21.16666666666666, 98.0, 1.0, 2.0, 0.4856943416163791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 554192.3855675332, 554192.3855675332, 139663.0198598871], 
processed observation next is [1.0, 1.0, 0.5984848484848482, 0.98, 1.0, 1.0, 0.35711792702047385, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20525643909908636, 0.20525643909908636, 0.3406415118533832], 
reward next is 0.6594, 
noisyNet noise sample is [array([0.27554953], dtype=float32), 1.0148996]. 
=============================================
[2019-03-23 14:29:54,057] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.7201881e-07 9.9999976e-01 2.6664256e-31 5.2300087e-19 1.2730031e-37], sum to 1.0000
[2019-03-23 14:29:54,063] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4828
[2019-03-23 14:29:54,068] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 100.0, 1.0, 2.0, 0.4723400015681615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 538975.9569223528, 538975.9569223528, 137722.8447298801], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1480800.0000, 
sim time next is 1481400.0000, 
raw observation next is [20.5, 100.0, 1.0, 2.0, 0.4668148540565634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 532622.800517931, 532622.8005179312, 136752.9857209871], 
processed observation next is [0.0, 0.13043478260869565, 0.5681818181818182, 1.0, 1.0, 1.0, 0.33351856757070425, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19726770389553, 0.19726770389553008, 0.3335438676121637], 
reward next is 0.6665, 
noisyNet noise sample is [array([-2.194334], dtype=float32), -0.9277108]. 
=============================================
[2019-03-23 14:29:56,155] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.0634066e-05 9.9997938e-01 3.5452891e-30 1.4380132e-19 2.2047828e-37], sum to 1.0000
[2019-03-23 14:29:56,163] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0249
[2019-03-23 14:29:56,172] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 91.5, 1.0, 2.0, 0.5021772900640278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 572483.1014518024, 572483.1014518021, 142652.9660331589], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1521000.0000, 
sim time next is 1521600.0000, 
raw observation next is [23.0, 88.66666666666666, 1.0, 2.0, 0.5059301573624307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576521.6865230842, 576521.6865230842, 143366.7844683559], 
processed observation next is [0.0, 0.6086956521739131, 0.6818181818181818, 0.8866666666666666, 1.0, 1.0, 0.3824126967030384, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21352655056410524, 0.21352655056410524, 0.34967508406916076], 
reward next is 0.6503, 
noisyNet noise sample is [array([0.84940153], dtype=float32), -0.22662236]. 
=============================================
[2019-03-23 14:30:09,956] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0418504e-04 9.9979585e-01 1.6637523e-33 1.0210927e-20 0.0000000e+00], sum to 1.0000
[2019-03-23 14:30:09,964] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5128
[2019-03-23 14:30:09,973] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 51.00000000000001, 1.0, 2.0, 0.3259521658307207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 353946.1602582484, 353946.1602582481, 81016.89369270927], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1765200.0000, 
sim time next is 1765800.0000, 
raw observation next is [16.0, 51.0, 1.0, 2.0, 0.3167137560314527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 343910.7737660002, 343910.7737660002, 80076.70285680822], 
processed observation next is [1.0, 0.43478260869565216, 0.36363636363636365, 0.51, 1.0, 1.0, 0.14589219503931583, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12737436065407415, 0.12737436065407415, 0.19530903135806882], 
reward next is 0.8047, 
noisyNet noise sample is [array([-0.09300178], dtype=float32), 1.2619661]. 
=============================================
[2019-03-23 14:30:13,586] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.3673844e-04 9.9926323e-01 8.4945786e-34 8.8158685e-18 0.0000000e+00], sum to 1.0000
[2019-03-23 14:30:13,591] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9093
[2019-03-23 14:30:13,596] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.5, 85.0, 1.0, 2.0, 0.4360185194424793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 473523.6250762747, 473523.6250762747, 95301.72623800485], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1839000.0000, 
sim time next is 1839600.0000, 
raw observation next is [14.0, 82.0, 1.0, 2.0, 0.3412719178780543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 370587.9691075918, 370587.9691075918, 86471.35598834674], 
processed observation next is [1.0, 0.30434782608695654, 0.2727272727272727, 0.82, 1.0, 1.0, 0.17658989734756783, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13725480337318213, 0.13725480337318213, 0.21090574631304082], 
reward next is 0.7891, 
noisyNet noise sample is [array([-0.05517711], dtype=float32), 1.6908324]. 
=============================================
[2019-03-23 14:30:14,478] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.3487696e-06 9.9999368e-01 1.7909563e-30 1.8244534e-17 0.0000000e+00], sum to 1.0000
[2019-03-23 14:30:14,489] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5145
[2019-03-23 14:30:14,493] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [10.5, 100.0, 1.0, 2.0, 0.3406353537548021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 369896.4597298147, 369896.459729815, 82214.55982577291], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1834200.0000, 
sim time next is 1834800.0000, 
raw observation next is [10.66666666666667, 100.0, 1.0, 2.0, 0.3036693198383476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 329741.3762468422, 329741.3762468425, 79154.4375450861], 
processed observation next is [1.0, 0.21739130434782608, 0.12121212121212134, 1.0, 1.0, 1.0, 0.1295866497979345, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1221264356469786, 0.1221264356469787, 0.19305960376850267], 
reward next is 0.8069, 
noisyNet noise sample is [array([0.779482], dtype=float32), -1.5742159]. 
=============================================
[2019-03-23 14:30:15,832] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.1626554e-05 9.9994838e-01 2.0920755e-31 1.7218316e-18 0.0000000e+00], sum to 1.0000
[2019-03-23 14:30:15,840] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7545
[2019-03-23 14:30:15,851] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 49.0, 1.0, 2.0, 0.2861729732097004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 310736.7806464899, 310736.7806464899, 89899.1729068967], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1888200.0000, 
sim time next is 1888800.0000, 
raw observation next is [21.0, 49.0, 1.0, 2.0, 0.2846747915817217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 309109.484810754, 309109.4848107537, 89751.76573393197], 
processed observation next is [1.0, 0.8695652173913043, 0.5909090909090909, 0.49, 1.0, 1.0, 0.10584348947715212, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11448499437435333, 0.11448499437435324, 0.218906745692517], 
reward next is 0.7811, 
noisyNet noise sample is [array([-1.1324016], dtype=float32), 0.6917879]. 
=============================================
[2019-03-23 14:30:20,069] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.9173833e-03 9.9808264e-01 6.6716971e-19 7.8831380e-10 7.6958604e-24], sum to 1.0000
[2019-03-23 14:30:20,081] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5523
[2019-03-23 14:30:20,089] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1189113.669935409 W.
[2019-03-23 14:30:20,096] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.83333333333334, 60.33333333333334, 1.0, 2.0, 0.5211974552064541, 1.0, 1.0, 0.5211974552064541, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1189113.669935409, 1189113.669935409, 233563.8089124566], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1959000.0000, 
sim time next is 1959600.0000, 
raw observation next is [25.66666666666667, 59.66666666666667, 1.0, 2.0, 0.5197660791442269, 1.0, 2.0, 0.5197660791442269, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1186270.286938675, 1186270.286938675, 232583.1516726136], 
processed observation next is [1.0, 0.6956521739130435, 0.8030303030303032, 0.5966666666666667, 1.0, 1.0, 0.39970759893028357, 1.0, 1.0, 0.39970759893028357, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4393593655328426, 0.4393593655328426, 0.5672759796893014], 
reward next is 0.4327, 
noisyNet noise sample is [array([-1.4485153], dtype=float32), -0.28717992]. 
=============================================
[2019-03-23 14:30:22,162] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.3390353e-06 9.9999368e-01 6.9739331e-35 1.5121486e-19 0.0000000e+00], sum to 1.0000
[2019-03-23 14:30:22,170] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0949
[2019-03-23 14:30:22,173] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333333, 70.66666666666667, 1.0, 2.0, 0.243101222386625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 263955.2518479449, 263955.2518479446, 82961.11540864102], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2000400.0000, 
sim time next is 2001000.0000, 
raw observation next is [17.16666666666667, 71.33333333333333, 1.0, 2.0, 0.2410366687771976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 261712.9908606742, 261712.9908606739, 82299.51079417112], 
processed observation next is [0.0, 0.13043478260869565, 0.4166666666666669, 0.7133333333333333, 1.0, 1.0, 0.05129583597149698, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09693073735580526, 0.09693073735580514, 0.20073051413212467], 
reward next is 0.7993, 
noisyNet noise sample is [array([0.21654175], dtype=float32), -0.5491086]. 
=============================================
[2019-03-23 14:30:22,188] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[79.38175]
 [79.36272]
 [79.33217]
 [79.49121]
 [79.83721]], R is [[79.40943146]
 [79.41299438]
 [79.41481781]
 [79.41481781]
 [79.41298676]].
[2019-03-23 14:30:22,888] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.9229736e-04 9.9980778e-01 1.4424696e-33 5.3030309e-18 0.0000000e+00], sum to 1.0000
[2019-03-23 14:30:22,895] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3467
[2019-03-23 14:30:22,900] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 77.0, 1.0, 2.0, 0.2261991316963089, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 245598.6102204237, 245598.610220424, 78524.87787056869], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2008800.0000, 
sim time next is 2009400.0000, 
raw observation next is [16.16666666666667, 76.16666666666667, 1.0, 2.0, 0.2264150963499716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 245833.1558733574, 245833.1558733577, 78806.33792241057], 
processed observation next is [0.0, 0.2608695652173913, 0.37121212121212144, 0.7616666666666667, 1.0, 1.0, 0.03301887043746447, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09104931699013237, 0.09104931699013248, 0.1922105802985624], 
reward next is 0.8078, 
noisyNet noise sample is [array([-0.35152754], dtype=float32), 1.3505641]. 
=============================================
[2019-03-23 14:30:23,244] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 14:30:23,247] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:30:23,248] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:30:23,248] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:30:23,249] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:30:23,249] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:30:23,250] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:30:23,253] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:30:23,254] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:30:23,251] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:30:23,259] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:30:23,277] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run71
[2019-03-23 14:30:23,301] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run71
[2019-03-23 14:30:23,340] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run71
[2019-03-23 14:30:23,365] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run71
[2019-03-23 14:30:23,367] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run71
[2019-03-23 14:31:17,557] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5375824]
[2019-03-23 14:31:17,560] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.47337928333334, 52.01377893999999, 1.0, 2.0, 0.3829048730867534, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 432116.2934707238, 432116.2934707238, 128003.3078291236]
[2019-03-23 14:31:17,562] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:31:17,565] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.5874990e-05 9.9998415e-01 1.6500776e-32 1.1100555e-18 0.0000000e+00], sampled 0.9601320044093381
[2019-03-23 14:31:37,502] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5375824]
[2019-03-23 14:31:37,503] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.56666666666667, 81.0, 1.0, 2.0, 0.3573240276773811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 397805.0499297217, 397805.0499297213, 123129.3208956084]
[2019-03-23 14:31:37,506] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:31:37,511] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.7108765e-05 9.9998283e-01 1.4351863e-32 9.9110227e-19 0.0000000e+00], sampled 0.5275839311263874
[2019-03-23 14:31:48,592] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5375824]
[2019-03-23 14:31:48,594] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.98296730166667, 62.93257373333334, 1.0, 2.0, 0.5216286012691299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 594075.0169109248, 594075.0169109248, 149813.8476362241]
[2019-03-23 14:31:48,596] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:31:48,601] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.1676303e-05 9.9996829e-01 3.9343490e-31 6.6895089e-18 0.0000000e+00], sampled 0.7221483706601463
[2019-03-23 14:31:49,872] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5375824]
[2019-03-23 14:31:49,874] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [27.10600216, 75.37661122666667, 1.0, 2.0, 0.6224688634952052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 699408.2698838884, 699408.2698838881, 166370.0652148672]
[2019-03-23 14:31:49,874] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:31:49,877] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.6331616e-05 9.9998367e-01 1.7561627e-32 1.1742735e-18 0.0000000e+00], sampled 0.46553851447827277
[2019-03-23 14:32:01,121] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5375824]
[2019-03-23 14:32:01,122] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.3, 65.0, 1.0, 2.0, 0.2426298397484943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 263429.6869623542, 263429.6869623542, 83993.28379526414]
[2019-03-23 14:32:01,124] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:32:01,126] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.1089323e-06 9.9999094e-01 3.3182104e-33 5.1591420e-19 0.0000000e+00], sampled 0.01450644271088819
[2019-03-23 14:32:04,641] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5375824]
[2019-03-23 14:32:04,643] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.06111603, 100.0, 1.0, 2.0, 0.3132949807958035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 340601.6530271916, 340601.6530271916, 116546.4198037042]
[2019-03-23 14:32:04,643] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:32:04,647] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.7763892e-05 9.9998224e-01 2.5149502e-32 1.3928341e-18 0.0000000e+00], sampled 0.1277177236562842
[2019-03-23 14:32:05,719] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:32:06,046] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 14:32:06,449] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 14:32:06,587] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 14:32:06,657] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.6267 1663778858.8467 105.0000
[2019-03-23 14:32:07,671] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1750000, evaluation results [1750000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.626664099582, 1663778858.8466926, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 14:32:09,361] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.5071359e-05 9.9994493e-01 3.7262442e-31 6.8626345e-17 0.0000000e+00], sum to 1.0000
[2019-03-23 14:32:09,367] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9108
[2019-03-23 14:32:09,372] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.6, 48.0, 1.0, 2.0, 0.3183499597214681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 347977.78137266, 347977.78137266, 113239.6816744002], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2050200.0000, 
sim time next is 2050800.0000, 
raw observation next is [23.46666666666667, 48.33333333333333, 1.0, 2.0, 0.3173512707786962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 346510.6397994291, 346510.6397994294, 113035.2032495995], 
processed observation next is [0.0, 0.7391304347826086, 0.7030303030303031, 0.4833333333333333, 1.0, 1.0, 0.1466890884733702, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12833727399978856, 0.12833727399978867, 0.27569561768195], 
reward next is 0.7243, 
noisyNet noise sample is [array([0.21472186], dtype=float32), 0.53212774]. 
=============================================
[2019-03-23 14:32:11,726] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.2313782e-06 9.9999774e-01 1.5947260e-32 2.2733159e-18 0.0000000e+00], sum to 1.0000
[2019-03-23 14:32:11,734] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3065
[2019-03-23 14:32:11,739] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 64.0, 1.0, 2.0, 0.2831974539234325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 307504.8346228056, 307504.8346228056, 105660.2362992079], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2104200.0000, 
sim time next is 2104800.0000, 
raw observation next is [20.33333333333334, 62.66666666666667, 1.0, 2.0, 0.2868568654603892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 311479.6129591942, 311479.6129591945, 108713.1944859344], 
processed observation next is [0.0, 0.34782608695652173, 0.5606060606060609, 0.6266666666666667, 1.0, 1.0, 0.10857108182548647, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11536281961451636, 0.11536281961451648, 0.26515413289252293], 
reward next is 0.7348, 
noisyNet noise sample is [array([-1.4142101], dtype=float32), -0.01290492]. 
=============================================
[2019-03-23 14:32:13,621] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.4327860e-07 9.9999917e-01 1.3796006e-33 1.9811371e-19 0.0000000e+00], sum to 1.0000
[2019-03-23 14:32:13,630] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1954
[2019-03-23 14:32:13,633] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 72.5, 1.0, 2.0, 0.2421362708272823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 262907.240363693, 262907.2403636927, 85276.68233046256], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2100600.0000, 
sim time next is 2101200.0000, 
raw observation next is [18.0, 71.0, 1.0, 2.0, 0.2510262606431582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 272562.5373299517, 272562.5373299519, 88689.63269968626], 
processed observation next is [0.0, 0.30434782608695654, 0.45454545454545453, 0.71, 1.0, 1.0, 0.06378282580394773, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10094908789998211, 0.10094908789998218, 0.21631617731630795], 
reward next is 0.7837, 
noisyNet noise sample is [array([0.02961496], dtype=float32), 0.07476155]. 
=============================================
[2019-03-23 14:32:14,554] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.4166735e-06 9.9999654e-01 1.0421237e-29 2.2704978e-17 0.0000000e+00], sum to 1.0000
[2019-03-23 14:32:14,567] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7549
[2019-03-23 14:32:14,570] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.33333333333333, 94.66666666666667, 1.0, 2.0, 0.2474882752024005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 268719.9565244907, 268719.9565244907, 82236.35379335395], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2179200.0000, 
sim time next is 2179800.0000, 
raw observation next is [14.3, 94.5, 1.0, 2.0, 0.2415230832847394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 262241.2727842501, 262241.2727842499, 81192.73327289162], 
processed observation next is [1.0, 0.21739130434782608, 0.2863636363636364, 0.945, 1.0, 1.0, 0.051903854105924234, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09712639732750003, 0.09712639732749997, 0.1980310567631503], 
reward next is 0.8020, 
noisyNet noise sample is [array([0.5214365], dtype=float32), 0.2622379]. 
=============================================
[2019-03-23 14:32:18,157] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.1279599e-06 9.9999893e-01 6.7903423e-34 3.8069013e-19 0.0000000e+00], sum to 1.0000
[2019-03-23 14:32:18,167] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9801
[2019-03-23 14:32:18,173] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 64.0, 1.0, 2.0, 0.2588082139227862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 281014.5682281378, 281014.5682281381, 87291.93888083227], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2584200.0000, 
sim time next is 2584800.0000, 
raw observation next is [18.6, 64.0, 1.0, 2.0, 0.258456104834349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 280632.1370469544, 280632.1370469541, 86795.02110118474], 
processed observation next is [1.0, 0.9565217391304348, 0.48181818181818187, 0.64, 1.0, 1.0, 0.07307013104293623, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10393782853590905, 0.10393782853590894, 0.21169517341752375], 
reward next is 0.7883, 
noisyNet noise sample is [array([-0.9829302], dtype=float32), 0.58672184]. 
=============================================
[2019-03-23 14:32:18,639] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.4814069e-06 9.9999547e-01 9.7110991e-29 2.0077208e-18 1.2390996e-38], sum to 1.0000
[2019-03-23 14:32:18,645] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4533
[2019-03-23 14:32:18,654] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 72.0, 1.0, 2.0, 0.908696579892236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1021853.021650518, 1021853.021650518, 186475.3551658728], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2212800.0000, 
sim time next is 2213400.0000, 
raw observation next is [21.66666666666667, 70.5, 1.0, 2.0, 0.9204182748676003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1036269.329471503, 1036269.329471504, 188930.6583755545], 
processed observation next is [1.0, 0.6086956521739131, 0.6212121212121214, 0.705, 1.0, 1.0, 0.9005228435845003, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3838034553598159, 0.3838034553598163, 0.46080648384281586], 
reward next is 0.5392, 
noisyNet noise sample is [array([-1.112721], dtype=float32), 1.4499519]. 
=============================================
[2019-03-23 14:32:24,496] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.3024648e-06 9.9999666e-01 3.2802497e-31 3.0752675e-20 0.0000000e+00], sum to 1.0000
[2019-03-23 14:32:24,503] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8778
[2019-03-23 14:32:24,506] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 86.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 203194.6676941479, 203194.6676941476, 68236.20509079282], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2348400.0000, 
sim time next is 2349000.0000, 
raw observation next is [13.0, 85.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 201471.4990203494, 201471.4990203496, 67744.99004891537], 
processed observation next is [1.0, 0.17391304347826086, 0.22727272727272727, 0.85, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07461907371124052, 0.0746190737112406, 0.16523168304613503], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9299174], dtype=float32), -1.0609146]. 
=============================================
[2019-03-23 14:32:24,523] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[69.96014 ]
 [69.957115]
 [69.929634]
 [69.93755 ]
 [69.983696]], R is [[69.3006897 ]
 [68.60768127]
 [67.92160797]
 [67.24239349]
 [66.56996918]].
[2019-03-23 14:32:27,090] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0705558e-06 9.9999893e-01 3.6684288e-34 2.2799166e-20 0.0000000e+00], sum to 1.0000
[2019-03-23 14:32:27,099] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4800
[2019-03-23 14:32:27,102] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666667, 48.5, 1.0, 2.0, 0.3908568875822686, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 424455.904853014, 424455.9048530143, 101150.4483598498], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2380200.0000, 
sim time next is 2380800.0000, 
raw observation next is [21.33333333333334, 48.0, 1.0, 2.0, 0.46818110559947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 508471.0147842696, 508471.0147842696, 109756.3788550529], 
processed observation next is [1.0, 0.5652173913043478, 0.6060606060606063, 0.48, 1.0, 1.0, 0.33522638199933746, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.188322598068248, 0.188322598068248, 0.2676984850123241], 
reward next is 0.7323, 
noisyNet noise sample is [array([-0.23058662], dtype=float32), 0.7232873]. 
=============================================
[2019-03-23 14:32:30,272] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4531198e-06 9.9999857e-01 7.5484846e-35 1.7153415e-19 0.0000000e+00], sum to 1.0000
[2019-03-23 14:32:30,286] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6562
[2019-03-23 14:32:30,290] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 82.0, 1.0, 2.0, 0.5270857854279821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 572482.4825111068, 572482.4825111068, 122157.3992862479], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2462400.0000, 
sim time next is 2463000.0000, 
raw observation next is [17.16666666666667, 81.16666666666667, 1.0, 2.0, 0.7217736557406981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 784108.9739954432, 784108.9739954435, 145325.3740618487], 
processed observation next is [1.0, 0.5217391304347826, 0.4166666666666669, 0.8116666666666668, 1.0, 1.0, 0.6522170696758725, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2904107311094234, 0.29041073110942356, 0.3544521318581676], 
reward next is 0.6455, 
noisyNet noise sample is [array([1.6965767], dtype=float32), 0.38543683]. 
=============================================
[2019-03-23 14:32:30,309] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[76.71161]
 [76.70257]
 [76.67036]
 [76.65702]
 [76.64425]], R is [[76.74365234]
 [76.67827606]
 [76.6101532 ]
 [76.54045105]
 [76.47025299]].
[2019-03-23 14:32:35,125] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.2870101e-05 9.9991715e-01 1.8788952e-32 1.7062622e-18 0.0000000e+00], sum to 1.0000
[2019-03-23 14:32:35,129] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8828
[2019-03-23 14:32:35,133] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.5, 97.0, 1.0, 2.0, 0.3548798373433263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 385370.6961087743, 385370.696108774, 90200.22303614173], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2536200.0000, 
sim time next is 2536800.0000, 
raw observation next is [13.66666666666667, 96.0, 1.0, 2.0, 0.3704849794754739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 402323.6244982646, 402323.6244982646, 92453.41329469038], 
processed observation next is [1.0, 0.34782608695652173, 0.25757575757575774, 0.96, 1.0, 1.0, 0.21310622434434232, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14900874981417206, 0.14900874981417206, 0.2254961299870497], 
reward next is 0.7745, 
noisyNet noise sample is [array([-0.61896634], dtype=float32), -1.131046]. 
=============================================
[2019-03-23 14:32:39,810] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.9853566e-06 9.9999499e-01 2.5307489e-30 3.4775351e-18 0.0000000e+00], sum to 1.0000
[2019-03-23 14:32:39,821] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3526
[2019-03-23 14:32:39,828] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 46.5, 1.0, 2.0, 0.3845092767645026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 433653.9923805742, 433653.9923805745, 123665.6314541797], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2658600.0000, 
sim time next is 2659200.0000, 
raw observation next is [26.33333333333334, 47.0, 1.0, 2.0, 0.3821481011187505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 430788.3777705879, 430788.3777705882, 123345.9120878186], 
processed observation next is [0.0, 0.782608695652174, 0.8333333333333336, 0.47, 1.0, 1.0, 0.22768512639843813, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15955125102614368, 0.1595512510261438, 0.30084368801906974], 
reward next is 0.6992, 
noisyNet noise sample is [array([0.3470242], dtype=float32), -0.66283333]. 
=============================================
[2019-03-23 14:32:40,926] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.7086627e-07 9.9999952e-01 3.5474938e-32 9.4599522e-20 0.0000000e+00], sum to 1.0000
[2019-03-23 14:32:40,934] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3992
[2019-03-23 14:32:40,941] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.25, 75.83333333333333, 1.0, 2.0, 0.3512870550314278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 390915.8214390898, 390915.8214390896, 118257.1609718758], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2679000.0000, 
sim time next is 2679600.0000, 
raw observation next is [20.2, 76.66666666666667, 1.0, 2.0, 0.3516252666192793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 391600.1354545901, 391600.1354545901, 118415.0560584253], 
processed observation next is [0.0, 0.0, 0.5545454545454546, 0.7666666666666667, 1.0, 1.0, 0.18953158327409908, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14503708720540373, 0.14503708720540373, 0.28881720989859827], 
reward next is 0.7112, 
noisyNet noise sample is [array([0.4063187], dtype=float32), -0.45586216]. 
=============================================
[2019-03-23 14:32:43,188] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.3280651e-06 9.9999464e-01 1.7732150e-30 1.1111389e-18 0.0000000e+00], sum to 1.0000
[2019-03-23 14:32:43,197] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7370
[2019-03-23 14:32:43,201] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.86666666666667, 100.0, 1.0, 2.0, 0.3334308190983543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 368112.8698841897, 368112.8698841897, 115664.0317351502], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2701200.0000, 
sim time next is 2701800.0000, 
raw observation next is [16.9, 100.0, 1.0, 2.0, 0.3345651256516622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369577.9346108176, 369577.9346108176, 115831.7750622633], 
processed observation next is [0.0, 0.2608695652173913, 0.4045454545454545, 1.0, 1.0, 1.0, 0.1682064070645777, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13688071652252504, 0.13688071652252504, 0.28251652454210563], 
reward next is 0.7175, 
noisyNet noise sample is [array([0.7304827], dtype=float32), -0.53765625]. 
=============================================
[2019-03-23 14:32:43,574] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0532052e-07 9.9999988e-01 9.4298185e-31 9.1993128e-20 0.0000000e+00], sum to 1.0000
[2019-03-23 14:32:43,579] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9273
[2019-03-23 14:32:43,593] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.8, 100.0, 1.0, 2.0, 0.3313047244367166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 365277.1143717992, 365277.1143717992, 115316.5295712463], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2700000.0000, 
sim time next is 2700600.0000, 
raw observation next is [16.83333333333334, 100.0, 1.0, 2.0, 0.3324344190060424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 366795.3674812024, 366795.3674812021, 115505.2731566442], 
processed observation next is [0.0, 0.2608695652173913, 0.40151515151515177, 1.0, 1.0, 1.0, 0.165543023757553, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13585013610414903, 0.13585013610414892, 0.2817201784308395], 
reward next is 0.7183, 
noisyNet noise sample is [array([-0.63874435], dtype=float32), -0.1583282]. 
=============================================
[2019-03-23 14:32:48,840] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.7666394e-06 9.9999523e-01 3.8345650e-19 3.8749318e-10 3.6622937e-25], sum to 1.0000
[2019-03-23 14:32:48,847] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8207
[2019-03-23 14:32:48,855] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 78.83333333333333, 1.0, 2.0, 0.457137699336454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 521242.2063967424, 521242.2063967424, 134853.056959623], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2851800.0000, 
sim time next is 2852400.0000, 
raw observation next is [22.66666666666667, 79.66666666666667, 1.0, 2.0, 0.4540561556894684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 517663.95361687, 517663.9536168703, 134419.4974391613], 
processed observation next is [1.0, 0.0, 0.6666666666666669, 0.7966666666666667, 1.0, 1.0, 0.31757019461183544, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19172739022847035, 0.19172739022847046, 0.32785243277844217], 
reward next is 0.6721, 
noisyNet noise sample is [array([-0.49902835], dtype=float32), -0.015260231]. 
=============================================
[2019-03-23 14:32:55,003] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.2282602e-10 4.6698435e-05 4.9260669e-18 9.9995327e-01 1.4799578e-28], sum to 1.0000
[2019-03-23 14:32:55,009] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9806
[2019-03-23 14:32:55,012] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 73.33333333333333, 1.0, 2.0, 0.7533340857075265, 1.0, 2.0, 0.7533340857075265, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1694692.17736792, 1694692.17736792, 309064.1165382725], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2907600.0000, 
sim time next is 2908200.0000, 
raw observation next is [26.5, 76.16666666666667, 1.0, 2.0, 0.7474836522027307, 1.0, 2.0, 0.7474836522027307, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1681511.554400071, 1681511.554400071, 307122.8958170445], 
processed observation next is [1.0, 0.6521739130434783, 0.8409090909090909, 0.7616666666666667, 1.0, 1.0, 0.6843545652534133, 1.0, 1.0, 0.6843545652534133, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.6227820571852115, 0.6227820571852115, 0.7490802337001085], 
reward next is 0.2509, 
noisyNet noise sample is [array([-0.5408124], dtype=float32), 1.0553925]. 
=============================================
[2019-03-23 14:32:55,745] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 14:32:55,748] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:32:55,749] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:32:55,749] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:32:55,750] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:32:55,751] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:32:55,751] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:32:55,751] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:32:55,751] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:32:55,753] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:32:55,753] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:32:55,774] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run72
[2019-03-23 14:32:55,799] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run72
[2019-03-23 14:32:55,824] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run72
[2019-03-23 14:32:55,852] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run72
[2019-03-23 14:32:55,875] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run72
[2019-03-23 14:32:59,441] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.54508525]
[2019-03-23 14:32:59,444] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.2, 26.0, 1.0, 2.0, 0.3367033924171199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 365598.9177914045, 365598.9177914045, 94995.41729552542]
[2019-03-23 14:32:59,446] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:32:59,449] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.9607632e-08 1.0000000e+00 3.3444987e-31 3.4773687e-17 0.0000000e+00], sampled 0.8201855922846174
[2019-03-23 14:33:08,046] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.54508525]
[2019-03-23 14:33:08,047] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.63333333333333, 49.0, 1.0, 2.0, 0.3396238914207134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 377588.8015755349, 377588.8015755349, 121511.5854718739]
[2019-03-23 14:33:08,048] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:33:08,051] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.8683083e-08 1.0000000e+00 5.0131853e-31 4.2765185e-17 0.0000000e+00], sampled 0.2849196858791728
[2019-03-23 14:33:10,091] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.54508525]
[2019-03-23 14:33:10,092] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.8, 74.83333333333334, 1.0, 2.0, 0.3266572295207223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 360345.6637029959, 360345.6637029959, 119363.9399182412]
[2019-03-23 14:33:10,094] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:33:10,098] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.1786792e-08 1.0000000e+00 1.5342116e-30 8.1497487e-17 2.2245371e-38], sampled 0.6183755347657157
[2019-03-23 14:33:11,708] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.54508525]
[2019-03-23 14:33:11,711] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.83333333333333, 90.0, 1.0, 2.0, 0.4053039483844764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 458166.6401304272, 458166.6401304272, 130466.3182432422]
[2019-03-23 14:33:11,714] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:33:11,719] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.2495974e-07 9.9999988e-01 6.8967461e-29 8.4452599e-16 2.4680766e-36], sampled 0.06949076916193342
[2019-03-23 14:33:22,262] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.54508525]
[2019-03-23 14:33:22,266] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 64.0, 1.0, 2.0, 0.2593609231746895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 281614.8749869078, 281614.874986908, 90054.53162816586]
[2019-03-23 14:33:22,269] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:33:22,271] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.2711021e-08 1.0000000e+00 6.6240846e-31 5.3225787e-17 0.0000000e+00], sampled 0.8223611120148615
[2019-03-23 14:33:27,070] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.54508525]
[2019-03-23 14:33:27,070] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.43333333333333, 58.33333333333333, 1.0, 2.0, 0.2471028204010471, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 268287.2052016245, 268287.2052016241, 79887.98153850724]
[2019-03-23 14:33:27,072] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:33:27,075] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.1502901e-08 1.0000000e+00 2.0861039e-30 9.4849757e-17 3.4049524e-38], sampled 0.11155365128710704
[2019-03-23 14:33:44,081] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.54508525]
[2019-03-23 14:33:44,083] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.0, 90.0, 1.0, 2.0, 0.4480105724463124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 510194.5550455308, 510194.5550455305, 137384.6732036695]
[2019-03-23 14:33:44,085] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:33:44,089] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.1206137e-07 9.9999988e-01 3.7201182e-29 5.7766816e-16 1.1609993e-36], sampled 0.4329255429254719
[2019-03-23 14:33:58,262] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.54508525]
[2019-03-23 14:33:58,263] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.4, 89.0, 1.0, 2.0, 0.680098033483945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 766362.6788058187, 766362.6788058187, 159560.1399671465]
[2019-03-23 14:33:58,265] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:33:58,268] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.4792644e-07 9.9999976e-01 4.0376339e-25 1.0383465e-12 7.4725541e-32], sampled 0.3638953867715087
[2019-03-23 14:34:23,310] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.54508525]
[2019-03-23 14:34:23,310] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.04899090333333, 56.51300477666666, 1.0, 2.0, 0.3326845549892573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 361233.8765063196, 361233.8765063193, 113353.8352915699]
[2019-03-23 14:34:23,310] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:34:23,313] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.6132799e-08 9.9999988e-01 7.3268559e-30 2.0445210e-16 1.6385766e-37], sampled 0.32740292023257633
[2019-03-23 14:34:39,033] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8864.3004 1663373441.2646 86.0000
[2019-03-23 14:34:39,104] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8594.4798 1681337376.1826 167.0000
[2019-03-23 14:34:39,272] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9069.1904 1655860118.6724 62.0000
[2019-03-23 14:34:39,371] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8539.0821 1759391611.6663 153.0000
[2019-03-23 14:34:39,510] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8620.6620 1703162078.6290 403.0000
[2019-03-23 14:34:40,528] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1775000, evaluation results [1775000.0, 8539.082081062244, 1759391611.6662884, 153.0, 9069.190367153824, 1655860118.67237, 62.0, 8864.300373780059, 1663373441.2646143, 86.0, 8620.661974615261, 1703162078.6289804, 403.0, 8594.479816870184, 1681337376.182585, 167.0]
[2019-03-23 14:34:40,552] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0924639e-07 9.9999976e-01 8.3994695e-25 2.4483778e-11 4.7729688e-31], sum to 1.0000
[2019-03-23 14:34:40,554] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0669
[2019-03-23 14:34:40,562] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.5325972509099031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 607407.7476255537, 607407.7476255537, 145994.5841454098], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2952600.0000, 
sim time next is 2953200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5152902436809513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 587659.015764204, 587659.0157642042, 143905.4915812509], 
processed observation next is [1.0, 0.17391304347826086, 0.6363636363636364, 0.94, 1.0, 1.0, 0.39411280460118914, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21765148732007555, 0.21765148732007564, 0.35098900385670956], 
reward next is 0.6490, 
noisyNet noise sample is [array([2.167221], dtype=float32), -0.91871077]. 
=============================================
[2019-03-23 14:34:41,237] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.6769498e-09 4.1769053e-06 2.7505002e-16 9.9999583e-01 3.8342588e-27], sum to 1.0000
[2019-03-23 14:34:41,248] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0104
[2019-03-23 14:34:41,256] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.5297303356501957, 1.0, 2.0, 0.5297303356501957, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1198227.335318053, 1198227.335318053, 241271.7113242161], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2982000.0000, 
sim time next is 2982600.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.4998521961554998, 1.0, 2.0, 0.4998521961554998, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1131610.473951497, 1131610.473951497, 233461.0648143992], 
processed observation next is [1.0, 0.5217391304347826, 0.9090909090909091, 0.58, 1.0, 1.0, 0.3748152451943747, 1.0, 1.0, 0.3748152451943747, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.41911499035240635, 0.41911499035240635, 0.5694172312546322], 
reward next is 0.4306, 
noisyNet noise sample is [array([-1.4091194], dtype=float32), 1.9253393]. 
=============================================
[2019-03-23 14:34:44,030] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.7983032e-08 1.0000000e+00 7.1770579e-31 3.3344713e-17 7.8288774e-38], sum to 1.0000
[2019-03-23 14:34:44,038] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0687
[2019-03-23 14:34:44,045] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333334, 88.0, 1.0, 2.0, 0.3580416801904152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 396655.9646696436, 396655.9646696433, 118070.9320130994], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3026400.0000, 
sim time next is 3027000.0000, 
raw observation next is [18.16666666666666, 88.0, 1.0, 2.0, 0.3538154541998506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 390929.9733424254, 390929.9733424254, 117331.7248713573], 
processed observation next is [1.0, 0.0, 0.4621212121212119, 0.88, 1.0, 1.0, 0.19226931774981323, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1447888790157131, 0.1447888790157131, 0.2861749387106276], 
reward next is 0.7138, 
noisyNet noise sample is [array([-1.0765461], dtype=float32), 2.3084595]. 
=============================================
[2019-03-23 14:34:44,059] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[66.03928 ]
 [66.26883 ]
 [66.772934]
 [67.63827 ]
 [68.3688  ]], R is [[65.8690567 ]
 [65.92238617]
 [65.97327423]
 [66.02179718]
 [66.0680542 ]].
[2019-03-23 14:34:46,885] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.3921830e-09 1.9732558e-03 1.2652312e-19 9.9802667e-01 1.0563045e-29], sum to 1.0000
[2019-03-23 14:34:46,891] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3562
[2019-03-23 14:34:46,896] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 74.0, 1.0, 2.0, 0.5211991369946016, 1.0, 2.0, 0.5211991369946016, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846265342194, 1187513.035213726, 1187513.035213726, 235143.7976656831], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3073800.0000, 
sim time next is 3074400.0000, 
raw observation next is [24.0, 74.0, 1.0, 2.0, 0.5147226660335029, 1.0, 2.0, 0.5147226660335029, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846343865015, 1172754.70504232, 1172754.70504232, 233546.8409472753], 
processed observation next is [1.0, 0.6086956521739131, 0.7272727272727273, 0.74, 1.0, 1.0, 0.3934033325418786, 1.0, 1.0, 0.3934033325418786, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288128884968, 0.43435359446011856, 0.43435359446011856, 0.5696264413348179], 
reward next is 0.4304, 
noisyNet noise sample is [array([0.09683768], dtype=float32), -1.1409141]. 
=============================================
[2019-03-23 14:34:46,965] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.0249135e-08 1.0000000e+00 4.6074691e-24 3.2683922e-10 6.3005451e-32], sum to 1.0000
[2019-03-23 14:34:46,980] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7150
[2019-03-23 14:34:46,983] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5246945639578317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 597761.1588436305, 597761.1588436305, 145774.320967315], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3108000.0000, 
sim time next is 3108600.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5251920965508002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 598327.8186483674, 598327.8186483678, 145835.5018169904], 
processed observation next is [1.0, 1.0, 0.6818181818181818, 0.89, 1.0, 1.0, 0.40649012068850027, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22160289579569165, 0.22160289579569176, 0.3556963458950986], 
reward next is 0.6443, 
noisyNet noise sample is [array([-0.40029624], dtype=float32), -0.28736907]. 
=============================================
[2019-03-23 14:34:47,271] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.0405519e-08 1.0000000e+00 4.7896865e-27 2.9942208e-14 4.9576649e-34], sum to 1.0000
[2019-03-23 14:34:47,285] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0702
[2019-03-23 14:34:47,288] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 89.0, 1.0, 2.0, 0.5517208555085951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 626960.5106101752, 626960.5106101752, 150204.2130454729], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3101400.0000, 
sim time next is 3102000.0000, 
raw observation next is [23.33333333333333, 89.0, 1.0, 2.0, 0.5445692342752103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 619390.5442996036, 619390.5442996036, 148979.8367665326], 
processed observation next is [1.0, 0.9130434782608695, 0.6969696969696968, 0.89, 1.0, 1.0, 0.43071154284401286, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22940390529614946, 0.22940390529614946, 0.36336545552812827], 
reward next is 0.6366, 
noisyNet noise sample is [array([0.56959724], dtype=float32), -2.1675277]. 
=============================================
[2019-03-23 14:34:47,305] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[59.247414]
 [59.247654]
 [59.259422]
 [59.269554]
 [59.294403]], R is [[59.29005051]
 [59.3307991 ]
 [59.3686676 ]
 [59.40437317]
 [59.43919754]].
[2019-03-23 14:34:49,570] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0065728e-05 4.6512032e-01 2.3096847e-18 5.3486961e-01 7.2188332e-28], sum to 1.0000
[2019-03-23 14:34:49,578] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8677
[2019-03-23 14:34:49,582] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.83333333333334, 71.33333333333333, 1.0, 2.0, 0.3793636720687431, 1.0, 1.0, 0.3793636720687431, 1.0, 2.0, 0.7684604923895672, 6.911199999999999, 6.9112, 77.3421103, 1292649.076736656, 1292649.076736656, 292246.1290693501], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3160200.0000, 
sim time next is 3160800.0000, 
raw observation next is [25.0, 69.0, 1.0, 2.0, 0.5419642612671762, 1.0, 2.0, 0.5419642612671762, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344350959, 1232803.089429319, 1232803.089429319, 241667.4447848825], 
processed observation next is [1.0, 0.6086956521739131, 0.7727272727272727, 0.69, 1.0, 1.0, 0.42745532658397023, 1.0, 1.0, 0.42745532658397023, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129204473, 0.45659373682567367, 0.45659373682567367, 0.5894327921582501], 
reward next is 0.4106, 
noisyNet noise sample is [array([-0.69440925], dtype=float32), 0.18479206]. 
=============================================
[2019-03-23 14:34:56,662] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.4777000e-09 1.0000000e+00 1.5566524e-33 1.5238736e-18 0.0000000e+00], sum to 1.0000
[2019-03-23 14:34:56,670] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3350
[2019-03-23 14:34:56,674] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 78.66666666666667, 1.0, 2.0, 0.2939199185978877, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 319151.449397184, 319151.4493971842, 101093.5448862984], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3280800.0000, 
sim time next is 3281400.0000, 
raw observation next is [17.5, 79.5, 1.0, 2.0, 0.292390805244492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 317490.5274397882, 317490.5274397879, 100006.7365284086], 
processed observation next is [0.0, 1.0, 0.4318181818181818, 0.795, 1.0, 1.0, 0.115488506555615, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1175890842369586, 0.11758908423695849, 0.24391886958148437], 
reward next is 0.7561, 
noisyNet noise sample is [array([0.41504294], dtype=float32), 0.0951367]. 
=============================================
[2019-03-23 14:35:02,055] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.0177893e-05 4.7956776e-02 4.3314131e-16 9.5202303e-01 1.0663445e-24], sum to 1.0000
[2019-03-23 14:35:02,062] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5082
[2019-03-23 14:35:02,068] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.2632481218515699, 1.0, 1.0, 0.2632481218515699, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 599549.0974007729, 599549.0974007729, 182089.4438346751], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3729600.0000, 
sim time next is 3730200.0000, 
raw observation next is [21.83333333333334, 94.00000000000001, 1.0, 2.0, 0.278496561986229, 1.0, 2.0, 0.278496561986229, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 634325.4267569595, 634325.4267569595, 184610.7811206693], 
processed observation next is [1.0, 0.17391304347826086, 0.628787878787879, 0.9400000000000002, 1.0, 1.0, 0.09812070248278626, 1.0, 1.0, 0.09812070248278626, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23493534324331836, 0.23493534324331836, 0.450270197855291], 
reward next is 0.5497, 
noisyNet noise sample is [array([-1.3388575], dtype=float32), 0.60132945]. 
=============================================
[2019-03-23 14:35:05,000] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.6080337e-07 9.9999964e-01 5.8211250e-22 2.9017363e-11 2.7591019e-27], sum to 1.0000
[2019-03-23 14:35:05,018] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7129
[2019-03-23 14:35:05,023] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5300506367198855, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 603755.4980429822, 603755.4980429822, 146528.1836024101], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3445200.0000, 
sim time next is 3445800.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5261254144956876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 599375.153705224, 599375.153705224, 145964.6002385935], 
processed observation next is [1.0, 0.9130434782608695, 0.6818181818181818, 0.89, 1.0, 1.0, 0.4076567681196095, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2219907976686015, 0.2219907976686015, 0.3560112200941305], 
reward next is 0.6440, 
noisyNet noise sample is [array([-1.7132202], dtype=float32), -0.43891418]. 
=============================================
[2019-03-23 14:35:05,272] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5608657e-10 1.0000000e+00 1.6932624e-30 2.2720454e-19 2.6574415e-37], sum to 1.0000
[2019-03-23 14:35:05,279] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7350
[2019-03-23 14:35:05,283] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5180790456492395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 590213.3560913217, 590213.3560913217, 144976.4171016198], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3450600.0000, 
sim time next is 3451200.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5169182338544277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588890.9458383044, 588890.9458383044, 144835.2885456496], 
processed observation next is [1.0, 0.9565217391304348, 0.6818181818181818, 0.89, 1.0, 1.0, 0.3961477923180346, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2181077577178905, 0.2181077577178905, 0.35325680133085263], 
reward next is 0.6467, 
noisyNet noise sample is [array([0.23684217], dtype=float32), -0.20295131]. 
=============================================
[2019-03-23 14:35:05,708] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.0535174e-09 1.0000000e+00 2.0742836e-27 2.4824357e-16 3.6996997e-35], sum to 1.0000
[2019-03-23 14:35:05,713] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6666
[2019-03-23 14:35:05,718] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5092313253943408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 581015.4342845341, 581015.4342845341, 142585.7481271915], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3466200.0000, 
sim time next is 3466800.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5130226200974819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 585344.1770142464, 585344.1770142464, 143030.2722476103], 
processed observation next is [1.0, 0.13043478260869565, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3912782751218523, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21679413963490607, 0.21679413963490607, 0.34885432255514703], 
reward next is 0.6511, 
noisyNet noise sample is [array([1.0966822], dtype=float32), -0.5355892]. 
=============================================
[2019-03-23 14:35:14,882] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.0986330e-10 1.0000000e+00 1.0345506e-28 1.3045269e-19 2.3286054e-35], sum to 1.0000
[2019-03-23 14:35:14,899] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3776
[2019-03-23 14:35:14,903] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5587067949922615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 637488.7957034763, 637488.7957034761, 148616.6073612014], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3638400.0000, 
sim time next is 3639000.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5517182476991648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 629514.1790873717, 629514.1790873714, 147733.8499597977], 
processed observation next is [1.0, 0.08695652173913043, 0.5909090909090909, 1.0, 1.0, 1.0, 0.43964780962395594, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2331533996619895, 0.23315339966198942, 0.36032646331657975], 
reward next is 0.6397, 
noisyNet noise sample is [array([-0.14178626], dtype=float32), 0.6579741]. 
=============================================
[2019-03-23 14:35:14,925] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[56.49343 ]
 [55.93357 ]
 [55.687363]
 [55.469807]
 [57.480167]], R is [[56.34554291]
 [56.41960907]
 [56.48460388]
 [56.52663422]
 [56.51601028]].
[2019-03-23 14:35:16,204] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.8396192e-07 9.1586495e-03 5.3700158e-17 9.9084115e-01 1.1420170e-25], sum to 1.0000
[2019-03-23 14:35:16,212] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4676
[2019-03-23 14:35:16,218] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.33333333333333, 81.66666666666667, 1.0, 2.0, 0.5505542841836762, 1.0, 2.0, 0.5505542841836762, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1242720.625574332, 1242720.625574332, 247399.0616118776], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3667200.0000, 
sim time next is 3667800.0000, 
raw observation next is [24.66666666666667, 79.83333333333333, 1.0, 2.0, 0.5509327302687992, 1.0, 2.0, 0.5509327302687992, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1243070.853383865, 1243070.853383865, 247626.6150230221], 
processed observation next is [1.0, 0.43478260869565216, 0.7575757575757578, 0.7983333333333333, 1.0, 1.0, 0.43866591283599893, 1.0, 1.0, 0.43866591283599893, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.46039661236439444, 0.46039661236439444, 0.6039673537146881], 
reward next is 0.3960, 
noisyNet noise sample is [array([0.8246918], dtype=float32), -0.5787288]. 
=============================================
[2019-03-23 14:35:25,135] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3342742e-07 9.9999988e-01 1.9305227e-23 1.7215285e-08 4.8925730e-31], sum to 1.0000
[2019-03-23 14:35:25,146] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2862
[2019-03-23 14:35:25,149] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 81.33333333333334, 1.0, 2.0, 0.6059659085274011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 681987.862138409, 681987.862138409, 145750.2662391772], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4185600.0000, 
sim time next is 4186200.0000, 
raw observation next is [20.66666666666666, 79.66666666666666, 1.0, 2.0, 0.6250815938826154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 704387.5498610522, 704387.5498610522, 148434.606004966], 
processed observation next is [1.0, 0.43478260869565216, 0.5757575757575755, 0.7966666666666665, 1.0, 1.0, 0.5313519923532692, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2608842777263156, 0.2608842777263156, 0.36203562440235604], 
reward next is 0.6380, 
noisyNet noise sample is [array([-1.1133871], dtype=float32), 0.9567049]. 
=============================================
[2019-03-23 14:35:25,892] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4766858e-09 1.0000000e+00 4.3814517e-35 1.6056225e-21 0.0000000e+00], sum to 1.0000
[2019-03-23 14:35:25,900] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7280
[2019-03-23 14:35:25,905] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 64.0, 1.0, 2.0, 0.3157360944629611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 346078.1780737575, 346078.1780737572, 113404.8863690952], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3874800.0000, 
sim time next is 3875400.0000, 
raw observation next is [21.0, 64.0, 1.0, 2.0, 0.317895014338307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 348449.51259999, 348449.5125999897, 113559.8008318022], 
processed observation next is [0.0, 0.8695652173913043, 0.5909090909090909, 0.64, 1.0, 1.0, 0.14736876792288375, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12905537503703335, 0.12905537503703324, 0.2769751239800054], 
reward next is 0.7230, 
noisyNet noise sample is [array([0.5574889], dtype=float32), 1.12333]. 
=============================================
[2019-03-23 14:35:26,062] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.2961131e-10 1.0000000e+00 1.2532400e-35 2.3830435e-21 0.0000000e+00], sum to 1.0000
[2019-03-23 14:35:26,069] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0210
[2019-03-23 14:35:26,077] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 88.0, 1.0, 2.0, 0.2997053763642186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 325435.6612986392, 325435.6612986395, 109853.5516598192], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3818400.0000, 
sim time next is 3819000.0000, 
raw observation next is [17.0, 88.0, 1.0, 2.0, 0.2993229018039821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 325020.2117726508, 325020.2117726508, 109825.3269173944], 
processed observation next is [0.0, 0.17391304347826086, 0.4090909090909091, 0.88, 1.0, 1.0, 0.12415362725497758, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12037785621209288, 0.12037785621209288, 0.26786665101803514], 
reward next is 0.7321, 
noisyNet noise sample is [array([0.01476308], dtype=float32), -1.6611799]. 
=============================================
[2019-03-23 14:35:26,098] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[73.0764  ]
 [73.079445]
 [73.08141 ]
 [73.08369 ]
 [73.08861 ]], R is [[73.07712555]
 [73.07841492]
 [73.07985687]
 [73.08127594]
 [73.08232117]].
[2019-03-23 14:35:28,604] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 14:35:28,609] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:35:28,610] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:35:28,611] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:35:28,611] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:35:28,612] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:35:28,612] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:35:28,613] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:35:28,614] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:35:28,617] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:35:28,618] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:35:28,632] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run73
[2019-03-23 14:35:28,654] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run73
[2019-03-23 14:35:28,682] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run73
[2019-03-23 14:35:28,718] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run73
[2019-03-23 14:35:28,719] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run73
[2019-03-23 14:35:31,569] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5497432]
[2019-03-23 14:35:31,570] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.64131567666667, 62.38845195, 1.0, 2.0, 0.2394513540974068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 259977.9739992863, 259977.973999286, 78778.82485711512]
[2019-03-23 14:35:31,574] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:35:31,576] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.349514e-10 1.000000e+00 3.280880e-35 2.691005e-21 0.000000e+00], sampled 0.31240395943072186
[2019-03-23 14:35:44,250] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5497432]
[2019-03-23 14:35:44,253] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.9, 63.0, 1.0, 2.0, 0.6307473626909087, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 715623.5522835257, 715623.5522835257, 165614.7239538237]
[2019-03-23 14:35:44,253] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:35:44,257] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.9962662e-10 1.0000000e+00 4.8738980e-35 3.1545397e-21 0.0000000e+00], sampled 0.48873970568565894
[2019-03-23 14:35:45,724] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5497432]
[2019-03-23 14:35:45,726] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.28889523, 89.15744917, 1.0, 2.0, 0.3789003379909024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 424664.180242491, 424664.180242491, 126143.2722456556]
[2019-03-23 14:35:45,727] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:35:45,730] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.6003276e-10 1.0000000e+00 4.0729470e-35 2.8458260e-21 0.0000000e+00], sampled 0.5214058040947026
[2019-03-23 14:35:54,766] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5497432]
[2019-03-23 14:35:54,767] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.74725155833334, 56.71545235666667, 1.0, 2.0, 0.3127141770643341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 340566.421267461, 340566.4212674606, 116713.9324556792]
[2019-03-23 14:35:54,768] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:35:54,772] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.5401546e-10 1.0000000e+00 5.6312631e-35 3.5760621e-21 0.0000000e+00], sampled 0.7239295678919523
[2019-03-23 14:36:03,611] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5497432]
[2019-03-23 14:36:03,613] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [12.627127065, 98.22411424, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 204560.5736731827, 204560.5736731827, 74432.74708521584]
[2019-03-23 14:36:03,613] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:36:03,616] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.9899711e-10 1.0000000e+00 4.4601711e-35 3.1586219e-21 0.0000000e+00], sampled 0.7004458937974879
[2019-03-23 14:36:05,084] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5497432]
[2019-03-23 14:36:05,085] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.33333333333334, 47.0, 1.0, 2.0, 0.3821481011187505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 430788.3777705879, 430788.3777705882, 123345.9120878186]
[2019-03-23 14:36:05,087] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:36:05,091] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.9087550e-10 1.0000000e+00 3.7784022e-35 2.8423109e-21 0.0000000e+00], sampled 0.4612921491236158
[2019-03-23 14:36:41,016] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5497432]
[2019-03-23 14:36:41,017] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.94061015, 45.45273974, 1.0, 2.0, 0.4526646416008933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 507958.8656014582, 507958.8656014582, 133058.8288443686]
[2019-03-23 14:36:41,018] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:36:41,020] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.6655947e-10 1.0000000e+00 6.8061393e-35 3.8144315e-21 0.0000000e+00], sampled 0.3991596438349525
[2019-03-23 14:36:52,211] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5497432]
[2019-03-23 14:36:52,212] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.222326905, 83.51402951166668, 1.0, 2.0, 0.2672289326190094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 290144.0244944859, 290144.0244944856, 92943.08401749248]
[2019-03-23 14:36:52,212] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:36:52,217] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.6623601e-10 1.0000000e+00 3.5982318e-35 2.7945114e-21 0.0000000e+00], sampled 0.4460457885917244
[2019-03-23 14:37:10,747] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5497432]
[2019-03-23 14:37:10,748] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.28817057333333, 76.10658935333333, 1.0, 2.0, 0.207888277031282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 225702.7639927143, 225702.7639927139, 76166.37452667653]
[2019-03-23 14:37:10,749] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:37:10,751] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.6366191e-10 1.0000000e+00 3.4984253e-35 2.7426256e-21 0.0000000e+00], sampled 0.15103969157550468
[2019-03-23 14:37:11,876] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8514.0903 1771834031.7717 173.0000
[2019-03-23 14:37:11,979] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.9398 1705910596.8174 464.0000
[2019-03-23 14:37:12,191] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.8544 1663709020.9157 104.0000
[2019-03-23 14:37:12,257] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8577.4421 1682717794.9096 210.0000
[2019-03-23 14:37:12,270] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:37:13,287] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1800000, evaluation results [1800000.0, 8514.090298289926, 1771834031.7716832, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.854385711344, 1663709020.9156682, 104.0, 8597.939758372268, 1705910596.817383, 464.0, 8577.44211141971, 1682717794.9096184, 210.0]
[2019-03-23 14:37:23,908] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.0552649e-09 1.0000000e+00 1.2838615e-26 1.2197625e-11 2.5442027e-33], sum to 1.0000
[2019-03-23 14:37:23,917] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4449
[2019-03-23 14:37:23,922] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.16666666666667, 94.00000000000001, 1.0, 2.0, 0.4282818102065404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 477613.9502228837, 477613.9502228837, 125141.4406050031], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4090200.0000, 
sim time next is 4090800.0000, 
raw observation next is [18.33333333333334, 94.0, 1.0, 2.0, 0.5290484084775643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 591715.1939827312, 591715.193982731, 135513.5087341162], 
processed observation next is [1.0, 0.34782608695652173, 0.46969696969696995, 0.94, 1.0, 1.0, 0.41131051059695534, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2191537755491597, 0.21915377554915963, 0.3305207530100395], 
reward next is 0.6695, 
noisyNet noise sample is [array([-0.9007158], dtype=float32), -1.7272718]. 
=============================================
[2019-03-23 14:37:30,667] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.7990194e-12 1.0000000e+00 1.7677444e-33 6.1459972e-20 0.0000000e+00], sum to 1.0000
[2019-03-23 14:37:30,673] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0865
[2019-03-23 14:37:30,677] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 88.0, 1.0, 2.0, 0.3632247883867044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 405960.2554352916, 405960.2554352913, 119974.8684751069], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4226400.0000, 
sim time next is 4227000.0000, 
raw observation next is [19.0, 88.00000000000001, 1.0, 2.0, 0.3630382835921166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 405711.8957844048, 405711.8957844045, 119941.6642023276], 
processed observation next is [1.0, 0.9565217391304348, 0.5, 0.8800000000000001, 1.0, 1.0, 0.20379785449014573, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15026366510533512, 0.15026366510533498, 0.292540644395921], 
reward next is 0.7075, 
noisyNet noise sample is [array([0.20325737], dtype=float32), 0.31778574]. 
=============================================
[2019-03-23 14:37:30,697] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[67.89786 ]
 [67.90193 ]
 [67.93413 ]
 [67.97352 ]
 [67.985634]], R is [[67.90021515]
 [67.92858887]
 [67.9563446 ]
 [67.98369598]
 [68.01084137]].
[2019-03-23 14:37:33,617] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.2453501e-14 1.0000000e+00 9.1065743e-36 7.4852074e-21 0.0000000e+00], sum to 1.0000
[2019-03-23 14:37:33,632] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9155
[2019-03-23 14:37:33,642] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 47.5, 1.0, 2.0, 0.6470619810563984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 729011.5833163175, 729011.5833163175, 151019.956586571], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4278600.0000, 
sim time next is 4279200.0000, 
raw observation next is [26.33333333333334, 46.66666666666667, 1.0, 2.0, 0.6411445171492884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 723123.763579753, 723123.763579753, 150695.2992686113], 
processed observation next is [1.0, 0.5217391304347826, 0.8333333333333336, 0.46666666666666673, 1.0, 1.0, 0.5514306464366105, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.26782361614064926, 0.26782361614064926, 0.36754951041124706], 
reward next is 0.6325, 
noisyNet noise sample is [array([0.778421], dtype=float32), -0.21295851]. 
=============================================
[2019-03-23 14:37:33,755] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.4470387e-13 1.0000000e+00 2.2491748e-35 2.7439756e-21 0.0000000e+00], sum to 1.0000
[2019-03-23 14:37:33,767] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7583
[2019-03-23 14:37:33,776] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333334, 59.66666666666667, 1.0, 2.0, 0.3967433805683652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 448916.650866345, 448916.6508663453, 125611.8857862015], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4304400.0000, 
sim time next is 4305000.0000, 
raw observation next is [24.16666666666666, 60.33333333333334, 1.0, 2.0, 0.3961987338210102, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 448139.4167087661, 448139.4167087661, 125462.1717173884], 
processed observation next is [1.0, 0.8260869565217391, 0.7348484848484845, 0.6033333333333334, 1.0, 1.0, 0.2452484172762627, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16597756174398742, 0.16597756174398742, 0.306005296871679], 
reward next is 0.6940, 
noisyNet noise sample is [array([-0.09631821], dtype=float32), 0.9456333]. 
=============================================
[2019-03-23 14:37:33,794] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[72.26008 ]
 [72.20264 ]
 [72.03821 ]
 [71.712425]
 [71.36432 ]], R is [[72.13143158]
 [72.10374451]
 [72.07566071]
 [72.04718018]
 [72.01835632]].
[2019-03-23 14:37:37,950] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.3626980e-07 9.9999976e-01 2.7531687e-22 6.2467227e-09 8.5955896e-29], sum to 1.0000
[2019-03-23 14:37:37,951] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1970
[2019-03-23 14:37:37,964] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.3512380286586956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 390867.1176969858, 390867.1176969858, 118255.6431511961], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4337400.0000, 
sim time next is 4338000.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.3509303647761504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 390521.0963326881, 390521.0963326884, 118229.7287136881], 
processed observation next is [1.0, 0.21739130434782608, 0.45454545454545453, 0.94, 1.0, 1.0, 0.188662955970188, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1446374430861808, 0.1446374430861809, 0.28836519198460514], 
reward next is 0.7116, 
noisyNet noise sample is [array([-0.08445215], dtype=float32), 0.20844683]. 
=============================================
[2019-03-23 14:37:37,993] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[51.34849 ]
 [51.416862]
 [51.507626]
 [51.551365]
 [51.410595]], R is [[51.47232437]
 [51.66917419]
 [51.86370468]
 [52.05576324]
 [52.24536133]].
[2019-03-23 14:37:46,371] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.427993e-11 1.000000e+00 5.624651e-35 7.280842e-19 0.000000e+00], sum to 1.0000
[2019-03-23 14:37:46,377] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9102
[2019-03-23 14:37:46,382] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 82.0, 1.0, 2.0, 0.2738489408625469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 297350.8174940987, 297350.817494099, 95429.27408771575], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4578000.0000, 
sim time next is 4578600.0000, 
raw observation next is [17.0, 82.0, 1.0, 2.0, 0.2739240853111768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 297432.4358340525, 297432.4358340522, 95431.92065948929], 
processed observation next is [0.0, 1.0, 0.4090909090909091, 0.82, 1.0, 1.0, 0.09240510663897097, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11016016142001944, 0.11016016142001935, 0.23276078209631534], 
reward next is 0.7672, 
noisyNet noise sample is [array([2.2725725], dtype=float32), 0.5129357]. 
=============================================
[2019-03-23 14:38:01,542] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 14:38:01,543] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:38:01,544] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:38:01,544] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:38:01,545] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:38:01,546] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:38:01,547] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:38:01,547] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:38:01,548] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:38:01,548] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:38:01,549] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:38:01,573] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run74
[2019-03-23 14:38:01,602] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run74
[2019-03-23 14:38:01,603] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run74
[2019-03-23 14:38:01,657] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run74
[2019-03-23 14:38:01,658] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run74
[2019-03-23 14:38:44,201] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.55112255]
[2019-03-23 14:38:44,203] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.1, 90.0, 1.0, 2.0, 0.4467288567248134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 508938.2832978586, 508938.2832978583, 137499.4387379738]
[2019-03-23 14:38:44,203] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:38:44,206] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0335981e-09 1.0000000e+00 5.9961073e-31 7.7791812e-18 2.0382929e-37], sampled 0.7564024505856843
[2019-03-23 14:39:19,919] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.55112255]
[2019-03-23 14:39:19,920] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.89585202, 67.56260163, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 216826.8023140729, 216826.8023140729, 73561.78654813433]
[2019-03-23 14:39:19,921] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:39:19,924] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.10681586e-10 1.00000000e+00 9.38159596e-31 1.25955875e-17
 3.41766785e-37], sampled 0.975086264057684
[2019-03-23 14:39:45,349] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8600.0550 1705715959.7657 457.0000
[2019-03-23 14:39:45,397] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8517.4469 1770292639.3961 170.0000
[2019-03-23 14:39:45,439] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8858.6590 1663588978.3837 100.0000
[2019-03-23 14:39:45,523] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8582.7607 1682244573.8905 195.0000
[2019-03-23 14:39:45,604] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9064.0363 1656078433.7793 75.0000
[2019-03-23 14:39:46,621] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1825000, evaluation results [1825000.0, 8517.446882720613, 1770292639.3960814, 170.0, 9064.03627509881, 1656078433.7792792, 75.0, 8858.658951337618, 1663588978.3836937, 100.0, 8600.055034343837, 1705715959.7657459, 457.0, 8582.760698218155, 1682244573.8905406, 195.0]
[2019-03-23 14:39:47,838] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.6909055e-10 1.0000000e+00 7.1249787e-32 1.3811046e-15 0.0000000e+00], sum to 1.0000
[2019-03-23 14:39:47,844] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4311
[2019-03-23 14:39:47,850] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.4447708574377938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 506897.6585365623, 506897.6585365623, 133179.0958903647], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4841400.0000, 
sim time next is 4842000.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.4441918628443092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 506237.0057321845, 506237.0057321845, 133118.364897608], 
processed observation next is [1.0, 0.043478260869565216, 0.5454545454545454, 1.0, 1.0, 1.0, 0.3052398285553865, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1874951873082165, 0.1874951873082165, 0.32467893877465365], 
reward next is 0.6753, 
noisyNet noise sample is [array([0.6919315], dtype=float32), 1.7601104]. 
=============================================
[2019-03-23 14:39:47,883] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[67.87032 ]
 [67.8726  ]
 [67.85522 ]
 [67.89824 ]
 [68.025826]], R is [[67.8939743 ]
 [67.89020538]
 [67.88627625]
 [67.88217926]
 [67.87806702]].
[2019-03-23 14:39:48,899] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3661741e-10 1.0000000e+00 1.0813450e-29 1.8414147e-16 9.1851029e-37], sum to 1.0000
[2019-03-23 14:39:48,906] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8033
[2019-03-23 14:39:48,911] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.4447708574377938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 506897.6585365623, 506897.6585365623, 133179.0958903647], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4841400.0000, 
sim time next is 4842000.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.4441918628443092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 506237.0057321845, 506237.0057321845, 133118.364897608], 
processed observation next is [1.0, 0.043478260869565216, 0.5454545454545454, 1.0, 1.0, 1.0, 0.3052398285553865, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1874951873082165, 0.1874951873082165, 0.32467893877465365], 
reward next is 0.6753, 
noisyNet noise sample is [array([1.6740698], dtype=float32), -0.89858043]. 
=============================================
[2019-03-23 14:39:48,933] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[62.974247]
 [62.983063]
 [63.08183 ]
 [63.30698 ]
 [63.655758]], R is [[62.91799545]
 [62.96398926]
 [63.00931931]
 [63.05399704]
 [63.0981636 ]].
[2019-03-23 14:39:49,988] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.8567188e-10 1.0000000e+00 1.2038451e-29 2.5571266e-16 5.4379676e-37], sum to 1.0000
[2019-03-23 14:39:49,997] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5074
[2019-03-23 14:39:50,001] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666666, 74.66666666666667, 1.0, 2.0, 0.8420065275855197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 958498.0688241562, 958498.0688241562, 183869.2070470887], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4894800.0000, 
sim time next is 4895400.0000, 
raw observation next is [22.83333333333334, 73.83333333333333, 1.0, 2.0, 0.8518591263726549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 969921.7368394608, 969921.7368394606, 185626.6283906058], 
processed observation next is [1.0, 0.6521739130434783, 0.6742424242424245, 0.7383333333333333, 1.0, 1.0, 0.8148239079658187, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.359230272903504, 0.3592302729035039, 0.45274787412342876], 
reward next is 0.5473, 
noisyNet noise sample is [array([0.2805374], dtype=float32), 1.283391]. 
=============================================
[2019-03-23 14:39:51,746] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.2238432e-10 1.0000000e+00 9.3046124e-31 1.7183976e-17 8.2128595e-38], sum to 1.0000
[2019-03-23 14:39:51,758] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1557
[2019-03-23 14:39:51,764] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.3915224532148444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 441312.3786047756, 441312.3786047759, 124151.7704161575], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4919400.0000, 
sim time next is 4920000.0000, 
raw observation next is [18.66666666666667, 96.0, 1.0, 2.0, 0.3883494562087395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 437259.0299480187, 437259.0299480187, 123616.1909732122], 
processed observation next is [1.0, 0.9565217391304348, 0.4848484848484851, 0.96, 1.0, 1.0, 0.23543682026092436, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16194778886963657, 0.16194778886963657, 0.3015029048127127], 
reward next is 0.6985, 
noisyNet noise sample is [array([-1.1062725], dtype=float32), -0.9081606]. 
=============================================
[2019-03-23 14:39:51,782] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[66.673805]
 [66.693085]
 [66.69437 ]
 [66.703   ]
 [66.70759 ]], R is [[66.67268372]
 [66.70314789]
 [66.73175049]
 [66.75827789]
 [66.7828598 ]].
[2019-03-23 14:39:52,029] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.1863654e-10 1.0000000e+00 2.6084258e-32 7.9922098e-17 0.0000000e+00], sum to 1.0000
[2019-03-23 14:39:52,040] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1005
[2019-03-23 14:39:52,048] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 75.5, 1.0, 2.0, 0.4170236586395323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 473944.5417075017, 473944.5417075017, 128971.6107150298], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4901400.0000, 
sim time next is 4902000.0000, 
raw observation next is [22.66666666666666, 74.66666666666667, 1.0, 2.0, 0.4219979539060369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 479705.1473376881, 479705.1473376884, 129546.4088727526], 
processed observation next is [1.0, 0.7391304347826086, 0.6666666666666664, 0.7466666666666667, 1.0, 1.0, 0.2774974423825461, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17766857308803263, 0.17766857308803274, 0.31596685090915266], 
reward next is 0.6840, 
noisyNet noise sample is [array([-0.45195833], dtype=float32), -0.21486787]. 
=============================================
[2019-03-23 14:39:52,065] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[67.60636]
 [67.3283 ]
 [66.86463]
 [66.2707 ]
 [66.05606]], R is [[67.76128387]
 [67.769104  ]
 [67.77528381]
 [67.7563858 ]
 [67.659935  ]].
[2019-03-23 14:39:55,101] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0011318e-11 1.0000000e+00 1.1435369e-35 8.0981768e-18 0.0000000e+00], sum to 1.0000
[2019-03-23 14:39:55,106] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0694
[2019-03-23 14:39:55,114] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 82.0, 1.0, 2.0, 0.2799746326454133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 304004.2986441747, 304004.298644175, 96110.02167971885], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5000400.0000, 
sim time next is 5001000.0000, 
raw observation next is [17.16666666666667, 81.16666666666667, 1.0, 2.0, 0.2809147974511244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 305025.4760707429, 305025.4760707432, 97049.106216607], 
processed observation next is [1.0, 0.9130434782608695, 0.4166666666666669, 0.8116666666666668, 1.0, 1.0, 0.1011434968139055, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11297239854471959, 0.11297239854471972, 0.2367051371136756], 
reward next is 0.7633, 
noisyNet noise sample is [array([-0.67854524], dtype=float32), -0.12484648]. 
=============================================
[2019-03-23 14:39:55,135] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[78.416275]
 [78.3327  ]
 [78.32498 ]
 [78.31978 ]
 [78.37083 ]], R is [[78.43762207]
 [78.41883087]
 [78.40033722]
 [78.38239288]
 [78.36537933]].
[2019-03-23 14:40:02,091] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.5112661e-09 1.0000000e+00 4.1587544e-32 1.8198904e-18 0.0000000e+00], sum to 1.0000
[2019-03-23 14:40:02,098] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5875
[2019-03-23 14:40:02,106] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4328705274285373, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 493172.6840744808, 493172.6840744808, 131744.3931782842], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5124600.0000, 
sim time next is 5125200.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4336576291417297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 494070.6094298993, 494070.6094298993, 131825.4659238429], 
processed observation next is [0.0, 0.30434782608695654, 0.6363636363636364, 0.83, 1.0, 1.0, 0.29207203642716206, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1829891146036664, 0.1829891146036664, 0.32152552664351924], 
reward next is 0.6785, 
noisyNet noise sample is [array([-0.38950208], dtype=float32), 1.5947316]. 
=============================================
[2019-03-23 14:40:04,361] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1580055e-09 1.0000000e+00 1.5090667e-30 9.2143248e-17 1.5338075e-38], sum to 1.0000
[2019-03-23 14:40:04,369] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6140
[2019-03-23 14:40:04,377] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666666, 81.33333333333333, 1.0, 2.0, 0.4571885197673928, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 521411.1366617353, 521411.1366617353, 135070.4393905402], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5211600.0000, 
sim time next is 5212200.0000, 
raw observation next is [22.83333333333334, 82.16666666666667, 1.0, 2.0, 0.4523018113033654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516041.2081376446, 516041.2081376446, 135121.4700703672], 
processed observation next is [1.0, 0.30434782608695654, 0.6742424242424245, 0.8216666666666668, 1.0, 1.0, 0.3153772641292067, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1911263733843128, 0.1911263733843128, 0.3295645611472371], 
reward next is 0.6704, 
noisyNet noise sample is [array([0.5444079], dtype=float32), -1.4246006]. 
=============================================
[2019-03-23 14:40:08,140] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0916684e-06 9.9999893e-01 2.2613759e-24 5.0245580e-10 4.4503031e-30], sum to 1.0000
[2019-03-23 14:40:08,148] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6329
[2019-03-23 14:40:08,155] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.5046353822557949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 575504.1982674772, 575504.1982674772, 142636.983408003], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5249400.0000, 
sim time next is 5250000.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5035628795988327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 574281.7908122662, 574281.7908122662, 142508.5154543534], 
processed observation next is [1.0, 0.782608695652174, 0.6363636363636364, 0.94, 1.0, 1.0, 0.37945359949854085, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2126969595600986, 0.2126969595600986, 0.347581745010618], 
reward next is 0.6524, 
noisyNet noise sample is [array([-0.00155732], dtype=float32), -0.72905535]. 
=============================================
[2019-03-23 14:40:08,170] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[55.608963]
 [55.237663]
 [55.209114]
 [55.036415]
 [54.6108  ]], R is [[56.08016205]
 [56.17146301]
 [56.26147461]
 [56.34992981]
 [56.4366188 ]].
[2019-03-23 14:40:08,537] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.2983256e-09 1.0000000e+00 1.5088008e-24 1.8707555e-12 4.0069048e-31], sum to 1.0000
[2019-03-23 14:40:08,543] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3765
[2019-03-23 14:40:08,548] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5012343236721676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 571625.6545119487, 571625.6545119489, 142233.6172971097], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5253600.0000, 
sim time next is 5254200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5039357001865337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 574707.6113416294, 574707.6113416294, 142551.71406249], 
processed observation next is [1.0, 0.8260869565217391, 0.6363636363636364, 0.94, 1.0, 1.0, 0.379919625233167, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21285467086727014, 0.21285467086727014, 0.34768710746948783], 
reward next is 0.6523, 
noisyNet noise sample is [array([0.4500665], dtype=float32), -1.0915142]. 
=============================================
[2019-03-23 14:40:09,814] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3373577e-10 1.0000000e+00 3.2193649e-33 2.9917455e-20 0.0000000e+00], sum to 1.0000
[2019-03-23 14:40:09,819] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4692
[2019-03-23 14:40:09,824] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.43333333333333, 76.33333333333334, 1.0, 2.0, 0.3236192461992649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 355942.9634118532, 355942.9634118529, 114421.1672054083], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5280000.0000, 
sim time next is 5280600.0000, 
raw observation next is [19.36666666666667, 77.16666666666666, 1.0, 2.0, 0.3229299195152236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 355426.2524821325, 355426.2524821322, 114462.7551525095], 
processed observation next is [1.0, 0.08695652173913043, 0.5166666666666668, 0.7716666666666666, 1.0, 1.0, 0.15366239939402948, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1316393527711602, 0.13163935277116007, 0.2791774515914866], 
reward next is 0.7208, 
noisyNet noise sample is [array([-0.41700217], dtype=float32), 1.2341703]. 
=============================================
[2019-03-23 14:40:10,974] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.7069500e-11 1.0292607e-08 1.3697021e-17 1.0000000e+00 9.0025461e-27], sum to 1.0000
[2019-03-23 14:40:10,981] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3206
[2019-03-23 14:40:10,985] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.48333333333333, 54.66666666666667, 1.0, 2.0, 0.6410258534605372, 1.0, 2.0, 0.6410258534605372, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 79.72385527075286, 1451921.362629283, 1451921.362629283, 272715.784997299], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5314200.0000, 
sim time next is 5314800.0000, 
raw observation next is [28.66666666666667, 54.33333333333334, 1.0, 2.0, 0.5331744200119701, 1.0, 2.0, 0.5331744200119701, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1206792.081464704, 1206792.081464704, 241915.8516446702], 
processed observation next is [1.0, 0.5217391304347826, 0.9393939393939396, 0.5433333333333334, 1.0, 1.0, 0.4164680250149626, 1.0, 1.0, 0.4164680250149626, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.44696003017211255, 0.44696003017211255, 0.5900386625479761], 
reward next is 0.4100, 
noisyNet noise sample is [array([0.83376926], dtype=float32), -0.3751676]. 
=============================================
[2019-03-23 14:40:12,900] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0171074e-10 2.7702809e-09 3.9650750e-16 1.0000000e+00 3.0727621e-24], sum to 1.0000
[2019-03-23 14:40:12,911] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4480
[2019-03-23 14:40:12,918] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.4, 51.0, 1.0, 2.0, 0.6585313628642109, 1.0, 2.0, 0.6585313628642109, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1487658.65288566, 1487658.65288566, 277525.5117447117], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5324400.0000, 
sim time next is 5325000.0000, 
raw observation next is [29.5, 51.0, 1.0, 2.0, 0.6564459813522895, 1.0, 2.0, 0.6564459813522895, 0.0, 2.0, 0.0, 6.9112, 6.9112, 79.1607752524639, 1482498.879108393, 1482498.879108393, 278194.2507137541], 
processed observation next is [1.0, 0.6521739130434783, 0.9772727272727273, 0.51, 1.0, 1.0, 0.5705574766903618, 1.0, 1.0, 0.5705574766903618, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5204761248214179, 0.5490736589290345, 0.5490736589290345, 0.6785225627164734], 
reward next is 0.3215, 
noisyNet noise sample is [array([-0.45237684], dtype=float32), -0.10633631]. 
=============================================
[2019-03-23 14:40:12,933] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[37.296726]
 [37.491047]
 [37.448254]
 [37.535458]
 [37.56859 ]], R is [[37.01207352]
 [36.96506119]
 [36.90055084]
 [36.83956146]
 [36.78992462]].
[2019-03-23 14:40:15,383] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.5864417e-23 5.4802864e-21 3.0589888e-29 1.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 14:40:15,389] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2590
[2019-03-23 14:40:15,401] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.8, 79.0, 1.0, 2.0, 0.4619683309335345, 1.0, 2.0, 0.4619683309335345, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1051001.716872329, 1051001.716872329, 222114.5574817153], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5389200.0000, 
sim time next is 5389800.0000, 
raw observation next is [24.08333333333334, 78.66666666666667, 1.0, 2.0, 0.4755993446211469, 1.0, 2.0, 0.4755993446211469, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1080642.715275245, 1080642.715275245, 226017.815044777], 
processed observation next is [1.0, 0.391304347826087, 0.7310606060606063, 0.7866666666666667, 1.0, 1.0, 0.3444991807764336, 1.0, 1.0, 0.3444991807764336, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.40023804269453517, 0.40023804269453517, 0.5512629635238463], 
reward next is 0.4487, 
noisyNet noise sample is [array([-1.0225362], dtype=float32), 0.4228888]. 
=============================================
[2019-03-23 14:40:17,338] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0589207e-09 1.0000000e+00 8.2112372e-29 2.9273876e-18 2.0907341e-36], sum to 1.0000
[2019-03-23 14:40:17,345] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4807
[2019-03-23 14:40:17,352] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 95.0, 1.0, 2.0, 0.3269762733194131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 359575.7567413406, 359575.7567413409, 114643.2848225369], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5467800.0000, 
sim time next is 5468400.0000, 
raw observation next is [17.2, 96.0, 1.0, 2.0, 0.3286617055359304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 362117.8286965055, 362117.8286965055, 115027.0222153749], 
processed observation next is [1.0, 0.30434782608695654, 0.41818181818181815, 0.96, 1.0, 1.0, 0.16082713191991296, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1341177143320391, 0.1341177143320391, 0.2805537127204266], 
reward next is 0.7194, 
noisyNet noise sample is [array([-0.9293136], dtype=float32), -0.88270605]. 
=============================================
[2019-03-23 14:40:25,449] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.9097095e-10 1.0000000e+00 4.5142903e-30 9.5568415e-19 7.8502977e-36], sum to 1.0000
[2019-03-23 14:40:25,458] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2568
[2019-03-23 14:40:25,468] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.1, 72.0, 1.0, 2.0, 0.4679684259038334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 533897.9383146506, 533897.9383146506, 136708.8839376101], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5596200.0000, 
sim time next is 5596800.0000, 
raw observation next is [22.9, 77.0, 1.0, 2.0, 0.4532681522658806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 516707.1596471458, 516707.1596471455, 134242.6832441908], 
processed observation next is [1.0, 0.782608695652174, 0.6772727272727272, 0.77, 1.0, 1.0, 0.31658519033235066, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19137302209153548, 0.19137302209153537, 0.32742117864436776], 
reward next is 0.6726, 
noisyNet noise sample is [array([-0.24517317], dtype=float32), -0.58473825]. 
=============================================
[2019-03-23 14:40:26,192] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.0630463e-12 1.0000000e+00 7.5081679e-37 1.1277455e-22 0.0000000e+00], sum to 1.0000
[2019-03-23 14:40:26,198] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6374
[2019-03-23 14:40:26,200] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.43333333333333, 97.0, 1.0, 2.0, 0.3842121643695404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 432121.6260765143, 432121.6260765143, 123004.8795526978], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5635200.0000, 
sim time next is 5635800.0000, 
raw observation next is [18.25, 97.0, 1.0, 2.0, 0.3786374002901878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 424959.6156763367, 424959.615676337, 122077.3357094135], 
processed observation next is [0.0, 0.21739130434782608, 0.4659090909090909, 0.97, 1.0, 1.0, 0.2232967503627347, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15739245025049506, 0.15739245025049517, 0.29774959929125244], 
reward next is 0.7023, 
noisyNet noise sample is [array([1.439032], dtype=float32), -0.8746146]. 
=============================================
[2019-03-23 14:40:28,874] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9390846e-14 1.0000000e+00 2.1341253e-37 5.7919582e-21 0.0000000e+00], sum to 1.0000
[2019-03-23 14:40:28,883] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1872
[2019-03-23 14:40:28,888] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.1, 93.5, 1.0, 2.0, 0.2905097709923071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 315447.3570058552, 315447.3570058552, 102991.2571151747], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5651400.0000, 
sim time next is 5652000.0000, 
raw observation next is [16.1, 93.0, 1.0, 2.0, 0.2891877545098726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 314011.3941439678, 314011.3941439681, 101921.0433489284], 
processed observation next is [0.0, 0.43478260869565216, 0.3681818181818182, 0.93, 1.0, 1.0, 0.11148469313734075, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11630051634961769, 0.11630051634961783, 0.24858791060714244], 
reward next is 0.7514, 
noisyNet noise sample is [array([-1.0450318], dtype=float32), 0.3511141]. 
=============================================
[2019-03-23 14:40:28,908] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[80.02656 ]
 [79.97964 ]
 [79.92271 ]
 [79.852806]
 [79.783745]], R is [[80.0193634 ]
 [79.9679718 ]
 [79.91434479]
 [79.85832214]
 [79.79970551]].
[2019-03-23 14:40:34,057] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.9746796e-06 2.1766352e-02 4.6712753e-13 9.7822565e-01 1.0861003e-19], sum to 1.0000
[2019-03-23 14:40:34,071] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7748
[2019-03-23 14:40:34,077] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.26666666666667, 48.33333333333334, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 240258.0642548342, 240258.0642548342, 97216.0406781321], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5743200.0000, 
sim time next is 5743800.0000, 
raw observation next is [18.55, 47.5, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 243432.9247950205, 243432.9247950202, 97977.35439277964], 
processed observation next is [0.0, 0.4782608695652174, 0.47954545454545455, 0.475, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09016034251667425, 0.09016034251667415, 0.2389691570555601], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.56716007], dtype=float32), 1.1604255]. 
=============================================
[2019-03-23 14:40:34,625] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 14:40:34,626] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:40:34,627] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:40:34,627] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:40:34,627] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:40:34,628] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:40:34,629] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:40:34,631] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:40:34,630] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:40:34,631] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:40:34,629] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:40:34,654] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run75
[2019-03-23 14:40:34,680] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run75
[2019-03-23 14:40:34,705] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run75
[2019-03-23 14:40:34,740] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run75
[2019-03-23 14:40:34,742] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run75
[2019-03-23 14:40:55,458] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.55339825]
[2019-03-23 14:40:55,459] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.11108634, 100.0, 1.0, 2.0, 0.4326802347342806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 491438.7324764324, 491438.7324764324, 134605.4411301788]
[2019-03-23 14:40:55,459] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:40:55,461] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.2301514e-09 1.0000000e+00 8.7916280e-33 8.5802004e-20 0.0000000e+00], sampled 0.5438174448454483
[2019-03-23 14:41:30,231] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.55339825]
[2019-03-23 14:41:30,232] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.86666666666667, 59.66666666666667, 1.0, 2.0, 0.5010363154851865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 571616.2424253759, 571616.2424253759, 145858.2721123146]
[2019-03-23 14:41:30,233] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:41:30,235] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0626354e-09 1.0000000e+00 4.6124422e-33 5.5053284e-20 0.0000000e+00], sampled 0.9110944107007956
[2019-03-23 14:42:05,803] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.55339825]
[2019-03-23 14:42:05,804] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.8, 78.66666666666667, 1.0, 2.0, 0.379880652794885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 427335.5144878511, 427335.5144878511, 126997.7242640127]
[2019-03-23 14:42:05,806] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:42:05,808] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0414225e-09 1.0000000e+00 3.1255333e-33 4.3478358e-20 0.0000000e+00], sampled 0.7196360802593015
[2019-03-23 14:42:08,418] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.55339825]
[2019-03-23 14:42:08,421] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.75, 78.16666666666667, 1.0, 2.0, 0.4219676865229501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 468766.9839289231, 468766.9839289231, 128172.9874454924]
[2019-03-23 14:42:08,421] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:42:08,427] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.9465157e-10 1.0000000e+00 1.7193803e-33 3.0153134e-20 0.0000000e+00], sampled 0.013341155704716168
[2019-03-23 14:42:18,019] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 14:42:18,103] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8576.0790 1683117533.5416 212.0000
[2019-03-23 14:42:18,178] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8514.5598 1772421605.8979 173.0000
[2019-03-23 14:42:18,353] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 14:42:18,372] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:42:19,385] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1850000, evaluation results [1850000.0, 8514.559787053195, 1772421605.8978891, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8576.07903678212, 1683117533.5415888, 212.0]
[2019-03-23 14:42:22,903] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7595270e-10 1.0000000e+00 7.0303144e-34 1.1767365e-18 0.0000000e+00], sum to 1.0000
[2019-03-23 14:42:22,912] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8030
[2019-03-23 14:42:22,916] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.78333333333333, 66.16666666666667, 1.0, 2.0, 0.3485641030070381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 388368.2509071157, 388368.2509071159, 118248.6888461788], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6202200.0000, 
sim time next is 6202800.0000, 
raw observation next is [21.6, 68.0, 1.0, 2.0, 0.3515289843532827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 392176.1484642511, 392176.1484642511, 118704.179027893], 
processed observation next is [1.0, 0.8260869565217391, 0.6181818181818183, 0.68, 1.0, 1.0, 0.18941123044160338, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14525042535713004, 0.14525042535713004, 0.28952238787290974], 
reward next is 0.7105, 
noisyNet noise sample is [array([-0.4150755], dtype=float32), 0.5520228]. 
=============================================
[2019-03-23 14:42:38,135] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.1452881e-10 1.0000000e+00 1.5628591e-32 1.8891965e-20 0.0000000e+00], sum to 1.0000
[2019-03-23 14:42:38,145] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6465
[2019-03-23 14:42:38,150] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.6, 62.33333333333333, 1.0, 2.0, 0.2716422007188077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 294953.9670070806, 294953.9670070803, 94699.65944695771], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6129600.0000, 
sim time next is 6130200.0000, 
raw observation next is [19.8, 61.66666666666666, 1.0, 2.0, 0.2732885693805557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 296742.1689712431, 296742.1689712428, 96018.20635376025], 
processed observation next is [1.0, 0.9565217391304348, 0.5363636363636364, 0.6166666666666666, 1.0, 1.0, 0.09161071172569459, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10990450702638632, 0.10990450702638623, 0.2341907472042933], 
reward next is 0.7658, 
noisyNet noise sample is [array([1.3335073], dtype=float32), 1.2431805]. 
=============================================
[2019-03-23 14:42:48,370] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0535518e-09 1.0000000e+00 5.3837118e-34 3.4529786e-18 0.0000000e+00], sum to 1.0000
[2019-03-23 14:42:48,376] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2082
[2019-03-23 14:42:48,381] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 86.5, 1.0, 2.0, 0.4876437219919363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 556298.969146129, 556298.9691461287, 140295.9171660077], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6333000.0000, 
sim time next is 6333600.0000, 
raw observation next is [22.9, 86.0, 1.0, 2.0, 0.4894587002633068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558341.721465199, 558341.721465199, 140572.7458930015], 
processed observation next is [0.0, 0.30434782608695654, 0.6772727272727272, 0.86, 1.0, 1.0, 0.36182337532913345, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20679323017229592, 0.20679323017229592, 0.342860355836589], 
reward next is 0.6571, 
noisyNet noise sample is [array([1.0408486], dtype=float32), 0.50586045]. 
=============================================
[2019-03-23 14:42:53,290] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.7765552e-10 1.0000000e+00 1.0054272e-31 1.5607953e-20 2.5006563e-38], sum to 1.0000
[2019-03-23 14:42:53,298] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7536
[2019-03-23 14:42:53,302] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.9, 71.5, 1.0, 2.0, 0.5346801302674933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 610044.5104875583, 610044.5104875583, 145701.4343904134], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6419400.0000, 
sim time next is 6420000.0000, 
raw observation next is [24.8, 72.0, 1.0, 2.0, 0.5390687764177086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 615062.7122673099, 615062.7122673099, 146210.8846233359], 
processed observation next is [1.0, 0.30434782608695654, 0.7636363636363637, 0.72, 1.0, 1.0, 0.4238359705221357, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22780100454344812, 0.22780100454344812, 0.3566119137154534], 
reward next is 0.6434, 
noisyNet noise sample is [array([0.5273611], dtype=float32), -0.47974932]. 
=============================================
[2019-03-23 14:42:53,320] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[63.96825]
 [64.09813]
 [64.11538]
 [64.11437]
 [64.11474]], R is [[63.88355637]
 [63.88935089]
 [63.90683746]
 [63.92757797]
 [63.94736099]].
[2019-03-23 14:42:54,056] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.0281220e-09 1.0000000e+00 2.1063737e-31 2.5286717e-19 3.5285090e-38], sum to 1.0000
[2019-03-23 14:42:54,064] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3019
[2019-03-23 14:42:54,069] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 82.5, 1.0, 2.0, 0.8295021430347137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 946877.712201508, 946877.7122015078, 187351.1576848085], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6424200.0000, 
sim time next is 6424800.0000, 
raw observation next is [22.53333333333333, 85.33333333333333, 1.0, 2.0, 0.8401520711153051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 959073.1974067441, 959073.1974067441, 188910.1542250757], 
processed observation next is [1.0, 0.34782608695652173, 0.6606060606060605, 0.8533333333333333, 1.0, 1.0, 0.8001900888941312, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.35521229533583115, 0.35521229533583115, 0.46075647371969686], 
reward next is 0.5392, 
noisyNet noise sample is [array([-0.13633332], dtype=float32), 1.5767113]. 
=============================================
[2019-03-23 14:43:05,450] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.0838266e-11 1.0000000e+00 2.7615947e-37 1.3383881e-22 0.0000000e+00], sum to 1.0000
[2019-03-23 14:43:05,458] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1689
[2019-03-23 14:43:05,462] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 87.0, 1.0, 2.0, 0.3506940019780208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 390179.9906920823, 390179.9906920823, 118177.9983683436], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6648600.0000, 
sim time next is 6649200.0000, 
raw observation next is [18.8, 87.0, 1.0, 2.0, 0.349645385452977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 389008.5074160997, 389008.5074160994, 118093.08648937], 
processed observation next is [1.0, 1.0, 0.49090909090909096, 0.87, 1.0, 1.0, 0.18705673181622126, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14407722496892583, 0.14407722496892572, 0.2880319182667561], 
reward next is 0.7120, 
noisyNet noise sample is [array([0.95492125], dtype=float32), -0.8016602]. 
=============================================
[2019-03-23 14:43:06,340] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1796610e-09 1.0000000e+00 9.2346284e-32 4.0519927e-21 0.0000000e+00], sum to 1.0000
[2019-03-23 14:43:06,347] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3135
[2019-03-23 14:43:06,354] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.46666666666667, 89.0, 1.0, 2.0, 0.3406122546024116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 378444.8823194136, 378444.8823194139, 117167.9124267749], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6673200.0000, 
sim time next is 6673800.0000, 
raw observation next is [18.38333333333333, 89.5, 1.0, 2.0, 0.3390489085125916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 376565.135428149, 376565.1354281493, 116987.3755563455], 
processed observation next is [1.0, 0.21739130434782608, 0.47196969696969676, 0.895, 1.0, 1.0, 0.1738111356407395, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13946856867709223, 0.13946856867709234, 0.28533506233255], 
reward next is 0.7147, 
noisyNet noise sample is [array([0.4854066], dtype=float32), -0.20259777]. 
=============================================
[2019-03-23 14:43:07,283] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 14:43:07,285] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:43:07,285] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:43:07,285] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:43:07,286] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:43:07,287] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:43:07,288] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:43:07,288] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:43:07,288] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:43:07,290] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:43:07,292] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:43:07,309] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run76
[2019-03-23 14:43:07,335] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run76
[2019-03-23 14:43:07,337] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run76
[2019-03-23 14:43:07,361] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run76
[2019-03-23 14:43:07,361] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run76
[2019-03-23 14:43:09,914] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5522312]
[2019-03-23 14:43:09,915] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.4, 57.0, 1.0, 2.0, 0.2217505605348254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 240755.956687802, 240755.9566878017, 77021.40126502387]
[2019-03-23 14:43:09,916] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:43:09,918] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.5668724e-10 1.0000000e+00 9.3675688e-33 6.5155808e-20 0.0000000e+00], sampled 0.010463122029970129
[2019-03-23 14:43:38,888] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5522312]
[2019-03-23 14:43:38,890] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.72942583, 55.89645961, 1.0, 2.0, 0.2655181973067074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 288286.1468148122, 288286.1468148122, 81652.63539537661]
[2019-03-23 14:43:38,891] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:43:38,893] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.7504991e-10 1.0000000e+00 6.7626897e-34 1.2851492e-20 0.0000000e+00], sampled 0.49136109178350473
[2019-03-23 14:43:51,528] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5522312]
[2019-03-23 14:43:51,529] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.9, 83.0, 1.0, 2.0, 0.3355625544496391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 370989.0449966371, 370989.0449966371, 120345.0642752186]
[2019-03-23 14:43:51,530] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:43:51,533] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.4774294e-10 1.0000000e+00 1.5877665e-33 2.0584312e-20 0.0000000e+00], sampled 0.19050462585375938
[2019-03-23 14:43:58,086] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5522312]
[2019-03-23 14:43:58,088] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.57283594, 75.46544535833334, 1.0, 2.0, 0.492814223028007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 562236.4599321445, 562236.4599321441, 143920.2284846628]
[2019-03-23 14:43:58,090] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:43:58,094] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.2943438e-10 1.0000000e+00 2.6549428e-34 7.5630472e-21 0.0000000e+00], sampled 0.6904777873644116
[2019-03-23 14:44:51,503] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 14:44:51,518] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:44:51,546] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 14:44:51,600] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 14:44:51,605] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 14:44:52,620] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1875000, evaluation results [1875000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 14:44:55,358] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.2469409e-12 1.0000000e+00 1.6176962e-37 5.6218805e-21 0.0000000e+00], sum to 1.0000
[2019-03-23 14:44:55,364] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0673
[2019-03-23 14:44:55,367] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.46666666666667, 77.66666666666667, 1.0, 2.0, 0.456174829109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 495424.8787180755, 495424.8787180758, 123042.5151166682], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6769200.0000, 
sim time next is 6769800.0000, 
raw observation next is [18.85, 77.5, 1.0, 2.0, 0.5554300699682049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 606823.5824035944, 606823.5824035944, 133117.0875512947], 
processed observation next is [1.0, 0.34782608695652173, 0.4931818181818182, 0.775, 1.0, 1.0, 0.44428758746025604, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22474947496429423, 0.22474947496429423, 0.32467582329584077], 
reward next is 0.6753, 
noisyNet noise sample is [array([-0.08249555], dtype=float32), -0.6612589]. 
=============================================
[2019-03-23 14:45:07,146] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2650195e-09 1.0000000e+00 7.4453538e-32 5.8098886e-19 0.0000000e+00], sum to 1.0000
[2019-03-23 14:45:07,153] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0505
[2019-03-23 14:45:07,158] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 84.0, 1.0, 2.0, 0.4583006409946204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 522665.713603448, 522665.7136034477, 135158.6450254579], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6998400.0000, 
sim time next is 6999000.0000, 
raw observation next is [22.2, 84.0, 1.0, 2.0, 0.4570858388304922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 521259.9939512297, 521259.99395123, 134990.3161223205], 
processed observation next is [1.0, 0.0, 0.6454545454545454, 0.84, 1.0, 1.0, 0.32135729853811523, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19305925701897397, 0.19305925701897408, 0.32924467346907443], 
reward next is 0.6708, 
noisyNet noise sample is [array([0.17527494], dtype=float32), 0.33441493]. 
=============================================
[2019-03-23 14:45:07,179] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[65.57041 ]
 [65.65655 ]
 [65.666695]
 [65.67364 ]
 [65.67193 ]], R is [[65.8801651 ]
 [65.89170837]
 [65.90207672]
 [65.91125488]
 [65.91929626]].
[2019-03-23 14:45:07,298] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.7909929e-10 1.0000000e+00 4.6019872e-32 4.8335902e-20 0.0000000e+00], sum to 1.0000
[2019-03-23 14:45:07,304] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0362
[2019-03-23 14:45:07,309] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.28333333333333, 60.16666666666666, 1.0, 2.0, 0.5058371336576881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 576678.1402709187, 576678.1402709191, 143059.1254912481], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6976200.0000, 
sim time next is 6976800.0000, 
raw observation next is [27.2, 60.0, 1.0, 2.0, 0.5015247720981404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 571908.414673172, 571908.414673172, 142343.7308883737], 
processed observation next is [0.0, 0.782608695652174, 0.8727272727272727, 0.6, 1.0, 1.0, 0.37690596512267543, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2118179313604341, 0.2118179313604341, 0.3471798314350578], 
reward next is 0.6528, 
noisyNet noise sample is [array([-0.08863363], dtype=float32), -0.7051588]. 
=============================================
[2019-03-23 14:45:08,622] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2823858e-07 9.9999988e-01 9.5376988e-31 3.1146425e-18 2.2409336e-37], sum to 1.0000
[2019-03-23 14:45:08,630] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5612
[2019-03-23 14:45:08,634] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 77.0, 1.0, 2.0, 0.925489828347147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1052976.407619488, 1052976.407619488, 196910.4718812353], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7053600.0000, 
sim time next is 7054200.0000, 
raw observation next is [22.2, 77.5, 1.0, 2.0, 0.9903815943977108, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1127472.109704924, 1127472.109704924, 208723.3348018957], 
processed observation next is [1.0, 0.6521739130434783, 0.6454545454545454, 0.775, 1.0, 1.0, 0.9879769929971385, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.41758226285367556, 0.41758226285367556, 0.5090813043948675], 
reward next is 0.4909, 
noisyNet noise sample is [array([0.7008923], dtype=float32), -0.2226333]. 
=============================================
[2019-03-23 14:45:09,078] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.7499462e-09 1.0000000e+00 6.9721297e-31 1.1406881e-19 4.4027928e-37], sum to 1.0000
[2019-03-23 14:45:09,085] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0736
[2019-03-23 14:45:09,088] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.2, 94.33333333333334, 1.0, 2.0, 0.6760761142325337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 764717.1508635818, 764717.1508635822, 156242.5356159805], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7036800.0000, 
sim time next is 7037400.0000, 
raw observation next is [19.3, 93.66666666666666, 1.0, 2.0, 0.6740011012748051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 762500.2236949436, 762500.2236949436, 156051.7094431528], 
processed observation next is [1.0, 0.43478260869565216, 0.5136363636363637, 0.9366666666666665, 1.0, 1.0, 0.5925013765935063, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.28240749025738654, 0.28240749025738654, 0.3806139254711044], 
reward next is 0.6194, 
noisyNet noise sample is [array([-0.6942712], dtype=float32), 0.23610836]. 
=============================================
[2019-03-23 14:45:09,450] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5811275e-10 1.0000000e+00 4.5039797e-33 9.9660812e-21 0.0000000e+00], sum to 1.0000
[2019-03-23 14:45:09,459] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8644
[2019-03-23 14:45:09,462] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.7, 86.0, 1.0, 2.0, 0.6121130283769876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 694799.1237861754, 694799.1237861757, 149834.3640402386], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7042800.0000, 
sim time next is 7043400.0000, 
raw observation next is [20.8, 85.5, 1.0, 2.0, 0.5560429944559979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 631094.0348961471, 631094.0348961471, 143131.668557291], 
processed observation next is [1.0, 0.5217391304347826, 0.5818181818181819, 0.855, 1.0, 1.0, 0.44505374306999734, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23373853144301743, 0.23373853144301743, 0.349101630627539], 
reward next is 0.6509, 
noisyNet noise sample is [array([-0.5747089], dtype=float32), -0.4208341]. 
=============================================
[2019-03-23 14:45:13,868] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.7991844e-11 1.0000000e+00 1.5551145e-34 1.6276824e-20 0.0000000e+00], sum to 1.0000
[2019-03-23 14:45:13,874] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6264
[2019-03-23 14:45:13,877] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 59.0, 1.0, 2.0, 0.6694268942410804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 746415.2171722506, 746415.2171722506, 150329.0491811953], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7128000.0000, 
sim time next is 7128600.0000, 
raw observation next is [22.8, 58.33333333333334, 1.0, 2.0, 0.698633280166849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 778629.0334998135, 778629.0334998135, 153736.3662757708], 
processed observation next is [1.0, 0.5217391304347826, 0.6727272727272727, 0.5833333333333335, 1.0, 1.0, 0.6232916002085612, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.28838112351844947, 0.28838112351844947, 0.3749667470140751], 
reward next is 0.6250, 
noisyNet noise sample is [array([-1.5329193], dtype=float32), 0.6829668]. 
=============================================
[2019-03-23 14:45:27,928] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.0327872e-05 9.9995959e-01 2.8013816e-19 6.7511387e-08 6.1891195e-24], sum to 1.0000
[2019-03-23 14:45:27,937] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8755
[2019-03-23 14:45:27,945] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1714358.313808046 W.
[2019-03-23 14:45:27,950] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.56666666666667, 58.33333333333334, 1.0, 2.0, 0.7582673371796258, 1.0, 2.0, 0.7582673371796258, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1714358.313808046, 1714358.313808046, 308686.7765993096], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7404000.0000, 
sim time next is 7404600.0000, 
raw observation next is [27.38333333333333, 59.16666666666666, 1.0, 2.0, 0.519686694395819, 1.0, 2.0, 0.5029168372945232, 1.0, 1.0, 0.9829951291150081, 6.911199999999999, 6.9112, 77.3421103, 1702036.409489946, 1702036.409489946, 356335.8994838059], 
processed observation next is [1.0, 0.6956521739130435, 0.8810606060606059, 0.5916666666666666, 1.0, 1.0, 0.3996083679947738, 1.0, 1.0, 0.37864604661815393, 1.0, 0.5, 0.9757073273071544, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.6303838553666467, 0.6303838553666467, 0.8691119499605021], 
reward next is 0.1309, 
noisyNet noise sample is [array([1.2267218], dtype=float32), 0.46086568]. 
=============================================
[2019-03-23 14:45:30,493] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3907342e-08 1.0000000e+00 8.0457335e-34 8.3767183e-18 0.0000000e+00], sum to 1.0000
[2019-03-23 14:45:30,499] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3312
[2019-03-23 14:45:30,507] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666666, 90.0, 1.0, 2.0, 0.350327794479523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 390661.2741461231, 390661.2741461229, 118531.5248873601], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7458000.0000, 
sim time next is 7458600.0000, 
raw observation next is [19.03333333333333, 88.5, 1.0, 2.0, 0.3555883890692863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 397541.1448824763, 397541.144882476, 119404.2769759259], 
processed observation next is [0.0, 0.30434782608695654, 0.5015151515151515, 0.885, 1.0, 1.0, 0.19448548633660787, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1472374610675838, 0.1472374610675837, 0.2912299438437217], 
reward next is 0.7088, 
noisyNet noise sample is [array([1.2557284], dtype=float32), 0.8738591]. 
=============================================
[2019-03-23 14:45:31,404] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.3289247e-09 1.0000000e+00 2.4160015e-31 7.0070013e-17 0.0000000e+00], sum to 1.0000
[2019-03-23 14:45:31,412] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4454
[2019-03-23 14:45:31,418] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.68333333333333, 86.5, 1.0, 2.0, 0.3668735738326588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 412139.5827249974, 412139.5827249977, 121269.2615325897], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7459800.0000, 
sim time next is 7460400.0000, 
raw observation next is [19.96666666666667, 86.0, 1.0, 2.0, 0.3732557413888919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 420305.9020279915, 420305.9020279918, 122322.9167880176], 
processed observation next is [0.0, 0.34782608695652173, 0.5439393939393941, 0.86, 1.0, 1.0, 0.21656967673611485, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15566885260295982, 0.15566885260295993, 0.29834857753175026], 
reward next is 0.7017, 
noisyNet noise sample is [array([-0.4457373], dtype=float32), -0.25679672]. 
=============================================
[2019-03-23 14:45:38,841] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:45:38,842] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:45:38,897] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run10
[2019-03-23 14:45:40,348] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 14:45:40,349] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:45:40,350] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:45:40,351] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:45:40,351] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:45:40,351] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:45:40,353] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:45:40,356] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:45:40,357] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:45:40,357] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:45:40,356] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:45:40,378] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run77
[2019-03-23 14:45:40,403] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run77
[2019-03-23 14:45:40,426] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run77
[2019-03-23 14:45:40,456] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run77
[2019-03-23 14:45:40,457] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run77
[2019-03-23 14:45:57,004] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.55746794]
[2019-03-23 14:45:57,004] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.9, 79.0, 1.0, 2.0, 0.5675865876879428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 647451.4780634493, 647451.4780634489, 154288.6516549402]
[2019-03-23 14:45:57,008] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:45:57,010] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.9144029e-07 9.9999905e-01 2.4537511e-27 3.4790421e-14 2.1510955e-33], sampled 0.6496978462677295
[2019-03-23 14:45:59,252] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.55746794]
[2019-03-23 14:45:59,253] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.300851735, 93.106916825, 1.0, 2.0, 0.5475400515624651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 620971.5762469405, 620971.5762469402, 154506.0184352346]
[2019-03-23 14:45:59,254] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:45:59,258] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.3251783e-06 9.9999869e-01 3.1439201e-26 2.2935104e-13 4.3020052e-32], sampled 0.4675708224800067
[2019-03-23 14:46:08,619] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.55746794]
[2019-03-23 14:46:08,621] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 51.0, 1.0, 2.0, 0.2946424950750031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 319936.3134832993, 319936.313483299, 104125.6386624788]
[2019-03-23 14:46:08,623] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 14:46:08,626] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.2768959e-07 9.9999940e-01 8.1117304e-29 4.3695092e-15 3.4133434e-35], sampled 0.7099674670715034
[2019-03-23 14:46:20,349] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.55746794]
[2019-03-23 14:46:20,351] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.6516556, 88.23497865, 1.0, 2.0, 0.5690411000805586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 645988.0992714154, 645988.099271415, 157031.7953315971]
[2019-03-23 14:46:20,353] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:46:20,356] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.56267651e-07 9.99999404e-01 3.29674579e-29 2.49328298e-15
 1.14110476e-35], sampled 0.9935847306057728
[2019-03-23 14:46:40,731] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.55746794]
[2019-03-23 14:46:40,733] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.0, 79.0, 1.0, 2.0, 0.5955527806216283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 671388.1032955974, 671388.103295597, 162096.0384814012]
[2019-03-23 14:46:40,734] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:46:40,738] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.0426237e-07 9.9999940e-01 3.7407220e-29 2.6806634e-15 1.3197719e-35], sampled 0.16203502296278371
[2019-03-23 14:46:43,746] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.55746794]
[2019-03-23 14:46:43,747] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.38333333333333, 66.33333333333334, 1.0, 2.0, 0.3001377591639672, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 325884.4960349535, 325884.4960349535, 107025.5720072627]
[2019-03-23 14:46:43,747] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:46:43,749] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.6647027e-07 9.9999928e-01 1.3273955e-28 6.4427058e-15 6.0860095e-35], sampled 0.7574148529007478
[2019-03-23 14:46:52,535] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.55746794]
[2019-03-23 14:46:52,536] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.47114713666667, 54.64823845333333, 1.0, 2.0, 0.5025194754748922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 570212.2720088336, 570212.2720088336, 141431.4082014622]
[2019-03-23 14:46:52,536] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:46:52,540] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0763705e-06 9.9999893e-01 5.6347395e-27 6.1133546e-14 5.8398824e-33], sampled 0.6917522050432018
[2019-03-23 14:47:24,050] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.55746794]
[2019-03-23 14:47:24,050] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.13333333333333, 76.33333333333334, 1.0, 2.0, 0.3503118993063943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 389631.8861331873, 389631.8861331873, 122414.7737487017]
[2019-03-23 14:47:24,052] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:47:24,056] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.9241429e-07 9.9999928e-01 1.8484117e-28 8.1591762e-15 9.0380139e-35], sampled 0.12961249179149947
[2019-03-23 14:47:24,640] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:47:24,755] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8577.2172 1683039974.7239 210.0000
[2019-03-23 14:47:24,813] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8514.2800 1772601346.4094 173.0000
[2019-03-23 14:47:24,816] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 14:47:24,857] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 14:47:25,874] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1900000, evaluation results [1900000.0, 8514.279989204195, 1772601346.409439, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8577.217176693464, 1683039974.7239134, 210.0]
[2019-03-23 14:47:28,015] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.5356547e-06 9.9999642e-01 7.6673029e-22 4.2120968e-10 4.6098168e-28], sum to 1.0000
[2019-03-23 14:47:28,021] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8812
[2019-03-23 14:47:28,026] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 85.0, 1.0, 2.0, 0.4831802440676297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 551343.9350745789, 551343.9350745789, 139222.0039313154], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7675200.0000, 
sim time next is 7675800.0000, 
raw observation next is [22.51666666666667, 86.33333333333334, 1.0, 2.0, 0.4813994778442716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 549313.8203650479, 549313.8203650482, 138988.8128136347], 
processed observation next is [1.0, 0.8695652173913043, 0.659848484848485, 0.8633333333333334, 1.0, 1.0, 0.35174934730533947, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2034495630981659, 0.20344956309816603, 0.33899710442349923], 
reward next is 0.6610, 
noisyNet noise sample is [array([-0.7538669], dtype=float32), 0.49372166]. 
=============================================
[2019-03-23 14:47:28,792] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.1729794e-07 9.9999905e-01 4.4230093e-28 2.5887700e-14 2.4263122e-34], sum to 1.0000
[2019-03-23 14:47:28,800] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5761
[2019-03-23 14:47:28,806] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.73333333333333, 72.66666666666667, 1.0, 2.0, 0.48286388914144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 550896.6879830888, 550896.6879830885, 139601.0407955951], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7670400.0000, 
sim time next is 7671000.0000, 
raw observation next is [24.26666666666667, 75.83333333333334, 1.0, 2.0, 0.4839636636941364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 552133.794766323, 552133.794766323, 139780.9918335656], 
processed observation next is [1.0, 0.782608695652174, 0.7393939393939395, 0.7583333333333334, 1.0, 1.0, 0.35495457961767046, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2044939980616011, 0.2044939980616011, 0.3409292483745503], 
reward next is 0.6591, 
noisyNet noise sample is [array([0.853316], dtype=float32), 0.7550483]. 
=============================================
[2019-03-23 14:47:28,827] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[61.43297 ]
 [61.486176]
 [61.613403]
 [61.797714]
 [61.6898  ]], R is [[61.58012009]
 [61.6238327 ]
 [61.66732025]
 [61.71081161]
 [61.75536346]].
[2019-03-23 14:47:31,177] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1695597e-08 1.0000000e+00 4.0108023e-32 1.8838092e-17 3.3281326e-38], sum to 1.0000
[2019-03-23 14:47:31,186] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5321
[2019-03-23 14:47:31,189] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.86666666666667, 51.83333333333334, 1.0, 2.0, 0.60908387766838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 661603.5022976216, 661603.5022976216, 128103.5519918539], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7750200.0000, 
sim time next is 7750800.0000, 
raw observation next is [20.5, 53.0, 1.0, 2.0, 0.6266222819429391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 680667.5367918202, 680667.5367918202, 128961.2996072231], 
processed observation next is [1.0, 0.7391304347826086, 0.5681818181818182, 0.53, 1.0, 1.0, 0.5332778524286739, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25209908770067413, 0.25209908770067413, 0.31453975513956856], 
reward next is 0.6855, 
noisyNet noise sample is [array([0.91222477], dtype=float32), -1.2451257]. 
=============================================
[2019-03-23 14:47:32,731] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.1534682e-09 1.0000000e+00 7.5151994e-34 2.7981776e-16 0.0000000e+00], sum to 1.0000
[2019-03-23 14:47:32,742] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2069
[2019-03-23 14:47:32,746] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.85, 87.0, 1.0, 2.0, 0.2044377948394141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221965.5682086248, 221965.5682086245, 72969.25750119155], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7792200.0000, 
sim time next is 7792800.0000, 
raw observation next is [13.66666666666667, 89.0, 1.0, 2.0, 0.2000303708882461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 217179.1990082877, 217179.1990082877, 72552.76581231972], 
processed observation next is [1.0, 0.17391304347826086, 0.25757575757575774, 0.89, 1.0, 1.0, 3.796361030761197e-05, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08043674037343988, 0.08043674037343988, 0.17695796539590175], 
reward next is 0.8230, 
noisyNet noise sample is [array([0.32277188], dtype=float32), 1.5165192]. 
=============================================
[2019-03-23 14:47:33,556] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.2350761e-08 1.0000000e+00 1.3210288e-32 1.4718208e-17 0.0000000e+00], sum to 1.0000
[2019-03-23 14:47:33,565] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9509
[2019-03-23 14:47:33,569] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.85, 94.5, 1.0, 2.0, 0.2107672027969843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 228839.2537800013, 228839.2537800013, 75827.8236372432], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7799400.0000, 
sim time next is 7800000.0000, 
raw observation next is [14.03333333333333, 94.0, 1.0, 2.0, 0.2143113220488628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 232688.1808912402, 232688.1808912399, 76721.60341894062], 
processed observation next is [1.0, 0.2608695652173913, 0.27424242424242407, 0.94, 1.0, 1.0, 0.017889152561078488, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08618080773749637, 0.08618080773749626, 0.18712586199741615], 
reward next is 0.8129, 
noisyNet noise sample is [array([-0.32733607], dtype=float32), 0.95823]. 
=============================================
[2019-03-23 14:47:33,588] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[70.402855]
 [70.46182 ]
 [70.505005]
 [70.54171 ]
 [70.52403 ]], R is [[70.4593277 ]
 [70.5697937 ]
 [70.68119049]
 [70.79276276]
 [70.90492249]].
[2019-03-23 14:47:34,527] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1665655e-08 1.0000000e+00 5.8346975e-34 1.2797167e-16 0.0000000e+00], sum to 1.0000
[2019-03-23 14:47:34,534] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0814
[2019-03-23 14:47:34,540] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.73333333333333, 78.0, 1.0, 2.0, 0.2581353653524849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 280283.7771472135, 280283.7771472135, 86620.47034872555], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7804200.0000, 
sim time next is 7804800.0000, 
raw observation next is [17.2, 75.0, 1.0, 2.0, 0.2772305623653217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 301023.7881197027, 301023.7881197027, 89284.79496065024], 
processed observation next is [1.0, 0.34782608695652173, 0.41818181818181815, 0.75, 1.0, 1.0, 0.09653820295665208, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11149029189618619, 0.11149029189618619, 0.2177677925869518], 
reward next is 0.7822, 
noisyNet noise sample is [array([-1.517135], dtype=float32), -0.1266043]. 
=============================================
[2019-03-23 14:47:39,155] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1657279e-05 1.3232010e-03 9.1470640e-20 9.9866509e-01 2.3401618e-28], sum to 1.0000
[2019-03-23 14:47:39,162] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9725
[2019-03-23 14:47:39,167] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.8, 93.0, 1.0, 2.0, 0.85570259865617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 975969.569644999, 975969.5696449992, 188306.8384008958], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7911000.0000, 
sim time next is 7911600.0000, 
raw observation next is [20.9, 93.0, 1.0, 2.0, 0.4368505897189047, 1.0, 1.0, 0.4368505897189047, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 997348.673033981, 997348.673033981, 212348.1838974977], 
processed observation next is [1.0, 0.5652173913043478, 0.5863636363636363, 0.93, 1.0, 1.0, 0.29606323714863086, 1.0, 0.5, 0.29606323714863086, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.36938839741999296, 0.36938839741999296, 0.5179223997499944], 
reward next is 0.4821, 
noisyNet noise sample is [array([0.83223337], dtype=float32), -1.8425183]. 
=============================================
[2019-03-23 14:47:40,509] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:47:40,509] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:47:40,526] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run10
[2019-03-23 14:47:40,781] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:47:40,781] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:47:40,836] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run10
[2019-03-23 14:47:41,390] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:47:41,390] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:47:41,403] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run10
[2019-03-23 14:47:41,668] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.235754e-08 1.000000e+00 2.424152e-32 5.544049e-18 0.000000e+00], sum to 1.0000
[2019-03-23 14:47:41,668] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5846
[2019-03-23 14:47:41,669] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.5, 71.5, 1.0, 2.0, 0.4041894618642209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 438941.1156739252, 438941.1156739252, 87395.81485484118], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 354600.0000, 
sim time next is 355200.0000, 
raw observation next is [12.33333333333333, 73.0, 1.0, 2.0, 0.4013425615439996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 435848.0570052839, 435848.0570052839, 87132.82908379873], 
processed observation next is [1.0, 0.08695652173913043, 0.19696969696969682, 0.73, 1.0, 1.0, 0.25167820192999946, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1614252062982533, 0.1614252062982533, 0.21251909532633836], 
reward next is 0.7875, 
noisyNet noise sample is [array([1.948954], dtype=float32), 2.1786106]. 
=============================================
[2019-03-23 14:47:41,862] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:47:41,863] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:47:41,872] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run10
[2019-03-23 14:47:41,908] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:47:41,908] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:47:41,912] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run10
[2019-03-23 14:47:41,941] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:47:41,942] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:47:41,941] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:47:41,949] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:47:41,962] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run10
[2019-03-23 14:47:41,992] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:47:41,993] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:47:41,998] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run10
[2019-03-23 14:47:42,041] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run10
[2019-03-23 14:47:42,277] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:47:42,277] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:47:42,281] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:47:42,281] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:47:42,284] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run10
[2019-03-23 14:47:42,322] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run10
[2019-03-23 14:47:42,347] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:47:42,347] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:47:42,353] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run10
[2019-03-23 14:47:42,384] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:47:42,385] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:47:42,393] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run10
[2019-03-23 14:47:42,444] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:47:42,445] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:47:42,466] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run10
[2019-03-23 14:47:42,592] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:47:42,592] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:47:42,595] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run10
[2019-03-23 14:47:42,717] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 14:47:42,717] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:47:42,720] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run10
[2019-03-23 14:47:47,632] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.6918665e-08 1.0000000e+00 1.8986368e-30 2.8982895e-16 5.3006440e-36], sum to 1.0000
[2019-03-23 14:47:47,642] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1180
[2019-03-23 14:47:47,645] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333333, 76.33333333333334, 1.0, 2.0, 0.372458056382274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 415522.8144128206, 415522.8144128209, 120406.2365531623], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 70800.0000, 
sim time next is 71400.0000, 
raw observation next is [20.16666666666667, 77.16666666666666, 1.0, 2.0, 0.3691359056397902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 411521.8029498086, 411521.8029498089, 120005.1479743306], 
processed observation next is [1.0, 0.8260869565217391, 0.5530303030303032, 0.7716666666666666, 1.0, 1.0, 0.21141988204973775, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1524154825740032, 0.15241548257400328, 0.292695482864221], 
reward next is 0.7073, 
noisyNet noise sample is [array([-0.548787], dtype=float32), 0.5218683]. 
=============================================
[2019-03-23 14:47:47,914] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.2569498e-09 1.0000000e+00 2.0283419e-29 2.4814972e-17 3.2126707e-38], sum to 1.0000
[2019-03-23 14:47:47,920] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5528
[2019-03-23 14:47:47,925] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 77.0, 1.0, 2.0, 0.2327953857835236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 252762.4387278546, 252762.4387278543, 79224.48953072705], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 85200.0000, 
sim time next is 85800.0000, 
raw observation next is [16.0, 77.0, 1.0, 2.0, 0.2303966827873546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 250157.3272193348, 250157.3272193345, 78974.96913533095], 
processed observation next is [1.0, 1.0, 0.36363636363636365, 0.77, 1.0, 1.0, 0.03799585348419322, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09265086193308697, 0.09265086193308684, 0.19262187593983157], 
reward next is 0.8074, 
noisyNet noise sample is [array([0.13049842], dtype=float32), 1.2078925]. 
=============================================
[2019-03-23 14:47:59,253] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6838022e-09 1.0000000e+00 2.1145969e-28 5.5716133e-17 1.3367931e-34], sum to 1.0000
[2019-03-23 14:47:59,262] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1604
[2019-03-23 14:47:59,265] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 41.66666666666667, 1.0, 2.0, 0.2735728022063413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 297050.8888861133, 297050.8888861136, 88080.07464487173], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 318000.0000, 
sim time next is 318600.0000, 
raw observation next is [22.0, 42.0, 1.0, 2.0, 0.2703495142596522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 293549.9212836099, 293549.9212836102, 86313.06777299978], 
processed observation next is [0.0, 0.6956521739130435, 0.6363636363636364, 0.42, 1.0, 1.0, 0.08793689282456524, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10872219306800365, 0.10872219306800379, 0.21051967749512143], 
reward next is 0.7895, 
noisyNet noise sample is [array([1.9352624], dtype=float32), -1.2254729]. 
=============================================
[2019-03-23 14:48:06,005] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8894495e-08 1.0000000e+00 1.8393076e-32 1.6287942e-20 0.0000000e+00], sum to 1.0000
[2019-03-23 14:48:06,014] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6713
[2019-03-23 14:48:06,024] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.5340306161252266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 580029.9563577559, 580029.9563577559, 109523.6740018485], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 448800.0000, 
sim time next is 449400.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.5336683248131092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 579636.2240344074, 579636.2240344074, 109458.208737486], 
processed observation next is [1.0, 0.17391304347826086, 0.22727272727272727, 1.0, 1.0, 1.0, 0.4170854060163865, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21468008297570645, 0.21468008297570645, 0.26697124082313656], 
reward next is 0.7330, 
noisyNet noise sample is [array([-0.0644933], dtype=float32), 1.78865]. 
=============================================
[2019-03-23 14:48:12,005] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.9704456e-08 9.9999988e-01 4.0760498e-30 8.4341767e-18 1.2950995e-36], sum to 1.0000
[2019-03-23 14:48:12,014] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4851
[2019-03-23 14:48:12,019] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 71.66666666666667, 1.0, 2.0, 0.4219672453892512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 461386.3418357777, 461386.3418357777, 121211.7907193146], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 562800.0000, 
sim time next is 563400.0000, 
raw observation next is [20.0, 71.0, 1.0, 2.0, 0.3913967805958204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 429442.5139075505, 429442.5139075505, 119247.0815695932], 
processed observation next is [1.0, 0.5217391304347826, 0.5454545454545454, 0.71, 1.0, 1.0, 0.23924597574477546, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1590527829287224, 0.1590527829287224, 0.29084654041364194], 
reward next is 0.7092, 
noisyNet noise sample is [array([-2.080919], dtype=float32), -1.8662993]. 
=============================================
[2019-03-23 14:48:15,239] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 14:48:15,243] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:48:15,244] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:48:15,246] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:48:15,247] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:48:15,248] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:48:15,249] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:48:15,250] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:48:15,250] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:48:15,251] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:48:15,254] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:48:15,273] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run78
[2019-03-23 14:48:15,300] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run78
[2019-03-23 14:48:15,323] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run78
[2019-03-23 14:48:15,324] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run78
[2019-03-23 14:48:15,325] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run78
[2019-03-23 14:48:23,716] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5641553]
[2019-03-23 14:48:23,718] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.11782904, 60.50693771, 1.0, 2.0, 0.3213086272179089, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 348878.1381952749, 348878.1381952749, 108107.3199407079]
[2019-03-23 14:48:23,720] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:48:23,723] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.0775208e-09 1.0000000e+00 2.7985696e-33 7.5152853e-19 0.0000000e+00], sampled 0.4278824448466425
[2019-03-23 14:49:20,109] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5641553]
[2019-03-23 14:49:20,109] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.10530163833333, 98.56651956166667, 1.0, 2.0, 0.4820351425174208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 549036.7853872775, 549036.7853872771, 141079.5767886441]
[2019-03-23 14:49:20,109] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:49:20,112] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.2057653e-08 1.0000000e+00 2.0298482e-32 2.2665324e-18 0.0000000e+00], sampled 0.7421937500267023
[2019-03-23 14:49:22,266] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5641553]
[2019-03-23 14:49:22,267] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.67064052666667, 89.01583806000001, 1.0, 2.0, 0.2961454499086377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 321548.5546381483, 321548.5546381483, 109383.3270541454]
[2019-03-23 14:49:22,269] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:49:22,275] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.1706695e-09 1.0000000e+00 3.7476582e-33 8.7466647e-19 0.0000000e+00], sampled 0.2388587368455216
[2019-03-23 14:49:27,338] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5641553]
[2019-03-23 14:49:27,341] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [30.052988965, 45.06307735, 1.0, 2.0, 0.489080598214394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 558022.3548081651, 558022.3548081648, 144167.2801336296]
[2019-03-23 14:49:27,342] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:49:27,344] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.8590723e-09 1.0000000e+00 2.6746344e-33 7.4248973e-19 0.0000000e+00], sampled 0.5342951994557043
[2019-03-23 14:49:31,627] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5641553]
[2019-03-23 14:49:31,628] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.03333333333333, 78.33333333333334, 1.0, 2.0, 0.2933293853302912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 318490.1202620608, 318490.1202620605, 97629.76907969269]
[2019-03-23 14:49:31,630] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 14:49:31,633] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.3274023e-08 1.0000000e+00 8.5573979e-32 5.8326308e-18 1.8858815e-38], sampled 0.7737397693598553
[2019-03-23 14:49:39,110] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5641553]
[2019-03-23 14:49:39,112] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.86666666666667, 86.5, 1.0, 2.0, 0.3733835809554906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 420304.6019398497, 420304.6019398493, 126581.753651898]
[2019-03-23 14:49:39,113] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:49:39,115] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0184440e-08 1.0000000e+00 9.2974352e-33 1.4570776e-18 0.0000000e+00], sampled 0.8000882235998701
[2019-03-23 14:49:59,050] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5641553]
[2019-03-23 14:49:59,050] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.83333333333334, 71.33333333333334, 1.0, 2.0, 0.409762875396027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 461037.0197004621, 461037.0197004617, 129692.7394434768]
[2019-03-23 14:49:59,051] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:49:59,055] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0205557e-08 1.0000000e+00 9.6665492e-33 1.4942738e-18 0.0000000e+00], sampled 0.24167864191697896
[2019-03-23 14:49:59,152] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 14:49:59,404] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:49:59,427] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 14:49:59,457] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 14:49:59,463] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 14:50:00,481] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1925000, evaluation results [1925000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 14:50:01,196] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.0847374e-08 1.0000000e+00 7.6600408e-32 3.4367493e-18 0.0000000e+00], sum to 1.0000
[2019-03-23 14:50:01,206] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4404
[2019-03-23 14:50:01,212] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 94.0, 1.0, 2.0, 0.2463359124497418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 267468.3900953325, 267468.3900953328, 85665.96454172868], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 626400.0000, 
sim time next is 627000.0000, 
raw observation next is [15.16666666666667, 94.00000000000001, 1.0, 2.0, 0.2918855966244081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 316941.7714028768, 316941.7714028765, 91728.86128781989], 
processed observation next is [1.0, 0.2608695652173913, 0.3257575757575759, 0.9400000000000002, 1.0, 1.0, 0.11485699578051012, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11738584126032475, 0.11738584126032461, 0.22372892997029242], 
reward next is 0.7763, 
noisyNet noise sample is [array([-0.05651773], dtype=float32), 1.122055]. 
=============================================
[2019-03-23 14:50:01,234] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[71.411156]
 [71.440285]
 [71.47709 ]
 [71.481094]
 [71.490036]], R is [[71.35110474]
 [71.42865753]
 [71.50709534]
 [71.58639526]
 [71.6660614 ]].
[2019-03-23 14:50:01,725] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.0397854e-08 1.0000000e+00 2.4815635e-32 3.0892509e-17 0.0000000e+00], sum to 1.0000
[2019-03-23 14:50:01,734] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8079
[2019-03-23 14:50:01,739] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 57.0, 1.0, 2.0, 0.5759132811528127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 644483.5273992941, 644483.5273992941, 140647.6189799323], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 646200.0000, 
sim time next is 646800.0000, 
raw observation next is [23.66666666666667, 57.0, 1.0, 2.0, 0.6642506108662153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 744868.7339409532, 744868.7339409534, 151489.3091425096], 
processed observation next is [1.0, 0.4782608695652174, 0.7121212121212124, 0.57, 1.0, 1.0, 0.580313263582769, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.27587730886701967, 0.2758773088670198, 0.36948611985977947], 
reward next is 0.6305, 
noisyNet noise sample is [array([0.6904678], dtype=float32), -0.41873395]. 
=============================================
[2019-03-23 14:50:08,617] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.3003549e-09 1.0000000e+00 1.3140741e-30 2.7911266e-19 1.7550224e-36], sum to 1.0000
[2019-03-23 14:50:08,626] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9174
[2019-03-23 14:50:08,630] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 58.0, 1.0, 2.0, 0.4739861515087928, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 540854.3870567742, 540854.387056774, 138093.0696867444], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 757800.0000, 
sim time next is 758400.0000, 
raw observation next is [27.0, 58.0, 1.0, 2.0, 0.4724448293292485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 539094.7020128143, 539094.7020128143, 137920.5723339822], 
processed observation next is [1.0, 0.782608695652174, 0.8636363636363636, 0.58, 1.0, 1.0, 0.34055603666156053, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1996647044491905, 0.1996647044491905, 0.336391639838981], 
reward next is 0.6636, 
noisyNet noise sample is [array([0.20388137], dtype=float32), 0.15658246]. 
=============================================
[2019-03-23 14:50:09,252] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.332503e-08 1.000000e+00 7.307478e-32 8.324032e-18 3.628094e-38], sum to 1.0000
[2019-03-23 14:50:09,259] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3359
[2019-03-23 14:50:09,267] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.5, 56.5, 1.0, 2.0, 0.5262265342406446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 598977.2748829927, 598977.2748829927, 146386.5614491903], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 840600.0000, 
sim time next is 841200.0000, 
raw observation next is [28.33333333333333, 57.0, 1.0, 2.0, 0.5252185537093352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 597977.3431802014, 597977.3431802011, 146154.1260022804], 
processed observation next is [0.0, 0.7391304347826086, 0.924242424242424, 0.57, 1.0, 1.0, 0.406523192136669, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22147309006674123, 0.22147309006674115, 0.35647347805434243], 
reward next is 0.6435, 
noisyNet noise sample is [array([-1.5084922], dtype=float32), -0.67230934]. 
=============================================
[2019-03-23 14:50:12,820] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.2986490e-09 1.0000000e+00 1.2068642e-32 1.9447201e-17 0.0000000e+00], sum to 1.0000
[2019-03-23 14:50:12,828] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1892
[2019-03-23 14:50:12,831] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.16666666666667, 93.00000000000001, 1.0, 2.0, 0.3964403217125555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 446931.3163672245, 446931.3163672248, 124632.4948233106], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 868200.0000, 
sim time next is 868800.0000, 
raw observation next is [19.33333333333334, 92.0, 1.0, 2.0, 0.3971128665826482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 447894.8352455394, 447894.8352455397, 124804.7856132969], 
processed observation next is [0.0, 0.043478260869565216, 0.5151515151515155, 0.92, 1.0, 1.0, 0.24639108322831024, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16588697601686644, 0.16588697601686656, 0.30440191612999246], 
reward next is 0.6956, 
noisyNet noise sample is [array([0.81441563], dtype=float32), 1.0853629]. 
=============================================
[2019-03-23 14:50:13,547] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.2989446e-09 1.0000000e+00 5.6358680e-33 1.8136322e-18 0.0000000e+00], sum to 1.0000
[2019-03-23 14:50:13,556] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6956
[2019-03-23 14:50:13,560] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.3963890669487806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 446692.9677462039, 446692.9677462039, 124530.7606700649], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 876600.0000, 
sim time next is 877200.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.395185964415756, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 445334.6024915735, 445334.6024915735, 124421.6813234262], 
processed observation next is [0.0, 0.13043478260869565, 0.5, 0.94, 1.0, 1.0, 0.24398245551969497, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16493874166354575, 0.16493874166354575, 0.3034675154229907], 
reward next is 0.6965, 
noisyNet noise sample is [array([-1.0898982], dtype=float32), 0.62724555]. 
=============================================
[2019-03-23 14:50:21,604] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.9612064e-10 1.0000000e+00 3.5383793e-36 9.0343822e-24 0.0000000e+00], sum to 1.0000
[2019-03-23 14:50:21,613] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2355
[2019-03-23 14:50:21,623] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 95.0, 1.0, 2.0, 0.2538127178594478, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 275588.9100510245, 275588.9100510248, 77222.12043549075], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1044600.0000, 
sim time next is 1045200.0000, 
raw observation next is [13.0, 96.0, 1.0, 2.0, 0.2331403962920159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 253137.1385556061, 253137.1385556058, 76114.36011376113], 
processed observation next is [1.0, 0.08695652173913043, 0.22727272727272727, 0.96, 1.0, 1.0, 0.041425495365019875, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0937544957613356, 0.09375449576133549, 0.18564478076527105], 
reward next is 0.8144, 
noisyNet noise sample is [array([-1.0544596], dtype=float32), 1.062099]. 
=============================================
[2019-03-23 14:50:24,807] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.8804591e-09 1.0000000e+00 7.1328110e-32 5.0408686e-19 1.4205978e-38], sum to 1.0000
[2019-03-23 14:50:24,814] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7515
[2019-03-23 14:50:24,817] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 65.66666666666667, 1.0, 2.0, 0.7826781492953276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 883919.1456624361, 883919.1456624361, 169920.2923560732], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1093800.0000, 
sim time next is 1094400.0000, 
raw observation next is [23.0, 65.0, 1.0, 2.0, 0.8261371109417002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 933628.8245033798, 933628.8245033798, 176553.068293637], 
processed observation next is [1.0, 0.6956521739130435, 0.6818181818181818, 0.65, 1.0, 1.0, 0.7826713886771253, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3457884535197703, 0.3457884535197703, 0.4306172397405781], 
reward next is 0.5694, 
noisyNet noise sample is [array([2.0382845], dtype=float32), 1.256462]. 
=============================================
[2019-03-23 14:50:28,603] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.9598447e-07 9.9999952e-01 2.7560418e-26 1.0050352e-13 1.5663456e-30], sum to 1.0000
[2019-03-23 14:50:28,608] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8730
[2019-03-23 14:50:28,615] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1385244.736713717 W.
[2019-03-23 14:50:28,621] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 64.66666666666667, 1.0, 2.0, 0.6142163558425933, 1.0, 2.0, 0.6142163558425933, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1385244.736713717, 1385244.736713717, 265162.4454605585], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1174800.0000, 
sim time next is 1175400.0000, 
raw observation next is [27.0, 64.0, 1.0, 2.0, 0.7560684914154671, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9783650524370121, 6.911199999999999, 6.9112, 77.32846344354104, 1406515.19249536, 1406515.19249536, 301879.5044489207], 
processed observation next is [1.0, 0.6086956521739131, 0.8636363636363636, 0.64, 1.0, 1.0, 0.6950856142693337, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9690929320528746, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5209315527760593, 0.5209315527760593, 0.7362914742656603], 
reward next is 0.2637, 
noisyNet noise sample is [array([-0.48852047], dtype=float32), 2.1316872]. 
=============================================
[2019-03-23 14:50:36,736] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.9261350e-06 9.9999702e-01 1.7117141e-23 3.0725357e-13 1.9376614e-28], sum to 1.0000
[2019-03-23 14:50:36,744] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8507
[2019-03-23 14:50:36,753] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1219234.468101748 W.
[2019-03-23 14:50:36,759] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 70.66666666666667, 1.0, 2.0, 0.3614722506538572, 1.0, 2.0, 0.3614722506538572, 1.0, 2.0, 0.7313955177736433, 6.9112, 6.9112, 77.3421103, 1219234.468101748, 1219234.468101748, 289634.379948592], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1342200.0000, 
sim time next is 1342800.0000, 
raw observation next is [27.0, 70.0, 1.0, 2.0, 0.3707117548172484, 1.0, 2.0, 0.3707117548172484, 1.0, 2.0, 0.7500905404740896, 6.9112, 6.9112, 77.3421103, 1250433.417302822, 1250433.417302822, 293736.4292188347], 
processed observation next is [1.0, 0.5652173913043478, 0.8636363636363636, 0.7, 1.0, 1.0, 0.21338969352156045, 1.0, 1.0, 0.21338969352156045, 1.0, 1.0, 0.6429864863915566, 0.0, 0.0, 0.5085185399722538, 0.46312348788993407, 0.46312348788993407, 0.7164303151678895], 
reward next is 0.2836, 
noisyNet noise sample is [array([1.2572768], dtype=float32), 1.4535462]. 
=============================================
[2019-03-23 14:50:39,490] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.7717975e-08 1.0000000e+00 1.6091707e-31 1.3911943e-14 1.6111067e-37], sum to 1.0000
[2019-03-23 14:50:39,501] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6974
[2019-03-23 14:50:39,506] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4904998196512128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 559636.6765078908, 559636.676507891, 140394.2229382677], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1393200.0000, 
sim time next is 1393800.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4904671842698733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 559599.3683662912, 559599.3683662912, 140390.6703692838], 
processed observation next is [0.0, 0.13043478260869565, 0.5909090909090909, 1.0, 1.0, 1.0, 0.36308398033734157, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20725902532084858, 0.20725902532084858, 0.3424162691933751], 
reward next is 0.6576, 
noisyNet noise sample is [array([-0.51904947], dtype=float32), -0.52302694]. 
=============================================
[2019-03-23 14:50:40,780] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.8131501e-08 1.0000000e+00 5.2512711e-30 1.0813022e-13 1.1770624e-36], sum to 1.0000
[2019-03-23 14:50:40,788] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4740
[2019-03-23 14:50:40,795] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5114720839529375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 582690.4966788742, 582690.4966788742, 144172.3581190252], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1417200.0000, 
sim time next is 1417800.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5115193232845151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 582744.4913011721, 582744.4913011721, 144177.8941357236], 
processed observation next is [0.0, 0.391304347826087, 0.6818181818181818, 0.89, 1.0, 1.0, 0.38939915410564385, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21583129307450818, 0.21583129307450818, 0.35165340033103315], 
reward next is 0.6483, 
noisyNet noise sample is [array([0.02868692], dtype=float32), 0.6946661]. 
=============================================
[2019-03-23 14:50:41,188] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.6970958e-07 9.9999940e-01 2.0787309e-30 7.0274787e-16 1.2198939e-38], sum to 1.0000
[2019-03-23 14:50:41,197] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3848
[2019-03-23 14:50:41,203] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 74.66666666666667, 1.0, 2.0, 0.5274763950287916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 599440.0667354396, 599440.0667354398, 147123.7525924505], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1428600.0000, 
sim time next is 1429200.0000, 
raw observation next is [26.0, 74.0, 1.0, 2.0, 0.5364881004872948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 608870.921375908, 608870.921375908, 148638.3654891978], 
processed observation next is [0.0, 0.5652173913043478, 0.8181818181818182, 0.74, 1.0, 1.0, 0.4206101256091184, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2255077486577437, 0.2255077486577437, 0.362532598754141], 
reward next is 0.6375, 
noisyNet noise sample is [array([-1.541904], dtype=float32), 0.82141966]. 
=============================================
[2019-03-23 14:50:44,708] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.1447296e-08 9.9999988e-01 2.8801918e-31 6.3088147e-18 5.5002394e-38], sum to 1.0000
[2019-03-23 14:50:44,716] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5793
[2019-03-23 14:50:44,725] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.4504728830951305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 513477.1154204404, 513477.1154204407, 133885.5646368802], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1468800.0000, 
sim time next is 1469400.0000, 
raw observation next is [20.16666666666667, 100.0, 1.0, 2.0, 0.4501004929558588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 513168.4674223774, 513168.4674223774, 134030.9221878916], 
processed observation next is [0.0, 0.0, 0.5530303030303032, 1.0, 1.0, 1.0, 0.3126256161948235, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19006239534162125, 0.19006239534162125, 0.3269046882631503], 
reward next is 0.6731, 
noisyNet noise sample is [array([1.846593], dtype=float32), 1.3070624]. 
=============================================
[2019-03-23 14:50:48,472] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 14:50:48,475] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:50:48,476] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:50:48,476] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:50:48,478] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:50:48,477] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:50:48,479] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:50:48,481] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:50:48,482] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:50:48,481] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:50:48,486] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:50:48,501] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run79
[2019-03-23 14:50:48,527] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run79
[2019-03-23 14:50:48,552] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run79
[2019-03-23 14:50:48,576] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run79
[2019-03-23 14:50:48,596] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run79
[2019-03-23 14:51:08,441] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5633452]
[2019-03-23 14:51:08,441] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.43862896166667, 100.0, 1.0, 2.0, 0.5019862736376858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 572263.2379963468, 572263.2379963464, 146857.093787612]
[2019-03-23 14:51:08,444] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:51:08,447] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.0685356e-07 9.9999964e-01 3.5773990e-28 3.2232151e-15 1.7030141e-34], sampled 0.017459314069927512
[2019-03-23 14:52:32,789] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 14:52:32,825] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:52:32,909] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 14:52:33,030] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 14:52:33,050] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 14:52:34,064] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1950000, evaluation results [1950000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 14:52:42,481] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.5976667e-02 9.6966916e-01 1.3492704e-11 4.3541621e-03 3.1043130e-16], sum to 1.0000
[2019-03-23 14:52:42,495] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0682
[2019-03-23 14:52:42,499] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.5, 71.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 200979.3424372083, 200979.3424372086, 65540.12873585602], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1719000.0000, 
sim time next is 1719600.0000, 
raw observation next is [12.33333333333333, 73.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 198420.5025653548, 198420.5025653548, 65124.38499313661], 
processed observation next is [1.0, 0.9130434782608695, 0.19696969696969682, 0.73, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07348907502420549, 0.07348907502420549, 0.1588399633978942], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.2507261], dtype=float32), 2.1967201]. 
=============================================
[2019-03-23 14:52:46,407] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1636396e-04 6.8048583e-05 1.5466641e-08 9.9981564e-01 2.8903629e-13], sum to 1.0000
[2019-03-23 14:52:46,418] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1009
[2019-03-23 14:52:46,421] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.06666666666667, 44.66666666666666, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 288755.524593901, 288755.524593901, 105261.9144642594], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1791600.0000, 
sim time next is 1792200.0000, 
raw observation next is [19.03333333333333, 45.33333333333334, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 285100.1714324016, 285100.1714324016, 104869.9569570237], 
processed observation next is [1.0, 0.7391304347826086, 0.5015151515151515, 0.4533333333333334, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10559265608607465, 0.10559265608607465, 0.25578038282200904], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.56670284], dtype=float32), -0.6814906]. 
=============================================
[2019-03-23 14:52:46,854] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.2114419e-03 1.4577538e-04 7.7034798e-05 9.9356538e-01 3.8613331e-07], sum to 1.0000
[2019-03-23 14:52:46,863] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6160
[2019-03-23 14:52:46,868] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [17.0, 52.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 248686.504776765, 248686.5047767647, 97480.64022065452], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1800600.0000, 
sim time next is 1801200.0000, 
raw observation next is [17.0, 52.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 247881.6879957156, 247881.6879957153, 97355.04847751482], 
processed observation next is [1.0, 0.8695652173913043, 0.4090909090909091, 0.52, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09180803259100577, 0.09180803259100567, 0.23745133775003616], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.37195522], dtype=float32), 0.13623373]. 
=============================================
[2019-03-23 14:52:48,374] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.8699988e-03 9.9313003e-01 4.3953003e-17 4.0674887e-08 2.7434389e-22], sum to 1.0000
[2019-03-23 14:52:48,378] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6185
[2019-03-23 14:52:48,388] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [10.5, 100.0, 1.0, 2.0, 0.3406353537548021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 369896.4597298147, 369896.459729815, 82214.55982577291], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1834200.0000, 
sim time next is 1834800.0000, 
raw observation next is [10.66666666666667, 100.0, 1.0, 2.0, 0.3036693198383476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 329741.3762468422, 329741.3762468425, 79154.4375450861], 
processed observation next is [1.0, 0.21739130434782608, 0.12121212121212134, 1.0, 1.0, 1.0, 0.1295866497979345, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1221264356469786, 0.1221264356469787, 0.19305960376850267], 
reward next is 0.8069, 
noisyNet noise sample is [array([0.51131845], dtype=float32), 1.4743207]. 
=============================================
[2019-03-23 14:52:50,742] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1956474e-08 1.0000000e+00 9.2011040e-35 2.2786356e-17 0.0000000e+00], sum to 1.0000
[2019-03-23 14:52:50,745] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9255
[2019-03-23 14:52:50,748] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 45.0, 1.0, 2.0, 0.3214019397886859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 349003.3706376296, 349003.3706376294, 105435.8646599395], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1876800.0000, 
sim time next is 1877400.0000, 
raw observation next is [23.0, 45.5, 1.0, 2.0, 0.3125292150119522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 339365.3100155955, 339365.3100155958, 105421.5030608742], 
processed observation next is [1.0, 0.7391304347826086, 0.6818181818181818, 0.455, 1.0, 1.0, 0.1406615187649402, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12569085556133167, 0.12569085556133178, 0.2571256172216444], 
reward next is 0.7429, 
noisyNet noise sample is [array([0.74795794], dtype=float32), 1.1403433]. 
=============================================
[2019-03-23 14:52:54,180] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.7275798e-06 9.9999833e-01 1.2638261e-24 3.9347060e-13 3.0587606e-30], sum to 1.0000
[2019-03-23 14:52:54,185] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1465
[2019-03-23 14:52:54,192] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 61.0, 1.0, 2.0, 0.8337740461813518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344353894, 951731.5483067685, 951731.5483067685, 186693.3468624513], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1947600.0000, 
sim time next is 1948200.0000, 
raw observation next is [26.0, 61.0, 1.0, 2.0, 0.7762719782012161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354103, 886026.3903489842, 886026.3903489845, 177535.4609152156], 
processed observation next is [1.0, 0.5652173913043478, 0.8181818181818182, 0.61, 1.0, 1.0, 0.72033997275152, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.508428812920654, 0.3281579223514756, 0.32815792235147573, 0.43301331930540393], 
reward next is 0.5670, 
noisyNet noise sample is [array([-0.8336271], dtype=float32), -0.5699309]. 
=============================================
[2019-03-23 14:52:54,763] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5928219e-08 1.0000000e+00 5.3844102e-34 1.6428253e-16 0.0000000e+00], sum to 1.0000
[2019-03-23 14:52:54,770] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6840
[2019-03-23 14:52:54,772] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 60.0, 1.0, 2.0, 0.3401680462510711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 375191.9480378009, 375191.9480378012, 116032.4630017099], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1973400.0000, 
sim time next is 1974000.0000, 
raw observation next is [22.0, 60.00000000000001, 1.0, 2.0, 0.3403009721101373, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 375312.5582159061, 375312.5582159061, 116032.5736968675], 
processed observation next is [1.0, 0.8695652173913043, 0.6363636363636364, 0.6000000000000001, 1.0, 1.0, 0.17537621513767163, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13900465119107633, 0.13900465119107633, 0.28300627730943295], 
reward next is 0.7170, 
noisyNet noise sample is [array([-0.3548737], dtype=float32), 2.5153656]. 
=============================================
[2019-03-23 14:52:54,783] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[73.2734  ]
 [72.676544]
 [73.523346]
 [73.871025]
 [74.51777 ]], R is [[73.28447723]
 [73.26863098]
 [73.25235748]
 [73.23435211]
 [73.21481323]].
[2019-03-23 14:52:55,350] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8735109e-06 9.9999809e-01 4.3839979e-29 1.1837325e-15 2.7151385e-36], sum to 1.0000
[2019-03-23 14:52:55,357] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4511
[2019-03-23 14:52:55,369] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1241105.255339645 W.
[2019-03-23 14:52:55,376] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.5, 61.0, 1.0, 2.0, 0.5437215553459156, 1.0, 1.0, 0.5437215553459156, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1241105.255339645, 1241105.255339645, 238290.9343721424], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1953000.0000, 
sim time next is 1953600.0000, 
raw observation next is [25.33333333333333, 61.0, 1.0, 2.0, 0.6097200994293998, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9672666691936832, 6.911199999999999, 6.9112, 77.32846344354104, 1244388.784518588, 1244388.784518589, 269253.0457411061], 
processed observation next is [1.0, 0.6086956521739131, 0.7878787878787876, 0.61, 1.0, 1.0, 0.5121501242867497, 0.0, 0.5, -0.25, 1.0, 0.5, 0.953238098848119, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4608847350068845, 0.4608847350068848, 0.6567147457100149], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.13103154], dtype=float32), 0.41810665]. 
=============================================
[2019-03-23 14:52:56,638] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.23941673e-09 1.00000000e+00 2.99372888e-37 1.23661385e-20
 0.00000000e+00], sum to 1.0000
[2019-03-23 14:52:56,650] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2293
[2019-03-23 14:52:56,656] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 66.0, 1.0, 2.0, 0.2506293931282528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 272131.500834981, 272131.5008349807, 83988.19452268779], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1996200.0000, 
sim time next is 1996800.0000, 
raw observation next is [18.0, 66.66666666666666, 1.0, 2.0, 0.2510248144100453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 272560.9665802588, 272560.9665802588, 84555.62501171889], 
processed observation next is [0.0, 0.08695652173913043, 0.45454545454545453, 0.6666666666666665, 1.0, 1.0, 0.06378101801255663, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10094850614083659, 0.10094850614083659, 0.20623323173589972], 
reward next is 0.7938, 
noisyNet noise sample is [array([-0.6840179], dtype=float32), 0.83264285]. 
=============================================
[2019-03-23 14:52:59,199] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.8952138e-08 1.0000000e+00 1.1697496e-34 2.9542441e-18 0.0000000e+00], sum to 1.0000
[2019-03-23 14:52:59,206] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5675
[2019-03-23 14:52:59,211] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 60.00000000000001, 1.0, 2.0, 0.2633521714196965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 285949.8584271665, 285949.8584271662, 86135.54585811684], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2071200.0000, 
sim time next is 2071800.0000, 
raw observation next is [19.0, 60.0, 1.0, 2.0, 0.2633868447400624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 285987.5180604642, 285987.5180604642, 86137.10863042015], 
processed observation next is [0.0, 1.0, 0.5, 0.6, 1.0, 1.0, 0.079233555925078, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10592130298535711, 0.10592130298535711, 0.21009050885468328], 
reward next is 0.7899, 
noisyNet noise sample is [array([-0.8963931], dtype=float32), -0.8854236]. 
=============================================
[2019-03-23 14:53:07,844] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2687468e-07 9.9999988e-01 2.4816250e-28 4.1149491e-16 8.6091691e-38], sum to 1.0000
[2019-03-23 14:53:07,855] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2302
[2019-03-23 14:53:07,860] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 91.0, 1.0, 2.0, 0.3563380626768728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 394938.3102833663, 394938.3102833663, 118004.2577244148], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2237400.0000, 
sim time next is 2238000.0000, 
raw observation next is [17.66666666666666, 92.0, 1.0, 2.0, 0.3497525336518233, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 386267.0850263591, 386267.0850263588, 116951.1292446483], 
processed observation next is [1.0, 0.9130434782608695, 0.4393939393939391, 0.92, 1.0, 1.0, 0.1871906670647791, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14306188334309597, 0.14306188334309583, 0.28524665669426413], 
reward next is 0.7148, 
noisyNet noise sample is [array([-1.6183035], dtype=float32), 0.20477352]. 
=============================================
[2019-03-23 14:53:07,872] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[68.981346]
 [68.952515]
 [68.926865]
 [68.915344]
 [68.908615]], R is [[69.04046631]
 [69.0622406 ]
 [69.08139801]
 [69.09832001]
 [69.11351013]].
[2019-03-23 14:53:16,432] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.5031722e-07 9.9999988e-01 9.8195979e-33 1.8234777e-16 0.0000000e+00], sum to 1.0000
[2019-03-23 14:53:16,437] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2972
[2019-03-23 14:53:16,442] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 46.16666666666667, 1.0, 2.0, 0.5660387182255949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 614817.1016745005, 614817.1016745005, 124485.5853741394], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2383800.0000, 
sim time next is 2384400.0000, 
raw observation next is [22.33333333333334, 46.33333333333334, 1.0, 2.0, 0.5606054863892286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 608911.9642562683, 608911.9642562683, 125534.7333246104], 
processed observation next is [1.0, 0.6086956521739131, 0.6515151515151518, 0.46333333333333343, 1.0, 1.0, 0.4507568579865357, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22552294972454384, 0.22552294972454384, 0.30618227640148876], 
reward next is 0.6938, 
noisyNet noise sample is [array([-0.9993004], dtype=float32), 0.40374464]. 
=============================================
[2019-03-23 14:53:21,671] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.5748459e-06 9.9999344e-01 5.7036680e-29 4.5456613e-14 3.9751253e-36], sum to 1.0000
[2019-03-23 14:53:21,677] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9485
[2019-03-23 14:53:21,683] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 62.0, 1.0, 2.0, 0.7750995563830971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 852048.0049246709, 852048.0049246709, 159149.7442285513], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2478600.0000, 
sim time next is 2479200.0000, 
raw observation next is [21.06666666666667, 61.33333333333334, 1.0, 2.0, 0.7715382515918809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 846300.1983953983, 846300.1983953986, 158083.3251378278], 
processed observation next is [1.0, 0.6956521739130435, 0.5939393939393941, 0.6133333333333334, 1.0, 1.0, 0.7144228144898512, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3134445179242216, 0.3134445179242217, 0.38556908570201903], 
reward next is 0.6144, 
noisyNet noise sample is [array([0.44782344], dtype=float32), -1.4739196]. 
=============================================
[2019-03-23 14:53:21,934] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 14:53:21,935] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:53:21,936] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:53:21,937] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:53:21,937] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:53:21,937] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:53:21,939] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:53:21,940] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:53:21,938] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:53:21,940] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:53:21,943] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:53:21,964] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run80
[2019-03-23 14:53:21,991] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run80
[2019-03-23 14:53:22,015] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run80
[2019-03-23 14:53:22,046] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run80
[2019-03-23 14:53:22,046] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run80
[2019-03-23 14:54:25,213] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.560224]
[2019-03-23 14:54:25,218] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.92959745, 77.70806336, 1.0, 2.0, 0.3221610150723446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 352900.4183203115, 352900.4183203111, 118096.5321201944]
[2019-03-23 14:54:25,218] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:54:25,221] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.2176439e-08 1.0000000e+00 6.7270286e-34 1.9370203e-17 0.0000000e+00], sampled 0.12880632842561268
[2019-03-23 14:54:34,118] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.560224]
[2019-03-23 14:54:34,120] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.61905183166667, 61.610537475, 1.0, 2.0, 0.4894861721179666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 558369.3667223433, 558369.3667223433, 144738.1766239048]
[2019-03-23 14:54:34,121] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:54:34,125] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.3420592e-08 1.0000000e+00 8.2739447e-34 1.8821931e-17 0.0000000e+00], sampled 0.12994781815551648
[2019-03-23 14:55:05,770] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 14:55:06,052] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 14:55:06,193] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 14:55:06,235] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 14:55:06,366] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 14:55:07,385] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1975000, evaluation results [1975000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 14:55:12,613] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.6990986e-07 9.9999964e-01 4.8167193e-31 2.3574158e-16 0.0000000e+00], sum to 1.0000
[2019-03-23 14:55:12,620] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0466
[2019-03-23 14:55:12,628] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.56666666666667, 90.0, 1.0, 2.0, 0.2965990924816578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 322061.5800522059, 322061.5800522059, 105361.4870474758], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2601600.0000, 
sim time next is 2602200.0000, 
raw observation next is [16.48333333333333, 89.0, 1.0, 2.0, 0.2898617739667586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 314743.5077149647, 314743.507714965, 101222.7152429084], 
processed observation next is [0.0, 0.08695652173913043, 0.3856060606060605, 0.89, 1.0, 1.0, 0.11232721745844824, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11657166952406099, 0.1165716695240611, 0.2468846713241668], 
reward next is 0.7531, 
noisyNet noise sample is [array([0.13600539], dtype=float32), -0.47795457]. 
=============================================
[2019-03-23 14:55:13,505] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.3664680e-08 9.9999988e-01 2.0535491e-31 4.3822147e-15 0.0000000e+00], sum to 1.0000
[2019-03-23 14:55:13,511] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4190
[2019-03-23 14:55:13,519] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.33333333333334, 100.0, 1.0, 2.0, 0.2799511403854119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 303978.7821180819, 303978.7821180822, 100232.8821740192], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2611200.0000, 
sim time next is 2611800.0000, 
raw observation next is [15.5, 100.0, 1.0, 2.0, 0.284057640972706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 308439.1493688286, 308439.1493688286, 103729.7852761727], 
processed observation next is [0.0, 0.21739130434782608, 0.3409090909090909, 1.0, 1.0, 1.0, 0.10507205121588252, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11423672198845505, 0.11423672198845505, 0.25299947628334807], 
reward next is 0.7470, 
noisyNet noise sample is [array([1.4936526], dtype=float32), 0.20070979]. 
=============================================
[2019-03-23 14:55:19,956] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9526875e-07 9.9999976e-01 3.2903253e-30 2.5134142e-15 2.2434309e-37], sum to 1.0000
[2019-03-23 14:55:19,963] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3155
[2019-03-23 14:55:19,966] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 57.66666666666667, 1.0, 2.0, 0.4511995276312597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 514515.0188324074, 514515.0188324074, 134310.0878085838], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2737200.0000, 
sim time next is 2737800.0000, 
raw observation next is [26.5, 56.0, 1.0, 2.0, 0.4470117758204592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 509563.6637642221, 509563.6637642221, 133574.9505439058], 
processed observation next is [0.0, 0.6956521739130435, 0.8409090909090909, 0.56, 1.0, 1.0, 0.30876471977557396, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1887272828756378, 0.1887272828756378, 0.3257925623022093], 
reward next is 0.6742, 
noisyNet noise sample is [array([-0.7843244], dtype=float32), -1.421215]. 
=============================================
[2019-03-23 14:55:34,147] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.3051976e-09 1.0000000e+00 1.9506672e-29 6.9199675e-13 0.0000000e+00], sum to 1.0000
[2019-03-23 14:55:34,153] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4842
[2019-03-23 14:55:34,160] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 73.83333333333334, 1.0, 2.0, 0.4390760767120979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499323.5341652106, 499323.5341652106, 131413.7230725618], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3013800.0000, 
sim time next is 3014400.0000, 
raw observation next is [22.66666666666667, 74.66666666666667, 1.0, 2.0, 0.4388145640254517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 498918.9856887037, 498918.9856887039, 131292.9581720381], 
processed observation next is [1.0, 0.9130434782608695, 0.6666666666666669, 0.7466666666666667, 1.0, 1.0, 0.2985182050318146, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1847848095143347, 0.18478480951433476, 0.32022672724887347], 
reward next is 0.6798, 
noisyNet noise sample is [array([-0.43301356], dtype=float32), -0.35698777]. 
=============================================
[2019-03-23 14:55:35,456] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.2467637e-08 1.0000000e+00 6.3268444e-25 2.9493211e-12 3.5477431e-30], sum to 1.0000
[2019-03-23 14:55:35,464] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8020
[2019-03-23 14:55:35,468] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 80.5, 1.0, 2.0, 0.649572115970342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 727633.3304952374, 727633.3304952374, 149374.1391433586], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3058200.0000, 
sim time next is 3058800.0000, 
raw observation next is [20.33333333333334, 79.66666666666667, 1.0, 2.0, 0.7401699491705085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 831551.4331444534, 831551.4331444531, 161819.453152471], 
processed observation next is [1.0, 0.391304347826087, 0.5606060606060609, 0.7966666666666667, 1.0, 1.0, 0.6752124364631357, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.30798201227572347, 0.30798201227572336, 0.39468159305480727], 
reward next is 0.6053, 
noisyNet noise sample is [array([-0.831897], dtype=float32), 0.9042794]. 
=============================================
[2019-03-23 14:55:36,068] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0322109e-06 9.9999797e-01 5.2814107e-24 3.9406794e-11 6.2005601e-31], sum to 1.0000
[2019-03-23 14:55:36,083] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3291
[2019-03-23 14:55:36,087] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333333, 86.66666666666666, 1.0, 2.0, 0.6475941971459486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 716770.9419855453, 716770.941985545, 145741.9160387191], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3055200.0000, 
sim time next is 3055800.0000, 
raw observation next is [18.66666666666667, 84.83333333333333, 1.0, 2.0, 0.6708715562364163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 744099.6701978096, 744099.6701978096, 148992.5632211259], 
processed observation next is [1.0, 0.34782608695652173, 0.4848484848484851, 0.8483333333333333, 1.0, 1.0, 0.5885894452955203, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.27559247044363316, 0.27559247044363316, 0.3633964956612827], 
reward next is 0.6366, 
noisyNet noise sample is [array([-0.9906226], dtype=float32), 0.7370513]. 
=============================================
[2019-03-23 14:55:37,100] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.0377099e-08 9.9999988e-01 4.4521314e-27 1.2808840e-12 9.1199407e-32], sum to 1.0000
[2019-03-23 14:55:37,109] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6112
[2019-03-23 14:55:37,112] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 75.5, 1.0, 2.0, 0.5614800172858577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 637300.1421179833, 637300.142117983, 151820.270534361], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3093000.0000, 
sim time next is 3093600.0000, 
raw observation next is [25.33333333333334, 77.0, 1.0, 2.0, 0.5578802341350998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 633590.8453979105, 633590.8453979102, 151180.1795388327], 
processed observation next is [1.0, 0.8260869565217391, 0.7878787878787882, 0.77, 1.0, 1.0, 0.4473502926688747, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23466327607330018, 0.2346632760733001, 0.3687321452166651], 
reward next is 0.6313, 
noisyNet noise sample is [array([0.49822637], dtype=float32), -1.7059609]. 
=============================================
[2019-03-23 14:55:37,997] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.1571729e-08 1.0000000e+00 2.8630528e-28 4.0547288e-14 3.1940891e-35], sum to 1.0000
[2019-03-23 14:55:38,004] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8689
[2019-03-23 14:55:38,008] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 72.66666666666666, 1.0, 2.0, 0.5633153236414795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 638532.9432765454, 638532.9432765451, 152405.0113343227], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3091200.0000, 
sim time next is 3091800.0000, 
raw observation next is [26.16666666666667, 73.33333333333334, 1.0, 2.0, 0.5621985041669303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 637518.8441695552, 637518.8441695552, 152161.6553947382], 
processed observation next is [1.0, 0.782608695652174, 0.825757575757576, 0.7333333333333334, 1.0, 1.0, 0.45274813020866284, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23611809043316861, 0.23611809043316861, 0.3711259887676541], 
reward next is 0.6289, 
noisyNet noise sample is [array([-0.6603601], dtype=float32), -0.29459825]. 
=============================================
[2019-03-23 14:55:40,274] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.2622278e-06 9.9993920e-01 2.1824028e-22 5.8559235e-05 2.3161934e-28], sum to 1.0000
[2019-03-23 14:55:40,279] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6975
[2019-03-23 14:55:40,291] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1262708.825081235 W.
[2019-03-23 14:55:40,294] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 67.0, 1.0, 2.0, 0.3696547340561174, 1.0, 2.0, 0.3696547340561174, 1.0, 2.0, 0.7486488125442207, 6.9112, 6.9112, 77.3421103, 1262708.825081235, 1262708.825081235, 285835.0911407862], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3148200.0000, 
sim time next is 3148800.0000, 
raw observation next is [25.33333333333333, 66.33333333333333, 1.0, 2.0, 0.7218367676627189, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9720402578424994, 6.9112, 6.9112, 77.32846341132912, 1371858.17075165, 1371858.17075165, 290097.3727175568], 
processed observation next is [1.0, 0.43478260869565216, 0.7878787878787876, 0.6633333333333333, 1.0, 1.0, 0.6522959595783986, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9600575112035705, 0.0, 0.0, 0.5084288127088632, 0.5080956187969073, 0.5080956187969073, 0.707554567603797], 
reward next is 0.2924, 
noisyNet noise sample is [array([-1.5248885], dtype=float32), -0.3803605]. 
=============================================
[2019-03-23 14:55:51,348] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.2706792e-09 1.0000000e+00 1.1051644e-31 2.8749180e-12 4.2011421e-37], sum to 1.0000
[2019-03-23 14:55:51,356] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2075
[2019-03-23 14:55:51,359] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 54.0, 1.0, 2.0, 0.3500850350821492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 390980.3424319226, 390980.3424319223, 118773.259924086], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3328800.0000, 
sim time next is 3329400.0000, 
raw observation next is [24.0, 54.0, 1.0, 2.0, 0.3510772094848385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 392091.2457129736, 392091.2457129739, 118854.2074967756], 
processed observation next is [0.0, 0.5217391304347826, 0.7272727272727273, 0.54, 1.0, 1.0, 0.18884651185604812, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14521897989369392, 0.14521897989369403, 0.28988831096774537], 
reward next is 0.7101, 
noisyNet noise sample is [array([0.10526159], dtype=float32), 0.3867424]. 
=============================================
[2019-03-23 14:55:55,244] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 14:55:55,246] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:55:55,246] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:55:55,247] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:55:55,247] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:55:55,248] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:55:55,248] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:55:55,249] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:55:55,249] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:55:55,250] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:55:55,251] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:55:55,270] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run81
[2019-03-23 14:55:55,296] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run81
[2019-03-23 14:55:55,298] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run81
[2019-03-23 14:55:55,342] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run81
[2019-03-23 14:55:55,343] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run81
[2019-03-23 14:56:39,228] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5641741]
[2019-03-23 14:56:39,229] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.23333333333333, 66.0, 1.0, 2.0, 0.6461559375531902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 737314.4291010854, 737314.429101085, 163099.2973625977]
[2019-03-23 14:56:39,230] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 14:56:39,233] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.5023697e-07 9.9999988e-01 5.2997605e-26 8.9168603e-12 3.7396763e-32], sampled 0.9380370461351737
[2019-03-23 14:56:39,821] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5641741]
[2019-03-23 14:56:39,823] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.75450274, 63.91858295333333, 1.0, 2.0, 0.535434873658467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 610943.3014160327, 610943.3014160324, 149290.7448772588]
[2019-03-23 14:56:39,824] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 14:56:39,827] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0490751e-07 9.9999988e-01 9.3428649e-27 2.4563053e-12 5.1431955e-33], sampled 0.4766573057068
[2019-03-23 14:57:26,492] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5641741]
[2019-03-23 14:57:26,493] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.279875135, 94.32594389833334, 1.0, 2.0, 0.3611809523516976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 403583.4133002939, 403583.4133002935, 124086.5196660753]
[2019-03-23 14:57:26,493] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:57:26,497] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.2546173e-08 9.9999988e-01 1.8432877e-27 6.6099334e-13 8.0898045e-34], sampled 0.8455406304687939
[2019-03-23 14:57:35,347] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5641741]
[2019-03-23 14:57:35,350] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.542785065, 82.38540900000001, 1.0, 2.0, 0.4719177962217878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 538324.328482649, 538324.328482649, 142736.6541764433]
[2019-03-23 14:57:35,350] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:57:35,352] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.8426858e-08 9.9999988e-01 2.4644847e-27 1.1133417e-12 1.0341019e-33], sampled 0.8596712087951064
[2019-03-23 14:57:40,448] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8599.0677 1705830018.2437 461.0000
[2019-03-23 14:57:40,603] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8577.5742 1682730159.5390 205.0000
[2019-03-23 14:57:40,745] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8510.0149 1771833612.4802 173.0000
[2019-03-23 14:57:40,772] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9062.7857 1656143596.9779 78.0000
[2019-03-23 14:57:40,813] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.6821 1663708026.9778 104.0000
[2019-03-23 14:57:41,828] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 2000000, evaluation results [2000000.0, 8510.014879189379, 1771833612.4801621, 173.0, 9062.785693587695, 1656143596.9779, 78.0, 8857.682107176312, 1663708026.9777637, 104.0, 8599.067730498813, 1705830018.2436895, 461.0, 8577.574177438844, 1682730159.5389776, 205.0]
[2019-03-23 14:57:47,897] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.9529104e-08 1.0000000e+00 7.2733414e-28 2.2862587e-13 4.0725296e-34], sum to 1.0000
[2019-03-23 14:57:47,904] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5452
[2019-03-23 14:57:47,908] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5215851694867957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 594214.2028345306, 594214.2028345306, 145397.8863337873], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3544800.0000, 
sim time next is 3545400.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5209285237503305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 593466.2169340207, 593466.216934021, 145317.6062653552], 
processed observation next is [1.0, 0.0, 0.6818181818181818, 0.89, 1.0, 1.0, 0.40116065468791307, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21980230256815583, 0.21980230256815592, 0.35443318601306145], 
reward next is 0.6456, 
noisyNet noise sample is [array([-1.5861113], dtype=float32), -0.60105145]. 
=============================================
[2019-03-23 14:57:49,506] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.6139786e-08 1.0000000e+00 2.4064784e-26 7.8918961e-14 2.1160311e-30], sum to 1.0000
[2019-03-23 14:57:49,515] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1971
[2019-03-23 14:57:49,517] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 78.83333333333333, 1.0, 2.0, 0.5064837240507392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 577627.721122733, 577627.721122733, 142830.9053484374], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3610200.0000, 
sim time next is 3610800.0000, 
raw observation next is [24.0, 78.0, 1.0, 2.0, 0.5029712128375646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 573748.0857050144, 573748.0857050144, 142175.85431846], 
processed observation next is [1.0, 0.8260869565217391, 0.7272727272727273, 0.78, 1.0, 1.0, 0.37871401604695576, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2124992910018572, 0.2124992910018572, 0.34677037638648783], 
reward next is 0.6532, 
noisyNet noise sample is [array([-1.088486], dtype=float32), -0.3641164]. 
=============================================
[2019-03-23 14:57:49,614] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.3588278e-07 9.9999976e-01 1.4050973e-23 1.7090533e-12 6.4297698e-30], sum to 1.0000
[2019-03-23 14:57:49,620] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5925
[2019-03-23 14:57:49,628] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5170379440569611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 589926.2664006088, 589926.2664006086, 143511.9261757722], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3648000.0000, 
sim time next is 3648600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5123787828842317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 584609.551801616, 584609.551801616, 142952.9400470873], 
processed observation next is [1.0, 0.21739130434782608, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3904734786052895, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21652205622282072, 0.21652205622282072, 0.3486657074319202], 
reward next is 0.6513, 
noisyNet noise sample is [array([0.46093], dtype=float32), 0.22768016]. 
=============================================
[2019-03-23 14:57:53,430] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.3593071e-09 1.0000000e+00 2.7876037e-27 8.2697060e-14 3.9017247e-32], sum to 1.0000
[2019-03-23 14:57:53,439] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8110
[2019-03-23 14:57:53,446] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5137384904233374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 586161.6258329304, 586161.6258329304, 143114.1073258262], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3645000.0000, 
sim time next is 3645600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5082491698644442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 579896.07489621, 579896.07489621, 142463.9032231576], 
processed observation next is [1.0, 0.17391304347826086, 0.5909090909090909, 1.0, 1.0, 1.0, 0.38531146233055524, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21477632403563332, 0.21477632403563332, 0.3474729346906283], 
reward next is 0.6525, 
noisyNet noise sample is [array([-0.7276146], dtype=float32), -1.0738716]. 
=============================================
[2019-03-23 14:57:59,117] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.7548253e-10 1.0000000e+00 5.8471678e-29 1.1759614e-16 6.0319299e-35], sum to 1.0000
[2019-03-23 14:57:59,124] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8993
[2019-03-23 14:57:59,130] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333333, 78.16666666666667, 1.0, 2.0, 0.9343486238334031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1062363.665334082, 1062363.665334082, 197787.2983605844], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3765000.0000, 
sim time next is 3765600.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.8752922392524447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 994174.5519961881, 994174.5519961881, 187260.9599375295], 
processed observation next is [1.0, 0.6086956521739131, 0.5909090909090909, 0.83, 1.0, 1.0, 0.8441152990655559, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3682127970356252, 0.3682127970356252, 0.4567340486281207], 
reward next is 0.5433, 
noisyNet noise sample is [array([-0.43821838], dtype=float32), 1.5579435]. 
=============================================
[2019-03-23 14:57:59,627] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.1306220e-11 1.0000000e+00 8.1094374e-31 1.4716011e-18 6.5446445e-37], sum to 1.0000
[2019-03-23 14:57:59,637] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8978
[2019-03-23 14:57:59,640] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 60.5, 1.0, 2.0, 0.5986581674698025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 667690.3943901379, 667690.3943901379, 142247.2054582742], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3774600.0000, 
sim time next is 3775200.0000, 
raw observation next is [22.33333333333334, 60.33333333333334, 1.0, 2.0, 0.6758664416269818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 752123.0344608944, 752123.0344608944, 150521.7855573221], 
processed observation next is [1.0, 0.6956521739130435, 0.6515151515151518, 0.6033333333333334, 1.0, 1.0, 0.5948330520337273, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2785640868373683, 0.2785640868373683, 0.36712630623737097], 
reward next is 0.6329, 
noisyNet noise sample is [array([1.2567632], dtype=float32), -0.19472119]. 
=============================================
[2019-03-23 14:58:04,369] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1068977e-10 1.0000000e+00 3.5357537e-33 2.1724986e-17 0.0000000e+00], sum to 1.0000
[2019-03-23 14:58:04,373] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2756
[2019-03-23 14:58:04,378] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 45.0, 1.0, 2.0, 0.3491444711848279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 390517.5544572884, 390517.5544572884, 118965.7808200755], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3939000.0000, 
sim time next is 3939600.0000, 
raw observation next is [26.0, 45.0, 1.0, 2.0, 0.349463991999397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 390875.1062838271, 390875.1062838274, 118991.6286238038], 
processed observation next is [0.0, 0.6086956521739131, 0.8181818181818182, 0.45, 1.0, 1.0, 0.18682998999924622, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14476855788289894, 0.14476855788289902, 0.2902234844483019], 
reward next is 0.7098, 
noisyNet noise sample is [array([-0.8636015], dtype=float32), -0.9227963]. 
=============================================
[2019-03-23 14:58:07,838] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.3164395e-10 1.0000000e+00 1.7670105e-32 3.7884203e-19 0.0000000e+00], sum to 1.0000
[2019-03-23 14:58:07,852] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2806
[2019-03-23 14:58:07,857] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 53.0, 1.0, 2.0, 0.3255426348255305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 357699.4217912841, 357699.4217912844, 114426.2884433455], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3957000.0000, 
sim time next is 3957600.0000, 
raw observation next is [23.0, 53.0, 1.0, 2.0, 0.3263755476469519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 358608.5451938103, 358608.5451938103, 114484.5110066374], 
processed observation next is [0.0, 0.8260869565217391, 0.6818181818181818, 0.53, 1.0, 1.0, 0.1579694345586899, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13281797970141124, 0.13281797970141124, 0.2792305146503351], 
reward next is 0.7208, 
noisyNet noise sample is [array([-0.7677302], dtype=float32), -1.7689365]. 
=============================================
[2019-03-23 14:58:09,869] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.5525741e-12 1.0000000e+00 5.9476887e-34 8.2150698e-19 0.0000000e+00], sum to 1.0000
[2019-03-23 14:58:09,876] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6635
[2019-03-23 14:58:09,882] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.66666666666667, 95.0, 1.0, 2.0, 0.294364106469851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 319633.9270460486, 319633.9270460489, 98900.51590712184], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3989400.0000, 
sim time next is 3990000.0000, 
raw observation next is [15.33333333333333, 96.0, 1.0, 2.0, 0.275107658520295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 298717.9787861248, 298717.9787861245, 94184.7373459646], 
processed observation next is [1.0, 0.17391304347826086, 0.3333333333333332, 0.96, 1.0, 1.0, 0.09388457315036874, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11063628843930548, 0.11063628843930537, 0.22971887157552343], 
reward next is 0.7703, 
noisyNet noise sample is [array([-1.7240433], dtype=float32), 1.9304112]. 
=============================================
[2019-03-23 14:58:09,907] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[74.46044 ]
 [74.50501 ]
 [74.528046]
 [74.53163 ]
 [74.53279 ]], R is [[74.4906311 ]
 [74.50450897]
 [74.51256561]
 [74.5235672 ]
 [74.53726196]].
[2019-03-23 14:58:12,876] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.5728533e-13 1.0000000e+00 2.0173561e-34 3.5834243e-20 0.0000000e+00], sum to 1.0000
[2019-03-23 14:58:12,884] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9716
[2019-03-23 14:58:12,889] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.8, 100.0, 1.0, 2.0, 0.2965509352219973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 322009.2712676831, 322009.2712676831, 110961.007590441], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4078800.0000, 
sim time next is 4079400.0000, 
raw observation next is [15.83333333333333, 100.0, 1.0, 2.0, 0.3084554543853745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 334940.2224426488, 334940.2224426488, 111761.4560978119], 
processed observation next is [1.0, 0.21739130434782608, 0.3560606060606059, 1.0, 1.0, 1.0, 0.13556931798171806, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12405193423801807, 0.12405193423801807, 0.27258891731173635], 
reward next is 0.7274, 
noisyNet noise sample is [array([-1.1411657], dtype=float32), 1.419207]. 
=============================================
[2019-03-23 14:58:13,600] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.8871435e-13 1.0000000e+00 1.8949366e-33 1.6224396e-18 0.0000000e+00], sum to 1.0000
[2019-03-23 14:58:13,608] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3748
[2019-03-23 14:58:13,611] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 100.0, 1.0, 2.0, 0.3032483930237833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 329284.1552847101, 329284.1552847101, 111411.2139063067], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4068000.0000, 
sim time next is 4068600.0000, 
raw observation next is [16.16666666666667, 99.00000000000001, 1.0, 2.0, 0.3418093175572836, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 371607.4999743758, 371607.4999743755, 114236.6074991967], 
processed observation next is [1.0, 0.08695652173913043, 0.37121212121212144, 0.9900000000000001, 1.0, 1.0, 0.17726164694660448, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13763240739791696, 0.13763240739791685, 0.27862587194926025], 
reward next is 0.7214, 
noisyNet noise sample is [array([-0.42288986], dtype=float32), 1.0787513]. 
=============================================
[2019-03-23 14:58:14,519] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4035059e-11 1.0000000e+00 1.3089853e-31 8.7811037e-18 0.0000000e+00], sum to 1.0000
[2019-03-23 14:58:14,529] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8678
[2019-03-23 14:58:14,533] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 100.0, 1.0, 2.0, 0.3408459695497932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 377223.2218319739, 377223.2218319739, 116582.9724520694], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4048200.0000, 
sim time next is 4048800.0000, 
raw observation next is [17.0, 100.0, 1.0, 2.0, 0.3403951090371704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 376721.9603114771, 376721.9603114768, 116547.6658968825], 
processed observation next is [1.0, 0.8695652173913043, 0.4090909090909091, 1.0, 1.0, 1.0, 0.17549388629646298, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13952665196721373, 0.13952665196721362, 0.28426259974849394], 
reward next is 0.7157, 
noisyNet noise sample is [array([-1.1050789], dtype=float32), -0.10459594]. 
=============================================
[2019-03-23 14:58:26,566] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.5513909e-11 1.0000000e+00 5.0197513e-30 4.4008894e-17 1.9469952e-36], sum to 1.0000
[2019-03-23 14:58:26,573] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2877
[2019-03-23 14:58:26,577] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.3582408529464421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 398713.3903131844, 398713.3903131847, 118836.0285444309], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4335600.0000, 
sim time next is 4336200.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.3556575905118217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 395807.3064579043, 395807.3064579043, 118616.3268236205], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 0.94, 1.0, 1.0, 0.19457198813977714, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1465952986881127, 0.1465952986881127, 0.28930811420395247], 
reward next is 0.7107, 
noisyNet noise sample is [array([-0.12119218], dtype=float32), 1.1338629]. 
=============================================
[2019-03-23 14:58:29,560] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 14:58:29,561] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 14:58:29,562] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:58:29,563] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 14:58:29,564] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:58:29,568] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 14:58:29,569] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 14:58:29,570] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:58:29,570] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:58:29,571] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 14:58:29,574] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 14:58:29,594] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run82
[2019-03-23 14:58:29,624] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run82
[2019-03-23 14:58:29,625] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run82
[2019-03-23 14:58:29,682] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run82
[2019-03-23 14:58:29,683] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run82
[2019-03-23 14:58:51,919] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5622642]
[2019-03-23 14:58:51,920] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [27.541248705, 65.25502589833334, 1.0, 2.0, 0.8337494220988251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 944520.5300154244, 944520.5300154244, 198028.7297129164]
[2019-03-23 14:58:51,924] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:58:51,928] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.1838156e-09 1.0000000e+00 2.5498957e-26 4.6882494e-15 7.2047871e-32], sampled 0.140379066122703
[2019-03-23 14:59:08,233] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5622642]
[2019-03-23 14:59:08,234] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [30.84513682666667, 66.25025775333333, 1.0, 2.0, 0.757932195183162, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9684127518861766, 6.936314787157817, 6.9112, 95.55330086476866, 1400248.244836741, 1390169.08142027, 310197.5627974763]
[2019-03-23 14:59:08,235] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:59:08,240] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.6612851e-09 1.0000000e+00 2.7359846e-25 2.1711099e-14 1.2574141e-30], sampled 0.9457874724427058
[2019-03-23 14:59:08,241] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1400248.244836741 W.
[2019-03-23 14:59:42,716] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5622642]
[2019-03-23 14:59:42,720] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [29.29444079, 67.59872016666667, 1.0, 2.0, 0.6948913148762624, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9502508697987989, 6.961457006243631, 6.9112, 95.55320535734636, 1329308.024301254, 1309138.708540633, 297086.4734990969]
[2019-03-23 14:59:42,721] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 14:59:42,724] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.0643912e-09 1.0000000e+00 8.1911958e-26 1.1889624e-14 2.8868801e-31], sampled 0.05381488450599903
[2019-03-23 14:59:42,726] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1329308.024301254 W.
[2019-03-23 15:00:13,457] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 15:00:13,497] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 15:00:13,686] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 15:00:13,748] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 15:00:14,017] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 15:00:15,033] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 2025000, evaluation results [2025000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 15:00:20,689] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.8589105e-09 1.0000000e+00 8.5979066e-32 2.9533395e-20 1.6572776e-38], sum to 1.0000
[2019-03-23 15:00:20,691] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4628
[2019-03-23 15:00:20,698] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 78.0, 1.0, 2.0, 0.4507269448755032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 513946.6334416406, 513946.6334416409, 134206.9373651471], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4438800.0000, 
sim time next is 4439400.0000, 
raw observation next is [23.16666666666667, 77.33333333333333, 1.0, 2.0, 0.4528364569371474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516424.3005388851, 516424.3005388851, 134564.4740044223], 
processed observation next is [0.0, 0.391304347826087, 0.6893939393939396, 0.7733333333333333, 1.0, 1.0, 0.3160455711714342, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19126825945884635, 0.19126825945884635, 0.32820603415712757], 
reward next is 0.6718, 
noisyNet noise sample is [array([-0.14043471], dtype=float32), -0.23293787]. 
=============================================
[2019-03-23 15:00:20,778] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.6074841e-11 1.0000000e+00 3.9672083e-31 1.0903068e-17 0.0000000e+00], sum to 1.0000
[2019-03-23 15:00:20,787] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4240
[2019-03-23 15:00:20,792] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 85.5, 1.0, 2.0, 0.4346219162103465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 494828.9225017022, 494828.9225017022, 131526.0131189991], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4534200.0000, 
sim time next is 4534800.0000, 
raw observation next is [21.66666666666667, 84.66666666666666, 1.0, 2.0, 0.4355544495220723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 496004.9220401692, 496004.9220401692, 131746.0233670853], 
processed observation next is [0.0, 0.4782608695652174, 0.6212121212121214, 0.8466666666666666, 1.0, 1.0, 0.29444306190259034, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18370552668154413, 0.18370552668154413, 0.32133176430996413], 
reward next is 0.6787, 
noisyNet noise sample is [array([-0.66655767], dtype=float32), 0.6989652]. 
=============================================
[2019-03-23 15:00:21,127] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.5912769e-11 1.0000000e+00 8.2707342e-32 1.4438474e-19 0.0000000e+00], sum to 1.0000
[2019-03-23 15:00:21,137] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1392
[2019-03-23 15:00:21,140] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 73.0, 1.0, 2.0, 0.4014031981651237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 453858.877119161, 453858.877119161, 125836.8434670079], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4541400.0000, 
sim time next is 4542000.0000, 
raw observation next is [21.66666666666667, 73.0, 1.0, 2.0, 0.390588521893602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 440349.0003440228, 440349.0003440231, 124116.5660522897], 
processed observation next is [0.0, 0.5652173913043478, 0.6212121212121214, 0.73, 1.0, 1.0, 0.23823565236700248, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16309222234963808, 0.1630922223496382, 0.3027233318348529], 
reward next is 0.6973, 
noisyNet noise sample is [array([0.42844674], dtype=float32), -0.27443686]. 
=============================================
[2019-03-23 15:00:21,160] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[67.25506 ]
 [67.23913 ]
 [67.2264  ]
 [67.21874 ]
 [67.214676]], R is [[67.30319214]
 [67.32323456]
 [67.33907318]
 [67.35109711]
 [67.36004639]].
[2019-03-23 15:00:28,383] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.0884450e-11 1.0000000e+00 4.9322747e-34 9.2951565e-20 0.0000000e+00], sum to 1.0000
[2019-03-23 15:00:28,390] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2677
[2019-03-23 15:00:28,394] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 46.5, 1.0, 2.0, 0.6317883361924831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 692024.1951508492, 692024.1951508494, 141495.6057775584], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4629000.0000, 
sim time next is 4629600.0000, 
raw observation next is [24.0, 47.0, 1.0, 2.0, 0.6520553433708458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 717218.7433849239, 717218.7433849239, 144689.0339296748], 
processed observation next is [1.0, 0.6086956521739131, 0.7272727272727273, 0.47, 1.0, 1.0, 0.5650691792135573, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2656365716240459, 0.2656365716240459, 0.3529000827553044], 
reward next is 0.6471, 
noisyNet noise sample is [array([-0.70564604], dtype=float32), 0.37113515]. 
=============================================
[2019-03-23 15:00:36,191] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.4211294e-10 1.0000000e+00 5.0794986e-32 2.2802257e-18 2.3295169e-38], sum to 1.0000
[2019-03-23 15:00:36,197] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1972
[2019-03-23 15:00:36,203] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.4465983224959968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 508982.5113048792, 508982.5113048792, 133370.5940832774], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4839600.0000, 
sim time next is 4840200.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.4463494094944667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 508698.4964272336, 508698.4964272336, 133344.4221603242], 
processed observation next is [1.0, 0.0, 0.5454545454545454, 1.0, 1.0, 1.0, 0.3079367618680834, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18840685052860504, 0.18840685052860504, 0.32523029795201025], 
reward next is 0.6748, 
noisyNet noise sample is [array([1.2795196], dtype=float32), -2.2151227]. 
=============================================
[2019-03-23 15:00:36,504] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1558253e-09 1.0000000e+00 2.5677449e-29 2.8184369e-15 1.4837421e-34], sum to 1.0000
[2019-03-23 15:00:36,508] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1172
[2019-03-23 15:00:36,518] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4151569748086471, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 470474.5270697248, 470474.5270697251, 127785.9610970276], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4777200.0000, 
sim time next is 4777800.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4091054418031276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 463753.2567464196, 463753.2567464196, 127306.9307077955], 
processed observation next is [1.0, 0.30434782608695654, 0.5, 1.0, 1.0, 1.0, 0.26138180225390945, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1717604654616369, 0.1717604654616369, 0.31050470904340366], 
reward next is 0.6895, 
noisyNet noise sample is [array([1.002313], dtype=float32), 1.4466664]. 
=============================================
[2019-03-23 15:00:41,312] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.2356709e-09 1.0000000e+00 2.9725906e-26 6.3196609e-16 3.0418076e-33], sum to 1.0000
[2019-03-23 15:00:41,318] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1606
[2019-03-23 15:00:41,321] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.6742554105791162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 765186.632901401, 765186.632901401, 157608.0158005439], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4870200.0000, 
sim time next is 4870800.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.6818973687629488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 773904.9422276375, 773904.9422276375, 158643.7888870819], 
processed observation next is [1.0, 0.391304347826087, 0.5, 1.0, 1.0, 1.0, 0.602371710953686, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2866314600843102, 0.2866314600843102, 0.3869360704562973], 
reward next is 0.6131, 
noisyNet noise sample is [array([0.61173147], dtype=float32), -1.4996337]. 
=============================================
[2019-03-23 15:00:42,384] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.2346461e-07 9.9999976e-01 4.2882129e-25 4.5581376e-15 2.6817063e-31], sum to 1.0000
[2019-03-23 15:00:42,392] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5568
[2019-03-23 15:00:42,396] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.8712273174899358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 991205.71280688, 991205.71280688, 187983.9253156517], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4892400.0000, 
sim time next is 4893000.0000, 
raw observation next is [22.16666666666667, 77.16666666666667, 1.0, 2.0, 0.8642473811312387, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 983280.0502847629, 983280.0502847625, 186884.4183174663], 
processed observation next is [1.0, 0.6521739130434783, 0.6439393939393941, 0.7716666666666667, 1.0, 1.0, 0.8303092264140483, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.364177796401764, 0.3641777964017639, 0.45581565443284466], 
reward next is 0.5442, 
noisyNet noise sample is [array([-0.5189191], dtype=float32), 0.5006557]. 
=============================================
[2019-03-23 15:00:42,413] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[57.836605]
 [57.99737 ]
 [58.070946]
 [58.062725]
 [58.033714]], R is [[57.72040558]
 [57.68470764]
 [57.64580536]
 [57.60387802]
 [57.55727005]].
[2019-03-23 15:00:42,640] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.8505877e-08 1.0000000e+00 2.0195598e-25 1.9458040e-13 2.5107028e-30], sum to 1.0000
[2019-03-23 15:00:42,648] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3433
[2019-03-23 15:00:42,654] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 94.0, 1.0, 2.0, 0.7543024719924672, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 857811.8297521704, 857811.8297521704, 169884.1683639233], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4876200.0000, 
sim time next is 4876800.0000, 
raw observation next is [20.33333333333334, 92.0, 1.0, 2.0, 0.7564561711218748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 860705.1301659486, 860705.1301659486, 170582.8683053626], 
processed observation next is [1.0, 0.43478260869565216, 0.5606060606060609, 0.92, 1.0, 1.0, 0.6955702139023434, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3187796778392402, 0.3187796778392402, 0.4160557763545429], 
reward next is 0.5839, 
noisyNet noise sample is [array([-0.9098812], dtype=float32), -0.1589971]. 
=============================================
[2019-03-23 15:00:47,863] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1569799e-11 1.0000000e+00 2.5080996e-37 2.0379985e-21 0.0000000e+00], sum to 1.0000
[2019-03-23 15:00:47,867] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0358
[2019-03-23 15:00:47,877] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 70.5, 1.0, 2.0, 0.2800564649246914, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 304093.1822056074, 304093.1822056074, 96639.38729623515], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4995000.0000, 
sim time next is 4995600.0000, 
raw observation next is [18.33333333333334, 71.33333333333333, 1.0, 2.0, 0.2779444985766245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 301799.2382176683, 301799.2382176683, 95754.07799354676], 
processed observation next is [1.0, 0.8260869565217391, 0.46969696969696995, 0.7133333333333333, 1.0, 1.0, 0.09743062322078062, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11177749563617345, 0.11177749563617345, 0.23354653169157746], 
reward next is 0.7665, 
noisyNet noise sample is [array([-0.42651626], dtype=float32), 0.62118155]. 
=============================================
[2019-03-23 15:00:48,380] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.6584318e-14 1.0000000e+00 1.5044573e-37 1.9626259e-20 0.0000000e+00], sum to 1.0000
[2019-03-23 15:00:48,394] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2012
[2019-03-23 15:00:48,399] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 81.16666666666667, 1.0, 2.0, 0.2809147974511244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 305025.4760707429, 305025.4760707432, 97049.106216607], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5001000.0000, 
sim time next is 5001600.0000, 
raw observation next is [17.33333333333334, 80.33333333333334, 1.0, 2.0, 0.2833726176816193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 307695.0931917813, 307695.0931917815, 98190.34342682808], 
processed observation next is [1.0, 0.9130434782608695, 0.42424242424242453, 0.8033333333333335, 1.0, 1.0, 0.10421577210202412, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11396114562658567, 0.11396114562658574, 0.23948864250445873], 
reward next is 0.7605, 
noisyNet noise sample is [array([1.1810279], dtype=float32), 0.6355312]. 
=============================================
[2019-03-23 15:00:57,494] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1680722e-09 1.0000000e+00 9.3264314e-31 6.3966161e-17 1.4836889e-37], sum to 1.0000
[2019-03-23 15:00:57,503] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1376
[2019-03-23 15:00:57,509] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666666, 87.16666666666667, 1.0, 2.0, 0.4239796737432574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482522.8208262391, 482522.8208262391, 130263.849798952], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5194200.0000, 
sim time next is 5194800.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.4200482109279168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 477907.2206717658, 477907.2206717655, 129736.5721575049], 
processed observation next is [1.0, 0.13043478260869565, 0.5909090909090909, 0.88, 1.0, 1.0, 0.27506026365989594, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17700267432287622, 0.1770026743228761, 0.3164306637987924], 
reward next is 0.6836, 
noisyNet noise sample is [array([0.551407], dtype=float32), -1.7784848]. 
=============================================
[2019-03-23 15:00:57,958] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.7930503e-10 1.0000000e+00 2.7920252e-31 4.3491198e-17 1.7040713e-37], sum to 1.0000
[2019-03-23 15:00:57,964] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2912
[2019-03-23 15:00:57,968] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4304247081187441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 490380.4218633093, 490380.4218633093, 131490.3690173766], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5201400.0000, 
sim time next is 5202000.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4308359050608702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 490849.1951359095, 490849.1951359095, 131532.1677195505], 
processed observation next is [1.0, 0.21739130434782608, 0.6363636363636364, 0.83, 1.0, 1.0, 0.28854488132608774, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.181795998198485, 0.181795998198485, 0.32081016516963534], 
reward next is 0.6792, 
noisyNet noise sample is [array([1.0504936], dtype=float32), 0.6280632]. 
=============================================
[2019-03-23 15:00:57,994] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[67.43781]
 [67.44144]
 [67.4622 ]
 [67.50228]
 [67.51539]], R is [[67.38304138]
 [67.38850403]
 [67.39367676]
 [67.39839935]
 [67.40163422]].
[2019-03-23 15:01:03,479] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 15:01:03,481] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:01:03,482] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:01:03,482] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:01:03,484] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:01:03,485] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:01:03,486] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:01:03,486] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:01:03,488] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:01:03,493] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:01:03,494] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:01:03,508] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run83
[2019-03-23 15:01:03,536] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run83
[2019-03-23 15:01:03,580] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run83
[2019-03-23 15:01:03,606] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run83
[2019-03-23 15:01:03,632] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run83
[2019-03-23 15:01:07,659] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5636631]
[2019-03-23 15:01:07,662] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.08333333333333, 68.16666666666667, 1.0, 2.0, 0.2691380646185431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 292234.1142528537, 292234.1142528537, 98930.65808577603]
[2019-03-23 15:01:07,663] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:01:07,667] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.6333414e-09 1.0000000e+00 2.3960608e-28 1.2430446e-15 1.6207315e-34], sampled 0.48732920248578193
[2019-03-23 15:01:14,755] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5636631]
[2019-03-23 15:01:14,756] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.38333333333333, 57.83333333333334, 1.0, 2.0, 0.2756792949720367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 299321.2967567297, 299321.2967567297, 92191.68854057048]
[2019-03-23 15:01:14,758] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:01:14,761] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.1533812e-09 1.0000000e+00 3.8768517e-28 1.6274879e-15 2.9233911e-34], sampled 0.3514390031901049
[2019-03-23 15:01:17,034] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5636631]
[2019-03-23 15:01:17,035] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.6734705, 77.23946806000001, 1.0, 2.0, 0.4572657095532225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 520933.9846867984, 520933.984686798, 138582.3788326254]
[2019-03-23 15:01:17,036] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:01:17,039] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.6356681e-09 1.0000000e+00 2.8305302e-27 5.1082821e-15 3.2473884e-33], sampled 0.28624254763838053
[2019-03-23 15:01:21,480] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5636631]
[2019-03-23 15:01:21,482] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.31666666666667, 83.33333333333334, 1.0, 2.0, 0.5027152459928735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 573346.5886316036, 573346.5886316036, 146544.3722891244]
[2019-03-23 15:01:21,483] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:01:21,485] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.5021503e-09 1.0000000e+00 2.6182705e-28 1.3992089e-15 1.8021760e-34], sampled 0.4038771711792323
[2019-03-23 15:01:39,212] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5636631]
[2019-03-23 15:01:39,214] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.28124820666667, 50.531133165, 1.0, 2.0, 0.3233099007965719, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 351051.7633842148, 351051.7633842151, 102140.6456936652]
[2019-03-23 15:01:39,217] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:01:39,220] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.8946473e-09 1.0000000e+00 3.1298008e-28 1.4651561e-15 2.2415442e-34], sampled 0.40851430734529004
[2019-03-23 15:01:39,725] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5636631]
[2019-03-23 15:01:39,726] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [13.11385599166667, 100.0, 1.0, 2.0, 0.2171687316660888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 235780.4610542016, 235780.4610542016, 80375.8978742644]
[2019-03-23 15:01:39,728] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:01:39,731] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.8480253e-09 1.0000000e+00 2.6298132e-27 4.7247311e-15 2.9707775e-33], sampled 0.9119424687584008
[2019-03-23 15:02:25,349] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5636631]
[2019-03-23 15:02:25,351] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.6, 44.33333333333334, 1.0, 2.0, 0.3406146484927949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 373880.4305010694, 373880.4305010691, 119710.9171116848]
[2019-03-23 15:02:25,353] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:02:25,356] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.0727154e-09 1.0000000e+00 1.6534720e-28 1.0689992e-15 1.0315760e-34], sampled 0.7650536798957707
[2019-03-23 15:02:40,108] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5636631]
[2019-03-23 15:02:40,109] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.16666666666667, 87.66666666666667, 1.0, 2.0, 0.4808005469046154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 548570.1253925218, 548570.1253925215, 142871.7421680101]
[2019-03-23 15:02:40,110] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:02:40,113] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.4610586e-09 1.0000000e+00 2.4199623e-28 1.3201989e-15 1.6384980e-34], sampled 0.8141444262215369
[2019-03-23 15:02:48,754] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 15:02:48,998] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 15:02:49,114] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 15:02:49,226] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 15:02:49,251] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 15:02:50,268] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 2050000, evaluation results [2050000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 15:02:54,681] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.5217450e-08 1.0000000e+00 9.4021896e-25 6.1650506e-13 1.2576690e-29], sum to 1.0000
[2019-03-23 15:02:54,682] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3167
[2019-03-23 15:02:54,685] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1239983.491303422 W.
[2019-03-23 15:02:54,693] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.5, 77.0, 1.0, 2.0, 0.3676170875576323, 1.0, 1.0, 0.3676170875576323, 1.0, 2.0, 0.7425174555999116, 6.911199999999999, 6.9112, 77.3421103, 1239983.491303422, 1239983.491303423, 291743.443111636], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5392800.0000, 
sim time next is 5393400.0000, 
raw observation next is [25.86666666666667, 75.33333333333334, 1.0, 2.0, 0.43701322302801, 1.0, 2.0, 0.43701322302801, 1.0, 2.0, 0.8842435676662069, 6.9112, 6.9112, 77.80598815303584, 1474351.959059614, 1474351.959059614, 326127.2969146389], 
processed observation next is [1.0, 0.43478260869565216, 0.8121212121212124, 0.7533333333333334, 1.0, 1.0, 0.2962665287850125, 1.0, 1.0, 0.2962665287850125, 1.0, 1.0, 0.8346336680945815, 0.0, 0.0, 0.5115685018576519, 0.5460562811331904, 0.5460562811331904, 0.7954324314991192], 
reward next is 0.2046, 
noisyNet noise sample is [array([-1.2173407], dtype=float32), 0.11765201]. 
=============================================
[2019-03-23 15:02:54,831] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.1861160e-08 9.9999988e-01 1.1121257e-23 2.2508993e-13 1.9758689e-28], sum to 1.0000
[2019-03-23 15:02:54,838] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2771
[2019-03-23 15:02:54,843] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1087937.950327976 W.
[2019-03-23 15:02:54,850] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.36666666666667, 78.33333333333334, 1.0, 2.0, 0.4790808823088197, 1.0, 1.0, 0.4790808823088197, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1087937.950327976, 1087937.950327976, 227132.3031408133], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5390400.0000, 
sim time next is 5391000.0000, 
raw observation next is [24.65, 78.0, 1.0, 2.0, 0.4971553564926085, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9525933789720527, 6.952997168160537, 6.9112, 77.32835988532085, 1113289.064782781, 1099714.217643619, 259203.9414078402], 
processed observation next is [1.0, 0.391304347826087, 0.7568181818181817, 0.78, 1.0, 1.0, 0.3714441956157606, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9322762556743609, 0.004179716816053692, 0.0, 0.5084281320331695, 0.4123292832528819, 0.4073015620902293, 0.6322047351410737], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2086258], dtype=float32), 0.35277757]. 
=============================================
[2019-03-23 15:02:54,872] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[49.973515]
 [47.12436 ]
 [45.835545]
 [44.841335]
 [44.580162]], R is [[51.29215622]
 [51.22525406]
 [51.20142365]
 [51.19160843]
 [51.1897316 ]].
[2019-03-23 15:03:02,657] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4358563e-06 9.9999857e-01 8.3275641e-21 1.1058173e-11 1.7249690e-25], sum to 1.0000
[2019-03-23 15:03:02,662] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7751
[2019-03-23 15:03:02,669] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1257357.000749157 W.
[2019-03-23 15:03:02,676] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.1, 67.0, 1.0, 2.0, 0.5549738162030847, 1.0, 2.0, 0.5549738162030847, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1257357.000749157, 1257357.000749157, 247190.8824336441], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5565600.0000, 
sim time next is 5566200.0000, 
raw observation next is [26.1, 67.0, 1.0, 2.0, 0.5394485497291196, 0.0, 1.0, 0.0, 1.0, 1.0, 0.966851270926725, 6.926639989354302, 6.9112, 77.3284255667801, 1161994.277920899, 1156979.687637248, 266358.1999814312], 
processed observation next is [1.0, 0.43478260869565216, 0.8227272727272728, 0.67, 1.0, 1.0, 0.42431068716139947, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9526446727524642, 0.0015439989354302242, 0.0, 0.5084285638838086, 0.4303682510818144, 0.42851099542120297, 0.6496541462961736], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1949558], dtype=float32), -0.1100478]. 
=============================================
[2019-03-23 15:03:07,654] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.6029066e-12 1.0000000e+00 1.6034374e-36 3.4708527e-22 0.0000000e+00], sum to 1.0000
[2019-03-23 15:03:07,661] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3211
[2019-03-23 15:03:07,665] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 90.0, 1.0, 2.0, 0.2557526706380529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 277695.9049544323, 277695.9049544326, 87373.24085336555], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5659200.0000, 
sim time next is 5659800.0000, 
raw observation next is [15.6, 89.33333333333333, 1.0, 2.0, 0.256086006001618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 278057.9435064355, 278057.9435064358, 87618.19284360993], 
processed observation next is [0.0, 0.5217391304347826, 0.34545454545454546, 0.8933333333333333, 1.0, 1.0, 0.0701075075020225, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10298442352090204, 0.10298442352090215, 0.21370290937465836], 
reward next is 0.7863, 
noisyNet noise sample is [array([0.14734244], dtype=float32), -0.8441938]. 
=============================================
[2019-03-23 15:03:09,543] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.0567228e-10 1.0000000e+00 1.3330655e-34 7.8369830e-21 0.0000000e+00], sum to 1.0000
[2019-03-23 15:03:09,555] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5046
[2019-03-23 15:03:09,560] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 87.0, 1.0, 2.0, 0.2442024177183899, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 265151.2372891362, 265151.2372891362, 83776.42692844664], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5666400.0000, 
sim time next is 5667000.0000, 
raw observation next is [15.5, 86.0, 1.0, 2.0, 0.2410237734496106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 261698.9855944676, 261698.9855944673, 82758.16179115641], 
processed observation next is [0.0, 0.6086956521739131, 0.3409090909090909, 0.86, 1.0, 1.0, 0.05127971681201323, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09692555022017318, 0.09692555022017307, 0.2018491751003815], 
reward next is 0.7982, 
noisyNet noise sample is [array([0.7348537], dtype=float32), 0.7312915]. 
=============================================
[2019-03-23 15:03:09,576] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[78.48668 ]
 [78.480705]
 [78.47207 ]
 [78.47036 ]
 [78.462975]], R is [[78.48293304]
 [78.49377441]
 [78.50244141]
 [78.50891876]
 [78.51316833]].
[2019-03-23 15:03:09,797] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.0309104e-09 1.0000000e+00 6.7129515e-35 5.0010347e-17 0.0000000e+00], sum to 1.0000
[2019-03-23 15:03:09,807] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2750
[2019-03-23 15:03:09,811] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 80.5, 1.0, 2.0, 0.2193316617289132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 238140.3411831098, 238140.3411831101, 77416.62082505952], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5670600.0000, 
sim time next is 5671200.0000, 
raw observation next is [15.5, 80.0, 1.0, 2.0, 0.216310142660457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 234858.9211802802, 234858.92118028, 76872.92599766681], 
processed observation next is [0.0, 0.6521739130434783, 0.3409090909090909, 0.8, 1.0, 1.0, 0.020387678325571243, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08698478562232599, 0.08698478562232594, 0.18749494145772394], 
reward next is 0.8125, 
noisyNet noise sample is [array([0.42437935], dtype=float32), 0.45609325]. 
=============================================
[2019-03-23 15:03:14,627] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.3312495e-09 1.0000000e+00 1.2947325e-31 9.2714490e-16 0.0000000e+00], sum to 1.0000
[2019-03-23 15:03:14,635] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4093
[2019-03-23 15:03:14,640] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.0, 84.0, 1.0, 2.0, 0.3927167636756478, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 426476.5462842387, 426476.5462842387, 87361.67149751239], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5804400.0000, 
sim time next is 5805000.0000, 
raw observation next is [11.9, 84.5, 1.0, 2.0, 0.3915405054915699, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 425198.6128539467, 425198.6128539467, 87194.0197559574], 
processed observation next is [1.0, 0.17391304347826086, 0.17727272727272728, 0.845, 1.0, 1.0, 0.23942563186446233, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15748096772368395, 0.15748096772368395, 0.21266834086818878], 
reward next is 0.7873, 
noisyNet noise sample is [array([-0.6452483], dtype=float32), -0.03453119]. 
=============================================
[2019-03-23 15:03:14,662] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[70.5989  ]
 [70.61458 ]
 [70.65481 ]
 [70.676765]
 [70.67008 ]], R is [[70.65962982]
 [70.73995972]
 [70.82048035]
 [70.9015274 ]
 [70.98097229]].
[2019-03-23 15:03:16,070] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.5400268e-07 9.9999964e-01 3.5557628e-30 3.7476909e-15 2.5060165e-35], sum to 1.0000
[2019-03-23 15:03:16,073] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5059
[2019-03-23 15:03:16,076] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.11666666666666, 51.83333333333334, 1.0, 2.0, 0.5679205290745974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 632459.4600000773, 632459.4600000773, 138522.2390062285], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5831400.0000, 
sim time next is 5832000.0000, 
raw observation next is [24.4, 52.0, 1.0, 2.0, 0.519817604510014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 580881.7880275964, 580881.7880275964, 134350.6514145775], 
processed observation next is [1.0, 0.5217391304347826, 0.7454545454545454, 0.52, 1.0, 1.0, 0.39977200563751747, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21514140297318385, 0.21514140297318385, 0.327684515645311], 
reward next is 0.6723, 
noisyNet noise sample is [array([0.08646178], dtype=float32), -0.8773482]. 
=============================================
[2019-03-23 15:03:16,099] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[66.031784]
 [65.87425 ]
 [65.77695 ]
 [65.67414 ]
 [65.60158 ]], R is [[66.43663788]
 [66.4344101 ]
 [66.43996429]
 [66.45413971]
 [66.46923828]].
[2019-03-23 15:03:29,414] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7296167e-10 1.0000000e+00 1.1410369e-33 4.1093609e-18 0.0000000e+00], sum to 1.0000
[2019-03-23 15:03:29,422] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9221
[2019-03-23 15:03:29,427] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.21666666666667, 79.5, 1.0, 2.0, 0.222952192437141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 242072.3269541627, 242072.3269541624, 76342.89285292955], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6059400.0000, 
sim time next is 6060000.0000, 
raw observation next is [14.93333333333333, 81.0, 1.0, 2.0, 0.2146084313724729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 233010.8441407656, 233010.8441407659, 75210.82078903647], 
processed observation next is [1.0, 0.13043478260869565, 0.315151515151515, 0.81, 1.0, 1.0, 0.018260539215591114, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.086300312644728, 0.08630031264472811, 0.18344102631472312], 
reward next is 0.8166, 
noisyNet noise sample is [array([-0.8708228], dtype=float32), -0.19331156]. 
=============================================
[2019-03-23 15:03:29,450] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[71.545494]
 [71.62397 ]
 [71.78525 ]
 [71.70655 ]
 [71.66185 ]], R is [[71.54223633]
 [71.64060974]
 [71.73751831]
 [71.83166504]
 [71.92177582]].
[2019-03-23 15:03:33,444] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.2194075e-09 1.0000000e+00 2.7898746e-31 2.2789039e-18 3.3524593e-37], sum to 1.0000
[2019-03-23 15:03:33,451] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9566
[2019-03-23 15:03:33,458] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.23333333333333, 77.33333333333334, 1.0, 2.0, 0.3090515652102189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 335587.7402031122, 335587.7402031125, 88159.82481849012], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6596400.0000, 
sim time next is 6597000.0000, 
raw observation next is [16.6, 75.5, 1.0, 2.0, 0.3585497589858911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 389357.5287020187, 389357.5287020187, 94306.88747113805], 
processed observation next is [1.0, 0.34782608695652173, 0.390909090909091, 0.755, 1.0, 1.0, 0.19818719873236385, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1442064921118588, 0.1442064921118588, 0.2300167987100928], 
reward next is 0.7700, 
noisyNet noise sample is [array([-1.7739921], dtype=float32), -0.7393651]. 
=============================================
[2019-03-23 15:03:33,486] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[67.749535]
 [67.88178 ]
 [67.94805 ]
 [68.011894]
 [68.072525]], R is [[67.6886673 ]
 [67.79675293]
 [67.92150879]
 [68.05233765]
 [68.18513489]].
[2019-03-23 15:03:35,673] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.11537979e-09 1.00000000e+00 9.33593012e-32 1.87113251e-17
 1.01531845e-36], sum to 1.0000
[2019-03-23 15:03:35,681] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6151
[2019-03-23 15:03:35,687] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.15, 62.5, 1.0, 2.0, 0.3448464270878739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 383115.7638314132, 383115.7638314132, 117483.2509005552], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6201000.0000, 
sim time next is 6201600.0000, 
raw observation next is [21.96666666666667, 64.33333333333333, 1.0, 2.0, 0.3460446049976357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 385024.981814187, 385024.9818141867, 117819.3677828247], 
processed observation next is [1.0, 0.782608695652174, 0.6348484848484849, 0.6433333333333333, 1.0, 1.0, 0.18255575624704456, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14260184511636556, 0.14260184511636545, 0.2873643116654261], 
reward next is 0.7126, 
noisyNet noise sample is [array([1.5735483], dtype=float32), 0.48708457]. 
=============================================
[2019-03-23 15:03:37,527] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.0420031e-07 9.9999905e-01 2.8975381e-29 1.5783785e-13 1.3197511e-35], sum to 1.0000
[2019-03-23 15:03:37,534] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9505
[2019-03-23 15:03:37,537] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 77.66666666666667, 1.0, 2.0, 0.3606074200709195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 403026.1594744007, 403026.1594744007, 119756.4429313161], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6211200.0000, 
sim time next is 6211800.0000, 
raw observation next is [20.25, 78.5, 1.0, 2.0, 0.3622187220468097, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 404976.669272196, 404976.669272196, 119956.0473436402], 
processed observation next is [1.0, 0.9130434782608695, 0.5568181818181818, 0.785, 1.0, 1.0, 0.20277340255851212, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14999135898970223, 0.14999135898970223, 0.2925757252283907], 
reward next is 0.7074, 
noisyNet noise sample is [array([1.4810028], dtype=float32), 0.07048565]. 
=============================================
[2019-03-23 15:03:37,927] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 15:03:37,929] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:03:37,930] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:03:37,930] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:03:37,931] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:03:37,933] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:03:37,932] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:03:37,933] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:03:37,934] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:03:37,935] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:03:37,935] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:03:37,958] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run84
[2019-03-23 15:03:37,987] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run84
[2019-03-23 15:03:37,988] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run84
[2019-03-23 15:03:38,052] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run84
[2019-03-23 15:03:38,052] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run84
[2019-03-23 15:04:43,900] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.56986564]
[2019-03-23 15:04:43,900] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.1, 56.0, 1.0, 2.0, 0.3860226618962694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 433388.0166534834, 433388.0166534834, 127105.4318464154]
[2019-03-23 15:04:43,903] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:04:43,907] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.2064899e-08 1.0000000e+00 4.2704258e-30 1.2154862e-16 6.0968828e-37], sampled 0.7977452012050792
[2019-03-23 15:04:47,451] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.56986564]
[2019-03-23 15:04:47,453] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.86244330666667, 67.02798468333333, 1.0, 2.0, 0.3345629005318278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 368882.3231109947, 368882.3231109947, 119879.9224977738]
[2019-03-23 15:04:47,454] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:04:47,456] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.9845801e-08 1.0000000e+00 2.4742037e-29 3.1742602e-16 5.2565461e-36], sampled 0.6757719007924329
[2019-03-23 15:04:53,896] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.56986564]
[2019-03-23 15:04:53,897] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.23267916333333, 87.89292757999999, 1.0, 2.0, 0.4190291884223371, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 474971.3354651107, 474971.3354651107, 132562.1419614365]
[2019-03-23 15:04:53,899] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:04:53,902] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.3778784e-08 1.0000000e+00 8.1529595e-30 1.7663644e-16 1.3640835e-36], sampled 0.48111168002892535
[2019-03-23 15:04:55,365] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.56986564]
[2019-03-23 15:04:55,367] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [12.1, 77.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 182174.8174775832, 182174.8174775835, 62696.7142151537]
[2019-03-23 15:04:55,368] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:04:55,370] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.0570825e-07 9.9999976e-01 1.6352644e-25 4.1087098e-14 2.5987230e-31], sampled 0.26487780243641224
[2019-03-23 15:05:06,205] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.56986564]
[2019-03-23 15:05:06,207] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.2, 88.33333333333334, 1.0, 2.0, 0.3616660802285735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 405255.2096533201, 405255.2096533198, 124647.8237598501]
[2019-03-23 15:05:06,209] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:05:06,212] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.3516119e-08 1.0000000e+00 7.5928456e-30 1.7009527e-16 1.2499497e-36], sampled 0.8036005725074218
[2019-03-23 15:05:15,776] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.56986564]
[2019-03-23 15:05:15,776] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.8, 55.66666666666667, 1.0, 2.0, 0.277833827864982, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 301661.1874716218, 301661.1874716218, 92847.43691106886]
[2019-03-23 15:05:15,777] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:05:15,780] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.3380100e-08 1.0000000e+00 4.5094214e-29 4.4236309e-16 1.0980100e-35], sampled 0.7250626710022449
[2019-03-23 15:05:16,257] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.56986564]
[2019-03-23 15:05:16,259] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.72566600666667, 61.20603618666667, 1.0, 2.0, 0.2582874908422297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 280433.5821707556, 280433.5821707553, 85111.27601352605]
[2019-03-23 15:05:16,260] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:05:16,263] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.15852306e-08 1.00000000e+00 3.54763480e-30 1.09889641e-16
 4.84841421e-37], sampled 0.39568772576246813
[2019-03-23 15:05:21,266] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.56986564]
[2019-03-23 15:05:21,269] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.06666666666667, 52.0, 1.0, 2.0, 0.481471529892709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 528728.2460980008, 528728.2460980004, 131405.3369102272]
[2019-03-23 15:05:21,270] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:05:21,273] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.1995328e-08 1.0000000e+00 4.2986358e-30 1.2237583e-16 6.1627770e-37], sampled 0.9018832403871376
[2019-03-23 15:05:21,778] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.56986564]
[2019-03-23 15:05:21,778] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.42498281, 62.39177058, 1.0, 2.0, 0.3985458208850598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 438148.4225434884, 438148.422543488, 124441.3468175916]
[2019-03-23 15:05:21,779] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:05:21,782] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.5170538e-09 1.0000000e+00 1.8101722e-30 7.5676226e-17 2.1258700e-37], sampled 0.010168501006630137
[2019-03-23 15:05:23,561] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 15:05:23,574] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 15:05:23,597] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 15:05:23,722] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 15:05:23,723] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 15:05:24,738] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 2075000, evaluation results [2075000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 15:05:26,054] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.8198693e-07 9.9999928e-01 1.2094750e-27 4.8676087e-15 2.1482916e-33], sum to 1.0000
[2019-03-23 15:05:26,062] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8640
[2019-03-23 15:05:26,073] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.28333333333333, 66.16666666666667, 1.0, 2.0, 0.5078748680952498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 578889.5897615692, 578889.5897615694, 143436.3653091454], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6295800.0000, 
sim time next is 6296400.0000, 
raw observation next is [26.1, 67.0, 1.0, 2.0, 0.506947353038847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 577891.064740827, 577891.0647408273, 143256.7989800763], 
processed observation next is [0.0, 0.9130434782608695, 0.8227272727272728, 0.67, 1.0, 1.0, 0.3836841912985587, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21403372768178777, 0.21403372768178788, 0.3494068267806739], 
reward next is 0.6506, 
noisyNet noise sample is [array([-0.49761537], dtype=float32), -1.1357452]. 
=============================================
[2019-03-23 15:05:31,394] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.8276566e-08 1.0000000e+00 4.2836741e-30 1.5883974e-17 6.6902437e-37], sum to 1.0000
[2019-03-23 15:05:31,402] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4409
[2019-03-23 15:05:31,406] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 88.5, 1.0, 2.0, 0.6513345234242524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 723612.7389809107, 723612.7389809107, 147164.0318502174], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6449400.0000, 
sim time next is 6450000.0000, 
raw observation next is [18.3, 88.0, 1.0, 2.0, 0.633671058454794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 703317.2261290294, 703317.2261290294, 144886.9719380347], 
processed observation next is [1.0, 0.6521739130434783, 0.4681818181818182, 0.88, 1.0, 1.0, 0.5420888230684925, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.26048786152927017, 0.26048786152927017, 0.35338285838545047], 
reward next is 0.6466, 
noisyNet noise sample is [array([-1.2232898], dtype=float32), 1.7220577]. 
=============================================
[2019-03-23 15:05:31,423] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[65.80268 ]
 [65.82119 ]
 [65.824135]
 [65.82311 ]
 [65.82854 ]], R is [[65.75724792]
 [65.74073792]
 [65.72528076]
 [65.70048523]
 [65.67756653]].
[2019-03-23 15:05:35,206] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.0195394e-10 1.0000000e+00 2.7086823e-33 2.2595494e-17 0.0000000e+00], sum to 1.0000
[2019-03-23 15:05:35,212] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9960
[2019-03-23 15:05:35,215] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 93.0, 1.0, 2.0, 0.7080396247433547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 804678.0197907799, 804678.0197907799, 162959.0832743647], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6432600.0000, 
sim time next is 6433200.0000, 
raw observation next is [20.0, 93.0, 1.0, 2.0, 0.7129621120010339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 810272.0686165675, 810272.0686165675, 163633.267632164], 
processed observation next is [1.0, 0.4782608695652174, 0.5454545454545454, 0.93, 1.0, 1.0, 0.6412026400012923, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.30010076615428427, 0.30010076615428427, 0.3991055308101561], 
reward next is 0.6009, 
noisyNet noise sample is [array([-2.4417446], dtype=float32), -0.1576123]. 
=============================================
[2019-03-23 15:05:39,531] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.4936560e-08 1.0000000e+00 9.6409279e-31 3.4636266e-17 2.7418723e-36], sum to 1.0000
[2019-03-23 15:05:39,537] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8492
[2019-03-23 15:05:39,543] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 51.00000000000001, 1.0, 2.0, 0.4515697544751163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 490421.0530130503, 490421.0530130503, 106648.6816045663], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6535200.0000, 
sim time next is 6535800.0000, 
raw observation next is [20.5, 51.0, 1.0, 2.0, 0.4587270101955814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 498198.074049669, 498198.0740496687, 107392.1914023696], 
processed observation next is [1.0, 0.6521739130434783, 0.5681818181818182, 0.51, 1.0, 1.0, 0.32340876274447666, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18451780520358113, 0.184517805203581, 0.261932174152121], 
reward next is 0.7381, 
noisyNet noise sample is [array([0.28849655], dtype=float32), -1.3641657]. 
=============================================
[2019-03-23 15:05:40,885] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1870542e-07 9.9999976e-01 3.0490158e-29 7.6257021e-15 8.6477245e-35], sum to 1.0000
[2019-03-23 15:05:40,890] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8644
[2019-03-23 15:05:40,897] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.53333333333333, 72.33333333333334, 1.0, 2.0, 0.2191455298933444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 237938.198271567, 237938.1982715668, 74503.39042978284], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6567600.0000, 
sim time next is 6568200.0000, 
raw observation next is [15.25, 75.0, 1.0, 2.0, 0.2157824734509878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 234285.865906147, 234285.865906147, 74256.65993160968], 
processed observation next is [1.0, 0.0, 0.32954545454545453, 0.75, 1.0, 1.0, 0.019728091813734742, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08677254292820259, 0.08677254292820259, 0.18111380471124314], 
reward next is 0.8189, 
noisyNet noise sample is [array([-1.8035438], dtype=float32), 0.8088076]. 
=============================================
[2019-03-23 15:05:45,509] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.18255675e-05 9.99988198e-01 2.59421861e-29 7.70387781e-17
 2.73740897e-36], sum to 1.0000
[2019-03-23 15:05:45,516] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5933
[2019-03-23 15:05:45,522] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.46666666666667, 92.0, 1.0, 2.0, 0.3562027733191913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 397768.6979857694, 397768.6979857694, 119246.8040919691], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6662400.0000, 
sim time next is 6663000.0000, 
raw observation next is [18.38333333333333, 92.5, 1.0, 2.0, 0.3535834611375874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 394688.1696236137, 394688.1696236134, 118965.8538626137], 
processed observation next is [1.0, 0.08695652173913043, 0.47196969696969676, 0.925, 1.0, 1.0, 0.1919793264219842, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14618080356430138, 0.14618080356430127, 0.2901606191771066], 
reward next is 0.7098, 
noisyNet noise sample is [array([0.3401367], dtype=float32), -0.54018605]. 
=============================================
[2019-03-23 15:05:45,553] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[69.76076]
 [69.52937]
 [69.38907]
 [68.99328]
 [68.80162]], R is [[69.95867157]
 [69.96823883]
 [69.97602844]
 [69.97871399]
 [69.97306824]].
[2019-03-23 15:05:46,134] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6503166e-07 9.9999988e-01 2.0936613e-30 1.4228339e-13 8.5126079e-37], sum to 1.0000
[2019-03-23 15:05:46,143] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8066
[2019-03-23 15:05:46,148] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.21666666666667, 87.5, 1.0, 2.0, 0.3541509843767553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 396339.8930671076, 396339.8930671076, 119474.308536655], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6677400.0000, 
sim time next is 6678000.0000, 
raw observation next is [19.4, 87.0, 1.0, 2.0, 0.3696067565060206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 414286.9594578456, 414286.9594578456, 121051.644398419], 
processed observation next is [1.0, 0.30434782608695654, 0.5181818181818181, 0.87, 1.0, 1.0, 0.21200844563252572, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1534396146140169, 0.1534396146140169, 0.2952479131668756], 
reward next is 0.7048, 
noisyNet noise sample is [array([-0.13762222], dtype=float32), 0.3353548]. 
=============================================
[2019-03-23 15:05:46,175] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[68.0157  ]
 [67.996376]
 [67.96649 ]
 [67.92313 ]
 [67.87555 ]], R is [[68.063591  ]
 [68.09156036]
 [68.12071228]
 [68.15097046]
 [68.18202972]].
[2019-03-23 15:05:46,500] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.7907015e-08 1.0000000e+00 4.4918900e-30 2.1203126e-16 1.0035389e-37], sum to 1.0000
[2019-03-23 15:05:46,510] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6009
[2019-03-23 15:05:46,518] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.63333333333333, 89.0, 1.0, 2.0, 0.3575109362528712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 398248.8917778309, 398248.8917778306, 118925.17425991], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6669600.0000, 
sim time next is 6670200.0000, 
raw observation next is [18.71666666666667, 88.0, 1.0, 2.0, 0.3539365033776979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 394062.0044265463, 394062.0044265463, 118551.1837535346], 
processed observation next is [1.0, 0.17391304347826086, 0.48712121212121223, 0.88, 1.0, 1.0, 0.19242062922212233, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14594889052835047, 0.14594889052835047, 0.28914922866715753], 
reward next is 0.7109, 
noisyNet noise sample is [array([0.90239066], dtype=float32), 1.5959413]. 
=============================================
[2019-03-23 15:05:50,605] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.7131096e-06 9.9999726e-01 1.1541781e-29 5.0739878e-16 7.4090775e-37], sum to 1.0000
[2019-03-23 15:05:50,615] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4635
[2019-03-23 15:05:50,618] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 84.0, 1.0, 2.0, 0.277957259508419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 301813.0986630188, 301813.0986630185, 99053.11240594226], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6760800.0000, 
sim time next is 6761400.0000, 
raw observation next is [17.11666666666667, 82.5, 1.0, 2.0, 0.2911575093750212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 316150.926379014, 316150.926379014, 99410.6947002079], 
processed observation next is [1.0, 0.2608695652173913, 0.4143939393939396, 0.825, 1.0, 1.0, 0.11394688671877651, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1170929356959311, 0.1170929356959311, 0.24246510902489732], 
reward next is 0.7575, 
noisyNet noise sample is [array([-0.86373556], dtype=float32), -1.7066027]. 
=============================================
[2019-03-23 15:05:51,804] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3702486e-09 1.0000000e+00 2.2735997e-32 9.4490736e-18 0.0000000e+00], sum to 1.0000
[2019-03-23 15:05:51,813] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7009
[2019-03-23 15:05:51,823] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.1, 94.0, 1.0, 2.0, 0.3215624961406733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 352466.7054836501, 352466.7054836498, 113820.1167154428], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6750000.0000, 
sim time next is 6750600.0000, 
raw observation next is [17.11666666666667, 93.83333333333334, 1.0, 2.0, 0.3491459318812746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 382772.6933400017, 382772.693340002, 115861.856209597], 
processed observation next is [1.0, 0.13043478260869565, 0.4143939393939396, 0.9383333333333335, 1.0, 1.0, 0.1864324148515932, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14176766420000061, 0.14176766420000073, 0.282589893194139], 
reward next is 0.7174, 
noisyNet noise sample is [array([0.13485305], dtype=float32), 0.79407245]. 
=============================================
[2019-03-23 15:05:52,607] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.2191598e-07 9.9999976e-01 3.7576695e-30 1.4547960e-16 6.1755038e-38], sum to 1.0000
[2019-03-23 15:05:52,617] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0214
[2019-03-23 15:05:52,622] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.36666666666667, 79.0, 1.0, 2.0, 0.3694523946251549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 414105.2598385714, 414105.2598385714, 121034.1581477298], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6828000.0000, 
sim time next is 6828600.0000, 
raw observation next is [20.18333333333333, 80.0, 1.0, 2.0, 0.3676372293573891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 411825.4161685975, 411825.4161685975, 120766.2819898959], 
processed observation next is [0.0, 0.0, 0.5537878787878786, 0.8, 1.0, 1.0, 0.2095465366967363, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15252793191429537, 0.15252793191429537, 0.294551907292429], 
reward next is 0.7054, 
noisyNet noise sample is [array([1.8487452], dtype=float32), -1.1967571]. 
=============================================
[2019-03-23 15:05:53,727] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.3733073e-07 9.9999964e-01 6.4448959e-30 4.5856384e-16 9.1691056e-36], sum to 1.0000
[2019-03-23 15:05:53,738] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7919
[2019-03-23 15:05:53,742] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.18333333333333, 80.0, 1.0, 2.0, 0.3676372293573891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 411825.4161685975, 411825.4161685975, 120766.2819898959], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6828600.0000, 
sim time next is 6829200.0000, 
raw observation next is [20.0, 81.0, 1.0, 2.0, 0.3659489593088031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 409677.4458205416, 409677.4458205413, 120505.7317709861], 
processed observation next is [0.0, 0.043478260869565216, 0.5454545454545454, 0.81, 1.0, 1.0, 0.20743619913600386, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15173238734094133, 0.15173238734094122, 0.29391641895362464], 
reward next is 0.7061, 
noisyNet noise sample is [array([0.1356754], dtype=float32), 1.3209257]. 
=============================================
[2019-03-23 15:05:55,909] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.3738037e-06 9.9999762e-01 1.8703460e-29 5.7160986e-17 6.2835652e-38], sum to 1.0000
[2019-03-23 15:05:55,915] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9649
[2019-03-23 15:05:55,921] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.61666666666667, 93.5, 1.0, 2.0, 0.3384696564883997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 374119.9514625591, 374119.9514625593, 116214.9355501881], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6844200.0000, 
sim time next is 6844800.0000, 
raw observation next is [17.53333333333333, 94.0, 1.0, 2.0, 0.337807660703731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 373212.6608539017, 373212.6608539017, 116096.1875670421], 
processed observation next is [0.0, 0.21739130434782608, 0.43333333333333324, 0.94, 1.0, 1.0, 0.17225957587966376, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.138226911427371, 0.138226911427371, 0.2831614330903466], 
reward next is 0.7168, 
noisyNet noise sample is [array([0.5677961], dtype=float32), -0.24218284]. 
=============================================
[2019-03-23 15:05:58,466] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.83198767e-07 9.99999642e-01 1.37397845e-30 2.81567251e-16
 2.17043672e-38], sum to 1.0000
[2019-03-23 15:05:58,473] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4587
[2019-03-23 15:05:58,479] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 90.0, 1.0, 2.0, 0.3734225184289738, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 418722.3849495394, 418722.3849495394, 121447.6801483327], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6925200.0000, 
sim time next is 6925800.0000, 
raw observation next is [18.9, 90.0, 1.0, 2.0, 0.3713057975886481, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415842.4556389913, 415842.4556389913, 121030.2956738246], 
processed observation next is [0.0, 0.13043478260869565, 0.49545454545454537, 0.9, 1.0, 1.0, 0.21413224698581013, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15401572431073754, 0.15401572431073754, 0.2951958431068893], 
reward next is 0.7048, 
noisyNet noise sample is [array([-0.42298537], dtype=float32), 1.3537555]. 
=============================================
[2019-03-23 15:06:07,978] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.1168441e-09 1.0000000e+00 7.5754867e-30 3.3879508e-17 4.4431362e-36], sum to 1.0000
[2019-03-23 15:06:07,988] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4972
[2019-03-23 15:06:07,996] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 96.33333333333334, 1.0, 2.0, 0.3529078109244196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 392580.289784138, 392580.2897841383, 118326.8678711814], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7107000.0000, 
sim time next is 7107600.0000, 
raw observation next is [17.7, 95.66666666666667, 1.0, 2.0, 0.3515251849419924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 390637.6124364844, 390637.6124364847, 118048.282753556], 
processed observation next is [1.0, 0.2608695652173913, 0.44090909090909086, 0.9566666666666667, 1.0, 1.0, 0.1894064811774905, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14468059719869794, 0.14468059719869805, 0.2879226408623317], 
reward next is 0.7121, 
noisyNet noise sample is [array([2.2511163], dtype=float32), -1.2250377]. 
=============================================
[2019-03-23 15:06:12,369] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 15:06:12,369] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:06:12,371] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:06:12,371] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:06:12,375] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:06:12,377] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:06:12,378] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:06:12,374] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:06:12,379] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:06:12,381] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:06:12,383] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:06:12,402] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run85
[2019-03-23 15:06:12,433] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run85
[2019-03-23 15:06:12,458] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run85
[2019-03-23 15:06:12,458] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run85
[2019-03-23 15:06:12,483] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run85
[2019-03-23 15:06:20,578] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5752473]
[2019-03-23 15:06:20,579] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [10.5037343775, 96.40152834833333, 1.0, 2.0, 0.3526513930018397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 382921.0758406649, 382921.0758406641, 87590.54314812375]
[2019-03-23 15:06:20,581] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:06:20,585] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.0573696e-09 1.0000000e+00 4.8708019e-32 3.2566819e-17 0.0000000e+00], sampled 0.23062539713516617
[2019-03-23 15:06:25,192] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5752473]
[2019-03-23 15:06:25,192] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 94.0, 1.0, 2.0, 0.3963890669487806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 446692.9677462039, 446692.9677462039, 124530.7606700649]
[2019-03-23 15:06:25,193] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:06:25,195] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.9543346e-09 1.0000000e+00 4.2200256e-32 2.9996580e-17 0.0000000e+00], sampled 0.22378007245204323
[2019-03-23 15:06:32,659] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5752473]
[2019-03-23 15:06:32,660] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.97125095, 58.90479194, 1.0, 2.0, 0.4932100679566607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 562657.5327634437, 562657.5327634437, 145049.0698531287]
[2019-03-23 15:06:32,662] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:06:32,666] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.9317448e-09 1.0000000e+00 9.7674882e-32 4.6816497e-17 0.0000000e+00], sampled 0.8080621841589718
[2019-03-23 15:06:37,275] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5752473]
[2019-03-23 15:06:37,277] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.83333333333334, 48.5, 1.0, 2.0, 0.3757371598036817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 408029.5585392249, 408029.5585392249, 86376.42158670214]
[2019-03-23 15:06:37,278] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:06:37,282] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.2345270e-09 1.0000000e+00 1.0767338e-31 4.8849250e-17 0.0000000e+00], sampled 0.9705887918835129
[2019-03-23 15:06:41,211] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5752473]
[2019-03-23 15:06:41,212] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.00704727, 54.64911224, 1.0, 2.0, 0.2864547426349267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 311023.8641240552, 311023.8641240548, 94036.57281925877]
[2019-03-23 15:06:41,214] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:06:41,218] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.6951865e-09 1.0000000e+00 1.3000875e-31 5.3705691e-17 0.0000000e+00], sampled 0.23244987091446656
[2019-03-23 15:07:08,740] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5752473]
[2019-03-23 15:07:08,741] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.37580308666667, 97.32681133333334, 1.0, 2.0, 0.3515846717838575, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 390034.1810321572, 390034.1810321572, 122096.8620576164]
[2019-03-23 15:07:08,741] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:07:08,743] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.6343909e-09 1.0000000e+00 1.9141831e-32 2.1493105e-17 0.0000000e+00], sampled 0.6244179783106649
[2019-03-23 15:07:11,536] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5752473]
[2019-03-23 15:07:11,537] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.90034601666667, 86.88593535999999, 1.0, 2.0, 0.3848193998548224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 433280.608985136, 433280.608985136, 127630.6418274612]
[2019-03-23 15:07:11,538] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:07:11,541] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.3732603e-09 1.0000000e+00 1.4171272e-32 1.8533306e-17 0.0000000e+00], sampled 0.09460761333167111
[2019-03-23 15:07:54,364] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5752473]
[2019-03-23 15:07:54,366] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.13333333333333, 58.33333333333333, 1.0, 2.0, 0.355895204278792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 397224.4835889357, 397224.4835889357, 123452.6509141916]
[2019-03-23 15:07:54,367] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:07:54,369] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.0522910e-09 1.0000000e+00 9.1361684e-32 4.4724789e-17 0.0000000e+00], sampled 0.2771587483690502
[2019-03-23 15:07:56,962] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5752473]
[2019-03-23 15:07:56,963] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.38333333333333, 50.5, 1.0, 2.0, 0.308035639032129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 334484.2039011743, 334484.2039011743, 110329.1182433779]
[2019-03-23 15:07:56,964] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:07:56,966] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.6953778e-09 1.0000000e+00 5.3665523e-33 1.1354017e-17 0.0000000e+00], sampled 0.6423745732061208
[2019-03-23 15:07:57,836] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 15:07:58,081] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 15:07:58,152] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 15:07:58,211] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 15:07:58,239] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 15:07:59,253] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 2100000, evaluation results [2100000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 15:08:08,056] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.9051715e-06 9.9999809e-01 1.4817917e-29 1.6100328e-13 4.9172312e-36], sum to 1.0000
[2019-03-23 15:08:08,068] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5301
[2019-03-23 15:08:08,077] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 87.0, 1.0, 2.0, 0.3219240054888309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 351603.470519886, 351603.4705198857, 113392.2697996964], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7360800.0000, 
sim time next is 7361400.0000, 
raw observation next is [17.7, 87.0, 1.0, 2.0, 0.3237190881979839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 353573.3894902105, 353573.3894902102, 113522.5828170329], 
processed observation next is [1.0, 0.17391304347826086, 0.44090909090909086, 0.87, 1.0, 1.0, 0.15464886024747984, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1309531072185965, 0.13095310721859638, 0.2768843483342266], 
reward next is 0.7231, 
noisyNet noise sample is [array([1.3145553], dtype=float32), 0.40356645]. 
=============================================
[2019-03-23 15:08:15,192] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.6223141e-09 1.0000000e+00 1.7621388e-30 4.8921791e-17 2.9479774e-38], sum to 1.0000
[2019-03-23 15:08:15,200] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8508
[2019-03-23 15:08:15,206] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.35, 92.0, 1.0, 2.0, 0.4655379839254744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 531083.1999846408, 531083.1999846408, 136315.4783976727], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7929000.0000, 
sim time next is 7929600.0000, 
raw observation next is [21.26666666666667, 92.33333333333334, 1.0, 2.0, 0.462835524572094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 527965.3988343573, 527965.3988343576, 135930.2478752211], 
processed observation next is [1.0, 0.782608695652174, 0.6030303030303031, 0.9233333333333335, 1.0, 1.0, 0.32854440571511745, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19554274030902122, 0.19554274030902133, 0.33153718993956366], 
reward next is 0.6685, 
noisyNet noise sample is [array([-0.6570943], dtype=float32), -0.5669636]. 
=============================================
[2019-03-23 15:08:17,130] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:08:17,131] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:08:17,174] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run11
[2019-03-23 15:08:18,915] A3C_AGENT_WORKER-Thread-11 INFO:Local step 132500, global step 2110467: loss 8.4958
[2019-03-23 15:08:18,917] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 132500, global step 2110468: learning rate 0.0001
[2019-03-23 15:08:19,785] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.5170922e-08 1.0000000e+00 8.6932186e-32 1.6518791e-18 2.0883407e-38], sum to 1.0000
[2019-03-23 15:08:19,791] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9831
[2019-03-23 15:08:19,796] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.06666666666667, 55.00000000000001, 1.0, 2.0, 0.4948875865085496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564491.7619011565, 564491.7619011565, 141297.5941911906], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7572000.0000, 
sim time next is 7572600.0000, 
raw observation next is [28.25, 54.0, 1.0, 2.0, 0.4947895245360241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564400.6156167232, 564400.6156167232, 141243.4211652634], 
processed observation next is [0.0, 0.6521739130434783, 0.9204545454545454, 0.54, 1.0, 1.0, 0.36848690567003006, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2090372650432308, 0.2090372650432308, 0.34449614918356924], 
reward next is 0.6555, 
noisyNet noise sample is [array([-1.6740224], dtype=float32), 0.24798028]. 
=============================================
[2019-03-23 15:08:33,870] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133000, global step 2118416: loss 0.0160
[2019-03-23 15:08:33,871] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133000, global step 2118417: learning rate 0.0001
[2019-03-23 15:08:33,938] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.7716068e-06 9.9999821e-01 2.2290613e-30 5.8662279e-17 1.2282749e-37], sum to 1.0000
[2019-03-23 15:08:33,944] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3855
[2019-03-23 15:08:33,947] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 93.5, 1.0, 2.0, 0.6873520590352228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 778133.7176941247, 778133.7176941247, 158092.8876991878], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7895400.0000, 
sim time next is 7896000.0000, 
raw observation next is [19.4, 94.0, 1.0, 2.0, 0.6934552301900127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 785390.1518468313, 785390.1518468313, 159105.1875426223], 
processed observation next is [1.0, 0.391304347826087, 0.5181818181818181, 0.94, 1.0, 1.0, 0.6168190377375158, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.29088524142475236, 0.29088524142475236, 0.3880614330307861], 
reward next is 0.6119, 
noisyNet noise sample is [array([-1.0222398], dtype=float32), -0.03877353]. 
=============================================
[2019-03-23 15:08:33,960] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[72.66828 ]
 [72.852776]
 [72.96644 ]
 [73.08139 ]
 [73.228966]], R is [[72.30797577]
 [72.1993103 ]
 [72.08279419]
 [71.96688843]
 [71.86109161]].
[2019-03-23 15:08:34,147] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.1053082e-07 9.9999917e-01 8.1655632e-29 8.9032494e-14 5.3056743e-37], sum to 1.0000
[2019-03-23 15:08:34,154] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4987
[2019-03-23 15:08:34,157] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 63.0, 1.0, 2.0, 0.2910157966496616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 315996.9988175862, 315996.9988175865, 103583.9540898723], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7855200.0000, 
sim time next is 7855800.0000, 
raw observation next is [19.8, 65.16666666666667, 1.0, 2.0, 0.2933711187906577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 318555.3427410363, 318555.3427410366, 106022.9114142376], 
processed observation next is [1.0, 0.9565217391304348, 0.5363636363636364, 0.6516666666666667, 1.0, 1.0, 0.1167138984883221, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1179834602744579, 0.11798346027445801, 0.2585924668639942], 
reward next is 0.7414, 
noisyNet noise sample is [array([1.6216087], dtype=float32), -0.33400932]. 
=============================================
[2019-03-23 15:08:35,228] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:08:35,228] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:08:35,280] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run11
[2019-03-23 15:08:36,885] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:08:36,885] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:08:36,905] A3C_AGENT_WORKER-Thread-9 INFO:Local step 132500, global step 2120049: loss 0.0480
[2019-03-23 15:08:36,907] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 132500, global step 2120049: learning rate 0.0001
[2019-03-23 15:08:36,915] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run11
[2019-03-23 15:08:37,459] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:08:37,460] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:08:37,477] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run11
[2019-03-23 15:08:37,511] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:08:37,514] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:08:37,514] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:08:37,516] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:08:37,529] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run11
[2019-03-23 15:08:37,573] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run11
[2019-03-23 15:08:37,784] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:08:37,784] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:08:37,790] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run11
[2019-03-23 15:08:37,949] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:08:37,949] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:08:37,961] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run11
[2019-03-23 15:08:38,073] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:08:38,073] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:08:38,080] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run11
[2019-03-23 15:08:38,110] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:08:38,111] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:08:38,116] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run11
[2019-03-23 15:08:38,304] A3C_AGENT_WORKER-Thread-18 INFO:Local step 132500, global step 2120580: loss 145.5621
[2019-03-23 15:08:38,306] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 132500, global step 2120580: learning rate 0.0001
[2019-03-23 15:08:38,318] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:08:38,319] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:08:38,323] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run11
[2019-03-23 15:08:38,437] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:08:38,438] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:08:38,444] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run11
[2019-03-23 15:08:38,657] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:08:38,657] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:08:38,660] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run11
[2019-03-23 15:08:38,698] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:08:38,700] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:08:38,711] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:08:38,711] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:08:38,721] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run11
[2019-03-23 15:08:38,756] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run11
[2019-03-23 15:08:39,058] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:08:39,059] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:08:39,066] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run11
[2019-03-23 15:08:39,287] A3C_AGENT_WORKER-Thread-10 INFO:Local step 132500, global step 2120747: loss 235.9753
[2019-03-23 15:08:39,289] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 132500, global step 2120748: learning rate 0.0001
[2019-03-23 15:08:39,514] A3C_AGENT_WORKER-Thread-19 INFO:Local step 132500, global step 2120830: loss 254.6209
[2019-03-23 15:08:39,515] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 132500, global step 2120830: learning rate 0.0001
[2019-03-23 15:08:39,557] A3C_AGENT_WORKER-Thread-13 INFO:Local step 132500, global step 2120853: loss 258.9842
[2019-03-23 15:08:39,558] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 132500, global step 2120853: learning rate 0.0001
[2019-03-23 15:08:39,594] A3C_AGENT_WORKER-Thread-21 INFO:Local step 132500, global step 2120870: loss 225.8593
[2019-03-23 15:08:39,595] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 132500, global step 2120870: learning rate 0.0001
[2019-03-23 15:08:39,706] A3C_AGENT_WORKER-Thread-2 INFO:Local step 132500, global step 2120933: loss 85.9291
[2019-03-23 15:08:39,707] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 132500, global step 2120933: learning rate 0.0001
[2019-03-23 15:08:39,841] A3C_AGENT_WORKER-Thread-3 INFO:Local step 132500, global step 2121005: loss 28.9214
[2019-03-23 15:08:39,845] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 132500, global step 2121005: learning rate 0.0001
[2019-03-23 15:08:39,867] A3C_AGENT_WORKER-Thread-17 INFO:Local step 132500, global step 2121016: loss 18.5013
[2019-03-23 15:08:39,868] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 132500, global step 2121016: learning rate 0.0001
[2019-03-23 15:08:40,125] A3C_AGENT_WORKER-Thread-22 INFO:Local step 132500, global step 2121166: loss -1.2034
[2019-03-23 15:08:40,126] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 132500, global step 2121166: learning rate 0.0001
[2019-03-23 15:08:40,273] A3C_AGENT_WORKER-Thread-16 INFO:Local step 132500, global step 2121258: loss 70.5033
[2019-03-23 15:08:40,276] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 132500, global step 2121258: learning rate 0.0001
[2019-03-23 15:08:40,446] A3C_AGENT_WORKER-Thread-14 INFO:Local step 132500, global step 2121360: loss 31.9824
[2019-03-23 15:08:40,450] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 132500, global step 2121361: learning rate 0.0001
[2019-03-23 15:08:40,558] A3C_AGENT_WORKER-Thread-20 INFO:Local step 132500, global step 2121425: loss 30.3543
[2019-03-23 15:08:40,560] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 132500, global step 2121426: learning rate 0.0001
[2019-03-23 15:08:40,706] A3C_AGENT_WORKER-Thread-15 INFO:Local step 132500, global step 2121499: loss 3.9825
[2019-03-23 15:08:40,708] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 132500, global step 2121500: learning rate 0.0001
[2019-03-23 15:08:40,947] A3C_AGENT_WORKER-Thread-12 INFO:Local step 132500, global step 2121621: loss 4.6595
[2019-03-23 15:08:40,948] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 132500, global step 2121621: learning rate 0.0001
[2019-03-23 15:08:41,393] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.0252451e-01 6.6532320e-01 1.6948144e-06 3.2150581e-02 1.3207702e-08], sum to 1.0000
[2019-03-23 15:08:41,401] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8622
[2019-03-23 15:08:41,405] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.2, 78.0, 1.0, 2.0, 0.574657093429503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 649619.5401645622, 649619.5401645622, 143666.444989016], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 45600.0000, 
sim time next is 46200.0000, 
raw observation next is [21.1, 78.0, 1.0, 2.0, 0.5624798437647037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 635231.980850409, 635231.980850409, 141934.7284228273], 
processed observation next is [1.0, 0.5217391304347826, 0.5954545454545456, 0.78, 1.0, 1.0, 0.4530998047058796, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23527110401867002, 0.23527110401867002, 0.3461822644459202], 
reward next is 0.6538, 
noisyNet noise sample is [array([1.5635209], dtype=float32), 1.8384382]. 
=============================================
[2019-03-23 15:08:43,816] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.0339208e-01 9.6607953e-02 7.5654790e-23 3.8613644e-12 3.4473973e-30], sum to 1.0000
[2019-03-23 15:08:43,822] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6946
[2019-03-23 15:08:43,824] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.33333333333333, 78.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4147677409251071, 6.911199999999998, 6.9112, 77.32846344354104, 241237.4014795489, 241237.4014795494, 73333.76534840735], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 91200.0000, 
sim time next is 91800.0000, 
raw observation next is [15.0, 79.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4089295838805054, 6.911199999999999, 6.9112, 77.32846344354104, 237840.9797195046, 237840.9797195049, 71671.79042450176], 
processed observation next is [1.0, 0.043478260869565216, 0.3181818181818182, 0.795, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.15561369125786484, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08808925174796467, 0.08808925174796477, 0.17480924493780917], 
reward next is 0.8252, 
noisyNet noise sample is [array([1.5248713], dtype=float32), -0.30375087]. 
=============================================
[2019-03-23 15:08:45,779] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133500, global step 2124026: loss 2.2095
[2019-03-23 15:08:45,781] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133500, global step 2124026: learning rate 0.0001
[2019-03-23 15:08:47,739] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 15:08:47,740] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:08:47,742] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:08:47,742] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:08:47,743] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:08:47,744] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:08:47,745] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:08:47,745] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:08:47,745] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:08:47,745] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:08:47,747] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:08:47,770] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run86
[2019-03-23 15:08:47,801] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run86
[2019-03-23 15:08:47,802] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run86
[2019-03-23 15:08:47,856] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run86
[2019-03-23 15:08:47,857] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run86
[2019-03-23 15:08:56,011] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.57972884]
[2019-03-23 15:08:56,013] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [11.46666666666667, 84.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7276422860254425, 7.34549652890468, 6.9112, 95.55180993876392, 597932.3107995602, 423641.4693743077, 95279.11302189027]
[2019-03-23 15:08:56,015] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:08:56,020] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 4.0035232e-11 7.3313617e-29 1.2674653e-14 6.9540692e-38], sampled 0.5150427099885088
[2019-03-23 15:08:56,020] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 597932.3107995602 W.
[2019-03-23 15:09:09,702] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.57972884]
[2019-03-23 15:09:09,703] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.8, 87.0, 1.0, 1.0, 0.4807435960860281, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 95.5530743810874, 546115.1809190037, 546115.1809190037, 139579.5328150658]
[2019-03-23 15:09:09,704] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:09:09,707] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0000000e+00 1.6816871e-09 1.8602289e-25 2.6263231e-13 2.7370591e-33], sampled 0.19667846448040527
[2019-03-23 15:09:09,712] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 546115.1809190037 W.
[2019-03-23 15:09:16,073] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.57972884]
[2019-03-23 15:09:16,075] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.0, 47.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6178803612078994, 6.911199999999999, 6.9112, 95.55338769695034, 358470.128284905, 358470.1282849054, 119966.8232543783]
[2019-03-23 15:09:16,075] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:09:16,077] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0000000e+00 4.2155797e-12 2.3260353e-31 6.9619507e-16 0.0000000e+00], sampled 0.4384878252264601
[2019-03-23 15:09:33,125] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.57972884]
[2019-03-23 15:09:33,125] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.12188179333333, 70.666761535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4635146642070923, 6.9112, 6.9112, 95.55338769695034, 269583.216761272, 269583.216761272, 93314.67367345505]
[2019-03-23 15:09:33,127] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:09:33,130] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 5.1060692e-12 3.3979446e-31 8.3081153e-16 0.0000000e+00], sampled 0.29247169241649906
[2019-03-23 15:09:38,782] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.57972884]
[2019-03-23 15:09:38,783] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.93875482, 80.99037557, 1.0, 2.0, 0.5145889832750765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.5533876960765, 584617.2107200401, 584617.2107200398, 149896.9854006306]
[2019-03-23 15:09:38,784] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:09:38,786] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 2.8780827e-09 4.7106545e-24 2.6239462e-12 1.5556330e-31], sampled 0.6963696497646505
[2019-03-23 15:09:38,787] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 584617.2107200401 W.
[2019-03-23 15:10:13,144] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.57972884]
[2019-03-23 15:10:13,146] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [28.87317254333334, 45.71550269333333, 1.0, 2.0, 0.4754740979686085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 542315.3613448852, 542315.3613448852, 141565.9887969789]
[2019-03-23 15:10:13,148] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:10:13,150] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 3.6038859e-08 2.5651818e-20 5.7259864e-10 9.2317988e-27], sampled 0.23367882672681994
[2019-03-23 15:10:13,151] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 542315.3613448852 W.
[2019-03-23 15:10:21,282] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.57972884]
[2019-03-23 15:10:21,283] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.53333333333333, 73.0, 1.0, 1.0, 0.4507856279445568, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32823465405083, 511593.2454414423, 511593.2454414423, 131763.7201989286]
[2019-03-23 15:10:21,283] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:10:21,286] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 4.6606781e-09 1.7390255e-24 6.9792983e-13 5.3213201e-32], sampled 0.8759386145262543
[2019-03-23 15:10:21,314] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.57972884]
[2019-03-23 15:10:21,315] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.78333333333333, 44.16666666666667, 1.0, 1.0, 0.4036105642444585, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 95.55318309824344, 454499.1289370412, 454499.1289370415, 129335.0795299274]
[2019-03-23 15:10:21,316] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:10:21,319] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 8.6085618e-12 5.4391459e-31 6.8492847e-16 0.0000000e+00], sampled 0.33130064412404414
[2019-03-23 15:10:28,449] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.57972884]
[2019-03-23 15:10:28,449] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.33333333333333, 55.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7158460341500158, 7.169500908737285, 6.9112, 95.55232200756734, 515552.4441823661, 411891.1874350145, 131687.5598641682]
[2019-03-23 15:10:28,450] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:10:28,453] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 4.4340894e-12 3.1808421e-31 8.6141615e-16 0.0000000e+00], sampled 0.3260637435130672
[2019-03-23 15:10:32,605] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6328.7217 1723294598.4314 3425.0000
[2019-03-23 15:10:33,044] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6294.9961 1685630448.6673 3228.0000
[2019-03-23 15:10:33,083] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6481.6076 1678885180.2952 3057.0000
[2019-03-23 15:10:33,120] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6862.2842 1793014293.7888 2409.0000
[2019-03-23 15:10:33,170] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6553.1725 1698634175.0084 2957.0000
[2019-03-23 15:10:34,188] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 2125000, evaluation results [2125000.0, 6862.284208925443, 1793014293.78876, 2409.0, 6481.607577760913, 1678885180.2951708, 3057.0, 6294.9960618483565, 1685630448.6673346, 3228.0, 6328.721692698646, 1723294598.4313502, 3425.0, 6553.172466661831, 1698634175.0084193, 2957.0]
[2019-03-23 15:10:34,631] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 4.2561532e-12 1.3205337e-34 1.1360558e-17 0.0000000e+00], sum to 1.0000
[2019-03-23 15:10:34,638] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9717
[2019-03-23 15:10:34,642] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3774226736375854, 6.9112, 6.9112, 77.32846344354104, 219511.845226851, 219511.845226851, 68490.26027643931], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 180000.0000, 
sim time next is 180600.0000, 
raw observation next is [13.83333333333333, 89.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3748936307282986, 6.911199999999999, 6.9112, 77.32846344354104, 218040.605306234, 218040.6053062343, 68001.83517637175], 
processed observation next is [0.0, 0.08695652173913043, 0.265151515151515, 0.8900000000000001, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.10699090104042662, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08075577974304964, 0.08075577974304975, 0.16585813457651646], 
reward next is 0.8341, 
noisyNet noise sample is [array([0.8185179], dtype=float32), -0.14085719]. 
=============================================
[2019-03-23 15:10:36,132] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133000, global step 2126022: loss 0.0177
[2019-03-23 15:10:36,138] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133000, global step 2126027: learning rate 0.0001
[2019-03-23 15:10:39,440] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133000, global step 2127777: loss 0.0032
[2019-03-23 15:10:39,442] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133000, global step 2127777: learning rate 0.0001
[2019-03-23 15:10:40,741] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133000, global step 2128472: loss 0.0061
[2019-03-23 15:10:40,743] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133000, global step 2128473: learning rate 0.0001
[2019-03-23 15:10:41,033] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133000, global step 2128629: loss 0.0202
[2019-03-23 15:10:41,035] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133000, global step 2128629: learning rate 0.0001
[2019-03-23 15:10:41,232] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133000, global step 2128733: loss 0.0327
[2019-03-23 15:10:41,233] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133000, global step 2128733: learning rate 0.0001
[2019-03-23 15:10:41,313] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133000, global step 2128782: loss 0.0125
[2019-03-23 15:10:41,316] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133000, global step 2128782: learning rate 0.0001
[2019-03-23 15:10:41,584] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133000, global step 2128924: loss 0.0278
[2019-03-23 15:10:41,587] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133000, global step 2128925: learning rate 0.0001
[2019-03-23 15:10:41,671] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133000, global step 2128967: loss 0.0157
[2019-03-23 15:10:41,676] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133000, global step 2128967: learning rate 0.0001
[2019-03-23 15:10:41,704] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133000, global step 2128986: loss 0.0052
[2019-03-23 15:10:41,706] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133000, global step 2128986: learning rate 0.0001
[2019-03-23 15:10:41,982] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133000, global step 2129132: loss 0.0069
[2019-03-23 15:10:41,984] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133000, global step 2129133: learning rate 0.0001
[2019-03-23 15:10:42,161] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133000, global step 2129232: loss 0.0705
[2019-03-23 15:10:42,165] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133000, global step 2129232: learning rate 0.0001
[2019-03-23 15:10:42,320] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133000, global step 2129311: loss 0.0009
[2019-03-23 15:10:42,323] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133000, global step 2129313: learning rate 0.0001
[2019-03-23 15:10:42,529] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133000, global step 2129424: loss 0.0045
[2019-03-23 15:10:42,531] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133000, global step 2129425: learning rate 0.0001
[2019-03-23 15:10:42,680] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133000, global step 2129503: loss 0.0193
[2019-03-23 15:10:42,682] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133000, global step 2129503: learning rate 0.0001
[2019-03-23 15:10:43,026] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133000, global step 2129689: loss 0.0013
[2019-03-23 15:10:43,028] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133000, global step 2129691: learning rate 0.0001
[2019-03-23 15:10:43,286] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.8436654e-01 7.8996518e-06 6.0012204e-12 1.5625590e-02 4.7695737e-16], sum to 1.0000
[2019-03-23 15:10:43,294] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6357
[2019-03-23 15:10:43,301] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 602517.254679894 W.
[2019-03-23 15:10:43,305] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2773608659074552, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5177719735356772, 6.9112, 6.9112, 77.32846344354104, 602517.254679894, 602517.254679894, 144518.922530958], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 453000.0000, 
sim time next is 453600.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3485881741689064, 6.9112, 6.9112, 77.3421103, 608467.6136492942, 608467.6136492942, 180923.9566179101], 
processed observation next is [1.0, 0.2608695652173913, 0.22727272727272727, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.06941167738415205, 0.0, 0.0, 0.5085185399722538, 0.22535837542566453, 0.22535837542566453, 0.4412779429705124], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.01200292], dtype=float32), -0.14563608]. 
=============================================
[2019-03-23 15:10:43,736] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.4320538e-08 1.7159670e-25 1.1652848e-15 8.3616814e-33], sum to 1.0000
[2019-03-23 15:10:43,741] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1422
[2019-03-23 15:10:43,748] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 616969.992596114 W.
[2019-03-23 15:10:43,752] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.0, 56.0, 1.0, 2.0, 0.5431677677044493, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 616969.992596114, 616969.9925961138, 149247.8356995578], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 826800.0000, 
sim time next is 827400.0000, 
raw observation next is [29.0, 55.5, 1.0, 2.0, 0.2694731413879808, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5458724746034469, 6.9112, 6.9112, 77.32846344354104, 612136.8321640947, 612136.8321640947, 185682.593959771], 
processed observation next is [0.0, 0.5652173913043478, 0.9545454545454546, 0.555, 1.0, 1.0, 0.08684142673497597, 0.0, 1.0, -0.25, 1.0, 0.5, 0.3512463922906385, 0.0, 0.0, 0.5084288129206541, 0.226717345245961, 0.226717345245961, 0.4528843755116366], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8523595], dtype=float32), 0.81960714]. 
=============================================
[2019-03-23 15:10:45,450] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.3223654e-01 1.1456328e-06 1.8946036e-12 3.6776233e-01 2.4571219e-16], sum to 1.0000
[2019-03-23 15:10:45,456] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2949
[2019-03-23 15:10:45,459] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.83333333333333, 64.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5615108635222164, 6.911199999999999, 6.9112, 77.3284355315781, 326614.861974117, 326614.8619741173, 92028.57278506979], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 407400.0000, 
sim time next is 408000.0000, 
raw observation next is [17.66666666666667, 65.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4775192206745948, 6.9112, 6.9112, 77.32846327076341, 277745.3667320812, 277745.3667320812, 84170.83004638836], 
processed observation next is [1.0, 0.7391304347826086, 0.4393939393939396, 0.6533333333333334, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2535988866779926, 0.0, 0.0, 0.5084288117846542, 0.10286865434521526, 0.10286865434521526, 0.20529470743021552], 
reward next is 0.7947, 
noisyNet noise sample is [array([-0.52417564], dtype=float32), -0.9758303]. 
=============================================
[2019-03-23 15:10:45,467] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[33.99124 ]
 [34.62719 ]
 [35.104553]
 [34.964237]
 [35.572853]], R is [[35.18804932]
 [35.61170959]
 [35.76489258]
 [36.15364456]
 [36.41798782]].
[2019-03-23 15:10:48,439] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134000, global step 2132500: loss 256.1733
[2019-03-23 15:10:48,441] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134000, global step 2132500: learning rate 0.0001
[2019-03-23 15:10:51,236] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 4.9565013e-08 4.6318106e-22 9.1594024e-11 8.3152931e-28], sum to 1.0000
[2019-03-23 15:10:51,246] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9991
[2019-03-23 15:10:51,250] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4860736126484785, 6.911199999999999, 6.9112, 77.32846344354104, 282722.4083391517, 282722.408339152, 87952.81565601096], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 500400.0000, 
sim time next is 501000.0000, 
raw observation next is [15.0, 94.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4840075261157176, 6.9112, 6.9112, 77.32846344354104, 281520.3315200994, 281520.3315200994, 87740.29939837543], 
processed observation next is [1.0, 0.8260869565217391, 0.3181818181818182, 0.9400000000000002, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2628678944510252, 0.0, 0.0, 0.5084288129206541, 0.10426678945188868, 0.10426678945188868, 0.21400073023994007], 
reward next is 0.7860, 
noisyNet noise sample is [array([-0.6141612], dtype=float32), -0.3649864]. 
=============================================
[2019-03-23 15:10:51,276] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[51.427753]
 [51.452526]
 [51.535934]
 [51.766407]
 [52.621716]], R is [[51.24526978]
 [51.5182991 ]
 [51.78654099]
 [52.04965591]
 [52.30711746]].
[2019-03-23 15:10:51,393] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133500, global step 2134065: loss 0.4141
[2019-03-23 15:10:51,396] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133500, global step 2134066: learning rate 0.0001
[2019-03-23 15:10:51,683] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9996018e-01 6.8635891e-06 9.5758218e-15 3.2924559e-05 1.4273285e-19], sum to 1.0000
[2019-03-23 15:10:51,691] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0598
[2019-03-23 15:10:51,694] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.16666666666667, 88.00000000000001, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7448588662626271, 7.236541733156208, 6.9112, 77.32765345654272, 539021.0137420559, 433357.7799969482, 112440.067057084], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 551400.0000, 
sim time next is 552000.0000, 
raw observation next is [16.33333333333334, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7603484863923923, 7.366559181641064, 6.9112, 77.32712434908643, 590281.7209664641, 442392.9335049857, 119368.7834107678], 
processed observation next is [1.0, 0.391304347826087, 0.37878787878787906, 0.88, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6576406948462747, 0.04553591816410636, 0.0, 0.5084200084756461, 0.21862285961720895, 0.1638492346314762, 0.2911433741726044], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.102116], dtype=float32), -0.6940929]. 
=============================================
[2019-03-23 15:10:51,702] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[38.04653 ]
 [38.10905 ]
 [38.239574]
 [39.212975]
 [40.16156 ]], R is [[36.91690826]
 [36.54774094]
 [36.89717484]
 [36.52820206]
 [36.16292191]].
[2019-03-23 15:10:51,844] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9999976e-01 2.1540673e-07 1.2356092e-20 4.9385185e-10 3.8048875e-26], sum to 1.0000
[2019-03-23 15:10:51,853] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8765
[2019-03-23 15:10:51,857] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.83333333333334, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7305206778772835, 7.112159644670494, 6.9112, 77.32781257326211, 489981.7035968484, 424714.6706977973, 120869.65271136], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 553800.0000, 
sim time next is 554400.0000, 
raw observation next is [17.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7449617190698815, 7.236024026727438, 6.9112, 77.3275304557755, 538816.8809081764, 433321.9536661355, 124149.4119770996], 
processed observation next is [1.0, 0.43478260869565216, 0.4090909090909091, 0.88, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6356595986712593, 0.03248240267274376, 0.0, 0.508422678596487, 0.19956180774376905, 0.16048961246893909, 0.3028034438465844], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.15377675], dtype=float32), -1.0914217]. 
=============================================
[2019-03-23 15:10:54,700] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 4.4234042e-08 1.5192715e-17 1.5397981e-09 6.3247756e-23], sum to 1.0000
[2019-03-23 15:10:54,705] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3439
[2019-03-23 15:10:54,705] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 565482.9187066639 W.
[2019-03-23 15:10:54,710] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 76.33333333333334, 1.0, 2.0, 0.5189258648328229, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 565482.9187066639, 565482.9187066639, 129162.663113758], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 560400.0000, 
sim time next is 561000.0000, 
raw observation next is [18.83333333333333, 74.66666666666667, 1.0, 2.0, 0.5240303822465587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 569979.6907932262, 569979.6907932262, 129310.5755410966], 
processed observation next is [1.0, 0.4782608695652174, 0.4924242424242422, 0.7466666666666667, 1.0, 1.0, 0.4050379778081984, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21110358918267638, 0.21110358918267638, 0.3153916476612112], 
reward next is 0.6846, 
noisyNet noise sample is [array([-0.25388193], dtype=float32), 0.26894286]. 
=============================================
[2019-03-23 15:10:54,720] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[39.795433]
 [38.91464 ]
 [38.3716  ]
 [36.99743 ]
 [35.93587 ]], R is [[40.0193367 ]
 [39.61914444]
 [39.82672501]
 [39.42845917]
 [39.63481903]].
[2019-03-23 15:10:54,721] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133500, global step 2135816: loss 0.1682
[2019-03-23 15:10:54,725] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133500, global step 2135817: learning rate 0.0001
[2019-03-23 15:10:55,806] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133500, global step 2136389: loss 0.7200
[2019-03-23 15:10:55,807] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133500, global step 2136389: learning rate 0.0001
[2019-03-23 15:10:56,291] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133500, global step 2136651: loss 1.2814
[2019-03-23 15:10:56,293] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133500, global step 2136651: learning rate 0.0001
[2019-03-23 15:10:56,356] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133500, global step 2136677: loss 0.0773
[2019-03-23 15:10:56,358] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133500, global step 2136678: learning rate 0.0001
[2019-03-23 15:10:56,387] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133500, global step 2136695: loss 0.2823
[2019-03-23 15:10:56,388] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133500, global step 2136696: learning rate 0.0001
[2019-03-23 15:10:56,552] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133500, global step 2136784: loss 1.6261
[2019-03-23 15:10:56,554] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133500, global step 2136784: learning rate 0.0001
[2019-03-23 15:10:56,824] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133500, global step 2136930: loss 1.3119
[2019-03-23 15:10:56,827] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133500, global step 2136931: learning rate 0.0001
[2019-03-23 15:10:56,873] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133500, global step 2136950: loss 0.2102
[2019-03-23 15:10:56,876] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133500, global step 2136951: learning rate 0.0001
[2019-03-23 15:10:57,119] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133500, global step 2137087: loss 0.0221
[2019-03-23 15:10:57,122] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133500, global step 2137089: learning rate 0.0001
[2019-03-23 15:10:57,346] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133500, global step 2137202: loss 0.1431
[2019-03-23 15:10:57,348] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133500, global step 2137202: learning rate 0.0001
[2019-03-23 15:10:57,552] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133500, global step 2137311: loss 0.2352
[2019-03-23 15:10:57,553] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133500, global step 2137312: learning rate 0.0001
[2019-03-23 15:10:57,631] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133500, global step 2137356: loss 0.0929
[2019-03-23 15:10:57,635] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133500, global step 2137357: learning rate 0.0001
[2019-03-23 15:10:57,961] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133500, global step 2137532: loss 0.2860
[2019-03-23 15:10:57,962] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133500, global step 2137532: learning rate 0.0001
[2019-03-23 15:10:58,315] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133500, global step 2137714: loss 1.6194
[2019-03-23 15:10:58,317] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133500, global step 2137715: learning rate 0.0001
[2019-03-23 15:10:59,689] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.4548064e-10 2.0837222e-26 5.2176904e-13 7.8958360e-34], sum to 1.0000
[2019-03-23 15:10:59,697] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1593
[2019-03-23 15:10:59,701] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.33333333333333, 56.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6731183875326897, 6.911199999999999, 6.9112, 77.32846344354104, 388684.3047996797, 388684.30479968, 122016.5111440637], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 679200.0000, 
sim time next is 679800.0000, 
raw observation next is [23.16666666666667, 56.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6681886975859384, 6.911199999999999, 6.9112, 77.32846344354104, 385969.9181492102, 385969.9181492105, 121444.5135395809], 
processed observation next is [1.0, 0.8695652173913043, 0.6893939393939396, 0.565, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5259838536941976, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14295182153674452, 0.14295182153674463, 0.2962061305843437], 
reward next is 0.7038, 
noisyNet noise sample is [array([-2.110039], dtype=float32), -0.5624047]. 
=============================================
[2019-03-23 15:11:03,727] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134500, global step 2140566: loss 9.5036
[2019-03-23 15:11:03,728] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134500, global step 2140566: learning rate 0.0001
[2019-03-23 15:11:04,043] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.2192388e-02 9.6840918e-09 6.4648116e-14 9.3780756e-01 3.3758653e-20], sum to 1.0000
[2019-03-23 15:11:04,049] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7196
[2019-03-23 15:11:04,056] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.16666666666666, 57.5, 1.0, 2.0, 0.5814123451869537, 1.0, 2.0, 0.5814123451869537, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1321810.258264445, 1321810.258264445, 252408.7371576842], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 741000.0000, 
sim time next is 741600.0000, 
raw observation next is [27.0, 58.0, 1.0, 2.0, 0.5870059687476961, 1.0, 2.0, 0.5870059687476961, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1334982.020965226, 1334982.020965226, 253689.5055327868], 
processed observation next is [1.0, 0.6086956521739131, 0.8636363636363636, 0.58, 1.0, 1.0, 0.48375746093462, 1.0, 1.0, 0.48375746093462, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4944377855426763, 0.4944377855426763, 0.6187548915433825], 
reward next is 0.3812, 
noisyNet noise sample is [array([0.72302973], dtype=float32), 0.48023948]. 
=============================================
[2019-03-23 15:11:04,846] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9537603e-04 4.1225300e-12 1.6426110e-17 9.9900466e-01 6.1124252e-26], sum to 1.0000
[2019-03-23 15:11:04,855] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9640
[2019-03-23 15:11:04,858] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.66666666666666, 70.33333333333334, 1.0, 2.0, 0.2186244890426266, 1.0, 2.0, 0.2186244890426266, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 498692.1694187069, 498692.1694187066, 171131.0813435272], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 775200.0000, 
sim time next is 775800.0000, 
raw observation next is [23.5, 71.0, 1.0, 2.0, 0.217312187889145, 1.0, 2.0, 0.217312187889145, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 495638.1752688276, 495638.1752688274, 170771.9064354475], 
processed observation next is [1.0, 1.0, 0.7045454545454546, 0.71, 1.0, 1.0, 0.021640234861431233, 1.0, 1.0, 0.021640234861431233, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18356969454401023, 0.18356969454401015, 0.41651684496450614], 
reward next is 0.5835, 
noisyNet noise sample is [array([1.1915805], dtype=float32), -0.98387265]. 
=============================================
[2019-03-23 15:11:06,879] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134000, global step 2142234: loss 1.0427
[2019-03-23 15:11:06,879] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134000, global step 2142234: learning rate 0.0001
[2019-03-23 15:11:08,155] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.0646980e-08 1.4847450e-18 4.2418918e-26 1.0000000e+00 2.9333426e-35], sum to 1.0000
[2019-03-23 15:11:08,165] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9889
[2019-03-23 15:11:08,172] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.66666666666667, 75.66666666666666, 1.0, 2.0, 0.2966814531966854, 1.0, 2.0, 0.2966814531966854, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 666773.7842741337, 666773.7842741337, 191737.3613032625], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 816000.0000, 
sim time next is 816600.0000, 
raw observation next is [26.83333333333333, 74.83333333333334, 1.0, 2.0, 0.297315357104655, 1.0, 2.0, 0.297315357104655, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 668199.4247758565, 668199.4247758563, 191853.4916273814], 
processed observation next is [0.0, 0.43478260869565216, 0.8560606060606059, 0.7483333333333334, 1.0, 1.0, 0.12164419638081875, 1.0, 1.0, 0.12164419638081875, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24748126843550242, 0.24748126843550233, 0.46793534543263754], 
reward next is 0.5321, 
noisyNet noise sample is [array([-0.16949375], dtype=float32), -0.80107677]. 
=============================================
[2019-03-23 15:11:08,645] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9994206e-01 2.2982238e-09 1.8929782e-17 5.7870544e-05 1.4513709e-22], sum to 1.0000
[2019-03-23 15:11:08,649] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7769
[2019-03-23 15:11:08,658] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.66666666666666, 80.66666666666667, 1.0, 2.0, 0.221190835137701, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4422997164388584, 6.911199999999999, 6.9112, 77.32846121673633, 503613.6286844335, 503613.6286844338, 167884.3716883986], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 856200.0000, 
sim time next is 856800.0000, 
raw observation next is [21.0, 83.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7661607164810482, 7.295520990214982, 6.9112, 77.32752546332954, 562274.3018885626, 437456.2190294103, 135403.9769932082], 
processed observation next is [0.0, 0.9565217391304348, 0.5909090909090909, 0.83, 0.0, 0.5, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6659438806872118, 0.038432099021498176, 0.0, 0.5084226457715315, 0.20824974144020839, 0.16202082186274455, 0.33025360242245905], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.1250348], dtype=float32), 0.85829973]. 
=============================================
[2019-03-23 15:11:09,824] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134000, global step 2143796: loss -0.1653
[2019-03-23 15:11:09,825] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134000, global step 2143796: learning rate 0.0001
[2019-03-23 15:11:10,873] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134000, global step 2144350: loss 0.0200
[2019-03-23 15:11:10,877] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134000, global step 2144352: learning rate 0.0001
[2019-03-23 15:11:11,262] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134000, global step 2144556: loss 0.9804
[2019-03-23 15:11:11,265] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134000, global step 2144556: learning rate 0.0001
[2019-03-23 15:11:11,332] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134000, global step 2144594: loss 0.4828
[2019-03-23 15:11:11,333] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134000, global step 2144594: learning rate 0.0001
[2019-03-23 15:11:11,672] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134000, global step 2144768: loss 0.1799
[2019-03-23 15:11:11,673] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134000, global step 2144768: learning rate 0.0001
[2019-03-23 15:11:11,776] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134000, global step 2144825: loss 0.4603
[2019-03-23 15:11:11,778] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134000, global step 2144826: learning rate 0.0001
[2019-03-23 15:11:12,051] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134000, global step 2144972: loss 0.8396
[2019-03-23 15:11:12,054] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134000, global step 2144972: learning rate 0.0001
[2019-03-23 15:11:12,103] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134000, global step 2144999: loss 0.4843
[2019-03-23 15:11:12,105] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134000, global step 2144999: learning rate 0.0001
[2019-03-23 15:11:12,346] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134000, global step 2145127: loss 0.0344
[2019-03-23 15:11:12,348] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134000, global step 2145128: learning rate 0.0001
[2019-03-23 15:11:12,685] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134000, global step 2145318: loss 0.1462
[2019-03-23 15:11:12,686] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134000, global step 2145318: learning rate 0.0001
[2019-03-23 15:11:12,758] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134000, global step 2145358: loss 0.0224
[2019-03-23 15:11:12,763] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134000, global step 2145360: learning rate 0.0001
[2019-03-23 15:11:12,847] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134000, global step 2145412: loss 0.0113
[2019-03-23 15:11:12,848] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134000, global step 2145412: learning rate 0.0001
[2019-03-23 15:11:12,995] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134000, global step 2145496: loss 0.1177
[2019-03-23 15:11:12,997] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134000, global step 2145498: learning rate 0.0001
[2019-03-23 15:11:13,296] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134000, global step 2145680: loss 0.0184
[2019-03-23 15:11:13,298] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134000, global step 2145680: learning rate 0.0001
[2019-03-23 15:11:18,861] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135000, global step 2148500: loss 29.7512
[2019-03-23 15:11:18,862] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135000, global step 2148501: learning rate 0.0001
[2019-03-23 15:11:20,443] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.2358422e-01 8.8417540e-10 1.7335978e-11 7.6415800e-02 8.6707077e-17], sum to 1.0000
[2019-03-23 15:11:20,460] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0843
[2019-03-23 15:11:20,465] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 743741.2354799758 W.
[2019-03-23 15:11:20,469] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 69.0, 1.0, 2.0, 0.3282767732043017, 1.0, 1.0, 0.3282767732043017, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 743741.2354799758, 743741.2354799756, 183055.8774251001], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1090200.0000, 
sim time next is 1090800.0000, 
raw observation next is [22.0, 69.0, 1.0, 2.0, 0.6789378424627925, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 765637.2843621324, 765637.2843621324, 155344.1480150839], 
processed observation next is [1.0, 0.6521739130434783, 0.6363636363636364, 0.69, 1.0, 1.0, 0.5986723030784906, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2835693645785676, 0.2835693645785676, 0.3788881658904485], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3067105], dtype=float32), -1.3883374]. 
=============================================
[2019-03-23 15:11:21,847] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 15:11:21,848] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:11:21,849] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:11:21,849] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:11:21,850] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:11:21,850] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:11:21,850] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:11:21,850] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:11:21,851] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:11:21,854] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:11:21,856] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:11:21,878] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run87
[2019-03-23 15:11:21,909] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run87
[2019-03-23 15:11:21,909] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run87
[2019-03-23 15:11:21,935] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run87
[2019-03-23 15:11:21,984] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run87
[2019-03-23 15:11:24,218] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.58206654]
[2019-03-23 15:11:24,220] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.0, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4185433289558057, 6.911199999999999, 6.9112, 77.32846344354104, 243433.9102365127, 243433.9102365129, 69721.30054270847]
[2019-03-23 15:11:24,223] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:11:24,226] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 3.2817893e-15 1.0824832e-23 2.1569064e-11 6.6932761e-31], sampled 0.10872928639939838
[2019-03-23 15:11:48,620] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.58206654]
[2019-03-23 15:11:48,620] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.74870454, 83.27892291, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 451430.5682719228, 451430.5682719225, 169974.8176004114]
[2019-03-23 15:11:48,623] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:11:48,630] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.9075200e-03 8.7057922e-13 9.6259535e-15 9.9509251e-01 1.0454617e-21], sampled 0.7537359318270631
[2019-03-23 15:11:54,406] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.58206654]
[2019-03-23 15:11:54,406] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.24735887, 61.61624694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.391268263041784, 6.911199999999998, 6.9112, 95.55338769695034, 227556.2746300928, 227556.2746300935, 67309.59263986765]
[2019-03-23 15:11:54,408] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:11:54,410] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 6.3301597e-15 5.5145681e-23 9.8057659e-11 4.4513266e-30], sampled 0.8033306070717887
[2019-03-23 15:12:05,323] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.58206654]
[2019-03-23 15:12:05,325] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.33333333333334, 71.66666666666667, 1.0, 2.0, 0.3952509712807934, 1.0, 2.0, 0.3952509712807934, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 902330.9519653447, 902330.9519653447, 202456.8291567214]
[2019-03-23 15:12:05,326] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:12:05,330] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.7817415e-04 1.4698920e-14 6.1879505e-16 9.9962175e-01 1.5448459e-23], sampled 0.5442422187211692
[2019-03-23 15:12:10,821] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.58206654]
[2019-03-23 15:12:10,822] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.95, 71.5, 1.0, 2.0, 0.2515986297330559, 1.0, 2.0, 0.2515986297330559, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 573182.7995888076, 573182.7995888073, 185041.5923572351]
[2019-03-23 15:12:10,824] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:12:10,827] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.3197013e-01 4.6515389e-11 5.4906163e-14 6.6802984e-01 1.6146291e-20], sampled 0.9490475155939971
[2019-03-23 15:12:15,557] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.58206654]
[2019-03-23 15:12:15,560] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.67571136, 87.16084842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5934303561848118, 6.911199999999999, 6.9112, 95.55338769695034, 344740.9610213599, 344740.9610213602, 117584.3483614469]
[2019-03-23 15:12:15,561] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:12:15,567] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 1.9553737e-16 1.0036512e-27 7.7964793e-16 1.6581592e-35], sampled 0.4991830811028649
[2019-03-23 15:12:21,850] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.58206654]
[2019-03-23 15:12:21,851] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.85, 80.5, 1.0, 2.0, 0.2600479414487428, 1.0, 2.0, 0.2600479414487428, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 591783.5290140588, 591783.5290140584, 187099.6497899517]
[2019-03-23 15:12:21,853] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:12:21,855] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.6325606e-03 8.1628660e-14 1.1374217e-15 9.9836749e-01 4.0372033e-23], sampled 0.33434396520694576
[2019-03-23 15:12:56,064] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.58206654]
[2019-03-23 15:12:56,065] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [28.19668243333334, 59.79771718666667, 1.0, 2.0, 0.263778943153418, 1.0, 2.0, 0.263778943153418, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 597991.3787313397, 597991.3787313394, 189173.5837519523]
[2019-03-23 15:12:56,065] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:12:56,069] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.8922083e-02 2.5080615e-12 8.2784181e-15 9.8107797e-01 8.7349536e-22], sampled 0.17596164081929833
[2019-03-23 15:13:07,044] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6539.8111 1817444350.7065 2088.0000
[2019-03-23 15:13:07,079] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6429.1680 1826046508.5853 2355.0000
[2019-03-23 15:13:07,322] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6440.4209 1821199423.4309 2452.0000
[2019-03-23 15:13:07,353] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6780.0902 1882098723.6189 1776.0000
[2019-03-23 15:13:07,381] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6259.1447 1833702472.9057 2318.0000
[2019-03-23 15:13:08,395] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 2150000, evaluation results [2150000.0, 6780.090237607914, 1882098723.6188629, 1776.0, 6429.168049656711, 1826046508.5853345, 2355.0, 6259.144740566386, 1833702472.9057124, 2318.0, 6440.42090572933, 1821199423.4308805, 2452.0, 6539.811099128139, 1817444350.7065442, 2088.0]
[2019-03-23 15:13:08,830] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134500, global step 2150227: loss 1.4101
[2019-03-23 15:13:08,833] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134500, global step 2150227: learning rate 0.0001
[2019-03-23 15:13:11,038] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 4.3409693e-15 6.4365433e-23 3.2713501e-09 3.8536671e-31], sum to 1.0000
[2019-03-23 15:13:11,043] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9919
[2019-03-23 15:13:11,048] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.0, 94.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6706435440269353, 6.9112, 6.9112, 77.32846344354104, 387424.695148423, 387424.695148423, 121652.4453123153], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1138200.0000, 
sim time next is 1138800.0000, 
raw observation next is [18.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6641424872880595, 6.911199999999999, 6.9112, 77.32846344354104, 383620.9320705512, 383620.9320705515, 121067.8378359032], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5202035532686564, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14208182669279673, 0.14208182669279684, 0.29528740935586145], 
reward next is 0.7047, 
noisyNet noise sample is [array([-2.4055836], dtype=float32), 1.0002308]. 
=============================================
[2019-03-23 15:13:12,069] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134500, global step 2151947: loss 0.7280
[2019-03-23 15:13:12,076] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134500, global step 2151950: learning rate 0.0001
[2019-03-23 15:13:12,846] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134500, global step 2152348: loss -110.8257
[2019-03-23 15:13:12,847] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134500, global step 2152349: learning rate 0.0001
[2019-03-23 15:13:13,203] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134500, global step 2152527: loss 96.8013
[2019-03-23 15:13:13,205] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134500, global step 2152527: learning rate 0.0001
[2019-03-23 15:13:13,282] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134500, global step 2152570: loss -2.7967
[2019-03-23 15:13:13,286] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134500, global step 2152572: learning rate 0.0001
[2019-03-23 15:13:13,746] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134500, global step 2152807: loss -49.1486
[2019-03-23 15:13:13,749] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134500, global step 2152808: learning rate 0.0001
[2019-03-23 15:13:13,930] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134500, global step 2152906: loss 78.1451
[2019-03-23 15:13:13,936] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134500, global step 2152906: learning rate 0.0001
[2019-03-23 15:13:13,967] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134500, global step 2152923: loss 1.0718
[2019-03-23 15:13:13,968] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134500, global step 2152923: learning rate 0.0001
[2019-03-23 15:13:14,044] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134500, global step 2152966: loss -22.8082
[2019-03-23 15:13:14,046] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134500, global step 2152968: learning rate 0.0001
[2019-03-23 15:13:14,159] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134500, global step 2153024: loss 0.7503
[2019-03-23 15:13:14,161] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134500, global step 2153026: learning rate 0.0001
[2019-03-23 15:13:14,658] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134500, global step 2153285: loss 1.0733
[2019-03-23 15:13:14,660] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134500, global step 2153286: learning rate 0.0001
[2019-03-23 15:13:14,686] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134500, global step 2153302: loss 1.2293
[2019-03-23 15:13:14,690] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134500, global step 2153305: learning rate 0.0001
[2019-03-23 15:13:14,774] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134500, global step 2153344: loss 0.4364
[2019-03-23 15:13:14,775] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134500, global step 2153345: learning rate 0.0001
[2019-03-23 15:13:14,864] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134500, global step 2153393: loss 0.3434
[2019-03-23 15:13:14,867] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134500, global step 2153395: learning rate 0.0001
[2019-03-23 15:13:15,371] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134500, global step 2153655: loss 5.7286
[2019-03-23 15:13:15,372] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134500, global step 2153655: learning rate 0.0001
[2019-03-23 15:13:15,589] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.8560185e-04 3.4145392e-13 1.4692901e-16 9.9911433e-01 3.3337692e-24], sum to 1.0000
[2019-03-23 15:13:15,597] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7123
[2019-03-23 15:13:15,600] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.33333333333333, 60.33333333333333, 1.0, 2.0, 0.5908850899477113, 1.0, 2.0, 0.5908850899477113, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1339043.525784758, 1339043.525784758, 256754.3115326941], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1258800.0000, 
sim time next is 1259400.0000, 
raw observation next is [27.66666666666667, 59.16666666666666, 1.0, 2.0, 0.6297807195218003, 1.0, 2.0, 0.6297807195218003, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1424820.319251725, 1424820.319251724, 268461.7532009931], 
processed observation next is [1.0, 0.5652173913043478, 0.8939393939393941, 0.5916666666666666, 1.0, 1.0, 0.5372258994022503, 1.0, 1.0, 0.5372258994022503, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5277112293524907, 0.5277112293524904, 0.6547847639048613], 
reward next is 0.3452, 
noisyNet noise sample is [array([0.33909124], dtype=float32), 2.232469]. 
=============================================
[2019-03-23 15:13:17,144] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 4.0654020e-13 4.2793256e-17 1.7131889e-08 3.1527698e-22], sum to 1.0000
[2019-03-23 15:13:17,150] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2181
[2019-03-23 15:13:17,156] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6886922788817175, 6.9112, 6.9112, 77.32846344354104, 397779.2668036151, 397779.2668036151, 123464.9031336407], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1297800.0000, 
sim time next is 1298400.0000, 
raw observation next is [18.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.69231742960712, 6.911199999999999, 6.9112, 77.32846344354104, 399873.9731274626, 399873.9731274628, 123824.3715608344], 
processed observation next is [1.0, 0.0, 0.45454545454545453, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5604534708673142, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14810147152868985, 0.1481014715286899, 0.30201066234349855], 
reward next is 0.6980, 
noisyNet noise sample is [array([1.1234801], dtype=float32), 0.45603564]. 
=============================================
[2019-03-23 15:13:20,619] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.6186279e-15 1.1085648e-21 2.9536460e-11 1.7113426e-28], sum to 1.0000
[2019-03-23 15:13:20,629] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8049
[2019-03-23 15:13:20,632] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.66666666666667, 60.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3948635308596782, 6.911199999999999, 6.9112, 77.32846344354104, 229657.9727330955, 229657.9727330958, 64342.65389345588], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1811400.0000, 
sim time next is 1812000.0000, 
raw observation next is [15.33333333333333, 61.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3876509505942188, 6.911199999999999, 6.9112, 77.32846344354104, 225462.0662072988, 225462.0662072991, 63345.91981202422], 
processed observation next is [1.0, 1.0, 0.3333333333333332, 0.6166666666666667, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.12521564370602686, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08350446896566623, 0.08350446896566634, 0.15450224344396152], 
reward next is 0.8455, 
noisyNet noise sample is [array([-0.847078], dtype=float32), 0.845081]. 
=============================================
[2019-03-23 15:13:20,645] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[40.656742]
 [40.375725]
 [40.150524]
 [40.004807]
 [39.870094]], R is [[41.35402679]
 [41.78355408]
 [42.20653915]
 [42.62388611]
 [43.03576279]].
[2019-03-23 15:13:20,646] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135500, global step 2156469: loss 5.8941
[2019-03-23 15:13:20,648] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135500, global step 2156470: learning rate 0.0001
[2019-03-23 15:13:21,848] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.1357616e-04 4.6195659e-14 1.2947954e-18 9.9978644e-01 9.5146078e-27], sum to 1.0000
[2019-03-23 15:13:21,859] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8824
[2019-03-23 15:13:21,861] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.2465960020388203, 1.0, 2.0, 0.2465960020388203, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 562053.2479628029, 562053.2479628026, 178840.2822798431], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1383600.0000, 
sim time next is 1384200.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.2467382431691087, 1.0, 2.0, 0.2467382431691087, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 562374.0132666683, 562374.0132666683, 178867.8990605508], 
processed observation next is [0.0, 0.0, 0.5909090909090909, 1.0, 1.0, 1.0, 0.058422803961385855, 1.0, 1.0, 0.058422803961385855, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20828667158024752, 0.20828667158024752, 0.4362631684403678], 
reward next is 0.5637, 
noisyNet noise sample is [array([-1.719832], dtype=float32), 0.37599322]. 
=============================================
[2019-03-23 15:13:24,288] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135000, global step 2158410: loss 0.2869
[2019-03-23 15:13:24,289] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135000, global step 2158411: learning rate 0.0001
[2019-03-23 15:13:27,199] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135000, global step 2159945: loss 1.0983
[2019-03-23 15:13:27,201] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135000, global step 2159945: learning rate 0.0001
[2019-03-23 15:13:27,906] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135000, global step 2160322: loss 1.1964
[2019-03-23 15:13:27,908] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135000, global step 2160322: learning rate 0.0001
[2019-03-23 15:13:28,217] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135000, global step 2160487: loss 0.0018
[2019-03-23 15:13:28,219] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135000, global step 2160487: learning rate 0.0001
[2019-03-23 15:13:28,344] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135000, global step 2160556: loss 0.1575
[2019-03-23 15:13:28,346] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135000, global step 2160556: learning rate 0.0001
[2019-03-23 15:13:28,902] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135000, global step 2160852: loss 0.0002
[2019-03-23 15:13:28,904] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135000, global step 2160852: learning rate 0.0001
[2019-03-23 15:13:28,999] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135000, global step 2160906: loss 0.2109
[2019-03-23 15:13:29,003] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135000, global step 2160907: loss 0.2377
[2019-03-23 15:13:29,004] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135000, global step 2160907: learning rate 0.0001
[2019-03-23 15:13:29,005] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135000, global step 2160907: learning rate 0.0001
[2019-03-23 15:13:29,082] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135000, global step 2160942: loss 0.4392
[2019-03-23 15:13:29,084] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135000, global step 2160942: learning rate 0.0001
[2019-03-23 15:13:29,282] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135000, global step 2161048: loss 0.0554
[2019-03-23 15:13:29,282] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135000, global step 2161048: learning rate 0.0001
[2019-03-23 15:13:29,819] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135000, global step 2161337: loss 0.0021
[2019-03-23 15:13:29,820] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135000, global step 2161337: learning rate 0.0001
[2019-03-23 15:13:29,876] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135000, global step 2161365: loss 0.0110
[2019-03-23 15:13:29,878] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135000, global step 2161366: learning rate 0.0001
[2019-03-23 15:13:29,934] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135000, global step 2161391: loss 0.0125
[2019-03-23 15:13:29,935] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135000, global step 2161391: learning rate 0.0001
[2019-03-23 15:13:29,998] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135000, global step 2161426: loss 0.0308
[2019-03-23 15:13:30,000] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135000, global step 2161427: learning rate 0.0001
[2019-03-23 15:13:30,305] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135000, global step 2161591: loss 0.0648
[2019-03-23 15:13:30,313] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135000, global step 2161594: learning rate 0.0001
[2019-03-23 15:13:35,569] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136000, global step 2164376: loss 6.4963
[2019-03-23 15:13:35,571] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136000, global step 2164376: learning rate 0.0001
[2019-03-23 15:13:37,621] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.4649193e-02 6.8782894e-05 3.0396807e-06 9.6527892e-01 2.5845182e-10], sum to 1.0000
[2019-03-23 15:13:37,628] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7740
[2019-03-23 15:13:37,631] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.3166109490543633, 1.0, 2.0, 0.3166109490543633, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 699591.8766402586, 699591.8766402582, 172100.6760190794], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1684800.0000, 
sim time next is 1685400.0000, 
raw observation next is [19.18333333333333, 71.83333333333334, 1.0, 2.0, 0.3148060480597929, 1.0, 2.0, 0.3148060480597929, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 695493.0893424724, 695493.0893424724, 171795.5860534101], 
processed observation next is [1.0, 0.5217391304347826, 0.5083333333333332, 0.7183333333333334, 1.0, 1.0, 0.1435075600747411, 1.0, 1.0, 0.1435075600747411, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2575900330898046, 0.2575900330898046, 0.41901362452051244], 
reward next is 0.5810, 
noisyNet noise sample is [array([1.5032977], dtype=float32), 0.35108602]. 
=============================================
[2019-03-23 15:13:39,390] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135500, global step 2166393: loss 0.4374
[2019-03-23 15:13:39,392] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135500, global step 2166393: learning rate 0.0001
[2019-03-23 15:13:42,330] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135500, global step 2167952: loss 0.4075
[2019-03-23 15:13:42,333] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135500, global step 2167953: learning rate 0.0001
[2019-03-23 15:13:42,892] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135500, global step 2168252: loss 0.3744
[2019-03-23 15:13:42,896] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135500, global step 2168254: learning rate 0.0001
[2019-03-23 15:13:43,085] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135500, global step 2168350: loss 0.1643
[2019-03-23 15:13:43,086] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135500, global step 2168350: learning rate 0.0001
[2019-03-23 15:13:43,272] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135500, global step 2168450: loss 0.1501
[2019-03-23 15:13:43,275] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135500, global step 2168452: learning rate 0.0001
[2019-03-23 15:13:43,293] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 3.0636563e-24 0.0000000e+00 2.3717417e-30 0.0000000e+00], sum to 1.0000
[2019-03-23 15:13:43,300] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9435
[2019-03-23 15:13:43,305] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.0, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3688805632935128, 6.9112, 6.9112, 77.32846344354104, 214542.5944051744, 214542.5944051744, 65098.33464437886], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2262000.0000, 
sim time next is 2262600.0000, 
raw observation next is [14.0, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3667411376287053, 6.911200000000001, 6.9112, 77.32846344354104, 213298.0219976582, 213298.021997658, 64904.27334306101], 
processed observation next is [1.0, 0.17391304347826086, 0.2727272727272727, 0.82, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.09534448232672188, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07899926740654006, 0.07899926740654001, 0.15830310571478295], 
reward next is 0.8417, 
noisyNet noise sample is [array([0.3661943], dtype=float32), 1.1432519]. 
=============================================
[2019-03-23 15:13:43,726] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 7.0623744e-21 1.8512767e-37 9.7308435e-27 0.0000000e+00], sum to 1.0000
[2019-03-23 15:13:43,736] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2748
[2019-03-23 15:13:43,739] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.0, 40.0, 1.0, 1.0, 0.2327721985811987, 1.0, 1.0, 0.2327721985811987, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32825950686002, 505605.9126059067, 505605.9126059067, 136805.4238076542], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1785600.0000, 
sim time next is 1786200.0000, 
raw observation next is [19.03333333333333, 40.33333333333334, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7591746610137856, 7.356709876884691, 6.9112, 77.3273958369762, 586398.7014372578, 441708.2033208488, 91481.3106162166], 
processed observation next is [1.0, 0.6956521739130435, 0.5015151515151515, 0.40333333333333343, 0.0, 0.5, -0.25, 0.0, 0.5, -0.25, 1.0, 0.5, 0.6559638014482653, 0.04455098768846906, 0.0, 0.5084217934880383, 0.2171847042360214, 0.16359563085957363, 0.22312514784443072], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.26775596], dtype=float32), -0.58293945]. 
=============================================
[2019-03-23 15:13:43,828] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135500, global step 2168749: loss 0.0349
[2019-03-23 15:13:43,830] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135500, global step 2168749: learning rate 0.0001
[2019-03-23 15:13:43,913] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135500, global step 2168786: loss 0.0855
[2019-03-23 15:13:43,916] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135500, global step 2168786: learning rate 0.0001
[2019-03-23 15:13:44,044] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135500, global step 2168857: loss 0.0751
[2019-03-23 15:13:44,046] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135500, global step 2168857: learning rate 0.0001
[2019-03-23 15:13:44,184] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135500, global step 2168932: loss 0.0450
[2019-03-23 15:13:44,185] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135500, global step 2168932: learning rate 0.0001
[2019-03-23 15:13:44,434] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135500, global step 2169065: loss 0.0031
[2019-03-23 15:13:44,439] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135500, global step 2169065: learning rate 0.0001
[2019-03-23 15:13:44,778] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.000000e+00 2.813409e-23 0.000000e+00 8.426224e-28 0.000000e+00], sum to 1.0000
[2019-03-23 15:13:44,787] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5359
[2019-03-23 15:13:44,797] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.0, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4275719663995352, 6.9112, 6.9112, 77.32846344354104, 248686.504776765, 248686.504776765, 67445.10835255009], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1800600.0000, 
sim time next is 1801200.0000, 
raw observation next is [17.0, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.426188580410139, 6.9112, 6.9112, 77.32846344354104, 247881.6879957156, 247881.6879957156, 67301.92854028885], 
processed observation next is [1.0, 0.8695652173913043, 0.4090909090909091, 0.52, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1802694005859129, 0.0, 0.0, 0.5084288129206541, 0.09180803259100577, 0.09180803259100577, 0.1641510452202167], 
reward next is 0.8358, 
noisyNet noise sample is [array([-0.01723899], dtype=float32), -0.03362681]. 
=============================================
[2019-03-23 15:13:45,001] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135500, global step 2169363: loss 0.2412
[2019-03-23 15:13:45,002] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135500, global step 2169363: learning rate 0.0001
[2019-03-23 15:13:45,007] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135500, global step 2169364: loss 0.1858
[2019-03-23 15:13:45,008] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135500, global step 2169364: learning rate 0.0001
[2019-03-23 15:13:45,063] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135500, global step 2169395: loss 0.1610
[2019-03-23 15:13:45,065] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135500, global step 2169397: learning rate 0.0001
[2019-03-23 15:13:45,353] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135500, global step 2169552: loss 0.2288
[2019-03-23 15:13:45,355] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135500, global step 2169553: learning rate 0.0001
[2019-03-23 15:13:45,817] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135500, global step 2169793: loss 2.3470
[2019-03-23 15:13:45,818] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135500, global step 2169793: learning rate 0.0001
[2019-03-23 15:13:49,331] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0658270e-01 6.3939642e-06 7.1040132e-14 8.9341086e-01 2.6405898e-20], sum to 1.0000
[2019-03-23 15:13:49,344] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3707
[2019-03-23 15:13:49,353] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.0, 95.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 381782.9556472254, 381782.9556472254, 151389.4982811935], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1912200.0000, 
sim time next is 1912800.0000, 
raw observation next is [18.0, 96.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 383541.7866500721, 383541.7866500721, 151922.2496194268], 
processed observation next is [1.0, 0.13043478260869565, 0.45454545454545453, 0.96, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14205251357410076, 0.14205251357410076, 0.37054207224250435], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.22039224], dtype=float32), -0.7541231]. 
=============================================
[2019-03-23 15:13:50,812] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136500, global step 2172468: loss 1.6072
[2019-03-23 15:13:50,814] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136500, global step 2172468: learning rate 0.0001
[2019-03-23 15:13:51,177] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.0229471e-19 1.6160342e-33 4.6701616e-25 0.0000000e+00], sum to 1.0000
[2019-03-23 15:13:51,185] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2223
[2019-03-23 15:13:51,191] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1169528.3123259 W.
[2019-03-23 15:13:51,195] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 61.0, 1.0, 2.0, 0.5442968242381415, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9633914168941384, 6.922562898740703, 6.9112, 77.32843549189126, 1169528.3123259, 1165837.87656036, 261971.0197399151], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1951200.0000, 
sim time next is 1951800.0000, 
raw observation next is [25.83333333333334, 61.0, 1.0, 2.0, 0.3750100708204444, 1.0, 1.0, 0.3750100708204444, 1.0, 2.0, 0.7591586539198655, 6.9112, 6.9112, 77.3421103, 1282395.526859749, 1282395.526859749, 286851.8262036372], 
processed observation next is [1.0, 0.6086956521739131, 0.8106060606060609, 0.61, 1.0, 1.0, 0.2187625885255555, 1.0, 0.5, 0.2187625885255555, 1.0, 1.0, 0.6559409341712364, 0.0, 0.0, 0.5085185399722538, 0.4749613062443515, 0.4749613062443515, 0.699638600496676], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.658817], dtype=float32), -0.5727662]. 
=============================================
[2019-03-23 15:13:51,538] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 2.8686314e-26 0.0000000e+00 7.2154516e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 15:13:51,543] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5499
[2019-03-23 15:13:51,546] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 60.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.64561960449409, 6.911199999999999, 6.9112, 77.32846344354104, 374010.8483404958, 374010.8483404961, 118525.8447334371], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1975200.0000, 
sim time next is 1975800.0000, 
raw observation next is [22.0, 60.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6433487576526402, 6.911199999999999, 6.9112, 77.32846344354104, 372696.9819903087, 372696.981990309, 118319.5176498955], 
processed observation next is [1.0, 0.8695652173913043, 0.6363636363636364, 0.6, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.49049822521805747, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13803591925566988, 0.13803591925567002, 0.28858418938998903], 
reward next is 0.7114, 
noisyNet noise sample is [array([-0.331394], dtype=float32), 1.0190765]. 
=============================================
[2019-03-23 15:13:53,588] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 7.3609527e-22 0.0000000e+00 1.9304036e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 15:13:53,597] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9375
[2019-03-23 15:13:53,602] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 57.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6819983680362585, 6.911199999999999, 6.9112, 77.32846344275848, 393966.3044639339, 393966.3044639342, 122765.9429168445], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1971000.0000, 
sim time next is 1971600.0000, 
raw observation next is [22.66666666666666, 58.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.675319128275736, 6.911199999999999, 6.9112, 77.32846344353621, 390381.4012974974, 390381.4012974977, 121912.4563089604], 
processed observation next is [1.0, 0.8260869565217391, 0.6666666666666664, 0.58, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5361701832510515, -8.881784197001253e-17, 0.0, 0.5084288129206224, 0.14458570418425828, 0.1445857041842584, 0.29734745441209853], 
reward next is 0.7027, 
noisyNet noise sample is [array([-0.28647837], dtype=float32), 1.2963276]. 
=============================================
[2019-03-23 15:13:54,681] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136000, global step 2174384: loss 0.1411
[2019-03-23 15:13:54,682] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136000, global step 2174384: learning rate 0.0001
[2019-03-23 15:13:55,909] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 15:13:55,912] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:13:55,912] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:13:55,913] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:13:55,914] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:13:55,914] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:13:55,913] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:13:55,916] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:13:55,917] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:13:55,914] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:13:55,917] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:13:55,945] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run88
[2019-03-23 15:13:55,970] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run88
[2019-03-23 15:13:55,999] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run88
[2019-03-23 15:13:56,022] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run88
[2019-03-23 15:13:56,056] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run88
[2019-03-23 15:14:08,537] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.583992]
[2019-03-23 15:14:08,538] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.85937519333334, 82.08554112666667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.771199293216842, 7.573415951062905, 6.9112, 95.55132513375361, 704615.8883892428, 438858.3194644111, 141349.4613528237]
[2019-03-23 15:14:08,539] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:14:08,543] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0000000e+00 4.4850493e-19 1.1710991e-32 1.3624485e-24 0.0000000e+00], sampled 0.3891576382729386
[2019-03-23 15:14:08,545] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 704615.8883892428 W.
[2019-03-23 15:14:39,931] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.583992]
[2019-03-23 15:14:39,934] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.97525957666667, 87.70800726666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6759018138435677, 6.9112, 6.9112, 95.55334126025717, 390641.7002548883, 390641.7002548883, 126310.0569868219]
[2019-03-23 15:14:39,935] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:14:39,940] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 3.5991735e-23 0.0000000e+00 4.5300722e-31 0.0000000e+00], sampled 0.7680437504846908
[2019-03-23 15:15:08,792] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.583992]
[2019-03-23 15:15:08,794] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.86286264666667, 45.26843823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6372051538163945, 6.9112, 6.9112, 95.55338769695034, 369986.8586360328, 369986.8586360328, 121412.2215481444]
[2019-03-23 15:15:08,795] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:15:08,800] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0000000e+00 2.3455687e-22 0.0000000e+00 6.6747940e-30 0.0000000e+00], sampled 0.9389297890113709
[2019-03-23 15:15:13,260] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.583992]
[2019-03-23 15:15:13,261] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [8.8, 91.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 129943.02313596, 129943.02313596, 50140.85622717958]
[2019-03-23 15:15:13,264] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:15:13,267] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 5.8285872e-24 0.0000000e+00 4.0626343e-32 0.0000000e+00], sampled 0.3636231175389555
[2019-03-23 15:15:19,351] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.583992]
[2019-03-23 15:15:19,354] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.21589269666667, 73.35452784333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6945212703617821, 7.04936811817847, 6.9112, 95.55280317861585, 459320.3601614159, 403870.4859535741, 126266.4320174289]
[2019-03-23 15:15:19,357] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:15:19,359] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 3.3845466e-21 3.5652997e-37 3.8388100e-28 0.0000000e+00], sampled 0.526152004472106
[2019-03-23 15:15:31,565] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.583992]
[2019-03-23 15:15:31,567] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.47365493333333, 97.65440763666666, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.687485925740544, 6.960408774524894, 6.9112, 95.55310811350067, 417679.7488584946, 397931.1331787923, 126997.2886923157]
[2019-03-23 15:15:31,567] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:15:31,570] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0000000e+00 1.2427054e-19 5.6394994e-34 1.1882030e-25 0.0000000e+00], sampled 0.0611174426051968
[2019-03-23 15:15:41,408] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6553.1725 1698634175.0084 2957.0000
[2019-03-23 15:15:41,789] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6862.2842 1793014293.7888 2409.0000
[2019-03-23 15:15:41,822] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6328.7217 1723294598.4314 3425.0000
[2019-03-23 15:15:41,960] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6481.6076 1678885180.2952 3057.0000
[2019-03-23 15:15:41,968] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6294.9961 1685630448.6673 3228.0000
[2019-03-23 15:15:42,987] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 2175000, evaluation results [2175000.0, 6862.284208925443, 1793014293.78876, 2409.0, 6481.607577760913, 1678885180.2951708, 3057.0, 6294.9960618483565, 1685630448.6673346, 3228.0, 6328.721692698646, 1723294598.4313502, 3425.0, 6553.172466661831, 1698634175.0084193, 2957.0]
[2019-03-23 15:15:43,713] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 6.9272149e-25 0.0000000e+00 1.9239763e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 15:15:43,721] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4618
[2019-03-23 15:15:43,732] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.7, 51.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5647775561511789, 6.9112, 6.9112, 77.32846344354104, 328515.6032048526, 328515.6032048526, 102696.9099290466], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2057400.0000, 
sim time next is 2058000.0000, 
raw observation next is [21.46666666666667, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5579871671633011, 6.911199999999998, 6.9112, 77.32846344354104, 324564.5301464157, 324564.5301464162, 100966.3233835053], 
processed observation next is [0.0, 0.8260869565217391, 0.6121212121212122, 0.52, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.368553095947573, -1.7763568394002506e-16, 0.0, 0.5084288129206541, 0.12020908523941322, 0.12020908523941341, 0.24625932532562267], 
reward next is 0.7537, 
noisyNet noise sample is [array([-1.5500904], dtype=float32), -0.15645716]. 
=============================================
[2019-03-23 15:15:43,748] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[72.51919 ]
 [72.50913 ]
 [72.50823 ]
 [72.500565]
 [72.49438 ]], R is [[72.55944061]
 [72.58336639]
 [72.60305023]
 [72.61891174]
 [72.63083649]].
[2019-03-23 15:15:44,536] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136000, global step 2175821: loss 0.0468
[2019-03-23 15:15:44,538] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136000, global step 2175821: learning rate 0.0001
[2019-03-23 15:15:45,449] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136000, global step 2176307: loss 0.0035
[2019-03-23 15:15:45,451] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136000, global step 2176307: learning rate 0.0001
[2019-03-23 15:15:45,461] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136000, global step 2176312: loss 0.0045
[2019-03-23 15:15:45,463] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136000, global step 2176313: learning rate 0.0001
[2019-03-23 15:15:45,706] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136000, global step 2176440: loss 0.0060
[2019-03-23 15:15:45,710] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136000, global step 2176440: learning rate 0.0001
[2019-03-23 15:15:46,020] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136000, global step 2176610: loss 0.0383
[2019-03-23 15:15:46,022] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136000, global step 2176610: learning rate 0.0001
[2019-03-23 15:15:46,514] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136000, global step 2176873: loss 0.2398
[2019-03-23 15:15:46,522] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136000, global step 2176877: learning rate 0.0001
[2019-03-23 15:15:46,611] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136000, global step 2176915: loss 0.0065
[2019-03-23 15:15:46,614] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136000, global step 2176915: learning rate 0.0001
[2019-03-23 15:15:46,687] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136000, global step 2176964: loss 0.0086
[2019-03-23 15:15:46,692] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136000, global step 2176967: learning rate 0.0001
[2019-03-23 15:15:46,750] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136000, global step 2176989: loss 0.0072
[2019-03-23 15:15:46,752] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136000, global step 2176991: learning rate 0.0001
[2019-03-23 15:15:47,114] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 6.1214085e-19 1.3910771e-37 6.5866699e-30 0.0000000e+00], sum to 1.0000
[2019-03-23 15:15:47,122] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7685
[2019-03-23 15:15:47,127] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.5, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3951275222865317, 6.911199999999999, 6.9112, 77.32846344354104, 229811.5499915119, 229811.5499915121, 70908.5071991422], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2086200.0000, 
sim time next is 2086800.0000, 
raw observation next is [14.33333333333333, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.390547538955601, 6.9112, 6.9112, 77.32846344354104, 227147.1473005335, 227147.1473005335, 70272.13422164918], 
processed observation next is [0.0, 0.13043478260869565, 0.28787878787878773, 0.86, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.12935362707943004, 0.0, 0.0, 0.5084288129206541, 0.08412857307427167, 0.08412857307427167, 0.17139544932109554], 
reward next is 0.8286, 
noisyNet noise sample is [array([0.67928404], dtype=float32), -1.3024307]. 
=============================================
[2019-03-23 15:15:47,420] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136000, global step 2177344: loss 0.7652
[2019-03-23 15:15:47,425] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136000, global step 2177346: learning rate 0.0001
[2019-03-23 15:15:47,426] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136000, global step 2177347: loss 1.1595
[2019-03-23 15:15:47,432] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136000, global step 2177349: learning rate 0.0001
[2019-03-23 15:15:47,637] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136000, global step 2177455: loss 1.2824
[2019-03-23 15:15:47,639] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136000, global step 2177456: learning rate 0.0001
[2019-03-23 15:15:47,796] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136000, global step 2177543: loss 0.0645
[2019-03-23 15:15:47,798] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136000, global step 2177544: learning rate 0.0001
[2019-03-23 15:15:48,462] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136000, global step 2177893: loss 0.0310
[2019-03-23 15:15:48,466] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136000, global step 2177895: learning rate 0.0001
[2019-03-23 15:15:48,485] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.00000000e+00 4.82529019e-24 0.00000000e+00 1.05327785e-29
 0.00000000e+00], sum to 1.0000
[2019-03-23 15:15:48,493] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9108
[2019-03-23 15:15:48,497] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.16666666666667, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4882524682404386, 6.9112, 6.9112, 77.32846344354104, 283990.0999819834, 283990.0999819834, 89610.12621107695], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2173800.0000, 
sim time next is 2174400.0000, 
raw observation next is [15.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4775315786468612, 6.9112, 6.9112, 77.32846344354104, 277752.556703431, 277752.556703431, 87345.19923748534], 
processed observation next is [1.0, 0.17391304347826086, 0.3181818181818182, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2536165409240874, 0.0, 0.0, 0.5084288129206541, 0.10287131729756704, 0.10287131729756704, 0.21303707131093985], 
reward next is 0.7870, 
noisyNet noise sample is [array([0.37552267], dtype=float32), -0.19809264]. 
=============================================
[2019-03-23 15:15:53,431] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137000, global step 2180543: loss -42.6232
[2019-03-23 15:15:53,433] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137000, global step 2180543: learning rate 0.0001
[2019-03-23 15:15:53,862] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.00000000e+00 7.83498212e-13 8.25293809e-22 6.21466854e-14
 1.20398284e-29], sum to 1.0000
[2019-03-23 15:15:53,868] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2995
[2019-03-23 15:15:53,873] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.66666666666666, 67.66666666666667, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 1.0, 0.3016913901987064, 6.9112, 6.9112, 77.3421103, 511755.8792255441, 511755.8792255441, 202043.5972737025], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2719200.0000, 
sim time next is 2719800.0000, 
raw observation next is [25.0, 67.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.790185588082937, 7.439436952799153, 6.9112, 77.32720982437449, 619014.6601663216, 447456.8834847507, 140910.9305287784], 
processed observation next is [0.0, 0.4782608695652174, 0.7727272727272727, 0.67, 0.0, 0.5, -0.25, 0.0, 0.5, -0.25, 1.0, 1.0, 0.7002651258327672, 0.0528236952799153, 0.0, 0.5084205704692162, 0.22926468895048946, 0.1657247716610188, 0.3436851964116547], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.94494855], dtype=float32), 0.63535726]. 
=============================================
[2019-03-23 15:15:54,190] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 2.3320176e-21 0.0000000e+00 2.9855723e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 15:15:54,196] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1285
[2019-03-23 15:15:54,200] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.16666666666667, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.458241276541537, 6.911199999999999, 6.9112, 77.32846344354104, 266529.4269847099, 266529.4269847102, 82311.96638694091], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2249400.0000, 
sim time next is 2250000.0000, 
raw observation next is [15.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4479663291204654, 6.911200000000001, 6.9112, 77.32846344354104, 260551.5512934966, 260551.5512934963, 80327.69291734174], 
processed observation next is [1.0, 0.043478260869565216, 0.3181818181818182, 0.88, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.21138047017209347, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09650057455314688, 0.09650057455314678, 0.19592120223741888], 
reward next is 0.8041, 
noisyNet noise sample is [array([0.96248466], dtype=float32), 1.7051212]. 
=============================================
[2019-03-23 15:15:54,216] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[73.58918 ]
 [73.42822 ]
 [73.213936]
 [73.09379 ]
 [72.73897 ]], R is [[73.82955933]
 [73.89050293]
 [73.94579315]
 [73.99530029]
 [74.03896332]].
[2019-03-23 15:15:56,649] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 5.2175244e-23 0.0000000e+00 1.6759102e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 15:15:56,663] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5304
[2019-03-23 15:15:56,670] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 557680.4521468236 W.
[2019-03-23 15:15:56,674] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.83333333333333, 46.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7504972006291415, 7.28386920496456, 6.9112, 77.32755987421406, 557680.4521468236, 436646.5310540979, 101538.3016603985], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2307000.0000, 
sim time next is 2307600.0000, 
raw observation next is [21.0, 46.0, 1.0, 1.0, 0.4765926240529666, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32823950291515, 517611.2614018999, 517611.2614018999, 110927.1375833142], 
processed observation next is [1.0, 0.7391304347826086, 0.5909090909090909, 0.46, 1.0, 0.5, 0.34574078006620823, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084273405279346, 0.19170787459329627, 0.19170787459329627, 0.2705539941056444], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.8975619], dtype=float32), 0.96515286]. 
=============================================
[2019-03-23 15:15:57,100] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136500, global step 2182381: loss 0.0046
[2019-03-23 15:15:57,102] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136500, global step 2182382: learning rate 0.0001
[2019-03-23 15:15:59,829] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136500, global step 2183831: loss 0.0563
[2019-03-23 15:15:59,831] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136500, global step 2183833: learning rate 0.0001
[2019-03-23 15:16:00,797] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136500, global step 2184354: loss 0.1002
[2019-03-23 15:16:00,806] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136500, global step 2184354: learning rate 0.0001
[2019-03-23 15:16:00,841] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136500, global step 2184373: loss 0.0506
[2019-03-23 15:16:00,844] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136500, global step 2184373: learning rate 0.0001
[2019-03-23 15:16:00,926] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136500, global step 2184421: loss 0.0419
[2019-03-23 15:16:00,927] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136500, global step 2184421: learning rate 0.0001
[2019-03-23 15:16:01,224] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136500, global step 2184579: loss 0.0001
[2019-03-23 15:16:01,225] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136500, global step 2184580: learning rate 0.0001
[2019-03-23 15:16:01,840] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136500, global step 2184909: loss 0.1436
[2019-03-23 15:16:01,844] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136500, global step 2184909: learning rate 0.0001
[2019-03-23 15:16:01,931] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136500, global step 2184952: loss 0.0307
[2019-03-23 15:16:01,932] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136500, global step 2184953: learning rate 0.0001
[2019-03-23 15:16:01,938] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136500, global step 2184957: loss 0.0148
[2019-03-23 15:16:01,941] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136500, global step 2184958: learning rate 0.0001
[2019-03-23 15:16:02,134] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136500, global step 2185064: loss 0.0206
[2019-03-23 15:16:02,138] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136500, global step 2185065: learning rate 0.0001
[2019-03-23 15:16:02,372] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136500, global step 2185195: loss 0.0077
[2019-03-23 15:16:02,374] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136500, global step 2185196: learning rate 0.0001
[2019-03-23 15:16:02,462] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136500, global step 2185239: loss 0.0004
[2019-03-23 15:16:02,463] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136500, global step 2185240: learning rate 0.0001
[2019-03-23 15:16:02,635] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136500, global step 2185328: loss 0.0002
[2019-03-23 15:16:02,638] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136500, global step 2185330: learning rate 0.0001
[2019-03-23 15:16:03,147] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136500, global step 2185603: loss 0.0519
[2019-03-23 15:16:03,149] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136500, global step 2185604: learning rate 0.0001
[2019-03-23 15:16:03,562] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.000000e+00 9.653232e-21 0.000000e+00 4.183731e-27 0.000000e+00], sum to 1.0000
[2019-03-23 15:16:03,569] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2329
[2019-03-23 15:16:03,574] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4145180795867759, 6.9112, 6.9112, 77.32846344354104, 241092.1573503336, 241092.1573503336, 74698.28454394631], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2430000.0000, 
sim time next is 2430600.0000, 
raw observation next is [14.0, 94.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4190598327671958, 6.911200000000001, 6.9112, 77.32846344354104, 243734.3953656263, 243734.395365626, 75059.76218573123], 
processed observation next is [1.0, 0.13043478260869565, 0.2727272727272727, 0.9400000000000002, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.17008547538170826, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09027199828356529, 0.09027199828356519, 0.18307259069690546], 
reward next is 0.8169, 
noisyNet noise sample is [array([-0.72777116], dtype=float32), 1.1605881]. 
=============================================
[2019-03-23 15:16:03,772] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136500, global step 2185929: loss 0.0121
[2019-03-23 15:16:03,773] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136500, global step 2185929: learning rate 0.0001
[2019-03-23 15:16:05,866] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.9568192e-18 0.0000000e+00 8.6598357e-29 0.0000000e+00], sum to 1.0000
[2019-03-23 15:16:05,873] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4740
[2019-03-23 15:16:05,879] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 852082.0983036256 W.
[2019-03-23 15:16:05,885] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.1, 62.0, 1.0, 2.0, 0.2541792255454546, 1.0, 2.0, 0.2541792255454546, 1.0, 1.0, 0.4928320555359465, 6.911199999999998, 6.9112, 77.3421103, 852082.0983036256, 852082.0983036262, 221665.4586069616], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2478600.0000, 
sim time next is 2479200.0000, 
raw observation next is [21.06666666666667, 61.33333333333334, 1.0, 2.0, 0.3826301952462996, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7315199251809378, 6.9112, 6.9112, 77.32846344354104, 846271.7806536286, 846271.7806536286, 194934.1166340229], 
processed observation next is [1.0, 0.6956521739130435, 0.5939393939393941, 0.6133333333333334, 1.0, 1.0, 0.22828774405787447, 0.0, 0.5, -0.25, 1.0, 1.0, 0.6164570359727684, 0.0, 0.0, 0.5084288129206541, 0.31343399283467727, 0.31343399283467727, 0.4754490649610315], 
reward next is 0.5246, 
noisyNet noise sample is [array([-1.6730167], dtype=float32), -1.9761639]. 
=============================================
[2019-03-23 15:16:06,487] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 2.8048390e-21 0.0000000e+00 4.9910393e-28 0.0000000e+00], sum to 1.0000
[2019-03-23 15:16:06,493] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2511
[2019-03-23 15:16:06,498] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.0, 76.33333333333334, 1.0, 1.0, 0.471448311677062, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32817151318369, 512021.2541040856, 512021.2541040856, 122697.0106690513], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2466600.0000, 
sim time next is 2467200.0000, 
raw observation next is [18.0, 75.66666666666667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8148479840545073, 7.824147540199792, 6.9112, 77.32642006979944, 770689.1409859193, 474190.2880061665, 124395.3414298618], 
processed observation next is [1.0, 0.5652173913043478, 0.45454545454545453, 0.7566666666666667, 0.0, 0.5, -0.25, 0.0, 1.0, -0.25, 1.0, 0.5, 0.7354971200778676, 0.09129475401997925, 0.0, 0.50841537789247, 0.2854404225873775, 0.1756260325948765, 0.30340327178015075], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7086257], dtype=float32), -1.3592633]. 
=============================================
[2019-03-23 15:16:09,799] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137500, global step 2189118: loss -114.0654
[2019-03-23 15:16:09,802] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137500, global step 2189118: learning rate 0.0001
[2019-03-23 15:16:11,786] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.4928797e-01 1.2206758e-06 3.5018850e-12 4.5071086e-01 4.4445502e-18], sum to 1.0000
[2019-03-23 15:16:11,796] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0233
[2019-03-23 15:16:11,807] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 583457.4722147689 W.
[2019-03-23 15:16:11,811] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.5, 86.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7760642274040359, 7.349249754936181, 6.9112, 77.32741725772654, 583457.4722147689, 441189.79626047, 137941.0870250182], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2710800.0000, 
sim time next is 2711400.0000, 
raw observation next is [21.71666666666667, 84.66666666666667, 1.0, 1.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3189257697806117, 6.9112, 6.9112, 77.3421103, 541913.1415748872, 541913.1415748872, 204879.3433864118], 
processed observation next is [0.0, 0.391304347826087, 0.6234848484848485, 0.8466666666666667, 1.0, 0.5, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.027036813972302464, 0.0, 0.0, 0.5085185399722538, 0.20070857095366193, 0.20070857095366193, 0.4997057155766142], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3660511], dtype=float32), -0.5742978]. 
=============================================
[2019-03-23 15:16:11,843] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137000, global step 2190205: loss -2.3356
[2019-03-23 15:16:11,844] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137000, global step 2190205: learning rate 0.0001
[2019-03-23 15:16:14,814] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137000, global step 2191781: loss 23.3137
[2019-03-23 15:16:14,815] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137000, global step 2191781: learning rate 0.0001
[2019-03-23 15:16:15,744] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137000, global step 2192250: loss 32.3464
[2019-03-23 15:16:15,745] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137000, global step 2192250: learning rate 0.0001
[2019-03-23 15:16:15,826] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137000, global step 2192292: loss 33.0968
[2019-03-23 15:16:15,828] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137000, global step 2192292: learning rate 0.0001
[2019-03-23 15:16:15,932] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137000, global step 2192344: loss 16.3328
[2019-03-23 15:16:15,934] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137000, global step 2192344: learning rate 0.0001
[2019-03-23 15:16:16,378] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137000, global step 2192576: loss 16.5200
[2019-03-23 15:16:16,381] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137000, global step 2192576: learning rate 0.0001
[2019-03-23 15:16:16,889] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137000, global step 2192849: loss -43.0811
[2019-03-23 15:16:16,890] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137000, global step 2192850: learning rate 0.0001
[2019-03-23 15:16:16,898] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137000, global step 2192855: loss -35.2169
[2019-03-23 15:16:16,900] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137000, global step 2192855: learning rate 0.0001
[2019-03-23 15:16:17,087] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137000, global step 2192946: loss -73.9982
[2019-03-23 15:16:17,089] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137000, global step 2192947: learning rate 0.0001
[2019-03-23 15:16:17,113] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137000, global step 2192957: loss 22.5667
[2019-03-23 15:16:17,117] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137000, global step 2192957: learning rate 0.0001
[2019-03-23 15:16:17,234] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137000, global step 2193023: loss -11.7939
[2019-03-23 15:16:17,237] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137000, global step 2193024: learning rate 0.0001
[2019-03-23 15:16:17,479] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137000, global step 2193148: loss 6.9324
[2019-03-23 15:16:17,481] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137000, global step 2193148: learning rate 0.0001
[2019-03-23 15:16:17,817] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137000, global step 2193326: loss -8.5396
[2019-03-23 15:16:17,818] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137000, global step 2193328: learning rate 0.0001
[2019-03-23 15:16:18,478] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137000, global step 2193676: loss -6.2413
[2019-03-23 15:16:18,480] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137000, global step 2193676: learning rate 0.0001
[2019-03-23 15:16:18,698] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137000, global step 2193790: loss 15.8434
[2019-03-23 15:16:18,704] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137000, global step 2193790: learning rate 0.0001
[2019-03-23 15:16:21,677] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 5.0101248e-09 2.7721291e-14 6.5477435e-10 1.6718300e-17], sum to 1.0000
[2019-03-23 15:16:21,682] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8690
[2019-03-23 15:16:21,688] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1325845.765333307 W.
[2019-03-23 15:16:21,693] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.03333333333333, 51.83333333333334, 1.0, 2.0, 0.3909418295921011, 1.0, 2.0, 0.3909418295921011, 1.0, 1.0, 0.791146071956605, 6.911199999999999, 6.9112, 77.3421103, 1325845.765333307, 1325845.765333308, 300230.9290216263], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2825400.0000, 
sim time next is 2826000.0000, 
raw observation next is [29.0, 52.0, 1.0, 2.0, 0.6461568343587085, 1.0, 2.0, 0.6461568343587085, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1462331.164558161, 1462331.164558161, 273100.72468869], 
processed observation next is [1.0, 0.7391304347826086, 0.9545454545454546, 0.52, 1.0, 1.0, 0.5576960429483856, 1.0, 1.0, 0.5576960429483856, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.5416041350215411, 0.5416041350215411, 0.666099328509], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.89102393], dtype=float32), 0.9930554]. 
=============================================
[2019-03-23 15:16:21,709] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[20.875574]
 [20.920403]
 [19.674057]
 [19.804987]
 [18.713858]], R is [[19.62723541]
 [19.43096352]
 [19.59894943]
 [19.61745834]
 [19.42128372]].
[2019-03-23 15:16:24,708] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5485448e-10 2.7503737e-17 2.7333557e-25 1.0000000e+00 1.7616957e-37], sum to 1.0000
[2019-03-23 15:16:24,719] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9895
[2019-03-23 15:16:24,731] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.2249735651637831, 1.0, 2.0, 0.2249735651637831, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 513007.0155125057, 513007.0155125057, 171592.9691175077], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2866800.0000, 
sim time next is 2867400.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.2199134941528162, 1.0, 2.0, 0.2199134941528162, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 501420.6203256934, 501420.6203256931, 170769.0162155046], 
processed observation next is [1.0, 0.17391304347826086, 0.5909090909090909, 0.88, 1.0, 1.0, 0.024891867691020225, 1.0, 1.0, 0.024891867691020225, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18571134086136792, 0.1857113408613678, 0.41650979564757223], 
reward next is 0.5835, 
noisyNet noise sample is [array([-0.25491711], dtype=float32), -2.3130882]. 
=============================================
[2019-03-23 15:16:24,929] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3898503e-13 5.9002105e-19 4.4680293e-24 1.0000000e+00 2.7041899e-34], sum to 1.0000
[2019-03-23 15:16:24,937] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9374
[2019-03-23 15:16:24,943] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 74.0, 1.0, 2.0, 0.6242082887426659, 1.0, 2.0, 0.6242082887426659, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1403852.010347672, 1403852.010347672, 268888.3451898507], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2885400.0000, 
sim time next is 2886000.0000, 
raw observation next is [26.0, 74.0, 1.0, 2.0, 0.6452956529560196, 1.0, 2.0, 0.6452956529560196, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1451338.529101918, 1451338.529101918, 275066.5240412281], 
processed observation next is [1.0, 0.391304347826087, 0.8181818181818182, 0.74, 1.0, 1.0, 0.5566195661950245, 1.0, 1.0, 0.5566195661950245, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.537532788556266, 0.537532788556266, 0.6708939610761662], 
reward next is 0.3291, 
noisyNet noise sample is [array([0.46312717], dtype=float32), -0.76003325]. 
=============================================
[2019-03-23 15:16:24,961] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[59.608707]
 [59.99675 ]
 [60.3914  ]
 [60.12617 ]
 [59.98037 ]], R is [[58.92414474]
 [58.67907715]
 [58.44932938]
 [58.20743942]
 [58.02166748]].
[2019-03-23 15:16:25,258] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138000, global step 2197295: loss 0.1789
[2019-03-23 15:16:25,260] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138000, global step 2197296: learning rate 0.0001
[2019-03-23 15:16:27,542] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137500, global step 2198445: loss 0.1206
[2019-03-23 15:16:27,543] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137500, global step 2198445: learning rate 0.0001
[2019-03-23 15:16:29,430] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9999821e-01 3.0865943e-10 1.0419455e-16 1.7466708e-06 1.1076666e-21], sum to 1.0000
[2019-03-23 15:16:29,437] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6483
[2019-03-23 15:16:29,451] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 631101.35308026 W.
[2019-03-23 15:16:29,456] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 93.16666666666667, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.374636960297645, 6.911199999999999, 6.9112, 77.3421103, 631101.35308026, 631101.3530802602, 221197.984828526], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2959800.0000, 
sim time next is 2960400.0000, 
raw observation next is [22.33333333333334, 92.33333333333334, 1.0, 2.0, 0.5495495027034142, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 626282.6173160598, 626282.61731606, 148670.8116692436], 
processed observation next is [1.0, 0.2608695652173913, 0.6515151515151518, 0.9233333333333335, 1.0, 1.0, 0.4369368783792677, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.231956524931874, 0.23195652493187408, 0.3626117357786429], 
reward next is 0.6374, 
noisyNet noise sample is [array([-0.20139098], dtype=float32), -0.72045636]. 
=============================================
[2019-03-23 15:16:30,202] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137500, global step 2199766: loss 36.9033
[2019-03-23 15:16:30,205] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137500, global step 2199767: learning rate 0.0001
[2019-03-23 15:16:30,659] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 15:16:30,660] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:16:30,661] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:16:30,661] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:16:30,662] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:16:30,662] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:16:30,663] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:16:30,666] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:16:30,664] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:16:30,668] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:16:30,669] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:16:30,692] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run89
[2019-03-23 15:16:30,724] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run89
[2019-03-23 15:16:30,750] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run89
[2019-03-23 15:16:30,775] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run89
[2019-03-23 15:16:30,775] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run89
[2019-03-23 15:16:36,034] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.57996994]
[2019-03-23 15:16:36,034] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.7618215, 56.15473903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3344856728989822, 6.911199999999999, 6.9112, 95.55338769695034, 194965.2666284888, 194965.2666284891, 63670.89986377919]
[2019-03-23 15:16:36,034] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:16:36,040] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0000000e+00 3.0787156e-21 6.7859994e-34 4.2663151e-26 0.0000000e+00], sampled 0.6575667867285893
[2019-03-23 15:16:56,122] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.57996994]
[2019-03-23 15:16:56,125] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [10.101670086, 97.46806567499999, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7182566720493724, 7.263210881560641, 6.9112, 95.55225130858203, 559416.364504092, 418147.5491874929, 90455.87647042562]
[2019-03-23 15:16:56,127] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:16:56,131] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.9999392e-01 4.1789829e-09 5.0456120e-14 6.0746379e-06 1.4112209e-19], sampled 0.18238340800209096
[2019-03-23 15:16:56,134] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 559416.364504092 W.
[2019-03-23 15:17:05,599] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.57996994]
[2019-03-23 15:17:05,599] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.46666666666667, 70.33333333333334, 1.0, 1.0, 0.4510253504338513, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 95.553149194742, 513019.3910579392, 513019.3910579392, 137073.9354082094]
[2019-03-23 15:17:05,601] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:17:05,606] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.6084163e-01 3.9200104e-06 5.3720701e-11 6.3915449e-01 8.3822519e-17], sampled 0.4505521168218972
[2019-03-23 15:17:39,942] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.57996994]
[2019-03-23 15:17:39,943] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.1, 54.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5013141613918682, 6.911199999999999, 6.9112, 95.55338769695034, 291572.9887113908, 291572.9887113911, 93723.37242260105]
[2019-03-23 15:17:39,944] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:17:39,950] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 9.1602343e-20 4.0491600e-31 7.1601015e-24 0.0000000e+00], sampled 0.6059575805757778
[2019-03-23 15:17:56,735] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.57996994]
[2019-03-23 15:17:56,736] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.56666666666667, 79.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5085231774132155, 6.911199999999999, 6.9112, 95.55338769695034, 295766.9088144458, 295766.9088144462, 101856.1303778772]
[2019-03-23 15:17:56,739] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:17:56,740] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 3.6789609e-17 9.2162866e-26 8.8228015e-19 4.2939585e-33], sampled 0.3385087885674347
[2019-03-23 15:18:00,210] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.57996994]
[2019-03-23 15:18:00,211] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [12.27858436, 93.04039453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3502605226642018, 6.911199999999999, 6.9112, 95.55338769695034, 203702.6921461791, 203702.6921461794, 66205.95044778744]
[2019-03-23 15:18:00,212] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:18:00,216] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 7.0546737e-21 1.7288644e-33 1.2402626e-25 0.0000000e+00], sampled 0.4332605833091846
[2019-03-23 15:18:02,004] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.57996994]
[2019-03-23 15:18:02,005] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.6, 88.33333333333334, 1.0, 2.0, 0.2742912738211308, 1.0, 2.0, 0.2742912738211308, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 621055.3453447026, 621055.3453447022, 191358.5958082197]
[2019-03-23 15:18:02,007] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:18:02,012] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.3598471e-03 2.1221224e-07 1.1038662e-11 9.9863988e-01 1.0355127e-17], sampled 0.8006032523228871
[2019-03-23 15:18:06,691] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.57996994]
[2019-03-23 15:18:06,693] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.1, 76.66666666666666, 1.0, 2.0, 0.2688880551502773, 1.0, 2.0, 0.2688880551502773, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 609423.9875720285, 609423.9875720282, 190134.4116704845]
[2019-03-23 15:18:06,695] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:18:06,698] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.5366671e-02 7.7032058e-07 1.7071077e-11 9.8463249e-01 1.6829459e-17], sampled 0.9447337675225107
[2019-03-23 15:18:16,661] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 7017.6810 1912948844.9277 1670.0000
[2019-03-23 15:18:16,791] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6374.1920 1878062643.7263 2015.0000
[2019-03-23 15:18:16,897] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.57996994]
[2019-03-23 15:18:16,898] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.4, 66.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4645098894944312, 6.911199999999999, 6.9112, 95.55338769695034, 270162.1765404893, 270162.1765404897, 84973.75789916751]
[2019-03-23 15:18:16,898] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:18:16,900] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 4.5254340e-20 9.5335842e-32 2.4859886e-24 0.0000000e+00], sampled 0.010989673059213056
[2019-03-23 15:18:16,969] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6625.2961 1847581762.8993 2330.0000
[2019-03-23 15:18:16,996] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6608.8216 1860006245.8589 1830.0000
[2019-03-23 15:18:17,010] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6620.5566 1857126108.5135 2254.0000
[2019-03-23 15:18:18,025] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 2200000, evaluation results [2200000.0, 7017.681043878039, 1912948844.9277427, 1670.0, 6620.556639222746, 1857126108.5134776, 2254.0, 6374.192037181953, 1878062643.7262845, 2015.0, 6625.296099761395, 1847581762.8993106, 2330.0, 6608.821630712838, 1860006245.8588672, 1830.0]
[2019-03-23 15:18:18,496] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137500, global step 2200248: loss -7.0460
[2019-03-23 15:18:18,498] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137500, global step 2200248: learning rate 0.0001
[2019-03-23 15:18:18,741] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137500, global step 2200382: loss 31.7431
[2019-03-23 15:18:18,744] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137500, global step 2200383: learning rate 0.0001
[2019-03-23 15:18:19,086] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137500, global step 2200558: loss 45.7567
[2019-03-23 15:18:19,089] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137500, global step 2200558: learning rate 0.0001
[2019-03-23 15:18:19,262] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137500, global step 2200651: loss 0.4592
[2019-03-23 15:18:19,266] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137500, global step 2200652: learning rate 0.0001
[2019-03-23 15:18:19,565] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137500, global step 2200814: loss 0.3366
[2019-03-23 15:18:19,568] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137500, global step 2200814: learning rate 0.0001
[2019-03-23 15:18:19,766] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137500, global step 2200915: loss 0.0877
[2019-03-23 15:18:19,768] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137500, global step 2200915: learning rate 0.0001
[2019-03-23 15:18:19,863] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137500, global step 2200973: loss 0.0415
[2019-03-23 15:18:19,864] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137500, global step 2200973: learning rate 0.0001
[2019-03-23 15:18:19,904] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137500, global step 2200989: loss 0.1808
[2019-03-23 15:18:19,907] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137500, global step 2200991: learning rate 0.0001
[2019-03-23 15:18:19,931] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137500, global step 2201000: loss 0.1435
[2019-03-23 15:18:19,932] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137500, global step 2201000: learning rate 0.0001
[2019-03-23 15:18:20,476] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137500, global step 2201294: loss 0.0109
[2019-03-23 15:18:20,477] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137500, global step 2201294: learning rate 0.0001
[2019-03-23 15:18:20,498] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137500, global step 2201303: loss 0.0483
[2019-03-23 15:18:20,499] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137500, global step 2201303: learning rate 0.0001
[2019-03-23 15:18:21,190] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137500, global step 2201667: loss -81.4946
[2019-03-23 15:18:21,192] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137500, global step 2201667: learning rate 0.0001
[2019-03-23 15:18:21,320] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137500, global step 2201733: loss -127.1448
[2019-03-23 15:18:21,323] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137500, global step 2201734: learning rate 0.0001
[2019-03-23 15:18:24,563] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 3.5583558e-15 3.0759130e-19 2.7399883e-15 8.1675762e-26], sum to 1.0000
[2019-03-23 15:18:24,574] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2478
[2019-03-23 15:18:24,584] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 986768.4705217863 W.
[2019-03-23 15:18:24,589] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.0, 69.0, 1.0, 2.0, 0.4322138247540588, 1.0, 2.0, 0.4322138247540588, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 986768.4705217863, 986768.4705217863, 211273.7592473916], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3146400.0000, 
sim time next is 3147000.0000, 
raw observation next is [24.33333333333333, 68.33333333333333, 1.0, 2.0, 0.3915125572800856, 1.0, 2.0, 0.3915125572800856, 1.0, 1.0, 0.7920482048869807, 6.9112, 6.9112, 85.90013989615356, 1339800.270530605, 1339800.270530605, 296794.284617402], 
processed observation next is [1.0, 0.43478260869565216, 0.7424242424242422, 0.6833333333333332, 1.0, 1.0, 0.23939069660010698, 1.0, 1.0, 0.23939069660010698, 1.0, 0.5, 0.7029260069814011, 0.0, 0.0, 0.564786938887086, 0.4962223224187426, 0.4962223224187426, 0.7238884990668342], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4264045], dtype=float32), 0.52411544]. 
=============================================
[2019-03-23 15:18:24,599] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[27.51115 ]
 [27.538965]
 [27.24557 ]
 [27.005527]
 [27.033216]], R is [[27.18315697]
 [27.3960228 ]
 [27.52079773]
 [27.64693832]
 [27.37047005]].
[2019-03-23 15:18:27,779] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138500, global step 2205135: loss 0.4310
[2019-03-23 15:18:27,784] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138500, global step 2205135: learning rate 0.0001
[2019-03-23 15:18:29,573] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 4.9115519e-13 4.3144759e-21 9.3090737e-11 1.4124672e-28], sum to 1.0000
[2019-03-23 15:18:29,579] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1199
[2019-03-23 15:18:29,583] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 66.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7245540575624223, 7.00803656962984, 6.9112, 77.32808860151471, 448929.5529228112, 417479.1682107586, 127888.9532725433], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3231000.0000, 
sim time next is 3231600.0000, 
raw observation next is [22.0, 65.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7192262228704734, 6.967415346518447, 6.9112, 77.32820226560406, 432913.9325373492, 414656.3994561094, 127138.0517338654], 
processed observation next is [0.0, 0.391304347826087, 0.6363636363636364, 0.6566666666666667, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5988946041006764, 0.005621534651844673, 0.0, 0.5084270956954237, 0.16033849353235155, 0.15357644424300348, 0.3100928091069888], 
reward next is 0.4088, 
noisyNet noise sample is [array([-1.0533322], dtype=float32), 0.32854176]. 
=============================================
[2019-03-23 15:18:29,749] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138000, global step 2206187: loss 0.0247
[2019-03-23 15:18:29,752] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138000, global step 2206188: learning rate 0.0001
[2019-03-23 15:18:30,759] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 2.6611226e-23 3.0444249e-37 4.6691923e-28 0.0000000e+00], sum to 1.0000
[2019-03-23 15:18:30,769] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0380
[2019-03-23 15:18:30,778] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.16666666666667, 72.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.705584982030824, 6.911199999999999, 6.9112, 77.32844510325086, 406821.527358598, 406821.5273585983, 125692.9120720715], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3226200.0000, 
sim time next is 3226800.0000, 
raw observation next is [21.33333333333334, 71.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7150795581078987, 6.931244370067843, 6.9112, 77.32837481391778, 418652.792444694, 412142.7984863307, 126791.228876316], 
processed observation next is [0.0, 0.34782608695652173, 0.6060606060606063, 0.7166666666666667, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5929707972969982, 0.002004437006784343, 0.0, 0.508428230187568, 0.1550565897943311, 0.15264548092086322, 0.3092468996983317], 
reward next is 0.5905, 
noisyNet noise sample is [array([0.4147327], dtype=float32), -0.58343816]. 
=============================================
[2019-03-23 15:18:32,899] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138000, global step 2207866: loss 0.0684
[2019-03-23 15:18:32,900] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138000, global step 2207866: learning rate 0.0001
[2019-03-23 15:18:33,017] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.4394576e-28 0.0000000e+00 1.8727803e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 15:18:33,026] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9524
[2019-03-23 15:18:33,030] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.66666666666667, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4362431147498476, 6.911200000000001, 6.9112, 77.32846344354104, 253731.176121978, 253731.1761219777, 78477.48040781589], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3300000.0000, 
sim time next is 3300600.0000, 
raw observation next is [14.33333333333333, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4288388419860815, 6.911200000000001, 6.9112, 77.32846344354104, 249423.5401037422, 249423.5401037419, 77060.730392568], 
processed observation next is [0.0, 0.17391304347826086, 0.28787878787878773, 0.92, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.18405548855154505, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09237908892731193, 0.09237908892731181, 0.18795300095748294], 
reward next is 0.8120, 
noisyNet noise sample is [array([0.06518336], dtype=float32), 1.1655309]. 
=============================================
[2019-03-23 15:18:33,572] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138000, global step 2208222: loss 0.1196
[2019-03-23 15:18:33,574] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138000, global step 2208223: learning rate 0.0001
[2019-03-23 15:18:33,898] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138000, global step 2208397: loss 0.0268
[2019-03-23 15:18:33,905] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138000, global step 2208398: learning rate 0.0001
[2019-03-23 15:18:34,245] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138000, global step 2208581: loss 0.0069
[2019-03-23 15:18:34,249] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138000, global step 2208581: learning rate 0.0001
[2019-03-23 15:18:34,453] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138000, global step 2208688: loss 0.0446
[2019-03-23 15:18:34,454] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138000, global step 2208688: learning rate 0.0001
[2019-03-23 15:18:34,600] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138000, global step 2208766: loss 0.0015
[2019-03-23 15:18:34,601] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138000, global step 2208766: learning rate 0.0001
[2019-03-23 15:18:34,910] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138000, global step 2208929: loss 0.0062
[2019-03-23 15:18:34,911] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138000, global step 2208929: learning rate 0.0001
[2019-03-23 15:18:34,927] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138000, global step 2208936: loss 0.0000
[2019-03-23 15:18:34,930] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138000, global step 2208937: learning rate 0.0001
[2019-03-23 15:18:35,070] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138000, global step 2209011: loss 0.0000
[2019-03-23 15:18:35,075] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138000, global step 2209012: learning rate 0.0001
[2019-03-23 15:18:35,128] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138000, global step 2209036: loss 0.0000
[2019-03-23 15:18:35,133] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138000, global step 2209039: learning rate 0.0001
[2019-03-23 15:18:35,491] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138000, global step 2209232: loss 0.0082
[2019-03-23 15:18:35,494] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138000, global step 2209236: learning rate 0.0001
[2019-03-23 15:18:35,569] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138000, global step 2209271: loss 0.0001
[2019-03-23 15:18:35,574] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138000, global step 2209272: learning rate 0.0001
[2019-03-23 15:18:35,637] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 6.2572595e-26 0.0000000e+00 4.4022932e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 15:18:35,646] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1842
[2019-03-23 15:18:35,651] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.0, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5195121024145302, 6.911199999999999, 6.9112, 77.32846344354104, 302177.7900688088, 302177.7900688091, 98178.32526153019], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3312600.0000, 
sim time next is 3313200.0000, 
raw observation next is [19.0, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.524201554710987, 6.9112, 6.9112, 77.32846344354104, 304906.2973407179, 304906.2973407179, 98573.95631746315], 
processed observation next is [0.0, 0.34782608695652173, 0.5, 0.68, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.32028793530141, 0.0, 0.0, 0.5084288129206541, 0.11292825827433997, 0.11292825827433997, 0.24042428370112962], 
reward next is 0.7596, 
noisyNet noise sample is [array([-0.7083135], dtype=float32), -0.80531913]. 
=============================================
[2019-03-23 15:18:36,297] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138000, global step 2209660: loss 0.0054
[2019-03-23 15:18:36,299] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138000, global step 2209660: learning rate 0.0001
[2019-03-23 15:18:36,302] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138000, global step 2209661: loss 0.0082
[2019-03-23 15:18:36,303] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138000, global step 2209661: learning rate 0.0001
[2019-03-23 15:18:36,489] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 4.7019652e-24 0.0000000e+00 1.2794018e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 15:18:36,504] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8576
[2019-03-23 15:18:36,509] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.16666666666666, 53.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6840653728491367, 6.911199999999999, 6.9112, 77.32846344354104, 394540.5314070925, 394540.5314070928, 123427.6415149418], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3330600.0000, 
sim time next is 3331200.0000, 
raw observation next is [24.33333333333333, 52.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6853786700158777, 6.9112, 6.9112, 77.32846344354104, 395240.9071437696, 395240.9071437696, 123599.8282838867], 
processed observation next is [0.0, 0.5652173913043478, 0.7424242424242422, 0.5266666666666667, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5505409571655396, 0.0, 0.0, 0.5084288129206541, 0.14638552116435913, 0.14638552116435913, 0.3014629958143578], 
reward next is 0.6985, 
noisyNet noise sample is [array([2.5297747], dtype=float32), 0.25998983]. 
=============================================
[2019-03-23 15:18:40,319] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.9270673e-02 3.2479821e-07 2.3113204e-13 9.4072896e-01 1.1346896e-20], sum to 1.0000
[2019-03-23 15:18:40,324] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6249
[2019-03-23 15:18:40,328] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.93333333333333, 55.33333333333333, 1.0, 2.0, 0.5886244477348384, 1.0, 2.0, 0.5886244477348384, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1335908.503105448, 1335908.503105448, 255389.5941306254], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3426000.0000, 
sim time next is 3426600.0000, 
raw observation next is [27.96666666666667, 55.16666666666667, 1.0, 2.0, 0.5859506049712684, 1.0, 2.0, 0.5859506049712684, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1329919.240951695, 1329919.240951695, 254627.8033004322], 
processed observation next is [1.0, 0.6521739130434783, 0.9075757575757577, 0.5516666666666667, 1.0, 1.0, 0.4824382562140854, 1.0, 1.0, 0.4824382562140854, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4925626818339611, 0.4925626818339611, 0.6210434226839809], 
reward next is 0.3790, 
noisyNet noise sample is [array([-1.5379183], dtype=float32), 0.05357646]. 
=============================================
[2019-03-23 15:18:40,571] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.1734755e-05 1.9198623e-07 9.1499684e-14 9.9997807e-01 3.3399307e-20], sum to 1.0000
[2019-03-23 15:18:40,581] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0646
[2019-03-23 15:18:40,587] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.66666666666667, 96.0, 1.0, 2.0, 0.2494148097894253, 1.0, 2.0, 0.2494148097894253, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 568032.7883128755, 568032.7883128755, 179829.8098612686], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3460800.0000, 
sim time next is 3461400.0000, 
raw observation next is [21.5, 97.0, 1.0, 2.0, 0.2483030000880511, 1.0, 2.0, 0.2483030000880511, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 565606.7083883323, 565606.7083883319, 179534.230315467], 
processed observation next is [1.0, 0.043478260869565216, 0.6136363636363636, 0.97, 1.0, 1.0, 0.06037875011006385, 1.0, 1.0, 0.06037875011006385, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2094839660697527, 0.20948396606975256, 0.4378883666230902], 
reward next is 0.5621, 
noisyNet noise sample is [array([1.6792194], dtype=float32), 1.0981052]. 
=============================================
[2019-03-23 15:18:43,072] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139000, global step 2213228: loss 0.0989
[2019-03-23 15:18:43,074] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139000, global step 2213230: learning rate 0.0001
[2019-03-23 15:18:45,173] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138500, global step 2214333: loss 0.8124
[2019-03-23 15:18:45,175] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138500, global step 2214335: learning rate 0.0001
[2019-03-23 15:18:47,915] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9998987e-01 8.4203623e-11 2.4459258e-19 1.0140759e-05 2.4431369e-27], sum to 1.0000
[2019-03-23 15:18:47,923] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8870
[2019-03-23 15:18:47,929] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 594756.6104010944 W.
[2019-03-23 15:18:47,933] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 1.0, 0.3536671347421187, 6.9112, 6.9112, 77.3421103, 594756.6104010944, 594756.6104010944, 217218.9511145783], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3541800.0000, 
sim time next is 3542400.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.2608715519895372, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5283199633428775, 6.911199999999999, 6.9112, 77.32846344354104, 593747.1486339885, 593747.1486339888, 182650.1808216201], 
processed observation next is [1.0, 0.0, 0.6818181818181818, 0.89, 1.0, 1.0, 0.0760894399869215, 0.0, 0.5, -0.25, 1.0, 1.0, 0.3261713762041107, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21990635134592165, 0.2199063513459218, 0.44548824590639047], 
reward next is 0.5545, 
noisyNet noise sample is [array([1.7552854], dtype=float32), -0.16069485]. 
=============================================
[2019-03-23 15:18:48,287] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138500, global step 2215984: loss -7.4981
[2019-03-23 15:18:48,290] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138500, global step 2215985: learning rate 0.0001
[2019-03-23 15:18:48,823] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138500, global step 2216260: loss -133.3651
[2019-03-23 15:18:48,826] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138500, global step 2216261: learning rate 0.0001
[2019-03-23 15:18:49,216] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138500, global step 2216472: loss 37.2807
[2019-03-23 15:18:49,219] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138500, global step 2216473: learning rate 0.0001
[2019-03-23 15:18:49,369] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138500, global step 2216553: loss 179.2625
[2019-03-23 15:18:49,371] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138500, global step 2216553: learning rate 0.0001
[2019-03-23 15:18:49,435] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138500, global step 2216589: loss 46.7265
[2019-03-23 15:18:49,436] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138500, global step 2216589: learning rate 0.0001
[2019-03-23 15:18:49,724] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138500, global step 2216740: loss -15.8530
[2019-03-23 15:18:49,725] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138500, global step 2216740: learning rate 0.0001
[2019-03-23 15:18:49,968] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138500, global step 2216864: loss -117.2609
[2019-03-23 15:18:49,971] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138500, global step 2216866: loss -89.6142
[2019-03-23 15:18:49,972] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138500, global step 2216866: learning rate 0.0001
[2019-03-23 15:18:49,973] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138500, global step 2216866: learning rate 0.0001
[2019-03-23 15:18:50,247] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138500, global step 2217011: loss -53.8410
[2019-03-23 15:18:50,249] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138500, global step 2217011: learning rate 0.0001
[2019-03-23 15:18:50,366] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138500, global step 2217076: loss -221.8947
[2019-03-23 15:18:50,368] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138500, global step 2217076: learning rate 0.0001
[2019-03-23 15:18:50,662] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138500, global step 2217229: loss -7.7451
[2019-03-23 15:18:50,663] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138500, global step 2217229: learning rate 0.0001
[2019-03-23 15:18:50,756] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138500, global step 2217277: loss -17.9071
[2019-03-23 15:18:50,757] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138500, global step 2217278: learning rate 0.0001
[2019-03-23 15:18:51,421] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138500, global step 2217631: loss -75.7781
[2019-03-23 15:18:51,422] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138500, global step 2217631: learning rate 0.0001
[2019-03-23 15:18:51,747] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138500, global step 2217801: loss 12.6729
[2019-03-23 15:18:51,749] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138500, global step 2217802: learning rate 0.0001
[2019-03-23 15:18:53,943] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.5000978e-11 1.5408158e-15 1.1707329e-17 1.0000000e+00 2.2975481e-26], sum to 1.0000
[2019-03-23 15:18:53,952] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0300
[2019-03-23 15:18:53,956] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.66666666666667, 53.0, 1.0, 2.0, 0.6437320163029402, 1.0, 2.0, 0.6437320163029402, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1457564.71498118, 1457564.71498118, 272163.7970058781], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3687600.0000, 
sim time next is 3688200.0000, 
raw observation next is [28.5, 53.5, 1.0, 2.0, 0.6451888670098691, 1.0, 2.0, 0.6451888670098691, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1461640.181029916, 1461640.181029916, 272339.4489609582], 
processed observation next is [1.0, 0.6956521739130435, 0.9318181818181818, 0.535, 1.0, 1.0, 0.5564860837623363, 1.0, 1.0, 0.5564860837623363, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5413482151962652, 0.5413482151962652, 0.6642425584413615], 
reward next is 0.3358, 
noisyNet noise sample is [array([-0.8468137], dtype=float32), 1.2795496]. 
=============================================
[2019-03-23 15:18:57,810] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139500, global step 2221013: loss 15.6236
[2019-03-23 15:18:57,814] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139500, global step 2221014: learning rate 0.0001
[2019-03-23 15:19:00,074] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139000, global step 2222271: loss 0.0297
[2019-03-23 15:19:00,076] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139000, global step 2222271: learning rate 0.0001
[2019-03-23 15:19:03,246] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139000, global step 2223856: loss 0.0112
[2019-03-23 15:19:03,250] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139000, global step 2223856: learning rate 0.0001
[2019-03-23 15:19:04,180] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139000, global step 2224335: loss 0.0000
[2019-03-23 15:19:04,188] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139000, global step 2224335: learning rate 0.0001
[2019-03-23 15:19:04,470] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139000, global step 2224477: loss 0.0102
[2019-03-23 15:19:04,471] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139000, global step 2224477: learning rate 0.0001
[2019-03-23 15:19:04,635] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139000, global step 2224556: loss 0.0002
[2019-03-23 15:19:04,637] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139000, global step 2224559: learning rate 0.0001
[2019-03-23 15:19:04,717] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139000, global step 2224593: loss 0.0007
[2019-03-23 15:19:04,719] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139000, global step 2224594: learning rate 0.0001
[2019-03-23 15:19:04,839] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139000, global step 2224656: loss 0.0005
[2019-03-23 15:19:04,841] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139000, global step 2224656: learning rate 0.0001
[2019-03-23 15:19:05,280] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139000, global step 2224880: loss 0.0018
[2019-03-23 15:19:05,283] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139000, global step 2224881: learning rate 0.0001
[2019-03-23 15:19:05,369] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139000, global step 2224916: loss 0.0005
[2019-03-23 15:19:05,380] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139000, global step 2224918: learning rate 0.0001
[2019-03-23 15:19:05,427] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139000, global step 2224952: loss 0.0008
[2019-03-23 15:19:05,429] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139000, global step 2224952: learning rate 0.0001
[2019-03-23 15:19:05,488] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139000, global step 2224978: loss 0.0050
[2019-03-23 15:19:05,489] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139000, global step 2224978: learning rate 0.0001
[2019-03-23 15:19:05,534] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 15:19:05,535] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:19:05,536] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:19:05,536] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:19:05,538] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:19:05,539] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:19:05,539] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:19:05,540] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:19:05,540] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:19:05,541] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:19:05,542] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:19:05,560] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run90
[2019-03-23 15:19:05,586] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run90
[2019-03-23 15:19:05,627] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run90
[2019-03-23 15:19:05,628] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run90
[2019-03-23 15:19:05,652] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run90
[2019-03-23 15:19:38,197] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.58583623]
[2019-03-23 15:19:38,198] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.244614095, 51.46376023000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.539344785815863, 6.911199999999998, 6.9112, 95.55338769695034, 313816.2056120948, 313816.2056120955, 80303.14266980534]
[2019-03-23 15:19:38,199] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:19:38,202] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 1.4076698e-27 0.0000000e+00 1.7341053e-37 0.0000000e+00], sampled 0.09882627366649965
[2019-03-23 15:19:50,259] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.58583623]
[2019-03-23 15:19:50,260] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.5, 48.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.60251258792506, 6.911200000000001, 6.9112, 77.32846344354104, 349846.7476499888, 349846.7476499885, 114165.8024341418]
[2019-03-23 15:19:50,262] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:19:50,266] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 2.0254589e-28 0.0000000e+00 1.5103391e-38 0.0000000e+00], sampled 0.9421314477894538
[2019-03-23 15:19:53,804] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.58583623]
[2019-03-23 15:19:53,805] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.6080285, 93.19797313000001, 1.0, 2.0, 0.5792192809675443, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 654996.5687186174, 654996.5687186171, 159316.9774821099]
[2019-03-23 15:19:53,807] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:19:53,810] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 1.0652085e-24 0.0000000e+00 2.8807386e-33 0.0000000e+00], sampled 0.2827282912279402
[2019-03-23 15:19:53,811] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 654996.5687186174 W.
[2019-03-23 15:19:55,043] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.58583623]
[2019-03-23 15:19:55,045] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 94.0, 1.0, 2.0, 0.5123454150266163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 584302.3980699554, 584302.3980699551, 143548.6900379106]
[2019-03-23 15:19:55,048] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:19:55,050] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 1.6777208e-24 0.0000000e+00 4.7320289e-33 0.0000000e+00], sampled 0.8581236276436739
[2019-03-23 15:19:55,053] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 584302.3980699554 W.
[2019-03-23 15:20:12,376] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.58583623]
[2019-03-23 15:20:12,377] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.33333333333334, 76.33333333333334, 1.0, 2.0, 0.4240194111513143, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 481848.6579749728, 481848.6579749728, 129613.8548955163]
[2019-03-23 15:20:12,378] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:20:12,380] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 2.2666251e-20 4.3680199e-34 1.1670444e-26 0.0000000e+00], sampled 0.30350536954952223
[2019-03-23 15:20:31,186] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.58583623]
[2019-03-23 15:20:31,188] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.0, 78.0, 1.0, 2.0, 0.4882785596330397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 557016.0738884703, 557016.0738884703, 140387.1176346351]
[2019-03-23 15:20:31,190] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:20:31,195] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 5.7220889e-25 0.0000000e+00 1.0394888e-33 0.0000000e+00], sampled 0.7269602186372645
[2019-03-23 15:20:31,199] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 557016.0738884703 W.
[2019-03-23 15:20:51,550] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6553.1725 1698634175.0084 2957.0000
[2019-03-23 15:20:51,604] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6294.9961 1685630448.6673 3228.0000
[2019-03-23 15:20:51,800] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6862.2842 1793014293.7888 2409.0000
[2019-03-23 15:20:51,849] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6481.6076 1678885180.2952 3057.0000
[2019-03-23 15:20:51,909] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6328.7217 1723294598.4314 3425.0000
[2019-03-23 15:20:52,924] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 2225000, evaluation results [2225000.0, 6862.284208925443, 1793014293.78876, 2409.0, 6481.607577760913, 1678885180.2951708, 3057.0, 6294.9960618483565, 1685630448.6673346, 3228.0, 6328.721692698646, 1723294598.4313502, 3425.0, 6553.172466661831, 1698634175.0084193, 2957.0]
[2019-03-23 15:20:53,158] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139000, global step 2225126: loss 0.0000
[2019-03-23 15:20:53,159] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139000, global step 2225126: learning rate 0.0001
[2019-03-23 15:20:53,589] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139000, global step 2225354: loss 0.0093
[2019-03-23 15:20:53,591] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139000, global step 2225355: learning rate 0.0001
[2019-03-23 15:20:54,198] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139000, global step 2225677: loss 0.0021
[2019-03-23 15:20:54,199] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139000, global step 2225678: learning rate 0.0001
[2019-03-23 15:20:54,606] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139000, global step 2225888: loss 0.0331
[2019-03-23 15:20:54,609] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139000, global step 2225891: learning rate 0.0001
[2019-03-23 15:21:01,505] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140000, global step 2229550: loss -23.1153
[2019-03-23 15:21:01,506] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140000, global step 2229550: learning rate 0.0001
[2019-03-23 15:21:02,811] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139500, global step 2230236: loss 343.2557
[2019-03-23 15:21:02,815] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139500, global step 2230236: learning rate 0.0001
[2019-03-23 15:21:06,020] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139500, global step 2231938: loss 9.3291
[2019-03-23 15:21:06,023] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139500, global step 2231938: learning rate 0.0001
[2019-03-23 15:21:06,348] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.1030139e-11 5.3898726e-13 1.4826079e-15 1.0000000e+00 6.9951378e-26], sum to 1.0000
[2019-03-23 15:21:06,354] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1480
[2019-03-23 15:21:06,358] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 422595.8794768703, 422595.8794768703, 158693.6837181903], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4145400.0000, 
sim time next is 4146000.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 421150.57210872, 421150.5721087197, 158486.2867952569], 
processed observation next is [1.0, 1.0, 0.45454545454545453, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15598169337360002, 0.15598169337359988, 0.3865519190128217], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.32243907], dtype=float32), 0.024121553]. 
=============================================
[2019-03-23 15:21:06,377] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[41.333935]
 [41.541195]
 [42.387733]
 [42.126717]
 [41.2344  ]], R is [[40.80900192]
 [40.40091324]
 [39.99690628]
 [39.59693909]
 [39.2009697 ]].
[2019-03-23 15:21:06,780] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139500, global step 2232335: loss 9.9608
[2019-03-23 15:21:06,782] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139500, global step 2232335: learning rate 0.0001
[2019-03-23 15:21:06,867] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139500, global step 2232386: loss 7.4495
[2019-03-23 15:21:06,868] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139500, global step 2232387: learning rate 0.0001
[2019-03-23 15:21:07,263] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139500, global step 2232588: loss 10.2122
[2019-03-23 15:21:07,263] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139500, global step 2232589: learning rate 0.0001
[2019-03-23 15:21:07,339] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139500, global step 2232632: loss 7.5499
[2019-03-23 15:21:07,344] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139500, global step 2232632: learning rate 0.0001
[2019-03-23 15:21:07,414] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139500, global step 2232673: loss 5.7723
[2019-03-23 15:21:07,416] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139500, global step 2232674: learning rate 0.0001
[2019-03-23 15:21:07,807] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139500, global step 2232884: loss -61.2306
[2019-03-23 15:21:07,807] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139500, global step 2232884: learning rate 0.0001
[2019-03-23 15:21:07,857] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139500, global step 2232908: loss 152.4681
[2019-03-23 15:21:07,860] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139500, global step 2232908: learning rate 0.0001
[2019-03-23 15:21:07,903] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139500, global step 2232930: loss 523.9086
[2019-03-23 15:21:07,905] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139500, global step 2232930: learning rate 0.0001
[2019-03-23 15:21:07,973] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139500, global step 2232971: loss 313.3640
[2019-03-23 15:21:07,977] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139500, global step 2232972: learning rate 0.0001
[2019-03-23 15:21:08,126] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139500, global step 2233051: loss 13.9551
[2019-03-23 15:21:08,132] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139500, global step 2233051: learning rate 0.0001
[2019-03-23 15:21:08,613] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139500, global step 2233304: loss 390.7534
[2019-03-23 15:21:08,615] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139500, global step 2233304: learning rate 0.0001
[2019-03-23 15:21:09,342] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139500, global step 2233693: loss 476.6408
[2019-03-23 15:21:09,343] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139500, global step 2233693: learning rate 0.0001
[2019-03-23 15:21:09,887] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139500, global step 2233983: loss 567.7464
[2019-03-23 15:21:09,892] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139500, global step 2233983: learning rate 0.0001
[2019-03-23 15:21:11,442] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.4206029e-16 1.8202143e-28 1.4858525e-22 3.5741937e-36], sum to 1.0000
[2019-03-23 15:21:11,449] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7456
[2019-03-23 15:21:11,453] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 641813.156452903 W.
[2019-03-23 15:21:11,457] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.83333333333333, 46.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 1.0, 0.3759016257602058, 6.911199999999999, 6.9112, 77.3421103, 641813.156452903, 641813.1564529033, 214436.1107456657], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4295400.0000, 
sim time next is 4296000.0000, 
raw observation next is [26.66666666666667, 47.0, 1.0, 2.0, 0.2, 0.0, 1.0, 0.0, 1.0, 2.0, 0.3798763296080622, 6.9112, 6.9112, 77.32846344354104, 434313.4848076042, 434313.4848076042, 159663.5094250074], 
processed observation next is [1.0, 0.7391304347826086, 0.8484848484848487, 0.47, 1.0, 1.0, 0.0, 0.0, 0.5, -0.25, 1.0, 1.0, 0.11410904229723177, 0.0, 0.0, 0.5084288129206541, 0.1608568462250386, 0.1608568462250386, 0.3894231937195302], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0971504], dtype=float32), 0.16538993]. 
=============================================
[2019-03-23 15:21:11,470] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[41.371338]
 [38.802544]
 [37.906754]
 [38.21769 ]
 [38.23991 ]], R is [[44.95367432]
 [44.50413895]
 [44.52102661]
 [44.07581711]
 [43.63505936]].
[2019-03-23 15:21:13,432] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 7.5092305e-10 5.7733584e-15 2.8426101e-09 3.8719037e-19], sum to 1.0000
[2019-03-23 15:21:13,439] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0734
[2019-03-23 15:21:13,447] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6749299432195632, 6.911199999999999, 6.9112, 77.32846344354104, 389829.0262932142, 389829.0262932145, 122118.6139886646], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4341000.0000, 
sim time next is 4341600.0000, 
raw observation next is [18.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6738030621790162, 6.9112, 6.9112, 77.32846344354104, 389177.9299734049, 389177.9299734049, 122009.8584647085], 
processed observation next is [1.0, 0.2608695652173913, 0.45454545454545453, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5340043745414518, 0.0, 0.0, 0.5084288129206541, 0.14413997406422405, 0.14413997406422405, 0.29758502064563047], 
reward next is 0.7024, 
noisyNet noise sample is [array([-0.26166463], dtype=float32), 1.1788077]. 
=============================================
[2019-03-23 15:21:16,470] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140500, global step 2237464: loss 0.1600
[2019-03-23 15:21:16,471] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140500, global step 2237464: learning rate 0.0001
[2019-03-23 15:21:17,130] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.2952805e-10 5.3294716e-15 2.0083887e-18 1.0000000e+00 1.4033537e-27], sum to 1.0000
[2019-03-23 15:21:17,139] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8219
[2019-03-23 15:21:17,144] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 58.0, 1.0, 2.0, 0.5905380210572346, 1.0, 2.0, 0.5905380210572346, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1342912.155463775, 1342912.155463775, 254702.6693633783], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4363200.0000, 
sim time next is 4363800.0000, 
raw observation next is [27.16666666666666, 56.83333333333334, 1.0, 2.0, 0.5732702822689454, 1.0, 2.0, 0.5732702822689454, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1304179.519940205, 1304179.519940205, 249759.6698327892], 
processed observation next is [1.0, 0.5217391304347826, 0.871212121212121, 0.5683333333333335, 1.0, 1.0, 0.4665878528361817, 1.0, 1.0, 0.4665878528361817, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4830294518297055, 0.4830294518297055, 0.6091699264214371], 
reward next is 0.3908, 
noisyNet noise sample is [array([0.3945442], dtype=float32), -2.8688731]. 
=============================================
[2019-03-23 15:21:17,419] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.7981549e-12 9.6311786e-14 1.1344517e-20 1.0000000e+00 3.3309406e-30], sum to 1.0000
[2019-03-23 15:21:17,424] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5872
[2019-03-23 15:21:17,429] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 78.0, 1.0, 2.0, 0.2297162287138544, 1.0, 2.0, 0.2297162287138544, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 524240.4835215014, 524240.4835215011, 174025.3687604561], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4401600.0000, 
sim time next is 4402200.0000, 
raw observation next is [23.0, 78.0, 1.0, 2.0, 0.2291618291387612, 1.0, 2.0, 0.2291618291387612, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 522974.4779762502, 522974.4779762505, 173936.6249834662], 
processed observation next is [1.0, 0.9565217391304348, 0.6818181818181818, 0.78, 1.0, 1.0, 0.036452286423451496, 1.0, 1.0, 0.036452286423451496, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1936942511023149, 0.193694251102315, 0.42423567069138096], 
reward next is 0.5758, 
noisyNet noise sample is [array([-0.49879566], dtype=float32), -0.0041992385]. 
=============================================
[2019-03-23 15:21:17,696] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.3340561e-12 5.9867171e-15 3.3608752e-20 1.0000000e+00 3.4956345e-29], sum to 1.0000
[2019-03-23 15:21:17,701] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4986
[2019-03-23 15:21:17,706] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.5, 81.0, 1.0, 2.0, 0.228202273481311, 1.0, 2.0, 0.228202273481311, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 520774.3644148069, 520774.3644148067, 173597.7430519877], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4406400.0000, 
sim time next is 4407000.0000, 
raw observation next is [22.41666666666667, 81.33333333333333, 1.0, 2.0, 0.2277616666165659, 1.0, 2.0, 0.2277616666165659, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 519761.450702538, 519761.450702538, 173449.6223471443], 
processed observation next is [0.0, 0.0, 0.6553030303030305, 0.8133333333333332, 1.0, 1.0, 0.034702083270707375, 1.0, 1.0, 0.034702083270707375, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19250424100094002, 0.19250424100094002, 0.42304785938327877], 
reward next is 0.5770, 
noisyNet noise sample is [array([-0.6623792], dtype=float32), 1.5379192]. 
=============================================
[2019-03-23 15:21:17,724] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[46.388565]
 [46.261696]
 [46.31091 ]
 [46.364105]
 [46.425285]], R is [[46.49489212]
 [46.60653687]
 [46.71694565]
 [46.82609558]
 [46.93394089]].
[2019-03-23 15:21:17,981] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140000, global step 2238273: loss 0.0328
[2019-03-23 15:21:17,984] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140000, global step 2238273: learning rate 0.0001
[2019-03-23 15:21:21,139] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140000, global step 2239937: loss 0.0256
[2019-03-23 15:21:21,141] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140000, global step 2239938: learning rate 0.0001
[2019-03-23 15:21:21,931] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140000, global step 2240368: loss 0.1824
[2019-03-23 15:21:21,933] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140000, global step 2240369: learning rate 0.0001
[2019-03-23 15:21:21,957] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140000, global step 2240378: loss 0.1194
[2019-03-23 15:21:21,960] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140000, global step 2240379: learning rate 0.0001
[2019-03-23 15:21:22,250] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140000, global step 2240535: loss 0.2232
[2019-03-23 15:21:22,254] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140000, global step 2240535: learning rate 0.0001
[2019-03-23 15:21:22,400] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140000, global step 2240612: loss 0.0079
[2019-03-23 15:21:22,401] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140000, global step 2240612: learning rate 0.0001
[2019-03-23 15:21:22,461] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140000, global step 2240635: loss 0.1080
[2019-03-23 15:21:22,467] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140000, global step 2240638: learning rate 0.0001
[2019-03-23 15:21:22,802] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140000, global step 2240812: loss 0.1179
[2019-03-23 15:21:22,805] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140000, global step 2240813: learning rate 0.0001
[2019-03-23 15:21:22,904] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140000, global step 2240867: loss 0.0053
[2019-03-23 15:21:22,908] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140000, global step 2240869: learning rate 0.0001
[2019-03-23 15:21:22,964] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140000, global step 2240896: loss 0.0866
[2019-03-23 15:21:22,965] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140000, global step 2240896: learning rate 0.0001
[2019-03-23 15:21:23,048] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140000, global step 2240938: loss 0.0291
[2019-03-23 15:21:23,051] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140000, global step 2240940: learning rate 0.0001
[2019-03-23 15:21:23,498] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140000, global step 2241181: loss 0.0008
[2019-03-23 15:21:23,498] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140000, global step 2241181: learning rate 0.0001
[2019-03-23 15:21:23,541] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140000, global step 2241205: loss 0.0087
[2019-03-23 15:21:23,543] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140000, global step 2241205: learning rate 0.0001
[2019-03-23 15:21:24,571] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140000, global step 2241767: loss 0.1261
[2019-03-23 15:21:24,573] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140000, global step 2241767: learning rate 0.0001
[2019-03-23 15:21:24,948] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140000, global step 2241974: loss 0.2249
[2019-03-23 15:21:24,954] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140000, global step 2241974: learning rate 0.0001
[2019-03-23 15:21:26,977] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 2.4994503e-19 1.1717593e-34 9.9845447e-27 0.0000000e+00], sum to 1.0000
[2019-03-23 15:21:26,977] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0929
[2019-03-23 15:21:26,989] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.16666666666667, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4155192528726099, 6.9112, 6.9112, 77.32846344354104, 241674.6047906237, 241674.6047906237, 74726.78488111419], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4675800.0000, 
sim time next is 4676400.0000, 
raw observation next is [15.0, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4082215252906373, 6.911199999999999, 6.9112, 77.32846344354104, 237429.0592848869, 237429.0592848872, 73139.85581357952], 
processed observation next is [1.0, 0.13043478260869565, 0.3181818181818182, 0.82, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.15460217898662476, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08793668862403219, 0.0879366886240323, 0.17838989222824272], 
reward next is 0.8216, 
noisyNet noise sample is [array([0.5277483], dtype=float32), 0.976277]. 
=============================================
[2019-03-23 15:21:32,014] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141000, global step 2245399: loss -119.7125
[2019-03-23 15:21:32,015] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141000, global step 2245399: learning rate 0.0001
[2019-03-23 15:21:33,970] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140500, global step 2246435: loss -13.7951
[2019-03-23 15:21:33,973] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140500, global step 2246436: learning rate 0.0001
[2019-03-23 15:21:35,161] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 3.3586221e-11 1.6563869e-15 4.8557526e-11 6.6939520e-20], sum to 1.0000
[2019-03-23 15:21:35,167] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2832
[2019-03-23 15:21:35,175] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 651746.4710085535 W.
[2019-03-23 15:21:35,179] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.66666666666666, 53.00000000000001, 1.0, 2.0, 0.2877491719972639, 1.0, 2.0, 0.2877491719972639, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 651746.4710085535, 651746.4710085539, 176488.2267096641], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4710000.0000, 
sim time next is 4710600.0000, 
raw observation next is [25.0, 52.5, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 1.0, 0.3498220407875777, 6.9112, 6.9112, 77.3421103, 599966.9823319142, 599966.9823319142, 206504.1000282326], 
processed observation next is [1.0, 0.5217391304347826, 0.7727272727272727, 0.525, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.07117434398225392, 0.0, 0.0, 0.5085185399722538, 0.22220999345626455, 0.22220999345626455, 0.5036685366542258], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.73792404], dtype=float32), 0.8125682]. 
=============================================
[2019-03-23 15:21:36,263] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2623885e-04 7.1402974e-06 2.2195350e-09 9.9986660e-01 2.3122647e-13], sum to 1.0000
[2019-03-23 15:21:36,269] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1894
[2019-03-23 15:21:36,272] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.5, 85.5, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416463.9808729848, 416463.9808729848, 157454.5316730897], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4753800.0000, 
sim time next is 4754400.0000, 
raw observation next is [19.33333333333334, 86.33333333333334, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415855.6000522253, 415855.6000522253, 157212.5362928864], 
processed observation next is [1.0, 0.0, 0.5151515151515155, 0.8633333333333334, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1540205926119353, 0.1540205926119353, 0.3834452104704546], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1835808], dtype=float32), 1.7022802]. 
=============================================
[2019-03-23 15:21:36,705] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140500, global step 2247952: loss 1.8293
[2019-03-23 15:21:36,707] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140500, global step 2247952: learning rate 0.0001
[2019-03-23 15:21:37,135] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140500, global step 2248174: loss 0.2715
[2019-03-23 15:21:37,138] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140500, global step 2248175: learning rate 0.0001
[2019-03-23 15:21:37,537] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140500, global step 2248371: loss 0.2984
[2019-03-23 15:21:37,541] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140500, global step 2248372: learning rate 0.0001
[2019-03-23 15:21:37,606] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140500, global step 2248409: loss 0.2627
[2019-03-23 15:21:37,609] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140500, global step 2248409: learning rate 0.0001
[2019-03-23 15:21:38,138] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140500, global step 2248672: loss 0.0532
[2019-03-23 15:21:38,143] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140500, global step 2248672: learning rate 0.0001
[2019-03-23 15:21:38,148] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140500, global step 2248674: loss 0.2119
[2019-03-23 15:21:38,150] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140500, global step 2248674: learning rate 0.0001
[2019-03-23 15:21:38,283] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140500, global step 2248746: loss 0.1927
[2019-03-23 15:21:38,286] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140500, global step 2248747: learning rate 0.0001
[2019-03-23 15:21:38,493] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140500, global step 2248847: loss 0.1132
[2019-03-23 15:21:38,494] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140500, global step 2248847: learning rate 0.0001
[2019-03-23 15:21:38,613] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140500, global step 2248908: loss 0.1744
[2019-03-23 15:21:38,618] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140500, global step 2248909: learning rate 0.0001
[2019-03-23 15:21:38,740] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140500, global step 2248972: loss 0.4106
[2019-03-23 15:21:38,741] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140500, global step 2248972: learning rate 0.0001
[2019-03-23 15:21:39,188] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140500, global step 2249205: loss 0.7422
[2019-03-23 15:21:39,190] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140500, global step 2249206: learning rate 0.0001
[2019-03-23 15:21:39,325] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140500, global step 2249274: loss 0.1624
[2019-03-23 15:21:39,328] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140500, global step 2249274: learning rate 0.0001
[2019-03-23 15:21:40,272] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140500, global step 2249753: loss 0.1809
[2019-03-23 15:21:40,276] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140500, global step 2249755: learning rate 0.0001
[2019-03-23 15:21:40,346] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.0280215e-17 4.2339950e-22 1.8642631e-26 1.0000000e+00 1.5253535e-37], sum to 1.0000
[2019-03-23 15:21:40,356] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7265
[2019-03-23 15:21:40,364] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.33333333333333, 82.0, 1.0, 2.0, 0.2000116928267595, 1.0, 2.0, 0.2000116928267595, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 453279.5479929562, 453279.547992956, 164361.2994669678], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5272800.0000, 
sim time next is 5273400.0000, 
raw observation next is [20.26666666666667, 77.5, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 426921.2783440953, 426921.2783440953, 158902.9363476552], 
processed observation next is [1.0, 0.0, 0.5575757575757577, 0.775, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15811899197929455, 0.15811899197929455, 0.38756813743330537], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6072812], dtype=float32), 1.4603024]. 
=============================================
[2019-03-23 15:21:40,580] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140500, global step 2249907: loss 0.0687
[2019-03-23 15:21:40,582] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140500, global step 2249907: learning rate 0.0001
[2019-03-23 15:21:40,771] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 15:21:40,772] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:21:40,772] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:21:40,773] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:21:40,774] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:21:40,774] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:21:40,775] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:21:40,778] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:21:40,779] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:21:40,775] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:21:40,781] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:21:40,801] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run91
[2019-03-23 15:21:40,831] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run91
[2019-03-23 15:21:40,832] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run91
[2019-03-23 15:21:40,895] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run91
[2019-03-23 15:21:40,930] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run91
[2019-03-23 15:21:59,750] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5840645]
[2019-03-23 15:21:59,752] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [28.12364075, 82.42812854333333, 1.0, 2.0, 0.4234823833772301, 1.0, 2.0, 0.4234823833772301, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 951852.5994754992, 951852.5994754992, 223471.8001637147]
[2019-03-23 15:21:59,755] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:21:59,759] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.7040872e-10 1.3391662e-12 3.5065007e-17 1.0000000e+00 1.7129323e-25], sampled 0.6819360622645029
[2019-03-23 15:22:04,334] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5840645]
[2019-03-23 15:22:04,336] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.4, 64.0, 1.0, 2.0, 0.276039245360185, 1.0, 2.0, 0.276039245360185, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 608197.7997584784, 608197.7997584781, 165705.8653183282]
[2019-03-23 15:22:04,337] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:22:04,340] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.2110636e-09 3.4375792e-12 9.0623737e-17 1.0000000e+00 7.1921538e-25], sampled 0.8431522707437593
[2019-03-23 15:22:31,437] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5840645]
[2019-03-23 15:22:31,438] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.8, 90.0, 1.0, 2.0, 0.4291055995602363, 1.0, 2.0, 0.4291055995602363, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 973136.1821290047, 973136.1821290047, 222325.1219894993]
[2019-03-23 15:22:31,439] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:22:31,444] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.6075395e-10 5.2475120e-13 1.3342675e-17 1.0000000e+00 3.8726877e-26], sampled 0.6261462559278254
[2019-03-23 15:23:01,274] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01929497], dtype=float32), -0.5840645]
[2019-03-23 15:23:01,275] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.36666666666667, 46.66666666666666, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 307875.2898907778, 307875.2898907775, 118006.221479947]
[2019-03-23 15:23:01,276] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:23:01,279] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.5623796e-07 1.1267122e-09 3.8741291e-14 9.9999988e-01 7.8835175e-21], sampled 0.5762526972769414
[2019-03-23 15:23:26,986] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 3409.0040 2109104825.4974 0.0000
[2019-03-23 15:23:27,196] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 3560.9620 2114722436.2013 0.0000
[2019-03-23 15:23:27,459] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3745.4103 2146513028.8498 0.0000
[2019-03-23 15:23:27,544] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 3041.1653 2120525975.9236 0.0000
[2019-03-23 15:23:27,562] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 3251.2968 2111734548.9412 0.0000
[2019-03-23 15:23:28,578] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 2250000, evaluation results [2250000.0, 3745.410319669, 2146513028.8498197, 0.0, 3409.0040195481893, 2109104825.4973507, 0.0, 3560.9620381202194, 2114722436.201325, 0.0, 3041.165336533025, 2120525975.9235623, 0.0, 3251.2968070522656, 2111734548.941248, 0.0]
[2019-03-23 15:23:29,227] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.4070820e-13 6.7949136e-18 9.0088174e-23 1.0000000e+00 4.5303635e-32], sum to 1.0000
[2019-03-23 15:23:29,234] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8707
[2019-03-23 15:23:29,238] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.3916361143907605, 1.0, 2.0, 0.3916361143907605, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 893075.4907245453, 893075.4907245453, 199264.6081155062], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4874400.0000, 
sim time next is 4875000.0000, 
raw observation next is [19.33333333333334, 98.00000000000001, 1.0, 2.0, 0.3738789472193965, 1.0, 2.0, 0.3738789472193965, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 852684.5628149352, 852684.5628149349, 196104.391265225], 
processed observation next is [1.0, 0.43478260869565216, 0.5151515151515155, 0.9800000000000001, 1.0, 1.0, 0.21734868402424562, 1.0, 1.0, 0.21734868402424562, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3158090973388649, 0.31580909733886475, 0.47830339332981703], 
reward next is 0.5217, 
noisyNet noise sample is [array([-1.3952448], dtype=float32), -1.1574776]. 
=============================================
[2019-03-23 15:23:29,252] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[54.202835]
 [54.742165]
 [55.336426]
 [55.853218]
 [56.356792]], R is [[53.63813019]
 [53.61573792]
 [53.59446335]
 [53.57327271]
 [53.55338669]].
[2019-03-23 15:23:35,183] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141500, global step 2253503: loss 0.0218
[2019-03-23 15:23:35,190] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141500, global step 2253503: learning rate 0.0001
[2019-03-23 15:23:36,928] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141000, global step 2254436: loss -33.7583
[2019-03-23 15:23:36,933] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141000, global step 2254438: learning rate 0.0001
[2019-03-23 15:23:37,192] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.00000000e+00 1.28810033e-18 1.91406627e-32 1.09939286e-13
 0.00000000e+00], sum to 1.0000
[2019-03-23 15:23:37,198] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9626
[2019-03-23 15:23:37,203] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.7, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6996252960725476, 6.9112, 6.9112, 77.3284219837137, 403814.6303052923, 403814.6303052923, 124765.5721441831], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5450400.0000, 
sim time next is 5451000.0000, 
raw observation next is [17.7, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7290114899261094, 7.058061204089023, 6.9112, 77.32811661924504, 468652.4881178025, 420955.1867879198, 127692.6452316186], 
processed observation next is [1.0, 0.08695652173913043, 0.44090909090909086, 0.97, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6128735570372992, 0.014686120408902336, 0.0, 0.5084265325770748, 0.1735749955991861, 0.1559093284399703, 0.31144547617467955], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.90220916], dtype=float32), 1.4501544]. 
=============================================
[2019-03-23 15:23:37,217] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[66.565254]
 [65.74215 ]
 [64.791794]
 [64.076416]
 [64.08968 ]], R is [[66.7047348 ]
 [66.73338318]
 [66.59333038]
 [66.2308197 ]
 [65.69007874]].
[2019-03-23 15:23:37,586] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 7.4220994e-25 0.0000000e+00 3.5866721e-24 0.0000000e+00], sum to 1.0000
[2019-03-23 15:23:37,598] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4478
[2019-03-23 15:23:37,602] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.66666666666667, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5622485089552824, 6.911199999999999, 6.9112, 77.32846344354104, 326948.8353550706, 326948.8353550708, 110608.2003705431], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5039400.0000, 
sim time next is 5040000.0000, 
raw observation next is [17.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5765598094214192, 6.9112, 6.9112, 77.32846344354104, 335021.7635512952, 335021.7635512952, 111894.0513231156], 
processed observation next is [0.0, 0.34782608695652173, 0.4090909090909091, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3950854420305988, 0.0, 0.0, 0.5084288129206541, 0.12408213464862786, 0.12408213464862786, 0.27291232030028195], 
reward next is 0.7271, 
noisyNet noise sample is [array([1.5651232], dtype=float32), -0.042928535]. 
=============================================
[2019-03-23 15:23:37,616] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[65.51491 ]
 [66.113045]
 [66.73453 ]
 [67.33937 ]
 [67.96129 ]], R is [[64.94924164]
 [65.02997589]
 [65.11533356]
 [65.2096405 ]
 [65.31243896]].
[2019-03-23 15:23:37,783] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.5448830e-22 5.0589908e-36 8.3219106e-24 0.0000000e+00], sum to 1.0000
[2019-03-23 15:23:37,790] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8231
[2019-03-23 15:23:37,792] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.0, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5175816719375198, 6.911199999999999, 6.9112, 77.32846344354104, 301054.5943376458, 301054.5943376461, 95241.03375247083], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4996800.0000, 
sim time next is 4997400.0000, 
raw observation next is [17.83333333333333, 74.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5198131294548615, 6.911199999999999, 6.9112, 77.32846344354104, 302352.9389430756, 302352.9389430759, 95644.26247439024], 
processed observation next is [1.0, 0.8695652173913043, 0.44696969696969674, 0.745, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3140187563640878, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11198256997891688, 0.111982569978917, 0.2332786889619274], 
reward next is 0.7667, 
noisyNet noise sample is [array([0.519535], dtype=float32), -0.15335168]. 
=============================================
[2019-03-23 15:23:39,860] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141000, global step 2255988: loss -79.2434
[2019-03-23 15:23:39,861] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141000, global step 2255988: learning rate 0.0001
[2019-03-23 15:23:40,097] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141000, global step 2256113: loss -15.7850
[2019-03-23 15:23:40,100] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141000, global step 2256113: learning rate 0.0001
[2019-03-23 15:23:40,440] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141000, global step 2256293: loss 29.7138
[2019-03-23 15:23:40,441] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141000, global step 2256294: learning rate 0.0001
[2019-03-23 15:23:40,846] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141000, global step 2256508: loss 8.0705
[2019-03-23 15:23:40,848] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141000, global step 2256508: learning rate 0.0001
[2019-03-23 15:23:41,174] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141000, global step 2256681: loss 8.7985
[2019-03-23 15:23:41,175] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141000, global step 2256681: learning rate 0.0001
[2019-03-23 15:23:41,355] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141000, global step 2256772: loss -56.6493
[2019-03-23 15:23:41,357] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141000, global step 2256773: learning rate 0.0001
[2019-03-23 15:23:41,384] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141000, global step 2256788: loss 6.6091
[2019-03-23 15:23:41,386] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141000, global step 2256789: learning rate 0.0001
[2019-03-23 15:23:41,391] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141000, global step 2256791: loss 18.7553
[2019-03-23 15:23:41,392] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141000, global step 2256791: learning rate 0.0001
[2019-03-23 15:23:41,606] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141000, global step 2256909: loss 8.9446
[2019-03-23 15:23:41,609] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141000, global step 2256909: learning rate 0.0001
[2019-03-23 15:23:41,628] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141000, global step 2256919: loss 6.7169
[2019-03-23 15:23:41,630] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141000, global step 2256919: learning rate 0.0001
[2019-03-23 15:23:41,877] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141000, global step 2257045: loss 1.4932
[2019-03-23 15:23:41,880] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141000, global step 2257046: learning rate 0.0001
[2019-03-23 15:23:42,338] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141000, global step 2257289: loss 7.8827
[2019-03-23 15:23:42,339] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141000, global step 2257289: learning rate 0.0001
[2019-03-23 15:23:43,195] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141000, global step 2257718: loss 4.9657
[2019-03-23 15:23:43,198] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141000, global step 2257718: learning rate 0.0001
[2019-03-23 15:23:43,590] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141000, global step 2257930: loss 3.4609
[2019-03-23 15:23:43,596] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141000, global step 2257931: learning rate 0.0001
[2019-03-23 15:23:43,659] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.9561132e-03 1.0075375e-05 4.0855238e-14 9.9503386e-01 7.1889260e-22], sum to 1.0000
[2019-03-23 15:23:43,666] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9635
[2019-03-23 15:23:43,670] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.4348166221091683, 1.0, 2.0, 0.4348166221091683, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 987919.0507866807, 987919.0507866803, 216707.4154733192], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5239200.0000, 
sim time next is 5239800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.4223053975452191, 1.0, 2.0, 0.4223053975452191, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 959748.6044519333, 959748.6044519331, 213816.2634108565], 
processed observation next is [1.0, 0.6521739130434783, 0.6363636363636364, 0.94, 1.0, 1.0, 0.27788174693152384, 1.0, 1.0, 0.27788174693152384, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3554624460933086, 0.3554624460933085, 0.5215030814898939], 
reward next is 0.4785, 
noisyNet noise sample is [array([0.7181571], dtype=float32), -0.11822753]. 
=============================================
[2019-03-23 15:23:46,597] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.0147135e-09 6.0721717e-08 1.5217747e-20 9.9999988e-01 1.5569306e-34], sum to 1.0000
[2019-03-23 15:23:46,607] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7282
[2019-03-23 15:23:46,612] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.0, 93.00000000000001, 1.0, 2.0, 0.3524387724867282, 1.0, 2.0, 0.3524387724867282, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 804339.7041345809, 804339.7041345809, 195903.690954196], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5217000.0000, 
sim time next is 5217600.0000, 
raw observation next is [21.0, 92.0, 1.0, 2.0, 0.3363299983590485, 1.0, 2.0, 0.3363299983590485, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 767688.9309765429, 767688.9309765426, 192342.2534717107], 
processed observation next is [1.0, 0.391304347826087, 0.5909090909090909, 0.92, 1.0, 1.0, 0.17041249794881058, 1.0, 1.0, 0.17041249794881058, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2843292336950159, 0.2843292336950158, 0.46912744749197727], 
reward next is 0.5309, 
noisyNet noise sample is [array([0.14988607], dtype=float32), 0.88869524]. 
=============================================
[2019-03-23 15:23:50,287] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.982034e-01 1.536050e-05 5.514946e-13 1.781174e-03 1.068685e-20], sum to 1.0000
[2019-03-23 15:23:50,288] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142000, global step 2261484: loss 0.7024
[2019-03-23 15:23:50,290] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0143
[2019-03-23 15:23:50,294] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.9, 87.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 398082.4284094052, 398082.4284094052, 153706.1734975294], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5289000.0000, 
sim time next is 5289600.0000, 
raw observation next is [19.0, 87.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6728174715134814, 6.9112, 6.9112, 77.32846344354104, 387482.4787783482, 387482.4787783482, 122742.4928246767], 
processed observation next is [1.0, 0.21739130434782608, 0.5, 0.87, 0.0, 0.5, -0.25, 0.0, 0.5, -0.25, 1.0, 0.5, 0.532596387876402, 0.0, 0.0, 0.5084288129206541, 0.143512029177166, 0.143512029177166, 0.29937193371872367], 
reward next is 0.7006, 
noisyNet noise sample is [array([-0.79385257], dtype=float32), 1.2375164]. 
=============================================
[2019-03-23 15:23:50,296] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142000, global step 2261486: learning rate 0.0001
[2019-03-23 15:23:52,184] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141500, global step 2262495: loss 2.0894
[2019-03-23 15:23:52,187] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141500, global step 2262496: learning rate 0.0001
[2019-03-23 15:23:55,039] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141500, global step 2264001: loss 7.0441
[2019-03-23 15:23:55,042] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141500, global step 2264003: learning rate 0.0001
[2019-03-23 15:23:55,311] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141500, global step 2264146: loss 4.8531
[2019-03-23 15:23:55,312] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141500, global step 2264146: learning rate 0.0001
[2019-03-23 15:23:55,501] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141500, global step 2264250: loss 4.4211
[2019-03-23 15:23:55,503] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141500, global step 2264250: learning rate 0.0001
[2019-03-23 15:23:55,961] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141500, global step 2264492: loss 5.0819
[2019-03-23 15:23:55,961] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141500, global step 2264492: learning rate 0.0001
[2019-03-23 15:23:56,280] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.9749662e-07 2.4428116e-08 1.9234116e-18 9.9999964e-01 2.4363723e-30], sum to 1.0000
[2019-03-23 15:23:56,290] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2128
[2019-03-23 15:23:56,294] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.9, 90.5, 1.0, 2.0, 0.2857687379849175, 1.0, 2.0, 0.2857687379849175, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 651009.7746375822, 651009.7746375822, 179756.2975075534], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5418600.0000, 
sim time next is 5419200.0000, 
raw observation next is [19.8, 91.0, 1.0, 2.0, 0.204905207875623, 1.0, 2.0, 0.204905207875623, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 465876.6869733659, 465876.6869733659, 166586.2533383789], 
processed observation next is [1.0, 0.7391304347826086, 0.5363636363636364, 0.91, 1.0, 1.0, 0.006131509844528732, 1.0, 1.0, 0.006131509844528732, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17254692110124664, 0.17254692110124664, 0.4063079349716559], 
reward next is 0.5937, 
noisyNet noise sample is [array([0.44098046], dtype=float32), 0.1241796]. 
=============================================
[2019-03-23 15:23:56,466] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141500, global step 2264761: loss 0.0744
[2019-03-23 15:23:56,471] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141500, global step 2264762: learning rate 0.0001
[2019-03-23 15:23:56,494] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141500, global step 2264776: loss 0.1069
[2019-03-23 15:23:56,495] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141500, global step 2264776: learning rate 0.0001
[2019-03-23 15:23:56,511] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141500, global step 2264785: loss 0.2191
[2019-03-23 15:23:56,513] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141500, global step 2264786: learning rate 0.0001
[2019-03-23 15:23:56,584] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141500, global step 2264822: loss 0.3269
[2019-03-23 15:23:56,585] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141500, global step 2264822: learning rate 0.0001
[2019-03-23 15:23:56,614] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141500, global step 2264839: loss 0.2818
[2019-03-23 15:23:56,617] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141500, global step 2264840: learning rate 0.0001
[2019-03-23 15:23:56,861] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141500, global step 2264966: loss 0.0395
[2019-03-23 15:23:56,863] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141500, global step 2264967: learning rate 0.0001
[2019-03-23 15:23:56,975] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141500, global step 2265026: loss 0.0784
[2019-03-23 15:23:56,978] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141500, global step 2265027: learning rate 0.0001
[2019-03-23 15:23:57,507] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141500, global step 2265309: loss 1.3718
[2019-03-23 15:23:57,509] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141500, global step 2265310: learning rate 0.0001
[2019-03-23 15:23:58,188] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141500, global step 2265672: loss 1.1252
[2019-03-23 15:23:58,190] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141500, global step 2265672: learning rate 0.0001
[2019-03-23 15:23:58,685] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141500, global step 2265936: loss 0.9680
[2019-03-23 15:23:58,686] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141500, global step 2265936: learning rate 0.0001
[2019-03-23 15:24:00,303] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.9999988e-01 1.6775320e-07 1.4285709e-14 7.4900870e-11 2.2664097e-19], sum to 1.0000
[2019-03-23 15:24:00,309] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4215
[2019-03-23 15:24:00,315] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1252499.007219478 W.
[2019-03-23 15:24:00,318] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.36666666666667, 72.33333333333334, 1.0, 2.0, 0.6194004692015013, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9766495459114556, 6.911199999999999, 6.9112, 77.32846344354104, 1252499.007219478, 1252499.007219478, 279850.4550738611], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5484000.0000, 
sim time next is 5484600.0000, 
raw observation next is [25.55, 71.5, 1.0, 2.0, 0.3707309593286138, 1.0, 1.0, 0.3707309593286138, 1.0, 2.0, 0.7503622781805728, 6.911199999999999, 6.9112, 77.3421103, 1257881.884999586, 1257881.884999586, 290854.9793671953], 
processed observation next is [1.0, 0.4782608695652174, 0.7977272727272727, 0.715, 1.0, 1.0, 0.2134136991607672, 1.0, 0.5, 0.2134136991607672, 1.0, 1.0, 0.643374683115104, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4658821796294763, 0.4658821796294763, 0.7094023887004763], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2426326], dtype=float32), -0.42031497]. 
=============================================
[2019-03-23 15:24:05,339] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142500, global step 2269406: loss 59.8855
[2019-03-23 15:24:05,341] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142500, global step 2269406: learning rate 0.0001
[2019-03-23 15:24:06,416] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9997640e-01 2.3560053e-05 4.1460290e-11 1.5708954e-08 1.0153098e-14], sum to 1.0000
[2019-03-23 15:24:06,423] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8003
[2019-03-23 15:24:06,427] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.33333333333334, 89.0, 1.0, 1.0, 0.2220299742021982, 1.0, 1.0, 0.2220299742021982, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32826204204082, 505527.6565847664, 505527.6565847664, 169827.6099025396], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5599200.0000, 
sim time next is 5599800.0000, 
raw observation next is [20.25, 90.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7635617619558237, 7.265802204752915, 6.9112, 77.32758723849834, 550557.316701543, 435391.0784249645, 135505.136016444], 
processed observation next is [1.0, 0.8260869565217391, 0.5568181818181818, 0.9, 0.0, 0.5, -0.25, 0.0, 0.5, -0.25, 1.0, 0.5, 0.6622310885083197, 0.035460220475291494, 0.0, 0.5084230519386056, 0.2039101172968678, 0.16125595497220907, 0.33050033174742444], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.317524], dtype=float32), 0.6890255]. 
=============================================
[2019-03-23 15:24:07,280] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142000, global step 2270428: loss 0.9585
[2019-03-23 15:24:07,283] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142000, global step 2270428: learning rate 0.0001
[2019-03-23 15:24:08,313] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5505160e-05 9.9997842e-01 3.4165990e-17 6.1196247e-06 3.6365936e-30], sum to 1.0000
[2019-03-23 15:24:08,319] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5904
[2019-03-23 15:24:08,324] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.36666666666667, 99.0, 1.0, 2.0, 0.3566049611660184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 396386.4588467014, 396386.4588467011, 118493.4136247351], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5640000.0000, 
sim time next is 5640600.0000, 
raw observation next is [17.28333333333333, 99.5, 1.0, 2.0, 0.3545997519352713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 393976.9072335592, 393976.9072335592, 118259.4344824921], 
processed observation next is [0.0, 0.2608695652173913, 0.4219696969696969, 0.995, 1.0, 1.0, 0.19324968991908914, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14591737304946636, 0.14591737304946636, 0.288437645079249], 
reward next is 0.7116, 
noisyNet noise sample is [array([1.6828508], dtype=float32), 1.5361944]. 
=============================================
[2019-03-23 15:24:08,829] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.0461821e-05 9.9985313e-01 1.3223926e-17 1.1628047e-04 3.2378257e-30], sum to 1.0000
[2019-03-23 15:24:08,836] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3481
[2019-03-23 15:24:08,839] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.98333333333333, 64.0, 1.0, 2.0, 0.4080809322852422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846243100887, 443169.0954403123, 443169.0954403126, 99593.15952097808], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6081000.0000, 
sim time next is 6081600.0000, 
raw observation next is [18.26666666666667, 63.0, 1.0, 2.0, 0.405740924353142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846343727338, 440626.7342569287, 440626.7342569284, 99781.00137430444], 
processed observation next is [1.0, 0.391304347826087, 0.4666666666666668, 0.63, 1.0, 1.0, 0.25717615544142747, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288128794447, 0.16319508676182545, 0.16319508676182531, 0.24336829603488888], 
reward next is 0.7566, 
noisyNet noise sample is [array([-0.20290676], dtype=float32), -0.15143926]. 
=============================================
[2019-03-23 15:24:10,319] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142000, global step 2272042: loss 1.4689
[2019-03-23 15:24:10,320] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142000, global step 2272042: learning rate 0.0001
[2019-03-23 15:24:10,555] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142000, global step 2272174: loss 11.7535
[2019-03-23 15:24:10,559] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142000, global step 2272175: learning rate 0.0001
[2019-03-23 15:24:10,627] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142000, global step 2272213: loss 19.5289
[2019-03-23 15:24:10,631] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142000, global step 2272214: learning rate 0.0001
[2019-03-23 15:24:11,202] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142000, global step 2272541: loss 0.0643
[2019-03-23 15:24:11,204] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142000, global step 2272542: learning rate 0.0001
[2019-03-23 15:24:11,483] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142000, global step 2272711: loss 1.5049
[2019-03-23 15:24:11,483] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142000, global step 2272711: learning rate 0.0001
[2019-03-23 15:24:11,547] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142000, global step 2272759: loss 2.3681
[2019-03-23 15:24:11,547] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142000, global step 2272759: loss 2.6411
[2019-03-23 15:24:11,548] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142000, global step 2272759: learning rate 0.0001
[2019-03-23 15:24:11,549] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142000, global step 2272759: learning rate 0.0001
[2019-03-23 15:24:11,702] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142000, global step 2272852: loss 3.0942
[2019-03-23 15:24:11,703] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142000, global step 2272852: learning rate 0.0001
[2019-03-23 15:24:11,825] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142000, global step 2272925: loss 1.6288
[2019-03-23 15:24:11,829] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142000, global step 2272927: learning rate 0.0001
[2019-03-23 15:24:11,841] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142000, global step 2272932: loss 1.2471
[2019-03-23 15:24:11,842] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142000, global step 2272932: learning rate 0.0001
[2019-03-23 15:24:12,052] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142000, global step 2273033: loss 0.6957
[2019-03-23 15:24:12,053] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142000, global step 2273033: learning rate 0.0001
[2019-03-23 15:24:12,660] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142000, global step 2273340: loss 3.4611
[2019-03-23 15:24:12,661] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142000, global step 2273340: learning rate 0.0001
[2019-03-23 15:24:13,310] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142000, global step 2273666: loss 1.6431
[2019-03-23 15:24:13,312] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142000, global step 2273666: learning rate 0.0001
[2019-03-23 15:24:13,989] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142000, global step 2274004: loss 2.5218
[2019-03-23 15:24:13,992] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142000, global step 2274005: learning rate 0.0001
[2019-03-23 15:24:15,962] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 15:24:15,963] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:24:15,963] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:24:15,964] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:24:15,964] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:24:15,965] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:24:15,965] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:24:15,966] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:24:15,967] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:24:15,969] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:24:15,970] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:24:15,991] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run92
[2019-03-23 15:24:16,017] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run92
[2019-03-23 15:24:16,043] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run92
[2019-03-23 15:24:16,068] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run92
[2019-03-23 15:24:16,068] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run92
[2019-03-23 15:24:37,062] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00794832], dtype=float32), -0.5993589]
[2019-03-23 15:24:37,063] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.81666666666667, 53.33333333333334, 1.0, 2.0, 0.5158437710518992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 587814.521242552, 587814.521242552, 148799.9158473508]
[2019-03-23 15:24:37,067] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:24:37,070] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.5624930e-09 9.9999475e-01 4.2626762e-21 5.2609066e-06 1.5230379e-36], sampled 0.18494564199431907
[2019-03-23 15:24:43,317] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00794832], dtype=float32), -0.5993589]
[2019-03-23 15:24:43,317] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.60219738, 51.45426292000001, 1.0, 2.0, 0.6660283052670272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 753353.8484866017, 753353.8484866017, 159328.8396056945]
[2019-03-23 15:24:43,319] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:24:43,324] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.3316945e-08 9.9999380e-01 8.4025485e-20 6.1830988e-06 5.6271296e-34], sampled 0.5180998254341068
[2019-03-23 15:25:27,346] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00794832], dtype=float32), -0.5993589]
[2019-03-23 15:25:27,348] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.43333333333333, 100.0, 1.0, 2.0, 0.5077729129636704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 578833.6500893852, 578833.6500893852, 143353.6001958245]
[2019-03-23 15:25:27,349] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:25:27,355] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.4115690e-08 9.9999440e-01 1.8539405e-19 5.4466336e-06 3.6163518e-33], sampled 0.2821687985688336
[2019-03-23 15:25:31,095] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00794832], dtype=float32), -0.5993589]
[2019-03-23 15:25:31,096] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [27.61914780333333, 57.19235153666666, 1.0, 2.0, 0.5049991753541724, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769694984, 575827.7585317633, 575827.7585317633, 147026.8244762581]
[2019-03-23 15:25:31,098] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:25:31,103] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.0973241e-08 9.9999332e-01 3.3195188e-20 6.6500697e-06 7.1833496e-35], sampled 0.1714264807579695
[2019-03-23 15:25:56,318] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00794832], dtype=float32), -0.5993589]
[2019-03-23 15:25:56,320] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.66898835333333, 58.63630755333334, 1.0, 2.0, 0.3851263691871822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 428669.3883112008, 428669.3883112008, 125369.3321817487]
[2019-03-23 15:25:56,322] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:25:56,327] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.2008619e-08 9.9999535e-01 4.6806185e-21 4.6101663e-06 2.2371920e-36], sampled 0.047948244743267754
[2019-03-23 15:26:02,413] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9063.7365 1656114873.2322 80.0000
[2019-03-23 15:26:02,436] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00794832], dtype=float32), -0.5993589]
[2019-03-23 15:26:02,437] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.43333333333334, 91.66666666666667, 1.0, 2.0, 0.4672763517472092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 533096.4240530259, 533096.4240530255, 136594.9872231207]
[2019-03-23 15:26:02,438] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:26:02,440] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.4045665e-08 9.9999595e-01 6.6115991e-20 3.9800821e-06 6.2836161e-34], sampled 0.4983707137996096
[2019-03-23 15:26:02,615] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 15:26:02,618] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 15:26:02,753] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.4445 1663743378.0756 105.0000
[2019-03-23 15:26:02,767] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 15:26:03,780] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 2275000, evaluation results [2275000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9063.736514502001, 1656114873.2322423, 80.0, 8857.444472927175, 1663743378.0755634, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 15:26:04,620] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.1581180e-10 1.0000000e+00 8.6922500e-26 1.8379765e-08 0.0000000e+00], sum to 1.0000
[2019-03-23 15:26:04,625] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7383
[2019-03-23 15:26:04,631] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 80.0, 1.0, 2.0, 0.2592151496093118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 281456.5478085445, 281456.5478085445, 93166.15663138534], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5900400.0000, 
sim time next is 5901000.0000, 
raw observation next is [17.46666666666667, 79.33333333333334, 1.0, 2.0, 0.2673052758090171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 290243.4510657737, 290243.4510657737, 96407.12447900884], 
processed observation next is [1.0, 0.30434782608695654, 0.4303030303030304, 0.7933333333333334, 1.0, 1.0, 0.08413159476127134, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10749757446880509, 0.10749757446880509, 0.23513932799758253], 
reward next is 0.7649, 
noisyNet noise sample is [array([-0.5561216], dtype=float32), -0.35592765]. 
=============================================
[2019-03-23 15:26:04,649] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[78.04687 ]
 [78.051186]
 [78.07261 ]
 [78.08755 ]
 [78.06485 ]], R is [[78.05479431]
 [78.04701233]
 [78.04299927]
 [78.04248047]
 [78.04479218]].
[2019-03-23 15:26:06,266] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.2310712e-08 9.9999952e-01 8.4948446e-18 4.4520309e-07 1.1151120e-30], sum to 1.0000
[2019-03-23 15:26:06,272] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1307
[2019-03-23 15:26:06,281] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1111594.374248788 W.
[2019-03-23 15:26:06,289] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.7, 46.0, 1.0, 2.0, 0.4868303741674521, 1.0, 2.0, 0.4868303741674521, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1111594.374248788, 1111594.374248788, 221735.0639365923], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5932200.0000, 
sim time next is 5932800.0000, 
raw observation next is [27.7, 46.0, 1.0, 2.0, 0.3159827254626221, 1.0, 2.0, 0.3159827254626221, 1.0, 1.0, 0.6369503299241126, 6.9112, 6.9112, 77.3421103, 1082264.919556021, 1082264.919556021, 258194.152834322], 
processed observation next is [1.0, 0.6956521739130435, 0.8954545454545454, 0.46, 1.0, 1.0, 0.14497840682827765, 1.0, 1.0, 0.14497840682827765, 1.0, 0.5, 0.48135761417730377, 0.0, 0.0, 0.5085185399722538, 0.4008388590948226, 0.4008388590948226, 0.6297418361812732], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.24946795], dtype=float32), -0.22870044]. 
=============================================
[2019-03-23 15:26:08,152] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143000, global step 2277331: loss 0.0474
[2019-03-23 15:26:08,154] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143000, global step 2277332: learning rate 0.0001
[2019-03-23 15:26:10,233] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142500, global step 2278438: loss -216.1135
[2019-03-23 15:26:10,235] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142500, global step 2278439: learning rate 0.0001
[2019-03-23 15:26:13,351] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.5801997e-09 1.0000000e+00 1.6625261e-24 2.9785012e-13 0.0000000e+00], sum to 1.0000
[2019-03-23 15:26:13,353] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9398
[2019-03-23 15:26:13,360] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.61666666666667, 90.5, 1.0, 2.0, 0.3452423516646236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 379431.2372801439, 379431.2372801442, 115910.0557623321], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5980200.0000, 
sim time next is 5980800.0000, 
raw observation next is [17.53333333333333, 91.0, 1.0, 2.0, 0.348749288621957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 383136.782823124, 383136.7828231243, 116119.506293368], 
processed observation next is [1.0, 0.21739130434782608, 0.43333333333333324, 0.91, 1.0, 1.0, 0.1859366107774462, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1419025121567126, 0.1419025121567127, 0.2832183080326049], 
reward next is 0.7168, 
noisyNet noise sample is [array([-0.52823466], dtype=float32), 0.06459116]. 
=============================================
[2019-03-23 15:26:13,437] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142500, global step 2280141: loss -142.2625
[2019-03-23 15:26:13,443] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142500, global step 2280142: learning rate 0.0001
[2019-03-23 15:26:13,578] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142500, global step 2280216: loss -64.7870
[2019-03-23 15:26:13,581] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142500, global step 2280217: learning rate 0.0001
[2019-03-23 15:26:13,768] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142500, global step 2280313: loss -144.8548
[2019-03-23 15:26:13,770] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142500, global step 2280314: learning rate 0.0001
[2019-03-23 15:26:14,249] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142500, global step 2280569: loss -50.1420
[2019-03-23 15:26:14,252] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142500, global step 2280570: learning rate 0.0001
[2019-03-23 15:26:14,428] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142500, global step 2280667: loss -10.9860
[2019-03-23 15:26:14,430] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142500, global step 2280667: learning rate 0.0001
[2019-03-23 15:26:14,533] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142500, global step 2280720: loss -47.6740
[2019-03-23 15:26:14,536] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142500, global step 2280720: learning rate 0.0001
[2019-03-23 15:26:14,748] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142500, global step 2280838: loss -28.4938
[2019-03-23 15:26:14,749] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142500, global step 2280838: learning rate 0.0001
[2019-03-23 15:26:14,765] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142500, global step 2280845: loss -42.3624
[2019-03-23 15:26:14,770] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142500, global step 2280845: learning rate 0.0001
[2019-03-23 15:26:14,885] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142500, global step 2280907: loss -199.4843
[2019-03-23 15:26:14,887] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142500, global step 2280909: learning rate 0.0001
[2019-03-23 15:26:14,963] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142500, global step 2280950: loss -137.4997
[2019-03-23 15:26:14,964] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142500, global step 2280950: learning rate 0.0001
[2019-03-23 15:26:15,245] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142500, global step 2281100: loss -133.4270
[2019-03-23 15:26:15,247] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142500, global step 2281100: learning rate 0.0001
[2019-03-23 15:26:15,445] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142500, global step 2281201: loss -287.1204
[2019-03-23 15:26:15,448] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142500, global step 2281202: learning rate 0.0001
[2019-03-23 15:26:16,291] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142500, global step 2281649: loss -342.2506
[2019-03-23 15:26:16,292] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142500, global step 2281650: learning rate 0.0001
[2019-03-23 15:26:16,877] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142500, global step 2281961: loss -249.0124
[2019-03-23 15:26:16,880] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142500, global step 2281961: learning rate 0.0001
[2019-03-23 15:26:17,412] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.6483175e-09 1.0000000e+00 7.2533754e-25 1.2050415e-11 0.0000000e+00], sum to 1.0000
[2019-03-23 15:26:17,419] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7222
[2019-03-23 15:26:17,422] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 78.0, 1.0, 2.0, 0.2210385729075685, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 239994.0849210345, 239994.0849210348, 76539.08626361765], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6058800.0000, 
sim time next is 6059400.0000, 
raw observation next is [15.21666666666667, 79.5, 1.0, 2.0, 0.222952192437141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 242072.3269541627, 242072.3269541624, 76342.89285292955], 
processed observation next is [1.0, 0.13043478260869565, 0.32803030303030317, 0.795, 1.0, 1.0, 0.02869024054642625, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08965641739043063, 0.08965641739043051, 0.18620217769007208], 
reward next is 0.8138, 
noisyNet noise sample is [array([-1.6902131], dtype=float32), -0.25481156]. 
=============================================
[2019-03-23 15:26:22,683] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.6589280e-07 9.9999928e-01 1.9076019e-22 1.6321000e-11 9.3676953e-35], sum to 1.0000
[2019-03-23 15:26:22,687] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4176
[2019-03-23 15:26:22,694] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 63.0, 1.0, 2.0, 0.2728139606640939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 296226.6724307628, 296226.6724307628, 93805.4674603494], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6123600.0000, 
sim time next is 6124200.0000, 
raw observation next is [19.3, 63.33333333333333, 1.0, 2.0, 0.2710656806213578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 294327.7817330501, 294327.7817330498, 93098.58440776798], 
processed observation next is [1.0, 0.9130434782608695, 0.5136363636363637, 0.6333333333333333, 1.0, 1.0, 0.0888321007766972, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10901028953075931, 0.10901028953075918, 0.22706971806772677], 
reward next is 0.7729, 
noisyNet noise sample is [array([-0.00699959], dtype=float32), 0.04991329]. 
=============================================
[2019-03-23 15:26:22,984] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143500, global step 2285172: loss 1.7809
[2019-03-23 15:26:22,986] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143500, global step 2285173: learning rate 0.0001
[2019-03-23 15:26:23,866] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.5406996e-05 9.9997461e-01 7.6553536e-23 6.1164433e-12 3.5735614e-34], sum to 1.0000
[2019-03-23 15:26:23,878] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4153
[2019-03-23 15:26:23,881] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 57.0, 1.0, 2.0, 0.4750279709630296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 526744.162036301, 526744.162036301, 128296.3329849911], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6196200.0000, 
sim time next is 6196800.0000, 
raw observation next is [22.7, 57.00000000000001, 1.0, 2.0, 0.3493269663625418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 386609.8336658461, 386609.8336658464, 117234.6160317101], 
processed observation next is [1.0, 0.7391304347826086, 0.6681818181818181, 0.5700000000000001, 1.0, 1.0, 0.1866587079531772, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1431888272836467, 0.14318882728364682, 0.28593808788221975], 
reward next is 0.7141, 
noisyNet noise sample is [array([1.362727], dtype=float32), 0.079968]. 
=============================================
[2019-03-23 15:26:25,085] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143000, global step 2286295: loss 0.0810
[2019-03-23 15:26:25,090] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143000, global step 2286297: learning rate 0.0001
[2019-03-23 15:26:28,630] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143000, global step 2288176: loss -164.3274
[2019-03-23 15:26:28,632] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143000, global step 2288176: learning rate 0.0001
[2019-03-23 15:26:28,717] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143000, global step 2288223: loss -98.3983
[2019-03-23 15:26:28,719] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143000, global step 2288224: learning rate 0.0001
[2019-03-23 15:26:29,227] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143000, global step 2288491: loss 36.4921
[2019-03-23 15:26:29,228] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143000, global step 2288491: learning rate 0.0001
[2019-03-23 15:26:29,521] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143000, global step 2288647: loss 41.0769
[2019-03-23 15:26:29,525] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143000, global step 2288647: learning rate 0.0001
[2019-03-23 15:26:29,599] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143000, global step 2288687: loss -5.4678
[2019-03-23 15:26:29,601] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143000, global step 2288688: learning rate 0.0001
[2019-03-23 15:26:29,646] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143000, global step 2288712: loss 45.8121
[2019-03-23 15:26:29,647] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143000, global step 2288712: learning rate 0.0001
[2019-03-23 15:26:29,838] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143000, global step 2288812: loss 212.6351
[2019-03-23 15:26:29,841] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143000, global step 2288812: learning rate 0.0001
[2019-03-23 15:26:29,857] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143000, global step 2288821: loss 147.6338
[2019-03-23 15:26:29,862] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143000, global step 2288822: learning rate 0.0001
[2019-03-23 15:26:30,048] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143000, global step 2288921: loss 318.5689
[2019-03-23 15:26:30,050] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143000, global step 2288921: learning rate 0.0001
[2019-03-23 15:26:30,272] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143000, global step 2289043: loss 151.8958
[2019-03-23 15:26:30,276] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143000, global step 2289044: learning rate 0.0001
[2019-03-23 15:26:30,448] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143000, global step 2289131: loss 64.8985
[2019-03-23 15:26:30,450] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143000, global step 2289131: learning rate 0.0001
[2019-03-23 15:26:30,548] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143000, global step 2289185: loss 87.7898
[2019-03-23 15:26:30,551] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143000, global step 2289185: learning rate 0.0001
[2019-03-23 15:26:31,106] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 4.4058627e-24 2.8992116e-28 9.6440596e-30 0.0000000e+00], sum to 1.0000
[2019-03-23 15:26:31,108] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 3.1902087e-25 2.2493533e-29 9.8353977e-30 0.0000000e+00], sum to 1.0000
[2019-03-23 15:26:31,111] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2170
[2019-03-23 15:26:31,112] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1379
[2019-03-23 15:26:31,120] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 588772.0936329353 W.
[2019-03-23 15:26:31,123] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 550814.6147998407 W.
[2019-03-23 15:26:31,124] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 77.5, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3500863866805175, 6.911199999999999, 6.9112, 77.3421103, 588772.0936329353, 588772.0936329355, 216382.5351153557], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6341400.0000, 
sim time next is 6342000.0000, 
raw observation next is [24.8, 77.0, 1.0, 2.0, 0.5170945614548303, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588518.4599208547, 588518.4599208547, 145308.8964551867], 
processed observation next is [0.0, 0.391304347826087, 0.7636363636363637, 0.77, 1.0, 1.0, 0.3963682018185379, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2179697999706869, 0.2179697999706869, 0.3544119425736261], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.98146325], dtype=float32), 0.13604702]. 
=============================================
[2019-03-23 15:26:31,126] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.45, 87.0, 1.0, 2.0, 0.241504343418802, 1.0, 1.0, 0.241504343418802, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846097430154, 550814.6147998407, 550814.6147998404, 177401.6249925937], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6330600.0000, 
sim time next is 6331200.0000, 
raw observation next is [22.53333333333333, 87.0, 1.0, 2.0, 0.4779836969924517, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846342825624, 545334.5139332475, 545334.5139332475, 139018.9363780286], 
processed observation next is [0.0, 0.2608695652173913, 0.6606060606060605, 0.87, 1.0, 1.0, 0.3474796212405646, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288128201577, 0.2019757459012028, 0.2019757459012028, 0.3390705765317771], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8358211], dtype=float32), 0.37950894]. 
=============================================
[2019-03-23 15:26:31,138] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[26.007383]
 [26.169424]
 [26.21823 ]
 [26.161985]
 [25.848099]], R is [[25.72780418]
 [25.47052574]
 [25.77255249]
 [26.07309532]
 [26.4618969 ]].
[2019-03-23 15:26:31,640] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143000, global step 2289746: loss -163.1951
[2019-03-23 15:26:31,642] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143000, global step 2289746: learning rate 0.0001
[2019-03-23 15:26:32,039] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143000, global step 2289956: loss -91.4088
[2019-03-23 15:26:32,040] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143000, global step 2289956: learning rate 0.0001
[2019-03-23 15:26:34,633] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.3822639e-23 2.1675029e-28 4.9136066e-27 0.0000000e+00], sum to 1.0000
[2019-03-23 15:26:34,643] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6325
[2019-03-23 15:26:34,651] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 632353.1355673892 W.
[2019-03-23 15:26:34,654] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.8, 64.33333333333334, 1.0, 2.0, 0.5580212932593475, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 632353.1355673892, 632353.1355673892, 151778.6119758703], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6361800.0000, 
sim time next is 6362400.0000, 
raw observation next is [27.9, 63.66666666666667, 1.0, 2.0, 0.557617878053041, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 632155.0294285876, 632155.029428588, 151629.5510486878], 
processed observation next is [0.0, 0.6521739130434783, 0.9045454545454544, 0.6366666666666667, 1.0, 1.0, 0.44702234756630116, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2341314923809584, 0.2341314923809585, 0.3698281732894825], 
reward next is 0.6302, 
noisyNet noise sample is [array([0.10699], dtype=float32), 0.45494944]. 
=============================================
[2019-03-23 15:26:35,399] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 6.9274302e-24 2.4442245e-27 4.3044491e-28 2.6050766e-38], sum to 1.0000
[2019-03-23 15:26:35,404] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0625
[2019-03-23 15:26:35,409] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 610044.3997783641 W.
[2019-03-23 15:26:35,414] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.9, 71.5, 1.0, 2.0, 0.5347732515303499, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 610044.3997783641, 610044.3997783641, 145977.5585403545], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6419400.0000, 
sim time next is 6420000.0000, 
raw observation next is [24.8, 72.0, 1.0, 2.0, 0.269594696622831, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5448895094303495, 6.911199999999999, 6.9112, 77.32846344354104, 615062.7115798837, 615062.711579884, 182931.6837814448], 
processed observation next is [1.0, 0.30434782608695654, 0.7636363636363637, 0.72, 1.0, 1.0, 0.0869933707785387, 0.0, 1.0, -0.25, 1.0, 0.5, 0.3498421563290708, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2278010042888458, 0.22780100428884595, 0.4461748384913288], 
reward next is 0.5538, 
noisyNet noise sample is [array([0.84310704], dtype=float32), -0.12400144]. 
=============================================
[2019-03-23 15:26:35,426] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[23.71888 ]
 [23.82355 ]
 [23.978136]
 [24.034096]
 [24.218958]], R is [[24.10194969]
 [24.50488663]
 [24.82300949]
 [24.57477951]
 [24.89807892]].
[2019-03-23 15:26:37,562] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144000, global step 2292832: loss -45.7708
[2019-03-23 15:26:37,565] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144000, global step 2292832: learning rate 0.0001
[2019-03-23 15:26:38,025] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.1305072e-13 9.0638765e-36 7.6222216e-28 0.0000000e+00], sum to 1.0000
[2019-03-23 15:26:38,032] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8412
[2019-03-23 15:26:38,040] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [12.25, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3661111564874727, 6.9112, 6.9112, 77.32846344354104, 212931.5424045164, 212931.5424045164, 62494.31283765277], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6579000.0000, 
sim time next is 6579600.0000, 
raw observation next is [12.03333333333333, 94.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3553391059736509, 6.911199999999999, 6.9112, 77.32846344354104, 206665.1488330299, 206665.1488330302, 61538.43145109552], 
processed observation next is [1.0, 0.13043478260869565, 0.18333333333333315, 0.9433333333333332, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0790558656766442, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.076542647715937, 0.0765426477159371, 0.15009373524657443], 
reward next is 0.8499, 
noisyNet noise sample is [array([0.6855375], dtype=float32), -1.6276169]. 
=============================================
[2019-03-23 15:26:39,445] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.00000000e+00 1.94634357e-19 1.10550795e-35 2.56032236e-28
 0.00000000e+00], sum to 1.0000
[2019-03-23 15:26:39,450] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0361
[2019-03-23 15:26:39,458] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 692623.0512609386 W.
[2019-03-23 15:26:39,465] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [18.3, 87.5, 1.0, 2.0, 0.3088862957798968, 1.0, 2.0, 0.3088862957798968, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 692623.0512609386, 692623.0512609386, 175595.873102142], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6450600.0000, 
sim time next is 6451200.0000, 
raw observation next is [18.3, 87.0, 1.0, 2.0, 0.2094471502563826, 1.0, 2.0, 0.2094471502563826, 1.0, 1.0, 0.4083999610472704, 6.911199999999999, 6.9112, 77.3421103, 704815.2745145005, 704815.2745145008, 212882.8046392373], 
processed observation next is [1.0, 0.6956521739130435, 0.4681818181818182, 0.87, 1.0, 1.0, 0.011808937820478246, 1.0, 1.0, 0.011808937820478246, 1.0, 0.5, 0.1548570872103863, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.26104269426462984, 0.2610426942646299, 0.5192263527786275], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.19143341], dtype=float32), 1.0412872]. 
=============================================
[2019-03-23 15:26:39,693] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143500, global step 2293968: loss 723.7972
[2019-03-23 15:26:39,695] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143500, global step 2293968: learning rate 0.0001
[2019-03-23 15:26:43,772] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143500, global step 2296132: loss 209.8044
[2019-03-23 15:26:43,775] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143500, global step 2296133: learning rate 0.0001
[2019-03-23 15:26:43,997] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143500, global step 2296251: loss 143.1424
[2019-03-23 15:26:43,998] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143500, global step 2296252: learning rate 0.0001
[2019-03-23 15:26:44,460] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143500, global step 2296497: loss 109.2178
[2019-03-23 15:26:44,463] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143500, global step 2296498: learning rate 0.0001
[2019-03-23 15:26:44,728] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143500, global step 2296632: loss -3.4399
[2019-03-23 15:26:44,729] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143500, global step 2296632: learning rate 0.0001
[2019-03-23 15:26:44,828] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143500, global step 2296688: loss 183.6230
[2019-03-23 15:26:44,832] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143500, global step 2296690: learning rate 0.0001
[2019-03-23 15:26:44,855] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143500, global step 2296699: loss 11.9090
[2019-03-23 15:26:44,858] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143500, global step 2296700: learning rate 0.0001
[2019-03-23 15:26:45,176] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143500, global step 2296872: loss 136.3326
[2019-03-23 15:26:45,178] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143500, global step 2296872: learning rate 0.0001
[2019-03-23 15:26:45,203] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143500, global step 2296884: loss 80.2871
[2019-03-23 15:26:45,205] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143500, global step 2296884: learning rate 0.0001
[2019-03-23 15:26:45,378] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143500, global step 2296977: loss 116.1770
[2019-03-23 15:26:45,382] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143500, global step 2296977: learning rate 0.0001
[2019-03-23 15:26:45,554] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143500, global step 2297064: loss 101.5545
[2019-03-23 15:26:45,554] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143500, global step 2297064: loss -89.4210
[2019-03-23 15:26:45,556] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143500, global step 2297065: learning rate 0.0001
[2019-03-23 15:26:45,557] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143500, global step 2297064: learning rate 0.0001
[2019-03-23 15:26:45,602] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143500, global step 2297094: loss 76.0549
[2019-03-23 15:26:45,603] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143500, global step 2297094: learning rate 0.0001
[2019-03-23 15:26:46,900] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143500, global step 2297799: loss -52.8803
[2019-03-23 15:26:46,902] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143500, global step 2297799: learning rate 0.0001
[2019-03-23 15:26:47,278] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143500, global step 2298023: loss 29.9935
[2019-03-23 15:26:47,280] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143500, global step 2298023: learning rate 0.0001
[2019-03-23 15:26:47,873] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 3.2162749e-16 2.3776219e-29 2.5174539e-23 0.0000000e+00], sum to 1.0000
[2019-03-23 15:26:47,878] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1322
[2019-03-23 15:26:47,888] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 755151.3326825522 W.
[2019-03-23 15:26:47,891] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.8, 96.33333333333334, 1.0, 2.0, 0.3351671455156887, 1.0, 1.0, 0.3351671455156887, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 755151.3326825522, 755151.3326825519, 181566.6888268228], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6695400.0000, 
sim time next is 6696000.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.313570691369536, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6112262639519581, 6.9112, 6.9112, 77.32846344354104, 703306.0519116923, 703306.0519116923, 181748.3623547071], 
processed observation next is [1.0, 0.5217391304347826, 0.44090909090909086, 0.97, 1.0, 1.0, 0.14196336421192002, 0.0, 0.5, -0.25, 1.0, 0.5, 0.44460894850279736, 0.0, 0.0, 0.5084288129206541, 0.2604837229302564, 0.2604837229302564, 0.4432886886700173], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7896321], dtype=float32), 0.5900069]. 
=============================================
[2019-03-23 15:26:47,907] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[46.432518]
 [46.33286 ]
 [45.734688]
 [46.609375]
 [46.744133]], R is [[46.08655167]
 [45.62568665]
 [45.71026611]
 [45.80937576]
 [45.90845871]].
[2019-03-23 15:26:51,175] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 15:26:51,177] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:26:51,177] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:26:51,178] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:26:51,179] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:26:51,180] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:26:51,181] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:26:51,182] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:26:51,183] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:26:51,183] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:26:51,186] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:26:51,205] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run93
[2019-03-23 15:26:51,232] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run93
[2019-03-23 15:26:51,258] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run93
[2019-03-23 15:26:51,282] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run93
[2019-03-23 15:26:51,307] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run93
[2019-03-23 15:27:00,079] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01125825], dtype=float32), -0.6021366]
[2019-03-23 15:27:00,081] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5023361485402797, 6.911200000000001, 6.9112, 77.32846344354104, 292184.2770875579, 292184.2770875576, 92406.59129922243]
[2019-03-23 15:27:00,082] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:27:00,084] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 2.4644925e-21 1.8750883e-35 4.3891224e-31 0.0000000e+00], sampled 0.751593857476013
[2019-03-23 15:27:02,962] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01125825], dtype=float32), -0.6021366]
[2019-03-23 15:27:02,964] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.33750793, 76.045710705, 1.0, 2.0, 0.5474064032646414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 621753.5692322633, 621753.5692322629, 154072.3377997791]
[2019-03-23 15:27:02,965] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:27:02,968] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0000000e+00 7.6324653e-20 2.7410170e-27 1.0185401e-25 4.7789672e-37], sampled 0.5717845154156208
[2019-03-23 15:27:02,970] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 621753.5692322633 W.
[2019-03-23 15:27:04,957] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01125825], dtype=float32), -0.6021366]
[2019-03-23 15:27:04,958] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.96471822333334, 96.19582274000001, 1.0, 2.0, 0.4188245981020062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338699202423, 473888.1592655624, 473888.1592655624, 131989.7130175514]
[2019-03-23 15:27:04,961] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:27:04,965] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 3.9521217e-22 1.2003483e-33 1.3260893e-30 0.0000000e+00], sampled 0.2511335958304728
[2019-03-23 15:27:17,892] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01125825], dtype=float32), -0.6021366]
[2019-03-23 15:27:17,894] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.58333333333333, 89.16666666666667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7395651551233957, 7.324560183734834, 6.9112, 95.55208726597422, 588132.7009714026, 422243.5019076609, 136626.8571762902]
[2019-03-23 15:27:17,894] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:27:17,897] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 2.4673454e-19 8.0069348e-28 9.3028968e-26 9.5281020e-38], sampled 0.20253051472149808
[2019-03-23 15:27:17,898] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 588132.7009714026 W.
[2019-03-23 15:27:23,455] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01125825], dtype=float32), -0.6021366]
[2019-03-23 15:27:23,456] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [12.1, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3355362122303065, 6.9112, 6.9112, 95.55338769695034, 195577.7054168327, 195577.7054168327, 63711.18282996849]
[2019-03-23 15:27:23,459] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:27:23,463] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 7.6342338e-22 4.0003251e-37 3.1704828e-32 0.0000000e+00], sampled 0.8691453879443529
[2019-03-23 15:27:35,127] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01125825], dtype=float32), -0.6021366]
[2019-03-23 15:27:35,127] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.23333333333333, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6899682645353064, 6.98630789091083, 6.9112, 95.5529786907099, 429802.7974701513, 399660.3101313834, 127022.1623052201]
[2019-03-23 15:27:35,130] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:27:35,133] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0000000e+00 4.0783772e-18 1.4134607e-33 4.4295816e-28 0.0000000e+00], sampled 0.770609652566495
[2019-03-23 15:27:52,601] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01125825], dtype=float32), -0.6021366]
[2019-03-23 15:27:52,603] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.8, 87.0, 1.0, 2.0, 0.503442944986934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 574194.6664635263, 574194.6664635263, 146594.4774836438]
[2019-03-23 15:27:52,603] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:27:52,610] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0000000e+00 2.3330523e-19 7.6630634e-29 2.0441756e-26 0.0000000e+00], sampled 0.7523993806828595
[2019-03-23 15:27:52,610] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 574194.6664635263 W.
[2019-03-23 15:28:37,256] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6862.2842 1793014293.7888 2409.0000
[2019-03-23 15:28:37,718] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6481.6076 1678885180.2952 3057.0000
[2019-03-23 15:28:37,732] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6328.7217 1723294598.4314 3425.0000
[2019-03-23 15:28:37,774] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6294.9961 1685630448.6673 3228.0000
[2019-03-23 15:28:37,877] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6553.1725 1698634175.0084 2957.0000
[2019-03-23 15:28:38,892] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 2300000, evaluation results [2300000.0, 6862.284208925443, 1793014293.78876, 2409.0, 6481.607577760913, 1678885180.2951708, 3057.0, 6294.9960618483565, 1685630448.6673346, 3228.0, 6328.721692698646, 1723294598.4313502, 3425.0, 6553.172466661831, 1698634175.0084193, 2957.0]
[2019-03-23 15:28:40,937] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144500, global step 2301086: loss 19.4721
[2019-03-23 15:28:40,938] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144500, global step 2301086: learning rate 0.0001
[2019-03-23 15:28:41,676] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 2.3995593e-17 4.8457924e-28 9.8211003e-25 1.5840609e-37], sum to 1.0000
[2019-03-23 15:28:41,683] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1721
[2019-03-23 15:28:41,690] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 701025.7118376414 W.
[2019-03-23 15:28:41,695] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.1, 76.5, 1.0, 2.0, 0.6214993449565974, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 701025.7118376414, 701025.7118376414, 148350.9331042371], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6773400.0000, 
sim time next is 6774000.0000, 
raw observation next is [21.46666666666667, 76.33333333333333, 1.0, 2.0, 0.2176971954972945, 1.0, 1.0, 0.2176971954972945, 1.0, 1.0, 0.4331305349941075, 6.9112, 6.9112, 77.3421103, 741869.6582747783, 741869.6582747783, 221486.5687580887], 
processed observation next is [1.0, 0.391304347826087, 0.6121212121212122, 0.7633333333333333, 1.0, 1.0, 0.022121494371618103, 1.0, 0.5, 0.022121494371618103, 1.0, 0.5, 0.1901864785630107, 0.0, 0.0, 0.5085185399722538, 0.2747665401017697, 0.2747665401017697, 0.5402111433124114], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.71056455], dtype=float32), 1.1779604]. 
=============================================
[2019-03-23 15:28:41,729] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[37.878384]
 [38.3453  ]
 [37.761845]
 [37.937805]
 [37.68899 ]], R is [[37.84912491]
 [37.47063446]
 [37.09592819]
 [36.72496796]
 [36.35771942]].
[2019-03-23 15:28:42,316] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.3712419e-13 1.6241706e-29 1.3058493e-22 0.0000000e+00], sum to 1.0000
[2019-03-23 15:28:42,323] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9216
[2019-03-23 15:28:42,330] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 556225.8038204741 W.
[2019-03-23 15:28:42,336] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.6, 60.66666666666667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7641584695348005, 7.280179668878226, 6.9112, 77.32755379316863, 556225.8038204741, 436390.1640066545, 135111.4190178294], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6805200.0000, 
sim time next is 6805800.0000, 
raw observation next is [24.4, 61.0, 1.0, 1.0, 0.2228294527974274, 1.0, 1.0, 0.2228294527974274, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32824171235157, 507314.8825036381, 507314.8825036381, 169892.5879073154], 
processed observation next is [1.0, 0.782608695652174, 0.7454545454545454, 0.61, 1.0, 0.5, 0.028536815996784252, 1.0, 0.5, 0.028536815996784252, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084273550548124, 0.18789440092727336, 0.18789440092727336, 0.41437216562759854], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.30784827], dtype=float32), -0.77508736]. 
=============================================
[2019-03-23 15:28:42,605] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144000, global step 2301953: loss -36.4173
[2019-03-23 15:28:42,607] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144000, global step 2301953: learning rate 0.0001
[2019-03-23 15:28:44,721] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 9.8096997e-10 1.8773533e-24 1.3543541e-17 6.9631247e-37], sum to 1.0000
[2019-03-23 15:28:44,727] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8912
[2019-03-23 15:28:44,730] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.2, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.63097008220322, 6.9112, 6.9112, 77.32846344354104, 365547.2832640692, 365547.2832640692, 117200.3489182382], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6850200.0000, 
sim time next is 6850800.0000, 
raw observation next is [17.2, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6306570597625013, 6.911199999999999, 6.9112, 77.32846344354104, 365366.0112101986, 365366.0112101989, 117172.7310937617], 
processed observation next is [0.0, 0.30434782608695654, 0.41818181818181815, 0.96, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4723672282321448, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13532074489266613, 0.13532074489266627, 0.2857871490091749], 
reward next is 0.7142, 
noisyNet noise sample is [array([0.58256495], dtype=float32), 0.2228922]. 
=============================================
[2019-03-23 15:28:44,797] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.4939927e-09 2.9648700e-24 6.2542981e-19 3.3513851e-37], sum to 1.0000
[2019-03-23 15:28:44,805] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3751
[2019-03-23 15:28:44,811] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.53333333333333, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6446728880306893, 6.9112, 6.9112, 77.32846344354104, 373212.6608539017, 373212.6608539017, 118627.7299909922], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6844800.0000, 
sim time next is 6845400.0000, 
raw observation next is [17.45, 94.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6424670465562533, 6.911199999999999, 6.9112, 77.32846344354104, 371991.5701259371, 371991.5701259373, 118386.2550296992], 
processed observation next is [0.0, 0.21739130434782608, 0.4295454545454545, 0.945, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4892386379375048, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13777465560219893, 0.137774655602199, 0.28874696348707124], 
reward next is 0.7113, 
noisyNet noise sample is [array([-0.15046245], dtype=float32), -1.2172039]. 
=============================================
[2019-03-23 15:28:46,663] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144000, global step 2304105: loss 0.1966
[2019-03-23 15:28:46,666] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144000, global step 2304106: learning rate 0.0001
[2019-03-23 15:28:46,786] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144000, global step 2304171: loss 5.6626
[2019-03-23 15:28:46,787] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144000, global step 2304171: learning rate 0.0001
[2019-03-23 15:28:47,322] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.5741010e-06 9.9999738e-01 4.0224684e-24 1.0869451e-08 0.0000000e+00], sum to 1.0000
[2019-03-23 15:28:47,330] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9814
[2019-03-23 15:28:47,337] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 73.0, 1.0, 2.0, 0.421419923970807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 478573.6217466707, 478573.6217466707, 129102.0367517076], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6904800.0000, 
sim time next is 6905400.0000, 
raw observation next is [22.61666666666667, 73.0, 1.0, 2.0, 0.4194841724452161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476138.7301653822, 476138.7301653822, 128733.9923586643], 
processed observation next is [0.0, 0.9565217391304348, 0.6643939393939395, 0.73, 1.0, 1.0, 0.27435521555652004, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17634767783903044, 0.17634767783903044, 0.3139853472162544], 
reward next is 0.6860, 
noisyNet noise sample is [array([-0.15465544], dtype=float32), 0.49482372]. 
=============================================
[2019-03-23 15:28:47,340] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144000, global step 2304462: loss 2.0728
[2019-03-23 15:28:47,340] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144000, global step 2304462: learning rate 0.0001
[2019-03-23 15:28:47,571] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144000, global step 2304588: loss 4.0629
[2019-03-23 15:28:47,574] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144000, global step 2304589: learning rate 0.0001
[2019-03-23 15:28:47,691] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144000, global step 2304656: loss 1.6142
[2019-03-23 15:28:47,695] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144000, global step 2304656: learning rate 0.0001
[2019-03-23 15:28:47,770] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144000, global step 2304688: loss 0.5008
[2019-03-23 15:28:47,774] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144000, global step 2304691: learning rate 0.0001
[2019-03-23 15:28:48,145] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144000, global step 2304892: loss 3.2450
[2019-03-23 15:28:48,146] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144000, global step 2304892: learning rate 0.0001
[2019-03-23 15:28:48,181] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144000, global step 2304907: loss 1.2627
[2019-03-23 15:28:48,183] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144000, global step 2304907: learning rate 0.0001
[2019-03-23 15:28:48,215] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.1302626e-06 9.9999392e-01 1.8556963e-17 3.8911580e-08 8.1884692e-31], sum to 1.0000
[2019-03-23 15:28:48,225] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9497
[2019-03-23 15:28:48,229] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.06666666666667, 71.66666666666667, 1.0, 2.0, 0.4250298339783294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 483111.3716024688, 483111.3716024688, 129808.6591117855], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6903600.0000, 
sim time next is 6904200.0000, 
raw observation next is [22.88333333333333, 72.33333333333333, 1.0, 2.0, 0.4229462001689734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 480531.8328744086, 480531.8328744086, 129429.0082625609], 
processed observation next is [0.0, 0.9130434782608695, 0.6765151515151513, 0.7233333333333333, 1.0, 1.0, 0.2786827502112167, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17797475291644763, 0.17797475291644763, 0.3156805079574656], 
reward next is 0.6843, 
noisyNet noise sample is [array([0.08077785], dtype=float32), 1.1797816]. 
=============================================
[2019-03-23 15:28:48,286] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144000, global step 2304965: loss 0.3145
[2019-03-23 15:28:48,288] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144000, global step 2304965: learning rate 0.0001
[2019-03-23 15:28:48,573] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144000, global step 2305115: loss 2.3194
[2019-03-23 15:28:48,575] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144000, global step 2305117: learning rate 0.0001
[2019-03-23 15:28:48,651] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144000, global step 2305153: loss 1.8255
[2019-03-23 15:28:48,652] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144000, global step 2305153: learning rate 0.0001
[2019-03-23 15:28:48,779] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144000, global step 2305223: loss 1.3315
[2019-03-23 15:28:48,780] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144000, global step 2305224: learning rate 0.0001
[2019-03-23 15:28:49,766] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144000, global step 2305750: loss 0.8345
[2019-03-23 15:28:49,767] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144000, global step 2305750: learning rate 0.0001
[2019-03-23 15:28:50,427] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.2725222e-04 9.9917275e-01 1.6822846e-16 2.1348820e-08 1.7453958e-28], sum to 1.0000
[2019-03-23 15:28:50,429] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144000, global step 2306102: loss 0.4049
[2019-03-23 15:28:50,434] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144000, global step 2306103: learning rate 0.0001
[2019-03-23 15:28:50,435] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9563
[2019-03-23 15:28:50,444] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666666, 60.0, 1.0, 2.0, 0.4897448719031897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558563.6499127664, 558563.6499127664, 140814.7385576353], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6954000.0000, 
sim time next is 6954600.0000, 
raw observation next is [27.43333333333333, 59.0, 1.0, 2.0, 0.4929861819020036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 562180.9461397793, 562180.9461397793, 141324.5074302757], 
processed observation next is [0.0, 0.4782608695652174, 0.8833333333333332, 0.59, 1.0, 1.0, 0.36623272737750445, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2082151652369553, 0.2082151652369553, 0.34469392056164805], 
reward next is 0.6553, 
noisyNet noise sample is [array([-0.66972625], dtype=float32), -0.5968753]. 
=============================================
[2019-03-23 15:28:50,583] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.5292311e-04 9.9984705e-01 2.1812823e-18 1.1481375e-08 3.2046668e-29], sum to 1.0000
[2019-03-23 15:28:50,591] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7705
[2019-03-23 15:28:50,595] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.25, 66.5, 1.0, 2.0, 0.4604340425214138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 525347.1110905183, 525347.1110905183, 136102.9736468002], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6949800.0000, 
sim time next is 6950400.0000, 
raw observation next is [25.53333333333333, 65.66666666666667, 1.0, 2.0, 0.4652477136605942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 530876.6389695948, 530876.6389695945, 136900.9211760252], 
processed observation next is [0.0, 0.43478260869565216, 0.7969696969696969, 0.6566666666666667, 1.0, 1.0, 0.33155964207574273, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19662097739614623, 0.19662097739614612, 0.33390468579518345], 
reward next is 0.6661, 
noisyNet noise sample is [array([-0.7608153], dtype=float32), 0.14442158]. 
=============================================
[2019-03-23 15:28:51,878] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3966776e-06 9.9999857e-01 6.7043397e-21 6.2367563e-11 1.8376742e-36], sum to 1.0000
[2019-03-23 15:28:51,884] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6989
[2019-03-23 15:28:51,890] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.73333333333333, 68.33333333333334, 1.0, 2.0, 0.5021147872486318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 572561.4366761661, 572561.4366761661, 142443.2738045019], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6981600.0000, 
sim time next is 6982200.0000, 
raw observation next is [25.55, 69.0, 1.0, 2.0, 0.5005855448912505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 570901.2407425449, 570901.2407425449, 142131.1704829988], 
processed observation next is [0.0, 0.8260869565217391, 0.7977272727272727, 0.69, 1.0, 1.0, 0.3757319311140631, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21144490397872032, 0.21144490397872032, 0.3466613914219483], 
reward next is 0.6533, 
noisyNet noise sample is [array([-0.19424708], dtype=float32), -0.72135323]. 
=============================================
[2019-03-23 15:28:55,723] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.6790484e-07 9.9999905e-01 1.4953954e-26 1.3338561e-14 0.0000000e+00], sum to 1.0000
[2019-03-23 15:28:55,732] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9416
[2019-03-23 15:28:55,735] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3518231870843704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 391701.0742500816, 391701.0742500813, 118379.6194619304], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7093800.0000, 
sim time next is 7094400.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.3491612338743127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 388716.4559288201, 388716.4559288204, 118159.6120857777], 
processed observation next is [1.0, 0.08695652173913043, 0.44090909090909086, 0.97, 1.0, 1.0, 0.18645154234289085, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14396905775141486, 0.14396905775141497, 0.28819417581897], 
reward next is 0.7118, 
noisyNet noise sample is [array([-0.7183366], dtype=float32), 0.42657092]. 
=============================================
[2019-03-23 15:28:56,263] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145000, global step 2309176: loss 0.0274
[2019-03-23 15:28:56,266] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145000, global step 2309176: learning rate 0.0001
[2019-03-23 15:28:56,712] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.5981182e-09 1.0000000e+00 8.4521747e-27 3.9981392e-13 0.0000000e+00], sum to 1.0000
[2019-03-23 15:28:56,721] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7226
[2019-03-23 15:28:56,727] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 90.5, 1.0, 2.0, 0.352137945299304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 391401.0757138183, 391401.0757138183, 118130.8909963871], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7080600.0000, 
sim time next is 7081200.0000, 
raw observation next is [18.3, 90.0, 1.0, 2.0, 0.3495772888626847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 388214.0501200749, 388214.0501200752, 117787.9330521604], 
processed observation next is [1.0, 1.0, 0.4681818181818182, 0.9, 1.0, 1.0, 0.18697161107835583, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14378298152595367, 0.14378298152595376, 0.28728764159063513], 
reward next is 0.7127, 
noisyNet noise sample is [array([-0.9775217], dtype=float32), 1.5066838]. 
=============================================
[2019-03-23 15:28:57,684] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144500, global step 2309917: loss 38.7620
[2019-03-23 15:28:57,685] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144500, global step 2309918: learning rate 0.0001
[2019-03-23 15:28:58,026] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.8756075e-02 9.7124398e-01 1.7397225e-18 2.8487575e-09 1.6376416e-29], sum to 1.0000
[2019-03-23 15:28:58,037] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8708
[2019-03-23 15:28:58,044] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3489995138531743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 388533.0142260384, 388533.0142260384, 118145.3722230678], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7096800.0000, 
sim time next is 7097400.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.3477382451737883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 387122.7304422402, 387122.7304422402, 118043.0964405321], 
processed observation next is [1.0, 0.13043478260869565, 0.44090909090909086, 0.97, 1.0, 1.0, 0.18467280646723538, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14337878905268156, 0.14337878905268156, 0.287909991318371], 
reward next is 0.7121, 
noisyNet noise sample is [array([-0.5319765], dtype=float32), -1.542175]. 
=============================================
[2019-03-23 15:29:00,428] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.5938634e-13 3.8228989e-34 1.4242366e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 15:29:00,436] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8336
[2019-03-23 15:29:00,442] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.85, 77.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3976972728105063, 6.911199999999999, 6.9112, 77.32846344354104, 231306.5072853487, 231306.507285349, 69044.00962119314], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7175400.0000, 
sim time next is 7176000.0000, 
raw observation next is [14.7, 78.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3928933212503192, 6.9112, 6.9112, 77.32846344354104, 228511.8029894686, 228511.8029894686, 68468.56042506728], 
processed observation next is [1.0, 0.043478260869565216, 0.3045454545454545, 0.7866666666666667, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1327047446433132, 0.0, 0.0, 0.5084288129206541, 0.08463400110721059, 0.08463400110721059, 0.16699648884162752], 
reward next is 0.8330, 
noisyNet noise sample is [array([-0.9971514], dtype=float32), -1.0955111]. 
=============================================
[2019-03-23 15:29:00,450] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[71.48577 ]
 [71.60881 ]
 [71.796036]
 [72.061676]
 [72.34894 ]], R is [[71.38988495]
 [71.50758362]
 [71.62312317]
 [71.73640442]
 [71.84719849]].
[2019-03-23 15:29:00,583] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 3.1339626e-14 4.1025558e-29 1.1207623e-24 0.0000000e+00], sum to 1.0000
[2019-03-23 15:29:00,595] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9273
[2019-03-23 15:29:00,601] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 912033.9068749938 W.
[2019-03-23 15:29:00,603] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.2, 49.33333333333333, 1.0, 2.0, 0.4054702355240146, 1.0, 1.0, 0.4054702355240146, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 912033.9068749938, 912033.9068749938, 192812.1436932223], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7143600.0000, 
sim time next is 7144200.0000, 
raw observation next is [24.1, 50.0, 1.0, 2.0, 0.397960830932944, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7731360923025759, 6.9112, 6.9112, 77.32846344354104, 890670.7197746023, 890670.7197746023, 204319.8330481621], 
processed observation next is [1.0, 0.6956521739130435, 0.7318181818181819, 0.5, 1.0, 1.0, 0.24745103866617996, 0.0, 0.5, -0.25, 1.0, 0.5, 0.6759087032893941, 0.0, 0.0, 0.5084288129206541, 0.32987804436096385, 0.32987804436096385, 0.49834105621502955], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.4903219], dtype=float32), 0.84847504]. 
=============================================
[2019-03-23 15:29:01,588] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144500, global step 2311983: loss -84.0461
[2019-03-23 15:29:01,589] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144500, global step 2311984: learning rate 0.0001
[2019-03-23 15:29:01,925] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144500, global step 2312166: loss 84.3971
[2019-03-23 15:29:01,927] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144500, global step 2312167: learning rate 0.0001
[2019-03-23 15:29:02,283] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144500, global step 2312349: loss -42.8019
[2019-03-23 15:29:02,285] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144500, global step 2312349: learning rate 0.0001
[2019-03-23 15:29:02,438] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144500, global step 2312431: loss 24.0342
[2019-03-23 15:29:02,440] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144500, global step 2312433: learning rate 0.0001
[2019-03-23 15:29:02,764] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144500, global step 2312603: loss -108.1861
[2019-03-23 15:29:02,765] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144500, global step 2312603: learning rate 0.0001
[2019-03-23 15:29:03,158] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144500, global step 2312801: loss 59.5828
[2019-03-23 15:29:03,162] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144500, global step 2312801: learning rate 0.0001
[2019-03-23 15:29:03,267] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144500, global step 2312861: loss 196.2424
[2019-03-23 15:29:03,270] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144500, global step 2312862: learning rate 0.0001
[2019-03-23 15:29:03,397] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144500, global step 2312928: loss 193.0386
[2019-03-23 15:29:03,399] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144500, global step 2312928: learning rate 0.0001
[2019-03-23 15:29:03,532] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144500, global step 2313001: loss 94.7922
[2019-03-23 15:29:03,534] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144500, global step 2313001: learning rate 0.0001
[2019-03-23 15:29:03,658] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144500, global step 2313069: loss 225.0897
[2019-03-23 15:29:03,662] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144500, global step 2313071: learning rate 0.0001
[2019-03-23 15:29:03,818] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144500, global step 2313158: loss 10.0485
[2019-03-23 15:29:03,820] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144500, global step 2313158: learning rate 0.0001
[2019-03-23 15:29:03,887] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144500, global step 2313190: loss 63.8521
[2019-03-23 15:29:03,888] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144500, global step 2313190: learning rate 0.0001
[2019-03-23 15:29:05,049] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144500, global step 2313806: loss -49.4168
[2019-03-23 15:29:05,051] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144500, global step 2313806: learning rate 0.0001
[2019-03-23 15:29:05,614] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144500, global step 2314103: loss -7.9519
[2019-03-23 15:29:05,618] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144500, global step 2314105: learning rate 0.0001
[2019-03-23 15:29:06,282] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.00000000e+00 7.51718674e-13 1.46861995e-30 3.00033558e-23
 0.00000000e+00], sum to 1.0000
[2019-03-23 15:29:06,287] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4554
[2019-03-23 15:29:06,295] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1286384.270250096 W.
[2019-03-23 15:29:06,300] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.9, 56.5, 1.0, 2.0, 0.6464995538890205, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9695604601501481, 6.911199999999999, 6.9112, 77.32846344325449, 1286384.270250096, 1286384.270250096, 276610.3078971847], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7385400.0000, 
sim time next is 7386000.0000, 
raw observation next is [27.16666666666666, 55.33333333333333, 1.0, 2.0, 0.6115290895337633, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9697400289767413, 6.9112, 6.9112, 77.32846344353928, 1246389.308470117, 1246389.308470117, 272075.5997874803], 
processed observation next is [1.0, 0.4782608695652174, 0.871212121212121, 0.5533333333333332, 1.0, 1.0, 0.514411361917204, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9567714699667732, 0.0, 0.0, 0.5084288129206426, 0.46162566980374703, 0.46162566980374703, 0.6635990238719032], 
reward next is 0.3364, 
noisyNet noise sample is [array([-0.87150687], dtype=float32), -0.87798107]. 
=============================================
[2019-03-23 15:29:06,318] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[65.65452 ]
 [65.89048 ]
 [67.341034]
 [66.97877 ]
 [66.69402 ]], R is [[65.37658691]
 [65.04816437]
 [64.39768219]
 [63.75370789]
 [63.11617279]].
[2019-03-23 15:29:06,673] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.8130900e-01 1.8690960e-02 2.8278840e-20 3.2583599e-12 6.4726467e-35], sum to 1.0000
[2019-03-23 15:29:06,684] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3016
[2019-03-23 15:29:06,691] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.36666666666667, 99.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.6741595373939726, 6.9112, 6.9112, 77.32846344350618, 389291.546088466, 389291.546088466, 122112.6302122022], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7708800.0000, 
sim time next is 7709400.0000, 
raw observation next is [17.45, 98.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6683323079472304, 6.911199999999999, 6.9112, 77.32846344354083, 386082.7680609609, 386082.7680609612, 121436.0886656083], 
processed observation next is [1.0, 0.21739130434782608, 0.4295454545454545, 0.985, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5261890113531864, -8.881784197001253e-17, 0.0, 0.5084288129206527, 0.1429936178003559, 0.142993617800356, 0.29618558211123974], 
reward next is 0.7038, 
noisyNet noise sample is [array([-1.6779902], dtype=float32), -0.040540565]. 
=============================================
[2019-03-23 15:29:10,401] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 2.8850722e-10 3.0815160e-26 1.5149063e-19 0.0000000e+00], sum to 1.0000
[2019-03-23 15:29:10,409] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2154
[2019-03-23 15:29:10,418] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.11666666666667, 84.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7391546308073271, 7.175284920348703, 6.9112, 77.32790902185553, 514869.6979564995, 429100.932238472, 127035.3429395542], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7351800.0000, 
sim time next is 7352400.0000, 
raw observation next is [18.03333333333333, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7332138051178455, 7.126329645007245, 6.9112, 77.32766429126383, 495568.4603892388, 425699.473922719, 126373.9279246342], 
processed observation next is [1.0, 0.08695652173913043, 0.456060606060606, 0.85, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6188768644540651, 0.021512964500724506, 0.0, 0.5084235585547253, 0.1835438742182366, 0.15766647182322927, 0.3082290924991078], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.02529228], dtype=float32), -0.26740056]. 
=============================================
[2019-03-23 15:29:11,930] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145500, global step 2317433: loss 33.9606
[2019-03-23 15:29:11,932] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145500, global step 2317434: learning rate 0.0001
[2019-03-23 15:29:12,370] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 7.4799632e-19 2.7982486e-26 1.0737433e-24 3.5137911e-36], sum to 1.0000
[2019-03-23 15:29:12,375] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1913
[2019-03-23 15:29:12,381] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1380836.421731008 W.
[2019-03-23 15:29:12,384] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.8, 53.0, 1.0, 2.0, 0.729502814840415, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9714192433162091, 6.911200000000001, 6.9112, 77.32846344354104, 1380836.421731008, 1380836.421731007, 290586.5282215322], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7387800.0000, 
sim time next is 7388400.0000, 
raw observation next is [27.9, 53.0, 1.0, 2.0, 0.4818433175590074, 1.0, 1.0, 0.4818433175590074, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1097618.065164617, 1097618.065164617, 225817.6475457747], 
processed observation next is [1.0, 0.5217391304347826, 0.9045454545454544, 0.53, 1.0, 1.0, 0.3523041469487592, 1.0, 0.5, 0.3523041469487592, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4065252093202285, 0.4065252093202285, 0.5507747501116456], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7739168], dtype=float32), 0.3437514]. 
=============================================
[2019-03-23 15:29:12,823] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145000, global step 2317898: loss -44.8677
[2019-03-23 15:29:12,826] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145000, global step 2317900: learning rate 0.0001
[2019-03-23 15:29:16,957] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145000, global step 2320055: loss -21.4278
[2019-03-23 15:29:16,958] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145000, global step 2320055: learning rate 0.0001
[2019-03-23 15:29:17,298] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145000, global step 2320232: loss -31.8278
[2019-03-23 15:29:17,301] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145000, global step 2320232: learning rate 0.0001
[2019-03-23 15:29:17,436] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145000, global step 2320307: loss -12.0072
[2019-03-23 15:29:17,439] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145000, global step 2320307: learning rate 0.0001
[2019-03-23 15:29:17,726] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145000, global step 2320455: loss 23.4327
[2019-03-23 15:29:17,729] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145000, global step 2320456: learning rate 0.0001
[2019-03-23 15:29:18,085] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145000, global step 2320636: loss -1.2636
[2019-03-23 15:29:18,086] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145000, global step 2320636: learning rate 0.0001
[2019-03-23 15:29:18,164] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145000, global step 2320681: loss -39.2047
[2019-03-23 15:29:18,164] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145000, global step 2320681: learning rate 0.0001
[2019-03-23 15:29:18,591] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 3.2584125e-15 3.2940827e-14 1.3651809e-15 1.0527886e-20], sum to 1.0000
[2019-03-23 15:29:18,600] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4865
[2019-03-23 15:29:18,608] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 587514.5043315021 W.
[2019-03-23 15:29:18,612] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.73333333333333, 81.5, 1.0, 1.0, 0.2574352187462161, 0.0, 2.0, 0.0, 1.0, 2.0, 0.518711376672278, 6.9112, 6.9112, 77.32809855160471, 587514.5043315021, 587514.5043315021, 178332.0042234623], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7519800.0000, 
sim time next is 7520400.0000, 
raw observation next is [22.7, 82.0, 1.0, 2.0, 0.2344185468033881, 0.0, 2.0, 0.0, 1.0, 2.0, 0.472381839041426, 6.911199999999999, 6.9112, 77.32846118478572, 534961.7690066893, 534961.7690066895, 173212.5791680693], 
processed observation next is [0.0, 0.043478260869565216, 0.6681818181818181, 0.82, 1.0, 1.0, 0.043023183504235125, 0.0, 1.0, -0.25, 1.0, 1.0, 0.24625977005918004, -8.881784197001253e-17, 0.0, 0.5084287980695084, 0.19813398852099603, 0.19813398852099612, 0.4224697052879739], 
reward next is 0.5775, 
noisyNet noise sample is [array([1.5936077], dtype=float32), -2.2665663]. 
=============================================
[2019-03-23 15:29:18,615] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145000, global step 2320918: loss -15.9652
[2019-03-23 15:29:18,618] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145000, global step 2320920: learning rate 0.0001
[2019-03-23 15:29:18,633] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145000, global step 2320928: loss 23.2632
[2019-03-23 15:29:18,635] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145000, global step 2320928: learning rate 0.0001
[2019-03-23 15:29:18,811] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145000, global step 2321016: loss 28.8633
[2019-03-23 15:29:18,814] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145000, global step 2321016: learning rate 0.0001
[2019-03-23 15:29:18,909] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145000, global step 2321064: loss -11.8554
[2019-03-23 15:29:18,911] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145000, global step 2321065: learning rate 0.0001
[2019-03-23 15:29:19,009] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145000, global step 2321111: loss -4.3544
[2019-03-23 15:29:19,011] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145000, global step 2321112: learning rate 0.0001
[2019-03-23 15:29:19,063] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145000, global step 2321147: loss 13.3389
[2019-03-23 15:29:19,064] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145000, global step 2321147: learning rate 0.0001
[2019-03-23 15:29:19,894] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:29:19,894] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:29:19,941] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run12
[2019-03-23 15:29:20,370] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145000, global step 2321801: loss 3.1759
[2019-03-23 15:29:20,374] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145000, global step 2321803: learning rate 0.0001
[2019-03-23 15:29:20,680] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145000, global step 2321966: loss 1.2036
[2019-03-23 15:29:20,682] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145000, global step 2321967: learning rate 0.0001
[2019-03-23 15:29:25,561] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.6875687e-07 9.9999952e-01 1.4418261e-20 1.8920089e-12 8.3695463e-36], sum to 1.0000
[2019-03-23 15:29:25,568] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5412
[2019-03-23 15:29:25,574] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 77.0, 1.0, 2.0, 0.2281749137546891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 247744.3872981316, 247744.3872981316, 78714.23637294014], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 90000.0000, 
sim time next is 90600.0000, 
raw observation next is [15.66666666666667, 77.83333333333334, 1.0, 2.0, 0.2259100196680026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 245284.6239728472, 245284.6239728472, 77584.6731262327], 
processed observation next is [1.0, 0.043478260869565216, 0.3484848484848486, 0.7783333333333334, 1.0, 1.0, 0.03238752458500322, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09084615702698046, 0.09084615702698046, 0.18923091006398218], 
reward next is 0.8108, 
noisyNet noise sample is [array([-0.15884489], dtype=float32), -1.5542743]. 
=============================================
[2019-03-23 15:29:25,737] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.0393433e-08 9.9999988e-01 6.0556207e-23 5.4782832e-12 4.2256503e-38], sum to 1.0000
[2019-03-23 15:29:25,742] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3394
[2019-03-23 15:29:25,748] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 82.0, 1.0, 2.0, 0.2077025519903881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 225511.0557956987, 225511.055795699, 72409.86519321462], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 93600.0000, 
sim time next is 94200.0000, 
raw observation next is [14.0, 82.00000000000001, 1.0, 2.0, 0.2784561837137965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 302355.0117259032, 302355.0117259032, 79051.66301352587], 
processed observation next is [1.0, 0.08695652173913043, 0.2727272727272727, 0.8200000000000002, 1.0, 1.0, 0.0980702296422456, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11198333767626044, 0.11198333767626044, 0.1928089341793314], 
reward next is 0.8072, 
noisyNet noise sample is [array([-0.3360624], dtype=float32), 0.30693293]. 
=============================================
[2019-03-23 15:29:26,366] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 15:29:26,367] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:29:26,368] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:29:26,370] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:29:26,371] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:29:26,372] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:29:26,373] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:29:26,374] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:29:26,376] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:29:26,380] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:29:26,382] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:29:26,397] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run94
[2019-03-23 15:29:26,421] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run94
[2019-03-23 15:29:26,450] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run94
[2019-03-23 15:29:26,475] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run94
[2019-03-23 15:29:26,476] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run94
[2019-03-23 15:29:36,922] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00465424], dtype=float32), -0.58872175]
[2019-03-23 15:29:36,923] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.6, 40.66666666666667, 1.0, 2.0, 0.3211471737697134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 348702.7805631511, 348702.7805631507, 105302.1417064021]
[2019-03-23 15:29:36,925] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:29:36,928] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.2937910e-05 9.9998701e-01 4.2782886e-18 4.8559601e-10 2.9379721e-29], sampled 0.30658105793332613
[2019-03-23 15:29:46,468] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00465424], dtype=float32), -0.58872175]
[2019-03-23 15:29:46,469] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [28.96666666666667, 52.66666666666666, 1.0, 2.0, 0.5198234027406822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 592354.4893293977, 592354.4893293977, 149276.9964289424]
[2019-03-23 15:29:46,470] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:29:46,474] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.0319108e-05 9.9995971e-01 1.4234043e-16 2.4255811e-09 1.4400493e-26], sampled 0.934026699972683
[2019-03-23 15:29:55,975] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00465424], dtype=float32), -0.58872175]
[2019-03-23 15:29:55,976] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.67694191, 52.67917967, 1.0, 2.0, 0.338273948981033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 374632.780224492, 374632.780224492, 120807.3327559612]
[2019-03-23 15:29:55,977] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:29:55,981] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.08138875e-05 9.99989152e-01 4.02025411e-18 4.96391650e-10
 2.40111178e-29], sampled 0.8346600583516787
[2019-03-23 15:29:56,658] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00465424], dtype=float32), -0.58872175]
[2019-03-23 15:29:56,660] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.62656425666667, 82.99336781, 1.0, 2.0, 0.2089039678658522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 226805.7000585778, 226805.7000585778, 76417.8876267956]
[2019-03-23 15:29:56,662] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:29:56,665] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.4784850e-06 9.9999452e-01 2.3594691e-19 1.2940060e-10 1.6775073e-31], sampled 0.24229458866932851
[2019-03-23 15:30:04,425] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00465424], dtype=float32), -0.58872175]
[2019-03-23 15:30:04,427] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.4, 78.0, 1.0, 2.0, 0.4239108918969118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 460326.7413098601, 460326.7413098597, 124671.7404314704]
[2019-03-23 15:30:04,428] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:30:04,431] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.8898319e-05 9.9997115e-01 5.0633702e-18 4.3015738e-10 5.3549158e-29], sampled 0.2364498670864451
[2019-03-23 15:30:08,154] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00465424], dtype=float32), -0.58872175]
[2019-03-23 15:30:08,157] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.95, 64.83333333333334, 1.0, 2.0, 0.5779339009814394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 659375.063224738, 659375.0632247376, 155286.6690527139]
[2019-03-23 15:30:08,158] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:30:08,162] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.2711482e-05 9.9998724e-01 5.2190237e-18 5.5701915e-10 3.8435799e-29], sampled 0.993610814828355
[2019-03-23 15:30:11,234] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00465424], dtype=float32), -0.58872175]
[2019-03-23 15:30:11,238] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.35, 74.16666666666666, 1.0, 2.0, 0.2337509239854423, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 253787.5761650353, 253787.5761650349, 83917.02366455476]
[2019-03-23 15:30:11,239] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:30:11,242] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.7767760e-06 9.9999321e-01 1.1071221e-18 2.8678585e-10 2.3294040e-30], sampled 0.9680095756663845
[2019-03-23 15:30:14,352] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00465424], dtype=float32), -0.58872175]
[2019-03-23 15:30:14,352] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.084052585, 65.62691908833332, 1.0, 2.0, 0.5351111137085361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 610170.2421429706, 610170.2421429701, 147953.9379126212]
[2019-03-23 15:30:14,354] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:30:14,357] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.5577176e-06 9.9999547e-01 7.2902302e-19 2.5030283e-10 9.5404946e-31], sampled 0.2476258336789865
[2019-03-23 15:30:16,143] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00465424], dtype=float32), -0.58872175]
[2019-03-23 15:30:16,147] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.14400540666667, 76.783508725, 1.0, 2.0, 0.4187036967349451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 472675.2566088795, 472675.2566088795, 131345.1796458276]
[2019-03-23 15:30:16,149] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:30:16,151] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0004491e-05 9.9998999e-01 9.3762329e-18 8.1194107e-10 8.6756199e-29], sampled 0.6542246611576279
[2019-03-23 15:30:29,076] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00465424], dtype=float32), -0.58872175]
[2019-03-23 15:30:29,077] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.118977235, 91.66022520499999, 1.0, 2.0, 0.3481678815011228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 386494.7478556917, 386494.7478556917, 121932.856426633]
[2019-03-23 15:30:29,079] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:30:29,081] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.9354921e-06 9.9999511e-01 3.3417882e-18 5.6793725e-10 1.1257716e-29], sampled 0.9377663385740348
[2019-03-23 15:30:55,654] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00465424], dtype=float32), -0.58872175]
[2019-03-23 15:30:55,655] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.779246645, 53.364344855, 1.0, 2.0, 0.2959299115892591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 321314.4650652804, 321314.4650652804, 99066.56663601748]
[2019-03-23 15:30:55,656] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:30:55,660] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.6697212e-06 9.9999332e-01 1.7687715e-18 3.5719544e-10 4.9426107e-30], sampled 0.4459091821804734
[2019-03-23 15:31:06,179] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00465424], dtype=float32), -0.58872175]
[2019-03-23 15:31:06,180] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [14.1, 84.0, 1.0, 2.0, 0.3425813884415098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 371983.3325025738, 371983.3325025735, 91277.77637697103]
[2019-03-23 15:31:06,181] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:31:06,184] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.9369942e-06 9.9999511e-01 5.5743655e-19 2.0684598e-10 6.7459453e-31], sampled 0.093233450492478
[2019-03-23 15:31:09,533] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00465424], dtype=float32), -0.58872175]
[2019-03-23 15:31:09,534] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.96666666666667, 52.33333333333334, 1.0, 2.0, 0.3777387003984703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 410171.0384945287, 410171.0384945283, 120047.6134419875]
[2019-03-23 15:31:09,536] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:31:09,537] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.0542741e-06 9.9999189e-01 2.3192893e-18 4.0348769e-10 8.3749380e-30], sampled 0.24797137091895805
[2019-03-23 15:31:12,779] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00465424], dtype=float32), -0.58872175]
[2019-03-23 15:31:12,780] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.06666666666667, 60.33333333333334, 1.0, 2.0, 0.3227220554006693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 351038.7329081713, 351038.7329081717, 117262.5176852107]
[2019-03-23 15:31:12,781] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:31:12,784] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.5781914e-05 9.9998426e-01 7.5514087e-18 6.2544914e-10 7.6076026e-29], sampled 0.11423273586712401
[2019-03-23 15:31:13,036] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8606.2188 1705817617.5903 465.0000
[2019-03-23 15:31:13,222] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0444 1773163022.0884 173.0000
[2019-03-23 15:31:13,265] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9067.9194 1656072448.3809 80.0000
[2019-03-23 15:31:13,380] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8855.8668 1663754703.0909 106.0000
[2019-03-23 15:31:13,435] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8572.4021 1683281658.6191 214.0000
[2019-03-23 15:31:14,475] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2325000, evaluation results [2325000.0, 8513.044440378659, 1773163022.0884285, 173.0, 9067.919440914608, 1656072448.3808725, 80.0, 8855.86683429155, 1663754703.0908902, 106.0, 8606.218829891337, 1705817617.5903056, 465.0, 8572.40206756753, 1683281658.619057, 214.0]
[2019-03-23 15:31:14,665] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1033197e-06 9.9999893e-01 6.7715596e-20 4.2355328e-11 1.0754225e-32], sum to 1.0000
[2019-03-23 15:31:14,674] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1394
[2019-03-23 15:31:14,681] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.61666666666667, 80.00000000000001, 1.0, 2.0, 0.485413918503796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 553801.2853231912, 553801.2853231912, 139910.5139098169], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7672200.0000, 
sim time next is 7672800.0000, 
raw observation next is [23.43333333333334, 81.0, 1.0, 2.0, 0.4849324083747856, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 553275.4391475534, 553275.4391475534, 139778.2389768467], 
processed observation next is [1.0, 0.8260869565217391, 0.7015151515151519, 0.81, 1.0, 1.0, 0.35616551046848194, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20491682931390867, 0.20491682931390867, 0.34092253408987], 
reward next is 0.6591, 
noisyNet noise sample is [array([-0.25875944], dtype=float32), 0.2970492]. 
=============================================
[2019-03-23 15:31:16,123] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145500, global step 2325868: loss 1.9992
[2019-03-23 15:31:16,126] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145500, global step 2325870: learning rate 0.0001
[2019-03-23 15:31:20,134] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145500, global step 2327991: loss 0.2314
[2019-03-23 15:31:20,137] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145500, global step 2327993: learning rate 0.0001
[2019-03-23 15:31:20,619] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145500, global step 2328247: loss 0.3720
[2019-03-23 15:31:20,627] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145500, global step 2328248: learning rate 0.0001
[2019-03-23 15:31:20,715] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145500, global step 2328293: loss 0.1455
[2019-03-23 15:31:20,717] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145500, global step 2328293: learning rate 0.0001
[2019-03-23 15:31:21,030] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.9588846e-07 9.9999952e-01 4.7044179e-25 4.0364357e-12 0.0000000e+00], sum to 1.0000
[2019-03-23 15:31:21,039] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8251
[2019-03-23 15:31:21,045] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 52.5, 1.0, 2.0, 0.2902851015139143, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 315203.3226637584, 315203.3226637587, 90973.88944669161], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7756200.0000, 
sim time next is 7756800.0000, 
raw observation next is [20.13333333333333, 53.66666666666666, 1.0, 2.0, 0.28301506327353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 307306.7264607733, 307306.726460773, 89132.48915447654], 
processed observation next is [1.0, 0.782608695652174, 0.5515151515151513, 0.5366666666666666, 1.0, 1.0, 0.10376882909191247, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11381730609658271, 0.11381730609658258, 0.21739631501091838], 
reward next is 0.7826, 
noisyNet noise sample is [array([1.0529085], dtype=float32), -0.063146226]. 
=============================================
[2019-03-23 15:31:21,107] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145500, global step 2328497: loss 0.1852
[2019-03-23 15:31:21,113] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145500, global step 2328497: learning rate 0.0001
[2019-03-23 15:31:21,153] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145500, global step 2328525: loss 0.1020
[2019-03-23 15:31:21,155] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145500, global step 2328525: learning rate 0.0001
[2019-03-23 15:31:21,236] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145500, global step 2328566: loss 0.0671
[2019-03-23 15:31:21,239] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145500, global step 2328567: learning rate 0.0001
[2019-03-23 15:31:21,622] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.6213466e-07 9.9999952e-01 4.9698657e-23 1.6908484e-14 4.6138537e-38], sum to 1.0000
[2019-03-23 15:31:21,630] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4831
[2019-03-23 15:31:21,633] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 63.0, 1.0, 2.0, 0.2487411268572745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 270080.6663177864, 270080.6663177864, 80483.633033743], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7768800.0000, 
sim time next is 7769400.0000, 
raw observation next is [17.51666666666667, 64.16666666666667, 1.0, 2.0, 0.247986710201251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 269261.3013918719, 269261.3013918716, 80312.72204348199], 
processed observation next is [1.0, 0.9565217391304348, 0.43257575757575767, 0.6416666666666667, 1.0, 1.0, 0.05998338775156372, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09972640792291551, 0.0997264079229154, 0.1958846879109317], 
reward next is 0.8041, 
noisyNet noise sample is [array([1.1621279], dtype=float32), -0.11540528]. 
=============================================
[2019-03-23 15:31:21,724] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145500, global step 2328826: loss 0.0951
[2019-03-23 15:31:21,727] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145500, global step 2328826: learning rate 0.0001
[2019-03-23 15:31:21,790] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145500, global step 2328861: loss 0.1319
[2019-03-23 15:31:21,791] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145500, global step 2328861: learning rate 0.0001
[2019-03-23 15:31:21,901] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145500, global step 2328919: loss 0.1702
[2019-03-23 15:31:21,903] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145500, global step 2328920: learning rate 0.0001
[2019-03-23 15:31:22,035] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145500, global step 2328989: loss 0.0598
[2019-03-23 15:31:22,036] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145500, global step 2328989: learning rate 0.0001
[2019-03-23 15:31:22,104] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145500, global step 2329030: loss 0.0401
[2019-03-23 15:31:22,107] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145500, global step 2329032: learning rate 0.0001
[2019-03-23 15:31:22,217] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145500, global step 2329088: loss 0.0692
[2019-03-23 15:31:22,218] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145500, global step 2329088: learning rate 0.0001
[2019-03-23 15:31:23,305] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145500, global step 2329664: loss 0.0039
[2019-03-23 15:31:23,307] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145500, global step 2329664: learning rate 0.0001
[2019-03-23 15:31:23,809] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145500, global step 2329929: loss 0.0180
[2019-03-23 15:31:23,811] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145500, global step 2329929: learning rate 0.0001
[2019-03-23 15:31:24,000] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:31:24,000] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:31:24,026] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run12
[2019-03-23 15:31:25,795] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.1277858e-04 9.9978727e-01 4.5366878e-21 5.3597971e-10 2.6153799e-34], sum to 1.0000
[2019-03-23 15:31:25,802] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9628
[2019-03-23 15:31:25,808] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 63.0, 1.0, 2.0, 0.2951290446335647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 320464.8053487063, 320464.8053487063, 103989.5090854971], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7851600.0000, 
sim time next is 7852200.0000, 
raw observation next is [20.0, 63.0, 1.0, 2.0, 0.2941697596891436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 319422.8271716449, 319422.8271716449, 103906.103902565], 
processed observation next is [1.0, 0.9130434782608695, 0.5454545454545454, 0.63, 1.0, 1.0, 0.1177121996114295, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11830475080431292, 0.11830475080431292, 0.25342952171357314], 
reward next is 0.7466, 
noisyNet noise sample is [array([1.7048154], dtype=float32), -0.102756165]. 
=============================================
[2019-03-23 15:31:27,979] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:31:27,980] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:31:28,025] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run12
[2019-03-23 15:31:28,288] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:31:28,289] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:31:28,319] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run12
[2019-03-23 15:31:28,395] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:31:28,396] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:31:28,413] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run12
[2019-03-23 15:31:28,636] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:31:28,637] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:31:28,651] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run12
[2019-03-23 15:31:28,777] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:31:28,777] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:31:28,785] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run12
[2019-03-23 15:31:28,813] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:31:28,814] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:31:28,829] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run12
[2019-03-23 15:31:29,149] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:31:29,149] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:31:29,152] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run12
[2019-03-23 15:31:29,217] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:31:29,217] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:31:29,221] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run12
[2019-03-23 15:31:29,257] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:31:29,258] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:31:29,267] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run12
[2019-03-23 15:31:29,345] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:31:29,345] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:31:29,352] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run12
[2019-03-23 15:31:29,386] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:31:29,387] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:31:29,390] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run12
[2019-03-23 15:31:29,457] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:31:29,458] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:31:29,461] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run12
[2019-03-23 15:31:29,912] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:31:29,912] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:31:29,915] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run12
[2019-03-23 15:31:30,068] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 15:31:30,068] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:31:30,071] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run12
[2019-03-23 15:31:33,561] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9999917e-01 7.7654465e-07 1.3944773e-28 5.2910691e-19 0.0000000e+00], sum to 1.0000
[2019-03-23 15:31:33,566] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6439
[2019-03-23 15:31:33,573] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.0, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4276842462340321, 6.911200000000001, 6.9112, 77.32846344354104, 248751.826223403, 248751.8262234027, 76857.61486230386], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 87000.0000, 
sim time next is 87600.0000, 
raw observation next is [16.0, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.427885811222503, 6.911199999999998, 6.9112, 77.32846344354104, 248869.0914421031, 248869.0914421036, 76851.99400878993], 
processed observation next is [1.0, 0.0, 0.36363636363636365, 0.77, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1826940160321472, -1.7763568394002506e-16, 0.0, 0.5084288129206541, 0.09217373757114929, 0.09217373757114948, 0.1874438878263169], 
reward next is 0.8126, 
noisyNet noise sample is [array([-0.6731426], dtype=float32), 1.104388]. 
=============================================
[2019-03-23 15:31:35,542] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 8.1726362e-12 2.5926472e-36 1.5927916e-23 0.0000000e+00], sum to 1.0000
[2019-03-23 15:31:35,548] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0070
[2019-03-23 15:31:35,552] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [13.83333333333333, 83.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3999117884024067, 6.9112, 6.9112, 77.32846344354104, 232594.8096623888, 232594.8096623888, 67626.17799565327], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 97800.0000, 
sim time next is 98400.0000, 
raw observation next is [13.66666666666667, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3831758662330078, 6.911200000000001, 6.9112, 77.32846344354104, 222858.7115485393, 222858.711548539, 66182.76977531318], 
processed observation next is [1.0, 0.13043478260869565, 0.25757575757575774, 0.84, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.11882266604715404, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08254026353649603, 0.08254026353649592, 0.1614213896958858], 
reward next is 0.8386, 
noisyNet noise sample is [array([-1.4457399], dtype=float32), 0.76394755]. 
=============================================
[2019-03-23 15:31:37,982] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 2.2773333e-16 2.3148951e-35 1.2162725e-27 0.0000000e+00], sum to 1.0000
[2019-03-23 15:31:37,997] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0189
[2019-03-23 15:31:38,001] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.33333333333333, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4430449522906658, 6.911199999999999, 6.9112, 77.32846344354104, 257688.3627707406, 257688.3627707408, 74936.89259367144], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 164400.0000, 
sim time next is 165000.0000, 
raw observation next is [16.16666666666667, 70.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4380134214168158, 6.9112, 6.9112, 77.32846344354104, 254761.1055761047, 254761.1055761047, 74585.43086301301], 
processed observation next is [1.0, 0.9130434782608695, 0.37121212121212144, 0.705, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1971620305954512, 0.0, 0.0, 0.5084288129206541, 0.09435596502818692, 0.09435596502818692, 0.18191568503173905], 
reward next is 0.8181, 
noisyNet noise sample is [array([0.15006562], dtype=float32), -0.679078]. 
=============================================
[2019-03-23 15:31:38,015] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[78.44443 ]
 [78.377945]
 [78.30558 ]
 [78.2396  ]
 [78.18857 ]], R is [[78.53694916]
 [78.56880951]
 [78.59933472]
 [78.6282959 ]
 [78.65599823]].
[2019-03-23 15:31:47,113] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.00000000e+00 4.37206525e-14 1.20430195e-33 2.38653202e-25
 0.00000000e+00], sum to 1.0000
[2019-03-23 15:31:47,119] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8085
[2019-03-23 15:31:47,122] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.83333333333334, 43.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4921301822932884, 6.9112, 6.9112, 77.32846344354104, 286246.2206358277, 286246.2206358277, 86266.15490911416], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 312600.0000, 
sim time next is 313200.0000, 
raw observation next is [22.0, 43.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.495138854013188, 6.9112, 6.9112, 77.32846344354104, 287996.7247408383, 287996.7247408383, 87485.53599702464], 
processed observation next is [0.0, 0.6521739130434783, 0.6363636363636364, 0.43, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2787697914474115, 0.0, 0.0, 0.5084288129206541, 0.10666545360771788, 0.10666545360771788, 0.21337935609030398], 
reward next is 0.7866, 
noisyNet noise sample is [array([0.15534417], dtype=float32), 0.05870754]. 
=============================================
[2019-03-23 15:31:48,116] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 7.9307804e-22 2.3859008e-35 1.2945998e-30 0.0000000e+00], sum to 1.0000
[2019-03-23 15:31:48,122] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8775
[2019-03-23 15:31:48,127] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.16666666666667, 57.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.397890785883719, 6.9112, 6.9112, 77.32846344354104, 231419.08407271, 231419.08407271, 68226.34337537902], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 334200.0000, 
sim time next is 334800.0000, 
raw observation next is [17.0, 59.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3941612137541002, 6.9112, 6.9112, 77.32846344354104, 229249.3993389895, 229249.3993389895, 67903.80078766278], 
processed observation next is [0.0, 0.9130434782608695, 0.4090909090909091, 0.59, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.13451601964871457, 0.0, 0.0, 0.5084288129206541, 0.08490718494036648, 0.08490718494036648, 0.16561902631137262], 
reward next is 0.8344, 
noisyNet noise sample is [array([-1.7925038], dtype=float32), 0.18599391]. 
=============================================
[2019-03-23 15:31:52,346] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 2.4671838e-09 1.8294369e-29 7.4410304e-19 0.0000000e+00], sum to 1.0000
[2019-03-23 15:31:52,354] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7344
[2019-03-23 15:31:52,358] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [13.0, 99.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3632683781386706, 6.911199999999999, 6.9112, 77.32846344354104, 211277.8133942387, 211277.813394239, 67981.12947590611], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 433200.0000, 
sim time next is 433800.0000, 
raw observation next is [13.0, 99.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3633710241251712, 6.9112, 6.9112, 77.32846344354104, 211337.5255302898, 211337.5255302898, 67921.4151313892], 
processed observation next is [1.0, 0.0, 0.22727272727272727, 0.995, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0905300344645303, 0.0, 0.0, 0.5084288129206541, 0.07827315760381104, 0.07827315760381104, 0.16566198812533953], 
reward next is 0.8343, 
noisyNet noise sample is [array([-0.6480908], dtype=float32), -0.5201062]. 
=============================================
[2019-03-23 15:31:55,352] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.8335589e-08 1.0000000e+00 7.0635618e-28 1.4559375e-12 0.0000000e+00], sum to 1.0000
[2019-03-23 15:31:55,359] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2488
[2019-03-23 15:31:55,365] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.66666666666667, 90.0, 1.0, 2.0, 0.2310342188828885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 250849.7219662056, 250849.7219662053, 79585.74261782176], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 508800.0000, 
sim time next is 509400.0000, 
raw observation next is [14.5, 91.0, 1.0, 2.0, 0.2271848427615698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 246669.130049335, 246669.1300493353, 78884.56940215493], 
processed observation next is [1.0, 0.9130434782608695, 0.29545454545454547, 0.91, 1.0, 1.0, 0.03398105345196224, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09135893705530926, 0.09135893705530937, 0.19240138878574373], 
reward next is 0.8076, 
noisyNet noise sample is [array([-1.0266201], dtype=float32), 0.5827858]. 
=============================================
[2019-03-23 15:31:57,023] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.5351858e-03 9.9446481e-01 1.8795834e-22 2.0393073e-11 1.7787811e-36], sum to 1.0000
[2019-03-23 15:31:57,030] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.92582268e-03 9.96074200e-01 1.21166645e-23 2.07949131e-12
 3.52980133e-37], sum to 1.0000
[2019-03-23 15:31:57,034] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7268
[2019-03-23 15:31:57,039] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2138965708898807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 232237.7579670328, 232237.7579670328, 76616.4481239043], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 531000.0000, 
sim time next is 531600.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2128959175531676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 231151.042523119, 231151.0425231193, 76493.48431687053], 
processed observation next is [1.0, 0.13043478260869565, 0.2727272727272727, 0.94, 1.0, 1.0, 0.016119896941459502, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08561149723078482, 0.08561149723078493, 0.18656947394358664], 
reward next is 0.8134, 
noisyNet noise sample is [array([0.16551495], dtype=float32), 0.35305077]. 
=============================================
[2019-03-23 15:31:57,040] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9550
[2019-03-23 15:31:57,047] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 96.0, 1.0, 2.0, 0.4046678008279072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 455639.9373329426, 455639.9373329426, 125076.4269292458], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 976800.0000, 
sim time next is 977400.0000, 
raw observation next is [18.5, 97.0, 1.0, 2.0, 0.3964531137900652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 446100.8350175425, 446100.8350175425, 124189.57543056], 
processed observation next is [1.0, 0.30434782608695654, 0.4772727272727273, 0.97, 1.0, 1.0, 0.24556639223758148, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1652225314879787, 0.1652225314879787, 0.3029014034891707], 
reward next is 0.6971, 
noisyNet noise sample is [array([0.04848533], dtype=float32), 0.4353035]. 
=============================================
[2019-03-23 15:32:02,074] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.3266289e-02 9.5673376e-01 9.3403409e-21 6.5729431e-13 4.0437697e-35], sum to 1.0000
[2019-03-23 15:32:02,081] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7894
[2019-03-23 15:32:02,089] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 88.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.4830296811868691, 6.911199999999999, 6.9112, 77.32846344354104, 280951.4092715892, 280951.4092715895, 83061.92308882484], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 612000.0000, 
sim time next is 612600.0000, 
raw observation next is [16.0, 88.00000000000001, 1.0, 1.0, 0.2869409628907966, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 311570.9582584527, 311570.9582584529, 97510.10996886402], 
processed observation next is [1.0, 0.08695652173913043, 0.36363636363636365, 0.8800000000000001, 1.0, 0.5, 0.10867620361349577, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11539665120683433, 0.1153966512068344, 0.23782953650942446], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.6419734], dtype=float32), 0.37603217]. 
=============================================
[2019-03-23 15:32:02,990] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 15:32:02,991] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:32:02,991] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:32:02,999] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:32:02,999] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:32:03,000] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:32:03,001] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:32:03,001] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:32:03,003] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:32:03,001] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:32:03,004] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:32:03,026] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run95
[2019-03-23 15:32:03,054] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run95
[2019-03-23 15:32:03,082] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run95
[2019-03-23 15:32:03,111] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run95
[2019-03-23 15:32:03,139] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run95
[2019-03-23 15:32:21,986] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00362935], dtype=float32), -0.60418314]
[2019-03-23 15:32:21,990] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.8, 62.66666666666666, 1.0, 2.0, 0.7002521684997044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 798286.6770398674, 798286.6770398674, 173323.820865499]
[2019-03-23 15:32:21,992] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:32:21,997] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 2.1313348e-22 1.1133274e-30 3.7071864e-28 0.0000000e+00], sampled 0.40709016494719386
[2019-03-23 15:32:22,000] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 798286.6770398674 W.
[2019-03-23 15:32:32,436] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00362935], dtype=float32), -0.60418314]
[2019-03-23 15:32:32,437] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.12664347, 49.05885408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7186961970098041, 7.193952297240715, 6.9112, 95.55234593615293, 526997.7159137902, 413523.6055690058, 131997.1560323042]
[2019-03-23 15:32:32,439] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:32:32,443] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0000000e+00 2.0306077e-09 2.1764424e-21 1.2381033e-16 4.5733566e-32], sampled 0.5420743052983811
[2019-03-23 15:32:44,416] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00362935], dtype=float32), -0.60418314]
[2019-03-23 15:32:44,418] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.6, 75.0, 1.0, 1.0, 0.5291226143459437, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 95.55296208387898, 603571.8170657544, 603571.8170657544, 147755.2884065645]
[2019-03-23 15:32:44,420] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:32:44,423] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 1.7846596e-22 1.1024828e-30 4.2492076e-28 0.0000000e+00], sampled 0.9156854804241971
[2019-03-23 15:32:44,424] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 603571.8170657544 W.
[2019-03-23 15:33:12,635] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00362935], dtype=float32), -0.60418314]
[2019-03-23 15:33:12,637] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.33333333333334, 83.0, 1.0, 1.0, 0.4436149176424255, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32822735888365, 503811.9355629322, 503811.9355629325, 131314.7387656171]
[2019-03-23 15:33:12,639] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:33:12,642] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 4.1917046e-11 2.0703608e-21 1.8650325e-17 1.0353188e-31], sampled 0.21290518856075458
[2019-03-23 15:33:18,980] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00362935], dtype=float32), -0.60418314]
[2019-03-23 15:33:18,983] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.9, 56.33333333333334, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8094549554694382, 7.574004506309597, 6.9112, 77.3268581748104, 672068.896092293, 456808.0178527777, 144466.0386000361]
[2019-03-23 15:33:18,984] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:33:18,987] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 3.3011224e-13 1.7071145e-24 2.1390096e-20 1.3836692e-35], sampled 0.11796379124466672
[2019-03-23 15:33:18,988] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 672068.896092293 W.
[2019-03-23 15:33:49,288] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6533.3573 1698541259.4324 2953.0000
[2019-03-23 15:33:49,319] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6483.7818 1678800164.6002 3048.0000
[2019-03-23 15:33:49,410] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6855.4687 1792726050.6621 2373.0000
[2019-03-23 15:33:49,437] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6331.9036 1723182374.1704 3410.0000
[2019-03-23 15:33:49,531] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6291.3282 1685513642.5829 3213.0000
[2019-03-23 15:33:50,550] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 2350000, evaluation results [2350000.0, 6855.46868771106, 1792726050.6621156, 2373.0, 6483.781768155679, 1678800164.6002452, 3048.0, 6291.3282231745625, 1685513642.5829172, 3213.0, 6331.903551835411, 1723182374.1704392, 3410.0, 6533.3572968593335, 1698541259.4324338, 2953.0]
[2019-03-23 15:33:59,164] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.7473055e-08 1.0251387e-02 9.1796582e-16 9.8974842e-01 9.6051914e-33], sum to 1.0000
[2019-03-23 15:33:59,170] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7534
[2019-03-23 15:33:59,176] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 55.0, 1.0, 2.0, 0.2663710359380389, 1.0, 2.0, 0.2663710359380389, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 603809.1431266968, 603809.1431266965, 184537.3599322576], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 829800.0000, 
sim time next is 830400.0000, 
raw observation next is [29.0, 55.0, 1.0, 2.0, 0.2660955909184925, 1.0, 2.0, 0.2660955909184925, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 603188.698899395, 603188.698899395, 184488.6404789688], 
processed observation next is [0.0, 0.6086956521739131, 0.9545454545454546, 0.55, 1.0, 1.0, 0.08261948864811561, 1.0, 1.0, 0.08261948864811561, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2234032218145907, 0.2234032218145907, 0.4499722938511434], 
reward next is 0.5500, 
noisyNet noise sample is [array([-0.35424954], dtype=float32), 0.6687046]. 
=============================================
[2019-03-23 15:34:16,158] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1426385e-09 1.0000000e+00 2.3352414e-20 1.3956720e-11 1.7921942e-34], sum to 1.0000
[2019-03-23 15:34:16,165] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5581
[2019-03-23 15:34:16,169] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.83333333333334, 69.83333333333333, 1.0, 2.0, 0.6295202847422946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 717292.5309884605, 717292.5309884608, 159374.6049242349], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1169400.0000, 
sim time next is 1170000.0000, 
raw observation next is [26.0, 70.0, 1.0, 2.0, 0.6355966314104586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 723712.9570551693, 723712.9570551689, 160634.6844885089], 
processed observation next is [1.0, 0.5652173913043478, 0.8181818181818182, 0.7, 1.0, 1.0, 0.5444957892630733, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.268041835946359, 0.2680418359463589, 0.39179191338660707], 
reward next is 0.6082, 
noisyNet noise sample is [array([0.26455984], dtype=float32), -0.40386486]. 
=============================================
[2019-03-23 15:34:16,183] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[70.20389 ]
 [69.95497 ]
 [69.893814]
 [69.94226 ]
 [70.28818 ]], R is [[70.41151428]
 [70.31867981]
 [70.22531891]
 [70.11769104]
 [69.9825592 ]].
[2019-03-23 15:34:17,846] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.8376173e-08 1.0000000e+00 8.2458339e-20 2.8333928e-12 1.2008155e-33], sum to 1.0000
[2019-03-23 15:34:17,858] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7116
[2019-03-23 15:34:17,863] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.5217342743962263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593962.4831383928, 593962.4831383928, 145761.9843787778], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1200600.0000, 
sim time next is 1201200.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.522713080698724, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595076.9630608391, 595076.9630608391, 145882.0173891844], 
processed observation next is [1.0, 0.9130434782608695, 0.7272727272727273, 0.83, 1.0, 1.0, 0.403391350873405, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2203988752077182, 0.2203988752077182, 0.35580979851020583], 
reward next is 0.6442, 
noisyNet noise sample is [array([-1.2208989], dtype=float32), 0.93417716]. 
=============================================
[2019-03-23 15:34:24,680] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.5756478e-09 1.0000000e+00 4.5415218e-18 4.3242793e-10 2.7508621e-28], sum to 1.0000
[2019-03-23 15:34:24,688] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6831
[2019-03-23 15:34:24,697] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1358448.584571701 W.
[2019-03-23 15:34:24,706] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 79.0, 1.0, 2.0, 0.6040443109197928, 1.0, 1.0, 0.6040443109197928, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1358448.584571701, 1358448.584571701, 263130.4451457452], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1335600.0000, 
sim time next is 1336200.0000, 
raw observation next is [26.16666666666667, 78.16666666666667, 1.0, 2.0, 0.9483815112877915, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9865530188920543, 6.9112, 6.9112, 85.63255119717883, 1614821.3470085, 1614821.3470085, 345744.1830034481], 
processed observation next is [1.0, 0.4782608695652174, 0.825757575757576, 0.7816666666666667, 1.0, 1.0, 0.9354768891097393, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9807900269886491, 0.0, 0.0, 0.563027563380161, 0.5980819803735186, 0.5980819803735186, 0.8432784951303612], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5556971], dtype=float32), 1.1715413]. 
=============================================
[2019-03-23 15:34:25,176] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.4563325e-09 1.0000000e+00 1.1892190e-17 5.0097950e-11 3.5704236e-26], sum to 1.0000
[2019-03-23 15:34:25,186] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5863
[2019-03-23 15:34:25,203] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1520535.020513081 W.
[2019-03-23 15:34:25,206] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.5, 73.16666666666667, 1.0, 2.0, 0.4506805135883609, 1.0, 2.0, 0.4506805135883609, 1.0, 1.0, 0.9118976822984334, 6.911199999999999, 6.9112, 77.3421103, 1520535.020513081, 1520535.020513081, 333062.1361748785], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1347000.0000, 
sim time next is 1347600.0000, 
raw observation next is [27.0, 76.33333333333334, 1.0, 2.0, 0.7773897295848872, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9865530188920543, 6.911200000000001, 6.9112, 77.32846344354104, 1422485.991540926, 1422485.991540926, 312223.5347201949], 
processed observation next is [1.0, 0.6086956521739131, 0.8636363636363636, 0.7633333333333334, 1.0, 1.0, 0.7217371619811088, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9807900269886491, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5268466635336763, 0.5268466635336763, 0.7615208163907192], 
reward next is 0.2385, 
noisyNet noise sample is [array([-0.20930189], dtype=float32), -0.68180615]. 
=============================================
[2019-03-23 15:34:32,212] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.6320824e-15 5.4472858e-16 7.8796902e-16 8.9319226e-24], sum to 1.0000
[2019-03-23 15:34:32,218] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3158
[2019-03-23 15:34:32,223] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 573985.0109414579 W.
[2019-03-23 15:34:32,226] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.1264811e-15 2.8237299e-16 9.7111332e-16 8.7994523e-24], sum to 1.0000
[2019-03-23 15:34:32,228] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 1.0, 0.2515034247894511, 1.0, 1.0, 0.2515034247894511, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32807071299366, 573985.0109414579, 573985.0109414576, 177204.9959203105], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1485600.0000, 
sim time next is 1486200.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.4464955841256229, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846101245545, 509156.4824181712, 509156.482418171, 133828.2001186913], 
processed observation next is [0.0, 0.17391304347826086, 0.5454545454545454, 1.0, 1.0, 1.0, 0.3081194801570286, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084287969364497, 0.18857647496969304, 0.18857647496969296, 0.32641024419193004], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.067906], dtype=float32), 0.7582812]. 
=============================================
[2019-03-23 15:34:32,234] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2607
[2019-03-23 15:34:32,244] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 623825.0636791317 W.
[2019-03-23 15:34:32,253] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 100.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7901761288022597, 7.451638085360413, 6.9112, 77.32718055772534, 623825.0636791317, 448304.7393700003, 140324.8487375628], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1488600.0000, 
sim time next is 1489200.0000, 
raw observation next is [20.66666666666667, 100.0, 1.0, 1.0, 0.5041932413468252, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32813868858935, 575330.1347613508, 575330.1347613508, 141148.2689914517], 
processed observation next is [0.0, 0.21739130434782608, 0.575757575757576, 1.0, 1.0, 0.5, 0.38024155168353146, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084266776813486, 0.2130852350967966, 0.2130852350967966, 0.34426407071085785], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.03291596], dtype=float32), -0.66192204]. 
=============================================
[2019-03-23 15:34:36,286] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.0509100e-29 1.5076053e-30 7.2850204e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 15:34:36,294] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2829
[2019-03-23 15:34:36,298] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.83333333333334, 72.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4366109781638006, 6.911199999999999, 6.9112, 77.32846344354104, 253945.1916111617, 253945.191611162, 79446.2877668825], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2011800.0000, 
sim time next is 2012400.0000, 
raw observation next is [17.0, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4404037808462406, 6.911200000000001, 6.9112, 77.32846344354104, 256151.7729415424, 256151.7729415421, 80152.54536984404], 
processed observation next is [0.0, 0.30434782608695654, 0.4090909090909091, 0.72, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.20057682978034375, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09487102701538608, 0.09487102701538595, 0.1954940130971806], 
reward next is 0.8045, 
noisyNet noise sample is [array([-0.34252465], dtype=float32), -0.19530097]. 
=============================================
[2019-03-23 15:34:37,861] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 15:34:37,864] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:34:37,865] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:34:37,868] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:34:37,868] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:34:37,870] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:34:37,871] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:34:37,872] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:34:37,872] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:34:37,872] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:34:37,873] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:34:37,888] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run96
[2019-03-23 15:34:37,919] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run96
[2019-03-23 15:34:37,920] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run96
[2019-03-23 15:34:37,920] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run96
[2019-03-23 15:34:37,979] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run96
[2019-03-23 15:34:47,898] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00088793], dtype=float32), -0.6080682]
[2019-03-23 15:34:47,901] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.84609337166667, 58.75376376666667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7488708713365387, 7.462557976866233, 6.9112, 95.55168126857504, 652726.2487117903, 431456.885696074, 134875.6143191563]
[2019-03-23 15:34:47,904] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:34:47,906] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0000000e+00 3.4748286e-21 2.9480012e-22 3.1691203e-22 7.6332305e-33], sampled 0.8010925194338645
[2019-03-23 15:34:47,908] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 652726.2487117903 W.
[2019-03-23 15:34:52,623] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00088793], dtype=float32), -0.6080682]
[2019-03-23 15:34:52,625] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.18963363, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5293361655928163, 6.9112, 6.9112, 95.55338769695034, 307875.0996817647, 307875.0996817647, 94572.39985244135]
[2019-03-23 15:34:52,627] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:34:52,630] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0000000e+00 6.6959285e-17 2.3749358e-24 6.9761522e-22 2.3146556e-36], sampled 0.34743575344836075
[2019-03-23 15:35:22,452] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00088793], dtype=float32), -0.6080682]
[2019-03-23 15:35:22,452] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.0, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4702333429333402, 6.9112, 6.9112, 77.32846344354104, 273506.4006284022, 273506.4006284022, 84415.34061790191]
[2019-03-23 15:35:22,453] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:35:22,455] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 3.4623716e-17 4.5215975e-30 1.0344377e-25 0.0000000e+00], sampled 0.4419123364767754
[2019-03-23 15:35:28,165] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00088793], dtype=float32), -0.6080682]
[2019-03-23 15:35:28,168] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.83333333333334, 89.83333333333334, 1.0, 2.0, 0.522841143220128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595746.3977184803, 595746.3977184803, 145455.8039794979]
[2019-03-23 15:35:28,169] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:35:28,172] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 2.8778878e-22 9.8900186e-24 1.2434141e-23 8.2224332e-35], sampled 0.9087686120226098
[2019-03-23 15:35:28,174] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 595746.3977184803 W.
[2019-03-23 15:35:58,651] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00088793], dtype=float32), -0.6080682]
[2019-03-23 15:35:58,653] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [28.08509435, 67.4577374, 1.0, 2.0, 0.5806619454846476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338681917459, 655188.6658197951, 655188.6658197955, 159916.900565685]
[2019-03-23 15:35:58,654] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:35:58,659] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0000000e+00 4.9682620e-21 1.1791252e-21 8.5496104e-22 6.5028777e-32], sampled 7.540834777941541e-05
[2019-03-23 15:35:58,659] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 655188.6658197951 W.
[2019-03-23 15:35:59,449] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00088793], dtype=float32), -0.6080682]
[2019-03-23 15:35:59,452] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.0, 80.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5054294780430668, 6.911199999999998, 6.9112, 77.32846344354104, 293984.0588795758, 293984.0588795764, 93519.92125412879]
[2019-03-23 15:35:59,453] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:35:59,456] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 1.6814737e-11 2.0208304e-26 4.8257022e-21 0.0000000e+00], sampled 0.8957755976279028
[2019-03-23 15:36:10,496] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00088793], dtype=float32), -0.6080682]
[2019-03-23 15:36:10,498] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.53333333333333, 67.66666666666666, 1.0, 1.0, 0.4728624551627645, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 95.55308197503535, 537123.2152460504, 537123.2152460504, 138721.8708335712]
[2019-03-23 15:36:10,499] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:36:10,506] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0000000e+00 6.6694489e-15 3.6984354e-17 1.5545416e-16 6.9733973e-26], sampled 0.3345679668491538
[2019-03-23 15:36:22,778] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00088793], dtype=float32), -0.6080682]
[2019-03-23 15:36:22,783] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.26666666666667, 80.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4829682511417395, 6.9112, 6.9112, 95.55338769695034, 280900.1964755895, 280900.1964755895, 90523.21389655239]
[2019-03-23 15:36:22,783] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:36:22,787] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0000000e+00 2.1222085e-10 2.3402920e-25 6.7259219e-20 0.0000000e+00], sampled 0.3375339285605098
[2019-03-23 15:36:24,546] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6862.2842 1793014293.7888 2409.0000
[2019-03-23 15:36:24,680] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6481.6076 1678885180.2952 3057.0000
[2019-03-23 15:36:24,711] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6553.1725 1698634175.0084 2957.0000
[2019-03-23 15:36:24,822] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6328.7217 1723294598.4314 3425.0000
[2019-03-23 15:36:24,840] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6294.9961 1685630448.6673 3228.0000
[2019-03-23 15:36:25,856] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 2375000, evaluation results [2375000.0, 6862.284208925443, 1793014293.78876, 2409.0, 6481.607577760913, 1678885180.2951708, 3057.0, 6294.9960618483565, 1685630448.6673346, 3228.0, 6328.721692698646, 1723294598.4313502, 3425.0, 6553.172466661831, 1698634175.0084193, 2957.0]
[2019-03-23 15:36:28,143] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.6873739e-13 2.8359709e-24 3.2843216e-21 3.5057311e-36], sum to 1.0000
[2019-03-23 15:36:28,149] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7573
[2019-03-23 15:36:28,155] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.16666666666667, 87.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7266761194414454, 7.026772543288511, 6.9112, 77.32802592346745, 456316.5292980287, 418781.1434795174, 128058.09275048], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1641000.0000, 
sim time next is 1641600.0000, 
raw observation next is [19.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7226057014162327, 6.995005719291396, 6.9112, 77.32812588754663, 443791.9179785305, 416573.6532903923, 127520.0600946147], 
processed observation next is [1.0, 0.0, 0.5, 0.88, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6037224305946182, 0.008380571929139612, 0.0, 0.5084265935154586, 0.16436737702908538, 0.15428653825570085, 0.3110245368161334], 
reward next is 0.2699, 
noisyNet noise sample is [array([-0.23408179], dtype=float32), -0.27267495]. 
=============================================
[2019-03-23 15:36:32,589] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5123359e-07 9.9999988e-01 2.5113418e-17 1.6126751e-10 5.8633219e-27], sum to 1.0000
[2019-03-23 15:36:32,591] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1965
[2019-03-23 15:36:32,598] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.43333333333333, 92.66666666666667, 1.0, 2.0, 0.2319932922854099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 251891.3234914352, 251891.3234914352, 79880.04065475283], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2182800.0000, 
sim time next is 2183400.0000, 
raw observation next is [14.55, 92.0, 1.0, 2.0, 0.2315453933415509, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 251404.8826328927, 251404.8826328925, 80027.21876088354], 
processed observation next is [1.0, 0.2608695652173913, 0.2977272727272728, 0.92, 1.0, 1.0, 0.039431741676938595, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09311291949366396, 0.09311291949366389, 0.19518833844117936], 
reward next is 0.8048, 
noisyNet noise sample is [array([1.5409635], dtype=float32), -2.1237042]. 
=============================================
[2019-03-23 15:36:34,717] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6007091e-06 9.9999845e-01 1.4663850e-21 3.1679092e-13 3.6423792e-34], sum to 1.0000
[2019-03-23 15:36:34,726] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6581
[2019-03-23 15:36:34,730] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.33333333333333, 55.0, 1.0, 2.0, 0.3266651877322944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 354720.701553631, 354720.7015536313, 80704.47209933786], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1762800.0000, 
sim time next is 1763400.0000, 
raw observation next is [15.66666666666667, 53.0, 1.0, 2.0, 0.3423990734508641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 371812.4179194601, 371812.4179194601, 82337.45785636111], 
processed observation next is [1.0, 0.391304347826087, 0.3484848484848486, 0.53, 1.0, 1.0, 0.17799884181358014, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13770830293313338, 0.13770830293313338, 0.20082306794234417], 
reward next is 0.7992, 
noisyNet noise sample is [array([1.3123169], dtype=float32), -0.99916595]. 
=============================================
[2019-03-23 15:36:43,517] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.7899849e-07 9.9999964e-01 1.1348361e-21 5.4949785e-14 6.7524054e-33], sum to 1.0000
[2019-03-23 15:36:43,525] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2599
[2019-03-23 15:36:43,531] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 53.0, 1.0, 2.0, 0.2936269616869869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 318833.2393465457, 318833.239346546, 95807.63397226797], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2397600.0000, 
sim time next is 2398200.0000, 
raw observation next is [21.0, 53.0, 1.0, 2.0, 0.2938190689908496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 319041.9064430729, 319041.9064430732, 95816.1651287772], 
processed observation next is [1.0, 0.782608695652174, 0.5909090909090909, 0.53, 1.0, 1.0, 0.11727383623856197, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11816366905298996, 0.11816366905299007, 0.23369796372872487], 
reward next is 0.7663, 
noisyNet noise sample is [array([-0.38540888], dtype=float32), 1.36067]. 
=============================================
[2019-03-23 15:36:49,919] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.4976844e-07 9.9999952e-01 3.1028867e-27 4.8241110e-16 0.0000000e+00], sum to 1.0000
[2019-03-23 15:36:49,928] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2400
[2019-03-23 15:36:49,933] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 60.0, 1.0, 2.0, 0.2630175866488781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 285586.4569862969, 285586.4569862972, 86100.89655130086], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2073000.0000, 
sim time next is 2073600.0000, 
raw observation next is [19.0, 60.0, 1.0, 2.0, 0.2620660031506959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 284552.9182604818, 284552.9182604816, 85997.94488570564], 
processed observation next is [0.0, 0.0, 0.5, 0.6, 1.0, 1.0, 0.07758250393836985, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10538996972610437, 0.1053899697261043, 0.20975108508708692], 
reward next is 0.7902, 
noisyNet noise sample is [array([-0.04204221], dtype=float32), -1.4005463]. 
=============================================
[2019-03-23 15:36:55,784] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.1398310e-05 9.9992859e-01 4.6126969e-24 2.3904085e-16 8.8961097e-35], sum to 1.0000
[2019-03-23 15:36:55,791] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2954
[2019-03-23 15:36:55,798] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 77.0, 1.0, 2.0, 0.5289027207276912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 574457.0724814228, 574457.0724814228, 124775.5323340388], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2195400.0000, 
sim time next is 2196000.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.5066235267125375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 550245.2765279927, 550245.276527993, 124520.1670928881], 
processed observation next is [1.0, 0.43478260869565216, 0.45454545454545453, 0.77, 1.0, 1.0, 0.38327940839067187, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2037945468622195, 0.20379454686221965, 0.30370772461680023], 
reward next is 0.6963, 
noisyNet noise sample is [array([-1.68167], dtype=float32), -1.4759116]. 
=============================================
[2019-03-23 15:36:55,816] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[71.12246 ]
 [71.74118 ]
 [72.44764 ]
 [73.15296 ]
 [73.883804]], R is [[70.6746521 ]
 [70.66357422]
 [70.66165161]
 [70.66864014]
 [70.67941284]].
[2019-03-23 15:36:57,362] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.9153333e-06 9.9999809e-01 3.0766165e-23 8.5601658e-15 1.4233460e-37], sum to 1.0000
[2019-03-23 15:36:57,368] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9347
[2019-03-23 15:36:57,372] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 67.0, 1.0, 2.0, 0.37777172276608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 425274.655629214, 425274.6556292143, 122651.7326164767], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2673000.0000, 
sim time next is 2673600.0000, 
raw observation next is [22.33333333333334, 67.66666666666667, 1.0, 2.0, 0.3765941757038916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 423692.5067797057, 423692.5067797057, 122416.1347689297], 
processed observation next is [0.0, 0.9565217391304348, 0.6515151515151518, 0.6766666666666667, 1.0, 1.0, 0.22074271962986447, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15692315065915025, 0.15692315065915025, 0.29857593846080416], 
reward next is 0.7014, 
noisyNet noise sample is [array([1.2950681], dtype=float32), -0.39207283]. 
=============================================
[2019-03-23 15:36:58,545] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.4769568e-05 9.9996519e-01 2.4595182e-25 3.6367776e-17 4.2094979e-37], sum to 1.0000
[2019-03-23 15:36:58,545] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9426
[2019-03-23 15:36:58,550] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 77.16666666666666, 1.0, 2.0, 0.4291768211262207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469919.2811398479, 469919.2811398479, 122024.8452049433], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2206200.0000, 
sim time next is 2206800.0000, 
raw observation next is [19.0, 78.0, 1.0, 2.0, 0.4326524570928269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 474652.253736495, 474652.2537364953, 122627.4400925934], 
processed observation next is [1.0, 0.5652173913043478, 0.5, 0.78, 1.0, 1.0, 0.2908155713660336, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17579713101351666, 0.17579713101351677, 0.2990913172990083], 
reward next is 0.7009, 
noisyNet noise sample is [array([0.07372807], dtype=float32), 0.024070628]. 
=============================================
[2019-03-23 15:37:02,602] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.6299108e-04 9.9983704e-01 1.8120932e-24 6.6780219e-19 0.0000000e+00], sum to 1.0000
[2019-03-23 15:37:02,610] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1494
[2019-03-23 15:37:02,612] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333333, 62.66666666666666, 1.0, 2.0, 0.2251962912502317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 244509.4896483058, 244509.4896483058, 74126.92849449825], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2331600.0000, 
sim time next is 2332200.0000, 
raw observation next is [16.16666666666667, 65.33333333333334, 1.0, 2.0, 0.2227097353416013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 241809.0115670097, 241809.0115670094, 74269.34639295805], 
processed observation next is [1.0, 1.0, 0.37121212121212144, 0.6533333333333334, 1.0, 1.0, 0.028387169177001605, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08955889317296656, 0.08955889317296645, 0.18114474729989768], 
reward next is 0.8189, 
noisyNet noise sample is [array([-0.93552506], dtype=float32), -1.6020923]. 
=============================================
[2019-03-23 15:37:06,501] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.0897769e-01 6.9102234e-01 6.7309455e-22 2.1433103e-16 3.3889943e-34], sum to 1.0000
[2019-03-23 15:37:06,509] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3375
[2019-03-23 15:37:06,512] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 46.0, 1.0, 2.0, 0.5743193737711418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 623817.1149638064, 623817.1149638064, 124142.1783355511], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2394000.0000, 
sim time next is 2394600.0000, 
raw observation next is [21.83333333333334, 47.16666666666667, 1.0, 2.0, 0.3922450873168397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 425964.0980225675, 425964.0980225678, 105410.2248040797], 
processed observation next is [1.0, 0.7391304347826086, 0.628787878787879, 0.47166666666666673, 1.0, 1.0, 0.24030635914604961, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15776448074909907, 0.15776448074909918, 0.25709810927824317], 
reward next is 0.7429, 
noisyNet noise sample is [array([1.0373516], dtype=float32), 0.08115522]. 
=============================================
[2019-03-23 15:37:08,044] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 7.1697148e-11 1.3504738e-33 9.6681178e-29 0.0000000e+00], sum to 1.0000
[2019-03-23 15:37:08,050] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7561
[2019-03-23 15:37:08,056] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4200758656595292, 6.911200000000001, 6.9112, 77.32846344354104, 244325.490819186, 244325.4908191857, 75402.11444132398], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2438400.0000, 
sim time next is 2439000.0000, 
raw observation next is [14.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4128573818246407, 6.911199999999999, 6.9112, 77.32846344354104, 240126.0232809197, 240126.02328092, 74848.6510088605], 
processed observation next is [1.0, 0.21739130434782608, 0.2727272727272727, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1612248311780582, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0889355641781184, 0.08893556417811851, 0.18255768538746464], 
reward next is 0.8174, 
noisyNet noise sample is [array([-0.10422838], dtype=float32), -0.2833956]. 
=============================================
[2019-03-23 15:37:08,076] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[77.56707 ]
 [77.55855 ]
 [77.53861 ]
 [77.523994]
 [77.50501 ]], R is [[77.6149292 ]
 [77.65487671]
 [77.69322205]
 [77.73204803]
 [77.77264404]].
[2019-03-23 15:37:09,051] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.0963656e-08 1.0926221e-24 1.9491596e-19 4.0077486e-37], sum to 1.0000
[2019-03-23 15:37:09,058] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0018
[2019-03-23 15:37:09,061] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.48333333333333, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5411170984743522, 6.9112, 6.9112, 77.32846344354104, 314743.5077149644, 314743.5077149644, 101174.2920005218], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2602200.0000, 
sim time next is 2602800.0000, 
raw observation next is [16.4, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5283707843680197, 6.911200000000001, 6.9112, 77.32846344354104, 307330.4796111929, 307330.4796111926, 98224.11748190907], 
processed observation next is [0.0, 0.13043478260869565, 0.3818181818181818, 0.88, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3262439776685995, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11382610355970108, 0.11382610355970096, 0.2395710182485587], 
reward next is 0.7604, 
noisyNet noise sample is [array([0.8750213], dtype=float32), 0.50098866]. 
=============================================
[2019-03-23 15:37:09,164] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9999988e-01 9.0545527e-08 1.1424238e-22 9.8960489e-18 2.6807540e-32], sum to 1.0000
[2019-03-23 15:37:09,168] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3684
[2019-03-23 15:37:09,172] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.457296278805005, 6.911199999999999, 6.9112, 77.32846344354104, 265979.632415103, 265979.6324151033, 80932.62937299155], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2448000.0000, 
sim time next is 2448600.0000, 
raw observation next is [15.0, 89.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5898712065298243, 6.9112, 6.9112, 77.32846344354104, 343117.0847249876, 343117.0847249876, 92078.50396663933], 
processed observation next is [1.0, 0.34782608695652173, 0.3181818181818182, 0.8900000000000001, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.41410172361403474, 0.0, 0.0, 0.5084288129206541, 0.1270804017499954, 0.1270804017499954, 0.22458171699180324], 
reward next is 0.7754, 
noisyNet noise sample is [array([0.02741153], dtype=float32), -1.1198353]. 
=============================================
[2019-03-23 15:37:13,092] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 15:37:13,093] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:37:13,094] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:37:13,094] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:37:13,095] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:37:13,097] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:37:13,100] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:37:13,097] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:37:13,100] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:37:13,098] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:37:13,105] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:37:13,123] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run97
[2019-03-23 15:37:13,154] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run97
[2019-03-23 15:37:13,155] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run97
[2019-03-23 15:37:13,155] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run97
[2019-03-23 15:37:13,202] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run97
[2019-03-23 15:37:21,910] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00192902], dtype=float32), -0.60813963]
[2019-03-23 15:37:21,912] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.10952086, 67.6093114, 1.0, 1.0, 0.505969891698159, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 95.55300891262937, 569289.2746581149, 569289.2746581145, 139029.2451529133]
[2019-03-23 15:37:21,913] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:37:21,919] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 6.0978895e-20 8.8719452e-33 2.2173881e-29 0.0000000e+00], sampled 0.009081119216140743
[2019-03-23 15:37:21,920] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 569289.2746581149 W.
[2019-03-23 15:38:05,690] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00192902], dtype=float32), -0.60813963]
[2019-03-23 15:38:05,690] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.41666666666667, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6517807726272495, 6.9112, 6.9112, 95.55338768112914, 377491.4705597202, 377491.4705597202, 123438.4710049372]
[2019-03-23 15:38:05,692] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:38:05,696] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.000000e+00 9.782655e-19 2.230592e-34 5.906776e-30 0.000000e+00], sampled 0.13689940473813222
[2019-03-23 15:38:47,052] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00192902], dtype=float32), -0.60813963]
[2019-03-23 15:38:47,054] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [27.18822670666667, 57.61071595666667, 1.0, 2.0, 0.4835717236766899, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338685736864, 551720.5887210756, 551720.5887210756, 143659.1252991718]
[2019-03-23 15:38:47,054] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:38:47,057] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 1.6139371e-21 3.9321979e-36 3.0996152e-32 0.0000000e+00], sampled 0.3601401697408716
[2019-03-23 15:38:47,059] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 551720.5887210756 W.
[2019-03-23 15:38:59,722] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6862.2842 1793014293.7888 2409.0000
[2019-03-23 15:38:59,836] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6328.7217 1723294598.4314 3425.0000
[2019-03-23 15:38:59,974] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6553.1725 1698634175.0084 2957.0000
[2019-03-23 15:39:00,331] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6294.9961 1685630448.6673 3228.0000
[2019-03-23 15:39:00,348] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6481.6076 1678885180.2952 3057.0000
[2019-03-23 15:39:01,364] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 2400000, evaluation results [2400000.0, 6862.284208925443, 1793014293.78876, 2409.0, 6481.607577760913, 1678885180.2951708, 3057.0, 6294.9960618483565, 1685630448.6673346, 3228.0, 6328.721692698646, 1723294598.4313502, 3425.0, 6553.172466661831, 1698634175.0084193, 2957.0]
[2019-03-23 15:39:06,242] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.8648191e-17 2.0892257e-30 2.0818947e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 15:39:06,248] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6089
[2019-03-23 15:39:06,253] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.33333333333334, 45.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6507534572797808, 6.911199999999999, 6.9112, 77.32846344177864, 375955.6326059579, 375955.6326059581, 119760.9739069327], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2632800.0000, 
sim time next is 2633400.0000, 
raw observation next is [25.5, 44.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6472046897069297, 6.9112, 6.9112, 77.32846344353014, 373958.0779341795, 373958.0779341795, 119394.3455965714], 
processed observation next is [0.0, 0.4782608695652174, 0.7954545454545454, 0.445, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.49600669958132815, 0.0, 0.0, 0.5084288129205824, 0.1385029918274739, 0.1385029918274739, 0.2912057209672473], 
reward next is 0.7088, 
noisyNet noise sample is [array([-1.2556272], dtype=float32), 1.0604229]. 
=============================================
[2019-03-23 15:39:07,972] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.0730485e-01 5.9269518e-01 5.5773958e-14 2.7938399e-10 3.2214117e-21], sum to 1.0000
[2019-03-23 15:39:07,979] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0910
[2019-03-23 15:39:07,986] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.0, 57.0, 1.0, 1.0, 0.3780266715279158, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32841950181948, 424783.9769244149, 424783.9769244146, 122277.3175221411], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2667600.0000, 
sim time next is 2668200.0000, 
raw observation next is [23.83333333333333, 58.33333333333333, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.721430872223803, 6.965615585133851, 6.9112, 77.32828994732593, 432204.2687006634, 414531.2392921512, 128395.5232716359], 
processed observation next is [0.0, 0.9130434782608695, 0.7196969696969695, 0.5833333333333333, 0.0, 0.5, -0.25, 0.0, 1.0, -0.25, 1.0, 0.5, 0.6020441031768614, 0.005441558513385125, 0.0, 0.5084276721961296, 0.16007565507431978, 0.15353008862672265, 0.31315981285764855], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8892976], dtype=float32), 0.32565764]. 
=============================================
[2019-03-23 15:39:08,818] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.0270832e-01 7.9729170e-01 1.3526930e-17 4.8127878e-12 1.5553888e-27], sum to 1.0000
[2019-03-23 15:39:08,826] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5308
[2019-03-23 15:39:08,831] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 88.0, 1.0, 2.0, 0.4764875591828996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 543665.3997462573, 543665.3997462573, 137817.8826548338], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3115200.0000, 
sim time next is 3115800.0000, 
raw observation next is [22.0, 88.0, 1.0, 2.0, 0.4750831926623428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 542060.3784970595, 542060.3784970595, 137654.2156762225], 
processed observation next is [1.0, 0.043478260869565216, 0.6363636363636364, 0.88, 1.0, 1.0, 0.34385399082792845, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20076310314705906, 0.20076310314705906, 0.3357419894542012], 
reward next is 0.6643, 
noisyNet noise sample is [array([0.27494055], dtype=float32), 1.1304297]. 
=============================================
[2019-03-23 15:39:08,864] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.18727723e-04 9.99881268e-01 1.08739865e-17 2.04453440e-10
 1.27330846e-30], sum to 1.0000
[2019-03-23 15:39:08,872] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3171
[2019-03-23 15:39:08,880] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 55.00000000000001, 1.0, 2.0, 0.3597909832213626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 402556.072715061, 402556.0727150613, 119891.4635579844], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2665200.0000, 
sim time next is 2665800.0000, 
raw observation next is [24.0, 55.5, 1.0, 2.0, 0.3639590618032133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 407632.0449666719, 407632.0449666719, 120425.9682497586], 
processed observation next is [0.0, 0.8695652173913043, 0.7272727272727273, 0.555, 1.0, 1.0, 0.2049488272540166, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15097483146913773, 0.15097483146913773, 0.29372187377989906], 
reward next is 0.7063, 
noisyNet noise sample is [array([-0.48507476], dtype=float32), -2.0751255]. 
=============================================
[2019-03-23 15:39:12,807] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.7405543e-06 9.9999630e-01 2.4942583e-20 1.7163222e-12 8.2592355e-30], sum to 1.0000
[2019-03-23 15:39:12,821] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2564
[2019-03-23 15:39:12,825] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 64.5, 1.0, 2.0, 0.4772014830458878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 544388.909976281, 544388.909976281, 139085.5003722696], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2722200.0000, 
sim time next is 2722800.0000, 
raw observation next is [26.33333333333334, 64.0, 1.0, 2.0, 0.481628235056627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 549378.0742460991, 549378.0742460993, 139734.9555216949], 
processed observation next is [0.0, 0.5217391304347826, 0.8333333333333336, 0.64, 1.0, 1.0, 0.3520352938207837, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20347336083188855, 0.20347336083188863, 0.34081696468706074], 
reward next is 0.6592, 
noisyNet noise sample is [array([-0.49240246], dtype=float32), 0.41610143]. 
=============================================
[2019-03-23 15:39:23,139] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.1553633e-05 9.9997842e-01 6.8476410e-18 1.8521372e-11 4.4586811e-27], sum to 1.0000
[2019-03-23 15:39:23,146] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6594
[2019-03-23 15:39:23,153] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5227978844806144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 595584.5439143927, 595584.543914393, 145556.294714573], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2923200.0000, 
sim time next is 2923800.0000, 
raw observation next is [22.83333333333334, 89.83333333333334, 1.0, 2.0, 0.5231594874231991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 596105.3683108569, 596105.3683108569, 145498.3814270613], 
processed observation next is [1.0, 0.8695652173913043, 0.6742424242424245, 0.8983333333333334, 1.0, 1.0, 0.4039493592789988, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2207797660410581, 0.2207797660410581, 0.35487410104161293], 
reward next is 0.6451, 
noisyNet noise sample is [array([0.25412062], dtype=float32), 0.69551337]. 
=============================================
[2019-03-23 15:39:38,908] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9999988e-01 7.1909255e-08 1.0263869e-26 9.3573786e-20 2.2362442e-38], sum to 1.0000
[2019-03-23 15:39:38,912] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6472
[2019-03-23 15:39:38,916] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.66666666666666, 48.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6042720636826721, 6.911200000000001, 6.9112, 77.32846344354104, 350776.2574348401, 350776.2574348398, 114381.193287788], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3262800.0000, 
sim time next is 3263400.0000, 
raw observation next is [23.5, 48.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.60251258792506, 6.911200000000001, 6.9112, 77.32846344354104, 349846.7476499888, 349846.7476499885, 114165.8024341418], 
processed observation next is [0.0, 0.782608695652174, 0.7045454545454546, 0.485, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4321608398929429, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12957286949999586, 0.12957286949999575, 0.27845317666863856], 
reward next is 0.7215, 
noisyNet noise sample is [array([-0.6606291], dtype=float32), 0.083214544]. 
=============================================
[2019-03-23 15:39:40,127] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 2.1755488e-11 4.0290986e-31 1.7982256e-21 0.0000000e+00], sum to 1.0000
[2019-03-23 15:39:40,135] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5371
[2019-03-23 15:39:40,141] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.06666666666667, 48.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6274804713350532, 6.911199999999999, 6.9112, 77.32846344354104, 363578.0733241906, 363578.0733241909, 116854.5785098476], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3248400.0000, 
sim time next is 3249000.0000, 
raw observation next is [24.05, 49.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6312722553602346, 6.9112, 6.9112, 77.32846344354104, 365696.833678356, 365696.833678356, 117246.1626142163], 
processed observation next is [0.0, 0.6086956521739131, 0.7295454545454546, 0.49, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.47324607908604943, 0.0, 0.0, 0.5084288129206541, 0.13544327173272444, 0.13544327173272444, 0.28596625027857636], 
reward next is 0.7140, 
noisyNet noise sample is [array([0.42310917], dtype=float32), -1.7654432]. 
=============================================
[2019-03-23 15:39:40,171] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[72.4343 ]
 [72.4269 ]
 [72.42567]
 [72.42823]
 [72.4286 ]], R is [[72.43254089]
 [72.42320251]
 [72.41535187]
 [72.40929413]
 [72.40406036]].
[2019-03-23 15:39:41,215] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 3.0309651e-11 8.3065351e-30 2.8301068e-21 0.0000000e+00], sum to 1.0000
[2019-03-23 15:39:41,223] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3773
[2019-03-23 15:39:41,228] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.5, 58.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5667673706813375, 6.911199999999999, 6.9112, 77.32846344354104, 329529.7810177344, 329529.7810177347, 110986.3017281637], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3318600.0000, 
sim time next is 3319200.0000, 
raw observation next is [22.0, 57.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5783877484813151, 6.911199999999999, 6.9112, 77.32846344354104, 336048.9775816045, 336048.9775816048, 112063.5278524523], 
processed observation next is [0.0, 0.43478260869565216, 0.6363636363636364, 0.57, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3976967835447359, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12446258428948315, 0.12446258428948326, 0.27332567768890803], 
reward next is 0.7267, 
noisyNet noise sample is [array([-1.6043515], dtype=float32), 1.4882479]. 
=============================================
[2019-03-23 15:39:47,580] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.30631868e-03 9.98693645e-01 7.51830559e-19 5.02168584e-10
 1.02088696e-25], sum to 1.0000
[2019-03-23 15:39:47,592] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0416
[2019-03-23 15:39:47,596] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.7568660542364012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 860662.2224147522, 860662.2224147522, 170197.6117068492], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3403800.0000, 
sim time next is 3404400.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.7703306605650947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 876003.2988683091, 876003.2988683091, 172172.7257159047], 
processed observation next is [1.0, 0.391304347826087, 0.6363636363636364, 0.78, 1.0, 1.0, 0.7129133257063682, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3244456662475219, 0.3244456662475219, 0.4199334773558651], 
reward next is 0.5801, 
noisyNet noise sample is [array([0.08453067], dtype=float32), -0.45774773]. 
=============================================
[2019-03-23 15:39:47,662] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3143525e-02 9.8685652e-01 2.6482563e-17 2.7614502e-10 6.5151620e-24], sum to 1.0000
[2019-03-23 15:39:47,671] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7934
[2019-03-23 15:39:47,674] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5180790457092564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 590213.3560913217, 590213.3560913217, 144976.4171713347], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3450600.0000, 
sim time next is 3451200.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5169182338775263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588890.9458383044, 588890.9458383044, 144835.2885724012], 
processed observation next is [1.0, 0.9565217391304348, 0.6818181818181818, 0.89, 1.0, 1.0, 0.3961477923469079, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2181077577178905, 0.2181077577178905, 0.35325680139610044], 
reward next is 0.6467, 
noisyNet noise sample is [array([-0.27146235], dtype=float32), -2.4133308]. 
=============================================
[2019-03-23 15:39:48,804] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 15:39:48,806] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:39:48,807] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:39:48,807] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:39:48,808] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:39:48,809] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:39:48,810] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:39:48,811] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:39:48,809] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:39:48,813] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:39:48,814] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:39:48,832] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run98
[2019-03-23 15:39:48,862] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run98
[2019-03-23 15:39:48,890] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run98
[2019-03-23 15:39:48,890] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run98
[2019-03-23 15:39:48,958] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run98
[2019-03-23 15:39:59,410] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00607557], dtype=float32), -0.6124494]
[2019-03-23 15:39:59,411] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.2, 43.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6806320034157178, 6.930047440933008, 6.9112, 95.55302858745844, 403468.099070429, 395904.1928088862, 111093.3726983276]
[2019-03-23 15:39:59,413] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:39:59,418] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0000000e+00 2.3448477e-19 1.2994601e-35 1.2568686e-28 0.0000000e+00], sampled 0.7719574843560091
[2019-03-23 15:40:07,998] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00607557], dtype=float32), -0.6124494]
[2019-03-23 15:40:07,999] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.32790386166667, 89.71370010333332, 1.0, 2.0, 0.4597389421639713, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8699360326205258, 6.996614552980775, 6.9112, 95.55305545639386, 1042716.266359777, 1008437.455985206, 248503.0062565242]
[2019-03-23 15:40:08,001] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:40:08,004] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 6.2868581e-14 1.7296648e-23 1.5417357e-19 5.2823266e-32], sampled 0.1579582682532652
[2019-03-23 15:40:08,005] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1042716.266359777 W.
[2019-03-23 15:40:22,893] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00607557], dtype=float32), -0.6124494]
[2019-03-23 15:40:22,895] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.05, 87.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7232241319874274, 7.251395823471667, 6.9112, 95.55204245633178, 553885.8024815139, 417358.8982566216, 131573.924746929]
[2019-03-23 15:40:22,896] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:40:22,899] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.000000e+00 8.880693e-23 1.521309e-37 4.463993e-31 0.000000e+00], sampled 0.4692240747492997
[2019-03-23 15:40:22,901] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 553885.8024815139 W.
[2019-03-23 15:40:26,871] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00607557], dtype=float32), -0.6124494]
[2019-03-23 15:40:26,872] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.93333333333333, 44.66666666666667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7395816565721138, 7.351636701067314, 6.9112, 95.55199686234417, 600806.6112342005, 424051.2648647305, 135349.5340314315]
[2019-03-23 15:40:26,872] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:40:26,874] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0000000e+00 8.6049069e-22 9.9328713e-36 1.0843025e-29 0.0000000e+00], sampled 0.7493367350909335
[2019-03-23 15:40:26,876] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 600806.6112342005 W.
[2019-03-23 15:40:30,730] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00607557], dtype=float32), -0.6124494]
[2019-03-23 15:40:30,731] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 88.0, 1.0, 2.0, 0.481851704106128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 549808.6617451255, 549808.6617451255, 138517.4454515891]
[2019-03-23 15:40:30,732] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:40:30,736] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 1.6278712e-32 3.5981578e-38 2.3576725e-35 0.0000000e+00], sampled 0.5703901456496867
[2019-03-23 15:40:30,739] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 549808.6617451255 W.
[2019-03-23 15:41:03,239] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00607557], dtype=float32), -0.6124494]
[2019-03-23 15:41:03,243] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.2, 60.66666666666666, 1.0, 1.0, 0.5020783198385829, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 95.55302595700837, 571575.9320766196, 571575.9320766192, 142950.1491342282]
[2019-03-23 15:41:03,244] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:41:03,246] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0000000e+00 1.0583524e-22 3.4486309e-35 9.9410139e-30 0.0000000e+00], sampled 0.842990306804326
[2019-03-23 15:41:03,247] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 571575.9320766196 W.
[2019-03-23 15:41:08,675] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00607557], dtype=float32), -0.6124494]
[2019-03-23 15:41:08,676] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.51666666666667, 67.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5816512519563387, 6.911199999999999, 6.9112, 95.55338769695034, 338282.8574432589, 338282.8574432593, 112471.4402823011]
[2019-03-23 15:41:08,679] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:41:08,683] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 6.5968875e-20 2.3990510e-36 2.8403052e-29 0.0000000e+00], sampled 0.3270722606737906
[2019-03-23 15:41:12,253] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00607557], dtype=float32), -0.6124494]
[2019-03-23 15:41:12,256] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.45, 53.0, 1.0, 2.0, 0.5588934218281006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 632205.7275535439, 632205.7275535439, 146459.3564247625]
[2019-03-23 15:41:12,256] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:41:12,260] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0000000e+00 4.3353880e-32 0.0000000e+00 8.8437855e-36 0.0000000e+00], sampled 0.023119205706307433
[2019-03-23 15:41:12,262] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 632205.7275535439 W.
[2019-03-23 15:41:35,188] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6862.2842 1793014293.7888 2409.0000
[2019-03-23 15:41:35,513] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6328.7217 1723294598.4314 3425.0000
[2019-03-23 15:41:35,514] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6481.6076 1678885180.2952 3057.0000
[2019-03-23 15:41:35,551] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6553.1725 1698634175.0084 2957.0000
[2019-03-23 15:41:35,726] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6294.9961 1685630448.6673 3228.0000
[2019-03-23 15:41:36,747] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 2425000, evaluation results [2425000.0, 6862.284208925443, 1793014293.78876, 2409.0, 6481.607577760913, 1678885180.2951708, 3057.0, 6294.9960618483565, 1685630448.6673346, 3228.0, 6328.721692698646, 1723294598.4313502, 3425.0, 6553.172466661831, 1698634175.0084193, 2957.0]
[2019-03-23 15:41:37,661] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 5.7303298e-23 3.0934367e-25 8.1393737e-24 1.7054013e-33], sum to 1.0000
[2019-03-23 15:41:37,665] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2813
[2019-03-23 15:41:37,669] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1200806.24390303 W.
[2019-03-23 15:41:37,672] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.16666666666667, 93.16666666666667, 1.0, 2.0, 0.9970224131947691, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.110086568038128, 6.9112, 77.32806881208757, 1200806.24390303, 1136212.28418301, 220535.3482125653], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3489000.0000, 
sim time next is 3489600.0000, 
raw observation next is [22.33333333333334, 92.33333333333334, 1.0, 2.0, 0.5271133463636432, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9612286729614169, 6.933859723533768, 6.9112, 77.32828834201727, 1148651.266574539, 1141291.868506826, 262741.4607623621], 
processed observation next is [1.0, 0.391304347826087, 0.6515151515151518, 0.9233333333333335, 1.0, 1.0, 0.4088916829545539, 0.0, 1.0, -0.25, 1.0, 0.5, 0.9446123899448814, 0.0022659723533767994, 0.0, 0.5084276616413462, 0.42542639502760704, 0.4227006920395652, 0.6408328311277125], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.15556476], dtype=float32), -0.37946224]. 
=============================================
[2019-03-23 15:41:43,094] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 1.5969380e-19 1.6259642e-19 9.4318145e-20 2.1506376e-26], sum to 1.0000
[2019-03-23 15:41:43,098] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7701
[2019-03-23 15:41:43,101] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1724595.683962251 W.
[2019-03-23 15:41:43,105] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 70.0, 1.0, 2.0, 0.7666067374078565, 1.0, 2.0, 0.7666067374078565, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1724595.683962251, 1724595.683962251, 313502.3290477031], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3601800.0000, 
sim time next is 3602400.0000, 
raw observation next is [27.0, 70.0, 1.0, 2.0, 0.48197966204945, 1.0, 2.0, 0.48197966204945, 1.0, 1.0, 0.9752277355823675, 6.9112, 6.9112, 77.3421103, 1626285.770753624, 1626285.770753624, 350316.2015295098], 
processed observation next is [1.0, 0.6956521739130435, 0.8636363636363636, 0.7, 1.0, 1.0, 0.35247457756181244, 1.0, 1.0, 0.35247457756181244, 1.0, 0.5, 0.9646110508319536, 0.0, 0.0, 0.5085185399722538, 0.6023280632420829, 0.6023280632420829, 0.8544297598280727], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.61892503], dtype=float32), 0.88287216]. 
=============================================
[2019-03-23 15:41:44,550] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 9.1173583e-34 5.0598399e-36 8.0293875e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 15:41:44,555] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6652
[2019-03-23 15:41:44,559] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5711176118713069, 6.911199999999999, 6.9112, 77.32846344354104, 332193.5273246544, 332193.5273246546, 111215.3188801251], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4062000.0000, 
sim time next is 4062600.0000, 
raw observation next is [16.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5707356893199625, 6.911199999999999, 6.9112, 77.32846344354104, 331978.7239301503, 331978.7239301506, 111180.3956255658], 
processed observation next is [1.0, 0.0, 0.36363636363636365, 1.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3867652704570894, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12295508293709272, 0.12295508293709283, 0.27117169664772145], 
reward next is 0.7288, 
noisyNet noise sample is [array([-0.99044484], dtype=float32), -0.799951]. 
=============================================
[2019-03-23 15:41:45,911] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.7395868e-27 5.8994181e-28 8.2124628e-28 3.4271722e-37], sum to 1.0000
[2019-03-23 15:41:45,922] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2604
[2019-03-23 15:41:45,928] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 562952.4579187996 W.
[2019-03-23 15:41:45,933] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3332653792900619, 6.911199999999999, 6.9112, 77.3421103, 562952.4579187996, 562952.4579187998, 210656.1068425722], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3630600.0000, 
sim time next is 3631200.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3330662186209034, 6.911199999999999, 6.9112, 77.3421103, 562297.011060301, 562297.0110603013, 210864.5363661406], 
processed observation next is [1.0, 0.0, 0.5909090909090909, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.04723745517271918, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.20825815224455593, 0.20825815224455604, 0.5143037472344892], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.01701386], dtype=float32), 0.8203222]. 
=============================================
[2019-03-23 15:41:47,323] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.2378196e-24 1.3536984e-24 1.1468941e-24 8.6783368e-33], sum to 1.0000
[2019-03-23 15:41:47,328] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5796
[2019-03-23 15:41:47,334] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1260956.175591997 W.
[2019-03-23 15:41:47,339] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.33333333333334, 87.16666666666667, 1.0, 2.0, 0.5577131332802565, 1.0, 2.0, 0.5577131332802565, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1260956.175591997, 1260956.175591997, 248733.1851375475], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3665400.0000, 
sim time next is 3666000.0000, 
raw observation next is [23.66666666666667, 85.33333333333334, 1.0, 2.0, 0.3919392644990349, 1.0, 2.0, 0.3919392644990349, 1.0, 1.0, 0.7925603636336025, 6.9112, 6.9112, 77.3421103, 1326256.633492827, 1326256.633492827, 301669.992862285], 
processed observation next is [1.0, 0.43478260869565216, 0.7121212121212124, 0.8533333333333334, 1.0, 1.0, 0.23992408062379358, 1.0, 1.0, 0.23992408062379358, 1.0, 0.5, 0.703657662333718, 0.0, 0.0, 0.5085185399722538, 0.4912061605528989, 0.4912061605528989, 0.7357804703958171], 
reward next is 0.2642, 
noisyNet noise sample is [array([-0.14315434], dtype=float32), 0.022032762]. 
=============================================
[2019-03-23 15:41:47,351] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[19.885056]
 [20.130854]
 [20.24499 ]
 [20.34346 ]
 [20.371912]], R is [[19.94260406]
 [20.13651085]
 [19.93514633]
 [19.73579597]
 [19.92048073]].
[2019-03-23 15:41:48,017] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 9.4595375e-32 6.4567808e-31 1.2687120e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 15:41:48,022] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5983
[2019-03-23 15:41:48,026] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 580919.7029825826 W.
[2019-03-23 15:41:48,031] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 60.66666666666666, 1.0, 2.0, 0.509983892847727, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 580919.7029825826, 580919.702982583, 144058.6269046966], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3696000.0000, 
sim time next is 3696600.0000, 
raw observation next is [27.16666666666666, 61.33333333333334, 1.0, 2.0, 0.5088533081156221, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 579992.0923744732, 579992.0923744732, 143567.9508526293], 
processed observation next is [1.0, 0.782608695652174, 0.871212121212121, 0.6133333333333334, 1.0, 1.0, 0.3860666351445276, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2148118860646197, 0.2148118860646197, 0.3501657337869007], 
reward next is 0.6498, 
noisyNet noise sample is [array([0.5256191], dtype=float32), -1.0372709]. 
=============================================
[2019-03-23 15:41:52,080] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.1357523e-25 3.0073720e-30 7.4220838e-29 0.0000000e+00], sum to 1.0000
[2019-03-23 15:41:52,086] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3800
[2019-03-23 15:41:52,091] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1196564.713733791 W.
[2019-03-23 15:41:52,096] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 57.33333333333334, 1.0, 2.0, 0.5678862930558478, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9671717312122712, 6.911199999999999, 6.9112, 77.32846344354104, 1196564.713733791, 1196564.713733791, 263398.2212451035], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3759000.0000, 
sim time next is 3759600.0000, 
raw observation next is [26.0, 56.66666666666667, 1.0, 2.0, 0.2546358427517286, 1.0, 1.0, 0.2546358427517286, 1.0, 2.0, 0.51396060768252, 6.911199999999999, 6.9112, 77.3421103, 871934.4360253783, 871934.4360253785, 239124.005280456], 
processed observation next is [1.0, 0.5217391304347826, 0.8181818181818182, 0.5666666666666668, 1.0, 1.0, 0.06829480343966077, 1.0, 0.5, 0.06829480343966077, 1.0, 1.0, 0.3056580109750287, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.32293868000939935, 0.32293868000939946, 0.5832292811718439], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8903091], dtype=float32), 0.7989489]. 
=============================================
[2019-03-23 15:41:54,361] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 4.2892426e-11 8.8317135e-29 7.9552287e-23 0.0000000e+00], sum to 1.0000
[2019-03-23 15:41:54,369] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6629
[2019-03-23 15:41:54,372] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6166044072685142, 6.9112, 6.9112, 77.32846344354104, 357998.8144607443, 357998.8144607443, 115366.6384417547], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3805200.0000, 
sim time next is 3805800.0000, 
raw observation next is [17.0, 94.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6200806644248774, 6.9112, 6.9112, 77.32846344354104, 360017.8669853152, 360017.8669853152, 115661.6653234631], 
processed observation next is [0.0, 0.043478260869565216, 0.4090909090909091, 0.9400000000000002, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4572580920355392, 0.0, 0.0, 0.5084288129206541, 0.13333995073530194, 0.13333995073530194, 0.2821016227401539], 
reward next is 0.7179, 
noisyNet noise sample is [array([-0.06140423], dtype=float32), -0.7107862]. 
=============================================
[2019-03-23 15:41:56,297] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 2.0314031e-19 1.8612752e-37 2.2667703e-29 0.0000000e+00], sum to 1.0000
[2019-03-23 15:41:56,303] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6288
[2019-03-23 15:41:56,308] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 57.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5905663187162675, 6.911199999999999, 6.9112, 77.32846344354104, 342919.8289870507, 342919.828987051, 113185.1814290329], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3870000.0000, 
sim time next is 3870600.0000, 
raw observation next is [21.83333333333334, 58.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5898189463985463, 6.911200000000001, 6.9112, 77.32846344354104, 342466.2747032584, 342466.2747032581, 113139.9906744022], 
processed observation next is [0.0, 0.8260869565217391, 0.628787878787879, 0.5816666666666666, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.41402706628363756, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12683936100120682, 0.1268393610012067, 0.27595119676683466], 
reward next is 0.7240, 
noisyNet noise sample is [array([2.0538287], dtype=float32), -0.7554988]. 
=============================================
[2019-03-23 15:41:59,415] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9999988e-01 9.7572908e-08 2.9218262e-29 1.2859435e-20 0.0000000e+00], sum to 1.0000
[2019-03-23 15:41:59,421] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5016
[2019-03-23 15:41:59,425] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.66666666666667, 48.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6314174345082995, 6.9112, 6.9112, 77.32846344354104, 365257.040915287, 365257.040915287, 117650.8066038288], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3930600.0000, 
sim time next is 3931200.0000, 
raw observation next is [25.0, 47.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6379307799881802, 6.911199999999999, 6.9112, 77.32846344354104, 368818.7066883072, 368818.7066883075, 118386.2022206453], 
processed observation next is [0.0, 0.5217391304347826, 0.7727272727272727, 0.47, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4827582571259717, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13659952099566935, 0.13659952099566944, 0.28874683468450074], 
reward next is 0.7113, 
noisyNet noise sample is [array([0.26564872], dtype=float32), -0.43545544]. 
=============================================
[2019-03-23 15:42:00,689] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 3.9979839e-18 4.1750188e-38 5.6993991e-29 0.0000000e+00], sum to 1.0000
[2019-03-23 15:42:00,697] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1821
[2019-03-23 15:42:00,701] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 53.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6183971296199615, 6.911199999999999, 6.9112, 77.32846344354104, 358608.5451938097, 358608.54519381, 115845.8103821426], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3957600.0000, 
sim time next is 3958200.0000, 
raw observation next is [23.0, 53.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.618317000600501, 6.911199999999999, 6.9112, 77.32846344354104, 358569.2834603004, 358569.2834603007, 115833.5114753649], 
processed observation next is [0.0, 0.8260869565217391, 0.6818181818181818, 0.53, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.45473857228643005, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13280343831862979, 0.1328034383186299, 0.2825207596960119], 
reward next is 0.7175, 
noisyNet noise sample is [array([1.1370159], dtype=float32), -1.2628591]. 
=============================================
[2019-03-23 15:42:00,743] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 7.3866286e-16 5.9346996e-35 8.2681286e-29 0.0000000e+00], sum to 1.0000
[2019-03-23 15:42:00,747] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3083
[2019-03-23 15:42:00,750] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.33333333333334, 49.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6511308932163175, 6.9112, 6.9112, 77.32846344354104, 376586.4482494449, 376586.4482494449, 119489.368861851], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3951600.0000, 
sim time next is 3952200.0000, 
raw observation next is [24.16666666666666, 49.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6487079350703318, 6.911199999999999, 6.9112, 77.32846344354104, 375290.150425946, 375290.1504259463, 119188.1888412512], 
processed observation next is [0.0, 0.7391304347826086, 0.7348484848484845, 0.495, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4981541929576168, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13899635200960964, 0.13899635200960975, 0.2907028996128078], 
reward next is 0.7093, 
noisyNet noise sample is [array([1.6661007], dtype=float32), -0.95294106]. 
=============================================
[2019-03-23 15:42:00,760] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 9.4185259e-17 6.9738638e-37 1.0984167e-27 0.0000000e+00], sum to 1.0000
[2019-03-23 15:42:00,769] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9204
[2019-03-23 15:42:00,774] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.5, 51.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6299999787160563, 6.911199999999999, 6.9112, 77.32846344354104, 364898.7988099745, 364898.7988099748, 117179.8798631025], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3954600.0000, 
sim time next is 3955200.0000, 
raw observation next is [23.33333333333333, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6267268532226554, 6.9112, 6.9112, 77.32846344354104, 363115.3113986869, 363115.3113986869, 116808.2935922004], 
processed observation next is [0.0, 0.782608695652174, 0.6969696969696968, 0.52, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.46675264746093637, 0.0, 0.0, 0.5084288129206541, 0.13448715236988404, 0.13448715236988404, 0.28489827705414733], 
reward next is 0.7151, 
noisyNet noise sample is [array([-0.40650526], dtype=float32), -0.09929437]. 
=============================================
[2019-03-23 15:42:08,434] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 3.4434620e-14 4.7546615e-27 3.8473374e-23 1.5504638e-35], sum to 1.0000
[2019-03-23 15:42:08,441] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1554
[2019-03-23 15:42:08,446] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 802931.0096966702 W.
[2019-03-23 15:42:08,449] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.33333333333333, 81.33333333333334, 1.0, 2.0, 0.3521762655970807, 1.0, 2.0, 0.3521762655970807, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 802931.0096966702, 802931.00969667, 191747.9974422898], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4111800.0000, 
sim time next is 4112400.0000, 
raw observation next is [21.66666666666667, 79.66666666666667, 1.0, 2.0, 0.3783758515333585, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7559795254692934, 6.9112, 6.9112, 77.32846344354104, 861496.258699893, 861496.258699893, 208643.898263361], 
processed observation next is [1.0, 0.6086956521739131, 0.6212121212121214, 0.7966666666666667, 1.0, 1.0, 0.2229698144166981, 0.0, 0.5, -0.25, 1.0, 0.5, 0.6513993220989905, 0.0, 0.0, 0.5084288129206541, 0.3190726884073678, 0.3190726884073678, 0.5088875567399049], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2385787], dtype=float32), 0.5363364]. 
=============================================
[2019-03-23 15:42:14,708] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.2846088e-07 9.9999976e-01 5.7189919e-24 6.7574412e-15 1.3291046e-34], sum to 1.0000
[2019-03-23 15:42:14,716] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5083
[2019-03-23 15:42:14,720] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 88.0, 1.0, 2.0, 0.3647468568568258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 407621.5181973057, 407621.5181973054, 120082.22301072], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4230000.0000, 
sim time next is 4230600.0000, 
raw observation next is [19.0, 88.00000000000001, 1.0, 2.0, 0.3658487507797512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 408856.89922977, 408856.8992297697, 120174.7788646552], 
processed observation next is [1.0, 1.0, 0.5, 0.8800000000000001, 1.0, 1.0, 0.20731093847468898, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1514284811962111, 0.151428481196211, 0.2931092167430615], 
reward next is 0.7069, 
noisyNet noise sample is [array([-1.3643165], dtype=float32), 0.12516414]. 
=============================================
[2019-03-23 15:42:23,168] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.0319762e-07 9.9999964e-01 1.9006207e-16 1.1581027e-12 9.4230218e-23], sum to 1.0000
[2019-03-23 15:42:23,170] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5064
[2019-03-23 15:42:23,173] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 80.0, 1.0, 2.0, 0.457255698951139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 521364.2592235688, 521364.2592235688, 134843.755836694], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4405200.0000, 
sim time next is 4405800.0000, 
raw observation next is [22.58333333333333, 80.5, 1.0, 2.0, 0.4569030265636355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 520945.4239691026, 520945.4239691026, 134777.9213281628], 
processed observation next is [1.0, 1.0, 0.6628787878787876, 0.805, 1.0, 1.0, 0.32112878320454435, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19294274961818617, 0.19294274961818617, 0.3287266373857629], 
reward next is 0.6713, 
noisyNet noise sample is [array([-0.21699531], dtype=float32), 0.27895486]. 
=============================================
[2019-03-23 15:42:23,880] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 15:42:23,881] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:42:23,882] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:42:23,883] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:42:23,886] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:42:23,888] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:42:23,888] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:42:23,888] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:42:23,890] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:42:23,891] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:42:23,891] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:42:23,912] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run99
[2019-03-23 15:42:23,945] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run99
[2019-03-23 15:42:23,970] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run99
[2019-03-23 15:42:23,996] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run99
[2019-03-23 15:42:23,997] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run99
[2019-03-23 15:42:28,315] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0023607], dtype=float32), -0.60819227]
[2019-03-23 15:42:28,319] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.2, 32.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5843571982118685, 6.911199999999999, 6.9112, 95.55338769695034, 339885.9129503129, 339885.9129503133, 94675.94648700078]
[2019-03-23 15:42:28,320] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:42:28,322] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 9.3000661e-13 4.4984736e-23 4.0365057e-20 1.8682583e-32], sampled 0.3853250193746277
[2019-03-23 15:43:13,294] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0023607], dtype=float32), -0.60819227]
[2019-03-23 15:43:13,296] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.43724459, 62.82755222, 1.0, 2.0, 0.6699045529015026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 764075.8439293061, 764075.8439293061, 168333.2557136887]
[2019-03-23 15:43:13,298] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:43:13,300] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.9998379e-01 1.6265885e-05 2.9534735e-19 2.9064923e-15 3.9192886e-27], sampled 0.3883996052367784
[2019-03-23 15:43:13,301] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 764075.8439293061 W.
[2019-03-23 15:43:34,118] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0023607], dtype=float32), -0.60819227]
[2019-03-23 15:43:34,119] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.06666666666667, 58.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6974620470256631, 7.024367707553049, 6.9112, 95.55288267381094, 447618.0451123362, 402201.3422467576, 129111.2183268657]
[2019-03-23 15:43:34,121] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:43:34,125] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0000000e+00 2.3081492e-09 2.2017293e-20 3.7812629e-17 6.0097157e-29], sampled 0.29607057225276145
[2019-03-23 15:43:35,801] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0023607], dtype=float32), -0.60819227]
[2019-03-23 15:43:35,801] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.72033620666667, 84.59439560000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7314586682088091, 7.306951300519464, 6.9112, 95.55191686683094, 579890.1541551135, 421068.0136129741, 133226.5651588271]
[2019-03-23 15:43:35,803] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:43:35,805] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0000000e+00 7.8021888e-13 4.9692614e-23 3.6530978e-20 3.3898254e-32], sampled 0.00014359630413662838
[2019-03-23 15:43:35,806] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 579890.1541551135 W.
[2019-03-23 15:43:52,526] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0023607], dtype=float32), -0.60819227]
[2019-03-23 15:43:52,527] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.3, 50.0, 1.0, 2.0, 0.5592314095843944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 636726.5248930318, 636726.5248930318, 149563.2318896854]
[2019-03-23 15:43:52,529] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:43:52,532] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0000000e+00 1.3999720e-08 1.9335613e-21 1.0385302e-17 3.7053166e-30], sampled 0.6027928745083594
[2019-03-23 15:43:52,534] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 636726.5248930318 W.
[2019-03-23 15:44:02,781] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0023607], dtype=float32), -0.60819227]
[2019-03-23 15:44:02,782] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.41898222666667, 63.55172895333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5381793630153442, 6.911199999999999, 6.9112, 95.55338769695021, 312816.1721289433, 312816.1721289437, 103225.7399153933]
[2019-03-23 15:44:02,783] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:44:02,786] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 1.0448622e-21 8.0994802e-24 1.2913885e-23 7.1306038e-33], sampled 0.6955663352491263
[2019-03-23 15:44:09,552] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0023607], dtype=float32), -0.60819227]
[2019-03-23 15:44:09,554] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.9, 47.0, 1.0, 1.0, 0.4433598660200531, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 95.55318735575966, 481454.9316377, 481454.9316377, 126269.8406148392]
[2019-03-23 15:44:09,555] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:44:09,557] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 1.3142847e-15 2.6361491e-21 7.0340396e-20 9.8871593e-30], sampled 0.8873576262925904
[2019-03-23 15:44:10,848] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6888.8070 1792785211.3155 2385.0000
[2019-03-23 15:44:11,334] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6481.6076 1678885180.2952 3057.0000
[2019-03-23 15:44:11,408] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6558.4261 1698590633.0432 2953.0000
[2019-03-23 15:44:11,542] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6297.6206 1685608532.8038 3226.0000
[2019-03-23 15:44:11,617] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6336.5467 1723248550.9887 3423.0000
[2019-03-23 15:44:12,631] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 2450000, evaluation results [2450000.0, 6888.80696566984, 1792785211.3155246, 2385.0, 6481.607577760913, 1678885180.2951708, 3057.0, 6297.620645661, 1685608532.8038309, 3226.0, 6336.546695146426, 1723248550.988733, 3423.0, 6558.426098127307, 1698590633.043249, 2953.0]
[2019-03-23 15:44:13,034] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.9999535e-01 4.6107425e-06 4.2993780e-19 1.2432717e-14 1.3153388e-27], sum to 1.0000
[2019-03-23 15:44:13,043] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2981
[2019-03-23 15:44:13,048] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.0, 61.0, 1.0, 1.0, 0.2160680738870648, 1.0, 1.0, 0.2160680738870648, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32822223403663, 491032.0185598781, 491032.0185598781, 167838.3152854172], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4554000.0000, 
sim time next is 4554600.0000, 
raw observation next is [24.0, 61.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7460531781614956, 7.133702112210639, 6.9112, 77.32788569477502, 498475.0976839652, 426211.50250451, 132879.7433903127], 
processed observation next is [0.0, 0.7391304347826086, 0.7272727272727273, 0.61, 0.0, 0.5, -0.25, 0.0, 0.5, -0.25, 1.0, 0.5, 0.6372188259449938, 0.022250211221063944, 0.0, 0.5084250142661071, 0.18462040654961676, 0.1578561120387074, 0.32409693509832366], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.04600119], dtype=float32), 0.64278334]. 
=============================================
[2019-03-23 15:44:14,409] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 3.1534081e-14 1.8278883e-14 2.2615664e-14 3.7772346e-20], sum to 1.0000
[2019-03-23 15:44:14,421] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9732
[2019-03-23 15:44:14,428] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 551047.74043227 W.
[2019-03-23 15:44:14,430] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.33333333333334, 62.66666666666666, 1.0, 2.0, 0.2416761564763783, 1.0, 1.0, 0.2416761564763783, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 551047.74043227, 551047.74043227, 177731.4646177994], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4390800.0000, 
sim time next is 4391400.0000, 
raw observation next is [26.16666666666667, 63.83333333333334, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 1.0, 0.3273654156148279, 6.911199999999999, 6.9112, 77.3421103, 552790.077387051, 552790.0773870512, 209525.0310407531], 
processed observation next is [1.0, 0.8260869565217391, 0.825757575757576, 0.6383333333333334, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.039093450878325595, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.20473706569890776, 0.20473706569890784, 0.5110366610750076], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6868599], dtype=float32), -0.88406307]. 
=============================================
[2019-03-23 15:44:24,198] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.929154e-01 7.084639e-03 3.490850e-16 8.211581e-12 5.655370e-23], sum to 1.0000
[2019-03-23 15:44:24,203] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1291
[2019-03-23 15:44:24,211] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 717925.8320740795 W.
[2019-03-23 15:44:24,215] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.0, 100.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8129553910825952, 7.690316916299859, 6.9112, 77.32666936522122, 717925.8320740795, 464890.4641030858, 140651.4581532705], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4781400.0000, 
sim time next is 4782000.0000, 
raw observation next is [19.0, 100.0, 1.0, 1.0, 0.3601129408072387, 1.0, 1.0, 0.3601129408072387, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.327995254958, 820873.0633393792, 820873.0633393792, 192953.4923615102], 
processed observation next is [1.0, 0.34782608695652173, 0.5, 1.0, 1.0, 0.5, 0.20014117600904838, 1.0, 0.5, 0.20014117600904838, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084257346160441, 0.30402706049606637, 0.30402706049606637, 0.4706182740524639], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.62534213], dtype=float32), -0.4969398]. 
=============================================
[2019-03-23 15:44:24,234] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[41.461346]
 [43.92058 ]
 [42.378113]
 [41.98955 ]
 [40.419865]], R is [[42.03642654]
 [41.61606216]
 [41.19990158]
 [40.78790283]
 [40.96852875]].
[2019-03-23 15:44:24,527] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9999571e-01 4.3128571e-06 5.1954192e-22 1.7700262e-16 8.2897498e-31], sum to 1.0000
[2019-03-23 15:44:24,534] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3848
[2019-03-23 15:44:24,539] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 651379.8298859003 W.
[2019-03-23 15:44:24,543] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 49.5, 1.0, 2.0, 0.592586700775989, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 651379.8298859003, 651379.8298859, 138113.6624688961], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4639800.0000, 
sim time next is 4640400.0000, 
raw observation next is [23.0, 50.0, 1.0, 2.0, 0.6642472294339695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 727293.9937961756, 727293.9937961759, 144959.9384440698], 
processed observation next is [1.0, 0.7391304347826086, 0.6818181818181818, 0.5, 1.0, 1.0, 0.5803090367924618, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2693681458504354, 0.2693681458504355, 0.35356082547334095], 
reward next is 0.6464, 
noisyNet noise sample is [array([1.6402098], dtype=float32), -1.4132894]. 
=============================================
[2019-03-23 15:44:24,832] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 1.7183653e-09 1.1766619e-30 2.4188412e-24 0.0000000e+00], sum to 1.0000
[2019-03-23 15:44:24,839] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5141
[2019-03-23 15:44:24,846] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.5, 60.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5036000220234453, 6.911200000000001, 6.9112, 77.32846344354104, 292919.6315937592, 292919.6315937589, 91509.40463646252], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4653000.0000, 
sim time next is 4653600.0000, 
raw observation next is [19.33333333333334, 61.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4996158380171205, 6.911199999999998, 6.9112, 77.32846344354104, 290601.5333040308, 290601.5333040314, 91422.74851877056], 
processed observation next is [1.0, 0.8695652173913043, 0.5151515151515155, 0.6133333333333333, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.28516548288160076, -1.7763568394002506e-16, 0.0, 0.5084288129206541, 0.10763019752001139, 0.10763019752001164, 0.222982313460416], 
reward next is 0.7770, 
noisyNet noise sample is [array([-1.7294664], dtype=float32), 0.9745686]. 
=============================================
[2019-03-23 15:44:29,804] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.2140433e-04 9.9977857e-01 8.7151398e-15 4.4178151e-11 5.9487029e-21], sum to 1.0000
[2019-03-23 15:44:29,808] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9851
[2019-03-23 15:44:29,812] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 88.0, 1.0, 2.0, 0.3652859816137569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 408353.6406538109, 408353.6406538109, 120184.7483599148], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4755600.0000, 
sim time next is 4756200.0000, 
raw observation next is [19.0, 88.00000000000001, 1.0, 2.0, 0.3638513793372778, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 406651.7405919791, 406651.7405919791, 120022.4557449934], 
processed observation next is [1.0, 0.043478260869565216, 0.5, 0.8800000000000001, 1.0, 1.0, 0.20481422417159723, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1506117557748071, 0.1506117557748071, 0.29273769693900825], 
reward next is 0.7073, 
noisyNet noise sample is [array([-0.45350483], dtype=float32), -0.8779459]. 
=============================================
[2019-03-23 15:44:31,956] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6475168e-08 1.0000000e+00 1.3035889e-23 6.7816105e-16 4.1771662e-32], sum to 1.0000
[2019-03-23 15:44:31,963] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5846
[2019-03-23 15:44:31,967] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3739746812178723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 419842.3906121263, 419842.390612126, 121736.4368353642], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4770600.0000, 
sim time next is 4771200.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3676180742593604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 412686.5390323272, 412686.5390323272, 121188.2040947743], 
processed observation next is [1.0, 0.21739130434782608, 0.45454545454545453, 1.0, 1.0, 1.0, 0.20952259282420047, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15284686630826932, 0.15284686630826932, 0.29558098559701046], 
reward next is 0.7044, 
noisyNet noise sample is [array([0.6712964], dtype=float32), -0.4414386]. 
=============================================
[2019-03-23 15:44:32,721] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.2706374e-09 1.0000000e+00 4.0343710e-25 1.0171741e-16 9.3995293e-34], sum to 1.0000
[2019-03-23 15:44:32,731] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9279
[2019-03-23 15:44:32,740] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.4378864962787032, 1.0, 1.0, 0.4378864962787032, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32844399332144, 995259.1051726311, 995259.1051726311, 217206.6233499522], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4806000.0000, 
sim time next is 4806600.0000, 
raw observation next is [22.0, 95.0, 1.0, 2.0, 0.8396215002821441, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846332314244, 956761.7457863851, 956761.7457863848, 191801.5662190021], 
processed observation next is [1.0, 0.6521739130434783, 0.6363636363636364, 0.95, 1.0, 1.0, 0.7995268753526802, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288121290425, 0.3543562021431056, 0.3543562021431055, 0.46780869809512704], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5664569], dtype=float32), -0.060785655]. 
=============================================
[2019-03-23 15:44:34,408] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.8281156e-06 9.9999821e-01 5.6814459e-26 5.3106031e-17 2.6385615e-34], sum to 1.0000
[2019-03-23 15:44:34,417] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2052
[2019-03-23 15:44:34,424] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 96.0, 1.0, 2.0, 0.4560166454929357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 520029.2869963585, 520029.2869963582, 134855.4514891405], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4836000.0000, 
sim time next is 4836600.0000, 
raw observation next is [20.5, 97.0, 1.0, 2.0, 0.4536968895936507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517323.3711915888, 517323.3711915888, 134499.7272876151], 
processed observation next is [1.0, 1.0, 0.5681818181818182, 0.97, 1.0, 1.0, 0.31712111199206333, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19160124858947733, 0.19160124858947733, 0.3280481153356466], 
reward next is 0.6720, 
noisyNet noise sample is [array([-0.83227736], dtype=float32), -0.5560223]. 
=============================================
[2019-03-23 15:44:35,799] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.8777602e-05 9.9996126e-01 5.5772498e-23 2.9569528e-15 8.1046968e-32], sum to 1.0000
[2019-03-23 15:44:35,805] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5522
[2019-03-23 15:44:35,811] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4409488005917951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499911.6375624391, 499911.6375624391, 130416.7362132373], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4867800.0000, 
sim time next is 4868400.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.5249091537718604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595266.7118401612, 595266.7118401612, 139281.0306118988], 
processed observation next is [1.0, 0.34782608695652173, 0.5, 1.0, 1.0, 1.0, 0.4061364422148255, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22046915253339305, 0.22046915253339305, 0.3397098307607288], 
reward next is 0.6603, 
noisyNet noise sample is [array([2.7323122], dtype=float32), 0.903887]. 
=============================================
[2019-03-23 15:44:37,000] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.0995800e-07 9.9999976e-01 2.1957712e-22 1.5507810e-15 3.4154652e-29], sum to 1.0000
[2019-03-23 15:44:37,009] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0811
[2019-03-23 15:44:37,013] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.8002580497404439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 908620.9661537859, 908620.9661537859, 175481.9706051185], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4881600.0000, 
sim time next is 4882200.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.7316552364568514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 830420.0758636708, 830420.0758636708, 165405.5122401708], 
processed observation next is [1.0, 0.5217391304347826, 0.5909090909090909, 0.83, 1.0, 1.0, 0.6645690455710642, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3075629910606188, 0.3075629910606188, 0.4034280786345629], 
reward next is 0.5966, 
noisyNet noise sample is [array([1.2161685], dtype=float32), -0.66929466]. 
=============================================
[2019-03-23 15:44:38,972] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.5585625e-05 9.9996436e-01 1.6587553e-23 4.8812884e-16 5.0742994e-33], sum to 1.0000
[2019-03-23 15:44:38,983] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9378
[2019-03-23 15:44:38,987] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3746872933688968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 420634.8369124052, 420634.8369124052, 121793.4445544095], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4929600.0000, 
sim time next is 4930200.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3735943791233374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 419403.2034270405, 419403.2034270408, 121698.0831682279], 
processed observation next is [1.0, 0.043478260869565216, 0.45454545454545453, 1.0, 1.0, 1.0, 0.2169929739041717, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15533451978779278, 0.1553345197877929, 0.2968245930932388], 
reward next is 0.7032, 
noisyNet noise sample is [array([1.4837984], dtype=float32), 0.86005765]. 
=============================================
[2019-03-23 15:44:43,530] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.8679305e-32 5.2295611e-30 2.9406985e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 15:44:43,537] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4019
[2019-03-23 15:44:43,550] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 644271.5165582113 W.
[2019-03-23 15:44:43,557] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 66.0, 1.0, 2.0, 0.570588690360626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 644271.5165582113, 644271.5165582113, 154155.8497554097], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5148600.0000, 
sim time next is 5149200.0000, 
raw observation next is [28.0, 66.0, 1.0, 2.0, 0.2868672597296259, 1.0, 1.0, 0.2868672597296259, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 644702.3421007791, 644702.3421007791, 189959.024771415], 
processed observation next is [0.0, 0.6086956521739131, 0.9090909090909091, 0.66, 1.0, 1.0, 0.10858407466203236, 1.0, 0.5, 0.10858407466203236, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23877864522251077, 0.23877864522251077, 0.4633146945644268], 
reward next is 0.5367, 
noisyNet noise sample is [array([-1.0414968], dtype=float32), 0.16483383]. 
=============================================
[2019-03-23 15:44:49,573] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 2.8904061e-31 3.9139346e-24 4.9030252e-28 3.6929195e-34], sum to 1.0000
[2019-03-23 15:44:49,578] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0321
[2019-03-23 15:44:49,586] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 580101.5596509762 W.
[2019-03-23 15:44:49,590] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.16666666666666, 81.5, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3452081965647445, 6.911199999999999, 6.9112, 77.3421103, 580101.5596509762, 580101.5596509764, 215632.5857555864], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5140200.0000, 
sim time next is 5140800.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3473947395636094, 6.911199999999999, 6.9112, 77.3421103, 583566.8631182559, 583566.8631182561, 216285.6781967924], 
processed observation next is [0.0, 0.5217391304347826, 0.7272727272727273, 0.83, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.06770677080515629, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.21613587522898364, 0.21613587522898373, 0.5275260443824205], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.5282261], dtype=float32), -0.050255988]. 
=============================================
[2019-03-23 15:44:50,272] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.4152678e-26 1.7543955e-26 1.2448835e-26 4.8890138e-37], sum to 1.0000
[2019-03-23 15:44:50,281] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3772
[2019-03-23 15:44:50,287] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 639020.9714479946 W.
[2019-03-23 15:44:50,293] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 68.66666666666667, 1.0, 2.0, 0.5649901140880728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 639020.9714479946, 639020.9714479949, 153103.5157596636], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5145600.0000, 
sim time next is 5146200.0000, 
raw observation next is [27.5, 68.0, 1.0, 2.0, 0.5672160135126817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 641281.8367093356, 641281.8367093356, 153475.5925742481], 
processed observation next is [0.0, 0.5652173913043478, 0.8863636363636364, 0.68, 1.0, 1.0, 0.4590200168908521, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.237511791373828, 0.237511791373828, 0.37433071359572706], 
reward next is 0.6257, 
noisyNet noise sample is [array([0.47330195], dtype=float32), -0.7032223]. 
=============================================
[2019-03-23 15:44:55,446] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 4.3556437e-25 5.8175695e-24 1.8345363e-24 7.1581295e-33], sum to 1.0000
[2019-03-23 15:44:55,451] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1310
[2019-03-23 15:44:55,455] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.2170884231313857, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4360691579917629, 6.9112, 6.9112, 77.32846104625897, 495088.448847168, 495088.448847168, 168473.6404451198], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5203800.0000, 
sim time next is 5204400.0000, 
raw observation next is [22.0, 83.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7702684491142588, 7.303131474323488, 6.9112, 77.32751620747632, 565274.8263903587, 437985.0591718865, 137168.7583619201], 
processed observation next is [1.0, 0.21739130434782608, 0.6363636363636364, 0.83, 0.0, 0.5, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.671812070163227, 0.039193147432348766, 0.0, 0.5084225849149949, 0.20936104681124398, 0.16221668858218016, 0.33455794722419535], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6647658], dtype=float32), 0.6217611]. 
=============================================
[2019-03-23 15:44:56,331] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 3.1029497e-18 1.9394543e-23 1.1102233e-22 4.8818139e-32], sum to 1.0000
[2019-03-23 15:44:56,340] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6449
[2019-03-23 15:44:56,344] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.33333333333333, 82.0, 1.0, 1.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 489361.2218316597, 489361.2218316597, 193369.8929800466], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5272800.0000, 
sim time next is 5273400.0000, 
raw observation next is [20.26666666666667, 77.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7333115210313124, 7.049417747539998, 6.9112, 77.32806272823984, 465244.7082101946, 420354.6434720929, 130415.3677891797], 
processed observation next is [1.0, 0.0, 0.5575757575757577, 0.775, 0.0, 0.5, -0.25, 0.0, 0.5, -0.25, 1.0, 1.0, 0.6190164586161606, 0.013821774753999793, 0.0, 0.5084261782477816, 0.17231285489266468, 0.15568690498966406, 0.3180862629004383], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.51040924], dtype=float32), 0.4729452]. 
=============================================
[2019-03-23 15:45:00,423] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 15:45:00,424] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:45:00,425] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:45:00,426] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:45:00,425] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:45:00,426] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:45:00,426] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:45:00,426] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:45:00,427] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:45:00,428] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:45:00,430] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:45:00,448] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run100
[2019-03-23 15:45:00,475] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run100
[2019-03-23 15:45:00,510] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run100
[2019-03-23 15:45:00,511] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run100
[2019-03-23 15:45:00,511] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run100
[2019-03-23 15:45:28,816] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00927061], dtype=float32), -0.6116764]
[2019-03-23 15:45:28,818] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.0, 47.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6051924660998549, 6.9112, 6.9112, 95.55338769695034, 351106.95580206, 351106.95580206, 118900.0201340199]
[2019-03-23 15:45:28,819] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:45:28,823] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0000000e+00 6.5772408e-19 1.2503271e-35 4.5189764e-30 0.0000000e+00], sampled 0.10814649715955982
[2019-03-23 15:45:50,028] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00927061], dtype=float32), -0.6116764]
[2019-03-23 15:45:50,029] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [29.32406748333333, 75.39520596, 1.0, 2.0, 0.7096635462230763, 1.0, 1.0, 0.7096635462230763, 0.0, 1.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 1595883.792621733, 1595883.792621733, 300667.5389040362]
[2019-03-23 15:45:50,030] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:45:50,033] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 1.7202984e-26 1.8358164e-25 3.3812088e-26 2.4286108e-34], sampled 0.7862509359328791
[2019-03-23 15:45:50,034] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1595883.792621733 W.
[2019-03-23 15:46:04,367] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00927061], dtype=float32), -0.6116764]
[2019-03-23 15:46:04,369] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.5, 63.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7559555021919588, 7.205443787739861, 6.9112, 77.32774325886903, 526760.2478015937, 431196.7738913603, 134503.2651295943]
[2019-03-23 15:46:04,371] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:46:04,374] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 2.1697272e-29 8.9060124e-28 1.0576147e-28 1.5193603e-37], sampled 0.750246257048853
[2019-03-23 15:46:28,105] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00927061], dtype=float32), -0.6116764]
[2019-03-23 15:46:28,106] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [29.16666666666667, 47.33333333333333, 1.0, 2.0, 0.712836829302619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 813496.3456602943, 813496.3456602939, 173226.9652842764]
[2019-03-23 15:46:28,107] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:46:28,110] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0000000e+00 3.8690706e-33 1.5917412e-30 9.5465399e-32 0.0000000e+00], sampled 0.6943636666674059
[2019-03-23 15:46:28,113] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 813496.3456602943 W.
[2019-03-23 15:46:47,168] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6481.6076 1678885180.2952 3057.0000
[2019-03-23 15:46:47,357] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6862.2842 1793014293.7888 2409.0000
[2019-03-23 15:46:47,588] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6328.7217 1723294598.4314 3425.0000
[2019-03-23 15:46:47,857] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6294.9961 1685630448.6673 3228.0000
[2019-03-23 15:46:47,920] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6553.1725 1698634175.0084 2957.0000
[2019-03-23 15:46:48,937] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 2475000, evaluation results [2475000.0, 6862.284208925443, 1793014293.78876, 2409.0, 6481.607577760913, 1678885180.2951708, 3057.0, 6294.9960618483565, 1685630448.6673346, 3228.0, 6328.721692698646, 1723294598.4313502, 3425.0, 6553.172466661831, 1698634175.0084193, 2957.0]
[2019-03-23 15:46:50,437] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 8.4034453e-25 9.2285831e-22 8.5539773e-23 1.1407818e-30], sum to 1.0000
[2019-03-23 15:46:50,444] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5486
[2019-03-23 15:46:50,452] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 795737.5434373785 W.
[2019-03-23 15:46:50,455] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.1, 82.0, 1.0, 2.0, 0.3486100837193219, 1.0, 2.0, 0.3486100837193219, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 82.07700859777025, 795737.5434373785, 795737.5434373781, 195721.7074364997], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5364600.0000, 
sim time next is 5365200.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.2895972617572648, 1.0, 2.0, 0.2895972617572648, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846343462649, 660978.7927557545, 660978.7927557545, 183295.2728745221], 
processed observation next is [1.0, 0.08695652173913043, 0.6363636363636364, 0.83, 1.0, 1.0, 0.11199657719658099, 1.0, 1.0, 0.11199657719658099, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288128620416, 0.24480696027990909, 0.24480696027990909, 0.447061641157371], 
reward next is 0.5529, 
noisyNet noise sample is [array([1.116519], dtype=float32), 0.63742834]. 
=============================================
[2019-03-23 15:46:57,261] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 2.7150277e-15 1.1009844e-19 3.3462036e-19 1.1482243e-25], sum to 1.0000
[2019-03-23 15:46:57,266] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9462
[2019-03-23 15:46:57,271] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1517908.531651275 W.
[2019-03-23 15:46:57,276] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.9, 71.5, 1.0, 2.0, 0.8621320317406816, 0.0, 1.0, 0.0, 1.0, 1.0, 0.984791323880074, 6.911199999999999, 6.9112, 77.32846344354104, 1517908.531651275, 1517908.531651275, 325981.9695332859], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5499000.0000, 
sim time next is 5499600.0000, 
raw observation next is [26.8, 72.33333333333333, 1.0, 2.0, 0.760099493700072, 0.0, 2.0, 0.0, 1.0, 2.0, 0.984019354230038, 6.911199999999999, 6.9112, 77.32846344354104, 1404063.256470008, 1404063.256470008, 307737.9970923823], 
processed observation next is [1.0, 0.6521739130434783, 0.8545454545454546, 0.7233333333333333, 1.0, 1.0, 0.7001243671250901, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9771705060429113, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5200234283222253, 0.5200234283222253, 0.7505804807131276], 
reward next is 0.2494, 
noisyNet noise sample is [array([-0.00627244], dtype=float32), 0.21161404]. 
=============================================
[2019-03-23 15:47:00,137] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 2.3385462e-22 6.8038552e-20 2.3320800e-21 2.0366954e-26], sum to 1.0000
[2019-03-23 15:47:00,149] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6357
[2019-03-23 15:47:00,156] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 560006.5778754877 W.
[2019-03-23 15:47:00,164] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.5, 73.5, 1.0, 2.0, 0.245453684781429, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4959801487245862, 6.911199999999999, 6.9112, 77.32846344354104, 560006.5778754877, 560006.5778754881, 177011.932094467], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5518200.0000, 
sim time next is 5518800.0000, 
raw observation next is [24.4, 74.0, 1.0, 2.0, 0.2446038834595187, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4942108102316056, 6.9112, 6.9112, 77.32846344354104, 558086.8103527321, 558086.8103527321, 176756.2878714106], 
processed observation next is [1.0, 0.9130434782608695, 0.7454545454545454, 0.74, 1.0, 1.0, 0.055754854324398355, 0.0, 1.0, -0.25, 1.0, 1.0, 0.27744401461657947, 0.0, 0.0, 0.5084288129206541, 0.20669881864916004, 0.20669881864916004, 0.4311128972473429], 
reward next is 0.5689, 
noisyNet noise sample is [array([-0.7111298], dtype=float32), -1.585573]. 
=============================================
[2019-03-23 15:47:08,459] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 4.9804601e-11 1.7593738e-35 7.6925605e-28 0.0000000e+00], sum to 1.0000
[2019-03-23 15:47:08,467] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5813
[2019-03-23 15:47:08,470] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.1, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4840661178772259, 6.9112, 6.9112, 77.32846344354104, 281554.4211697627, 281554.4211697627, 89577.14361809239], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5662800.0000, 
sim time next is 5663400.0000, 
raw observation next is [16.0, 86.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4816716652929459, 6.9112, 6.9112, 77.32846344354104, 280161.2997240649, 280161.2997240649, 88757.08818473066], 
processed observation next is [0.0, 0.5652173913043478, 0.36363636363636365, 0.8616666666666667, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2595309504184942, 0.0, 0.0, 0.5084288129206541, 0.10376344434224626, 0.10376344434224626, 0.21648070288958698], 
reward next is 0.7835, 
noisyNet noise sample is [array([0.18586786], dtype=float32), -0.60287154]. 
=============================================
[2019-03-23 15:47:14,577] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.8545700e-01 1.4543068e-02 3.4785835e-25 3.9996416e-18 1.1955655e-35], sum to 1.0000
[2019-03-23 15:47:14,587] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5675
[2019-03-23 15:47:14,590] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.2, 93.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.6096617728075256, 6.9112, 6.9112, 77.32846344354104, 353491.0056981635, 353491.0056981635, 115143.4683504508], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5983200.0000, 
sim time next is 5983800.0000, 
raw observation next is [17.38333333333333, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6485990875367399, 6.911199999999999, 6.9112, 77.32846344354104, 376239.8284291539, 376239.8284291542, 118415.9987356076], 
processed observation next is [1.0, 0.2608695652173913, 0.42651515151515135, 0.92, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.49799869648105705, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13934808460339032, 0.13934808460339043, 0.28881950911123805], 
reward next is 0.7112, 
noisyNet noise sample is [array([0.60331315], dtype=float32), 2.101186]. 
=============================================
[2019-03-23 15:47:15,447] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.3781728e-08 8.0280382e-28 3.0567020e-22 3.1233205e-38], sum to 1.0000
[2019-03-23 15:47:15,452] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5208
[2019-03-23 15:47:15,455] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.31666666666667, 43.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6220337495896257, 6.911199999999999, 6.9112, 77.32846344354104, 360302.1857683576, 360302.1857683579, 116470.7825617273], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5854200.0000, 
sim time next is 5854800.0000, 
raw observation next is [25.13333333333334, 44.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6215700999033686, 6.911199999999999, 6.9112, 77.32846344354104, 359995.9481449901, 359995.9481449904, 116458.8615125647], 
processed observation next is [1.0, 0.782608695652174, 0.7787878787878791, 0.44, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4593858570048124, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13333183264629261, 0.13333183264629275, 0.2840460036891822], 
reward next is 0.7160, 
noisyNet noise sample is [array([-0.01760352], dtype=float32), 0.6570945]. 
=============================================
[2019-03-23 15:47:19,466] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9999988e-01 8.9312962e-08 1.0913652e-29 2.5344122e-23 0.0000000e+00], sum to 1.0000
[2019-03-23 15:47:19,475] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3963
[2019-03-23 15:47:19,481] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.2, 77.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4686077657710763, 6.9112, 6.9112, 77.32846344354104, 272560.6354090572, 272560.6354090572, 89215.09555539794], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5898600.0000, 
sim time next is 5899200.0000, 
raw observation next is [17.2, 78.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.472029120983473, 6.9112, 6.9112, 77.32846344354104, 274551.1913258678, 274551.1913258678, 90290.00980346651], 
processed observation next is [1.0, 0.2608695652173913, 0.41818181818181815, 0.7833333333333333, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.24575588711924717, 0.0, 0.0, 0.5084288129206541, 0.10168562641698807, 0.10168562641698807, 0.22021953610601588], 
reward next is 0.7798, 
noisyNet noise sample is [array([0.18138216], dtype=float32), -0.07059253]. 
=============================================
[2019-03-23 15:47:19,947] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 4.0076755e-09 1.0852330e-30 2.9905427e-23 0.0000000e+00], sum to 1.0000
[2019-03-23 15:47:19,955] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7550
[2019-03-23 15:47:19,958] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.8, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6256359130555559, 6.911199999999999, 6.9112, 77.32846344354104, 362414.3183632311, 362414.3183632314, 116764.8459681001], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5979000.0000, 
sim time next is 5979600.0000, 
raw observation next is [17.7, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6182004652205146, 6.911199999999999, 6.9112, 77.32846344354104, 358289.3720165641, 358289.3720165644, 115983.6271303901], 
processed observation next is [1.0, 0.21739130434782608, 0.44090909090909086, 0.9, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4545720931721638, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13269976741354228, 0.1326997674135424, 0.28288689543997586], 
reward next is 0.7171, 
noisyNet noise sample is [array([1.7418251], dtype=float32), 0.54981434]. 
=============================================
[2019-03-23 15:47:23,063] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 2.3045359e-18 6.4350914e-24 9.7969753e-23 7.3239434e-32], sum to 1.0000
[2019-03-23 15:47:23,073] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0186
[2019-03-23 15:47:23,080] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 764562.1478641094 W.
[2019-03-23 15:47:23,083] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [18.0, 91.5, 1.0, 2.0, 0.3406382575923828, 1.0, 1.0, 0.3406382575923828, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 764562.1478641094, 764562.1478641096, 180901.8506878397], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6445800.0000, 
sim time next is 6446400.0000, 
raw observation next is [18.1, 91.0, 1.0, 2.0, 0.2136522184131132, 1.0, 2.0, 0.2136522184131132, 1.0, 1.0, 0.4184211764742677, 6.9112, 6.9112, 77.3421103, 721113.8333206235, 721113.8333206235, 215108.3968415004], 
processed observation next is [1.0, 0.6086956521739131, 0.45909090909090916, 0.91, 1.0, 1.0, 0.01706527301639147, 1.0, 1.0, 0.01706527301639147, 1.0, 0.5, 0.16917310924895387, 0.0, 0.0, 0.5085185399722538, 0.26707919752615683, 0.26707919752615683, 0.5246546264426839], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.68113923], dtype=float32), -1.2821045]. 
=============================================
[2019-03-23 15:47:36,431] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 7.3538421e-32 7.2379134e-28 2.9960960e-28 4.9434370e-37], sum to 1.0000
[2019-03-23 15:47:36,434] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 15:47:36,437] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:47:36,438] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:47:36,438] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:47:36,438] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:47:36,438] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:47:36,440] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7621
[2019-03-23 15:47:36,440] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:47:36,441] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:47:36,440] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:47:36,441] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:47:36,443] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:47:36,443] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.4, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7271545986297493, 7.026758665323497, 6.9112, 77.32806306320003, 456311.0327013741, 418780.1361109089, 128313.926175037], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6217200.0000, 
sim time next is 6217800.0000, 
raw observation next is [19.4, 87.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.728485234244623, 7.036585584656982, 6.9112, 77.3280358147738, 460185.4569714706, 419463.0088512225, 128519.0520436776], 
processed observation next is [1.0, 1.0, 0.5181818181818181, 0.875, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.6121217632066043, 0.012538558465698202, 0.0, 0.5084260012937729, 0.1704390581375817, 0.15535666994489722, 0.3134611025455551], 
reward next is 0.0596, 
noisyNet noise sample is [array([0.657946], dtype=float32), 0.93159163]. 
=============================================
[2019-03-23 15:47:36,459] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run101
[2019-03-23 15:47:36,482] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run101
[2019-03-23 15:47:36,507] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run101
[2019-03-23 15:47:36,531] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run101
[2019-03-23 15:47:36,566] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/39/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run101
[2019-03-23 15:47:49,363] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00764915], dtype=float32), -0.6184023]
[2019-03-23 15:47:49,364] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [29.0, 55.0, 1.0, 2.0, 0.5321719319110614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 605299.529016975, 605299.529016975, 147415.0408409795]
[2019-03-23 15:47:49,365] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:47:49,367] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 1.3565578e-38 6.1634353e-37 3.8656107e-37 0.0000000e+00], sampled 0.9882461801162884
[2019-03-23 15:47:49,368] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 605299.529016975 W.
[2019-03-23 15:47:56,728] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00764915], dtype=float32), -0.6184023]
[2019-03-23 15:47:56,730] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.486691145, 98.00562602833334, 1.0, 2.0, 0.5510512686403998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 625955.2684028486, 625955.2684028483, 154510.5108540732]
[2019-03-23 15:47:56,733] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:47:56,739] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0000000e+00 0.0000000e+00 4.1837100e-37 1.2067644e-37 0.0000000e+00], sampled 0.9750433960948058
[2019-03-23 15:47:56,740] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 625955.2684028486 W.
[2019-03-23 15:48:14,976] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00764915], dtype=float32), -0.6184023]
[2019-03-23 15:48:14,978] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.0, 51.0, 1.0, 1.0, 0.4705259901236441, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.3281907403006, 535626.4492043261, 535626.4492043259, 135146.6710942601]
[2019-03-23 15:48:14,979] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:48:14,982] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 1.4643734e-38 0.0000000e+00 0.0000000e+00], sampled 0.19677434511469016
[2019-03-23 15:48:21,308] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00764915], dtype=float32), -0.6184023]
[2019-03-23 15:48:21,309] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.74697014666667, 98.39212252166668, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7324597026423829, 7.274467235962713, 6.9112, 95.5522134917789, 564685.2306455831, 418899.0790074174, 135316.8665026092]
[2019-03-23 15:48:21,311] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:48:21,313] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8692428221291373
[2019-03-23 15:48:21,316] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 564685.2306455831 W.
[2019-03-23 15:48:53,430] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00764915], dtype=float32), -0.6184023]
[2019-03-23 15:48:53,431] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [27.13249772666666, 63.97744317666667, 1.0, 2.0, 0.9860657198071653, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 1121543.519752651, 1121543.51975265, 224124.1588001161]
[2019-03-23 15:48:53,432] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:48:53,434] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0000000e+00 2.5120280e-35 4.3840598e-35 6.3355070e-35 0.0000000e+00], sampled 0.1698302730808786
[2019-03-23 15:48:53,436] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1121543.519752651 W.
[2019-03-23 15:48:56,069] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00764915], dtype=float32), -0.6184023]
[2019-03-23 15:48:56,071] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.96666666666667, 79.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5500623303633838, 6.911199999999999, 6.9112, 95.55338769695034, 319933.3130861831, 319933.3130861835, 110130.3336121323]
[2019-03-23 15:48:56,073] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:48:56,077] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8684588047520732
[2019-03-23 15:49:10,917] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00764915], dtype=float32), -0.6184023]
[2019-03-23 15:49:10,919] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.80526315, 53.47666440499999, 1.0, 2.0, 0.447451333296239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338699062449, 509708.2296828051, 509708.2296828051, 137506.6467747003]
[2019-03-23 15:49:10,920] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:49:10,924] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.000000e+00 0.000000e+00 1.897812e-37 5.149328e-38 0.000000e+00], sampled 0.532272095869065
[2019-03-23 15:49:12,034] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00764915], dtype=float32), -0.6184023]
[2019-03-23 15:49:12,035] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.1, 75.0, 1.0, 2.0, 0.4837751262018976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 552028.5932928325, 552028.5932928325, 139224.581876403]
[2019-03-23 15:49:12,036] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:49:12,040] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.00000000e+00 0.00000000e+00 1.35797785e-36 4.26024149e-37
 0.00000000e+00], sampled 0.11643004786069544
[2019-03-23 15:49:12,042] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 552028.5932928325 W.
[2019-03-23 15:49:24,533] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6481.6076 1678885180.2952 3057.0000
[2019-03-23 15:49:24,574] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6328.7217 1723294598.4314 3425.0000
[2019-03-23 15:49:24,851] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 6862.2842 1793014293.7888 2409.0000
[2019-03-23 15:49:24,862] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6294.9961 1685630448.6673 3228.0000
[2019-03-23 15:49:24,893] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6553.1725 1698634175.0084 2957.0000
[2019-03-23 15:49:25,907] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 2500000, evaluation results [2500000.0, 6862.284208925443, 1793014293.78876, 2409.0, 6481.607577760913, 1678885180.2951708, 3057.0, 6294.9960618483565, 1685630448.6673346, 3228.0, 6328.721692698646, 1723294598.4313502, 3425.0, 6553.172466661831, 1698634175.0084193, 2957.0]
